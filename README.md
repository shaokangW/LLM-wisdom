# LLM-wisdom
The papers related to the LLM wisdom, including test-time scaling, knowledge editing, model recognition, capacity enhancement, RAG, Agent, internal mechanism of LLM and etc. 

# 2025-06-16
+ [A Practical Guide for Evaluating LLMs and LLM-Reliant Systems](https://arxiv.org//abs/2506.13023)

	Ethan M. Rudd, Christopher Andrews, Philip Tully

+ [Discerning What Matters: A Multi-Dimensional Assessment of Moral Competence in LLMs](https://arxiv.org//abs/2506.13082)

	Daniel Kilov, Caroline Hendy, Secil Yanik Guyot, Aaron J. Snoswell, Seth Lazar

+ [AlphaEvolve: A coding agent for scientific and algorithmic discovery](https://arxiv.org//abs/2506.13131)

	Alexander Novikov, Ngân Vũ, Marvin Eisenberger, Emilien Dupont, Po-Sen Huang, Adam Zsolt Wagner, Sergey Shirobokov, Borislav Kozlovskii, Francisco J. R. Ruiz, Abbas Mehrabian, M. Pawan Kumar, Abigail See, Swarat Chaudhuri, George Holland, Alex Davies, Sebastian Nowozin, Pushmeet Kohli, Matej Balog

+ [A Game-Theoretic Negotiation Framework for Cross-Cultural Consensus in LLMs](https://arxiv.org//abs/2506.13245)

	Guoxi Zhang, Jiawei Chen, Tianzhuo Yang, Jiaming Ji, Yaodong Yang, Juntao Dai

+ [Vector Ontologies as an LLM world view extraction method](https://arxiv.org//abs/2506.13252)

	Kaspar Rothenfusser, Bekk Blando

+ [Navigating the Black Box: Leveraging LLMs for Effective Text-Level Graph Injection Attacks](https://arxiv.org//abs/2506.13276)

	Yuefei Lyu, Chaozhuo Li, Xi Zhang, Tianle Zhang

+ [Towards Pervasive Distributed Agentic Generative AI -- A State of The Art](https://arxiv.org//abs/2506.13324)

	Gianni Molinari, Fabio Ciravegna

+ [Verifying the Verifiers: Unveiling Pitfalls and Potentials in Fact Verifiers](https://arxiv.org//abs/2506.13342)

	Wooseok Seo, Seungju Han, Jaehun Jung, Benjamin Newman, Seungwon Lim, Seungbeen Lee, Ximing Lu, Yejin Choi, Youngjae Yu

+ [Socratic RL: A Novel Framework for Efficient Knowledge Acquisition through Iterative Reflection and Viewpoint Distillation](https://arxiv.org//abs/2506.13358)

	Xiangfan Wu

+ [Weakest Link in the Chain: Security Vulnerabilities in Advanced Reasoning Models](https://arxiv.org//abs/2506.13726)

	Arjun Krishna, Aaditya Rastogi, Erick Galinkin

+ [NaSh: Guardrails for an LLM-Powered Natural Language Shell](https://arxiv.org//abs/2506.13028)

	Bimal Raj Gyawali, Saikrishna Achalla, Konstantinos Kallas, Sam Kumar

+ [Just Go Parallel: Improving the Multilingual Capabilities of Large Language Models](https://arxiv.org//abs/2506.13044)

	Muhammad Reza Qorib, Junyi Li, Hwee Tou Ng

+ [MotiveBench: How Far Are We From Human-Like Motivational Reasoning in Large Language Models?](https://arxiv.org//abs/2506.13065)

	Xixian Yong, Jianxun Lian, Xiaoyuan Yi, Xiao Zhou, Xing Xie

+ [CHILL at SemEval-2025 Task 2: You Can't Just Throw Entities and Hope -- Make Your LLM to Get Them Right](https://arxiv.org//abs/2506.13070)

	Jaebok Lee, Yonghyun Ryu, Seongmin Park, Yoonjung Choi

+ [Rethinking Test-Time Scaling for Medical AI: Model and Task-Aware Strategies for LLMs and VLMs](https://arxiv.org//abs/2506.13102)

	Gyutaek Oh, Seoyeon Kim, Sangjoon Park, Byung-Hoon Kim

+ [Leveraging In-Context Learning for Language Model Agents](https://arxiv.org//abs/2506.13109)

	Shivanshu Gupta, Sameer Singh, Ashish Sabharwal, Tushar Khot, Ben Bogin

+ [ZINA: Multimodal Fine-grained Hallucination Detection and Editing](https://arxiv.org//abs/2506.13130)

	Yuiga Wada, Kazuki Matsuda, Komei Sugiura, Graham Neubig

+ [Adapting LLMs for Minimal-edit Grammatical Error Correction](https://arxiv.org//abs/2506.13148)

	Ryszard Staruch, Filip Graliński, Daniel Dzienisiewicz

+ [Querying Large Automotive Software Models: Agentic vs. Direct LLM Approaches](https://arxiv.org//abs/2506.13171)

	Lukasz Mazur, Nenad Petrovic, James Pontes Miranda, Ansgar Radermacher, Robert Rasche, Alois Knoll

+ [From Empirical Evaluation to Context-Aware Enhancement: Repairing Regression Errors with LLMs](https://arxiv.org//abs/2506.13182)

	Anh Ho, Thanh Le-Cong, Bach Le, Christine Rizkallah

+ [Dynamic Context-oriented Decomposition for Task-aware Low-rank Adaptation with Less Forgetting and Faster Convergence](https://arxiv.org//abs/2506.13187)

	Yibo Yang, Sihao Liu, Chuan Rao, Bang An, Tiancheng Shen, Philip H.S. Torr, Ming-Hsuan Yang, Bernard Ghanem

+ [Breaking Thought Patterns: A Multi-Dimensional Reasoning Framework for LLMs](https://arxiv.org//abs/2506.13192)

	Xintong Tang, Meiru Zhang, Shang Xiao, Junzhao Jin, Zihan Zhao, Liwei Li, Yang Zheng, Bangyi Wu

+ [Screen Hijack: Visual Poisoning of VLM Agents in Mobile Environments](https://arxiv.org//abs/2506.13205)

	Xuan Wang, Siyuan Liang, Zhe Liu, Yi Yu, Yuliang Lu, Xiaochun Cao, Ee-Chien Chang

+ [Thought Crime: Backdoors and Emergent Misalignment in Reasoning Models](https://arxiv.org//abs/2506.13206)

	James Chua, Jan Betley, Mia Taylor, Owain Evans

+ [Distinct Computations Emerge From Compositional Curricula in In-Context Learning](https://arxiv.org//abs/2506.13253)

	Jin Hwa Lee, Andrew K. Lampinen, Aaditya K. Singh, Andrew M. Saxe

+ [AceReason-Nemotron 1.1: Advancing Math and Code Reasoning through SFT and RL Synergy](https://arxiv.org//abs/2506.13284)

	Zihan Liu, Zhuolin Yang, Yang Chen, Chankyu Lee, Mohammad Shoeybi, Bryan Catanzaro, Wei Ping

+ [Direct Reasoning Optimization: LLMs Can Reward And Refine Their Own Reasoning for Open-Ended Tasks](https://arxiv.org//abs/2506.13351)

	Yifei Xu, Tusher Chakraborty, Srinagesh Sharma, Leonardo Nunes, Emre Kıcıman, Songwu Lu, Ranveer Chandra

+ [StoryBench: A Dynamic Benchmark for Evaluating Long-Term Memory with Multi Turns](https://arxiv.org//abs/2506.13356)

	Luanbo Wan, Weizhi Ma

+ [Unveiling the Learning Mind of Language Models: A Cognitive Framework and Empirical Study](https://arxiv.org//abs/2506.13464)

	Zhengyu Hu, Jianxun Lian, Zheyuan Xiao, Seraphina Zhang, Tianfu Wang, Nicholas Jing Yuan, Xing Xie, Hui Xiong

+ [ROSAQ: Rotation-based Saliency-Aware Weight Quantization for Efficiently Compressing Large Language Models](https://arxiv.org//abs/2506.13472)

	Junho Yoon, Geom Lee, Donghyeon Jeon, Inho Kang, Seung-Hoon Na

+ [Language Agents for Hypothesis-driven Clinical Decision Making with Reinforcement Learning](https://arxiv.org//abs/2506.13474)

	David Bani-Harouni, Chantal Pellegrini, Ege Özsoy, Matthias Keicher, Nassir Navab

+ [Position: Pause Recycling LoRAs and Prioritize Mechanisms to Uncover Limits and Effectiveness](https://arxiv.org//abs/2506.13479)

	Mei-Yen Chen, Thi Thu Uyen Hoang, Michael Hahn, M. Saquib Sarfraz

+ [Understand the Implication: Learning to Think for Pragmatic Understanding](https://arxiv.org//abs/2506.13559)

	Settaluri Lakshmi Sravanthi, Kishan Maharaj, Sravani Gunnu, Abhijit Mishra, Pushpak Bhattacharyya

+ [CAMS: A CityGPT-Powered Agentic Framework for Urban Human Mobility Simulation](https://arxiv.org//abs/2506.13599)

	Yuwei Du, Jie Feng, Jian Yuan, Yong Li

+ [DualEdit: Dual Editing for Knowledge Updating in Vision-Language Models](https://arxiv.org//abs/2506.13638)

	Zhiyi Shi, Binjie Wang, Chongjie Si, Yichen Wu, Junsik Kim, Hanspeter Pfister

+ [We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems](https://arxiv.org//abs/2506.13666)

	Junfeng Fang, Zijun Yao, Ruipeng Wang, Haokai Ma, Xiang Wang, Tat-Seng Chua

+ [Prefix-Tuning+: Modernizing Prefix-Tuning through Attention Independent Prefix Data](https://arxiv.org//abs/2506.13674)

	Haonan Wang, Brian Chen, Li Siquan, Liang Xinhe, Tianyang Hu, Hwee Kuan Lee, Kenji Kawaguchi

+ [TimeMaster: Training Time-Series Multimodal LLMs to Reason via Reinforcement Learning](https://arxiv.org//abs/2506.13705)

	Junru Zhang, Lang Feng, Xu Guo, Yuhan Wu, Yabo Dong, Duanqing Xu

+ [Attribution-guided Pruning for Compression, Circuit Discovery, and Targeted Correction in LLMs](https://arxiv.org//abs/2506.13727)

	Sayed Mohammad Vakilzadeh Hatefi, Maximilian Dreyer, Reduan Achtibat, Patrick Kahardipraja, Thomas Wiegand, Wojciech Samek, Sebastian Lapuschkin

+ [Instruction Following by Boosting Attention of Large Language Models](https://arxiv.org//abs/2506.13734)

	Vitoria Guardieiro, Adam Stein, Avishree Khare, Eric Wong

+ [Evaluating Large Language Models for Phishing Detection, Self-Consistency, Faithfulness, and Explainability](https://arxiv.org//abs/2506.13746)

	Shova Kuikel, Aritran Piplai, Palvi Aggarwal

+ [Steering LLM Thinking with Budget Guidance](https://arxiv.org//abs/2506.13752)

	Junyan Li, Wenshuo Zhao, Yang Zhang, Chuang Gan

+ [Multipole Attention for Efficient Long Context Reasoning](https://arxiv.org//abs/2506.13059)

	Coleman Hooper, Sebastian Zhao, Luca Manolache, Sehoon Kim, Michael W. Mahoney, Yakun Sophia Shao, Kurt Keutzer, Amir Gholami

+ [FinLMM-R1: Enhancing Financial Reasoning in LMM through Scalable Data and Reward Design](https://arxiv.org//abs/2506.13066)

	Kai Lan, Jiayong Zhu, Jiangtong Li, Dawei Cheng, Guang Chen, Changjun Jiang

+ [Enhancing Large Language Models with Reliable Knowledge Graphs](https://arxiv.org//abs/2506.13178)

	Qinggang Zhang

+ [Align-then-Unlearn: Embedding Alignment for LLM Unlearning](https://arxiv.org//abs/2506.13181)

	Philipp Spohn, Leander Girrbach, Jessica Bader, Zeynep Akata

+ [Capability Salience Vector: Fine-grained Alignment of Loss and Capabilities for Downstream Task Scaling Law](https://arxiv.org//abs/2506.13216)

	Qiming Ge, Shuhao Xing, Songyang Gao, Yunhua Zhou, Yicheng Zou, Songyang Zhang, Zhi Chen, Hang Yan, Qi Zhang, Qipeng Guo, Kai Chen

+ [IGD: Token Decisiveness Modeling via Information Gain in LLMs for Personalized Recommendation](https://arxiv.org//abs/2506.13229)

	Zijie Lin, Yang Zhang, Xiaoyan Zhao, Fengbin Zhu, Fuli Feng, Tat-Seng Chua

+ [Mitigating Safety Fallback in Editing-based Backdoor Injection on LLMs](https://arxiv.org//abs/2506.13285)

	Houcheng Jiang, Zetong Zhao, Junfeng Fang, Haokai Ma, Ruipeng Wang, Yang Deng, Xiang Wang, Xiangnan He

+ [Document-Level Tabular Numerical Cross-Checking: A Coarse-to-Fine Approach](https://arxiv.org//abs/2506.13328)

	Chaoxu Pang, Yixuan Cao, Ganbin Zhou, Hongwei Li, Ping Luo

+ [EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization](https://arxiv.org//abs/2506.13329)

	Zhongqian Fu, Ning Ding, Kai Han, Xianzhi Yu, Xiaosong Li, Xinghao Chen, Yehui Tang, Yunhe Wang

+ [Decompositional Reasoning for Graph Retrieval with Large Language Models](https://arxiv.org//abs/2506.13380)

	Valentin Six, Evan Dufraisse, Gaël de Chalendar

+ [RealHiTBench: A Comprehensive Realistic Hierarchical Table Benchmark for Evaluating LLM-Based Table Analysis](https://arxiv.org//abs/2506.13405)

	Pengzuo Wu, Yuhang Yang, Guangcheng Zhu, Chao Ye, Hong Gu, Xu Lu, Ruixuan Xiao, Bowen Bao, Yijing He, Liangyu Zha, Wentao Ye, Junbo Zhao, Haobo Wang

+ [BOW: Bottlenecked Next Word Exploration](https://arxiv.org//abs/2506.13502)

	Ming Shen, Zhikun Xu, Xiao Ye, Jacob Dineen, Ben Zhou

+ [Mixture of Weight-shared Heterogeneous Group Attention Experts for Dynamic Token-wise KV Optimization](https://arxiv.org//abs/2506.13541)

	Guanghui Song, Dongping Liao, Yiren Zhao, Kejiang Ye, Cheng-zhong Xu, Xitong Gao

+ [MiniMax-M1: Scaling Test-Time Compute Efficiently with Lightning Attention](https://arxiv.org//abs/2506.13585)

	MiniMax: Aili Chen, Aonian Li, Bangwei Gong, Binyang Jiang, Bo Fei, Bo Yang, Boji Shan, Changqing Yu, Chao Wang, Cheng Zhu, Chengjun Xiao, Chengyu Du, Chi Zhang, Chu Qiao, Chunhao Zhang, Chunhui Du, Congchao Guo, Da Chen, Deming Ding, Dianjun Sun, Dong Li, Enwei Jiao, Haigang Zhou, Haimo Zhang, Han Ding, Haohai Sun, Haoyu Feng, Huaiguang Cai, Haichao Zhu, Jian Sun, Jiaqi Zhuang, Jiaren Cai, Jiayuan Song, Jin Zhu, Jingyang Li, Jinhao Tian, Jinli Liu, Junhao Xu, Junjie Yan, Junteng Liu, Junxian He, Kaiyi Feng, Ke Yang, Kecheng Xiao, Le Han, Leyang Wang, Lianfei Yu, Liheng Feng, Lin Li, Lin Zheng, Linge Du, Lingyu Yang, Lunbin Zeng, Minghui Yu, Mingliang Tao, Mingyuan Chi, Mozhi Zhang, Mujie Lin, Nan Hu, Nongyu Di, Peng Gao, Pengfei Li, Pengyu Zhao, Qibing Ren, Qidi Xu, Qile Li, Qin Wang, Rong Tian, Ruitao Leng, Shaoxiang Chen, Shaoyu Chen, Shengmin Shi, Shitong Weng, Shuchang Guan, Shuqi Yu, Sichen Li, Songquan Zhu, Tengfei Li, Tianchi Cai, Tianrun Liang, Weiyu Cheng, Weize Kong, Wenkai Li, Xiancai Chen, Xiangjun Song, Xiao Luo, Xiao Su, Xiaobo Li, Xiaodong Han, Xinzhu Hou, Xuan Lu, Xun Zou, Xuyang Shen, Yan Gong, Yan Ma, Yang Wang, Yiqi Shi, Yiran Zhong, Yonghong Duan

+ [An Empirical Study of LLM-as-a-Judge: How Design Choices Impact Evaluation Reliability](https://arxiv.org//abs/2506.13639)

	Yusuke Yamauchi, Taro Yano, Masafumi Oyamada

+ [EvolvTrip: Enhancing Literary Character Understanding with Temporal Theory-of-Mind Graphs](https://arxiv.org//abs/2506.13641)

	Bohao Yang, Hainiu Xu, Jinhua Du, Ze Li, Yulan He, Chenghua Lin

+ [Turning Down the Heat: A Critical Analysis of Min-p Sampling in Language Models](https://arxiv.org//abs/2506.13681)

	Rylan Schaeffer, Joshua Kazdan, Yegor Denisov-Blanch

+ [LTRR: Learning To Rank Retrievers for LLMs](https://arxiv.org//abs/2506.13743)

	To Eun Kim, Fernando Diaz

+ [HKD4VLM: A Progressive Hybrid Knowledge Distillation Framework for Robust Multimodal Hallucination and Factuality Detection in VLMs](https://arxiv.org//abs/2506.13038)

	Zijian Zhang, Xuecheng Wu, Danlei Huang, Siyu Yan, Chong Peng, Xuezhi Cao

+ [Evolution of ReID: From Early Methods to LLM Integration](https://arxiv.org//abs/2506.13039)

	Amran Bhuiyan, Mizanur Rahman, Md Tahmid Rahman Laskar, Aijun An, Jimmy Xiangji Huang

+ [VIS-Shepherd: Constructing Critic for LLM-based Data Visualization Generation](https://arxiv.org//abs/2506.13326)

	Bo Pan, Yixiao Fu, Ke Wang, Junyu Lu, Lunke Pan, Ziyang Qian, Yuhan Chen, Guoliang Wang, Yitao Zhou, Li Zheng, Yinghao Tang, Zhen Wen, Yuchen Wu, Junhua Lu, Biao Zhu, Minfeng Zhu, Bo Zhang, Wei Chen

+ [Omni-AdaVideoRAG: Omni-Contextual Adaptive Retrieval-Augmented for Efficient Long Video Understanding](https://arxiv.org//abs/2506.13589)

	Zhucun Xue, Jiangning Zhang, Xurong Xie, Yuxuan Cai, Yong Liu, Xiangtai Li, Dacheng Tao

+ [A Comprehensive Survey on Continual Learning in Generative Models](https://arxiv.org//abs/2506.13045)

	Haiyang Guo, Fanhu Zeng, Fei Zhu, Jiayi Wang, Xukai Wang, Jingang Zhou, Hongbo Zhao, Wenzhuo Liu, Shijie Ma, Xu-Yao Zhang, Cheng-Lin Liu

+ [Antibody Foundational Model : Ab-RoBERTa](https://arxiv.org//abs/2506.13006)

	Eunna Huh, Hyeonsu Lee, Hyunjin Shin

+ [Mixture of Cognitive Reasoners: Modular Reasoning with Brain-Like Specialization](https://arxiv.org//abs/2506.13331)

	Badr AlKhamissi, C. Nicolò De Sabbata, Zeming Chen, Martin Schrimpf, Antoine Bosselut

+ [Calibrated Predictive Lower Bounds on Time-to-Unsafe-Sampling in LLMs](https://arxiv.org//abs/2506.13593)

	Hen Davidov, Gilad Freidkin, Shai Feldman, Yaniv Romano

+ [Assessing the Limits of In-Context Learning beyond Functions using Partially Ordered Relation](https://arxiv.org//abs/2506.13608)

	Debanjan Dutta, Faizanuddin Ansari, Swagatam Das

+ [xbench: Tracking Agents Productivity Scaling with Profession-Aligned Real-World Evaluations](https://arxiv.org//abs/2506.13651)

	Kaiyuan Chen, Yixin Ren, Yang Liu, Xiaobo Hu, Haotong Tian, Tianbao Xie, Fangfu Liu, Haoye Zhang, Hongzhang Liu, Yuan Gong, Chen Sun, Han Hou, Hui Yang, James Pan, Jianan Lou, Jiayi Mao, Jizheng Liu, Jinpeng Li, Kangyi Liu, Kenkun Liu, Rui Wang, Run Li, Tong Niu, Wenlong Zhang, Wenqi Yan, Xuanzheng Wang, Yuchen Zhang, Yi-Hsin Hung, Yuan Jiang, Zexuan Liu, Zihan Yin, Zijian Ma, Zhiwen Mo

+ [What Happens During the Loss Plateau? Understanding Abrupt Learning in Transformers](https://arxiv.org//abs/2506.13688)

	Pulkit Gopalani, Wei Hu

+ [Position: Certified Robustness Does Not (Yet) Imply Model Security](https://arxiv.org//abs/2506.13024)

	Andrew C. Cullen, Paul Montague, Sarah M. Erfani, Benjamin I.P. Rubinstein

+ [Detecting Hard-Coded Credentials in Software Repositories via LLMs](https://arxiv.org//abs/2506.13090)

	Chidera Biringa, Gokhan Kul

+ [Using LLMs for Security Advisory Investigations: How Far Are We?](https://arxiv.org//abs/2506.13161)

	Bayu Fedra Abdullah, Yusuf Sulistyo Nugroho, Brittany Reid, Raula Gaikovina Kula, Kazumasa Shimari, Kenichi Matsumoto

+ [From Promise to Peril: Rethinking Cybersecurity Red and Blue Teaming in the Age of LLMs](https://arxiv.org//abs/2506.13434)

	Alsharif Abuadbba, Chris Hicks, Kristen Moore, Vasilios Mavroudis, Burak Hasircioglu, Diksha Goel, Piers Jennings

+ [Watermarking LLM-Generated Datasets in Downstream Tasks](https://arxiv.org//abs/2506.13494)

	Yugeng Liu, Tianshuo Cong, Michael Backes, Zheng Li, Yang Zhang

+ [ExtendAttack: Attacking Servers of LRMs via Extending Reasoning](https://arxiv.org//abs/2506.13737)

	Zhenhao Zhu, Yue Liu, Yingwei Ma, Hongcheng Gao, Nuo Chen, Yanpei Guo, Wenjie Qu, Huiying Xu, Xinzhong Zhu, Jiaheng Zhang

# 2025-06-15
+ [SciSage: A Multi-Agent Framework for High-Quality Scientific Survey Generation](https://arxiv.org//abs/2506.12689)

	Xiaofeng Shi, Qian Kou, Yuduo Li, Ning Tang, Jinxin Xie, Longbin Yu, Songjing Wang, Hua Zhou

+ [Strategic Scaling of Test-Time Compute: A Bandit Learning Approach](https://arxiv.org//abs/2506.12721)

	Bowen Zuo, Yinglun Zhu

+ [Rethinking DPO: The Role of Rejected Responses in Preference Misalignment](https://arxiv.org//abs/2506.12725)

	Jay Hyeon Cho, JunHyeok Oh, Myunsoo Kim, Byung-Jun Lee

+ [Mastering Da Vinci Code: A Comparative Study of Transformer, LLM, and PPO-based Agents](https://arxiv.org//abs/2506.12801)

	LeCheng Zhang, Yuanshi Wang, Haotian Shen, Xujie Wang

+ [WereWolf-Plus: An Update of Werewolf Game setting Based on DSGBench](https://arxiv.org//abs/2506.12841)

	Xinyuan Xia, Yuanyi Song, Haomin Ma, Jinyu Cai

+ [Sectoral Coupling in Linguistic State Space](https://arxiv.org//abs/2506.12927)

	Sebastian Dumbrava

+ [Scaling Test-time Compute for LLM Agents](https://arxiv.org//abs/2506.12928)

	King Zhu, Hanhao Li, Siwei Wu, Tianshun Xing, Dehua Ma, Xiangru Tang, Minghao Liu, Jian Yang, Jiaheng Liu, Yuchen Eleanor Jiang, Changwang Zhang, Chenghua Lin, Jun Wang, Ge Zhang, Wangchunshu Zhou

+ [Reasoning Model Unlearning: Forgetting Traces, Not Just Answers, While Preserving Reasoning Skills](https://arxiv.org//abs/2506.12963)

	Changsheng Wang, Chongyu Fan, Yihua Zhang, Jinghan Jia, Dennis Wei, Parikshit Ram, Nathalie Baracaldo, Sijia Liu

+ [Efficient Neuro-Symbolic Retrieval-Augmented Generation through Adaptive Query Routing](https://arxiv.org//abs/2506.12981)

	Safayat Bin Hakim, Muhammad Adil, Alvaro Velasquez, Houbing Herbert Song

+ [Alphabet Index Mapping: Jailbreaking LLMs through Semantic Dissimilarity](https://arxiv.org//abs/2506.12685)

	Bilal Saleh Husain

+ [Flexible Realignment of Language Models](https://arxiv.org//abs/2506.12704)

	Wenhong Zhu, Ruobing Xie, Weinan Zhang, Rui Wang

+ [eLog analysis for accelerators: status and future outlook](https://arxiv.org//abs/2506.12949)

	Antonin Sulc, Thorsten Hellert, Aaron Reed, Adam Carpenter, Alex Bien, Chris Tennant, Claudio Bisegni, Daniel Lersch, Daniel Ratner, David Lawrence, Diana McSpadden, Hayden Hoschouer, Jason St. John, Thomas Britton

+ [Democratic or Authoritarian? Probing a New Dimension of Political Biases in Large Language Models](https://arxiv.org//abs/2506.12758)

	David Guzman Piedrahita, Irene Strauss, Bernhard Schölkopf, Rada Mihalcea, Zhijing Jin

+ [Surprise Calibration for Better In-Context Learning](https://arxiv.org//abs/2506.12796)

	Zhihang Tan, Jingrui Hou, Ping Wang, Qibiao Hu, Peng Zhu

+ [Transforming Chatbot Text: A Sequence-to-Sequence Approach](https://arxiv.org//abs/2506.12843)

	Natesh Reddy, Mark Stamp

+ [QFFT, Question-Free Fine-Tuning for Adaptive Reasoning](https://arxiv.org//abs/2506.12860)

	Wanlong Liu, Junxiao Xu, Fei Yu, Yukang Lin, Ke Ji, Wenyu Chen, Yan Xu, Yasheng Wang, Lifeng Shang, Benyou Wang

+ [SciDA: Scientific Dynamic Assessor of LLMs](https://arxiv.org//abs/2506.12909)

	Junting Zhou, Tingjia Miao, Yiyan Liao, Qichao Wang, Zhoufutu Wen, Yanqin Wang, Yunjie Huang, Ge Yan, Leqi Wang, Yucheng Xia, Hongwan Gao, Yuansong Zeng, Renjie Zheng, Chen Dun, Yitao Liang, Tong Yang, Wenhao Huang, Ge Zhang

+ [PersonaFeedback: A Large-scale Human-annotated Benchmark For Personalization](https://arxiv.org//abs/2506.12915)

	Meiling Tao, Chenghao Zhu, Dongyi Ding, Tiannan Wang, Yuchen Eleanor Jiang, Wangchunshu Zhou

+ [Multi-document Summarization through Multi-document Event Relation Graph Reasoning in LLMs: a case study in Framing Bias Mitigation](https://arxiv.org//abs/2506.12978)

	Yuanyuan Lei, Ruihong Huang

+ [Large Language Models Enhanced by Plug and Play Syntactic Knowledge for Aspect-based Sentiment Analysis](https://arxiv.org//abs/2506.12991)

	Yuanhe Tian, Xu Li, Wei Wang, Guoqing Jin, Pengsen Cheng, Yan Song

+ [SecurityLingua: Efficient Defense of LLM Jailbreak Attacks via Security-Aware Prompt Compression](https://arxiv.org//abs/2506.12707)

	Yucheng Li, Surin Ahn, Huiqiang Jiang, Amir H. Abdi, Yuqing Yang, Lili Qiu

+ [Humanity's Last Code Exam: Can Advanced LLMs Conquer Human's Hardest Code Competition?](https://arxiv.org//abs/2506.12713)

	Xiangyang Li, Xiaopeng Li, Kuicai Dong, Quanhu Zhang, Rongju Ruan, Xinyi Dai, Xiaoshuang Liu, Shengchun Xu, Yasheng Wang, Ruiming Tang

+ [Dynamic Modality Scheduling for Multimodal Large Models via Confidence, Uncertainty, and Semantic Consistency](https://arxiv.org//abs/2506.12724)

	Hiroshi Tanaka, Anika Rao, Hana Satou, Michael Johnson, Sofia García

+ [LOP: Learning Optimal Pruning for Efficient On-Demand MLLMs Scaling](https://arxiv.org//abs/2506.12826)

	Zhihan Zhang, Xiang Pan, Hongchen Wei, Zhenzhong Chen

+ [MaskPro: Linear-Space Probabilistic Learning for Strict (N:M)-Sparsity on Large Language Models](https://arxiv.org//abs/2506.12876)

	Yan Sun, Qixin Zhang, Zhiyuan Yu, Xikun Zhang, Li Shen, Dacheng Tao

+ [Jailbreak Strength and Model Similarity Predict Transferability](https://arxiv.org//abs/2506.12913)

	Rico Angell, Jannik Brinkmann, He He

+ [SoK: The Privacy Paradox of Large Language Models: Advancements, Privacy Risks, and Mitigation](https://arxiv.org//abs/2506.12699)

	Yashothara Shanmugarasa, Ming Ding, M.A.P Chamikara, Thierry Rakotoarivelo

+ [Universal Jailbreak Suffixes Are Strong Attention Hijackers](https://arxiv.org//abs/2506.12880)

	Matan Ben-Tov, Mor Geva, Mahmood Sharif

# 2025-06-14
+ [The SWE-Bench Illusion: When State-of-the-Art LLMs Remember Instead of Reason](https://arxiv.org//abs/2506.12286)

	Shanchao Liang, Spandan Garg, Roshanak Zilouchian Moghaddam

+ [The Budget AI Researcher and the Power of RAG Chains](https://arxiv.org//abs/2506.12317)

	Franklin Lee, Tengfei Ma

+ [ConsistencyChecker: Tree-based Evaluation of LLM Generalization Capabilities](https://arxiv.org//abs/2506.12376)

	Zhaochen Hong, Haofei Yu, Jiaxuan You

+ [Model Merging for Knowledge Editing](https://arxiv.org//abs/2506.12384)

	Zichuan Fu, Xian Wu, Guojing Li, Yingying Zhang, Yefeng Zheng, Tianshi Ming, Yejing Wang, Wanyu Wang, Xiangyu Zhao

+ [Plan Your Travel and Travel with Your Plan: Wide-Horizon Planning and Evaluation via LLM](https://arxiv.org//abs/2506.12421)

	Dongjie Yang, Chengqiang Lu, Qimeng Wang, Xinbei Ma, Yan Gao, Yao Hu, Hai Zhao

+ [Tiered Agentic Oversight: A Hierarchical Multi-Agent System for AI Safety in Healthcare](https://arxiv.org//abs/2506.12482)

	Yubin Kim, Hyewon Jeong, Chanwoo Park, Eugene Park, Haipeng Zhang, Xin Liu, Hyeonhoon Lee, Daniel McDuff, Marzyeh Ghassemi, Cynthia Breazeal, Samir Tulebaev, Hae Won Park

+ [MALM: A Multi-Information Adapter for Large Language Models to Mitigate Hallucination](https://arxiv.org//abs/2506.12483)

	Ao Jia, Haiming Wu, Guohui Yao, Dawei Song, Songkun Ji, Yazhou Zhang

+ [AgentOrchestra: A Hierarchical Multi-Agent Framework for General-Purpose Task Solving](https://arxiv.org//abs/2506.12508)

	Wentao Zhang, Ce Cui, Yilei Zhao, Yang Liu, Bo An

+ [Graph of Verification: Structured Verification of LLM Reasoning with Directed Acyclic Graphs](https://arxiv.org//abs/2506.12509)

	Jiwei Fang, Bin Zhang, Changwei Wang, Jin Wan, Zhiwei Xu

+ [LIFELONG SOTOPIA: Evaluating Social Intelligence of Language Agents Over Lifelong Social Interactions](https://arxiv.org//abs/2506.12666)

	Hitesh Goel, Hao Zhu

+ [QGuard:Question-based Zero-shot Guard for Multi-modal LLM Safety](https://arxiv.org//abs/2506.12299)

	Taegyeong Lee, Jeonghwa Yoo, Hyoungseo Cho, Soo Yong Kim, Yunho Maeng

+ [Unveiling Confirmation Bias in Chain-of-Thought Reasoning](https://arxiv.org//abs/2506.12301)

	Yue Wan, Xiaowei Jia, Xiang Lorraine Li

+ [Med-U1: Incentivizing Unified Medical Reasoning in LLMs via Large-scale Reinforcement Learning](https://arxiv.org//abs/2506.12307)

	Xiaotian Zhang, Yuan Wang, Zhaopeng Feng, Ruizhe Chen, Zhijie Zhou, Yan Zhang, Hongxia Xu, Jian Wu, Zuozhu Liu

+ [The Foundation Cracks: A Comprehensive Study on Bugs and Testing Practices in LLM Libraries](https://arxiv.org//abs/2506.12320)

	Weipeng Jiang, Xiaoyu Zhang, Xiaofei Xie, Jiongchi Yu, Yuhan Zhi, Shiqing Ma, Chao Shen

+ [Extending Memorization Dynamics in Pythia Models from Instance-Level Insights](https://arxiv.org//abs/2506.12321)

	Jie Zhang, Qinghua Zhao, Lei Li, Chi-ho Lin

+ [Intersectional Bias in Japanese Large Language Models from a Contextualized Perspective](https://arxiv.org//abs/2506.12327)

	Hitomi Yanaka, Xinqi He, Jie Lu, Namgi Han, Sunjin Oh, Ryoma Kumon, Yuma Matsuoka, Katsuhiko Watabe, Yuko Itatsu

+ [IndoorWorld: Integrating Physical Task Solving and Social Simulation in A Heterogeneous Multi-Agent Environment](https://arxiv.org//abs/2506.12331)

	Dekun Wu, Frederik Brudy, Bang Liu, Yi Wang

+ [SheetMind: An End-to-End LLM-Powered Multi-Agent Framework for Spreadsheet Automation](https://arxiv.org//abs/2506.12339)

	Ruiyan Zhu, Xi Cheng, Ke Liu, Brian Zhu, Daniel Jin, Neeraj Parihar, Zhoutian Xu, Oliver Gao

+ [Refract ICL: Rethinking Example Selection in the Era of Million-Token Models](https://arxiv.org//abs/2506.12346)

	Arjun R. Akula, Kazuma Hashimoto, Krishna Srinivasan, Aditi Chaudhary, Karthik Raman, Michael Bendersky

+ [Information Suppression in Large Language Models: Auditing, Quantifying, and Characterizing Censorship in DeepSeek](https://arxiv.org//abs/2506.12349)

	Peiran Qiu, Siyi Zhou, Emilio Ferrara

+ [Efficient Reasoning Through Suppression of Self-Affirmation Reflections in Large Reasoning Models](https://arxiv.org//abs/2506.12353)

	Kaiyuan Liu, Chen Shen, Zhanwei Zhang, Junjie Liu, Xiaosong Yuan, Jieping ye

+ [Training-free LLM Merging for Multi-task Learning](https://arxiv.org//abs/2506.12379)

	Zichuan Fu, Xian Wu, Yejing Wang, Wanyu Wang, Shanshan Ye, Hongzhi Yin, Yi Chang, Yefeng Zheng, Xiangyu Zhao

+ [Exploring the Secondary Risks of Large Language Models](https://arxiv.org//abs/2506.12382)

	Jiawei Chen, Zhengwei Fang, Xiao Yang, Chao Yu, Zhaoxia Yin, Hang Su

+ [Group then Scale: Dynamic Mixture-of-Experts Multilingual Language Model](https://arxiv.org//abs/2506.12388)

	Chong Li, Yingzhuo Deng, Jiajun Zhang, Chengqing Zong

+ [LARGO: Low-Rank Regulated Gradient Projection for Robust Parameter Efficient Fine-Tuning](https://arxiv.org//abs/2506.12394)

	Haotian Zhang, Liu Liu, Baosheng Yu, Jiayan Qiu, Yanwei Ren, Xianglong Liu

+ [Robust LLM Unlearning with MUDMAN: Meta-Unlearning with Disruption Masking And Normalization](https://arxiv.org//abs/2506.12484)

	Filip Sondej, Yushi Yang, Mikołaj Kniejski, Marcel Windys

+ [RealFactBench: A Benchmark for Evaluating Large Language Models in Real-World Fact-Checking](https://arxiv.org//abs/2506.12538)

	Shuo Yang, Yuqin Dai, Guoqing Wang, Xinran Zheng, Jinfeng Xu, Jinze Li, Zhenzhe Ying, Weiqiang Wang, Edith C.H. Ngai

+ [MEraser: An Effective Fingerprint Erasure Approach for Large Language Models](https://arxiv.org//abs/2506.12551)

	Jingxuan Zhang, Zhenhua Xu, Rui Hu, Wenpeng Xing, Xuhong Zhang, Meng Han

+ [Profiling News Media for Factuality and Bias Using LLMs and the Fact-Checking Methodology of Human Experts](https://arxiv.org//abs/2506.12552)

	Zain Muhammad Mujahid, Dilshod Azizov, Maha Tufail Agro, Preslav Nakov

+ [DoTA-RAG: Dynamic of Thought Aggregation RAG](https://arxiv.org//abs/2506.12571)

	Saksorn Ruangtanusak, Natthapath Rungseesiripak, Peerawat Rojratchadakorn, Monthol Charattrakool, Natapong Nitarach

+ [Enabling Precise Topic Alignment in Large Language Models Via Sparse Autoencoders](https://arxiv.org//abs/2506.12576)

	Ananya Joshi, Celia Cintas, Skyler Speakman

+ [Investigating the Effects of Cognitive Biases in Prompts on Large Language Model Outputs](https://arxiv.org//abs/2506.12338)

	Yan Sun, Stanley Kok

+ [Advances in LLMs with Focus on Reasoning, Adaptability, Efficiency and Ethics](https://arxiv.org//abs/2506.12365)

	Asifullah khan, Muhammad Zaeem Khan, Saleha Jamshed, Sadia Ahmad, Aleesha Zainab, Kaynat Khatib, Faria Bibi, Abdul Rehman

+ [From Outcomes to Processes: Guiding PRM Learning from ORM for Inference-Time Alignment](https://arxiv.org//abs/2506.12446)

	Bin Xie, Bingbing Xu, Yige Yuan, Shengmao Zhu, Huawei Shen

+ [Language Surgery in Multilingual Large Language Models](https://arxiv.org//abs/2506.12450)

	Joanito Agili Lopo, Muhammad Ravi Shulthan Habibi, Tack Hwa Wong, Muhammad Ilham Ghozali, Fajri Koto, Genta Indra Winata, Peerat Limkonchotiwat, Alham Fikri Aji, Samuel Cahyawijaya

+ [TagRouter: Learning Route to LLMs through Tags for Open-Domain Text Generation Tasks](https://arxiv.org//abs/2506.12473)

	Zhou Chen, Zhiqiang Wei, Yuqi Bai, Xue Xiong, Jianmin Wu

+ [FlexRAG: A Flexible and Comprehensive Framework for Retrieval-Augmented Generation](https://arxiv.org//abs/2506.12494)

	Zhuocheng Zhang, Yang Feng, Min Zhang

+ [Improving Factuality for Dialogue Response Generation via Graph-Based Knowledge Augmentation](https://arxiv.org//abs/2506.12496)

	Xiangyan Chen, Yujian Gan, Matthew Purver

+ [Detection, Classification, and Mitigation of Gender Bias in Large Language Models](https://arxiv.org//abs/2506.12527)

	Xiaoqing Cheng, Hongying Zan, Lulu Kong, Jinwang Song, Min Peng

+ [OneEval: Benchmarking LLM Knowledge-intensive Reasoning over Diverse Knowledge Bases](https://arxiv.org//abs/2506.12577)

	Yongrui Chen, Zhiqiang Liu, Jing Yu, Lin Ren, Nan Hu, Xinbang Dai, Jiajun Liu, Jiazhen Kang, Shenyu Zhang, Xinda Wang, Keyan Ding, Pengfei Shen, Haolei Zhu, Hongjie Deng, Yisong Wang, Tongtong Wu, Sheng Bi, Wen Zhang, Tianxing Wu, Qiu Ji, Haofen Wang, Wenliang Chen, Huajun Chen, Guilin Qi

+ [Towards Building General Purpose Embedding Models for Industry 4.0 Agents](https://arxiv.org//abs/2506.12607)

	Christodoulos Constantinides, Shuxin Lin, Dhaval Patel

+ [OpenUnlearning: Accelerating LLM Unlearning via Unified Benchmarking of Methods and Metrics](https://arxiv.org//abs/2506.12618)

	Vineeth Dorna, Anmol Mekala, Wenlong Zhao, Andrew McCallum, Zachary C. Lipton, J. Zico Kolter, Pratyush Maini

+ [Synthetic Socratic Debates: Examining Persona Effects on Moral Decision and Persuasion Dynamics](https://arxiv.org//abs/2506.12657)

	Jiarui Liu, Yueqi Song, Yunze Xiao, Mingqian Zheng, Lindia Tjuatja, Jana Schaich Borg, Mona Diab, Maarten Sap

+ [QiMeng-Attention: SOTA Attention Operator is generated by SOTA Attention Algorithm](https://arxiv.org//abs/2506.12355)

	Qirui Zhou, Shaohui Peng, Weiqiang Xiong, Haixin Chen, Yuanbo Wen, Haochen Li, Ling Li, Qi Guo, Yongwei Zhao, Ke Gao, Ruizhi Chen, Yanjun Wu, Chen Zhao, Yunji Chen

+ [Understanding and Benchmarking the Trustworthiness in Multimodal LLMs for Video Understanding](https://arxiv.org//abs/2506.12336)

	Youze Wang, Zijun Chen, Ruoyu Chen, Shishen Gu, Yinpeng Dong, Hang Su, Jun Zhu, Meng Wang, Richang Hong, Wenbo Hu

+ [Image Corruption-Inspired Membership Inference Attacks against Large Vision-Language Models](https://arxiv.org//abs/2506.12340)

	Zongyu Wu, Minhua Lin, Zhiwei Zhang, Fali Wang, Xianren Zhang, Xiang Zhang, Suhang Wang

+ [Not All Tokens and Heads Are Equally Important: Dual-Level Attention Intervention for Hallucination Mitigation](https://arxiv.org//abs/2506.12609)

	Lexiang Tang, Xianwei Zhuang, Bang Yang, Zhiyuan Hu, Hongxiang Li, Lu Ma, Jinghan Ru, Yuexian Zou

+ [InverTune: Removing Backdoors from Multimodal Contrastive Learning Models via Trigger Inversion and Activation Tuning](https://arxiv.org//abs/2506.12411)

	Mengyuan Sun, Yu Li, Yuchen Liu, Bo Du, Yunjie Ge

+ [Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025](https://arxiv.org//abs/2506.12430)

	Zonghao Ying, Siyang Wu, Run Hao, Peng Ying, Shixuan Sun, Pengyu Chen, Junze Chen, Hao Du, Kaiwen Shen, Shangkun Wu, Jiwei Wei, Shiyuan He, Yang Yang, Xiaohai Xu, Ke Ma, Qianqian Xu, Qingming Huang, Shi Lin, Xun Wang, Changting Lin, Meng Han, Yilei Jiang, Siqi Lai, Yaozhi Zheng, Yifei Song, Xiangyu Yue, Zonglei Jing, Tianyuan Zhang, Zhilei Zhu, Aishan Liu, Jiakai Wang, Siyuan Liang, Xianglong Kong, Hainan Li, Junjie Mu, Haotong Qin, Yue Yu, Lei Chen, Felix Juefei-Xu, Qing Guo, Xinyun Chen, Yew Soon Ong, Xianglong Liu, Dawn Song, Alan Yuille, Philip Torr, Dacheng Tao

+ [Automatic Expert Discovery in LLM Upcycling via Sparse Interpolated Mixture-of-Experts](https://arxiv.org//abs/2506.12597)

	Shengzhuang Chen, Ying Wei, Jonathan Richard Schwarz

+ [When Forgetting Triggers Backdoors: A Clean Unlearning Attack](https://arxiv.org//abs/2506.12522)

	Marco Arazzi, Antonino Nocera, Vinod P

# 2025-06-13
+ [Large Language Model-Powered Conversational Agent Delivering Problem-Solving Therapy (PST) for Family Caregivers: Enhancing Empathy and Therapeutic Alliance Using In-Context Learning](https://arxiv.org//abs/2506.11376)

	Liying Wang, Ph.D., Daffodil Carrington, M.S., Daniil Filienko, M.S., Caroline El Jazmi, M.S., Serena Jinchen Xie, M.S., Martine De Cock, Ph.D., Sarah Iribarren, Ph.D., Weichao Yuwen, Ph.D

+ [RAG+: Enhancing Retrieval-Augmented Generation with Application-Aware Reasoning](https://arxiv.org//abs/2506.11555)

	Yu Wang, Shiwan Zhao, Ming Fan, Zhihu Wang, Yubo Zhang, Xicheng Zhang, Zhengfan Wang, Heyuan Huang, Ting Liu

+ [Collaborative LLM Inference via Planning for Efficient Reasoning](https://arxiv.org//abs/2506.11578)

	Byeongchan Lee, Jonghoon Lee, Dongyoung Kim, Jaehyung Kim, Jinwoo Shin

+ [Mitigating Hallucination Through Theory-Consistent Symmetric Multimodal Preference Optimization](https://arxiv.org//abs/2506.11712)

	Wenqi Liu, Xuemeng Song, Jiaxi Li, Yinwei Wei, Na Zheng, Jianhua Yin, Liqiang Nie

+ [Revealing Political Bias in LLMs through Structured Multi-Agent Debate](https://arxiv.org//abs/2506.11825)

	Aishwarya Bandaru, Fabian Bindley, Trevor Bluth, Nandini Chavda, Baixu Chen, Ethan Law

+ [Addressing Bias in LLMs: Strategies and Application to Fair AI-based Recruitment](https://arxiv.org//abs/2506.11880)

	Alejandro Peña, Julian Fierrez, Aythami Morales, Gonzalo Mancera, Miguel Lopez, Ruben Tolosana

+ [Towards a Cascaded LLM Framework for Cost-effective Human-AI Decision-Making](https://arxiv.org//abs/2506.11887)

	Claudio Fanconi, Mihaela van der Schaar

+ [Tracing LLM Reasoning Processes with Strategic Games: A Framework for Planning, Revision, and Resource-Constrained Decision Making](https://arxiv.org//abs/2506.12012)

	Xiaopeng Yuan, Xingjian Zhang, Ke Xu, Yifan Xu, Lijun Yu, Jindong Wang, Yushun Dong, Haohan Wang

+ [LoRA Users Beware: A Few Spurious Tokens Can Manipulate Your Finetuned Model](https://arxiv.org//abs/2506.11402)

	Pradyut Sekhsaria, Marcel Mateos Salles, Hai Huang, Randall Balestriero

+ [Stop learning it all to mitigate visual hallucination, Focus on the hallucination target](https://arxiv.org//abs/2506.11417)

	Dokyoon Yoon, Youngsook Song, Woomyong Park

+ [Agent-RLVR: Training Software Engineering Agents via Guidance and Environment Rewards](https://arxiv.org//abs/2506.11425)

	Jeff Da, Clinton Wang, Xiang Deng, Yuntao Ma, Nikhil Barhate, Sean Hendryx

+ [LearnAlign: Reasoning Data Selection for Reinforcement Learning in Large Language Models Based on Improved Gradient Alignment](https://arxiv.org//abs/2506.11480)

	Shikun Li, Shipeng Li, Zhiqin Yang, Xinghua Zhang, Gaode Chen, Xiaobo Xia, Hengyu Liu, Zhe Peng

+ [Relational Schemata in BERT Are Inducible, Not Emergent: A Study of Performance vs. Competence in Language Models](https://arxiv.org//abs/2506.11485)

	Cole Gawin

+ [Prioritizing Alignment Paradigms over Task-Specific Model Customization in Time-Series LLMs](https://arxiv.org//abs/2506.11512)

	Wei Li, Yunyao Cheng, Xinli Hao, Chaohong Ma, Yuxuan Liang, Bin Yang, Christian S.Jensen, Xiaofeng Meng

+ [Investigating Vulnerabilities and Defenses Against Audio-Visual Attacks: A Comprehensive Survey Emphasizing Multimodal Models](https://arxiv.org//abs/2506.11521)

	Jinming Wen, Xinyi Wu, Shuai Zhao, Yanhao Jia, Yuwen Li

+ [DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs](https://arxiv.org//abs/2506.11558)

	Bo-Cheng Chiu, Jen-Jee Chen, Yu-Chee Tseng, Feng-Chi Chen

+ [Leveraging GPT-4 for Vulnerability-Witnessing Unit Test Generation](https://arxiv.org//abs/2506.11559)

	Gábor Antal, Dénes Bán, Martin Isztin, Rudolf Ferenc, Péter Hegedűs

+ [Identifying Helpful Context for LLM-based Vulnerability Repair: A Preliminary Study](https://arxiv.org//abs/2506.11561)

	Gábor Antal, Bence Bogenfürst, Rudolf Ferenc, Péter Hegedűs

+ [GraphRAG-Causal: A novel graph-augmented framework for causal reasoning and annotation in news](https://arxiv.org//abs/2506.11600)

	Abdul Haque, Umm e Hani, Ahmad Din, Muhammad Babar, Ali Abbas, Insaf Ullah

+ [Are LLMs Good Text Diacritizers? An Arabic and Yorùbá Case Study](https://arxiv.org//abs/2506.11602)

	Hawau Olamide Toyin, Samar M. Magdy, Hanan Aldarmaki

+ [Model Organisms for Emergent Misalignment](https://arxiv.org//abs/2506.11613)

	Edward Turner, Anna Soligo, Mia Taylor, Senthooran Rajamanoharan, Neel Nanda

+ [Convergent Linear Representations of Emergent Misalignment](https://arxiv.org//abs/2506.11618)

	Anna Soligo, Edward Turner, Senthooran Rajamanoharan, Neel Nanda

+ [FAA Framework: A Large Language Model-Based Approach for Credit Card Fraud Investigations](https://arxiv.org//abs/2506.11635)

	Shaun Shuster, Eyal Zaloof, Asaf Shabtai, Rami Puzis

+ [LoRA-Gen: Specializing Large Language Model via Online LoRA Generation](https://arxiv.org//abs/2506.11638)

	Yicheng Xiao, Lin Song, Rui Yang, Cheng Cheng, Yixiao Ge, Xiu Li, Ying Shan

+ [Improving Causal Interventions in Amnesic Probing with Mean Projection or LEACE](https://arxiv.org//abs/2506.11673)

	Alicja Dobrzeniecka, Antske Fokkens, Pia Sommerauer

+ [LLMs on support of privacy and security of mobile apps: state of the art and research directions](https://arxiv.org//abs/2506.11679)

	Tran Thanh Lam Nguyen, Barbara Carminati, Elena Ferrari

+ [Differential Privacy in Machine Learning: From Symbolic AI to LLMs](https://arxiv.org//abs/2506.11687)

	Francisco Aguilera-Martínez, Fernando Berzal

+ [Configurable Preference Tuning with Rubric-Guided Synthetic Data](https://arxiv.org//abs/2506.11702)

	Víctor Gallego

+ [TrustGLM: Evaluating the Robustness of GraphLLMs Against Prompt, Text, and Structure Attacks](https://arxiv.org//abs/2506.11844)

	Qihai Zhang, Xinyue Sheng, Yuanfu Sun, Qiaoyu Tan

+ [Improving Large Language Model Safety with Contrastive Representation Learning](https://arxiv.org//abs/2506.11938)

	Samuel Simko, Mrinmaya Sachan, Bernhard Schölkopf, Zhijing Jin

+ [EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction](https://arxiv.org//abs/2506.12015)

	Hsi-Che Lin, Yu-Chu Yu, Kai-Po Chang, Yu-Chiang Frank Wang

+ [Curriculum-Guided Layer Scaling for Language Model Pretraining](https://arxiv.org//abs/2506.11389)

	Karanpartap Singh, Neil Band, Ehsan Adeli

+ [Efficient Long-Context LLM Inference via KV Cache Clustering](https://arxiv.org//abs/2506.11418)

	Jie Hu, Shengnan Wang, Yutong He, Ping Gong, Jiawei Yi, Juncheng Zhang, Youhui Bai, Renhai Chen, Gong Zhang, Cheng Li, Kun Yuan

+ [AbsenceBench: Language Models Can't Tell What's Missing](https://arxiv.org//abs/2506.11440)

	Harvey Yiyun Fu, Aryan Shrivastava, Jared Moore, Peter West, Chenhao Tan, Ari Holtzman

+ [Med-PRM: Medical Reasoning Models with Stepwise, Guideline-verified Process Rewards](https://arxiv.org//abs/2506.11474)

	Jaehoon Yun, Jiwoong Sohn, Jungwoo Park, Hyunjae Kim, Xiangru Tang, Yanjun Shao, Yonghoe Koo, Minhyeok Ko, Qingyu Chen, Mark Gerstein, Michael Moor, Jaewoo Kang

+ [Lag-Relative Sparse Attention In Long Context Training](https://arxiv.org//abs/2506.11498)

	Manlai Liang, Wanyi Huang, Mandi Liu, Huaijun Li, Jinlong Li

+ [LLMs for Sentence Simplification: A Hybrid Multi-Agent prompting Approach](https://arxiv.org//abs/2506.11681)

	Pratibha Zunjare, Michael Hsiao

+ [DART: Distilling Autoregressive Reasoning to Silent Thought](https://arxiv.org//abs/2506.11752)

	Nan Jiang, Ziming Wu, De-Chuan Zhan, Fuming Lai, Shaobing Lian

+ [DeepResearch Bench: A Comprehensive Benchmark for Deep Research Agents](https://arxiv.org//abs/2506.11763)

	Mingxuan Du, Benfeng Xu, Chiwei Zhu, Xiaorui Wang, Zhendong Mao

+ [Long-Short Alignment for Effective Long-Context Modeling in LLMs](https://arxiv.org//abs/2506.11769)

	Tianqi Du, Haotian Huang, Yifei Wang, Yisen Wang

+ [Are Multimodal Large Language Models Pragmatically Competent Listeners in Simple Reference Resolution Tasks?](https://arxiv.org//abs/2506.11807)

	Simeon Junker, Manar Ali, Larissa Koch, Sina Zarrieß, Hendrik Buschmeier

+ [Post Persona Alignment for Multi-Session Dialogue Generation](https://arxiv.org//abs/2506.11857)

	Yi-Pei Chen, Noriki Nishida, Hideki Nakayama, Yuji Matsumoto

+ [Beyond Homogeneous Attention: Memory-Efficient LLMs via Fourier-Approximated KV Cache](https://arxiv.org//abs/2506.11886)

	Xiaoran Liu, Siyang He, Qiqi Wang, Ruixiao Li, Yuerong Song, Zhigeng Liu, Linlin Li, Qun Liu, Zengfeng Huang, Qipeng Guo, Ziwei He, Xipeng Qiu

+ [Feedback Friction: LLMs Struggle to Fully Incorporate External Feedback](https://arxiv.org//abs/2506.11930)

	Dongwei Jiang, Alvin Zhang, Andrew Wang, Nicholas Andrews, Daniel Khashabi

+ [Bias Amplification in RAG: Poisoning Knowledge Retrieval to Steer LLMs](https://arxiv.org//abs/2506.11415)

	Linlin Wang, Tianqing Zhu, Laiqiao Qin, Longxiang Gao, Wanlei Zhou

+ [AutoGen Driven Multi Agent Framework for Iterative Crime Data Analysis and Prediction](https://arxiv.org//abs/2506.11475)

	Syeda Kisaa Fatima, Tehreem Zubair, Noman Ahmed, Asifullah Khan

+ [Manager: Aggregating Insights from Unimodal Experts in Two-Tower VLMs and MLLMs](https://arxiv.org//abs/2506.11515)

	Xiao Xu, Libo Qin, Wanxiang Che, Min-Yen Kan

+ [Brewing Knowledge in Context: Distillation Perspectives on In-Context Learning](https://arxiv.org//abs/2506.11516)

	Chengye Li, Haiyun Liu, Yuanxi Li

+ [TreeRL: LLM Reinforcement Learning with On-Policy Tree Search](https://arxiv.org//abs/2506.11902)

	Zhenyu Hou, Ziniu Hu, Yujiang Li, Rui Lu, Jie Tang, Yuxiao Dong

+ [VFaith: Do Large Multimodal Models Really Reason on Seen Images Rather than Previous Memories?](https://arxiv.org//abs/2506.11571)

	Jiachen Yu, Yufei Zhan, Ziheng Wu, Yousong Zhu, Jinqiao Wang, Minghui Qiu

+ [Dynamic Mixture of Curriculum LoRA Experts for Continual Multimodal Instruction Tuning](https://arxiv.org//abs/2506.11672)

	Chendi Ge, Xin Wang, Zeyang Zhang, Hong Chen, Jiapei Fan, Longtao Huang, Hui Xue, Wenwu Zhu

+ [AgentSense: Virtual Sensor Data Generation Using LLM Agent in Simulated Home Environments](https://arxiv.org//abs/2506.11773)

	Zikang Leng, Megha Thukral, Yaqi Liu, Hrudhai Rajasekhar, Shruthi K. Hiremath, Thomas Plötz

+ [How Visual Representations Map to Language Feature Space in Multimodal LLMs](https://arxiv.org//abs/2506.11976)

	Constantin Venhoff, Ashkan Khakzar, Sonia Joseph, Philip Torr, Neel Nanda

+ [Simple Radiology VLLM Test-time Scaling with Thought Graph Traversal](https://arxiv.org//abs/2506.11989)

	Yue Yao, Zelin Wen, Yan Tong, Xinyu Tian, Xuqing Li, Xiao Ma, Dongliang Xu, Tom Gedeon

+ [SEC-bench: Automated Benchmarking of LLM Agents on Real-World Software Security Tasks](https://arxiv.org//abs/2506.11791)

	Hwiwon Lee, Ziqi Zhang, Hanxiao Lu, Lingming Zhang

+ [ReVeal: Self-Evolving Code Agents via Iterative Generation-Verification](https://arxiv.org//abs/2506.11442)

	Yiyang Jin, Kunzhao Xu, Hang Li, Xueting Han, Yanmin Zhou, Cheng Li, Jing Bai

+ [Because we have LLMs, we Can and Should Pursue Agentic Interpretability](https://arxiv.org//abs/2506.12152)

	Been Kim, John Hewitt, Neel Nanda, Noah Fiedel, Oyvind Tafjord

+ [Privacy Reasoning in Ambiguous Contexts](https://arxiv.org//abs/2506.12241)

	Ren Yi, Octavian Suciu, Adria Gascon, Sarah Meiklejohn, Eugene Bagdasarian, Marco Gruteser

+ [Cloud Infrastructure Management in the Age of AI Agents](https://arxiv.org//abs/2506.12270)

	Zhenning Yang, Archit Bhatnagar, Yiming Qiu, Tongyuan Miao, Patrick Tser Jern Kon, Yunming Xiao, Yibo Huang, Martin Casado, Ang Chen

+ [DRIFT: Dynamic Rule-Based Defense with Injection Isolation for Securing LLM Agents](https://arxiv.org//abs/2506.12104)

	Hao Li, Xiaogeng Liu, Hung-Chun Chiu, Dianqi Li, Ning Zhang, Chaowei Xiao

+ [Personalized LLM Decoding via Contrasting Personal Preference](https://arxiv.org//abs/2506.12109)

	Hyungjune Bu, Chanjoo Jung, Minjae Kang, Jaehyung Kim

+ [Eliciting Reasoning in Language Models with Cognitive Tools](https://arxiv.org//abs/2506.12115)

	Brown Ebouky, Andrea Bartezzaghi, Mattia Rigotti

+ [Can Mixture-of-Experts Surpass Dense LLMs Under Strictly Equal Resources?](https://arxiv.org//abs/2506.12119)

	Houyi Li, Ka Man Lo, Ziqi Wang, Zili Wang, Wenzhen Zheng, Shuigeng Zhou, Xiangyu Zhang, Daxin Jiang

+ [Supernova Event Dataset: Interpreting Large Language Model's Personality through Critical Event Analysis](https://arxiv.org//abs/2506.12189)

	Pranav Agarwal, Ioana Ciucă

+ [A Fast, Reliable, and Secure Programming Language for LLM Agents with Code Actions](https://arxiv.org//abs/2506.12202)

	Stephen Mell, Botong Zhang, David Mell, Shuo Li, Ramya Ramalingam, Nathan Yu, Steve Zdancewic, Osbert Bastani

+ [Semantic Scheduling for LLM Inference](https://arxiv.org//abs/2506.12204)

	Wenyue Hua, Dujian Ding, Yile Gu, Yujie Ren, Kai Mei, Minghua Ma, William Yang Wang

+ [From Emergence to Control: Probing and Modulating Self-Reflection in Language Models](https://arxiv.org//abs/2506.12217)

	Xudong Zhu, Jiachen Jiang, Mohammad Mahdi Khalili, Zhihui Zhu

+ [Two heads are better than one: simulating large transformers with small ones](https://arxiv.org//abs/2506.12220)

	Hantao Yu, Josh Alman

+ [Uncovering Bias Paths with LLM-guided Causal Discovery: An Active Learning and Dynamic Scoring Approach](https://arxiv.org//abs/2506.12227)

	Khadija Zanna, Akane Sano

+ [Mind the XAI Gap: A Human-Centered LLM Framework for Democratizing Explainable AI](https://arxiv.org//abs/2506.12240)

	Eva Paraschou, Ioannis Arapakis, Sofia Yfantidou, Sebastian Macaluso, Athena Vakali

+ [The Behavior Gap: Evaluating Zero-shot LLM Agents in Complex Task-Oriented Dialogs](https://arxiv.org//abs/2506.12266)

	Avinash Baidya, Kamalika Das, Xiang Gao

+ [Maximally-Informative Retrieval for State Space Model Generation](https://arxiv.org//abs/2506.12149)

	Evan Becker, Benjamin Bowman, Matthew Trager, Tian Yu Liu, Luca Zancato, Wei Xia, Stefano Soatto

+ [Instruction Tuning and CoT Prompting for Contextual Medical QA with LLMs](https://arxiv.org//abs/2506.12182)

	Chenqian Le, Ziheng Gong, Chihang Wang, Haowei Ni, Panfeng Li, Xupeng Chen

+ [InfoFlood: Jailbreaking Large Language Models with Information Overload](https://arxiv.org//abs/2506.12274)

	Advait Yadav, Haibo Jin, Man Luo, Jun Zhuang, Haohan Wang

+ [Can LLMs Generate High-Quality Test Cases for Algorithm Problems? TestCase-Eval: A Systematic Evaluation of Fault Coverage and Exposure](https://arxiv.org//abs/2506.12278)

	Zheyuan Yang, Zexi Kuang, Xue Xia, Yilun Zhao

# 2025-06-12
+ [WGSR-Bench: Wargame-based Game-theoretic Strategic Reasoning Benchmark for Large Language Models](https://arxiv.org//abs/2506.10264)

	Qiyue Yin, Pei Xu, Qiaozhe Li, Shengda Liu, Shengqi Shen, Tong Wang, Yihong Han, Xiaonan Zhao, Likun Yang, Shiyue Cao, Shiyu Qiu, Yuxuan Liu, Shizhao Yu, Lei Cui, Chengxin Yan, Jie Sun, Xiangquan Tang, Kaiqi Huang

+ [The Alignment Trap: Complexity Barriers](https://arxiv.org//abs/2506.10304)

	Jasper Yao

+ [Optimus-3: Towards Generalist Multimodal Minecraft Agents with Scalable Task Experts](https://arxiv.org//abs/2506.10357)

	Zaijing Li, Yuquan Xie, Rui Shao, Gongwei Chen, Weili Guan, Dongmei Jiang, Liqiang Nie

+ [Mirage-1: Augmenting and Updating GUI Agent with Hierarchical Multimodal Skills](https://arxiv.org//abs/2506.10387)

	Yuquan Xie, Zaijing Li, Rui Shao, Gongwei Chen, Kaiwen Zhou, Yinchuan Li, Dongmei Jiang, Liqiang Nie

+ [Reasoning RAG via System 1 or System 2: A Survey on Reasoning Agentic Retrieval-Augmented Generation for Industry Challenges](https://arxiv.org//abs/2506.10408)

	Jintao Liang, Gang Su, Huifeng Lin, You Wu, Rui Zhao, Ziyue Li

+ [Scientists' First Exam: Probing Cognitive Abilities of MLLM via Perception, Understanding, and Reasoning](https://arxiv.org//abs/2506.10521)

	Yuhao Zhou, Yiheng Wang, Xuming He, Ruoyao Xiao, Zhiwei Li, Qiantai Feng, Zijie Guo, Yuejin Yang, Hao Wu, Wenxuan Huang, Jiaqi Wei, Dan Si, Xiuqi Yao, Jia Bu, Haiwen Huang, Tianfan Fu, Shixiang Tang, Ben Fei, Dongzhan Zhou, Fenghua Ling, Yan Lu, Siqi Sun, Chenhui Li, Guanjie Zheng, Jiancheng Lv, Wenlong Zhang, Lei Bai

+ [LogiPlan: A Structured Benchmark for Logical Planning and Relational Reasoning in LLMs](https://arxiv.org//abs/2506.10527)

	Yanan Cai, Ahmed Salem, Besmira Nushi, Mark Russinovich

+ [Primender Sequence: A Novel Mathematical Construct for Testing Symbolic Inference and AI Reasoning](https://arxiv.org//abs/2506.10585)

	Mohd Anwar Jamal Faiz

+ [OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems](https://arxiv.org//abs/2506.10764)

	Xiaozhe Li, Jixuan Chen, Xinyu Fang, Shengyuan Ding, Haodong Duan, Qingwen Liu, Kai Chen

+ [GenPlanX. Generation of Plans and Execution](https://arxiv.org//abs/2506.10897)

	Daniel Borrajo, Giuseppe Canonaco, Tomás de la Rosa, Alfredo Garrachón, Sriram Gopalakrishnan, Simerjot Kaur, Marianela Morales, Sunandita Patra, Alberto Pozanco, Keshav Ramani, Charese Smiley, Pietro Totis, Manuela Veloso

+ [Breaking Bad Molecules: Are MLLMs Ready for Structure-Level Molecular Detoxification?](https://arxiv.org//abs/2506.10912)

	Fei Lin, Ziyang Gong, Cong Wang, Yonglin Tian, Tengchao Zhang, Xue Yang, Gen Luo, Fei-Yue Wang

+ [Do Language Models Have Bayesian Brains? Distinguishing Stochastic and Deterministic Decision Patterns within Large Language Models](https://arxiv.org//abs/2506.10268)

	Andrea Yaoyun Cui, Pengfei Yu

+ [ClusterUCB: Efficient Gradient-Based Data Selection for Targeted Fine-Tuning of LLMs](https://arxiv.org//abs/2506.10288)

	Zige Wang, Qi Zhu, Fei Mi, Minghui Xu, Ruochun Jin, Wenjing Yang

+ [Towards Understanding Bias in Synthetic Data for Evaluation](https://arxiv.org//abs/2506.10301)

	Hossein A. Rahmani, Varsha Ramineni, Nick Craswell, Bhaskar Mitra, Emine Yilmaz

+ [Augmenting Large Language Models with Static Code Analysis for Automated Code Quality Improvements](https://arxiv.org//abs/2506.10330)

	Seyed Moein Abtahi, Akramul Azim

+ [Code Execution as Grounded Supervision for LLM Reasoning](https://arxiv.org//abs/2506.10343)

	Dongwon Jung, Wenxuan Zhou, Muhao Chen

+ [Discovering Hierarchical Latent Capabilities of Language Models via Causal Representation Learning](https://arxiv.org//abs/2506.10378)

	Jikai Jin, Vasilis Syrgkanis, Sham Kakade, Hanlin Zhang

+ [Time To Impeach LLM-as-a-Judge: Programs are the Future of Evaluation](https://arxiv.org//abs/2506.10403)

	Tzu-Heng Huang, Harit Vishwakarma, Frederic Sala

+ [PAG: Multi-Turn Reinforced LLM Self-Correction with Policy as Generative Verifier](https://arxiv.org//abs/2506.10406)

	Yuhua Jiang, Yuwen Xiong, Yufeng Yuan, Chao Xin, Wenyuan Xu, Yu Yue, Qianchuan Zhao, Lin Yan

+ [PAL: Probing Audio Encoders via LLMs -- A Study of Information Transfer from Audio Encoders to LLMs](https://arxiv.org//abs/2506.10423)

	Tony Alex, Wish Suharitdamrong, Sara Atito, Armin Mustafa, Philip J. B. Jackson, Imran Razzak, Muhammad Awais

+ [SOFT: Selective Data Obfuscation for Protecting LLM Fine-tuning against Membership Inference Attacks](https://arxiv.org//abs/2506.10424)

	Kaiyuan Zhang, Siyuan Cheng, Hanxi Guo, Yuetian Chen, Zian Su, Shengwei An, Yuntao Du, Charles Fleming, Ashish Kundu, Xiangyu Zhang, Ninghui Li

+ [Specification and Evaluation of Multi-Agent LLM Systems -- Prototype and Cybersecurity Applications](https://arxiv.org//abs/2506.10467)

	Felix Härer

+ [Beyond Single-User Dialogue: Assessing Multi-User Dialogue State Tracking Capabilities of Large Language Models](https://arxiv.org//abs/2506.10504)

	Sangmin Song, Juhwan Choi, JungMin Yun, YoungBin Kim

+ [Reliable Reasoning Path: Distilling Effective Guidance for LLM Reasoning with Knowledge Graphs](https://arxiv.org//abs/2506.10508)

	Yilin Xiao, Chuang Zhou, Qinggang Zhang, Bo Li, Qing Li, Xiao Huang

+ [StepProof: Step-by-step verification of natural language mathematical proofs](https://arxiv.org//abs/2506.10558)

	Xiaolin Hu, Qinghua Zhou, Bogdan Grechuk, Ivan Y. Tyukin

+ [SoK: Evaluating Jailbreak Guardrails for Large Language Models](https://arxiv.org//abs/2506.10597)

	Xunguang Wang, Zhenlan Ji, Wenxuan Wang, Zongjie Li, Daoyuan Wu, Shuai Wang

+ [SDialog: A Python Toolkit for Synthetic Dialogue Generation and Analysis](https://arxiv.org//abs/2506.10622)

	Sergio Burdisso, Esaú Villatoro-Tello, Petr Motlicek

+ [NeuralNexus at BEA 2025 Shared Task: Retrieval-Augmented Prompting for Mistake Identification in AI Tutors](https://arxiv.org//abs/2506.10627)

	Numaan Naeem, Sarfraz Ahmad, Momina Ahsan, Hasan Iqbal

+ [Data Shifts Hurt CoT: A Theoretical Study](https://arxiv.org//abs/2506.10647)

	Lang Yin, Debangshu Banerjee, Gagandeep Singh

+ [PREMISE: Scalable and Strategic Prompt Optimization for Efficient Mathematical Reasoning in Large Models](https://arxiv.org//abs/2506.10716)

	Ye Yu, Yaoning Yu, Haohan Wang

+ [Improving Named Entity Transcription with Contextual LLM-based Revision](https://arxiv.org//abs/2506.10779)

	Viet Anh Trinh, Xinlu He, Jacob Whitehill

+ [VideoDeepResearch: Long Video Understanding With Agentic Tool Using](https://arxiv.org//abs/2506.10821)

	Huaying Yuan, Zheng Liu, Junjie Zhou, Ji-Rong Wen, Zhicheng Dou

+ [LLM-Driven Personalized Answer Generation and Evaluation](https://arxiv.org//abs/2506.10829)

	Mohammadreza Molavi, Mohammadreza Tavakoli, Mohammad Moein, Abdolali Faraji, Gábor Kismihók

+ [Accelerating Diffusion Large Language Models with SlowFast: The Three Golden Principles](https://arxiv.org//abs/2506.10848)

	Qingyan Wei, Yaojie Zhang, Zhiyuan Liu, Dongrui Liu, Linfeng Zhang

+ [Precise Zero-Shot Pointwise Ranking with LLMs through Post-Aggregated Global Context Information](https://arxiv.org//abs/2506.10859)

	Kehan Long, Shasha Li, Chen Xu, Jintao Tang, Ting Wang

+ [Slimming Down LLMs Without Losing Their Minds](https://arxiv.org//abs/2506.10885)

	Qingda (Michael)Mai

+ [Robustly Improving LLM Fairness in Realistic Settings via Interpretability](https://arxiv.org//abs/2506.10922)

	Adam Karvonen, Samuel Marks

+ [GUARD: Guided Unlearning and Retention via Data Attribution for Large Language Models](https://arxiv.org//abs/2506.10946)

	Evelyn Ma, Duo Zhou, Peizhi Niu, Huiting Zhou, Huan Zhang, Olgica Milenkovic, S. Rasoul Etesami

+ [Monitoring Decomposition Attacks in LLMs with Lightweight Sequential Monitors](https://arxiv.org//abs/2506.10949)

	Chen Yueh-Han, Nitish Joshi, Yulin Chen, Maksym Andriushchenko, Rico Angell, He He

+ [Domain2Vec: Vectorizing Datasets to Find the Optimal Data Mixture without Training](https://arxiv.org//abs/2506.10952)

	Mozhi Zhang, Howe Tissue, Lu Wang, Xipeng Qiu

+ [ChineseHarm-Bench: A Chinese Harmful Content Detection Benchmark](https://arxiv.org//abs/2506.10960)

	Kangwei Liu, Siyuan Cheng, Bozhong Tian, Xiaozhuan Liang, Yuyang Yin, Meng Han, Ningyu Zhang, Bryan Hooi, Xi Chen, Shumin Deng

+ [Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs](https://arxiv.org//abs/2506.10967)

	Qizhe Zhang, Mengzhen Liu, Lichen Li, Ming Lu, Yuan Zhang, Junwen Pan, Qi She, Shanghang Zhang

+ [Farseer: A Refined Scaling Law in Large Language Models](https://arxiv.org//abs/2506.10972)

	Houyi Li, Wenzhen Zheng, Qiufeng Wang, Zhenyu Ding, Haoying Wang, Zili Wang, Shijie Xuyang, Ning Ding, Shuigeng Zhou, Xiangyu Zhang, Daxin Jiang

+ [AutoMind: Adaptive Knowledgeable Agent for Automated Data Science](https://arxiv.org//abs/2506.10974)

	Yixin Ou, Yujie Luo, Jingsheng Zheng, Lanning Wei, Shuofei Qiao, Jintian Zhang, Da Zheng, Huajun Chen, Ningyu Zhang

+ ["Check My Work?": Measuring Sycophancy in a Simulated Educational Context](https://arxiv.org//abs/2506.10297)

	Chuck Arvin

+ [TableRAG: A Retrieval Augmented Generation Framework for Heterogeneous Document Reasoning](https://arxiv.org//abs/2506.10380)

	Xiaohan Yu, Pu Jian, Chong Chen

+ [Burn After Reading: Do Multimodal Large Language Models Truly Capture Order of Events in Image Sequences?](https://arxiv.org//abs/2506.10415)

	Yingjin Song, Yupei Du, Denis Paperno, Albert Gatt

+ [Fast on the Easy, Deep on the Hard: Efficient Reasoning via Powered Length Penalty](https://arxiv.org//abs/2506.10446)

	Zehui Ling, Deshu Chen, Hongwei Zhang, Yifeng Jiao, Xin Guo, Yuan Cheng

+ [Spelling-out is not Straightforward: LLMs' Capability of Tokenization from Token to Characters](https://arxiv.org//abs/2506.10641)

	Tatsuya Hiraoka, Kentaro Inui

+ [Beyond True or False: Retrieval-Augmented Hierarchical Analysis of Nuanced Claims](https://arxiv.org//abs/2506.10728)

	Priyanka Kargupta, Runchu Tian, Jiawei Han

+ [TaxoAdapt: Aligning LLM-Based Multidimensional Taxonomy Construction to Evolving Research Corpora](https://arxiv.org//abs/2506.10737)

	Priyanka Kargupta, Nan Zhang, Yunyi Zhang, Rui Zhang, Prasenjit Mitra, Jiawei Han

+ [Different Questions, Different Models: Fine-Grained Evaluation of Uncertainty and Calibration in Clinical QA with LLMs](https://arxiv.org//abs/2506.10769)

	Alberto Testoni, Iacer Calixto

+ [Mitigating Negative Interference in Multilingual Sequential Knowledge Editing through Null-Space Constraints](https://arxiv.org//abs/2506.10800)

	Wei Sun, Tingyu Qu, Mingxiao Li, Jesse Davis, Marie-Francine Moens

+ [ReCUT: Balancing Reasoning Length and Accuracy in LLMs via Stepwise Trails and Preference Optimization](https://arxiv.org//abs/2506.10822)

	Zhensheng Jin, Xinze Li, Yifan Ji, Chunyi Peng, Zhenghao Liu, Qi Shi, Yukun Yan, Shuo Wang, Furong Peng, Ge Yu

+ [CIIR@LiveRAG 2025: Optimizing Multi-Agent Retrieval Augmented Generation through Self-Training](https://arxiv.org//abs/2506.10844)

	Alireza Salemi, Mukta Maddipatla, Hamed Zamani

+ [Generalization or Hallucination? Understanding Out-of-Context Reasoning in Transformers](https://arxiv.org//abs/2506.10887)

	Yixiao Huang, Hanlin Zhu, Tianyu Guo, Jiantao Jiao, Somayeh Sojoudi, Michael I. Jordan, Stuart Russell, Song Mei

+ [Beyond Gold Standards: Epistemic Ensemble of LLM Judges for Formal Mathematical Reasoning](https://arxiv.org//abs/2506.10903)

	Lan Zhang, Marco Valentino, Andre Freitas

+ [Magistral](https://arxiv.org//abs/2506.10910)

	Mistral-AI: Abhinav Rastogi, Albert Q. Jiang, Andy Lo, Gabrielle Berrada, Guillaume Lample, Jason Rute, Joep Barmentlo, Karmesh Yadav, Kartik Khandelwal, Khyathi Raghavi Chandu, Léonard Blier, Lucile Saulnier, Matthieu Dinot, Maxime Darrin, Neha Gupta, Roman Soletskyi, Sagar Vaze, Teven Le Scao, Yihan Wang, Adam Yang, Alexander H. Liu, Alexandre Sablayrolles, Amélie Héliou, Amélie Martin, Andy Ehrenberg, Anmol Agarwal, Antoine Roux, Arthur Darcet, Arthur Mensch, Baptiste Bout, Baptiste Rozière, Baudouin De Monicault, Chris Bamford, Christian Wallenwein, Christophe Renaudin, Clémence Lanfranchi, Darius Dabert, Devon Mizelle, Diego de las Casas, Elliot Chane-Sane, Emilien Fugier, Emma Bou Hanna, Gauthier Delerce, Gauthier Guinet, Georgii Novikov, Guillaume Martin, Himanshu Jaju, Jan Ludziejewski, Jean-Hadrien Chabran, Jean-Malo Delignon, Joachim Studnia, Jonas Amar, Josselin Somerville Roberts, Julien Denize, Karan Saxena, Kush Jain, Lingxiao Zhao, Louis Martin, Luyu Gao, Lélio Renard Lavaud, Marie Pellat, Mathilde Guillaumin, Mathis Felardos, Maximilian Augustin, Mickaël Seznec, Nikhil Raghuraman, Olivier Duchenne, Patricia Wang, Patrick von Platen, Patryk Saffer, Paul Jacob, Paul Wambergue, Paula Kurylowicz, Pavankumar Reddy Muddireddy, Philomène Chagniot, Pierre Stock, Pravesh Agrawal, Romain Sauvestre, Rémi Delacourt, Sanchit Gandhi, Sandeep Subramanian, Shashwat Dalal, Siddharth Gandhi, Soham Ghosh, Srijan Mishra, Sumukh Aithal, Szymon Antoniak, Thibault Schueller, Thibaut Lavril, Thomas Robert, Thomas Wang, Timothée Lacroix, Valeriia Nemychnikova, Victor Paltz, Virgile Richard, Wen-Ding Li, William Marshall, Xuanyu Zhang, Yunhao Tang

+ [Decomposing MLP Activations into Interpretable Features via Semi-Nonnegative Matrix Factorization](https://arxiv.org//abs/2506.10920)

	Or Shafran, Atticus Geiger, Mor Geva

+ [Dynamic Epistemic Friction in Dialogue](https://arxiv.org//abs/2506.10934)

	Timothy Obiso, Kenneth Lai, Abhijnan Nath, Nikhil Krishnaswamy, James Pustejovsky

+ [How Well Can Reasoning Models Identify and Recover from Unhelpful Thoughts?](https://arxiv.org//abs/2506.10979)

	Sohee Yang, Sang-Woo Lee, Nora Kassner, Daniela Gottesman, Sebastian Riedel, Mor Geva

+ [Provably Learning from Language Feedback](https://arxiv.org//abs/2506.10341)

	Wanqiao Xu, Allen Nie, Ruijie Zheng, Aditya Modi, Adith Swaminathan, Ching-An Cheng

+ [Can We Infer Confidential Properties of Training Data from LLMs?](https://arxiv.org//abs/2506.10364)

	Penguin Huang, Chhavi Yadav, Ruihan Wu, Kamalika Chaudhuri

+ [Conversational Search: From Fundamentals to Frontiers in the LLM Era](https://arxiv.org//abs/2506.10635)

	Fengran Mo, Chuan Meng, Mohammad Aliannejadi, Jian-Yun Nie

+ [Neural at ArchEHR-QA 2025: Agentic Prompt Optimization for Evidence-Grounded Clinical Question Answering](https://arxiv.org//abs/2506.10751)

	Sai Prasanna Teja Reddy Bogireddy, Abrar Majeedi, Viswanatha Reddy Gajjala, Zhuoyan Xu, Siddhant Rai, Vaishnav Potlapalli

+ [Build the web for agents, not agents for the web](https://arxiv.org//abs/2506.10953)

	Xing Han Lù, Gaurav Kamath, Marius Mosbach, Siva Reddy

+ [HalLoc: Token-level Localization of Hallucinations for Vision Language Models](https://arxiv.org//abs/2506.10286)

	Eunkyu Park, Minyeong Kim, Gunhee Kim

+ [MedSeg-R: Reasoning Segmentation in Medical Images with Multimodal Large Language Models](https://arxiv.org//abs/2506.10465)

	Yu Huang, Zelin Peng, Yichen Zhao, Piao Yang, Xiaokang Yang, Wei Shen

+ [LLMs Are Not Yet Ready for Deepfake Image Detection](https://arxiv.org//abs/2506.10474)

	Shahroz Tariq, David Nguyen, M.A.P. Chamikara, Tingmin Wu, Alsharif Abuadbba, Kristen Moore

+ [Graph-MLLM: Harnessing Multimodal Large Language Models for Multimodal Graph Learning](https://arxiv.org//abs/2506.10282)

	Jiajin Liu, Dongzhe Fan, Jiacheng Shen, Chuanhao Ji, Daochen Zha, Qiaoyu Tan

+ [TreeLoRA: Efficient Continual Learning via Layer-Wise LoRAs Guided by a Hierarchical Gradient-Similarity Tree](https://arxiv.org//abs/2506.10355)

	Yu-Yang Qian, Yuan-Ze Xu, Zhen-Yu Zhang, Peng Zhao, Zhi-Hua Zhou

+ [EQA-RM: A Generative Embodied Reward Model with Test-time Scaling](https://arxiv.org//abs/2506.10389)

	Yuhang Chen, Zhen Tan, Tianlong Chen

+ [MNN-LLM: A Generic Inference Engine for Fast Large Language Model Deployment on Mobile Devices](https://arxiv.org//abs/2506.10443)

	Zhaode Wang, Jingbang Yang, Xinyu Qian, Shiwen Xing, Xiaotang Jiang, Chengfei Lv, Shengyu Zhang

+ [Preserving Task-Relevant Information Under Linear Concept Removal](https://arxiv.org//abs/2506.10703)

	Floris Holstege, Shauli Ravfogel, Bram Wouters

+ [Detecting High-Stakes Interactions with Activation Probes](https://arxiv.org//abs/2506.10805)

	Alex McKenzie, Urja Pawar, Phil Blandfort, William Bankes, David Krueger, Ekdeep Singh Lubana, Dmitrii Krasheninnikov

+ [Self-Adapting Language Models](https://arxiv.org//abs/2506.10943)

	Adam Zweiger, Jyothish Pari, Han Guo, Ekin Akyürek, Yoon Kim, Pulkit Agrawal

+ [Execution Guided Line-by-Line Code Generation](https://arxiv.org//abs/2506.10948)

	Boaz Lavon, Shahar Katz, Lior Wolf

+ [BugGen: A Self-Correcting Multi-Agent LLM Pipeline for Realistic RTL Bug Synthesis](https://arxiv.org//abs/2506.10501)

	Surya Jasper, Minh Luu, Evan Pan, Aakash Tyagi, Michael Quinn, Jiang Hu, David Kebo Houngninou

+ [ELFuzz: Efficient Input Generation via LLM-driven Synthesis Over Fuzzer Space](https://arxiv.org//abs/2506.10323)

	Chuyang Chen, Brendan Dolan-Gavitt, Zhiqiang Lin

+ [LLM-as-a-Fuzzy-Judge: Fine-Tuning Large Language Models as a Clinical Evaluation Judge with Fuzzy Logic](https://arxiv.org//abs/2506.11221)

	Weibing Zheng, Laurah Turner, Jess Kropczynski, Murat Ozer, Tri Nguyen, Shane Halse

+ [No Universal Prompt: Unifying Reasoning through Adaptive Prompting for Temporal Table Reasoning](https://arxiv.org//abs/2506.11246)

	Kushagra Dixit, Abhishek Rajgaria, Harshavardhan Kalalbandi, Dan Roth, Vivek Gupta

+ [Invocable APIs derived from NL2SQL datasets for LLM Tool-Calling Evaluation](https://arxiv.org//abs/2506.11266)

	Benjamin Elder, Anupama Murthi, Jungkoo Kang, Ankita Rajaram Naik, Kiran Kate, Kinjal Basu, Danish Contractor

+ [Don't Pay Attention](https://arxiv.org//abs/2506.11305)

	Mohammad Hammoud, Devang Acharya

+ [Iterative Multilingual Spectral Attribute Erasure](https://arxiv.org//abs/2506.11244)

	Shun Shao, Yftah Ziser, Zheng Zhao, Yifu Qiu, Shay B. Cohen, Anna Korhonen

+ [Learning a Continue-Thinking Token for Enhanced Test-Time Scaling](https://arxiv.org//abs/2506.11274)

	Liran Ringel, Elad Tolochinsky, Yaniv Romano

+ [From Replication to Redesign: Exploring Pairwise Comparisons for LLM-Based Peer Review](https://arxiv.org//abs/2506.11343)

	Yaohui Zhang, Haijing Zhang, Wenlong Ji, Tianyu Hua, Nick Haber, Hancheng Cao, Weixin Liang

+ [The Biased Samaritan: LLM biases in Perceived Kindness](https://arxiv.org//abs/2506.11361)

	Jack H Fagan, Ruhaan Juyaal, Amy Yue-Ming Yu, Siya Pun

+ [LLM-as-a-Judge for Reference-less Automatic Code Validation and Refinement for Natural Language to Bash in IT Automation](https://arxiv.org//abs/2506.11237)

	Ngoc Phuoc An Vo, Brent Paulovicks, Vadim Sheinin

+ [Lifting Data-Tracing Machine Unlearning to Knowledge-Tracing for Foundation Models](https://arxiv.org//abs/2506.11253)

	Yuwen Tan, Boqing Gong

+ [SwiftSpec: Ultra-Low Latency LLM Decoding by Scaling Asynchronous Speculative Decoding](https://arxiv.org//abs/2506.11309)

	Ziyi Zhang, Ziheng Jiang, Chengquan Jiang, Menghan Yu, Size Zheng, Haibin Lin, Henry Hoffmann, Xin Liu

+ [LLM Embedding-based Attribution (LEA): Quantifying Source Contributions to Generative Model's Response for Vulnerability Analysis](https://arxiv.org//abs/2506.12100)

	Reza Fayyazi, Michael Zuzak, Shanchieh Jay Yang

+ [UCD: Unlearning in LLMs via Contrastive Decoding](https://arxiv.org//abs/2506.12097)

	Vinith M. Suriyakumar, Ayush Sekhari, Ashia Wilson

# 2025-06-11
+ [Beyond Nash Equilibrium: Bounded Rationality of LLMs and humans in Strategic Decision-making](https://arxiv.org//abs/2506.09390)

	Kehan Zheng, Jinfeng Zhou, Hongning Wang

+ [A Call for Collaborative Intelligence: Why Human-Agent Systems Should Precede AI Autonomy](https://arxiv.org//abs/2506.09420)

	Henry Peng Zou, Wei-Chieh Huang, Yaozu Wu, Chunyu Miao, Dongyuan Li, Aiwei Liu, Yue Zhou, Yankai Chen, Weizhi Zhang, Yangning Li, Liancheng Fang, Renhe Jiang, Philip S. Yu

+ [DipLLM: Fine-Tuning LLM for Strategic Decision-making in Diplomacy](https://arxiv.org//abs/2506.09655)

	Kaixuan Xu, Jiajun Chai, Sicheng Li, Yuqian Fu, Yuanheng Zhu, Dongbin Zhao

+ [Application-Driven Value Alignment in Agentic AI Systems: Survey and Perspectives](https://arxiv.org//abs/2506.09656)

	Wei Zeng, Hengshu Zhu, Chuan Qin, Han Wu, Yihang Cheng, Sirui Zhang, Xiaowei Jin, Yinuo Shen, Zhenxing Wang, Feimin Zhong, Hui Xiong

+ [Intent Factored Generation: Unleashing the Diversity in Your Language Model](https://arxiv.org//abs/2506.09659)

	Eltayeb Ahmed, Uljad Berdica, Martha Elliott, Danijela Horak, Jakob N. Foerster

+ [Alzheimer's Dementia Detection Using Perplexity from Paired Large Language Models](https://arxiv.org//abs/2506.09315)

	Yao Xiao, Heidi Christensen, Stefan Goetze

+ [Multi-Agent Language Models: Advancing Cooperation, Coordination, and Adaptation](https://arxiv.org//abs/2506.09331)

	Arjun Vaithilingam Sudhakar

+ [Know What You Don't Know: Uncertainty Calibration of Process Reward Models](https://arxiv.org//abs/2506.09338)

	Young-Jin Park, Kristjan Greenewald, Kaveh Alim, Hao Wang, Navid Azizan

+ [RePO: Replay-Enhanced Policy Optimization](https://arxiv.org//abs/2506.09340)

	Siheng Li, Zhanhui Zhou, Wai Lam, Chao Yang, Chaochao Lu

+ ["Is This Really a Human Peer Supporter?": Misalignments Between Peer Supporters and Experts in LLM-Supported Interactions](https://arxiv.org//abs/2506.09354)

	Kellie Yu Hui Sim, Roy Ka-Wei Lee, Kenny Tsu Wei Choo

+ [Reasoning as a Resource: Optimizing Fast and Slow Thinking in Code Generation Models](https://arxiv.org//abs/2506.09396)

	Zongjie Li, Shuai Wang

+ [SLED: A Speculative LLM Decoding Framework for Efficient Edge Serving](https://arxiv.org//abs/2506.09397)

	Xiangchen Li, Dimitrios Spatharakis, Saeid Ghafouri, Jiakun Fan, Dimitrios Nikolopoulos

+ [Token Constraint Decoding Improves Robustness on Question Answering for Large Language Models](https://arxiv.org//abs/2506.09408)

	Jui-Ming Yao, Hao-Yuan Chen, Zi-Xian Tang, Bing-Jia Tan, Sheng-Wei Peng, Bing-Cheng Xie, Shun-Feng Su

+ [Improved Supervised Fine-Tuning for Large Language Models to Mitigate Catastrophic Forgetting](https://arxiv.org//abs/2506.09428)

	Fei Ding, Baiqiao Wang

+ [UniToMBench: Integrating Perspective-Taking to Improve Theory of Mind in LLMs](https://arxiv.org//abs/2506.09450)

	Prameshwar Thiyagarajan, Vaishnavi Parimi, Shamant Sai, Soumil Garg, Zhangir Meirbek, Nitin Yarlagadda, Kevin Zhu, Chris Kim

+ [ReasonMed: A 370K Multi-Agent Generated Dataset for Advancing Medical Reasoning](https://arxiv.org//abs/2506.09513)

	Yu Sun, Xingyu Qian, Weiwen Xu, Hao Zhang, Chenghao Xiao, Long Li, Yu Rong, Wenbing Huang, Qifeng Bai, Tingyang Xu

+ [Athena: Enhancing Multimodal Reasoning with Data-efficient Process Reward Models](https://arxiv.org//abs/2506.09532)

	Shuai Wang, Zhenhua Liu, Jiaheng Wei, Xuanwu Yin, Dong Li, Emad Barsoum

+ [AD^2-Bench: A Hierarchical CoT Benchmark for MLLM in Autonomous Driving under Adverse Conditions](https://arxiv.org//abs/2506.09557)

	Zhaoyang Wei, Chenhui Qiang, Bowen Jiang, Xumeng Han, Xuehui Yu, Zhenjun Han

+ [From Symbolic to Neural and Back: Exploring Knowledge Graph-Large Language Model Synergies](https://arxiv.org//abs/2506.09566)

	Blaž Škrlj, Boshko Koloski, Senja Pollak, Nada Lavrač

+ [Effective Red-Teaming of Policy-Adherent Agents](https://arxiv.org//abs/2506.09600)

	Itay Nakash, George Kour, Koren Lazar, Matan Vetzler, Guy Uziel, Ateret Anaby-Tavor

+ [Is Fine-Tuning an Effective Solution? Reassessing Knowledge Editing for Unstructured Data](https://arxiv.org//abs/2506.09672)

	Hao Xiong, Chuanyuan Tan, Wenliang Chen

+ [Reasoning Models Are More Easily Gaslighted Than You Think](https://arxiv.org//abs/2506.09677)

	Bin Zhu, Hailong Yin, Jingjing Chen, Yu-Gang Jiang

+ [TRIDENT: Temporally Restricted Inference via DFA-Enhanced Neural Traversal](https://arxiv.org//abs/2506.09701)

	Vincenzo Collura, Karim Tit, Laura Bussi, Eleonora Giunchiglia, Maxime Cordy

+ [Feature Engineering for Agents: An Adaptive Cognitive Architecture for Interpretable ML Monitoring](https://arxiv.org//abs/2506.09742)

	Gusseppe Bravo-Rocca, Peini Liu, Jordi Guitart, Rodrigo M Carrillo-Larco, Ajay Dholakia, David Ellison

+ [CoRT: Code-integrated Reasoning within Thinking](https://arxiv.org//abs/2506.09820)

	Chengpeng Li, Zhengyang Tang, Ziniu Li, Mingfeng Xue, Keqin Bao, Tian Ding, Ruoyu Sun, Benyou Wang, Xiang Wang, Junyang Lin, Dayiheng Liu

+ [Causal Sufficiency and Necessity Improves Chain-of-Thought Reasoning](https://arxiv.org//abs/2506.09853)

	Xiangning Yu, Zhuohan Wang, Linyi Yang, Haoxuan Li, Anjie Liu, Xiao Xue, Jun Wang, Mengyue Yang

+ [Attention Head Embeddings with Trainable Deep Kernels for Hallucination Detection in LLMs](https://arxiv.org//abs/2506.09886)

	Rodion Oblovatny, Alexandra Bazarova, Alexey Zaytsev

+ [The Emergence of Abstract Thought in Large Language Models Beyond Any Language](https://arxiv.org//abs/2506.09890)

	Yuxin Chen, Yiran Zhao, Yang Zhang, An Zhang, Kenji Kawaguchi, Shafiq Joty, Junnan Li, Tat-Seng Chua, Michael Qizhe Shieh, Wenxuan Zhang

+ [PersonaLens: A Benchmark for Personalization Evaluation in Conversational AI Assistants](https://arxiv.org//abs/2506.09902)

	Zheng Zhao, Clara Vania, Subhradeep Kayal, Naila Khan, Shay B. Cohen, Emine Yilmaz

+ [VerIF: Verification Engineering for Reinforcement Learning in Instruction Following](https://arxiv.org//abs/2506.09942)

	Hao Peng, Yunjia Qi, Xiaozhi Wang, Bin Xu, Lei Hou, Juanzi Li

+ [LLMail-Inject: A Dataset from a Realistic Adaptive Prompt Injection Challenge](https://arxiv.org//abs/2506.09956)

	Sahar Abdelnabi, Aideen Fay, Ahmed Salem, Egor Zverev, Kai-Chieh Liao, Chi-Huang Liu, Chun-Chih Kuo, Jannis Weigend, Danyael Manlangit, Alex Apostolov, Haris Umair, João Donato, Masayuki Kawakita, Athar Mahboob, Tran Huu Bach, Tsun-Han Chiang, Myeongjin Cho, Hajin Choi, Byeonghyeon Kim, Hyeonjin Lee, Benjamin Pannell, Conor McCauley, Mark Russinovich, Andrew Paverd, Giovanni Cherubin

+ [Reinforcing Spatial Reasoning in Vision-Language Models with Interwoven Thinking and Visual Drawing](https://arxiv.org//abs/2506.09965)

	Junfei Wu, Jian Guan, Kaituo Feng, Qiang Liu, Shu Wu, Liang Wang, Wei Wu, Tieniu Tan

+ [Towards Efficient and Effective Alignment of Large Language Models](https://arxiv.org//abs/2506.09329)

	Yuxin Jiang

+ [DIVE into MoE: Diversity-Enhanced Reconstruction of Large Language Models from Dense into Mixture-of-Experts](https://arxiv.org//abs/2506.09351)

	Yuchen Feng, Bowen Shen, Naibin Gu, Jiaxuan Zhao, Peng Fu, Zheng Lin, Weiping Wang

+ [Taming SQL Complexity: LLM-Based Equivalence Evaluation for Text-to-SQL](https://arxiv.org//abs/2506.09359)

	Qingyun Zeng, Simin Ma, Arash Niknafs, Ashish Basran, Carol Szabo

+ [Hidden in Plain Sight: Evaluation of the Deception Detection Capabilities of LLMs in Multimodal Settings](https://arxiv.org//abs/2506.09424)

	Md Messal Monem Miah, Adrita Anika, Xi Shi, Ruihong Huang

+ [Towards Bridging the Reward-Generation Gap in Direct Alignment Algorithms](https://arxiv.org//abs/2506.09457)

	Zeguan Xiao, Yun Chen, Guanhua Chen

+ [Give Me FP32 or Give Me Death? Challenges and Solutions for Reproducible Reasoning](https://arxiv.org//abs/2506.09501)

	Jiayi Yuan, Hao Li, Xinheng Ding, Wenya Xie, Yu-Jhe Li, Wentian Zhao, Kun Wan, Jing Shi, Xia Hu, Zirui Liu

+ [KG-Infused RAG: Augmenting Corpus-Based RAG with External Knowledge Graphs](https://arxiv.org//abs/2506.09542)

	Dingjun Wu, Yukun Yan, Zhenghao Liu, Zhiyuan Liu, Maosong Sun

+ [Memorization in Language Models through the Lens of Intrinsic Dimension](https://arxiv.org//abs/2506.09591)

	Stefan Arnold

+ [Benchmarking Debiasing Methods for LLM-based Parameter Estimates](https://arxiv.org//abs/2506.09627)

	Nicolas Audinet de Pieuchon, Adel Daoud, Connor T. Jerzak, Moa Johansson, Richard Johansson

+ [Learning Efficient and Generalizable Graph Retriever for Knowledge-Graph Question Answering](https://arxiv.org//abs/2506.09645)

	Tianjun Yao, Haoxuan Li, Zhiqiang Shen, Pan Li, Tongliang Liu, Kun Zhang

+ [Bridging the Gap Between Open-Source and Proprietary LLMs in Table QA](https://arxiv.org//abs/2506.09657)

	Nikolas Evkarpidi, Elena Tutubalina

+ [Query-Level Uncertainty in Large Language Models](https://arxiv.org//abs/2506.09669)

	Lihu Chen, Gaël Varoquaux

+ [Inv-Entropy: A Fully Probabilistic Framework for Uncertainty Quantification in Language Models](https://arxiv.org//abs/2506.09684)

	Haoyi Song, Ruihan Ji, Naichen Shi, Fan Lai, Raed Al Kontar

+ [Do LLMs Give Psychometrically Plausible Responses in Educational Assessments?](https://arxiv.org//abs/2506.09796)

	Andreas Säuberli, Diego Frassinelli, Barbara Plank

+ [Query-Focused Retrieval Heads Improve Long-Context Reasoning and Re-ranking](https://arxiv.org//abs/2506.09944)

	Wuwei Zhang, Fangcong Yin, Howard Yen, Danqi Chen, Xi Ye

+ [Resa: Transparent Reasoning Models via SAEs](https://arxiv.org//abs/2506.09967)

	Shangshang Wang, Julian Asilis, Ömer Faruk Akgül, Enes Burak Bilgin, Ollie Liu, Deqing Fu, Willie Neiswanger

+ [When Detection Fails: The Power of Fine-Tuned Models to Generate Human-Like Social Media Text](https://arxiv.org//abs/2506.09975)

	Hillary Dawkins, Kathleen C. Fraser, Svetlana Kiritchenko

+ [From Judgment to Interference: Early Stopping LLM Harmful Outputs via Streaming Content Monitoring](https://arxiv.org//abs/2506.09996)

	Yang Li, Qiang Sheng, Yehan Yang, Xueyao Zhang, Juan Cao

+ [Learning Obfuscations Of LLM Embedding Sequences: Stained Glass Transform](https://arxiv.org//abs/2506.09452)

	Jay Roberts, Kyle Mylonakis, Sidhartha Roy, Kaan Kale

+ [Flipping Against All Odds: Reducing LLM Coin Flip Bias via Verbalized Rejection Sampling](https://arxiv.org//abs/2506.09998)

	Tim Z. Xiao, Johannes Zenn, Zhen Liu, Weiyang Liu, Robert Bamler, Bernhard Schölkopf

+ [Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning](https://arxiv.org//abs/2506.09473)

	Cheng Chen, Yunpeng Zhai, Yifan Zhao, Jinyang Gao, Bolin Ding, Jia Li

+ [DAVSP: Safety Alignment for Large Vision-Language Models via Deep Aligned Visual Safety Prompt](https://arxiv.org//abs/2506.09353)

	Yitong Zhang, Jia Li, Liyi Cai, Ge Li

+ [On-the-Fly Adaptive Distillation of Transformer to Dual-State Linear Attention](https://arxiv.org//abs/2506.09316)

	Yeonju Ro, Zhenyu Zhang, Souvik Kundu, Zhangyang Wang, Aditya Akella

+ [Mitigating Spurious Correlations in LLMs via Causality-Aware Post-Training](https://arxiv.org//abs/2506.09433)

	Shurui Gui, Shuiwang Ji

+ [On a few pitfalls in KL divergence gradient estimation for RL](https://arxiv.org//abs/2506.09477)

	Yunhao Tang, Rémi Munos

+ [Beyond Overconfidence: Foundation Models Redefine Calibration in Deep Neural Networks](https://arxiv.org//abs/2506.09593)

	Achim Hekler, Lukas Kuhn, Florian Buettner

+ [SparseSSM: Efficient Selective Structured State Space Models Can Be Pruned in One-Shot](https://arxiv.org//abs/2506.09613)

	Kaiwen Tuo, Huan Wang

+ [In-Context Bias Propagation in LLM-Based Tabular Data Generation](https://arxiv.org//abs/2506.09630)

	Pol G.Recasens, Alberto Gutierrez, Jordi Torres, Josep.Ll Berral, Anisa Halimi, Kieran Fraser

+ [Towards Multi-modal Graph Large Language Model](https://arxiv.org//abs/2506.09738)

	Xin Wang, Zeyang Zhang, Linxin Xiao, Haibo Chen, Chendi Ge, Wenwu Zhu

+ [Apollo: A Posteriori Label-Only Membership Inference Attack Towards Machine Unlearning](https://arxiv.org//abs/2506.09923)

	Liou Tang, James Joshi, Ashish Kundu

+ [Multiverse: Your Language Models Secretly Decide How to Parallelize and Merge Generation](https://arxiv.org//abs/2506.09991)

	Xinyu Yang, Yuwei An, Hongyi Liu, Tianqi Chen, Beidi Chen

+ [LLMs Cannot Reliably Judge (Yet?): A Comprehensive Assessment on the Robustness of LLM-as-a-Judge](https://arxiv.org//abs/2506.09443)

	Songze Li, Chuokun Xu, Jiaying Wang, Xueluan Gong, Chen Chen, Jirui Zhang, Jun Wang, Kwok-Yan Lam, Shouling Ji

+ [Omni-DPO: A Dual-Perspective Paradigm for Dynamic Preference Learning of LLMs](https://arxiv.org//abs/2506.10054)

	Shangpin Peng, Weinong Wang, Zhuotao Tian, Senqiao Yang, Xing Wu, Haotian Xu, Chengquan Zhang, Takashi Isobe, Baotian Hu, Min Zhang

+ [Textual Bayes: Quantifying Uncertainty in LLM-Based Systems](https://arxiv.org//abs/2506.10060)

	Brendan Leigh Ross, Noël Vouitsis, Atiyeh Ashari Ghomi, Rasa Hosseinzadeh, Ji Xin, Zhaoyan Liu, Yi Sui, Shiyi Hou, Kin Kwan Leung, Gabriel Loaiza-Ganem, Jesse C. Cresswell

+ [Unsupervised Elicitation of Language Models](https://arxiv.org//abs/2506.10139)

	Jiaxin Wen, Zachary Ankner, Arushi Somani, Peter Hase, Samuel Marks, Jacob Goldman-Wetzler, Linda Petrini, Henry Sleight, Collin Burns, He He, Shi Feng, Ethan Perez, Jan Leike

+ [Disclosure Audits for LLM Agents](https://arxiv.org//abs/2506.10171)

	Saswat Das, Jameson Sandler, Ferdinando Fioretto

+ [Prompt Attacks Reveal Superficial Knowledge Removal in Unlearning Methods](https://arxiv.org//abs/2506.10236)

	Yeonwoo Jang, Shariqah Hossain, Ashwin Sreevatsa, Diogo Cruz

+ [TaskCraft: Automated Generation of Agentic Tasks](https://arxiv.org//abs/2506.10055)

	Dingfeng Shi, Jingyi Cao, Qianben Chen, Weichen Sun, Weizhen Li, Hongxuan Lu, Fangchen Dong, Tianrui Qin, King Zhu, Minghao Yang, Jian Yang, Ge Zhang, Jiaheng Liu, Changwang Zhang, Jun Wang, Yuchen Eleanor Jiang, Wangchunshu Zhou

+ [Chat-of-Thought: Collaborative Multi-Agent System for Generating Domain Specific Information](https://arxiv.org//abs/2506.10086)

	Christodoulos Constantinides, Shuxin Lin, Nianjun Zhou, Dhaval Patel

+ [When Meaning Stays the Same, but Models Drift: Evaluating Quality of Service under Token-Level Behavioral Instability in LLMs](https://arxiv.org//abs/2506.10095)

	Xiao Li, Joel Kreuzwieser, Alan Peters

+ [When Large Language Models are Reliable for Judging Empathic Communication](https://arxiv.org//abs/2506.10150)

	Aakriti Kumar, Nalin Poungpeth, Diyi Yang, Erina Farrell, Bruce Lambert, Matthew Groh

+ [GenBreak: Red Teaming Text-to-Image Generators Using Large Language Models](https://arxiv.org//abs/2506.10047)

	Zilong Wang, Xiang Zheng, Xiaosen Wang, Bo Wang, Xingjun Ma, Yu-Gang Jiang

+ [AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent](https://arxiv.org//abs/2506.10205)

	Jing Liu, Toshiaki Koike-Akino, Ye Wang, Hassan Mansour, Matthew Brand

+ [Prompt Variability Effects On LLM Code Generation](https://arxiv.org//abs/2506.10204)

	Andrei Paleyes, Radzim Sendyka, Diana Robinson, Christian Cabrera, Neil D. Lawrence

+ [Expert-in-the-Loop Systems with Cross-Domain and In-Domain Few-Shot Learning for Software Vulnerability Detection](https://arxiv.org//abs/2506.10104)

	David Farr, Kevin Talty, Alexandra Farr, John Stockdale, Iain Cruickshank, Jevin West

+ [D-LiFT: Improving LLM-based Decompiler Backend via Code Quality-driven Fine-tuning](https://arxiv.org//abs/2506.10125)

	Muqi Zou, Hongyu Cai, Hongwei Wu, Zion Leonahenahe Basque, Arslan Khan, Berkay Celik, Dave (Jing)Tian, Antonio Bianchi, Ruoyu (Fish)Wang, Dongyan Xu

+ [AURA: A Multi-Agent Intelligence Framework for Knowledge-Enhanced Cyber Threat Attribution](https://arxiv.org//abs/2506.10175)

	Nanda Rani, Sandeep Kumar Shukla

+ [Autonomous Computer Vision Development with Agentic AI](https://arxiv.org//abs/2506.11140)

	Jin Kim, Muhammad Wahi-Anwa, Sangyun Park, Shawn Shin, John M. Hoffman, Matthew S. Brown

+ [Test-Time-Scaling for Zero-Shot Diagnosis with Visual-Language Reasoning](https://arxiv.org//abs/2506.11166)

	Ji Young Byun, Young-Jin Park, Navid Azizan, Rama Chellappa

+ [ADAgent: LLM Agent for Alzheimer's Disease Analysis with Collaborative Coordinator](https://arxiv.org//abs/2506.11150)

	Wenlong Hou, Gangqian Yang, Ye Du, Yeung Lau, Lihao Liu, Junjun He, Ling Long, Shujun Wang

+ [ChatbotManip: A Dataset to Facilitate Evaluation and Oversight of Manipulative Chatbot Behaviour](https://arxiv.org//abs/2506.12090)

	Jack Contro, Simrat Deol, Yulan He, Martim Brandão

# 2025-06-10
+ [ORFS-agent: Tool-Using Agents for Chip Design Optimization](https://arxiv.org//abs/2506.08332)

	Amur Ghose, Andrew B. Kahng, Sayak Kundu, Zhiang Wang

+ [On Reasoning Strength Planning in Large Reasoning Models](https://arxiv.org//abs/2506.08390)

	Leheng Sheng, An Zhang, Zijian Wu, Weixiang Zhao, Changshuo Shen, Yi Zhang, Xiang Wang, Tat-Seng Chua

+ [SafeCoT: Improving VLM Safety with Minimal Reasoning](https://arxiv.org//abs/2506.08399)

	Jiachen Ma, Zhanhui Zhou, Chao Yang, Chaochao Lu

+ [A Survey on Large Language Models for Mathematical Reasoning](https://arxiv.org//abs/2506.08446)

	Peng-Yuan Wang, Tian-Shuo Liu, Chenyang Wang, Yi-Di Wang, Shu Yan, Cheng-Xing Jia, Xu-Hui Liu, Xin-Wei Chen, Jia-Cheng Xu, Ziniu Li, Yang Yu

+ [RHealthTwin: Towards Responsible and Multimodal Digital Twins for Personalized Well-being](https://arxiv.org//abs/2506.08486)

	Rahatara Ferdousi, M Anwar Hossain

+ [Consistent Paths Lead to Truth: Self-Rewarding Reinforcement Learning for LLM Reasoning](https://arxiv.org//abs/2506.08745)

	Kongcheng Zhang, Qi Yao, Shunyu Liu, Yingjie Wang, Baisheng Lai, Jieping Ye, Mingli Song, Dacheng Tao

+ [Paths to Causality: Finding Informative Subgraphs Within Knowledge Graphs for Knowledge-Based Causal Discovery](https://arxiv.org//abs/2506.08771)

	Yuni Susanti, Michael Färber

+ [Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents](https://arxiv.org//abs/2506.08800)

	Irene Testini, José Hernández-Orallo, Lorenzo Pacchiardi

+ [Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task](https://arxiv.org//abs/2506.08872)

	Nataliya Kosmyna, Eugene Hauptmann, Ye Tong Yuan, Jessica Situ, Xian-Hao Liao, Ashly Vivian Beresnitzky, Iris Braunstein, Pattie Maes

+ [AbstentionBench: Reasoning LLMs Fail on Unanswerable Questions](https://arxiv.org//abs/2506.09038)

	Polina Kirichenko, Mark Ibrahim, Kamalika Chaudhuri, Samuel J. Bell

+ [Understanding Software Engineering Agents Through the Lens of Traceability: An Empirical Study](https://arxiv.org//abs/2506.08311)

	Ira Ceka, Saurabh Pujar, Shyam Ramji, Luca Buratti, Gail Kaiser, Baishakhi Ray

+ [How Good LLM-Generated Password Policies Are?](https://arxiv.org//abs/2506.08320)

	Vivek Vaidya, Aditya Patwardhan, Ashish Kundu

+ [Your Agent Can Defend Itself against Backdoor Attacks](https://arxiv.org//abs/2506.08336)

	Li Changjiang, Liang Jiacheng, Cao Bochuan, Chen Jinghui, Wang Ting

+ [Evaluating LLMs Across Multi-Cognitive Levels: From Medical Knowledge Mastery to Scenario-Based Problem Solving](https://arxiv.org//abs/2506.08349)

	Yuxuan Zhou, Xien Liu, Chenwei Yan, Chen Ning, Xiao Zhang, Boxun Li, Xiangling Fu, Shijin Wang, Guoping Hu, Yu Wang, Ji Wu

+ [Draft-based Approximate Inference for LLMs](https://arxiv.org//abs/2506.08373)

	Kevin Galim, Ethan Ewer, Wonjun Kang, Minjae Lee, Hyung Il Koo, Kangwook Lee

+ [Reinforce LLM Reasoning through Multi-Agent Reflection](https://arxiv.org//abs/2506.08379)

	Yurun Yuan, Tengyang Xie

+ [Reinforcement Learning Teachers of Test Time Scaling](https://arxiv.org//abs/2506.08388)

	Edoardo Cetin, Tianyu Zhao, Yujin Tang

+ [TACTIC: Translation Agents with Cognitive-Theoretic Interactive Collaboration](https://arxiv.org//abs/2506.08403)

	Weiya Li, Junjie Chen, Bei Li, Boyang Liu, Zichen Wen, Nuanqiao Shan, Xiaoqian Liu, Anping Liu, Huajie Liu, Youyan Wang, Wujiuge Yin, Hu Song, Bing Huang, Zhiyuan Xia, Jialiang Chen, Linfeng Zhang

+ [Efficient Context Selection for Long-Context QA: No Tuning, No Iteration, Just Adaptive-$k$](https://arxiv.org//abs/2506.08479)

	Chihiro Taguchi, Seiji Maekawa, Nikita Bhutani

+ [EtiCor++: Towards Understanding Etiquettical Bias in LLMs](https://arxiv.org//abs/2506.08488)

	Ashutosh Dwivedi, Siddhant Shivdutt Singh, Ashutosh Modi

+ [DRAGged into Conflicts: Detecting and Addressing Conflicting Sources in Search-Augmented LLMs](https://arxiv.org//abs/2506.08500)

	Arie Cattan, Alon Jacovi, Ori Ram, Jonathan Herzig, Roee Aharoni, Sasha Goldshtein, Eran Ofek, Idan Szpektor, Avi Caciularu

+ [MLVTG: Mamba-Based Feature Alignment and LLM-Driven Purification for Multi-Modal Video Temporal Grounding](https://arxiv.org//abs/2506.08512)

	Zhiyi Zhu, Xiaoyu Wu, Zihao Liu, Linlin Yang

+ [Efficient Post-Training Refinement of Latent Reasoning in Large Language Models](https://arxiv.org//abs/2506.08552)

	Xinyuan Wang, Dongjie Wang, Wangyang Ying, Haoyue Bai, Nanxu Gong, Sixun Dong, Kunpeng Liu, Yanjie Fu

+ [The Geometries of Truth Are Orthogonal Across Tasks](https://arxiv.org//abs/2506.08572)

	Waiss Azizian, Michael Kirchhof, Eugene Ndiaye, Louis Bethune, Michal Klein, Pierre Ablin, Marco Cuturi

+ [TableDreamer: Progressive and Weakness-guided Data Synthesis from Scratch for Table Instruction Tuning](https://arxiv.org//abs/2506.08646)

	Mingyu Zheng, Zhifan Feng, Jia Wang, Lanrui Wang, Zheng Lin, Yang Hao, Weiping Wang

+ [ConfPO: Exploiting Policy Model Confidence for Critical Token Selection in Large Language Model Preference Optimization](https://arxiv.org//abs/2506.08712)

	Hee Suk Yoon, Eunseop Yoon, Mark A. Hasegawa-Johnson, Sungwoong Kim, Chang D. Yoo

+ [Improved LLM Agents for Financial Document Question Answering](https://arxiv.org//abs/2506.08726)

	Nelvin Tan, Zian Seng, Liang Zhang, Yu-Ching Shih, Dong Yang, Amol Salunkhe

+ [Breaking the ICE: Exploring promises and challenges of benchmarks for Inference Carbon & Energy estimation for LLMs](https://arxiv.org//abs/2506.08727)

	Samarth Sikand, Rohit Mehra, Priyavanshi Pathania, Nikhil Bamby, Vibhu Saujanya Sharma, Vikrant Kaulgud, Sanjay Podder, Adam P. Burden

+ [Factors affecting the in-context learning abilities of LLMs for dialogue state tracking](https://arxiv.org//abs/2506.08753)

	Pradyoth Hegde, Santosh Kesiraju, Jan Švec, Šimon Sedláček, Bolaji Yusuf, Oldřich Plchot, Deepak K T, Jan Černocký

+ [The impact of fine tuning in LLaMA on hallucinations for named entity extraction in legal documentation](https://arxiv.org//abs/2506.08827)

	Francisco Vargas, Alejandro González Coene, Gaston Escalante, Exequiel Lobón, Manuel Pulido

+ [SeerAttention-R: Sparse Attention Adaptation for Long Reasoning](https://arxiv.org//abs/2506.08889)

	Yizhao Gao, Shuming Guo, Shijie Cao, Yuqing Xia, Yu Cheng, Lei Wang, Lingxiao Ma, Yutao Sun, Tianzhu Ye, Li Dong, Hayden Kwok-Hay So, Yu Hua, Ting Cao, Fan Yang, Mao Yang

+ [PropMEND: Hypernetworks for Knowledge Propagation in LLMs](https://arxiv.org//abs/2506.08920)

	Zeyu Leo Liu, Greg Durrett, Eunsol Choi

+ [Can LLMs Ground when they (Don't) Know: A Study on Direct and Loaded Political Questions](https://arxiv.org//abs/2506.08952)

	Clara Lachenmaier, Judith Sieker, Sina Zarrieß

+ [GFRIEND: Generative Few-shot Reward Inference through EfficieNt DPO](https://arxiv.org//abs/2506.08965)

	Yiyang Zhao, Huiyu Bai, Xuejiao Zhao

+ [Router-R1: Teaching LLMs Multi-Round Routing and Aggregation via Reinforcement Learning](https://arxiv.org//abs/2506.09033)

	Haozhen Zhang, Tao Feng, Jiaxuan You

+ [FZOO: Fast Zeroth-Order Optimizer for Fine-Tuning Large Language Models towards Adam-Scale Speed](https://arxiv.org//abs/2506.09034)

	Sizhe Dang, Yangyang Guo, Yanjun Zhao, Haishan Ye, Xiaodong Zheng, Guang Dai, Ivor Tsang

+ [Autoregressive Semantic Visual Reconstruction Helps VLMs Understand Better](https://arxiv.org//abs/2506.09040)

	Dianyi Wang, Wei Song, Yikun Wang, Siyuan Wang, Kaicheng Yu, Zhongyu Wei, Jiaqi Wang

+ [Agentic Neural Networks: Self-Evolving Multi-Agent Systems via Textual Backpropagation](https://arxiv.org//abs/2506.09046)

	Xiaowen Ma, Chenyang Lin, Yao Zhang, Volker Tresp, Yunpu Ma

+ [Wait, We Don't Need to "Wait"! Removing Thinking Tokens Improves Reasoning Efficiency](https://arxiv.org//abs/2506.08343)

	Chenlong Wang, Yuanning Feng, Dongping Chen, Zhaoyang Chu, Ranjay Krishna, Tianyi Zhou

+ [DEAL: Disentangling Transformer Head Activations for LLM Steering](https://arxiv.org//abs/2506.08359)

	Li-Ming Zhan, Bo Liu, Zexin Lu, Chengqiang Xie, Jiannong Cao, Xiao-Ming Wu

+ [CC-RAG: Structured Multi-Hop Reasoning via Theme-Based Causal Graphs](https://arxiv.org//abs/2506.08364)

	Jash Rajesh Parekh, Pengcheng Jiang, Jiawei Han

+ [Mitigating Posterior Salience Attenuation in Long-Context LLMs with Positional Contrastive Decoding](https://arxiv.org//abs/2506.08371)

	Zikai Xiao, Ziyang Wang, Wen Ma, Yan Zhang, Wei Shen, Yan Wang, Luqi Gong, Zuozhu Liu

+ [EIFBENCH: Extremely Complex Instruction Following Benchmark for Large Language Models](https://arxiv.org//abs/2506.08375)

	Tao Zou, Xinghua Zhang, Haiyang Yu, Minzheng Wang, Fei Huang, Yongbin Li

+ [Large Language Models Have Intrinsic Meta-Cognition, but Need a Good Lens](https://arxiv.org//abs/2506.08410)

	Ziyang Ma, Qingyue Yuan, Zhenglin Wang, Deyu Zhou

+ [Know-MRI: A Knowledge Mechanisms Revealer&Interpreter for Large Language Models](https://arxiv.org//abs/2506.08427)

	Jiaxiang Liu, Boxuan Xing, Chenhao Yuan, Chenxiang Zhang, Di Wu, Xiusheng Huang, Haida Yu, Chuhan Lang, Pengfei Cao, Jun Zhao, Kang Liu

+ [CAF-I: A Collaborative Multi-Agent Framework for Enhanced Irony Detection with Large Language Models](https://arxiv.org//abs/2506.08430)

	Ziqi.Liu, Ziyang.Zhou, Mingxuan.Hu

+ [Olica: Efficient Structured Pruning of Large Language Models without Retraining](https://arxiv.org//abs/2506.08436)

	Jiujun He, Huazhen Lin

+ [CounselBench: A Large-Scale Expert Evaluation and Adversarial Benchmark of Large Language Models in Mental Health Counseling](https://arxiv.org//abs/2506.08584)

	Yahan Li, Jifan Yao, John Bosco S. Bunyi, Adam C. Frank, Angel Hwang, Ruishan Liu

+ [Dense Retrievers Can Fail on Simple Queries: Revealing The Granularity Dilemma of Embeddings](https://arxiv.org//abs/2506.08592)

	Liyan Xu, Zhenlin Su, Mo Yu, Jiangnan Li, Fandong Meng, Jie Zhou

+ [Hateful Person or Hateful Model? Investigating the Role of Personas in Hate Speech Detection by Large Language Models](https://arxiv.org//abs/2506.08593)

	Shuzhou Yuan, Ercong Nie, Mario Tawfelis, Helmut Schmid, Hinrich Schütze, Michael Färber

+ [RAISE: Enhancing Scientific Reasoning in LLMs via Step-by-Step Retrieval](https://arxiv.org//abs/2506.08625)

	Minhae Oh, Jeonghye Kim, Nakyung Lee, Donggeon Seo, Taeuk Kim, Jungwoo Lee

+ [MEMETRON: Metaheuristic Mechanisms for Test-time Response Optimization of Large Language Models](https://arxiv.org//abs/2506.08643)

	Son The Nguyen, Theja Tulabandhula

+ [Brevity is the soul of sustainability: Characterizing LLM response lengths](https://arxiv.org//abs/2506.08686)

	Soham Poddar, Paramita Koley, Janardan Misra, Sanjay Podder, Navveen Balani, Niloy Ganguly, Saptarshi Ghosh

+ [Towards Secure and Private Language Models for Nuclear Power Plants](https://arxiv.org//abs/2506.08746)

	Muhammad Anwar, Mishca de Costa, Issam Hammad, Daniel Lau

+ [AraReasoner: Evaluating Reasoning-Based LLMs for Arabic NLP](https://arxiv.org//abs/2506.08768)

	Ahmed Hasanaath, Aisha Alansari, Ahmed Ashraf, Chafik Salmane, Hamzah Luqman, Saad Ezzini

+ [AdversariaL attacK sAfety aLIgnment(ALKALI): Safeguarding LLMs through GRACE: Geometric Representation-Aware Contrastive Enhancement- Introducing Adversarial Vulnerability Quality Index (AVQI)](https://arxiv.org//abs/2506.08885)

	Danush Khanna, Krishna Kumar, Basab Ghosh, Vinija Jain, Vasu Sharma, Aman Chadha, Amitava Das

+ [FaithfulRAG: Fact-Level Conflict Modeling for Context-Faithful Retrieval-Augmented Generation](https://arxiv.org//abs/2506.08938)

	Qinggang Zhang, Zhishang Xiang, Yilin Xiao, Le Wang, Junhui Li, Xinrun Wang, Jinsong Su

+ [Pre-trained Language Models Learn Remarkably Accurate Representations of Numbers](https://arxiv.org//abs/2506.08966)

	Marek Kadlčík, Michal Štefánik, Timothee Mickus, Michal Spiegel, Josef Kuchař

+ [Atomic-to-Compositional Generalization for Mobile Agents with A New Benchmark and Scheduling System](https://arxiv.org//abs/2506.08972)

	Yuan Guo, Tingjia Miao, Zheng Wu, Pengzhou Cheng, Ming Zhou, Zhuosheng Zhang

+ [Learning to Reason Across Parallel Samples for LLM Reasoning](https://arxiv.org//abs/2506.09014)

	Jianing Qi, Xi Ye, Hao Tang, Zhigang Zhu, Eunsol Choi

+ [Same Task, Different Circuits: Disentangling Modality-Specific Mechanisms in VLMs](https://arxiv.org//abs/2506.09047)

	Yaniv Nikankin, Dana Arad, Yossi Gandelsman, Yonatan Belinkov

+ [Approaching Dialogue State Tracking via Aligning Speech Encoders and LLMs](https://arxiv.org//abs/2506.08633)

	Šimon Sedláček, Bolaji Yusuf, Ján Švec, Pradyoth Hegde, Santosh Kesiraju, Oldřich Plchot, Jan Černocký

+ [EDINET-Bench: Evaluating LLMs on Complex Financial Tasks using Japanese Financial Statements](https://arxiv.org//abs/2506.08762)

	Issa Sugiura, Takashi Ishida, Taro Makino, Chieko Tazuke, Takanori Nakagawa, Kosuke Nakago, David Ha

+ [SwS: Self-aware Weakness-driven Problem Synthesis in Reinforcement Learning for LLM Reasoning](https://arxiv.org//abs/2506.08989)

	Xiao Liang, Zhong-Zhi Li, Yeyun Gong, Yang Wang, Hengyuan Zhang, Yelong Shen, Ying Nian Wu, Weizhu Chen

+ [e3: Learning to Explore Enables Extrapolation of Test-Time Compute for LLMs](https://arxiv.org//abs/2506.09026)

	Amrith Setlur, Matthew Y. R. Yang, Charlie Snell, Jeremy Greer, Ian Wu, Virginia Smith, Max Simchowitz, Aviral Kumar

+ [Better Reasoning with Less Data: Enhancing VLMs Through Unified Modality Scoring](https://arxiv.org//abs/2506.08429)

	Mingjie Xu, Andrew Estornell, Hongzheng Yang, Yuzhi Zhao, Zhaowei Zhu, Qi Xuan, Jiaheng Wei

+ [VReST: Enhancing Reasoning in Large Vision-Language Models through Tree Search and Self-Reward Mechanism](https://arxiv.org//abs/2506.08691)

	Congzhi Zhang, Jiawei Peng, Zhenglin Wang, Yilong Lai, Haowen Sun, Heng Chang, Fei Ma, Weijiang Yu

+ [What Limits Virtual Agent Application? OmniBench: A Scalable Multi-Dimensional Benchmark for Essential Virtual Agent Capabilities](https://arxiv.org//abs/2506.08933)

	Wendong Bu, Yang Wu, Qifan Yu, Minghe Gao, Bingchen Miao, Zhenkui Zhang, Kaihang Pan, Yunfei Li, Mengze Li, Wei Ji, Juncheng Li, Siliang Tang, Yueting Zhuang

+ [AsFT: Anchoring Safety During LLM Fine-Tuning Within Narrow Safety Basin](https://arxiv.org//abs/2506.08473)

	Shuo Yang, Qihui Zhang, Yuyang Liu, Yue Huang, Xiaojun Jia, Kunpeng Ning, Jiayu Yao, Jigang Wang, Hailiang Dai, Yibing Song, Li Yuan

+ [Sample Efficient Demonstration Selection for In-Context Learning](https://arxiv.org//abs/2506.08607)

	Kiran Purohit, V Venktesh, Sourangshu Bhattacharya, Avishek Anand

+ [Mitigating Reward Over-optimization in Direct Alignment Algorithms with Importance Sampling](https://arxiv.org//abs/2506.08681)

	Phuc Minh Nguyen, Ngoc-Hieu Nguyen, Duy H. M. Nguyen, Anji Liu, An Mai, Binh T. Nguyen, Daniel Sonntag, Khoa D. Doan

+ [Design Patterns for Securing LLM Agents against Prompt Injections](https://arxiv.org//abs/2506.08837)

	Luca Beurer-Kellner, Beat Buesser Ana-Maria Creţu, Edoardo Debenedetti, Daniel Dobos, Daniel Fabian, Marc Fischer, David Froelicher, Kathrin Grosse, Daniel Naeff, Ezinwanne Ozoani, Andrew Paverd, Florian Tramèr, Václav Volhejn

+ [Understanding Task Vectors in In-Context Learning: Emergence, Functionality, and Limitations](https://arxiv.org//abs/2506.09048)

	Yuxin Dong, Jiachen Jiang, Zhihui Zhu, Xia Ning

+ [On the Ethics of Using LLMs for Offensive Security](https://arxiv.org//abs/2506.08693)

	Andreas Happe, Jürgen Cito

+ [LLM-ML Teaming: Integrated Symbolic Decoding and Gradient Search for Valid and Stable Generative Feature Transformation](https://arxiv.org//abs/2506.09085)

	Xinyuan Wang, Haoyue Bai, Nanxu Gong, Wangyang Ying, Sixun Dong, Xiquan Cui, Yanjie Fu

+ [Intra-Trajectory Consistency for Reward Modeling](https://arxiv.org//abs/2506.09096)

	Chaoyang Zhou, Shunyu Liu, Zengmao Wang, Di Wang, Rong-Cheng Tu, Bo Du, Dacheng Tao

+ [Too Big to Think: Capacity, Memorization, and Generalization in Pre-Trained Transformers](https://arxiv.org//abs/2506.09099)

	Joshua Barron, Devin White

+ [Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs](https://arxiv.org//abs/2506.09104)

	Jung Hyun Lee, Seungjae Shin, Vinnam Kim, Jaeseong You, An Chen

+ [FAIRTOPIA: Envisioning Multi-Agent Guardianship for Disrupting Unfair AI Pipelines](https://arxiv.org//abs/2506.09107)

	Athena Vakali, Ilias Dimitriadis

+ [LLM-as-a-qualitative-judge: automating error analysis in natural language generation](https://arxiv.org//abs/2506.09147)

	Nadezhda Chirkova, Tunde Oluwaseyi Ajayi, Seth Aycock, Zain Muhammad Mujahid, Vladana Perlić, Ekaterina Borisova, Markarit Vartampetian

+ [Improving LLM Agent Planning with In-Context Learning via Atomic Fact Augmentation and Lookahead Search](https://arxiv.org//abs/2506.09171)

	Samuel Holt, Max Ruiz Luyten, Thomas Pouplin, Mihaela van der Schaar

+ [FLoRIST: Singular Value Thresholding for Efficient and Accurate Federated Fine-Tuning of Large Language Models](https://arxiv.org//abs/2506.09199)

	Hariharan Ramesh, Jyotikrishna Dass

+ [Extrapolation by Association: Length Generalization Transfer in Transformers](https://arxiv.org//abs/2506.09251)

	Ziyang Cai, Nayoung Lee, Avi Schwarzschild, Samet Oymak, Dimitris Papailiopoulos

+ [Teaching Physical Awareness to LLMs through Sounds](https://arxiv.org//abs/2506.08524)

	Weiguo Wang, Andy Nie, Wenrui Zhou, Yi Kai, Chengchen Hu

+ [Did I Faithfully Say What I Thought? Bridging the Gap Between Neural Activity and Self-Explanations in Large Language Models](https://arxiv.org//abs/2506.09277)

	Milan Bhan, Jean-Noel Vittaut, Nicolas Chesneau, Sarath Chandar, Marie-Jeanne Lesot

+ [Adversarial Text Generation with Dynamic Contextual Perturbation](https://arxiv.org//abs/2506.09148)

	Hetvi Waghela, Jaydip Sen, Sneha Rakshit, Subhasis Dasgupta

+ [UTBoost: Rigorous Evaluation of Coding Agents on SWE-Bench](https://arxiv.org//abs/2506.09289)

	Boxi Yu, Yuxuan Zhu, Pinjia He, Daniel Kang

+ [The Curious Language Model: Strategic Test-Time Information Acquisition](https://arxiv.org//abs/2506.09173)

	Michael Cooper, Rohan Wadhawan, John Michael Giorgi, Chenhao Tan, Davis Liang

+ [FedRAG: A Framework for Fine-Tuning Retrieval-Augmented Generation Systems](https://arxiv.org//abs/2506.09200)

	Val Andrei Fajardo, David B. Emerson, Amandeep Singh, Veronica Chatrath, Marcelo Lotif, Ravi Theja, Alex Cheung, Izuki Matsubi

+ [SoK: Machine Unlearning for Large Language Models](https://arxiv.org//abs/2506.09227)

	Jie Ren, Yue Xing, Yingqian Cui, Charu C. Aggarwal, Hui Liu

+ [Agent-based Condition Monitoring Assistance with Multimodal Industrial Database Retrieval Augmented Generation](https://arxiv.org//abs/2506.09247)

	Karl Löwenmark, Daniel Strömbergsson, Chang Liu, Marcus Liwicki, Fredrik Sandin

+ [G-Sim: Generative Simulations with Large Language Models and Gradient-Free Calibration](https://arxiv.org//abs/2506.09272)

	Samuel Holt, Max Ruiz Luyten, Antonin Berthon, Mihaela van der Schaar

+ [DeepForm: Reasoning Large Language Model for Communication System Formulation](https://arxiv.org//abs/2506.08551)

	Panlong Wu, Ting Wang, Yifei Zhong, Haoqi Zhang, Zitong Wang, Fangxin Wang

+ [Evaluation empirique de la sécurisation et de l'alignement de ChatGPT et Gemini: analyse comparative des vulnérabilités par expérimentations de jailbreaks](https://arxiv.org//abs/2506.10029)

	Rafaël Nouailles (GdR)

+ [Safeguarding Multimodal Knowledge Copyright in the RAG-as-a-Service Environment](https://arxiv.org//abs/2506.10030)

	Tianyu Chen, Jian Lou, Wenjie Wang

+ [SDMPrune: Self-Distillation MLP Pruning for Efficient Large Language Models](https://arxiv.org//abs/2506.11120)

	Hourun Zhu, Chengchao Shen

+ [Stronger Language Models Produce More Human-Like Errors](https://arxiv.org//abs/2506.11128)

	Andrew Keenan Richardson, Ryan Othniel Kearns, Sean Moss, Vincent Wang-Mascianica, Philipp Koralus

+ [Trustworthy AI for Medicine: Continuous Hallucination Detection and Elimination with CHECK](https://arxiv.org//abs/2506.11129)

	Carlos Garcia-Fernandez, Luis Felipe, Monique Shotande, Muntasir Zitu, Aakash Tripathi, Ghulam Rasool, Issam El Naqa, Vivek Rudrapatna, Gilmer Valdes

+ [Risks & Benefits of LLMs & GenAI for Platform Integrity, Healthcare Diagnostics, Cybersecurity, Privacy & AI Safety: A Comprehensive Survey, Roadmap & Implementation Blueprint](https://arxiv.org//abs/2506.12088)

	Kiarash Ahi

# 2025-06-09
+ [Cognitive Weave: Synthesizing Abstracted Knowledge with a Spatio-Temporal Resonance Graph](https://arxiv.org//abs/2506.08098)

	Akash Vishwakarma, Hojin Lee, Mohith Suresh, Priyam Shankar Sharma, Rahul Vishwakarma, Sparsh Gupta, Yuvraj Anupam Chauhan

+ [SOP-Bench: Complex Industrial SOPs for Evaluating LLM Agents](https://arxiv.org//abs/2506.08119)

	Subhrangshu Nandi, Arghya Datta, Nikhil Vichare, Indranil Bhattacharya, Huzefa Raja, Jing Xu, Shayan Ray, Giuseppe Carenini, Abhi Srivastava, Aaron Chan, Man Ho Woo, Amar Kandola, Brandon Theresa, Francesco Carbone

+ [QUITE: A Query Rewrite System Beyond Rules with LLM Agents](https://arxiv.org//abs/2506.07675)

	Yuyang Song, Hanxu Yan, Jiale Lao, Yibo Wang, Yufei Li, Yuanchun Zhou, Jianguo Wang, Mingjie Tang

+ [Eliciting Fine-Tuned Transformer Capabilities via Inference-Time Techniques](https://arxiv.org//abs/2506.08060)

	Asankhaya Sharma

+ [Hierarchical Lexical Graph for Enhanced Multi-Hop Retrieval](https://arxiv.org//abs/2506.08074)

	Abdellah Ghassel, Ian Robinson, Gabriel Tanase, Hal Cooper, Bryan Thompson, Zhen Han, Vassilis N. Ioannidis, Soji Adeshina, Huzefa Rangwala

+ [Worst-Case Symbolic Constraints Analysis and Generalisation with Large Language Models](https://arxiv.org//abs/2506.08171)

	Daniel Koh, Yannic Noller, Corina S. Pasareanu, Adrians Skapars, Youcheng Sun

+ [Repeton: Structured Bug Repair with ReAct-Guided Patch-and-Test Cycles](https://arxiv.org//abs/2506.08173)

	Nguyen Phu Vinh, Anh Chung Hoang, Chris Ngo, Truong-Son Hy

+ [Unable to forget: Proactive lnterference Reveals Working Memory Limits in LLMs Beyond Context Length](https://arxiv.org//abs/2506.08184)

	Chupei Wang (University of Virginia), Jiaqiu Vince Sun (New York University)

+ [A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation](https://arxiv.org//abs/2506.08210)

	Andrew Z. Wang, Songwei Ge, Tero Karras, Ming-Yu Liu, Yogesh Balaji

+ [Ensuring Reliability of Curated EHR-Derived Data: The Validation of Accuracy for LLM/ML-Extracted Information and Data (VALID) Framework](https://arxiv.org//abs/2506.08231)

	Melissa Estevez, Nisha Singh, Lauren Dyson, Blythe Adamson, Qianyu Yuan, Megan W. Hildner, Erin Fidyk, Olive Mbah, Farhad Khan, Kathi Seidl-Rathkopf, Aaron B. Cohen

+ [Can AI Validate Science? Benchmarking LLMs for Accurate Scientific Claim $\rightarrow$ Evidence Reasoning](https://arxiv.org//abs/2506.08235)

	Shashidhar Reddy Javaji, Yupeng Cao, Haohang Li, Yangyang Yu, Nikhil Muralidhar, Zining Zhu

+ [SHIELD: Secure Hypernetworks for Incremental Expansion Learning Defense](https://arxiv.org//abs/2506.08255)

	Patryk Krukowski, Łukasz Gorczyca, Piotr Helm, Kamil Książek, Przemysław Spurek

+ [Reinforcement Learning from Human Feedback with High-Confidence Safety Constraints](https://arxiv.org//abs/2506.08266)

	Yaswanth Chittepu, Blossom Metevier, Will Schwarzer, Austin Hoag, Scott Niekum, Philip S. Thomas

+ [SAFEFLOW: A Principled Protocol for Trustworthy and Transactional Autonomous Agent Systems](https://arxiv.org//abs/2506.07564)

	Peiran Li, Xinkai Zou, Zhuohang Wu, Ruifeng Li, Shuo Xing, Hanwen Zheng, Zhikai Hu, Yuping Wang, Haoxi Li, Qin Yuan, Yingmo Zhang, Zhengzhong Tu

+ [Guideline Forest: Experience-Induced Multi-Guideline Reasoning with Stepwise Aggregation](https://arxiv.org//abs/2506.07820)

	Jiaxiang Chen, Zhuo Wang, Mingxi Zou, Qifan Wang, Zenglin Xu

+ [Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction](https://arxiv.org//abs/2506.07976)

	Junhong Shen, Hao Bai, Lunjun Zhang, Yifei Zhou, Amrith Setlur, Shengbang Tong, Diego Caples, Nan Jiang, Tong Zhang, Ameet Talwalkar, Aviral Kumar

+ [Conservative Bias in Large Language Models: Measuring Relation Predictions](https://arxiv.org//abs/2506.08120)

	Toyin Aguda, Erik Wilson, Allan Anzagira, Simerjot Kaur, Charese Smiley

+ [QA-LIGN: Aligning LLMs through Constitutionally Decomposed QA](https://arxiv.org//abs/2506.08123)

	Jacob Dineen (1), Aswin RRV (1), Qin Liu (2), Zhikun Xu (1), Xiao Ye (1), Ming Shen (1), Zhaonan Li (1), Shijie Lu (1), Chitta Baral (1), Muhao Chen (2), Ben Zhou (1) ((1) Arizona State University, (2) University of California Davis)

+ [EconWebArena: Benchmarking Autonomous Agents on Economic Tasks in Realistic Web Environments](https://arxiv.org//abs/2506.08136)

	Zefang Liu, Yinzhu Quan

+ [LLM-BT: Back-Translation as a Framework for Terminology Standardization and Dynamic Semantic Embedding](https://arxiv.org//abs/2506.08174)

	Li Weigang, Pedro Carvalho Brom

+ ["I Wrote, I Paused, I Rewrote" Teaching LLMs to Read Between the Lines of Student Writing](https://arxiv.org//abs/2506.08221)

	Samra Zafar, Shaheer Minhas, Syed Ali Hassan Zaidi, Arfa Naeem, Zahra Ali

+ [Bingo: Boosting Efficient Reasoning of LLMs via Dynamic and Significance-based Reinforcement Learning](https://arxiv.org//abs/2506.08125)

	Hanbing Liu, Lang Cao, Yuanyi Ren, Mengyu Zhou, Haoyu Dong, Xiaojun Ma, Shi Han, Dongmei Zhang

+ [GradEscape: A Gradient-Based Evader Against AI-Generated Text Detectors](https://arxiv.org//abs/2506.08188)

	Wenlong Meng, Shuguo Fan, Chengkun Wei, Min Chen, Yuwei Li, Yuanchao Zhang, Zhikun Zhang, Wenzhi Chen

+ [From Debate to Equilibrium: Belief-Driven Multi-Agent LLM Reasoning via Bayesian Nash Equilibrium](https://arxiv.org//abs/2506.08292)

	Xie Yi, Zhanke Zhou, Chentao Cao, Qiyu Niu, Tongliang Liu, Bo Han

+ [From Passive to Active Reasoning: Can Large Language Models Ask the Right Questions under Incomplete Information?](https://arxiv.org//abs/2506.08295)

	Zhanke Zhou, Xiao Feng, Zhaocheng Zhu, Jiangchao Yao, Sanmi Koyejo, Bo Han

+ [ARGUS: Hallucination and Omission Evaluation in Video-LLMs](https://arxiv.org//abs/2506.07371)

	Ruchit Rawal, Reza Shirkavand, Heng Huang, Gowthami Somepalli, Tom Goldstein

+ [BLUR: A Bi-Level Optimization Approach for LLM Unlearning](https://arxiv.org//abs/2506.08164)

	Hadi Reisizadeh, Jinghan Jia, Zhiqi Bu, Bhanukiran Vinzamuri, Anil Ramakrishna, Kai-Wei Chang, Volkan Cevher, Sijia Liu, Mingyi Hong

+ [Temporalizing Confidence: Evaluation of Chain-of-Thought Reasoning with Signal Temporal Logic](https://arxiv.org//abs/2506.08243)

	Zhenjiang Mao, Artem Bisliouk, Rohith Reddy Nama, Ivan Ruchkin

+ [LEANN: A Low-Storage Vector Index](https://arxiv.org//abs/2506.08276)

	Yichuan Wang, Shu Liu, Zhifei Li, Yongji Wu, Ziming Mao, Yilong Zhao, Xiao Yan, Zhiying Xu, Yang Zhou, Ion Stoica, Sewon Min, Matei Zaharia, Joseph E. Gonzalez

+ [RSafe: Incentivizing proactive reasoning to build robust and adaptive LLM safeguards](https://arxiv.org//abs/2506.07736)

	Jingnan Zheng, Xiangtian Ji, Yijun Lu, Chenhang Cui, Weixiang Zhao, Gelei Deng, Zhenkai Liang, An Zhang, Tat-Seng Chua

+ [MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models](https://arxiv.org//abs/2506.07400)

	Philip R. Liu, Sparsh Bansal, Jimmy Dinh, Aditya Pawar, Ramani Satishkumar, Shail Desai, Neeraj Gupta, Xin Wang, Shu Hu

+ [AbstRaL: Augmenting LLMs' Reasoning by Reinforcing Abstract Thinking](https://arxiv.org//abs/2506.07751)

	Silin Gao, Antoine Bosselut, Samy Bengio, Emmanuel Abbe

+ [LLMs Caught in the Crossfire: Malware Requests and Jailbreak Challenges](https://arxiv.org//abs/2506.10022)

	Haoyang Li, Huan Gao, Zhiyuan Zhao, Zhiyu Lin, Junyu Gao, Xuelong Li

+ [Private Memorization Editing: Turning Memorization into a Defense to Strengthen Data Privacy in Large Language Models](https://arxiv.org//abs/2506.10024)

	Elena Sofia Ruzzetti, Giancarlo A. Xompero, Davide Venditti, Fabio Massimo Zanzotto

+ [Reinforcing Multimodal Understanding and Generation with Dual Self-rewards](https://arxiv.org//abs/2506.07963)

	Jixiang Hong, Yiran Zhang, Guanzhong Wang, Yi Liu, Ji-Rong Wen, Rui Yan

+ [CheMatAgent: Enhancing LLMs for Chemistry and Materials Science through Tree-Search Based Tool Learning](https://arxiv.org//abs/2506.07551)

	Mengsong Wu, YaFei Wang, Yidong Ming, Yuqi An, Yuwei Wan, Wenliang Chen, Binbin Lin, Yuqiang Li, Tong Xie, Dongzhan Zhou

+ [Towards Large Language Models with Self-Consistent Natural Language Explanations](https://arxiv.org//abs/2506.07523)

	Sahar Admoni, Ofra Amir, Assaf Hallak, Yftah Ziser

+ [Play to Generalize: Learning to Reason Through Game Play](https://arxiv.org//abs/2506.08011)

	Yunfei Xie, Yinsong Ma, Shiyi Lan, Alan Yuille, Junfei Xiao, Chen Wei

+ [Infinity Instruct: Scaling Instruction Selection and Synthesis to Enhance Language Models](https://arxiv.org//abs/2506.11116)

	Jijie Li, Li Du, Hanyu Zhao, Bo-wen Zhang, Liangdong Wang, Boyan Gao, Guang Liu, Yonghua Lin

+ [ScIRGen: Synthesize Realistic and Large-Scale RAG Dataset for Scientific Research](https://arxiv.org//abs/2506.11117)

	Junyong Lin, Lu Dai, Ruiqian Han, Yijie Sui, Ruilin Wang, Xingliang Sun, Qinglin Wu, Min Feng, Hao Liu, Hui Xiong

+ [Improving Large Language Models with Concept-Aware Fine-Tuning](https://arxiv.org//abs/2506.07833)

	Michael K. Chen, Xikun Zhang, Jiaxing Huang, Dacheng Tao

+ [Reparameterized LLM Training via Orthogonal Equivalence Transformation](https://arxiv.org//abs/2506.08001)

	Zeju Qiu, Simon Buchholz, Tim Z. Xiao, Maximilian Dax, Bernhard Schölkopf, Weiyang Liu

+ [A Hybrid GA LLM Framework for Structured Task Optimization](https://arxiv.org//abs/2506.07483)

	William Shum, Rachel Chan, Jonas Lin, Benny Feng, Patrick Lau

+ [G-Memory: Tracing Hierarchical Memory for Multi-Agent Systems](https://arxiv.org//abs/2506.07398)

	Guibin Zhang, Muxin Fu, Guancheng Wan, Miao Yu, Kun Wang, Shuicheng Yan

# 2025-06-08
+ [Auditing Black-Box LLM APIs with a Rank-Based Uniformity Test](https://arxiv.org//abs/2506.06975)

	Xiaoyuan Zhu, Yaowen Ye, Tianyi Qiu, Hanlin Zhu, Sijun Tan, Ajraf Mannan, Jonathan Michala, Raluca Ada Popa, Willie Neiswanger

+ [Enhancing the Safety of Medical Vision-Language Models by Synthetic Demonstrations](https://arxiv.org//abs/2506.09067)

	Zhiyu Xue, Reza Abbasi-Asl, Ramtin Pedarsani

+ [Pre-trained Large Language Models Learn Hidden Markov Models In-context](https://arxiv.org//abs/2506.07298)

	Yijia Dai, Zhaolin Gao, Yahya Sattar, Sarah Dean, Jennifer J. Sun

+ [From Tool Calling to Symbolic Thinking: LLMs in a Persistent Lisp Metaprogramming Loop](https://arxiv.org//abs/2506.10021)

	Jordi de la Torre

+ [Chain-of-Code Collapse: Reasoning Failures in LLMs via Adversarial Prompting in Code Generation](https://arxiv.org//abs/2506.06971)

	Jaechul Roh, Varun Gandhi, Shivani Anilkumar, Arin Garg

+ [Enhancing Large Language Models for Mobility Analytics with Semantic Location Tokenization](https://arxiv.org//abs/2506.11109)

	Yile Chen, Yicheng Tao, Yue Jiang, Shuai Liu, Han Yu, Gao Cong

+ [AssertBench: A Benchmark for Evaluating Self-Assertion in Large Language Models](https://arxiv.org//abs/2506.11110)

	Jaeho Lee, Atharv Chowdhary

+ [Evaluating and Improving Robustness in Large Language Models: A Survey and Future Directions](https://arxiv.org//abs/2506.11111)

	Kun Zhang, Le Wu, Kui Yu, Guangyi Lv, Dacao Zhang

+ [Breaking the Reviewer: Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks](https://arxiv.org//abs/2506.11113)

	Tzu-Ling Lin, Wei-Chih Chen, Teng-Fang Hsiao, Hou-I Liu, Ya-Hsin Yeh, Yu Kai Chan, Wen-Sheng Lien, Po-Yen Kuo, Philip S. Yu, Hong-Han Shuai

+ [History-Aware Cross-Attention Reinforcement: Self-Supervised Multi Turn and Chain-of-Thought Fine-Tuning with vLLM](https://arxiv.org//abs/2506.11108)

	Andrew Kiruluta, Andreas Lemos, Priscilla Burity

+ [Reasoning with RAGged events: RAG-Enhanced Event Knowledge Base Construction and reasoning with proof-assistants](https://arxiv.org//abs/2506.07042)

	Stergios Chatzikyriakidis

# 2025-06-07
+ [Can LLMs Generate Reliable Test Case Generators? A Study on Competition-Level Programming Problems](https://arxiv.org//abs/2506.06821)

	Yuhan Cao, Zian Chen, Kun Quan, Ziliang Zhang, Yu Wang, Xiaoning Dong, Yeqi Feng, Guanzhong He, Jingcheng Huang, Jianhao Li, Yixuan Tan, Jiafu Tang, Yilin Tang, Junlei Wu, Qianyu Xiao, Can Zheng, Shouchen Zhou, Yuxiang Zhu, Yiming Huang, Tian Xie, Tianxing He

+ [From Threat to Tool: Leveraging Refusal-Aware Injection Attacks for Safety Alignment](https://arxiv.org//abs/2506.10020)

	Kyubyung Chae, Hyunbin Jin, Taesup Kim

+ [QuantMCP: Grounding Large Language Models in Verifiable Financial Reality](https://arxiv.org//abs/2506.06622)

	Yifan Zeng

+ [Enabling On-Device Medical AI Assistants via Input-Driven Saliency Adaptation](https://arxiv.org//abs/2506.11105)

	Uttej Kallakurik, Edward Humes, Rithvik Jonna, Xiaomin Lin, Tinoosh Mohsenin

+ [Graph-based RAG Enhancement via Global Query Disambiguation and Dependency-Aware Reranking](https://arxiv.org//abs/2506.11106)

	Ningyuan Li, Junrui Liu, Yi Shan, Minghui Huang, Tong Li

+ [RARL: Improving Medical VLM Reasoning and Generalization with Reinforcement Learning and LoRA under Data and Hardware Constraints](https://arxiv.org//abs/2506.06600)

	Tan-Hanh Pham, Chris Ngo

# 2025-06-06
+ [Topology of Reasoning: Understanding Large Reasoning Models through Reasoning Graph Properties](https://arxiv.org//abs/2506.05744)

	Gouki Minegishi, Hiroki Furuta, Takeshi Kojima, Yusuke Iwasawa, Yutaka Matsuo

+ [SPRINT: Enabling Interleaved Planning and Parallelized Execution in Reasoning Models](https://arxiv.org//abs/2506.05745)

	Emil Biju, Shayan Talaei, Zhemin Huang, Mohammadreza Pourreza, Azalia Mirhoseini, Amin Saberi

+ [Constrained Sampling for Language Models Should Be Easy: An MCMC Perspective](https://arxiv.org//abs/2506.05754)

	Emmanuel Anaya Gonzalez, Sairam Vaidya, Kanghee Park, Ruyi Ji, Taylor Berg-Kirkpatrick, Loris D'Antoni

+ [Explainability in Context: A Multilevel Framework Aligning AI Explanations with Stakeholder with LLMs](https://arxiv.org//abs/2506.05887)

	Marilyn Bello, Rafael Bello, Maria-Matilde García, Ann Nowé, Iván Sevillano-García, Francisco Herrera

+ [Preference Learning for AI Alignment: a Causal Perspective](https://arxiv.org//abs/2506.05967)

	Katarzyna Kobalczyk, Mihaela van der Schaar

+ [CrimeMind: Simulating Urban Crime with Multi-Modal LLM Agents](https://arxiv.org//abs/2506.05981)

	Qingbin Zeng, Ruotong Zhao, Jinzhu Mao, Haoyang Li, Fengli Xu, Yong Li

+ [CP-Bench: Evaluating Large Language Models for Constraint Modelling](https://arxiv.org//abs/2506.06052)

	Kostis Michailidis, Dimos Tsouros, Tias Guns

+ [PersonaAgent: When Large Language Model Agents Meet Personalization at Test Time](https://arxiv.org//abs/2506.06254)

	Weizhi Zhang, Xinyang Zhang, Chenwei Zhang, Liangwei Yang, Jingbo Shang, Zhepei Wei, Henry Peng Zou, Zijie Huang, Zhengyang Wang, Yifan Gao, Xiaoman Pan, Lian Xiong, Jingguo Liu, Philip S. Yu, Xian Li

+ [SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code](https://arxiv.org//abs/2506.05692)

	Xinghang Li, Jingzhe Ding, Chao Peng, Bing Zhao, Xiang Gao, Hongwan Gao, Xinchen Gu

+ [RKEFino1: A Regulation Knowledge-Enhanced Large Language Model](https://arxiv.org//abs/2506.05700)

	Yan Wang, Yueru He, Ruoyu Xiang, Jeff Zhao

+ [Large Language Models are Good Relational Learners](https://arxiv.org//abs/2506.05725)

	Fang Wu, Vijay Prakash Dwivedi, Jure Leskovec

+ [To Protect the LLM Agent Against the Prompt Injection Attack with Polymorphic Prompt](https://arxiv.org//abs/2506.05739)

	Zhilong Wang, Neha Nagaraja, Lan Zhang, Hayretdin Bahsi, Pawan Patil, Peng Liu

+ [Efficient Online RFT with Plug-and-Play LLM Judges: Unlocking State-of-the-Art Performance](https://arxiv.org//abs/2506.05748)

	Rudransh Agnihotri, Ananya Pandey

+ [dots.llm1 Technical Report](https://arxiv.org//abs/2506.05767)

	Bi Huo, Bin Tu, Cheng Qin, Da Zheng, Debing Zhang, Dongjie Zhang, En Li, Fu Guo, Jian Yao, Jie Lou, Junfeng Tian, Li Hu, Ran Zhu, Shengdong Chen, Shuo Liu, Su Guang, Te Wo, Weijun Zhang, Xiaoming Shi, Xinxin Peng, Xing Wu, Yawen Liu, Yuqiu Ji, Ze Wen, Zhenhai Liu, Zichao Li, Zilong Liao

+ [Cross-lingual Collapse: How Language-Centric Foundation Models Shape Reasoning in Large Language Models](https://arxiv.org//abs/2506.05850)

	Cheonbok Park, Jeonghoon Kim, Joosung Lee, Sanghwan Bae, Jaegul Choo, Kangmin Yoo

+ [Route-and-Reason: Scaling Large Language Model Reasoning with Reinforced Model Router](https://arxiv.org//abs/2506.05901)

	Chenyang Shao, Xinyang Liu, Yutang Lin, Fengli Xu, Yong Li

+ [Small Models, Big Support: A Local LLM Framework for Teacher-Centric Content Creation and Assessment using RAG and CAG](https://arxiv.org//abs/2506.05925)

	Zarreen Reza, Alexander Mazur, Michael T. Dugdale, Robin Ray-Chaudhuri

+ [MoA: Heterogeneous Mixture of Adapters for Parameter-Efficient Fine-Tuning of Large Language Models](https://arxiv.org//abs/2506.05928)

	Jie Cao, Tianwei Lin, Hongyang He, Rolan Yan, Wenqiao Zhang, Juncheng Li, Dongping Zhang, Siliang Tang, Yueting Zhuang

+ [DynamicMind: A Tri-Mode Thinking System for Large Language Models](https://arxiv.org//abs/2506.05936)

	Wei Li, Yanbin Wei, Qiushi Huang, Jiangyue Yan, Yang Chen, James T. Kwok, Yu Zhang

+ [IntentionESC: An Intention-Centered Framework for Enhancing Emotional Support in Dialogue Systems](https://arxiv.org//abs/2506.05947)

	Xinjie Zhang, Wenxuan Wang, Qin Jin

+ [Let's Put Ourselves in Sally's Shoes: Shoes-of-Others Prefixing Improves Theory of Mind in Large Language Models](https://arxiv.org//abs/2506.05970)

	Kazutoshi Shinoda, Nobukatsu Hojo, Kyosuke Nishida, Yoshihiro Yamazaki, Keita Suzuki, Hiroaki Sugiyama, Kuniko Saito

+ [Token Signature: Predicting Chain-of-Thought Gains with Token Decoding Feature in Large Language Models](https://arxiv.org//abs/2506.06008)

	Peijie Liu, Fengli Xu, Yong Li

+ [Unlocking Recursive Thinking of LLMs: Alignment via Refinement](https://arxiv.org//abs/2506.06009)

	Haoke Zhang, Xiaobo Liang, Cunxiang Wang, Juntao Li, Min Zhang

+ [When to Trust Context: Self-Reflective Debates for Context Reliability](https://arxiv.org//abs/2506.06020)

	Zeqi Zhou, Fang Wu, Shayan Talaei, Haokai Zhao, Cheng Meixin, Tinson Xu, Amin Saberi, Yejin Choi

+ [Hey, That's My Data! Label-Only Dataset Inference in Large Language Models](https://arxiv.org//abs/2506.06057)

	Chen Xiong, Zihao Wang, Rui Zhu, Tsung-Yi Ho, Pin-Yu Chen, Jingwei Xiong, Haixu Tang, Lucila Ohno-Machado

+ [Simple Yet Effective: Extracting Private Data Across Clients in Federated Fine-Tuning of Large Language Models](https://arxiv.org//abs/2506.06060)

	Yingqi Hu, Zhuo Zhang, Jingyuan Zhang, Lizhen Qu, Zenglin Xu

+ [Text-to-LoRA: Instant Transformer Adaption](https://arxiv.org//abs/2506.06105)

	Rujikorn Charakorn, Edoardo Cetin, Yujin Tang, Robert Tjarko Lange

+ [Towards Lifecycle Unlearning Commitment Management: Measuring Sample-level Unlearning Completeness](https://arxiv.org//abs/2506.06112)

	Cheng-Long Wang, Qi Li, Zihang Xiang, Yinzhi Cao, Di Wang

+ [Joint-GCG: Unified Gradient-Based Poisoning Attacks on Retrieval-Augmented Generation Systems](https://arxiv.org//abs/2506.06151)

	Haowei Wang, Rupeng Zhang, Junjie Wang, Mingyang Li, Yuekai Huang, Dandan Wang, Qing Wang

+ [The Lock-in Hypothesis: Stagnation by Algorithm](https://arxiv.org//abs/2506.06166)

	Tianyi Alex Qiu, Zhonghao He, Tejasveer Chugh, Max Kleiman-Weiner

+ [Building Models of Neurological Language](https://arxiv.org//abs/2506.06208)

	Henry Watkins

+ [Can Theoretical Physics Research Benefit from Language Agents?](https://arxiv.org//abs/2506.06214)

	Sirui Lu, Zhijing Jin, Terry Jingchen Zhang, Pavel Kos, J. Ignacio Cirac, Bernhard Schölkopf

+ [Cartridges: Lightweight and general-purpose long context representations via self-study](https://arxiv.org//abs/2506.06266)

	Sabri Eyuboglu, Ryan Ehrlich, Simran Arora, Neel Guha, Dylan Zinsley, Emily Liu, Will Tennien, Atri Rudra, James Zou, Azalia Mirhoseini, Christopher Re

+ [Distillation Robustifies Unlearning](https://arxiv.org//abs/2506.06278)

	Bruce W. Lee, Addie Foote, Alex Infanger, Leni Shor, Harish Kamath, Jacob Goldman-Wetzler, Bryce Woodworth, Alex Cloud, Alexander Matt Turner

+ [Eigenspectrum Analysis of Neural Networks without Aspect Ratio Bias](https://arxiv.org//abs/2506.06280)

	Yuanzhe Hu, Kinshuk Goel, Vlad Killiakov, Yaoqing Yang

+ [Can LLMs Express Personality Across Cultures? Introducing CulturalPersonas for Evaluating Trait Alignment](https://arxiv.org//abs/2506.05670)

	Priyanka Dey, Yugal Khanter, Aayush Bothra, Jieyu Zhao, Emilio Ferrara

+ [Zero-Shot Event Causality Identification via Multi-source Evidence Fuzzy Aggregation with Large Language Models](https://arxiv.org//abs/2506.05675)

	Zefan Zeng, Xingchen Hu, Qing Cheng, Weiping Ding, Wentao Li, Zhong Liu

+ [When to use Graphs in RAG: A Comprehensive Analysis for Graph Retrieval-Augmented Generation](https://arxiv.org//abs/2506.05690)

	Zhishang Xiang, Chuanjie Wu, Qinggang Zhang, Shengyuan Chen, Zijin Hong, Xiao Huang, Jinsong Su

+ [Being Strong Progressively! Enhancing Knowledge Distillation of Large Language Models through a Curriculum Learning Framework](https://arxiv.org//abs/2506.05695)

	Lingyuan Liu, Mengxiang Zhang

+ [Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation and Confidence Awareness](https://arxiv.org//abs/2506.05735)

	Rongzhe Wei, Peizhi Niu, Hans Hao-Hsun Hsu, Ruihan Wu, Haoteng Yin, Mohsen Ghassemi, Yifan Li, Vamsi K. Potluru, Eli Chien, Kamalika Chaudhuri, Olgica Milenkovic, Pan Li

+ [LLM-Symbolic Integration for Robust Temporal Tabular Reasoning](https://arxiv.org//abs/2506.05746)

	Atharv Kulkarni, Kushagra Dixit, Vivek Srikumar, Dan Roth, Vivek Gupta

+ [Writing-RL: Advancing Long-form Writing via Adaptive Curriculum Reinforcement Learning](https://arxiv.org//abs/2506.05760)

	Xuanyu Lei, Chenliang Li, Yuning Wu, Kaiming Liu, Weizhou Shen, Peng Li, Ming Yan, Ji Zhang, Fei Huang, Yang Liu

+ [BioMol-MQA: A Multi-Modal Question Answering Dataset For LLM Reasoning Over Bio-Molecular Interactions](https://arxiv.org//abs/2506.05766)

	Saptarshi Sengupta, Shuhua Yang, Paul Kwong Yu, Fali Wang, Suhang Wang

+ [Discrete Minds in a Continuous World: Do Language Models Know Time Passes?](https://arxiv.org//abs/2506.05790)

	Minghan Wang, Ye Bai, Thuy-Trang Vu, Ehsan Shareghi, Gholamreza Haffari

+ [MAPLE: Multi-Agent Adaptive Planning with Long-Term Memory for Table Reasoning](https://arxiv.org//abs/2506.05813)

	Ye Bai, Minghan Wang, Thuy-Trang Vu

+ [Generating Grounded Responses to Counter Misinformation via Learning Efficient Fine-Grained Critiques](https://arxiv.org//abs/2506.05924)

	Xiaofei Xu, Xiuzhen Zhang, Ke Deng

+ [AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search](https://arxiv.org//abs/2506.06017)

	Yu Li, Lehui Li, Zhihao Wu, Qingmin Liao, Jianye Hao, Kun Shao, Fengli Xu, Yong Li

+ [Large Language Models are Demonstration Pre-Selectors for Themselves](https://arxiv.org//abs/2506.06033)

	Jiarui Jin, Yuwei Wu, Haoxuan Li, Xiaoting He, Weinan Zhang, Yiming Yang, Yong Yu, Jun Wang, Mengyue Yang

+ [MATP-BENCH: Can MLLM Be a Good Automated Theorem Prover for Multimodal Problems?](https://arxiv.org//abs/2506.06034)

	Zhitao He, Zongwei Lyu, Dazhong Chen, Dadi Guo, Yi R. Fung

+ [Zero-Shot Detection of LLM-Generated Code via Approximated Task Conditioning](https://arxiv.org//abs/2506.06069)

	Maor Ashkenazi, Ofir Brenner, Tal Furman Shohet, Eran Treister

+ [MIRIAD: Augmenting LLMs with millions of medical query-response pairs](https://arxiv.org//abs/2506.06091)

	Qinyue Zheng, Salman Abdullah, Sam Rawal, Cyril Zakka, Sophie Ostmeier, Maximilian Purk, Eduardo Reis, Eric J. Topol, Jure Leskovec, Michael Moor

+ [Reinforcing Code Generation: Improving Text-to-SQL with Execution-Based Learning](https://arxiv.org//abs/2506.06093)

	Atharv Kulkarni, Vivek Srikumar

+ [Bridging the Gap: In-Context Learning for Modeling Human Disagreement](https://arxiv.org//abs/2506.06113)

	Benedetta Muscato, Yue Li, Gizem Gezici, Zhixue Zhao, Fosca Giannotti

+ [Let's CONFER: A Dataset for Evaluating Natural Language Inference Models on CONditional InFERence and Presupposition](https://arxiv.org//abs/2506.06133)

	Tara Azin, Daniel Dumitrescu, Diana Inkpen, Raj Singh

+ [Does It Run and Is That Enough? Revisiting Text-to-Chart Generation with a Multi-Agent Approach](https://arxiv.org//abs/2506.06175)

	James Ford, Anthony Rios

+ [Bridging External and Parametric Knowledge: Mitigating Hallucination of LLMs with Shared-Private Semantic Synergy in Dual-Stream Knowledge](https://arxiv.org//abs/2506.06240)

	Yi Sui, Chaozhuo Li, Chen Zhang, Dawei song, Qiuchi Li

+ [AdvSumm: Adversarial Training for Bias Mitigation in Text Summarization](https://arxiv.org//abs/2506.06273)

	Mukur Gupta, Nikhil Reddy Varimalla, Nicholas Deas, Melanie Subbiah, Kathleen McKeown

+ [Projectable Models: One-Shot Generation of Small Specialized Transformers from Large Ones](https://arxiv.org//abs/2506.05641)

	Andrey Zhmoginov, Jihwan Lee, Mark Sandler

+ [BAQ: Efficient Bit Allocation Quantization for Large Language Models](https://arxiv.org//abs/2506.05664)

	Chao Zhang, Li Wang, Samson Lasaulce, Merouane Debbah

+ [Low-Resource Domain Adaptation for Speech LLMs via Text-Only Fine-Tuning](https://arxiv.org//abs/2506.05671)

	Yangui Fang, Jing Peng, Xu Li, Yu Xi, Chengwei Zhang, Guohui Zhong, Kai Yu

+ [Contextually Guided Transformers via Low-Rank Adaptation](https://arxiv.org//abs/2506.05672)

	Andrey Zhmoginov, Jihwan Lee, Max Vladymyrov, Mark Sandler

+ [CodeContests+: High-Quality Test Case Generation for Competitive Programming](https://arxiv.org//abs/2506.05817)

	Zihan Wang, Siyao Liu, Yang Sun, Hongyan Li, Kai Shen

+ [Corrector Sampling in Language Models](https://arxiv.org//abs/2506.06215)

	Itai Gat, Neta Shaul, Uriel Singer, Yaron Lipman

+ [Pts3D-LLM: Studying the Impact of Token Structure for 3D Scene Understanding With Large Language Models](https://arxiv.org//abs/2506.05689)

	Hugues Thomas, Chen Chen, Jian Zhang

+ [Learning to Weight Parameters for Data Attribution](https://arxiv.org//abs/2506.05647)

	Shuangqi Li, Hieu Le, Jingyi Xu, Mathieu Salzmann

+ [EdgeProfiler: A Fast Profiling Framework for Lightweight LLMs on Edge Using Analytical Model](https://arxiv.org//abs/2506.09061)

	Alyssa Pinnock, Shakya Jayakody, Kawsher A Roxy, Md Rubel Ahmed

+ [The Scales of Justitia: A Comprehensive Survey on Safety Evaluation of LLMs](https://arxiv.org//abs/2506.11094)

	Songyang Liu, Chaozhuo Li, Jiameng Qiu, Xi Zhang, Feiran Huang, Litian Zhang, Yiming Hei, Philip S. Yu

+ [Debiasing Online Preference Learning via Preference Feature Preservation](https://arxiv.org//abs/2506.11098)

	Dongyoung Kim, Jinsung Yoon, Jinwoo Shin, Jaehyung Kim

+ [Evolutionary Perspectives on the Evaluation of LLM-Based AI Agents: A Comprehensive Survey](https://arxiv.org//abs/2506.11102)

	Jiachen Zhu, Menghui Zhu, Renting Rui, Rong Shan, Congmin Zheng, Bo Chen, Yunjia Xi, Jianghao Lin, Weiwen Liu, Ruiming Tang, Yong Yu, Weinan Zhang

+ [You Only Fine-tune Once: Many-Shot In-Context Fine-Tuning for Large Language Model](https://arxiv.org//abs/2506.11103)

	Wenchong He, Liqian Peng, Zhe Jiang, Alex Go

+ [DAM: Dynamic Attention Mask for Long-Context Large Language Model Inference Acceleration](https://arxiv.org//abs/2506.11104)

	Hanzhi Zhang, Heng Fan, Kewei Sha, Yan Huang, Yunhe Feng

# 2025-06-05
+ [CHANCERY: Evaluating corporate governance reasoning capabilities in language models](https://arxiv.org//abs/2506.04636)

	Lucas Irwin, Arda Kaz, Peiyao Sheng, Pramod Viswanath

+ [Agents of Change: Self-Evolving LLM Agents for Strategic Planning](https://arxiv.org//abs/2506.04651)

	Nikolas Belle, Dakota Barnes, Alfonso Amayuelas, Ivan Bercovich, Xin Eric Wang, William Wang

+ [Empowering Economic Simulation for Massively Multiplayer Online Games through Generative Agent-Based Modeling](https://arxiv.org//abs/2506.04699)

	Bihan Xu, Shiwei Zhao, Runze Wu, Zhenya Huang, Jiawei Wang, Zhipeng Hu, Kai Wang, Haoyu Liu, Tangjie Lv, Le Li, Changjie Fan, Xin Tong, Jiangze Han

+ [Beyond Accuracy: Dissecting Mathematical Reasoning for LLMs Under Reinforcement Learning](https://arxiv.org//abs/2506.04723)

	Jiayu Wang, Yifei Ming, Zixuan Ke, Caiming Xiong, Shafiq Joty, Aws Albarghouthi, Frederic Sala

+ [Evaluation is All You Need: Strategic Overclaiming of LLM Reasoning Capabilities Through Evaluation Design](https://arxiv.org//abs/2506.04734)

	Lin Sun, Weihong Lin, Jinzhu Wu, Yongfu Zhu, Xiaoqi Jian, Guangxiang Zhao, Change Jia, Linglin Zhang, Sai-er Hu, Yuhan Wu, Xiangzheng Zhang

+ [LLMs for sensory-motor control: Combining in-context and iterative learning](https://arxiv.org//abs/2506.04867)

	Jônata Tyska Carvalho, Stefano Nolfi

+ [When Thinking LLMs Lie: Unveiling the Strategic Deception in Representations of Reasoning Models](https://arxiv.org//abs/2506.04909)

	Kai Wang, Yihao Zhang, Meng Sun

+ [Mathematical Reasoning for Unmanned Aerial Vehicles: A RAG-Based Approach for Complex Arithmetic Reasoning](https://arxiv.org//abs/2506.04998)

	Mehdi Azarafza, Mojtaba Nayyeri, Faezeh Pasandideh, Steffen Staab, Achim Rettberg

+ [Truly Self-Improving Agents Require Intrinsic Metacognitive Learning](https://arxiv.org//abs/2506.05109)

	Tennison Liu, Mihaela van der Schaar

+ [LLM-First Search: Self-Guided Exploration of the Solution Space](https://arxiv.org//abs/2506.05213)

	Nathan Herr, Tim Rocktäschel, Roberta Raileanu

+ [Just Enough Thinking: Efficient Reasoning with Adaptive Length Penalties Reinforcement Learning](https://arxiv.org//abs/2506.05256)

	Violet Xiang, Chase Blagden, Rafael Rafailov, Nathan Lile, Sang Truong, Chelsea Finn, Nick Haber

+ [Control Tax: The Price of Keeping AI in Check](https://arxiv.org//abs/2506.05296)

	Mikhail Terekhov, Zhen Ning David Liu, Caglar Gulcehre, Samuel Albanie

+ [BESA: Boosting Encoder Stealing Attack with Perturbation Recovery](https://arxiv.org//abs/2506.04556)

	Xuhao Ren, Haotian Liang, Yajie Wang, Chuan Zhang, Zehui Xiong, Liehuang Zhu

+ [Clustering and Median Aggregation Improve Differentially Private Inference](https://arxiv.org//abs/2506.04566)

	Kareem Amin, Salman Avestimehr, Sara Babakniya, Alex Bie, Weiwei Kong, Natalia Ponomareva, Umar Syed

+ [SUCEA: Reasoning-Intensive Retrieval for Adversarial Fact-checking through Claim Decomposition and Editing](https://arxiv.org//abs/2506.04583)

	Hongjun Liu, Yilun Zhao, Arman Cohan, Chen Zhao

+ [Safe: Enhancing Mathematical Reasoning in Large Language Models via Retrospective Step-aware Formal Verification](https://arxiv.org//abs/2506.04592)

	Chengwu Liu, Ye Yuan, Yichun Yin, Yan Xu, Xin Xu, Zaoyu Chen, Yasheng Wang, Lifeng Shang, Qun Liu, Ming Zhang

+ [Urania: Differentially Private Insights into AI Use](https://arxiv.org//abs/2506.04681)

	Daogao Liu, Edith Cohen, Badih Ghazi, Peter Kairouz, Pritish Kamath, Alexander Knop, Ravi Kumar, Pasin Manurangsi, Adam Sealfon, Da Yu, Chiyuan Zhang

+ [MMRefine: Unveiling the Obstacles to Robust Refinement in Multimodal Large Language Models](https://arxiv.org//abs/2506.04688)

	Gio Paik, Geewook Kim, Jinbae Im

+ [On the Mechanism of Reasoning Pattern Selection in Reinforcement Learning for Language Models](https://arxiv.org//abs/2506.04695)

	Xingwu Chen, Tianle Li, Difan Zou

+ [Line of Sight: On Linear Representations in VLLMs](https://arxiv.org//abs/2506.04706)

	Achyuta Rajaram, Sarah Schwettmann, Jacob Andreas, Arthur Conmy

+ [UNO: Unlearning via Orthogonalization in Generative models](https://arxiv.org//abs/2506.04712)

	Pinak Mandal, Georg A. Gottwald

+ [Lifelong Evolution: Collaborative Learning between Large and Small Language Models for Continuous Emergent Fake News Detection](https://arxiv.org//abs/2506.04739)

	Ziyi Zhou, Xiaoming Zhang, Litian Zhang, Yibo Zhang, Zhenyu Guan, Chaozhuo Li, Philip S. Yu

+ [Truth in the Few: High-Value Data Selection for Efficient Multi-Modal Reasoning](https://arxiv.org//abs/2506.04755)

	Shenshen Li, Kaiyuan Deng, Lei Wang, Hao Yang, Chong Peng, Peng Yan, Fumin Shen, Heng Tao Shen, Xing Xu

+ [Fine-Grained Interpretation of Political Opinions in Large Language Models](https://arxiv.org//abs/2506.04774)

	Jingyu Hu, Mengyue Yang, Mengnan Du, Weiru Liu

+ [Towards LLM-Centric Multimodal Fusion: A Survey on Integration Strategies and Techniques](https://arxiv.org//abs/2506.04788)

	Jisu An, Junseok Lee, Jeoungeun Lee, Yongseok Son

+ [Dissecting Logical Reasoning in LLMs: A Fine-Grained Evaluation and Supervision Study](https://arxiv.org//abs/2506.04810)

	Yujun Zhou, Jiayi Ye, Zipeng Ling, Yufei Han, Yue Huang, Haomin Zhuang, Zhenwen Liang, Kehan Guo, Taicheng Guo, Xiangqi Wang, Xiangliang Zhang

+ [On Automating Security Policies with Contemporary LLMs](https://arxiv.org//abs/2506.04838)

	Pablo Fernández Saura, K. R. Jayaram, Vatche Isahagian, Jorge Bernal Bernabé, Antonio Skarmeta

+ [Verbose ListOps (VLO): Beyond Long Context -- Unmasking LLM's Reasoning Blind Spots](https://arxiv.org//abs/2506.04907)

	Alex Pan, Mary-Anne Williams

+ [Simulating LLM-to-LLM Tutoring for Multilingual Math Feedback](https://arxiv.org//abs/2506.04920)

	Junior Cedric Tonga, KV Aditya Srivatsa, Kaushal Kumar Maurya, Fajri Koto, Ekaterina Kochmar

+ [From Struggle (06-2024) to Mastery (02-2025) LLMs Conquer Advanced Algorithm Exams and Pave the Way for Editorial Generation](https://arxiv.org//abs/2506.04965)

	Adrian Marius Dumitran, Theodor-Pierre Moroianu, Vasile Paul Alexe

+ [A Multi-Dataset Evaluation of Models for Automated Vulnerability Repair](https://arxiv.org//abs/2506.04987)

	Zanis Ali Khan, Aayush Garg, Qiang Tang

+ [Does It Make Sense to Speak of Introspection in Large Language Models?](https://arxiv.org//abs/2506.05068)

	Iulia Comşa, Murray Shanahan

+ [Reason-to-Recommend: Using Interaction-of-Thought Reasoning to Enhance LLM Recommendation](https://arxiv.org//abs/2506.05069)

	Keyu Zhao, Fengli Xu, Yong Li

+ [DiCoRe: Enhancing Zero-shot Event Detection via Divergent-Convergent LLM Reasoning](https://arxiv.org//abs/2506.05128)

	Tanmay Parekh, Kartik Mehta, Ninareh Mehrabi, Kai-Wei Chang, Nanyun Peng

+ [Knowledgeable-r1: Policy Optimization for Knowledge Exploration in Retrieval-Augmented Generation](https://arxiv.org//abs/2506.05154)

	Chenyu Lin, Yilin Wen, Du Su, Fei Sun, Muhan Chen, Chenfu Bao, Zhonghou Lv

+ [Dissecting Bias in LLMs: A Mechanistic Interpretability Perspective](https://arxiv.org//abs/2506.05166)

	Bhavik Chandna, Zubair Bashir, Procheta Sen

+ [ECoRAG: Evidentiality-guided Compression for Long Context RAG](https://arxiv.org//abs/2506.05167)

	Yeonseok Jeong, Jinsu Kim, Dohyeon Lee, Seung-won Hwang

+ [TreeRPO: Tree Relative Policy Optimization](https://arxiv.org//abs/2506.05183)

	Zhicheng Yang, Zhijiang Guo, Yinya Huang, Xiaodan Liang, Yiwei Wang, Jing Tang

+ [Counterfactual reasoning: an analysis of in-context emergence](https://arxiv.org//abs/2506.05188)

	Moritz Miller, Bernhard Schölkopf, Siyuan Guo

+ [MesaNet: Sequence Modeling by Locally Optimal Test-Time Training](https://arxiv.org//abs/2506.05233)

	Johannes von Oswald, Nino Scherrer, Seijin Kobayashi, Luca Versari, Songlin Yang, Maximilian Schlegel, Kaitlin Maile, Yanick Schimpf, Oliver Sieberling, Alexander Meulemans, Rif A. Saurous, Guillaume Lajoie, Charlotte Frenkel, Razvan Pascanu, Blaise Agüera y Arcas, João Sacramento

+ [Teaming in the AI Era: AI-Augmented Frameworks for Forming, Simulating, and Optimizing Human Teams](https://arxiv.org//abs/2506.05265)

	Mohammed Almutairi

+ [Micro-Act: Mitigate Knowledge Conflict in Question Answering via Actionable Self-Reasoning](https://arxiv.org//abs/2506.05278)

	Nan Huo, Jinyang Li, Bowen Qin, Ge Qu, Xiaolong Li, Xiaodong Li, Chenhao Ma, Reynold Cheng

+ [Sample Complexity and Representation Ability of Test-time Scaling Paradigms](https://arxiv.org//abs/2506.05295)

	Baihe Huang, Shanda Li, Tianhao Wu, Yiming Yang, Ameet Talwalkar, Kannan Ramchandran, Michael I. Jordan, Jiantao Jiao

+ [ProRefine: Inference-time Prompt Refinement with Textual Feedback](https://arxiv.org//abs/2506.05305)

	Deepak Pandita, Tharindu Cyril Weerasooriya, Ankit Parag Shah, Christopher M. Homan, Wei Wei

+ [Time to Talk: LLM Agents for Asynchronous Group Communication in Mafia Games](https://arxiv.org//abs/2506.05309)

	Niv Eckhaus, Uri Berger, Gabriel Stanovsky

+ [Constrained Entropic Unlearning: A Primal-Dual Framework for Large Language Models](https://arxiv.org//abs/2506.05314)

	Taha Entesari, Arman Hatami, Rinat Khaziev, Anil Ramakrishna, Mahyar Fazlyab

+ [Improving Data Efficiency for LLM Reinforcement Fine-tuning Through Difficulty-targeted Online Data Selection and Rollout Replay](https://arxiv.org//abs/2506.05316)

	Yifan Sun, Jingyan Shen, Yibin Wang, Tianyu Chen, Zhendong Wang, Mingyuan Zhou, Huan Zhang

+ [Demonstrations of Integrity Attacks in Multi-Agent Systems](https://arxiv.org//abs/2506.04572)

	Can Zheng, Yuhan Cao, Xiaoning Dong, Tianxing He

+ [Are LLMs Reliable Translators of Logical Reasoning Across Lexically Diversified Contexts?](https://arxiv.org//abs/2506.04575)

	Qingchuan Li, Jiatong Li, Zirui Liu, Mingyue Cheng, Yuting Zeng, Qi Liu, Tongxuan Liu

+ [Selecting Demonstrations for Many-Shot In-Context Learning via Gradient Matching](https://arxiv.org//abs/2506.04579)

	Jianfei Zhang, Bei Li, Jun Bai, Rumei Li, Yanmeng Wang, Chenghua Lin, Wenge Rong

+ [Revisiting Test-Time Scaling: A Survey and a Diversity-Aware Method for Efficient Reasoning](https://arxiv.org//abs/2506.04611)

	Ho-Lam Chung, Teng-Yun Hsiao, Hsiao-Ying Huang, Chunerh Cho, Jian-Ren Lin, Zhang Ziwei, Yun-Nung Chen

+ [Advancing Tool-Augmented Large Language Models via Meta-Verification and Reflection Learning](https://arxiv.org//abs/2506.04625)

	Zhiyuan Ma, Jiayu Liu, Xianzhen Luo, Zhenya Huang, Qingfu Zhu, Wanxiang Che

+ [TaDA: Training-free recipe for Decoding with Adaptive KV Cache Compression and Mean-centering](https://arxiv.org//abs/2506.04642)

	Vinay Joshi, Pratik Prabhanjan Brahma, Zicheng Liu, Emad Barsoum

+ [Flex-TravelPlanner: A Benchmark for Flexible Planning with Language Agents](https://arxiv.org//abs/2506.04649)

	Juhyun Oh, Eunsu Kim, Alice Oh

+ [Normative Conflicts and Shallow AI Alignment](https://arxiv.org//abs/2506.04679)

	Raphaël Millière

+ [Accelerated Test-Time Scaling with Model-Free Speculative Sampling](https://arxiv.org//abs/2506.04708)

	Woomin Song, Saket Dingliwal, Sai Muralidhar Jayanthi, Bhavana Ganesh, Jinwoo Shin, Aram Galstyan, Sravan Babu Bodapati

+ [SPARTA ALIGNMENT: Collectively Aligning Multiple Language Models through Combat](https://arxiv.org//abs/2506.04721)

	Yuru Jiang, Wenxuan Ding, Shangbin Feng, Greg Durrett, Yulia Tsvetkov

+ [Joint Evaluation of Answer and Reasoning Consistency for Hallucination Detection in Large Reasoning Models](https://arxiv.org//abs/2506.04832)

	Changyue Wang, Weihang Su, Qingyao Ai, Yiqun Liu

+ [Prompting LLMs: Length Control for Isometric Machine Translation](https://arxiv.org//abs/2506.04855)

	Dávid Javorský, Ondřej Bojar, François Yvon

+ [ICPC-Eval: Probing the Frontiers of LLM Reasoning with Competitive Programming Contests](https://arxiv.org//abs/2506.04894)

	Shiyi Xu, Yiwen Hu, Yingqian Min, Zhipeng Chen, Wayne Xin Zhao, Ji-Rong Wen

+ [SCOP: Evaluating the Comprehension Process of Large Language Models from a Cognitive View](https://arxiv.org//abs/2506.05000)

	Yongjie Xiao, Hongru Liang, Peixin Qin, Yao Zhang, Wenqiang Lei

+ [Controlling Summarization Length Through EOS Token Weighting](https://arxiv.org//abs/2506.05017)

	Zeno Belligoli, Emmanouil Stergiadis, Eran Fainman, Ilya Gusev

+ [Automatic Robustness Stress Testing of LLMs as Mathematical Problem Solvers](https://arxiv.org//abs/2506.05038)

	Yutao Hou, Zeguan Xiao, Fei Yu, Yihan Jiang, Xuetao Wei, Hailiang Huang, Yun Chen, Guanhua Chen

+ [Debatable Intelligence: Benchmarking LLM Judges via Debate Speech Evaluation](https://arxiv.org//abs/2506.05062)

	Noy Sternlicht, Ariel Gera, Roy Bar-Haim, Tom Hope, Noam Slonim

+ [Just a Scratch: Enhancing LLM Capabilities for Self-harm Detection through Intent Differentiation and Emoji Interpretation](https://arxiv.org//abs/2506.05073)

	Soumitra Ghosh, Gopendra Vikram Singh, Shambhavi, Sabarna Choudhury, Asif Ekbal

+ [Do Large Language Models Judge Error Severity Like Humans?](https://arxiv.org//abs/2506.05142)

	Diege Sun, Guanyi Chen, Fan Zhao, Xiaorong Cheng, Tingting He

+ [Qwen3 Embedding: Advancing Text Embedding and Reranking Through Foundation Models](https://arxiv.org//abs/2506.05176)

	Yanzhao Zhang, Mingxin Li, Dingkun Long, Xin Zhang, Huan Lin, Baosong Yang, Pengjun Xie, An Yang, Dayiheng Liu, Junyang Lin, Fei Huang, Jingren Zhou

+ [RELIC: Evaluating Compositional Instruction Following via Language Recognition](https://arxiv.org//abs/2506.05205)

	Jackson Petty, Michael Y. Hu, Wentao Wang, Shauli Ravfogel, William Merrill, Tal Linzen

+ [CLATTER: Comprehensive Entailment Reasoning for Hallucination Detection](https://arxiv.org//abs/2506.05243)

	Ron Eliav, Arie Cattan, Eran Hirsch, Shahaf Bassan, Elias Stengel-Eskin, Mohit Bansal, Ido Dagan

+ [Search Arena: Analyzing Search-Augmented LLMs](https://arxiv.org//abs/2506.05334)

	Mihran Miroyan, Tsung-Han Wu, Logan King, Tianle Li, Jiayi Pan, Xinyan Hu, Wei-Lin Chiang, Anastasios N. Angelopoulos, Trevor Darrell, Narges Norouzi, Joseph E. Gonzalez

+ [Exp4Fuse: A Rank Fusion Framework for Enhanced Sparse Retrieval using Large Language Model-based Query Expansion](https://arxiv.org//abs/2506.04760)

	Lingyuan Liu, Mengxiang Zhang

+ [GOLFer: Smaller LM-Generated Documents Hallucination Filter & Combiner for Query Expansion in Information Retrieval](https://arxiv.org//abs/2506.04762)

	Lingyuan Liu, Mengxiang Zhang

+ [Dissecting Long Reasoning Models: An Empirical Study](https://arxiv.org//abs/2506.04913)

	Yongyu Mu, Jiali Zeng, Bei Li, Xinyan Guan, Fandong Meng, Jie Zhou, Tong Xiao, Jingbo Zhu

+ [Diagonal Batching Unlocks Parallelism in Recurrent Memory Transformers for Long Contexts](https://arxiv.org//abs/2506.05229)

	Danil Sivtsov, Ivan Rodkin, Gleb Kuzmin, Yuri Kuratov, Ivan Oseledets

+ [Kinetics: Rethinking Test-Time Scaling Laws](https://arxiv.org//abs/2506.05333)

	Ranajoy Sadhukhan, Zhuoming Chen, Haizhong Zheng, Yang Zhou, Emma Strubell, Beidi Chen

+ [Inference-Time Hyper-Scaling with KV Cache Compression](https://arxiv.org//abs/2506.05345)

	Adrian Łańcucki, Konrad Staniszewski, Piotr Nawrot, Edoardo M. Ponti

+ [Why LLM Safety Guardrails Collapse After Fine-tuning: A Similarity Analysis Between Alignment and Fine-tuning Datasets](https://arxiv.org//abs/2506.05346)

	Lei Hsiung, Tianyu Pang, Yung-Chen Tang, Linyue Song, Tsung-Yi Ho, Pin-Yu Chen, Yaoqing Yang

+ [SRD: Reinforcement-Learned Semantic Perturbation for Backdoor Defense in VLMs](https://arxiv.org//abs/2506.04743)

	Shuhan Xu, Siyuan Liang, Hongling Zheng, Yong Luo, Aishan Liu, Dacheng Tao

+ [LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table](https://arxiv.org//abs/2506.04790)

	Yusuke Matsui

+ [MokA: Multimodal Low-Rank Adaptation for MLLMs](https://arxiv.org//abs/2506.05191)

	Yake Wei, Yu Miao, Dongzhan Zhou, Di Hu

+ [SparseMM: Head Sparsity Emerges from Visual Concept Responses in MLLMs](https://arxiv.org//abs/2506.05344)

	Jiahui Wang, Zuyan Liu, Yongming Rao, Jiwen Lu

+ [Composing Agents to Minimize Worst-case Risk](https://arxiv.org//abs/2506.04632)

	Guruprerana Shabadi, Rajeev Alur

+ [Inference economics of language models](https://arxiv.org//abs/2506.04645)

	Ege Erdil

+ [Neural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction](https://arxiv.org//abs/2506.04650)

	Zesheng Ye, Chengyi Cai, Ruijiang Dong, Jianzhong Qi, Lei Feng, Pin-Yu Chen, Feng Liu

+ [Multi-Layer GRPO: Enhancing Reasoning and Self-Correction in Large Language Models](https://arxiv.org//abs/2506.04746)

	Fei Ding, Baiqiao Wang, Zijian Zeng, Youwei Wang

+ [LogicPuzzleRL: Cultivating Robust Mathematical Reasoning in LLMs via Reinforcement Learning](https://arxiv.org//abs/2506.04821)

	Zhen Hao Wong, Jingwen Deng, Runming He, Zirong Chen, Qijie You, Hejun Dong, Hao Liang, Chengyu Shen, Bin Cui, Wentao Zhang

+ [Agentic AI for Intent-Based Industrial Automation](https://arxiv.org//abs/2506.04980)

	Marcos Lima Romero, Ricardo Suyama

+ [FPTQuant: Function-Preserving Transforms for LLM Quantization](https://arxiv.org//abs/2506.04985)

	Boris van Breugel, Yelysei Bondarenko, Paul Whatmough, Markus Nagel

+ [Reliably detecting model failures in deployment without labels](https://arxiv.org//abs/2506.05047)

	Viet Nguyen Changjian Shui, Vijay Giri, Siddarth Arya, Amol Verma, Fahad Razak, Rahul G. Krishnan

+ [Transformers Meet In-Context Learning: A Universal Approximation Theory](https://arxiv.org//abs/2506.05200)

	Gen Li, Yuchen Jiao, Yu Huang, Yuting Wei, Yuxin Chen

+ [Power Law Guided Dynamic Sifting for Efficient Attention](https://arxiv.org//abs/2506.05300)

	Nirav Koley, Prajwal Singhania, Abhinav Bhatele

+ [Membership Inference Attacks on Sequence Models](https://arxiv.org//abs/2506.05126)

	Lorenzo Rossi, Michael Aerni, Jie Zhang, Florian Tramèr

+ [PoCGen: Generating Proof-of-Concept Exploits for Vulnerabilities in Npm Packages](https://arxiv.org//abs/2506.04962)

	Deniz Simsek, Aryaz Eghbali, Michael Pradel

+ [SECNEURON: Reliable and Flexible Abuse Control in Local LLMs via Hybrid Neuron Encryption](https://arxiv.org//abs/2506.05242)

	Zhiqiang Wang, Haohua Du, Junyang Wang, Haifeng Sun, Kaiwen Guo, Haikuo Yu, Chao Liu, Xiang-Yang Li

+ [When Models Know More Than They Can Explain: Quantifying Knowledge Transfer in Human-AI Collaboration](https://arxiv.org//abs/2506.05579)

	Quan Shi, Carlos E. Jimenez, Shunyu Yao, Nick Haber, Diyi Yang, Karthik Narasimhan

+ [PCDVQ: Enhancing Vector Quantization for Large Language Models via Polar Coordinate Decoupling](https://arxiv.org//abs/2506.05432)

	Yuxuan Yue, Zukang Xu, Zhihang Yuan, Dawei Yang, Jianglong Wu, Liqiang Nie

+ [Sentinel: SOTA model to protect against prompt injections](https://arxiv.org//abs/2506.05446)

	Dror Ivry, Oran Nahum

+ [Training Dynamics Underlying Language Model Scaling Laws: Loss Deceleration and Zero-Sum Learning](https://arxiv.org//abs/2506.05447)

	Andrei Mircea, Supriyo Chakraborty, Nima Chitsazan, Irina Rish, Ekaterina Lobacheva

+ [Interpretation Meets Safety: A Survey on Interpretation Methods and Tools for Improving LLM Safety](https://arxiv.org//abs/2506.05451)

	Seongmin Lee, Aeree Cho, Grace C. Kim, ShengYun Peng, Mansi Phute, Duen Horng Chau

+ [MLLM-CL: Continual Learning for Multimodal Large Language Models](https://arxiv.org//abs/2506.05453)

	Hongbo Zhao, Fei Zhu, Rundong Wang, Gaofeng Meng, Zhaoxiang Zhang

+ [Conformal Prediction Beyond the Seen: A Missing Mass Perspective for Uncertainty Quantification in Generative Models](https://arxiv.org//abs/2506.05497)

	Sima Noorani, Shayan Kiyani, George Pappas, Hamed Hassani

+ [StealthInk: A Multi-bit and Stealthy Watermark for Large Language Models](https://arxiv.org//abs/2506.05502)

	Ya Jiang, Chuxiong Wu, Massieh Kordi Boroujeny, Brian Mark, Kai Zeng

+ [ScaleRTL: Scaling LLMs with Reasoning Data and Test-Time Compute for Accurate RTL Code Generation](https://arxiv.org//abs/2506.05566)

	Chenhui Deng, Yun-Da Tsai, Guan-Ting Liu, Zhongzhi Yu, Haoxing Ren

+ [Ravan: Multi-Head Low-Rank Adaptation for Federated Fine-Tuning](https://arxiv.org//abs/2506.05568)

	Arian Raje, Baris Askin, Divyansh Jhunjhunwala, Gauri Joshi

+ [Collaborative Learning in Agentic Systems: A Collective AI is Greater Than the Sum of Its Parts](https://arxiv.org//abs/2506.05577)

	Saptarshi Nath, Christos Peridis, Eseoghene Benjamin, Xinran Liu, Soheil Kolouri, Peter Kinnell, Zexin Li, Cong Liu, Shirin Dora, Andrea Soltoggio

+ [SynthesizeMe! Inducing Persona-Guided Prompts for Personalized Reward Models in LLMs](https://arxiv.org//abs/2506.05598)

	Michael J Ryan, Omar Shaikh, Aditri Bhagirath, Daniel Frees, William Held, Diyi Yang

+ [Improving LLMs with a knowledge from databases](https://arxiv.org//abs/2506.05560)

	Petr Máša

+ [UTSA-NLP at ArchEHR-QA 2025: Improving EHR Question Answering via Self-Consistency Prompting](https://arxiv.org//abs/2506.05589)

	Sara Shields-Menard, Zach Reimers, Joshua Gardner, David Perry, Anthony Rios

+ [OPeRA: A Dataset of Observation, Persona, Rationale, and Action for Evaluating LLMs on Human Online Shopping Behavior Simulation](https://arxiv.org//abs/2506.05606)

	Ziyi Wang, Yuxuan Lu, Wenbo Li, Amirali Amini, Bo Sun, Yakov Bart, Weimin Lyu, Jiri Gesi, Tian Wang, Jing Huang, Yu Su, Upol Ehsan, Malihe Alikhani, Toby Jia-Jun Li, Lydia Chilton, Dakuo Wang

+ [Leveraging Self-Attention for Input-Dependent Soft Prompting in LLMs](https://arxiv.org//abs/2506.05629)

	Ananth Muppidi, Abhilash Nandy, Sambaran Bandyopadhyay

+ [IYKYK: Using language models to decode extremist cryptolects](https://arxiv.org//abs/2506.05635)

	Christine de Kock, Arij Riabi, Zeerak Talat, Michael Sejr Schlichtkrull, Pranava Madhyastha, Ed Hovy

+ [A Fictional Q&A Dataset for Studying Memorization and Knowledge Acquisition](https://arxiv.org//abs/2506.05639)

	John Kirchenbauer, Janny Mongkolsupawan, Yuxin Wen, Tom Goldstein, Daphne Ippolito

+ [SoK: Are Watermarks in LLMs Ready for Deployment?](https://arxiv.org//abs/2506.05594)

	Kieu Dang, Phung Lai, NhatHai Phan, Yelong Shen, Ruoming Jin, Abdallah Khreishah, My Thai

+ [When Semantics Mislead Vision: Mitigating Large Multimodal Models Hallucinations in Scene Text Spotting and Understanding](https://arxiv.org//abs/2506.05551)

	Yan Shu, Hangui Lin, Yexin Liu, Yan Zhang, Gangyan Zeng, Yan Li, Yu Zhou, Ser-Nam Lim, Harry Yang, Nicu Sebe

+ [Confidence Is All You Need: Few-Shot RL Fine-Tuning of Language Models](https://arxiv.org//abs/2506.06395)

	Pengyi Li, Matvey Skripkin, Alexander Zubrey, Andrey Kuznetsov, Ivan Oseledets

+ [ADAMIX: Adaptive Mixed-Precision Delta-Compression with Quantization Error Optimization for Large Language Models](https://arxiv.org//abs/2506.11087)

	Boya Xiong, Shuo Wang, Weifeng Ge, Guanhua Chen, Yun Chen

+ [Two Birds with One Stone: Improving Factuality and Faithfulness of LLMs via Dynamic Interactive Subspace Editing](https://arxiv.org//abs/2506.11088)

	Pengbo Wang, Chaozhuo Li, Chenxu Wang, Liwen Zheng, Litian Zhang, Xi Zhang

+ [Dynamic Context Tuning for Retrieval-Augmented Generation: Enhancing Multi-Turn Planning and Tool Adaptation](https://arxiv.org//abs/2506.11092)

	Jubin Abhishek Soni, Amit Anand, Rajesh Kumar Pandey, Aniket Abhishek Soni

+ [Customizing Speech Recognition Model with Large Language Model Feedback](https://arxiv.org//abs/2506.11091)

	Shaoshi Ling, Guoli Ye

+ [Hierarchical Language Models for Semantic Navigation and Manipulation in an Aerial-Ground Robotic System](https://arxiv.org//abs/2506.05020)

	Haokun Liu, Zhaoqi Ma, Yunong Li, Junichiro Sugihara, Yicheng Chen, Jinjie Li, Moju Zhao

# 2025-06-04
+ [Orak: A Foundational Benchmark for Training and Evaluating LLM Agents on Diverse Video Games](https://arxiv.org//abs/2506.03610)

	Dongmin Park, Minkyu Kim, Beongjun Choi, Junhyuck Kim, Keon Lee, Jonghyun Lee, Inkyu Park, Byeong-Uk Lee, Jaeyoung Hwang, Jaewoo Ahn, Ameya S. Mahabaleshwarkar, Bilal Kartal, Pritam Biswas, Yoshi Suhara, Kangwook Lee, Jaewoong Cho

+ [Reason from Future: Reverse Thought Chain Enhances LLM Reasoning](https://arxiv.org//abs/2506.03673)

	Yinlong Xu, Yanzhao Zheng, Shuoshuo Sun, Shuaihan Huang, Baohua Dong, Hangcheng Zhu, Ruohui Huang, Gang Yu, Hongxia Xu, Jian Wu

+ [AssetOpsBench: Benchmarking AI Agents for Task Automation in Industrial Asset Operations and Maintenance](https://arxiv.org//abs/2506.03828)

	Dhaval Patel, Shuxin Lin, James Rayfield, Nianjun Zhou, Roman Vaculin, Natalia Martinez, Fearghal O'donncha, Jayant Kalagnanam

+ [Graph Counselor: Adaptive Graph Exploration via Multi-Agent Synergy to Enhance LLM Reasoning](https://arxiv.org//abs/2506.03939)

	Junqi Gao, Xiang Zou, YIng Ai, Dong Li, Yichen Niu, Biqing Qi, Jianxing Liu

+ [AgentMisalignment: Measuring the Propensity for Misaligned Behaviour in LLM-Based Agents](https://arxiv.org//abs/2506.04018)

	Akshat Naik, Patrick Quinn, Guillermo Bosch, Emma Gouné, Francisco Javier Campos Zabala, Jason Ross Brown, Edward James Young

+ [TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management in LLM-based Agentic Multi-Agent Systems](https://arxiv.org//abs/2506.04133)

	Shaina Raza, Ranjan Sapkota, Manoj Karkee, Christos Emmanouilidis

+ [Does Thinking More always Help? Understanding Test-Time Scaling in Reasoning Models](https://arxiv.org//abs/2506.04210)

	Soumya Suvra Ghosal, Souradip Chakraborty, Avinash Reddy, Yifu Lu, Mengdi Wang, Dinesh Manocha, Furong Huang, Mohammad Ghavamzadeh, Amrit Singh Bedi

+ [EpiCoDe: Boosting Model Performance Beyond Training with Extrapolation and Contrastive Decoding](https://arxiv.org//abs/2506.03489)

	Mingxu Tao, Jie Hu, Mingchuan Yang, Yunhuai Liu, Dongyan Zhao, Yansong Feng

+ [Debate, Reflect, and Distill: Multi-Agent Feedback with Tree-Structured Preference Optimization for Efficient Language Model Enhancement](https://arxiv.org//abs/2506.03541)

	Xiaofeng Zhou, Heyan Huang, Lizi Liao

+ [POSS: Position Specialist Generates Better Draft for Speculative Decoding](https://arxiv.org//abs/2506.03566)

	Langlin Huang, Chengsong Huang, Jixuan Leng, Di Huang, Jiaxin Huang

+ [Auto prompt sql: a resource-efficient architecture for text-to-sql translation in constrained environments](https://arxiv.org//abs/2506.03598)

	Zetong Tang, Qian Ma, Di Wu

+ [Robustness of Prompting: Enhancing Robustness of Large Language Models Against Prompting Attacks](https://arxiv.org//abs/2506.03627)

	Lin Mu, Guowei Chu, Li Ni, Lei Sang, Zhize Wu, Peiquan Jin, Yiwen Zhang

+ [RewardAnything: Generalizable Principle-Following Reward Models](https://arxiv.org//abs/2506.03637)

	Zhuohao Yu, Jiali Zeng, Weizheng Gu, Yidong Wang, Jindong Wang, Fandong Meng, Jie Zhou, Yue Zhang, Shikun Zhang, Wei Ye

+ [Verbalized Confidence Triggers Self-Verification: Emergent Behavior Without Explicit Reasoning Supervision](https://arxiv.org//abs/2506.03723)

	Chaeyun Jang, Moonseok Choi, Yegon Kim, Hyungi Lee, Juho Lee

+ [AhaKV: Adaptive Holistic Attention-Driven KV Cache Eviction for Efficient Inference of Large Language Models](https://arxiv.org//abs/2506.03762)

	Yifeng Gu, Zicong Jiang, Jianxiu Jin, Kailing Guo, Ziyang Zhang, Xiangmin Xu

+ [Knockout LLM Assessment: Using Large Language Models for Evaluations through Iterative Pairwise Comparisons](https://arxiv.org//abs/2506.03785)

	Isik Baran Sandan, Tu Anh Dinh, Jan Niehues

+ [RadialRouter: Structured Representation for Efficient and Robust Large Language Models Routing](https://arxiv.org//abs/2506.03880)

	Ruihan Jin, Pengpeng Shao, Zhengqi Wen, Jinyang Wu, Mingkuan Feng, Shuai Zhang, Jianhua Tao

+ [VisCoder: Fine-Tuning LLMs for Executable Python Visualization Code Generation](https://arxiv.org//abs/2506.03930)

	Yuansheng Ni, Ping Nie, Kai Zou, Xiang Yue, Wenhu Chen

+ [Privacy and Security Threat for OpenAI GPTs](https://arxiv.org//abs/2506.04036)

	Wei Wenying, Zhao Kaifa, Xue Lei, Fan Ming

+ [Mitigating Hallucinations in Large Vision-Language Models via Entity-Centric Multimodal Preference Optimization](https://arxiv.org//abs/2506.04039)

	Jiulong Wu, Zhengliang Shi, Shuaiqiang Wang, Jizhou Huang, Dawei Yin, Lingyong Yan, Min Cao, Min Zhang

+ [Think Like a Person Before Responding: A Multi-Faceted Evaluation of Persona-Guided LLMs for Countering Hate](https://arxiv.org//abs/2506.04043)

	Mikel K. Ngueajio, Flor Miriam Plaza-del-Arco, Yi-Ling Chung, Danda B. Rawat, Amanda Cercas Curry

+ [Lacuna Inc. at SemEval-2025 Task 4: LoRA-Enhanced Influence-Based Unlearning for LLMs](https://arxiv.org//abs/2506.04044)

	Aleksey Kudelya, Alexander Shirnin

+ [Explainability-Based Token Replacement on LLM-Generated Text](https://arxiv.org//abs/2506.04050)

	Hadi Mohammadi, Anastasia Giachanou, Daniel L. Oberski, Ayoub Bagheri

+ [High Accuracy, Less Talk (HALT): Reliable LLMs through Capability-Aligned Finetuning](https://arxiv.org//abs/2506.04051)

	Tim Franzmeyer, Archie Sravankumar, Lijuan Liu, Yuning Mao, Rui Hou, Sinong Wang, Jakob N. Foerster, Luke Zettlemoyer, Madian Khabsa

+ [LLMEval-Med: A Real-world Clinical Benchmark for Medical LLMs with Physician Validation](https://arxiv.org//abs/2506.04078)

	Ming Zhang, Yujiong Shen, Zelin Li, Huayu Sha, Binze Hu, Yuhui Wang, Chenhao Huang, Shichun Liu, Jingqi Tong, Changhao Jiang, Mingxu Chai, Zhiheng Xi, Shihan Dou, Tao Gui, Qi Zhang, Xuanjing Huang

+ [TextAtari: 100K Frames Game Playing with Language Agents](https://arxiv.org//abs/2506.04098)

	Wenhao Li, Wenwu Li, Chuyun Shen, Junjie Sheng, Zixiao Huang, Di Wu, Yun Hua, Wei Yin, Xiangfeng Wang, Hongyuan Zha, Bo Jin

+ [TracLLM: A Generic Framework for Attributing Long Context LLMs](https://arxiv.org//abs/2506.04202)

	Yanting Wang, Wei Zou, Runpeng Geng, Jinyuan Jia

+ [Automated Skill Discovery for Language Agents through Exploration and Iterative Feedback](https://arxiv.org//abs/2506.04287)

	Yongjin Yang, Sinjae Kang, Juyong Lee, Dongjun Lee, Se-Young Yun, Kimin Lee

+ [A Statistical Physics of Language Model Reasoning](https://arxiv.org//abs/2506.04374)

	Jack David Carson, Amir Reisizadeh

+ [Plugging Schema Graph into Multi-Table QA: A Human-Guided Framework for Reducing LLM Reliance](https://arxiv.org//abs/2506.04427)

	Xixi Wang, Miguel Costa, Jordanka Kovaceva, Shuai Wang, Francisco C. Pereira

+ [Matching Markets Meet LLMs: Algorithmic Reasoning with Ranked Preferences](https://arxiv.org//abs/2506.04478)

	Hadi Hosseini, Samarth Khanna, Ronak Singh

+ [CogMath: Assessing LLMs' Authentic Mathematical Ability from a Human Cognitive Perspective](https://arxiv.org//abs/2506.04481)

	Jiayu Liu, Zhenya Huang, Wei Dai, Cheng Cheng, Jinze Wu, Jing Sha, Song Li, Qi Liu, Shijin Wang, Enhong Chen

+ ["Don't Do That!": Guiding Embodied Systems through Large Language Model-based Constraint Generation](https://arxiv.org//abs/2506.04500)

	Aladin Djuhera, Amin Seffo, Masataro Asai, Holger Boche

+ [HSSBench: Benchmarking Humanities and Social Sciences Ability for Multimodal Large Language Models](https://arxiv.org//abs/2506.03922)

	Zhaolu Kang, Junhao Gong, Jiaxu Yan, Wanke Xia, Yian Wang, Ziwen Wang, Huaxuan Ding, Zhuo Cheng, Wenhao Cao, Zhiyuan Feng, Siqi He, Shannan Yan, Junzhe Chen, Xiaomin He, Chaoya Jiang, Wei Ye, Kaidong Yu, Xuelong Li

+ [AUTOCT: Automating Interpretable Clinical Trial Prediction with LLM Agents](https://arxiv.org//abs/2506.04293)

	Fengze Liu, Haoyu Wang, Joonhyuk Cho, Dan Roth, Andrew W. Lo

+ [Mechanistic Decomposition of Sentence Representations](https://arxiv.org//abs/2506.04373)

	Matthieu Tehenan, Vikram Natarajan, Jonathan Michala, Milton Lin, Juri Opitz

+ [Through the Stealth Lens: Rethinking Attacks and Defenses in RAG](https://arxiv.org//abs/2506.04390)

	Sarthak Choudhary, Nils Palumbo, Ashish Hooda, Krishnamurthy Dj Dvijotham, Somesh Jha

+ [MedAgentGym: Training LLM Agents for Code-Based Medical Reasoning at Scale](https://arxiv.org//abs/2506.04405)

	Ran Xu, Yuchen Zhuang, Yishan Zhong, Yue Yu, Xiangru Tang, Hang Wu, May D. Wang, Peifeng Ruan, Donghan Yang, Tao Wang, Guanghua Xiao, Carl Yang, Yang Xie, Wenqi Shi

+ [Empaths at SemEval-2025 Task 11: Retrieval-Augmented Approach to Perceived Emotions Prediction](https://arxiv.org//abs/2506.04409)

	Lev Morozov, Aleksandr Mogilevskii, Alexander Shirnin

+ [Learning to Diagnose Privately: DP-Powered LLMs for Radiology Report Classification](https://arxiv.org//abs/2506.04450)

	Payel Bhattacharjee, Fengwei Tian, Ravi Tandon, Joseph Lo, Heidi Hanson, Geoffrey Rubin, Nirav Merchant, John Gounley

+ [GEM: Empowering LLM for both Embedding Generation and Language Understanding](https://arxiv.org//abs/2506.04344)

	Caojin Zhang, Qiang Zhang, Ke Li, Sai Vidyaranya Nuthalapati, Benyu Zhang, Jason Liu, Serena Li, Lizhu Zhang, Xiangjun Fan

+ [Zero-Shot Open-Schema Entity Structure Discovery](https://arxiv.org//abs/2506.04458)

	Xueqiang Xu, Jinfeng Xiao, James Barry, Mohab Elkaref, Jiaru Zou, Pengcheng Jiang, Yunyi Zhang, Max Giammona, Geeth de Mel, Jiawei Han

+ [Watermarking Degrades Alignment in Language Models: Analysis and Mitigation](https://arxiv.org//abs/2506.04462)

	Apurv Verma, NhatHai Phan, Shubhendu Trivedi

+ [Aligning Large Language Models with Implicit Preferences from User-Generated Content](https://arxiv.org//abs/2506.04463)

	Zhaoxuan Tan, Zheng Li, Tianyi Liu, Haodong Wang, Hyokun Yun, Ming Zeng, Pei Chen, Zhihan Zhang, Yifan Gao, Ruijie Wang, Priyanka Nigam, Bing Yin, Meng Jiang

+ [SQLens: An End-to-End Framework for Error Detection and Correction in Text-to-SQL](https://arxiv.org//abs/2506.04494)

	Yue Gong, Chuan Lei, Xiao Qin, Kapil Vaidya, Balakrishnan Narayanaswamy, Tim Kraska

+ [DRE: An Effective Dual-Refined Method for Integrating Small and Large Language Models in Open-Domain Dialogue Evaluation](https://arxiv.org//abs/2506.04516)

	Kun Zhao, Bohao Yang, Chen Tang, Siyuan Dai, Haoteng Tang, Chenghua Lin, Liang Zhan

+ [Understanding and Meeting Practitioner Needs When Measuring Representational Harms Caused by LLM-Based Systems](https://arxiv.org//abs/2506.04482)

	Emma Harvey, Emily Sheng, Su Lin Blodgett, Alexandra Chouldechova, Jean Garcia-Gathright, Alexandra Olteanu, Hanna Wallach

+ [Beyond Memorization: A Rigorous Evaluation Framework for Medical Knowledge Editing](https://arxiv.org//abs/2506.03490)

	Shigeng Chen, Linhao Luo, Zhangchi Qiu, Yanan Cao, Carl Yang, Shirui Pan

+ [Magic Mushroom: A Customizable Benchmark for Fine-grained Analysis of Retrieval Noise Erosion in RAG Systems](https://arxiv.org//abs/2506.03901)

	Yuxin Zhang, Yan Wang, Yongrui Chen, Shenyu Zhang, Xinbang Dai, Sheng Bi, Guilin Qi

+ [Rectified Sparse Attention](https://arxiv.org//abs/2506.04108)

	Yutao Sun, Tianzhu Ye, Li Dong, Yuqing Xia, Jian Chen, Yizhao Gao, Shijie Cao, Jianyong Wang, Furu Wei

+ [Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning](https://arxiv.org//abs/2506.04453)

	Hasin Us Sami, Swapneel Sen, Amit K. Roy-Chowdhury, Srikanth V. Krishnamurthy, Basak Guler

+ [DrSR: LLM based Scientific Equation Discovery with Dual Reasoning from Data and Experience](https://arxiv.org//abs/2506.04282)

	Runxiang Wang, Boxiao Wang, Kai Li, Yifan Zhang, Jian Cheng

+ [Relational reasoning and inductive bias in transformers trained on a transitive inference task](https://arxiv.org//abs/2506.04289)

	Jesse Geerts, Stephanie Chan, Claudia Clopath, Kimberly Stachenfeld

+ [The Cost of Dynamic Reasoning: Demystifying AI Agents and Test-Time Scaling from an AI Infrastructure Perspective](https://arxiv.org//abs/2506.04301)

	Jiin Kim, Byeongjun Shin, Jinha Chung, Minsoo Rhu

+ [RedRFT: A Light-Weight Benchmark for Reinforcement Fine-Tuning-Based Red Teaming](https://arxiv.org//abs/2506.04302)

	Xiang Zheng, Xingjun Ma, Wei-Bin Lee, Cong Wang

+ [Leveraging Coordinate Momentum in SignSGD and Muon: Memory-Optimized Zero-Order](https://arxiv.org//abs/2506.04430)

	Egor Petrov, Grigoriy Evseev, Aleksey Antonov, Andrey Veprikov, Pavel Plyusnin, Nikolay Bushkov, Stanislav Moiseev, Aleksandr Beznosikov

+ [Interpretable LLMs for Credit Risk: A Systematic Review and Taxonomy](https://arxiv.org//abs/2506.04290)

	Muhammed Golec, Maha AlabdulJalil

+ [SmoothRot: Combining Channel-Wise Scaling and Rotation for Quantization-Friendly LLMs](https://arxiv.org//abs/2506.05413)

	Patrik Czakó, Gábor Kertész, Sándor Szénási

+ [Homogeneous Keys, Heterogeneous Values: Exploiting Local KV Cache Asymmetry for Long-Context LLMs](https://arxiv.org//abs/2506.05410)

	Wanyun Cui, Mingwei Xu

+ [Robust Anti-Backdoor Instruction Tuning in LVLMs](https://arxiv.org//abs/2506.05401)

	Yuan Xun, Siyuan Liang, Xiaojun Jia, Xinwei Liu, Xiaochun Cao

+ [Mono: Is Your "Clean" Vulnerability Dataset Really Solvable? Exposing and Trapping Undecidable Patches and Beyond](https://arxiv.org//abs/2506.03651)

	Zeyu Gao, Junlin Zhou, Bolun Zhang, Yi He, Chao Zhang, Yuxin Cui, Hao Wang

+ [CyclicReflex: Improving Large Reasoning Models via Cyclical Reflection Token Scheduling](https://arxiv.org//abs/2506.11077)

	Chongyu Fan, Yihua Zhang, Jinghan Jia, Alfred Hero, Sijia Liu

+ [RoE-FND: A Case-Based Reasoning Approach with Dual Verification for Fake News Detection via LLMs](https://arxiv.org//abs/2506.11078)

	Yuzhou Yang, Yangming Zhou, Zhiying Zhu, Zhenxing Qian, Xinpeng Zhang, Sheng Li

+ [SAGE:Specification-Aware Grammar Extraction for Automated Test Case Generation with LLMs](https://arxiv.org//abs/2506.11081)

	Aditi, Hyunwoo Park, Sicheol Sung, Yo-Sub Han, Sang-Ki Ko

+ [RedDebate: Safer Responses through Multi-Agent Red Teaming Debates](https://arxiv.org//abs/2506.11083)

	Ali Asad, Stephen Obadinma, Radin Shayanfar, Xiaodan Zhu

+ [Unifying Uniform and Binary-coding Quantization for Accurate Compression of Large Language Models](https://arxiv.org//abs/2506.03781)

	Seungcheol Park, Jeongin Bae, Beomseok Kwon, Minjun Kim, Byeongwook Kim, Se Jung Kwon, U Kang, Dongsoo Lee

# 2025-06-03
+ [Helpful Agent Meets Deceptive Judge: Understanding Vulnerabilities in Agentic Workflows](https://arxiv.org//abs/2506.03332)

	Yifei Ming, Zixuan Ke, Xuan-Phi Nguyen, Jiayu Wang, Shafiq Joty

+ [DiaBlo: Diagonal Blocks Are Sufficient For Finetuning](https://arxiv.org//abs/2506.03230)

	Selcuk Gurses, Aozhong Zhang, Yanxia Deng, Xun Dong, Xin Li, Naigang Wang, Penghang Yin, Zi Yang

+ [NetPress: Dynamically Generated LLM Benchmarks for Network Applications](https://arxiv.org//abs/2506.03231)

	Yajie Zhou, Jiajun Ruan, Eric S. Wang, Sadjad Fouladi, Francis Y. Yan, Kevin Hsieh, Zaoxing Liu

+ [BadReward: Clean-Label Poisoning of Reward Models in Text-to-Image RLHF](https://arxiv.org//abs/2506.03234)

	Kaiwen Duan, Hongwei Yao, Yufei Chen, Ziyun Li, Tong Qiao, Zhan Qin, Cong Wang

+ [HyperSteer: Activation Steering at Scale with Hypernetworks](https://arxiv.org//abs/2506.03292)

	Jiuding Sun, Sidharth Baskaran, Zhengxuan Wu, Michael Sklar, Christopher Potts, Atticus Geiger

+ [Hopscotch: Discovering and Skipping Redundancies in Language Models](https://arxiv.org//abs/2506.03303)

	Mustafa Eyceoz, Nikhil Shivakumar Nayak, Hao Wang, Ligong Han, Akash Srivastava

+ [The Future of Continual Learning in the Era of Foundation Models: Three Key Directions](https://arxiv.org//abs/2506.03320)

	Jack Bell, Luigi Quarantiello, Eric Nuertey Coleman, Lanpei Li, Malio Li, Mauro Madeddu, Elia Piccoli, Vincenzo Lomonaco

+ [Mitigating Non-IID Drift in Zeroth-Order Federated LLM Fine-Tuning with Transferable Sparsity](https://arxiv.org//abs/2506.03337)

	Yide Ran, Wentao Guo, Jingwei Sun, Yanzhou Pan, Xiaodong Yu, Hao Wang, Jianwen Xie, Yiran Chen, Denghui Zhang, Zhaozhuo Xu

+ [Adversarial Attacks on Robotic Vision Language Action Models](https://arxiv.org//abs/2506.03350)

	Eliot Krzysztof Jones, Alexander Robey, Andy Zou, Zachary Ravichandran, George J. Pappas, Hamed Hassani, Matt Fredrikson, J. Zico Kolter

+ [Ask a Local: Detecting Hallucinations With Specialized Model Divergence](https://arxiv.org//abs/2506.03357)

	Aldan Creo, Héctor Cerezo-Costas, Pedro Alonso-Doval, Maximiliano Hormazábal-Lagos

+ [Sampling Preferences Yields Simple Trustworthiness Scores](https://arxiv.org//abs/2506.03399)

	Sean Steinle

+ [EvaLearn: Quantifying the Learning Capability and Efficiency of LLMs via Sequential Problem Solving](https://arxiv.org//abs/2506.02672)

	Shihan Dou, Ming Zhang, Chenhao Huang, Jiayi Chen, Feng Chen, Shichun Liu, Yan Liu, Chenxiao Liu, Cheng Zhong, Zongzhang Zhang, Tao Gui, Chao Xin, Wei Chengzhi, Lin Yan, Qi Zhang, Yonghui Wu, Xuanjing Huang

+ [Retrieval-Augmented Generation as Noisy In-Context Learning: A Unified Theory and Risk Bounds](https://arxiv.org//abs/2506.03100)

	Yang Guo, Yutian Tao, Yifei Ming, Robert D. Nowak, Yingyu Liang

+ [On Entity Identification in Language Models](https://arxiv.org//abs/2506.02701)

	Masaki Sakata, Benjamin Heinzerling, Sho Yokoi, Takumi Ito, Kentaro Inui

+ [Unleashing the Reasoning Potential of Pre-trained LLMs by Critique Fine-Tuning on One Problem](https://arxiv.org//abs/2506.03295)

	Yubo Wang, Ping Nie, Kai Zou, Lijun Wu, Wenhu Chen

+ [Beyond RAG: Reinforced Reasoning Augmented Generation for Clinical Notes](https://arxiv.org//abs/2506.05386)

	Lo Pang-Yun Ting, Chengshuai Zhao, Yu-Hua Zeng, Yuan Jee Lim, Kun-Ta Chuang

+ [Advancing Decoding Strategies: Enhancements in Locally Typical Sampling for LLMs](https://arxiv.org//abs/2506.05387)

	Jaydip Sen, Saptarshi Sengupta. Subhasis Dasgupta

+ [LLMs Can Also Do Well! Breaking Barriers in Semantic Role Labeling via Large Language Models](https://arxiv.org//abs/2506.05385)

	Xinxin Li, Huiyao Chen, Chengjun Liu, Jing Li, Meishan Zhang, Jun Yu, Min Zhang

+ [Understanding Gender Bias in AI-Generated Product Descriptions](https://arxiv.org//abs/2506.05390)

	Markelle Kelly, Mohammad Tahaei, Padhraic Smyth, Lauren Wilcox

+ [ChemGraph: An Agentic Framework for Computational Chemistry Workflows](https://arxiv.org//abs/2506.06363)

	Thang D. Pham, Aditya Tanikanti, Murat Keçeli

+ [TL;DR: Too Long, Do Re-weighting for Efficient LLM Reasoning Compression](https://arxiv.org//abs/2506.02678)

	Zhong-Zhi Li, Xiao Liang, Zihao Tang, Lei Ji, Peijie Wang, Haotian Xu, Xing W, Haizhen Huang, Weiwei Deng, Ying Nian Wu, Yeyun Gong, Zhijiang Guo, Xiao Liu, Fei Yin, Cheng-Lin Liu

+ [Surfer-H Meets Holo1: Cost-Efficient Web Agent Powered by Open Weights](https://arxiv.org//abs/2506.02865)

	Mathieu Andreux, Breno Baldas Skuk, Hamza Benchekroun, Emilien Biré, Antoine Bonnet, Riaz Bordie, Nathan Bout, Matthias Brunel, Pierre-Louis Cedoz, Antoine Chassang, Mickaël Chen, Alexandra D. Constantinou, Antoine d'Andigné, Hubert de La Jonquière, Aurélien Delfosse, Ludovic Denoyer, Alexis Deprez, Augustin Derupti, Michael Eickenberg, Mathïs Federico, Charles Kantor, Xavier Koegler, Yann Labbé, Matthew C. H. Lee, Erwan Le Jumeau de Kergaradec, Amir Mahla, Avshalom Manevich, Adrien Maret, Charles Masson, Rafaël Maurin, Arturo Mena, Philippe Modard, Axel Moyal, Axel Nguyen Kerbel, Julien Revelle, Mats L. Richter, María Santos, Laurent Sifre, Maxime Theillard, Marc Thibault, Louis Thiry, Léo Tronchon, Nicolas Usunier, Tony Wu

+ [GraphRAG-Bench: Challenging Domain-Specific Reasoning for Evaluating Graph Retrieval-Augmented Generation](https://arxiv.org//abs/2506.02404)

	Yilin Xiao, Junnan Dong, Chuang Zhou, Su Dong, Qian-wen Zhang, Di Yin, Xing Sun, Xiao Huang

+ [KVCache Cache in the Wild: Characterizing and Optimizing KVCache Cache at a Large Cloud Provider](https://arxiv.org//abs/2506.02634)

	Jiahao Wang, Jinbo Han, Xingda Wei, Sijie Shen, Dingyan Zhang, Chenguang Fang, Rong Chen, Wenyuan Yu, Haibo Chen

# 2025-06-02
+ [RAISE: Reasoning Agent for Interactive SQL Exploration](https://arxiv.org//abs/2506.01273)

	Fernando Granado, Roberto Lotufo, Jayr Pereira

+ [Scalable In-Context Q-Learning](https://arxiv.org//abs/2506.01299)

	Jinmei Liu, Fuhong Liu, Jianye Hao, Bo Wang, Huaxiong Li, Chunlin Chen, Zhi Wang

+ [An Empirical Study of Group Conformity in Multi-Agent Systems](https://arxiv.org//abs/2506.01332)

	Min Choi, Keonwoo Kim, Sungwon Chae, Sangyeob Baek

+ [AgentCPM-GUI: Building Mobile-Use Agents with Reinforcement Fine-Tuning](https://arxiv.org//abs/2506.01391)

	Zhong Zhang, Yaxi Lu, Yikun Fu, Yupeng Huo, Shenzhi Yang, Yesai Wu, Han Si, Xin Cong, Haotian Chen, Yankai Lin, Jie Xie, Wei Zhou, Wang Xu, Yuanheng Zhang, Zhou Su, Zhongwu Zhai, Xiaoming Liu, Yudong Mei, Jianming Xu, Hongyan Tian, Chongyi Wang, Chi Chen, Yuan Yao, Zhiyuan Liu, Maosong Sun

+ [Distinguishing Autonomous AI Agents from Collaborative Agentic Systems: A Comprehensive Framework for Understanding Modern Intelligent Architectures](https://arxiv.org//abs/2506.01438)

	Prashik Buddhaghosh Bansod

+ [Agentic Episodic Control](https://arxiv.org//abs/2506.01442)

	Xidong Yang, Wenhao Li, Junjie Sheng, Chuyun Shen, Yun Hua, Xiangfeng Wang

+ [PGPO: Enhancing Agent Reasoning via Pseudocode-style Planning Guided Preference Optimization](https://arxiv.org//abs/2506.01475)

	Zouying Cao, Runze Wang, Yifei Yang, Xinbei Ma, Xiaoyong Zhu, Bo Zheng, Hai Zhao

+ [MLA-Trust: Benchmarking Trustworthiness of Multimodal LLM Agents in GUI Environments](https://arxiv.org//abs/2506.01616)

	Xiao Yang, Jiawei Chen, Jun Luo, Zhengwei Fang, Yinpeng Dong, Hang Su, Jun Zhu

+ [Social Cooperation in Conversational AI Agents](https://arxiv.org//abs/2506.01624)

	Mustafa Mert Çelikok, Saptarashmi Bandyopadhyay, Robert Loftin

+ [Self-Challenging Language Model Agents](https://arxiv.org//abs/2506.01716)

	Yifei Zhou, Sergey Levine, Jason Weston, Xian Li, Sainbayar Sukhbaatar

+ [A Study on the MCP x A2A Framework for Enhancing Interoperability of LLM-based Autonomous Agents](https://arxiv.org//abs/2506.01804)

	Cheonsu Jeong

+ [WHEN TO ACT, WHEN TO WAIT: Modeling Structural Trajectories for Intent Triggerability in Task-Oriented Dialogue](https://arxiv.org//abs/2506.01881)

	Yaoyao Qian, Jindan Huang, Yuanli Wang, Simon Yu, Kyrie Zhixuan Zhou, Jiayuan Mao, Mingfu Liang, Hanhan Zhou

+ [COALESCE: Economic and Security Dynamics of Skill-Based Task Outsourcing Among Team of Autonomous LLM Agents](https://arxiv.org//abs/2506.01900)

	Manish Bhatt, Ronald F. Del Rosario, Vineeth Sai Narajala, Idan Habler

+ [Large language models can learn and generalize steganographic chain-of-thought under process supervision](https://arxiv.org//abs/2506.01926)

	Joey Skaf, Luis Ibanez-Lissen, Robert McCarthy, Connor Watts, Vasil Georgiv, Hannes Whittingham, Lorena Gonzalez-Manzano, David Lindner, Cameron Tice, Edward James Young, Puria Radmard

+ [Retrieval-Augmented Generation of Ontologies from Relational Databases](https://arxiv.org//abs/2506.01232)

	Mojtaba Nayyeri, Athish A Yogi, Nadeen Fathallah, Ratan Bahadur Thapa, Hans-Michael Tautenhahn, Anton Schnurpel, Steffen Staab

+ [Polishing Every Facet of the GEM: Testing Linguistic Competence of LLMs and Humans in Korean](https://arxiv.org//abs/2506.01237)

	SungHo Kim, Nayeon Kim, Taehee Jeon, SangKeun Lee

+ [MTCMB: A Multi-Task Benchmark Framework for Evaluating LLMs on Knowledge, Reasoning, and Safety in Traditional Chinese Medicine](https://arxiv.org//abs/2506.01252)

	Shufeng Kong, Xingru Yang, Yuanyuan Wei, Zijie Wang, Hao Tang, Jiuqi Qin, Shuting Lan, Yingheng Wang, Junwen Bai, Zhuangbin Chen, Zibin Zheng, Caihua Liu, Hao Liang

+ [DeepSeek in Healthcare: A Survey of Capabilities, Risks, and Clinical Applications of Open-Source Large Language Models](https://arxiv.org//abs/2506.01257)

	Jiancheng Ye, Sophie Bronstein, Jiarui Hai, Malak Abu Hashish

+ [Detoxification of Large Language Models through Output-layer Fusion with a Calibration Model](https://arxiv.org//abs/2506.01266)

	Yuanhe Tian, Mingjie Deng, Guoqing Jin, Yan Song

+ [Abstractive Visual Understanding of Multi-modal Structured Knowledge: A New Perspective for MLLM Evaluation](https://arxiv.org//abs/2506.01293)

	Yichi Zhang, Zhuo Chen, Lingbing Guo, Yajing Xu, Min Zhang, Wen Zhang, Huajun Chen

+ [Align is not Enough: Multimodal Universal Jailbreak Attack against Multimodal Large Language Models](https://arxiv.org//abs/2506.01307)

	Youze Wang, Wenbo Hu, Yinpeng Dong, Jing Liu, Hanwang Zhang, Richang Hong

+ [T-SHIRT: Token-Selective Hierarchical Data Selection for Instruction Tuning](https://arxiv.org//abs/2506.01317)

	Yanjun Fu, Faisal Hamman, Sanghamitra Dutta

+ [Unlearning's Blind Spots: Over-Unlearning and Prototypical Relearning Attack](https://arxiv.org//abs/2506.01318)

	SeungBum Ha, Saerom Park, Sung Whan Yoon

+ [Evaluating Large Language Models in Crisis Detection: A Real-World Benchmark from Psychological Support Hotlines](https://arxiv.org//abs/2506.01329)

	Guifeng Deng, Shuyin Rao, Tianyu Lin, Anlu Dai, Pan Wang, Junyi Xie, Haidong Song, Ke Zhao, Dongwu Xu, Zhengdong Cheng, Tao Li, Haiteng Jiang

+ [ETDI: Mitigating Tool Squatting and Rug Pull Attacks in Model Context Protocol (MCP) by using OAuth-Enhanced Tool Definitions and Policy-Based Access Control](https://arxiv.org//abs/2506.01333)

	Manish Bhatt, Vineeth Sai Narajala, Idan Habler

+ [Incentivizing LLMs to Self-Verify Their Answers](https://arxiv.org//abs/2506.01369)

	Fuxiang Zhang, Jiacheng Xu, Chaojie Wang, Ce Cui, Yang Liu, Bo An

+ [Incentivizing Reasoning for Advanced Instruction-Following of Large Language Models](https://arxiv.org//abs/2506.01413)

	Yulei Qin, Gang Li, Zongyi Li, Zihan Xu, Yuchen Shi, Zhekai Lin, Xiao Cui, Ke Li, Xing Sun

+ [Agentic AI and Multiagentic: Are We Reinventing the Wheel?](https://arxiv.org//abs/2506.01463)

	V.Botti

+ [Representations of Fact, Fiction and Forecast in Large Language Models: Epistemics and Attitudes](https://arxiv.org//abs/2506.01512)

	Meng Li, Michael Vrazitulis, David Schlangen

+ [LAMARL: LLM-Aided Multi-Agent Reinforcement Learning for Cooperative Policy Generation](https://arxiv.org//abs/2506.01538)

	Guobin Zhu, Rui Zhou, Wenkang Ji, Shiyu Zhao

+ [EvolveNav: Self-Improving Embodied Reasoning for LLM-Based Vision-Language Navigation](https://arxiv.org//abs/2506.01551)

	Bingqian Lin, Yunshuang Nie, Khun Loun Zai, Ziming Wei, Mingfei Han, Rongtao Xu, Minzhe Niu, Jianhua Han, Liang Lin, Cewu Lu, Xiaodan Liang

+ [Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification](https://arxiv.org//abs/2506.01631)

	Zehao Wu, Yanjie Zhao, Haoyu Wang

+ [ESGenius: Benchmarking LLMs on Environmental, Social, and Governance (ESG) and Sustainability Knowledge](https://arxiv.org//abs/2506.01646)

	Chaoyue He, Xin Zhou, Yi Wu, Xinjia Yu, Yan Zhang, Lei Zhang, Di Wang, Shengfei Lyu, Hong Xu, Xiaoqiao Wang, Wei Liu, Chunyan Miao

+ [When LLMs Team Up: The Emergence of Collaborative Affective Computing](https://arxiv.org//abs/2506.01698)

	Wenna Lai, Haoran Xie, Guandong Xu, Qing Li, S. Joe Qin

+ [Tug-of-war between idiom's figurative and literal meanings in LLMs](https://arxiv.org//abs/2506.01723)

	Soyoung Oh, Xinting Huang, Mathis Pink, Michael Hahn, Vera Demberg

+ [ReGA: Representation-Guided Abstraction for Model-based Safeguarding of LLMs](https://arxiv.org//abs/2506.01770)

	Zeming Wei, Chengcan Wu, Meng Sun

+ [iQUEST: An Iterative Question-Guided Framework for Knowledge Base Question Answering](https://arxiv.org//abs/2506.01784)

	Shuai Wang, Yinan Yu

+ [Transformers as Multi-task Learners: Decoupling Features in Hidden Markov Models](https://arxiv.org//abs/2506.01919)

	Yifan Hao, Chenlu Ye, Chi Han, Tong Zhang

+ [Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning](https://arxiv.org//abs/2506.01939)

	Shenzhi Wang, Le Yu, Chang Gao, Chujie Zheng, Shixuan Liu, Rui Lu, Kai Dang, Xionghui Chen, Jianxin Yang, Zhenru Zhang, Yuqiong Liu, An Yang, Andrew Zhao, Yang Yue, Shiji Song, Bowen Yu, Gao Huang, Junyang Lin

+ [WebChoreArena: Evaluating Web Browsing Agents on Realistic Tedious Web Tasks](https://arxiv.org//abs/2506.01952)

	Atsuyuki Miyai, Zaiying Zhao, Kazuki Egashira, Atsuki Sato, Tatsumi Sunada, Shota Onohara, Hiromasa Yamanishi, Mashiro Toyooka, Kunato Nishina, Ryoma Maeda, Kiyoharu Aizawa, Toshihiko Yamasaki

+ [DRAG: Distilling RAG for SLMs from LLMs to Transfer Knowledge and Mitigate Hallucination via Evidence and Graph-based Distillation](https://arxiv.org//abs/2506.01954)

	Jennifer Chen, Aidar Myrzakhan, Yaxin Luo, Hassaan Muhammad Khan, Sondos Mahmoud Bsharat, Zhiqiang Shen

+ [ExpertLongBench: Benchmarking Language Models on Expert-Level Long-Form Generation Tasks with Structured Checklists](https://arxiv.org//abs/2506.01241)

	Jie Ruan, Inderjeet Nair, Shuyang Cao, Amy Liu, Sheza Munir, Micah Pollens-Dempsey, Tiffany Chiang, Lucy Kates, Nicholas David, Sihan Chen, Ruxin Yang, Yuqian Yang, Jasmine Gump, Tessa Bialek, Vivek Sankaran, Margo Schlanger, Lu Wang

+ [Exploring the Potential of LLMs as Personalized Assistants: Dataset, Evaluation, and Analysis](https://arxiv.org//abs/2506.01262)

	Jisoo Mok, Ik-hwan Kim, Sangkwon Park, Sungroh Yoon

+ [Beyond In-Context Learning: Aligning Long-form Generation of Large Language Models via Task-Inherent Attribute Guidelines](https://arxiv.org//abs/2506.01265)

	Do Xuan Long, Duong Ngoc Yen, Do Xuan Trong, Luu Anh Tuan, Kenji Kawaguchi, Shafiq Joty, Min-Yen Kan, Nancy F. Chen

+ [Schema as Parameterized Tools for Universal Information Extraction](https://arxiv.org//abs/2506.01276)

	Sheng Liang, Yongyue Zhang, Yaxiong Wu, Ruiming Tang, Yong Liu

+ [Growing Through Experience: Scaling Episodic Grounding in Language Models](https://arxiv.org//abs/2506.01312)

	Chunhui Zhang, Sirui (Elsie)Wang, Zhongyu Ouyang, Xiangchi Yuan, Soroush Vosoughi

+ [Enhancing Interpretable Image Classification Through LLM Agents and Conditional Concept Bottleneck Models](https://arxiv.org//abs/2506.01334)

	Yiwen Jiang, Deval Mehta, Wei Feng, Zongyuan Ge

+ [TurnBench-MS: A Benchmark for Evaluating Multi-Turn, Multi-Step Reasoning in Large Language Models](https://arxiv.org//abs/2506.01341)

	Yiran Zhang, Mo Wang, Xiaoyang Li, Kaixuan Ren, Chencheng Zhu, Usman Naseem

+ [Follow the Flow: Fine-grained Flowchart Attribution with Neurosymbolic Agents](https://arxiv.org//abs/2506.01344)

	Manan Suri, Puneet Mathur, Nedim Lipka, Franck Dernoncourt, Ryan A. Rossi, Vivek Gupta, Dinesh Manocha

+ [The Surprising Effectiveness of Negative Reinforcement in LLM Reasoning](https://arxiv.org//abs/2506.01347)

	Xinyu Zhu, Mengzhou Xia, Zhepei Wei, Wei-Lin Chen, Danqi Chen, Yu Meng

+ [MMD-Flagger: Leveraging Maximum Mean Discrepancy to Detect Hallucinations](https://arxiv.org//abs/2506.01367)

	Kensuke Mitsuzawa, Damien Garreau

+ [AdaRewriter: Unleashing the Power of Prompting-based Conversational Query Reformulation via Test-Time Adaptation](https://arxiv.org//abs/2506.01381)

	Yilong Lai, Jialong Wu, Zhenglin Wang, Deyu Zhou

+ [Self-Refining Language Model Anonymizers via Adversarial Distillation](https://arxiv.org//abs/2506.01420)

	Kyuyoung Kim, Hyunjun Jeon, Jinwoo Shin

+ [LLM in the Loop: Creating the PARADEHATE Dataset for Hate Speech Detoxification](https://arxiv.org//abs/2506.01484)

	Shuzhou Yuan, Ercong Nie, Lukas Kouba, Ashish Yashwanth Kangen, Helmut Schmid, Hinrich Schutze, Michael Farber

+ [CVC: A Large-Scale Chinese Value Rule Corpus for Value Alignment of Large Language Models](https://arxiv.org//abs/2506.01495)

	Ping Wu, Guobin Shen, Dongcheng Zhao, Yuwei Wang, Yiting Dong, Yu Shi, Enmeng Lu, Feifei Zhao, Yi Zeng

+ [FormFactory: An Interactive Benchmarking Suite for Multimodal Form-Filling Agents](https://arxiv.org//abs/2506.01520)

	Bobo Li, Yuheng Wang, Hao Fei, Juncheng Li, Wei Ji, Mong-Li Lee, Wynne Hsu

+ [Unified Large Language Models for Misinformation Detection in Low-Resource Linguistic Settings](https://arxiv.org//abs/2506.01587)

	Muhammad Islam, Javed Ali Khan, Mohammed Abaker, Ali Daud, Azeem Irshad

+ [IndicRAGSuite: Large-Scale Datasets and a Benchmark for Indian Language RAG Systems](https://arxiv.org//abs/2506.01615)

	Pasunuti Prasanjith, Prathmesh B More, Anoop Kunchukuttan, Raj Dabre

+ [Cross-Lingual Generalization and Compression: From Language-Specific to Shared Neurons](https://arxiv.org//abs/2506.01629)

	Frederick Riemenschneider, Anette Frank

+ [Cross-Lingual Transfer of Cultural Knowledge: An Asymmetric Phenomenon](https://arxiv.org//abs/2506.01675)

	Chen Zhang, Zhiyuan Liao, Yansong Feng

+ [StochasTok: Improving Fine-Grained Subword Understanding in LLMs](https://arxiv.org//abs/2506.01687)

	Anya Sims, Thom Foster, Klara Kaleb, Tuan-Duy H. Nguyen, Joseph Lee, Jakob N. Foerster, Yee Whye Teh, Cong Lu

+ [mdok of KInIT: Robustly Fine-tuned LLM for Binary and Multiclass AI-Generated Text Detection](https://arxiv.org//abs/2506.01702)

	Dominik Macko

+ [Fairness Dynamics During Training](https://arxiv.org//abs/2506.01709)

	Krishna Patel, Nivedha Sivakumar, Barry-John Theobald, Luca Zappella, Nicholas Apostoloff

+ [SRPO: Enhancing Multimodal LLM Reasoning via Reflection-Aware Reinforcement Learning](https://arxiv.org//abs/2506.01713)

	Zhongwei Wan, Zhihao Dou, Che Liu, Yu Zhang, Dongfei Cui, Qinjian Zhao, Hui Shen, Jing Xiong, Yi Xin, Yifan Jiang, Yangfan He, Mi Zhang, Shen Yan

+ [Benford's Curse: Tracing Digit Bias to Numerical Hallucination in LLMs](https://arxiv.org//abs/2506.01734)

	Jiandong Shao, Yao Lu, Jianfei Yang

+ [Thinking in Character: Advancing Role-Playing Agents with Role-Aware Reasoning](https://arxiv.org//abs/2506.01748)

	Yihong Tang, Kehai Chen, Muyun Yang, Zhengyu Niu, Jing Li, Tiejun Zhao, Min Zhang

+ [Analysis of LLM Bias (Chinese Propaganda & Anti-US Sentiment) in DeepSeek-R1 vs. ChatGPT o3-mini-high](https://arxiv.org//abs/2506.01814)

	PeiHsuan Huang, ZihWei Lin, Simon Imbot, WenCheng Fu, Ethan Tu

+ [CONFETTI: Conversational Function-Calling Evaluation Through Turn-Level Interactions](https://arxiv.org//abs/2506.01859)

	Tamer Alkhouli, Katerina Margatina, James Gung, Raphael Shu, Claudia Zaghi, Monica Sunkara, Yi Zhang

+ [Is Extending Modality The Right Path Towards Omni-Modality?](https://arxiv.org//abs/2506.01872)

	Tinghui Zhu, Kai Zhang, Muhao Chen, Yu Su

+ [RewardBench 2: Advancing Reward Model Evaluation](https://arxiv.org//abs/2506.01937)

	Saumya Malik, Valentina Pyatkin, Sander Land, Jacob Morrison, Noah A. Smith, Hannaneh Hajishirzi, Nathan Lambert

+ [Self-ensemble: Mitigating Confidence Distortion for Large Language Models](https://arxiv.org//abs/2506.01951)

	Zicheng Xu, Guanchu Wang, Guangyao Zheng, Yu-Neng Chuang, Alexander Szalay, Xia Hu, Vladimir Braverman

+ [Unified Scaling Laws for Compressed Representations](https://arxiv.org//abs/2506.01863)

	Andrei Panferov, Alexandra Volkova, Ionut-Vlad Modoranu, Vage Egiazarian, Mher Safaryan, Dan Alistarh

+ [When Should Dense Retrievers Be Updated in Evolving Corpora? Detecting Out-of-Distribution Corpora Using GradNormIR](https://arxiv.org//abs/2506.01877)

	Dayoon Ko, Jinyoung Kim, Sohyeon Kim, Jinhyuk Kim, Jaehoon Lee, Seonghak Song, Minyoung Lee, Gunhee Kim

+ [MotionSight: Boosting Fine-Grained Motion Understanding in Multimodal LLMs](https://arxiv.org//abs/2506.01674)

	Yipeng Du, Tiehan Fan, Kepan Nan, Rui Xie, Penghao Zhou, Xiang Li, Jian Yang, Zhenheng Yang, Ying Tai

+ [VideoCap-R1: Enhancing MLLMs for Video Captioning via Structured Thinking](https://arxiv.org//abs/2506.01725)

	Desen Meng, Rui Huang, Zhilin Dai, Xinhao Li, Yifan Xu, Jun Zhang, Zhenpeng Huang, Meng Zhang, Lingshu Zhang, Yi Liu, Limin Wang

+ [Invariance Makes LLM Unlearning Resilient Even to Unanticipated Downstream Fine-Tuning](https://arxiv.org//abs/2506.01339)

	Changsheng Wang, Yihua Zhang, Jinghan Jia, Parikshit Ram, Dennis Wei, Yuguang Yao, Soumyadeep Pal, Nathalie Baracaldo, Sijia Liu

+ [BehaviorBox: Automated Discovery of Fine-Grained Performance Differences Between Language Models](https://arxiv.org//abs/2506.02204)

	Lindia Tjuatja, Graham Neubig

+ [SALAD: Systematic Assessment of Machine Unlearing on LLM-Aided Hardware Design](https://arxiv.org//abs/2506.02089)

	Zeng Wang, Minghao Shao, Rupesh Karn, Likhitha Mankali, Jitendra Bhandari, Ramesh Karri, Ozgur Sinanoglu, Muhammad Shafique, Johann Knechtel

+ [Focusing on Students, not Machines: Grounded Question Generation and Automated Answer Grading](https://arxiv.org//abs/2506.12066)

	Gérôme Meyer, Philip Breuer

# 2025-06-01
+ [Do not Abstain! Identify and Solve the Uncertainty](https://arxiv.org//abs/2506.00780)

	Jingyu Liu, Jingquan Peng, xiaopeng Wu, Xubin Li, Tiezheng Ge, Bo Zheng, Yong Liu

+ [CoP: Agentic Red-teaming for Large Language Models using Composition of Principles](https://arxiv.org//abs/2506.00781)

	Chen Xiong, Pin-Yu Chen, Tsung-Yi Ho

+ [Jailbreak-R1: Exploring the Jailbreak Capabilities of LLMs via Reinforcement Learning](https://arxiv.org//abs/2506.00782)

	Weiyang Guo, Zesheng Shi, Zhuo Li, Yequan Wang, Xuebo Liu, Wenya Wang, Fangming Liu, Min Zhang, Jing Li

+ [Enhancing LLM Reasoning for Time Series Classification by Tailored Thinking and Fused Decision](https://arxiv.org//abs/2506.00807)

	Jiahui Zhou, Dan Li, Lin Li, Zhuomin Chen, Shunyu Wu, Haozheng Ye, Jian Lou, Costas J. Spanos

+ [Toward a Theory of Agents as Tool-Use Decision-Makers](https://arxiv.org//abs/2506.00886)

	Hongru Wang, Cheng Qian, Manling Li, Jiahao Qiu, Boyang Xue, Mengdi Wang, Heng Ji, Kam-Fai Wong

+ [Conformal Arbitrage: Risk-Controlled Balancing of Competing Objectives in Language Models](https://arxiv.org//abs/2506.00911)

	William Overman, Mohsen Bayati

+ [Unlocking Personalized Knowledge in Federated Large Language Model: The Power of Mixture of Experts](https://arxiv.org//abs/2506.00965)

	Fan Liu, Bikang Pan, Zhongyi Wang, Xi Yao, Xiaoying Tang, Jingya Wang, Ye Shi

+ [IRT-Router: Effective and Interpretable Multi-LLM Routing via Item Response Theory](https://arxiv.org//abs/2506.01048)

	Wei Song, Zhenya Huang, Cheng Cheng, Weibo Gao, Bihan Xu, GuanHao Zhao, Fei Wang, Runze Wu

+ [MCP-Zero: Proactive Toolchain Construction for LLM Agents from Scratch](https://arxiv.org//abs/2506.01056)

	Xiang Fei, Xiawu Zheng, Hao Feng

+ [The Coming Crisis of Multi-Agent Misalignment: AI Alignment Must Be a Dynamic and Social Process](https://arxiv.org//abs/2506.01080)

	Florian Carichon, Aditi Khandelwal, Marylou Fauchard, Golnoosh Farnadi

+ [SuperRL: Reinforcement Learning with Supervision to Boost Language Model Reasoning](https://arxiv.org//abs/2506.01096)

	Yihao Liu, Shuocheng Li, Lang Cao, Yuhang Xie, Mengyu Zhou, Haoyu Dong, Xiaojun Ma, Shi Han, Dongmei Zhang

+ [ChemAU: Harness the Reasoning of LLMs in Chemical Research with Adaptive Uncertainty Estimation](https://arxiv.org//abs/2506.01116)

	Xinyi Liu, Lipeng Ma, Yixuan Li, Weidong Yang, Qingyuan Zhou, Jiayi Song, Shuhao Li, Ben Fei

+ [GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering](https://arxiv.org//abs/2506.01174)

	Muhammad Qasim Ali, Saeejith Nair, Alexander Wong, Yuchen Cui, Yuhao Chen

+ [LIFT the Veil for the Truth: Principal Weights Emerge after Rank Reduction for Reasoning-Focused Supervised Fine-Tuning](https://arxiv.org//abs/2506.00772)

	Zihang Liu, Tianyu Pang, Oleg Balabanov, Chaoqun Yang, Tianjin Huang, Lu Yin, Yaoqing Yang, Shiwei Liu

+ [KG-TRACES: Enhancing Large Language Models with Knowledge Graph-constrained Trajectory Reasoning and Attribution Supervision](https://arxiv.org//abs/2506.00783)

	Rong Wu, Pinlong Cai, Jianbiao Mei, Licheng Wen, Tao Hu, Xuemeng Yang, Daocheng Fu, Botian Shi

+ [SafeGenes: Evaluating the Adversarial Robustness of Genomic Foundation Models](https://arxiv.org//abs/2506.00821)

	Huixin Zhan, Jason H. Moore

+ [COMPKE: Complex Question Answering under Knowledge Editing](https://arxiv.org//abs/2506.00829)

	Keyuan Cheng, Zijian Kan, Zhixian He, Zhuoran Zhang, Muhammad Asif Ali, Ke Xu, Lijie Hu, Di Wang

+ [A Large Language Model-Supported Threat Modeling Framework for Transportation Cyber-Physical Systems](https://arxiv.org//abs/2506.00831)

	M Sabbir Salek, Mashrur Chowdhury, Muhaimin Bin Munir, Yuchen Cai, Mohammad Imtiaz Hasan, Jean-Michel Tine, Latifur Khan, Mizanur Rahman

+ [Toward Structured Knowledge Reasoning: Contrastive Retrieval-Augmented Generation on Experience](https://arxiv.org//abs/2506.00842)

	Jiawei Gu, Ziting Xian, Yuanzhen Xie, Ye Liu, Enjie Liu, Ruichao Zhong, Mochi Gao, Yunzhi Tan, Bo Hu, Zang Li

+ [Can AI Master Econometrics? Evidence from Econometrics AI Agent on Expert-Level Tasks](https://arxiv.org//abs/2506.00856)

	Qiang Chen, Tianyang Han, Jin Li, Ye Luo, Yuxiao Wu, Xiaowei Zhang, Tuo Zhou

+ [How do Transformer Embeddings Represent Compositions? A Functional Analysis](https://arxiv.org//abs/2506.00914)

	Aishik Nagar, Ishaan Singh Rawal, Mansi Dhanania, Cheston Tan

+ [Position as Probability: Self-Supervised Transformers that Think Past Their Training for Length Extrapolation](https://arxiv.org//abs/2506.00920)

	Philip Heejun Lee

+ [Legal Compliance Evaluation of Smart Contracts Generated By Large Language Models](https://arxiv.org//abs/2506.00943)

	Chanuka Wijayakoon, Hai Dong, H.M.N. Dilum Bandara, Zahir Tari, Anurag Soin

+ [Less is More: Local Intrinsic Dimensions of Contextual Language Models](https://arxiv.org//abs/2506.01034)

	Benjamin Matthias Ruppik, Julius von Rohrscheidt, Carel van Niekerk, Michael Heck, Renato Vukovic, Shutong Feng, Hsien-chin Lin, Nurul Lubis, Bastian Rieck, Marcus Zibrowius, Milica Gašić

+ [Probing Neural Topology of Large Language Models](https://arxiv.org//abs/2506.01042)

	Yu Zheng, Yuan Yuan, Yong Li, Paolo Santi

+ [Taming LLMs by Scaling Learning Rates with Gradient Grouping](https://arxiv.org//abs/2506.01049)

	Siyuan Li, Juanxi Tian, Zedong Wang, Xin Jin, Zicheng Liu, Wentao Zhang, Dan Xu

+ [SealQA: Raising the Bar for Reasoning in Search-Augmented Language Models](https://arxiv.org//abs/2506.01062)

	Thinh Pham, Nguyen Nguyen, Pratibha Zunjare, Weiyuan Chen, Yu-Min Tseng, Tu Vu

+ [Fighting Fire with Fire (F3): A Training-free and Efficient Visual Adversarial Example Purification Method in LVLMs](https://arxiv.org//abs/2506.01064)

	Yudong Zhang, Ruobing Xie, Yiqing Huang, Jiansheng Chen, Xingwu Sun, Zhanhui Kang, Di Wang, Yu Wang

+ [GThinker: Towards General Multimodal Reasoning via Cue-Guided Rethinking](https://arxiv.org//abs/2506.01078)

	Yufei Zhan, Ziheng Wu, Yousong Zhu, Rongkun Xue, Ruipu Luo, Zhenghao Chen, Can Zhang, Yifan Li, Zhentao He, Zheming Yang, Ming Tang, Minghui Qiu, Jinqiao Wang

+ [Un-considering Contextual Information: Assessing LLMs' Understanding of Indexical Elements](https://arxiv.org//abs/2506.01089)

	Metehan Oguz, Yavuz Bakman, Duygu Nur Yaldiz

+ [Reconsidering LLM Uncertainty Estimation Methods in the Wild](https://arxiv.org//abs/2506.01114)

	Yavuz Bakman, Duygu Nur Yaldiz, Sungmin Kang, Tuo Zhang, Baturalp Buyukates, Salman Avestimehr, Sai Praneeth Karimireddy

+ [From Words to Waves: Analyzing Concept Formation in Speech and Text-Based Foundation Models](https://arxiv.org//abs/2506.01133)

	Asım Ersoy, Basel Mousi, Shammur Chowdhury, Firoj Alam, Fahim Dalvi, Nadir Durrani

+ [Earley-Driven Dynamic Pruning for Efficient Structured Decoding](https://arxiv.org//abs/2506.01151)

	Xintong Sun, Chi Wei, Minghao Tian, Shiwen Ni

+ [Doubly Robust Alignment for Large Language Models](https://arxiv.org//abs/2506.01183)

	Erhan Xu, Kai Ye, Hongyi Zhou, Luhan Zhu, Francesco Quinzan, Chengchun Shi

+ [Incorporating Hierarchical Semantics in Sparse Autoencoder Architectures](https://arxiv.org//abs/2506.01197)

	Mark Muchane, Sean Richardson, Kiho Park, Victor Veitch

+ [Mamba Drafters for Speculative Decoding](https://arxiv.org//abs/2506.01206)

	Daewon Choi, Seunghyuk Oh, Saket Dingliwal, Jihoon Tack, Kyuyoung Kim, Woomin Song, Seojin Kim, Insu Han, Jinwoo Shin, Aram Galstyan, Shubham Katiyar, Sravan Babu Bodapati

+ [Understanding and Mitigating Cross-lingual Privacy Leakage via Language-specific and Universal Privacy Neurons](https://arxiv.org//abs/2506.00759)

	Wenshuo Dong, Qingsong Yang, Shu Yang, Lijie Hu, Meng Ding, Wanyu Lin, Tianhang Zheng, Di Wang

+ [Dynamic Chunking and Selection for Reading Comprehension of Ultra-Long Context in Large Language Models](https://arxiv.org//abs/2506.00773)

	Boheng Sheng, Jiacheng Yao, Meicong Zhang, Guoxiu He

+ [Improving Automatic Evaluation of Large Language Models (LLMs) in Biomedical Relation Extraction via LLMs-as-the-Judge](https://arxiv.org//abs/2506.00777)

	Md Tahmid Rahman Laskar, Israt Jahan, Elham Dolatabadi, Chun Peng, Enamul Hoque, Jimmy Huang

+ [Research Borderlands: Analysing Writing Across Research Cultures](https://arxiv.org//abs/2506.00784)

	Shaily Bhatt, Tal August, Maria Antoniak

+ [RARE: Retrieval-Aware Robustness Evaluation for Retrieval-Augmented Generation Systems](https://arxiv.org//abs/2506.00789)

	Yixiao Zeng, Tianyu Cao, Danqing Wang, Xinran Zhao, Zimeng Qiu, Morteza Ziyadi, Tongshuang Wu, Lei Li

+ [One for All: Update Parameterized Knowledge Across Multiple Models](https://arxiv.org//abs/2506.00817)

	Weitao Ma, Xiyuan Du, Xiaocheng Feng, Lei Huang, Yichong Huang, Huiyi Zhang, Xiaoliang Yang, Baohang Li, Xiachong Feng, Ting Liu, Bing Qin

+ [Probing the Geometry of Truth: Consistency and Generalization of Truth Directions in LLMs Across Logical Transformations and Question Answering Tasks](https://arxiv.org//abs/2506.00823)

	Yuntai Bao, Xuhong Zhang, Tianyu Du, Xinkui Zhao, Zhengwen Feng, Hao Peng, Jianwei Yin

+ [How Bidirectionality Helps Language Models Learn Better via Dynamic Bottleneck Estimation](https://arxiv.org//abs/2506.00859)

	Md Kowsher, Nusrat Jahan Prottasha, Shiyun Xu, Shetu Mohanto, Chen Chen, Niloofar Yousefi, Ozlem Garibay

+ [Not Every Token Needs Forgetting: Selective Unlearning to Limit Change in Utility in Large Language Model Unlearning](https://arxiv.org//abs/2506.00876)

	Yixin Wan, Anil Ramakrishna, Kai-Wei Chang, Volkan Cevher, Rahul Gupta

+ [Improve MLLM Benchmark Efficiency through Interview](https://arxiv.org//abs/2506.00883)

	Farong Wen, Yijin Guo, Junying Wang, Jiaohao Xiao, Yingjie Zhou, Chunyi Li, Zicheng Zhang, Guangtao Zhai

+ [SocialEval: Evaluating Social Intelligence of Large Language Models](https://arxiv.org//abs/2506.00900)

	Jinfeng Zhou, Yuxuan Chen, Yihan Shi, Xuanming Zhang, Leqi Lei, Yi Feng, Zexuan Xiong, Miao Yan, Xunzhi Wang, Yaru Cao, Jianing Yin, Shuai Wang, Quanyu Dai, Zhenhua Dong, Hongning Wang, Minlie Huang

+ [ACCESS DENIED INC: The First Benchmark Environment for Sensitivity Awareness](https://arxiv.org//abs/2506.00964)

	Dren Fazlija, Arkadij Orlov, Sandipan Sikdar

+ [XGUARD: A Graded Benchmark for Evaluating Safety Failures of Large Language Models on Extremist Content](https://arxiv.org//abs/2506.00973)

	Vadivel Abishethvarman, Bhavik Chandna, Pratik Jalan, Usman Naseem

+ [Talking to Data: Designing Smart Assistants for Humanities Databases](https://arxiv.org//abs/2506.00986)

	Alexander Sergeev, Valeriya Goloviznina, Mikhail Melnichenko, Evgeny Kotelnikov

+ [How Programming Concepts and Neurons Are Shared in Code Language Models](https://arxiv.org//abs/2506.01074)

	Amir Hossein Kargaran, Yihong Liu, François Yvon, Hinrich Schütze

+ [zip2zip: Inference-Time Adaptive Vocabularies for Language Models via Token Compression](https://arxiv.org//abs/2506.01084)

	Saibo Geng, Nathan Ranchin, Yunzhen yao, Maxime Peyrard, Chris Wendler, Michael Gastpar, Robert West

+ [Contextual Candor: Enhancing LLM Trustworthiness Through Hierarchical Unanswerability Detection](https://arxiv.org//abs/2506.01104)

	Steven Robinson, Antonio Carlos Rivera

+ [LAQuer: Localized Attribution Queries in Content-grounded Generation](https://arxiv.org//abs/2506.01187)

	Eran Hirsch, Aviv Slobodkin, David Wan, Elias Stengel-Eskin, Mohit Bansal, Ido Dagan

+ [Culturally-Grounded Chain-of-Thought (CG-CoT):Enhancing LLM Performance on Culturally-Specific Tasks in Low-Resource Languages](https://arxiv.org//abs/2506.01190)

	Madhavendra Thakur

+ [CoBRA: Quantifying Strategic Language Use and LLM Pragmatics](https://arxiv.org//abs/2506.01195)

	Anshun Asher Zheng, Junyi Jessy Li, David I. Beaver

+ [Trick or Neat: Adversarial Ambiguity and Language Model Evaluation](https://arxiv.org//abs/2506.01205)

	Antonia Karamolegkou, Oliver Eberle, Phillip Rust, Carina Kauf, Anders Søgaard

+ [Compress, Gather, and Recompute: REFORMing Long-Context Processing in Transformers](https://arxiv.org//abs/2506.01215)

	Woomin Song, Sai Muralidhar Jayanthi, Srikanth Ronanki, Kanthashree Mysore Sathyendra, Jinwoo Shin, Aram Galstyan, Shubham Katiyar, Sravan Babu Bodapati

+ [Simple Prompt Injection Attacks Can Leak Personal Data Observed by LLM Agents During Task Execution](https://arxiv.org//abs/2506.01055)

	Meysam Alizadeh, Zeynab Samei, Daria Stetsenko, Fabrizio Gilardi

+ [Attention Retrieves, MLP Memorizes: Disentangling Trainable Components in the Transformer](https://arxiv.org//abs/2506.01115)

	Yihe Dong, Lorenzo Noci, Mikhail Khodak, Mufan Li

+ [GOBench: Benchmarking Geometric Optics Generation and Understanding of MLLMs](https://arxiv.org//abs/2506.00991)

	Xiaorong Zhu, Ziheng Jia, Jiarui Wang, Xiangyu Zhao, Haodong Duan, Xiongkuo Min, Jia Wang, Zicheng Zhang, Guangtao Zhai

+ [NavBench: Probing Multimodal Large Language Models for Embodied Navigation](https://arxiv.org//abs/2506.01031)

	Yanyuan Qiao, Haodong Hong, Wenqi Lyu, Dong An, Siqi Zhang, Yutong Xie, Xinyu Wang, Qi Wu

+ [Generic Token Compression in Multimodal Large Language Models from an Explainability Perspective](https://arxiv.org//abs/2506.01097)

	Lei Lei, Jie Gu, Xiaokang Ma, Chu Tang, Jingmin Chen, Tong Xu

+ [Revolutionizing Radiology Workflow with Factual and Efficient CXR Report Generation](https://arxiv.org//abs/2506.01118)

	Pimchanok Sukjai, Apiradee Boonmee

+ [Uni-LoRA: One Vector is All You Need](https://arxiv.org//abs/2506.00799)

	Kaiyang Li, Shaobo Han, Qing Su, Wei Li, Zhipeng Cai, Shihao Ji

+ [LoRA-BAM: Input Filtering for Fine-tuned LLMs via Boxed Abstraction Monitors over LoRA Layers](https://arxiv.org//abs/2506.00998)

	Changshun Wu, Tianyi Duan, Saddek Bensalem, Chih-Hong Cheng

+ [Language-Guided Multi-Agent Learning in Simulations: A Unified Framework and Evaluation](https://arxiv.org//abs/2506.04251)

	Zhengyang Li

+ [A Graph-Retrieval-Augmented Generation Framework Enhances Decision-Making in the Circular Economy](https://arxiv.org//abs/2506.04252)

	Yang Zhao, Chengxiao Dai, Dusit Niyato, Chuan Fu Tan, Keyi Xiang, Yueyang Wang, Zhiquan Yeo, Daren Tan Zong Loong, Jonathan Low Zhaozhi, Eugene H.Z. HO

+ [HADA: Human-AI Agent Decision Alignment Architecture](https://arxiv.org//abs/2506.04253)

	Tapio Pitkäranta, Leena Pitkäranta

+ [SafeSteer: Interpretable Safety Steering with Refusal-Evasion in LLMs](https://arxiv.org//abs/2506.04250)

	Shaona Ghosh, Amrita Bhattacharjee, Yftah Ziser, Christopher Parisien

+ [Designing DSIC Mechanisms for Data Sharing in the Era of Large Language Models](https://arxiv.org//abs/2506.05379)

	Seyed Moein Ayyoubzadeh, Kourosh Shahnazari, Mohammmadali Keshtparvar, MohammadAmin Fazli

+ [Generalizable LLM Learning of Graph Synthetic Data with Reinforcement Learning](https://arxiv.org//abs/2506.00845)

	Yizhuo Zhang, Heng Wang, Shangbin Feng, Zhaoxuan Tan, Xinyun Liu, Yulia Tsvetkov

+ [Deontological Keyword Bias: The Impact of Modal Expressions on Normative Judgments of Language Models](https://arxiv.org//abs/2506.11068)

	Bumjin Park, Jinsil Lee, Jaesik Choi

# 2025-05-31
+ [Dyna-Think: Synergizing Reasoning, Acting, and World Model Simulation in AI Agents](https://arxiv.org//abs/2506.00320)

	Xiao Yu, Baolin Peng, Ruize Xu, Michel Galley, Hao Cheng, Suman Nath, Jianfeng Gao, Zhou Yu

+ [MIRROR: Cognitive Inner Monologue Between Conversational Turns for Persistent Reflection and Reasoning in Conversational LLMs](https://arxiv.org//abs/2506.00430)

	Nicole Hsing

+ [A "Wenlu" Brain System for Multimodal Cognition and Embodied Decision-Making: A Secure New Architecture for Deep Integration of Foundation Models and Domain Knowledge](https://arxiv.org//abs/2506.00570)

	Liang Geng

+ [Reasoning Like an Economist: Post-Training on Economic Problems Induces Strategic Generalization in LLMs](https://arxiv.org//abs/2506.00577)

	Yufa Zhou, Shaobo Wang, Xingyu Dong, Xiangqi Jin, Yifang Chen, Yue Min, Kexin Yang, Xingzhang Ren, Dayiheng Liu, Linfeng Zhang

+ [Do Language Models Mirror Human Confidence? Exploring Psychological Insights to Address Overconfidence in LLMs](https://arxiv.org//abs/2506.00582)

	Chenjun Xu, Bingbing Wen, Bin Han, Robert Wolfe, Lucy Lu Wang, Bill Howe

+ [RiOSWorld: Benchmarking the Risk of Multimodal Compter-Use Agents](https://arxiv.org//abs/2506.00618)

	Jingyi Yang, Shuai Shao, Dongrui Liu, Jing Shao

+ [AgentAuditor: Human-Level Safety and Security Evaluation for LLM Agents](https://arxiv.org//abs/2506.00641)

	Hanjun Luo, Shenyu Dai, Chiming Ni, Xinfeng Li, Guibin Zhang, Kun Wang, Tongliang Liu, Hanan Salam

+ [OntoRAG: Enhancing Question-Answering through Automated Ontology Derivation from Unstructured Knowledge Bases](https://arxiv.org//abs/2506.00664)

	Yash Tiwari, Owais Ahmad Lone, Mayukha Pal

+ [DrKGC: Dynamic Subgraph Retrieval-Augmented LLMs for Knowledge Graph Completion across General and Biomedical Domains](https://arxiv.org//abs/2506.00708)

	Yongkang Xiao, Sinian Zhang, Yi Dai, Huixue Zhou, Jue Hou, Jie Ding, Rui Zhang

+ [Alignment Revisited: Are Large Language Models Consistent in Stated and Revealed Preferences?](https://arxiv.org//abs/2506.00751)

	Zhuojun Gu, Quan Wang, Shuchu Han

+ [Efficient Latent Semantic Clustering for Scaling Test-Time Computation of LLMs](https://arxiv.org//abs/2506.00344)

	Sungjae Lee, Hoyoung Kim, Jeongyeon Hwang, Eunhyeok Park, Jungseul Ok

+ [Scaling Textual Gradients via Sampling-Based Momentum](https://arxiv.org//abs/2506.00400)

	Zixin Ding, Junyuan Hong, Jiachen T. Wang, Zinan Lin, Zhangyang Wang, Yuxin Chen

+ [Accelerating Diffusion LLMs via Adaptive Parallel Decoding](https://arxiv.org//abs/2506.00413)

	Daniel Israel, Guy Van den Broeck, Aditya Grover

+ [Wide Reflective Equilibrium in LLM Alignment: Bridging Moral Epistemology and AI Safety](https://arxiv.org//abs/2506.00415)

	Matthew Brophy

+ [Dual Debiasing for Noisy In-Context Learning for Text Generation](https://arxiv.org//abs/2506.00418)

	Siqi Liang, Sumyeong Ahn, Paramveer S. Dhillon, Jiayu Zhou

+ [RLAE: Reinforcement Learning-Assisted Ensemble for LLMs](https://arxiv.org//abs/2506.00439)

	Yuqian Fu, Yuanheng Zhu, Jiajun Chai, Guojun Yin, Wei Lin, Qichao Zhang, Dongbin Zhao

+ [BenchHub: A Unified Benchmark Suite for Holistic and Customizable LLM Evaluation](https://arxiv.org//abs/2506.00482)

	Eunsu Kim, Haneul Yoo, Guijin Son, Hitesh Patel, Amit Agarwal, Alice Oh

+ [It Takes a Good Model to Train a Good Model: Generalized Gaussian Priors for Optimized LLMs](https://arxiv.org//abs/2506.00486)

	Jun Wu, Yirong Xiong, Jiangtao Wen, Yuxing Han

+ [CausalAbstain: Enhancing Multilingual LLMs with Causal Reasoning for Trustworthy Abstention](https://arxiv.org//abs/2506.00519)

	Yuxi Sun, Aoqi Zuo, Wei Gao, Jing Ma

+ [Retrieval-Augmented Generation Systems for Intellectual Property via Synthetic Multi-Angle Fine-tuning](https://arxiv.org//abs/2506.00527)

	Runtao Ren, Jian Ma, Jianxi Luo

+ [The Security Threat of Compressed Projectors in Large Vision-Language Models](https://arxiv.org//abs/2506.00534)

	Yudong Zhang, Ruobing Xie, Xingwu Sun, Jiansheng Chen, Zhanhui Kang, Di Wang, Yu Wang

+ [Decoupling Reasoning and Knowledge Injection for In-Context Knowledge Editing](https://arxiv.org//abs/2506.00536)

	Changyue Wang, Weihang Su, Qingyao Ai, Yujia Zhou, Yiqun Liu

+ [AnnaAgent: Dynamic Evolution Agent System with Multi-Session Memory for Realistic Seeker Simulation](https://arxiv.org//abs/2506.00551)

	Ming Wang, Peidong Wang, Lin Wu, Xiaocui Yang, Daling Wang, Shi Feng, Yuxin Chen, Bixuan Wang, Yifei Zhang

+ [MMedAgent-RL: Optimizing Multi-Agent Collaboration for Multimodal Medical Reasoning](https://arxiv.org//abs/2506.00555)

	Peng Xia, Jinglu Wang, Yibo Peng, Kaide Zeng, Xian Wu, Xiangru Tang, Hongtu Zhu, Yun Li, Shujie Liu, Yan Lu, Huaxiu Yao

+ [Prompt-Tuned LLM-Augmented DRL for Dynamic O-RAN Network Slicing](https://arxiv.org//abs/2506.00574)

	Fatemeh Lotfi, Hossein Rajoli, Fatemeh Afghah

+ [ORAN-GUIDE: RAG-Driven Prompt Learning for LLM-Augmented Reinforcement Learning in O-RAN Network Slicing](https://arxiv.org//abs/2506.00576)

	Fatemeh Lotfi, Hossein Rajoli, Fatemeh Afghah

+ [Improving the Calibration of Confidence Scores in Text Generation Using the Output Distribution's Characteristics](https://arxiv.org//abs/2506.00637)

	Lorenzo Jaime Yu Flores, Ori Ernst, Jackie Chi Kit Cheung

+ [SATA-BENCH: Select All That Apply Benchmark for Multiple Choice Questions](https://arxiv.org//abs/2506.00643)

	Weijie Xu, Shixian Cui, Xi Fang, Chi Xue, Stephanie Eckman, Chandan Reddy

+ [Linear Representation Transferability Hypothesis: Leveraging Small Models to Steer Large Models](https://arxiv.org//abs/2506.00653)

	Femi Bello, Anubrata Das, Fanzhi Zeng, Fangcong Yin, Leqi Liu

+ [SafeTuneBed: A Toolkit for Benchmarking LLM Safety Alignment in Fine-Tuning](https://arxiv.org//abs/2506.00676)

	Saad Hossain, Samanvay Vajpayee, Sirisha Rambhatla

+ [Existing Large Language Model Unlearning Evaluations Are Inconclusive](https://arxiv.org//abs/2506.00688)

	Zhili Feng, Yixuan Even Xu, Alexander Robey, Robert Kirk, Xander Davies, Yarin Gal, Avi Schwarzschild, J. Zico Kolter

+ [Measuring Faithfulness and Abstention: An Automated Pipeline for Evaluating LLM-Generated 3-ply Case-Based Legal Arguments](https://arxiv.org//abs/2506.00694)

	Li Zhang, Morgan Gray, Jaromir Savelka, Kevin D. Ashley

+ [Bayesian Inference of Training Dataset Membership](https://arxiv.org//abs/2506.00701)

	Yongchao Huang

+ [QoQ-Med: Building Multimodal Clinical Foundation Models with Domain-Aware GRPO Training](https://arxiv.org//abs/2506.00711)

	Wei Dai, Peilin Chen, Chanakya Ekbote, Paul Pu Liang

+ [An LLM Agent for Functional Bug Detection in Network Protocols](https://arxiv.org//abs/2506.00714)

	Mingwei Zheng, Chengpeng Wang, Xuwei Liu, Jinyao Guo, Shiwei Feng, Xiangyu Zhang

+ [Pitfalls in Evaluating Language Model Forecasters](https://arxiv.org//abs/2506.00723)

	Daniel Paleka, Shashwat Goel, Jonas Geiping, Florian Tramèr

+ [Assortment of Attention Heads: Accelerating Federated PEFT with Head Pruning and Strategic Client Selection](https://arxiv.org//abs/2506.00743)

	Yeshwanth Venkatesha, Souvik Kundu, Priyadarshini Panda

+ [SkillVerse : Assessing and Enhancing LLMs with Tree Evaluation](https://arxiv.org//abs/2506.00319)

	Yufei Tian, Jiao Sun, Nanyun Peng, Zizhao Zhang

+ [TreeRare: Syntax Tree-Guided Retrieval and Reasoning for Knowledge-Intensive Question Answering](https://arxiv.org//abs/2506.00331)

	Boyi Zhang, Zhuo Liu, Hangfeng He

+ [Beyond Context to Cognitive Appraisal: Emotion Reasoning as a Theory of Mind Benchmark for Large Language Models](https://arxiv.org//abs/2506.00334)

	Gerard Christopher Yeo, Kokil Jaidka

+ [SHARE: An SLM-based Hierarchical Action CorREction Assistant for Text-to-SQL](https://arxiv.org//abs/2506.00391)

	Ge Qu, Jinyang Li, Bowen Qin, Xiaolong Li, Nan Huo, Chenhao Ma, Reynold Cheng

+ [Speculative Reward Model Boosts Decision Making Ability of LLMs Cost-Effectively](https://arxiv.org//abs/2506.00396)

	Jiawei Gu, Shangsong Liang

+ [Inter-Passage Verification for Multi-evidence Multi-answer QA](https://arxiv.org//abs/2506.00425)

	Bingsen Chen, Shengjie Wang, Xi Ye, Chen Zhao

+ [G2S: A General-to-Specific Learning Framework for Temporal Knowledge Graph Forecasting with Large Language Models](https://arxiv.org//abs/2506.00445)

	Long Bai, Zixuan Li, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng, Tat-Seng Chua

+ [Fact-Controlled Diagnosis of Hallucinations in Medical Text Summarization](https://arxiv.org//abs/2506.00448)

	Suhas BN, Han-Chin Shing, Lei Xu, Mitch Strong, Jon Burnsky, Jessica Ofor, Jordan R. Mason, Susan Chen, Sundararajan Srinivasan, Chaitanya Shivade, Jack Moriarty, Joseph Paul Cohen

+ [Massively Multilingual Adaptation of Large Language Models Using Bilingual Translation Data](https://arxiv.org//abs/2506.00469)

	Shaoxiong Ji, Zihao Li, Jaakko Paavola, Indraneil Paul, Hengyu Luo, Jörg Tiedemann

+ [Auto-Patching: Enhancing Multi-Hop Reasoning in Language Models](https://arxiv.org//abs/2506.00483)

	Aviv Jan, Dean Tahory, Omer Talmi, Omar Abo Mokh

+ [Synergizing LLMs with Global Label Propagation for Multimodal Fake News Detection](https://arxiv.org//abs/2506.00488)

	Shuguo Hu, Jun Hu, Huaiwen Zhang

+ [Goal-Aware Identification and Rectification of Misinformation in Multi-Agent Systems](https://arxiv.org//abs/2506.00509)

	Zherui Li, Yan Mi, Zhenhong Zhou, Houcheng Jiang, Guibin Zhang, Kun Wang, Junfeng Fang

+ [ARIA: Training Language Agents with Intention-Driven Reward Aggregation](https://arxiv.org//abs/2506.00539)

	Ruihan Yang, Yikai Zhang, Aili Chen, Xintao Wang, Siyu Yuan, Jiangjie Chen, Deqing Yang, Yanghua Xiao

+ [Entriever: Energy-based Retriever for Knowledge-Grounded Dialog Systems](https://arxiv.org//abs/2506.00585)

	Yucheng Cai, Ke Li, Yi Huang, Junlan Feng, Zhijian Ou

+ [PAKTON: A Multi-Agent Framework for Question Answering in Long Legal Agreements](https://arxiv.org//abs/2506.00608)

	Petros Raptopoulos, Giorgos Filandrianos, Maria Lymperaiou, Giorgos Stamou

+ [Enhancing Clinical Multiple-Choice Questions Benchmarks with Knowledge Graph Guided Distractor Generation](https://arxiv.org//abs/2506.00612)

	Running Yang, Wenlong Deng, Minghui Chen, Yuyin Zhou, Xiaoxiao Li

+ [SafeTy Reasoning Elicitation Alignment for Multi-Turn Dialogues](https://arxiv.org//abs/2506.00668)

	Martin Kuo, Jianyi Zhang, Aolin Ding, Louis DiValentin, Amin Hass, Benjamin F Morris, Isaac Jacobson, Randolph Linderman, James Kiessling, Nicolas Ramos, Bhavna Gopal, Maziyar Baran Pouyan, Changwei Liu, Hai Li, Yiran Chen

+ [DeepRAG: Integrating Hierarchical Reasoning and Process Supervision for Biomedical Multi-Hop QA](https://arxiv.org//abs/2506.00671)

	Yuelyu Ji, Hang Zhang, Shiven Verma, Hui Ji, Chun Li, Yushui Han, Yanshan Wang

+ [Structured Gradient Guidance for Few-Shot Adaptation in Large Language Models](https://arxiv.org//abs/2506.00726)

	Hongye Zheng, Yichen Wang, Ray Pan, Guiran Liu, Binrong Zhu, Hanlu Zhang

+ [DefenderBench: A Toolkit for Evaluating Language Agents in Cybersecurity Environments](https://arxiv.org//abs/2506.00739)

	Chiyu Zhang, Marc-Alexandre Cote, Michael Albada, Anush Sankaran, Jack W. Stokes, Tong Wang, Amir Abdi, William Blum, Muhammad Abdul-Mageed

+ [Data Swarms: Optimizable Generation of Synthetic Evaluation Data](https://arxiv.org//abs/2506.00741)

	Shangbin Feng, Yike Wang, Weijia Shi, Yulia Tsvetkov

+ [Translate With Care: Addressing Gender Bias, Neutrality, and Reasoning in Large Language Model Translations](https://arxiv.org//abs/2506.00748)

	Pardis Sadat Zahraei, Ali Emami

+ [Adapting General-Purpose Embedding Models to Private Datasets Using Keyword-based Retrieval](https://arxiv.org//abs/2506.00363)

	Yubai Wei, Jiale Han, Yi Yang

+ [Spectral Insights into Data-Oblivious Critical Layers in Large Language Models](https://arxiv.org//abs/2506.00382)

	Xuyuan Liu, Lei Hsiung, Yaoqing Yang, Yujun Yan

+ [FLoE: Fisher-Based Layer Selection for Efficient Sparse Adaptation of Low-Rank Experts](https://arxiv.org//abs/2506.00495)

	Xinyi Wang, Lirong Gao, Haobo Wang, Yiming Zhang, Junbo Zhao

+ [Con Instruction: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities](https://arxiv.org//abs/2506.00548)

	Jiahui Geng, Thy Thy Tran, Preslav Nakov, Iryna Gurevych

+ [Chain-of-Frames: Advancing Video Understanding in Multimodal LLMs via Frame-Aware Reasoning](https://arxiv.org//abs/2506.00318)

	Sara Ghazanfari, Francesco Croce, Nicolas Flammarion, Prashanth Krishnamurthy, Farshad Khorrami, Siddharth Garg

+ [AutoMixAlign: Adaptive Data Mixing for Multi-Task Preference Optimization in LLMs](https://arxiv.org//abs/2506.00569)

	Nicholas E. Corrado, Julian Katz-Samuels, Adithya Devraj, Hyokun Yun, Chao Zhang, Yi Xu, Yi Pan, Bing Yin, Trishul Chilimbi

+ [Model Reprogramming Demystified: A Neural Tangent Kernel Perspective](https://arxiv.org//abs/2506.00620)

	Ming-Yu Chung, Jiashuo Fan, Hancheng Ye, Qinsi Wang, Wei-Chen Shen, Chia-Mu Yu, Pin-Yu Chen, Sy-Yen Kuo

+ [Blending Complementary Memory Systems in Hybrid Quadratic-Linear Transformers](https://arxiv.org//abs/2506.00744)

	Kazuki Irie, Morris Yau, Samuel J. Gershman

+ [MINT: Memory-Infused Prompt Tuning at Test-time for CLIP](https://arxiv.org//abs/2506.03190)

	Jiaming Yi, Ruirui Pan, Jishen Yang, Xiulong Yang

+ [Beyond the Protocol: Unveiling Attack Vectors in the Model Context Protocol Ecosystem](https://arxiv.org//abs/2506.02040)

	Hao Song, Yiming Shen, Wenxuan Luo, Leixin Guo, Ting Chen, Jiashui Wang, Beibei Li, Xiaosong Zhang, Jiachi Chen

+ [Organizational Adaptation to Generative AI in Cybersecurity: A Systematic Review](https://arxiv.org//abs/2506.12060)

	Christopher Nott

# 2025-05-30
+ [SCOUT: Teaching Pre-trained Language Models to Enhance Reasoning via Flow Chain-of-Thought](https://arxiv.org//abs/2505.24181)

	Guanghao Li, Wenhao Jiang, Mingfeng Chen, Yan Li, Hao Yu, Shuting Dong, Tao Ren, Ming Tang, Chun Yuan

+ [Learning API Functionality from Demonstrations for Tool-based Agents](https://arxiv.org//abs/2505.24197)

	Bhrij Patel, Ashish Jagmohan, Aditya Vempaty

+ [SentinelAgent: Graph-based Anomaly Detection in Multi-Agent Systems](https://arxiv.org//abs/2505.24201)

	Xu He, Di Wu, Yan Zhai, Kun Sun

+ [Bootstrapping LLM Robustness for VLM Safety via Reducing the Pretraining Modality Gap](https://arxiv.org//abs/2505.24208)

	Wenhan Yang, Spencer Stice, Ali Payani, Baharan Mirzasoleiman

+ [E^2GraphRAG: Streamlining Graph-based RAG for High Efficiency and Effectiveness](https://arxiv.org//abs/2505.24226)

	Yibo Zhao, Jiapeng Zhu, Ye Guo, Kangkang He, Xiang Li

+ [ProofNet++: A Neuro-Symbolic System for Formal Proof Verification with Self-Correction](https://arxiv.org//abs/2505.24230)

	Murari Ambati

+ [FABLE: A Novel Data-Flow Analysis Benchmark on Procedural Text for Large Language Model Evaluation](https://arxiv.org//abs/2505.24258)

	Vishal Pallagani, Nitin Gupta, John Aydin, Biplav Srivastava

+ [How Much Backtracking is Enough? Exploring the Interplay of SFT and RL in Enhancing LLM Reasoning](https://arxiv.org//abs/2505.24273)

	Hongyi James Cai, Junlin Wang, Xiaoyin Chen, Bhuwan Dhingra

+ [Mind the Quote: Enabling Quotation-Aware Dialogue in LLMs via Plug-and-Play Modules](https://arxiv.org//abs/2505.24292)

	Yueqi Zhang, Peiwen Yuan, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Jiayi Shi, Chuyi Tan, Boyuan Pan, Yao Hu, Kan Li

+ [GridRoute: A Benchmark for LLM-Based Route Planning with Cardinal Movement in Grid Environments](https://arxiv.org//abs/2505.24306)

	Kechen Li, Yaotian Tao, Ximing Wen, Quanwei Sun, Zifei Gong, Chang Xu, Xizhe Zhang, Tianbo Ji

+ [RMoA: Optimizing Mixture-of-Agents through Diversity Maximization and Residual Compensation](https://arxiv.org//abs/2505.24442)

	Zhentao Xie, Chengcheng Han, Jinxin Shi, Wenjun Cui, Xin Zhao, Xingjiao Wu, Jiabao Zhao

+ [SEAR: A Multimodal Dataset for Analyzing AR-LLM-Driven Social Engineering Behaviors](https://arxiv.org//abs/2505.24458)

	Tianlong Yu, Chenghang Ye, Zheyu Yang, Ziyi Zhou, Cui Tang, Zui Tao, Jun Zhang, Kailong Wang, Liting Zhou, Yang Yang, Ting Bi

+ [Optimizing the Interface Between Knowledge Graphs and LLMs for Complex Reasoning](https://arxiv.org//abs/2505.24478)

	Vasilije Markovic, Lazar Obradovic, Laszlo Hajdu, Jovan Pavlovic

+ [Leveraging Knowledge Graphs and LLMs for Structured Generation of Misinformation](https://arxiv.org//abs/2505.24479)

	Sania Nayab, Marco Simoni, Giulio Rossolini

+ [MiCRo: Mixture Modeling and Context-aware Routing for Personalized Preference Learning](https://arxiv.org//abs/2505.24846)

	Jingyan Shen, Jiarui Yao, Rui Yang, Yifan Sun, Feng Luo, Rui Pan, Tong Zhang, Han Zhao

+ [Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents](https://arxiv.org//abs/2505.24878)

	Yaxin Luo, Zhaoyi Li, Jiacheng Liu, Jiacheng Cui, Xiaohan Zhao, Zhiqiang Shen

+ [R-KV: Redundancy-aware KV Cache Compression for Training-Free Reasoning Models Acceleration](https://arxiv.org//abs/2505.24133)

	Zefan Cai, Wen Xiao, Hanshi Sun, Cheng Luo, Yikai Zhang, Ke Wan, Yucheng Li, Yeyang Zhou, Li-Wen Chang, Jiuxiang Gu, Zhen Dong, Anima Anandkumar, Abedelkadir Asi, Junjie Hu

+ [The Butterfly Effect in Pathology: Exploring Security in Pathology Foundation Models](https://arxiv.org//abs/2505.24141)

	Jiashuai Liu, Yingjia Shang, Yingkang Zhan, Di Zhang, Yi Niu, Dong Wei, Xian Wu, Zeyu Gao, Chen Li, Yefeng Zheng

+ [Don't Just Follow MLLM Plans: Robust and Efficient Planning for Open-world Agents](https://arxiv.org//abs/2505.24157)

	Seungjoon Lee, Suhwan Kim, Minhyeon Oh, Youngsik Yoon, Jungseul Ok

+ [LKD-KGC: Domain-Specific KG Construction via LLM-driven Knowledge Dependency Parsing](https://arxiv.org//abs/2505.24163)

	Jiaqi Sun, Shiyou Qian, Zhangchi Han, Wei Li, Zelin Qian, Dingyu Yang, Jian Cao, Guangtao Xue

+ [SALE : Low-bit Estimation for Efficient Sparse Attention in Long-context LLM Prefilling](https://arxiv.org//abs/2505.24179)

	Xiaodong Ji, Hailin Zhang, Fangcheng Fu, Bin Cui

+ [Reasoning Can Hurt the Inductive Abilities of Large Language Models](https://arxiv.org//abs/2505.24225)

	Haibo Jin, Peiyan Zhang, Man Luo, Haohan Wang

+ [From Hallucinations to Jailbreaks: Rethinking the Vulnerability of Large Foundation Models](https://arxiv.org//abs/2505.24232)

	Haibo Jin, Peiyan Zhang, Peiran Wang, Man Luo, Haohan Wang

+ [An Adversary-Resistant Multi-Agent LLM System via Credibility Scoring](https://arxiv.org//abs/2505.24239)

	Sana Ebrahimi, Mohsen Dehghankar, Abolfazl Asudeh

+ [Effects of Theory of Mind and Prosocial Beliefs on Steering Human-Aligned Behaviors of LLMs in Ultimatum Games](https://arxiv.org//abs/2505.24255)

	Neemesh Yadav, Palakorn Achananuparp, Jing Jiang, Ee-Peng Lim

+ [Faithful and Robust LLM-Driven Theorem Proving for NLI Explanations](https://arxiv.org//abs/2505.24264)

	Xin Quan, Marco Valentino, Louise A. Dennis, André Freitas

+ [Large Language Models are Locally Linear Mappings](https://arxiv.org//abs/2505.24293)

	James R. Golden

+ [AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning](https://arxiv.org//abs/2505.24298)

	Wei Fu, Jiaxuan Gao, Xujie Shen, Chen Zhu, Zhiyu Mei, Chuyi He, Shusheng Xu, Guo Wei, Jun Mei, Jiashu Wang, Tongkai Yang, Binhang Yuan, Yi Wu

+ [ReCalKV: Low-Rank KV Cache Compression via Head Reordering and Offline Calibration](https://arxiv.org//abs/2505.24357)

	Xianglong Yan, Zhiteng Li, Tianao Zhang, Linghe Kong, Yulun Zhang, Xiaokang Yang

+ [Adversarial Preference Learning for Robust LLM Alignment](https://arxiv.org//abs/2505.24369)

	Yuanfu Wang, Pengyu Wang, Chenyang Xi, Bo Tang, Junyi Zhu, Wenqiang Wei, Chen Chen, Chao Yang, Jingfeng Zhang, Chaochao Lu, Yijun Niu, Keming Mao, Zhiyu Li, Feiyu Xiong, Jie Hu, Mingchuan Yang

+ [Breaking the Gold Standard: Extracting Forgotten Data under Exact Unlearning in Large Language Models](https://arxiv.org//abs/2505.24379)

	Xiaoyu Wu, Yifei Pang, Terrance Liu, Zhiwei Steven Wu

+ [LLMs Are Globally Multilingual Yet Locally Monolingual: Exploring Knowledge Transfer via Language and Thought Theory](https://arxiv.org//abs/2505.24409)

	Eojin Kang, Juae Kim

+ [Learning Safety Constraints for Large Language Models](https://arxiv.org//abs/2505.24445)

	Xin Chen, Yarden As, Andreas Krause

+ [LPASS: Linear Probes as Stepping Stones for vulnerability detection using compressed LLMs](https://arxiv.org//abs/2505.24451)

	Luis Ibanez-Lissen, Lorena Gonzalez-Manzano, Jose Maria de Fuentes, Nicolas Anciaux

+ [TimeHC-RL: Temporal-aware Hierarchical Cognitive Reinforcement Learning for Enhancing LLMs' Social Intelligence](https://arxiv.org//abs/2505.24500)

	Guiyang Hou, Xing Gao, Yuchuan Wu, Xiang Huang, Wenqi Zhang, Zhe Zheng, Yongliang Shen, Jialu Du, Fei Huang, Yongbin Li, Weiming Lu

+ [Can Slow-thinking LLMs Reason Over Time? Empirical Studies in Time Series Forecasting](https://arxiv.org//abs/2505.24511)

	Jiahao Wang, Mingyue Cheng, Qi Liu

+ [Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors](https://arxiv.org//abs/2505.24523)

	Andrea Pedrotti, Michele Papucci, Cristiano Ciaccio, Alessio Miaschi, Giovanni Puccetti, Felice Dell'Orletta, Andrea Esuli

+ [Beyond Linear Steering: Unified Multi-Attribute Control for Language Models](https://arxiv.org//abs/2505.24535)

	Narmeen Oozeer, Luke Marks, Fazl Barez, Amirali Abdullah

+ [Localizing Persona Representations in LLMs](https://arxiv.org//abs/2505.24539)

	Celia Cintas, Miriam Rateike, Erik Miehling, Elizabeth Daly, Skyler Speakman

+ [Cross-Attention Speculative Decoding](https://arxiv.org//abs/2505.24544)

	Wei Zhong, Manasa Bharadwaj, Yixiao Wang, Nikhil Verma, Yipeng Ji, Chul Lee

+ [CREFT: Sequential Multi-Agent LLM for Character Relation Extraction](https://arxiv.org//abs/2505.24553)

	Ye Eun Chun, Taeyoon Hwang, Seung-won Hwang, Byung-Hak Kim

+ [NexusSum: Hierarchical LLM Agents for Long-Form Narrative Summarization](https://arxiv.org//abs/2505.24575)

	Hyuntak Kim, Byung-Hak Kim

+ [Decoding Knowledge Attribution in Mixture-of-Experts: A Framework of Basic-Refinement Collaboration and Efficiency Analysis](https://arxiv.org//abs/2505.24593)

	Junzhuo Li, Bo Wang, Xiuze Zhou, Peijie Jiang, Jia Liu, Xuming Hu

+ [Eye of Judgement: Dissecting the Evaluation of Russian-speaking LLMs with POLLUX](https://arxiv.org//abs/2505.24616)

	Nikita Martynov, Anastasia Mordasheva, Dmitriy Gorbetskiy, Danil Astafurov, Ulyana Isaeva, Elina Basyrova, Sergey Skachkov, Victoria Berestova, Nikolay Ivanov, Valeriia Zanina, Alena Fenogenova

+ [The Hallucination Dilemma: Factuality-Aware Reinforcement Learning for Large Reasoning Models](https://arxiv.org//abs/2505.24630)

	Junyi Li, Hwee Tou Ng

+ [BIMA: Bijective Maximum Likelihood Learning Approach to Hallucination Prediction and Mitigation in Large Vision-Language Models](https://arxiv.org//abs/2505.24649)

	Huu-Thien Tran, Thanh-Dat Truong, Khoa Luu

+ [Multiple LLM Agents Debate for Equitable Cultural Alignment](https://arxiv.org//abs/2505.24671)

	Dayeon Ki, Rachel Rudinger, Tianyi Zhou, Marine Carpuat

+ [Causal-aware Large Language Models: Enhancing Decision-Making Through Learning, Adapting and Acting](https://arxiv.org//abs/2505.24710)

	Wei Chen, Jiahao Zhang, Haipeng Zhu, Boyan Xu, Zhifeng Hao, Keli Zhang, Junjian Ye, Ruichu Cai

+ [CoRet: Improved Retriever for Code Editing](https://arxiv.org//abs/2505.24715)

	Fabio Fehr, Prabhu Teja Sivaprasad, Luca Franceschi, Giovanni Zappella

+ [HELM: Hyperbolic Large Language Models via Mixture-of-Curvature Experts](https://arxiv.org//abs/2505.24722)

	Neil He, Rishabh Anand, Hiren Madhu, Ali Maatouk, Smita Krishnaswamy, Leandros Tassiulas, Menglin Yang, Rex Ying

+ [Drop Dropout on Single-Epoch Language Model Pretraining](https://arxiv.org//abs/2505.24788)

	Houjun Liu, John Bauer, Christopher D. Manning

+ [PhySense: Principle-Based Physics Reasoning Benchmarking for Large Language Models](https://arxiv.org//abs/2505.24823)

	Yinggan Xu, Yue Liu, Zhiqiang Gao, Changnan Peng, Di Luo

+ [Improving Reliability and Explainability of Medical Question Answering through Atomic Fact Checking in Retrieval-Augmented LLMs](https://arxiv.org//abs/2505.24830)

	Juraj Vladika, Annika Domres, Mai Nguyen, Rebecca Moser, Jana Nano, Felix Busch, Lisa C. Adams, Keno K. Bressem, Denise Bernhardt, Stephanie E. Combs, Kai J. Borm, Florian Matthes, Jan C. Peeken

+ [Harnessing Negative Signals: Reinforcement Distillation from Teacher Data for LLM Reasoning](https://arxiv.org//abs/2505.24850)

	Shuyao Xu, Cheng Peng, Jiangxuan Long, Weidi Xu, Wei Chu, Yuan Qi

+ [ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in Large Language Models](https://arxiv.org//abs/2505.24864)

	Mingjie Liu, Shizhe Diao, Ximing Lu, Jian Hu, Xin Dong, Yejin Choi, Jan Kautz, Yi Dong

+ [HardTests: Synthesizing High-Quality Test Cases for LLM Coding](https://arxiv.org//abs/2505.24098)

	Zhongmou He, Yee Man Choi, Kexun Zhang, Jiabao Ji, Junting Zhou, Dejia Xu, Ivan Bercovich, Aidan Zhang, Lei Li

+ [Training LLMs for EHR-Based Reasoning Tasks via Reinforcement Learning](https://arxiv.org//abs/2505.24105)

	Jiacheng Lin, Zhenbang Wu, Jimeng Sun

+ [The State of Multilingual LLM Safety Research: From Measuring the Language Gap to Mitigating It](https://arxiv.org//abs/2505.24119)

	Zheng-Xin Yong, Beyza Ermis, Marzieh Fadaee, Stephen H. Bach, Julia Kreutzer

+ [CrossICL: Cross-Task In-Context Learning via Unsupervised Demonstration Transfer](https://arxiv.org//abs/2505.24143)

	Jinglong Gao, Xiao Ding, Lingxiao Zou, Bing Qin, Ting Liu

+ [Rationales Are Not Silver Bullets: Measuring the Impact of Rationales on Model Performance and Reliability](https://arxiv.org//abs/2505.24147)

	Chiwei Zhu, Benfeng Xu, An Yang, Junyang Lin, Quan Wang, Chang Zhou, Zhendong Mao

+ [Mixed-R1: Unified Reward Perspective For Reasoning Capability in Multimodal Large Language Models](https://arxiv.org//abs/2505.24164)

	Shilin Xu, Yanwei Li, Rui Yang, Tao Zhang, Yueyi Sun, Wei Chow, Linfeng Li, Hang Song, Qi Xu, Yunhai Tong, Xiangtai Li, Hao Fei

+ [Adaptive LoRA Merge with Parameter Pruning for Low-Resource Generation](https://arxiv.org//abs/2505.24174)

	Ryota Miyano, Yuki Arase

+ [Beyond Exponential Decay: Rethinking Error Accumulation in Large Language Models](https://arxiv.org//abs/2505.24187)

	Mikhail L. Arbuzov, Alexey A. Shvets, Sisong Beir

+ [CLaSp: In-Context Layer Skip for Self-Speculative Decoding](https://arxiv.org//abs/2505.24196)

	Longze Chen, Renke Shan, Huiming Wang, Lu Wang, Ziqiang Liu, Run Luo, Jiawei Wang, Hamid Alinejad-Rokny, Min Yang

+ [Intuitionistic Fuzzy Sets for Large Language Model Data Annotation: A Novel Approach to Side-by-Side Preference Labeling](https://arxiv.org//abs/2505.24199)

	Yimin Du

+ [Semi-structured LLM Reasoners Can Be Rigorously Audited](https://arxiv.org//abs/2505.24217)

	Jixuan Leng, Cassandra A. Cohen, Zhixian Zhang, Chenyan Xiong, William W. Cohen

+ [Advantageous Parameter Expansion Training Makes Better Large Language Models](https://arxiv.org//abs/2505.24241)

	Naibin Gu, Yilong Chen, Zhenyu Zhang, Peng Fu, Zheng Lin, Shuohuan Wang, Yu Sun, Hua Wu, Weiping Wang, Haifeng Wang

+ [Mamba Knockout for Unraveling Factual Information Flow](https://arxiv.org//abs/2505.24244)

	Nir Endy, Idan Daniel Grosbard, Yuval Ran-Milo, Yonatan Slutzky, Itay Tshuva, Raja Giryes

+ [Proactive Guidance of Multi-Turn Conversation in Industrial Search](https://arxiv.org//abs/2505.24251)

	Xiaoyu Li, Xiao Li, Li Gao, Yiding Liu, Xiaoyang Wang, Shuaiqiang Wang, Junfeng Wang, Dawei Yin

+ [Simulating Training Data Leakage in Multiple-Choice Benchmarks for LLM Evaluation](https://arxiv.org//abs/2505.24263)

	Naila Shafirni Hidayat, Muhammad Dehan Al Kautsar, Alfan Farizki Wicaksono, Fajri Koto

+ [ScienceMeter: Tracking Scientific Knowledge Updates in Language Models](https://arxiv.org//abs/2505.24302)

	Yike Wang, Shangbin Feng, Yulia Tsvetkov, Hannaneh Hajishirzi

+ [HiCaM: A Hierarchical-Causal Modification Framework for Long-Form Text Modification](https://arxiv.org//abs/2505.24319)

	Yuntao Shi, Yi Luo, Yeyun Gong, Chen Lin

+ [Pangu DeepDiver: Adaptive Search Intensity Scaling via Open-Web Reinforcement Learning](https://arxiv.org//abs/2505.24332)

	Wenxuan Shi, Haochen Tan, Chuqiao Kuang, Xiaoguang Li, Xiaozhe Ren, Chen Zhang, Hanting Chen, Yasheng Wang, Lifeng Shang, Fisher Yu, Yunhe Wang

+ [Fewer Hallucinations, More Verification: A Three-Stage LLM-Based Framework for ASR Error Correction](https://arxiv.org//abs/2505.24347)

	Yangui Fang, Baixu Cheng, Jing Peng, Xu Li, Yu Xi, Chengwei Zhang, Guohui Zhong

+ [Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research](https://arxiv.org//abs/2505.24354)

	Qianqian Zhang, Jiajia Liao, Heting Ying, Yibo Ma, Haozhan Shen, Jingcheng Li, Peng Liu, Lu Zhang, Chunxin Fang, Kyusong Lee, Ruochen Xu, Tiancheng Zhao

+ [Knowing Before Saying: LLM Representations Encode Information About Chain-of-Thought Success Before Completion](https://arxiv.org//abs/2505.24362)

	Anum Afzal, Florian Matthes, Gal Chechik, Yftah Ziser

+ [LLM Inference Enhanced by External Knowledge: A Survey](https://arxiv.org//abs/2505.24377)

	Yu-Hsuan Lin, Qian-Hui Chen, Yi-Jie Cheng, Jia-Ren Zhang, Yi-Hung Liu, Liang-Yu Hsia, Yun-Nung Chen

+ [ClueAnchor: Clue-Anchored Knowledge Reasoning Exploration and Optimization for Retrieval-Augmented Generation](https://arxiv.org//abs/2505.24388)

	Hao Chen, Yukun Yan, Sen Mei, Wanxiang Che, Zhenghao Liu, Qi Shi, Xinze Li, Yuchun Fan, Pengcheng Huang, Qiushi Xiong, Zhiyuan Liu, Maosong Sun

+ [Model Unlearning via Sparse Autoencoder Subspace Guided Projections](https://arxiv.org//abs/2505.24428)

	Xu Wang, Zihao Li, Benyou Wang, Yan Hu, Difan Zou

+ [Exploring the Impact of Occupational Personas on Domain-Specific QA](https://arxiv.org//abs/2505.24448)

	Eojin Kang, Jaehyuk Yu, Juae Kim

+ [When Large Multimodal Models Confront Evolving Knowledge:Challenges and Pathways](https://arxiv.org//abs/2505.24449)

	Kailin Jiang, Yuntao Du, Yukai Ding, Yuchen Ren, Ning Jiang, Zhi Gao, Zilong Zheng, Lei Liu, Bin Li, Qing Li

+ [DEEPQUESTION: Systematic Generation of Real-World Challenges for Evaluating LLMs Performance](https://arxiv.org//abs/2505.24532)

	Ali Khoramfar, Ali Ramezani, Mohammad Mahdi Mohajeri, Mohammad Javad Dousti, Majid Nili Ahmadabadi, Heshaam Faili

+ [A*-Thought: Efficient Reasoning via Bidirectional Compression for Low-Resource Settings](https://arxiv.org//abs/2505.24550)

	Xiaoang Xu, Shuo Wang, Xu Han, Zhenghao Liu, Huijia Wu, Peipei Li, Zhiyuan Liu, Maosong Sun, Zhaofeng He

+ [When Harry Meets Superman: The Role of The Interlocutor in Persona-Based Dialogue Generation](https://arxiv.org//abs/2505.24613)

	Daniela Occhipinti, Marco Guerini, Malvina Nissim

+ [Benchmarking Large Language Models for Cryptanalysis and Mismatched-Generalization](https://arxiv.org//abs/2505.24621)

	Utsav Maskey, Chencheng Zhu, Usman Naseem

+ [Are Optimal Algorithms Still Optimal? Rethinking Sorting in LLM-Based Pairwise Ranking with Batching and Caching](https://arxiv.org//abs/2505.24643)

	Juan Wisznia, Cecilia Bolaños, Juan Tollo, Giovanni Marraffini, Agustín Gianolini, Noe Hsueh, Luciano Del Corro

+ [TRIDENT: Enhancing Large Language Model Safety with Tri-Dimensional Diversified Red-Teaming Data Synthesis](https://arxiv.org//abs/2505.24672)

	Xiaorui Wu, Xiaofeng Mao, Fei Li, Xin Zhang, Xuanhong Li, Chong Teng, Donghong Ji, Zhuang Li

+ [A Simple Linear Patch Revives Layer-Pruned Large Language Models](https://arxiv.org//abs/2505.24680)

	Xinrui Chen, Haoli Bai, Tao Yuan, Ruikang Liu, Kang Zhao, Xianzhi Yu, Lu Hou, Tian Guan, Yonghong He, Chun Yuan

+ [Soft Reasoning: Navigating Solution Spaces in Large Language Models through Controlled Embedding Exploration](https://arxiv.org//abs/2505.24688)

	Qinglin Zhu, Runcong Zhao, Hanqi Yan, Yulan He, Yudong Chen, Lin Gui

+ [BPE Stays on SCRIPT: Structured Encoding for Robust Multilingual Pretokenization](https://arxiv.org//abs/2505.24689)

	Sander Land, Catherine Arnett

+ [Reflect, Retry, Reward: Self-Improving LLMs via Reinforcement Learning](https://arxiv.org//abs/2505.24726)

	Shelly Bensal, Umar Jamil, Christopher Bryant, Melisa Russak, Kiran Kamble, Dmytro Mozolevskyi, Muayad Ali, Waseem AlShikh

+ [Circuit Stability Characterizes Language Model Generalization](https://arxiv.org//abs/2505.24731)

	Alan Sun

+ [LGAR: Zero-Shot LLM-Guided Neural Ranking for Abstract Screening in Systematic Literature Reviews](https://arxiv.org//abs/2505.24757)

	Christian Jaumann, Andreas Wiedholz, Annemarie Friedrich

+ [From Macro to Micro: Probing Dataset Diversity in Language Model Fine-Tuning](https://arxiv.org//abs/2505.24768)

	Haoyu Li, Xuhong Li, Yiming Dong, Kun Liu

+ [Revisiting Epistemic Markers in Confidence Estimation: Can Markers Accurately Reflect Large Language Models' Uncertainty?](https://arxiv.org//abs/2505.24778)

	Jiayu Liu, Qing Zong, Weiqi Wang, Yangqiu Song

+ [Guiding Generative Storytelling with Knowledge Graphs](https://arxiv.org//abs/2505.24803)

	Zhijun Pan, Antonios Andronis, Eva Hayek, Oscar AP Wilkinson, Ilya Lasy, Annette Parry, Guy Gadney, Tim J. Smith, Mick Grierson

+ [How much do language models memorize?](https://arxiv.org//abs/2505.24832)

	John X. Morris, Chawin Sitawarin, Chuan Guo, Narine Kokhlikyan, G. Edward Suh, Alexander M. Rush, Kamalika Chaudhuri, Saeed Mahloujifar

+ [MetaFaith: Faithful Natural Language Uncertainty Expression in LLMs](https://arxiv.org//abs/2505.24858)

	Gabrielle Kaili-May Liu, Gal Yona, Avi Caciularu, Idan Szpektor, Tim G. J. Rudner, Arman Cohan

+ [AlphaOne: Reasoning Models Thinking Slow and Fast at Test Time](https://arxiv.org//abs/2505.24863)

	Junyu Zhang, Runpei Dong, Han Wang, Xuying Ning, Haoran Geng, Peihao Li, Xialin He, Yutong Bai, Jitendra Malik, Saurabh Gupta, Huan Zhang

+ [AMIA: Automatic Masking and Joint Intention Analysis Makes LVLMs Robust Jailbreak Defenders](https://arxiv.org//abs/2505.24519)

	Yuqi Zhang, Yuchun Miao, Zuchao Li, Liang Ding

+ [SUMO: Subspace-Aware Moment-Orthogonalization for Accelerating Memory-Efficient LLM Training](https://arxiv.org//abs/2505.24749)

	Yehonathan Refael, Guy Smorodinsky, Tom Tirer, Ofir Lindenbaum

+ [Chameleon: A Flexible Data-mixing Framework for Language Model Pretraining and Finetuning](https://arxiv.org//abs/2505.24844)

	Wanyun Xie, Francesco Tonin, Volkan Cevher

+ [Beyond Multiple Choice: Evaluating Steering Vectors for Adaptive Free-Form Summarization](https://arxiv.org//abs/2505.24859)

	Joschka Braun, Carsten Eickhoff, Seyed Ali Bahrainian

+ [MoDoMoDo: Multi-Domain Data Mixtures for Multimodal LLM Reinforcement Learning](https://arxiv.org//abs/2505.24871)

	Yiqing Liang, Jielin Qiu, Wenhao Ding, Zuxin Liu, James Tompkin, Mengdi Xu, Mengzhou Xia, Zhengzhong Tu, Laixi Shi, Jiacheng Zhu

+ [Agent-X: Evaluating Deep Multimodal Reasoning in Vision-Centric Agentic Tasks](https://arxiv.org//abs/2505.24876)

	Tajamul Ashraf, Amal Saqib, Hanan Ghani, Muhra AlMahri, Yuhao Li, Noor Ahsan, Umair Nawaz, Jean Lahoud, Hisham Cholakkal, Mubarak Shah, Philip Torr, Fahad Shahbaz Khan, Rao Muhammad Anwer, Salman Khan

+ [Light as Deception: GPT-driven Natural Relighting Against Vision-Language Pre-training Models](https://arxiv.org//abs/2505.24227)

	Ying Yang, Jie Zhang, Xiao Lv, Di Lin, Tao Xiang, Qing Guo

+ [MIRAGE: Assessing Hallucination in Multimodal Reasoning Chains of MLLM](https://arxiv.org//abs/2505.24238)

	Bowen Dong, Minheng Ni, Zitong Huang, Guanglei Yang, Wangmeng Zuo, Lei Zhang

+ [SiLVR: A Simple Language-based Video Reasoning Framework](https://arxiv.org//abs/2505.24869)

	Ce Zhang, Yan-Bo Lin, Ziyang Wang, Mohit Bansal, Gedas Bertasius

+ [Practical Bayes-Optimal Membership Inference Attacks](https://arxiv.org//abs/2505.24089)

	Marcus Lassila, Johan Östman, Khac-Hoang Ngo, Alexandre Graell i Amat

+ [On Fairness of Task Arithmetic: The Role of Task Vectors](https://arxiv.org//abs/2505.24262)

	Hiroki Naganuma, Kotaro Yoshida, Laura Gomezjurado Gonzalez, Takafumi Horie, Yuji Naraki, Ryotaro Shimizu

+ [AFLoRA: Adaptive Federated Fine-Tuning of Large Language Models with Resource-Aware Low-Rank Adaption](https://arxiv.org//abs/2505.24773)

	Yajie Zhou, Xiaoyi Pang, Zhibo Wang

+ [Cascading Adversarial Bias from Injection to Distillation in Language Models](https://arxiv.org//abs/2505.24842)

	Harsh Chaudhari, Jamie Hayes, Matthew Jagielski, Ilia Shumailov, Milad Nasr, Alina Oprea

+ [Tournament of Prompts: Evolving LLM Instructions Through Structured Debates and Elo Ratings](https://arxiv.org//abs/2506.00178)

	Anirudh Nair, Adi Banerjee, Laurent Mombaerts, Matthew Hagen, Tarik Borogovac

+ [Control-R: Towards controllable test-time scaling](https://arxiv.org//abs/2506.00189)

	Di Zhang, Weida Wang, Junxian Li, Xunzhi Wang, Jiatong Li, Jianbo Wu, Jingdi Lei, Haonan He, Peng Ye, Shufei Zhang, Wanli Ouyang, Yuqiang Li, Dongzhan Zhou

+ [Whispers of Many Shores: Cultural Alignment through Collaborative Cultural Expertise](https://arxiv.org//abs/2506.00242)

	Shuai Feng, Wei-Chuang Chan, Srishti Chouhan, Junior Francisco Garcia Ayala, Srujananjali Medicherla, Kyle Clark, Mingwei Shi

+ [Hidden in Plain Sight: Probing Implicit Reasoning in Multimodal Language Models](https://arxiv.org//abs/2506.00258)

	Qianqi Yan, Hongquan Li, Shan Jiang, Yang Zhao, Xinze Guan, Ching-Chen Kuo, Xin Eric Wang

+ [Who Gets the Kidney? Human-AI Alignment, Indecision, and Moral Values](https://arxiv.org//abs/2506.00079)

	John P. Dickerson, Hadi Hosseini, Samarth Khanna, Leona Pierce

+ [Artificial Empathy: AI based Mental Health](https://arxiv.org//abs/2506.00081)

	Aditya Naik, Jovi Thomas, Teja Sree, Himavant Reddy

+ [COSMIC: Generalized Refusal Direction Identification in LLM Activations](https://arxiv.org//abs/2506.00085)

	Vincent Siu, Nicholas Crispino, Zihao Yu, Sam Pan, Zhun Wang, Yang Liu, Dawn Song, Chenguang Wang

+ [HD-NDEs: Neural Differential Equations for Hallucination Detection in LLMs](https://arxiv.org//abs/2506.00088)

	Qing Li, Jiahui Geng, Zongxiong Chen, Derui Zhu, Yuxia Wang, Congbo Ma, Chenyang Lyu, Fakhri Karray

+ [TRAPDOC: Deceiving LLM Users by Injecting Imperceptible Phantom Tokens into Documents](https://arxiv.org//abs/2506.00089)

	Hyundong Jin, Sicheol Sung, Shinwoo Park, SeungYeop Baik, Yo-Sub Han

+ [Spurious Correlations and Beyond: Understanding and Mitigating Shortcut Learning in SDOH Extraction with Large Language Models](https://arxiv.org//abs/2506.00134)

	Fardin Ahsan Sakib, Ziwei Zhu, Karen Trister Grace, Meliha Yetisgen, Ozlem Uzuner

+ [Disentangled Safety Adapters Enable Efficient Guardrails and Flexible Inference-Time Alignment](https://arxiv.org//abs/2506.00166)

	Kundan Krishna, Joseph Y Cheng, Charles Maalouf, Leon A Gatys

+ [Accountability Attribution: Tracing Model Behavior to Training Processes](https://arxiv.org//abs/2506.00175)

	Shichang Zhang, Hongzhe Du, Karim Saraipour, Jiaqi W. Ma, Himabindu Lakkaraju

+ [Let Them Down Easy! Contextual Effects of LLM Guardrails on User Perceptions and Preferences](https://arxiv.org//abs/2506.00195)

	Mingqian Zheng, Wenjia Hu, Patrick Zhao, Motahhare Eslami, Jena D. Hwang, Faeze Brahman, Carolyn Rose, Maarten Sap

+ [The World As Large Language Models See It: Exploring the reliability of LLMs in representing geographical features](https://arxiv.org//abs/2506.00203)

	Omid Reza Abbasi, Franz Welscher, Georg Weinberger, Johannes Scholz

+ [REIC: RAG-Enhanced Intent Classification at Scale](https://arxiv.org//abs/2506.00210)

	Ziji Zhang, Michael Yang, Zhiyu Chen, Yingying Zhuang, Shu-Ting Pi, Qun Liu, Rajashekar Maragoud, Vy Nguyen, Anurag Beniwal

+ [Aligned but Blind: Alignment Increases Implicit Bias by Reducing Awareness of Race](https://arxiv.org//abs/2506.00253)

	Lihao Sun, Chengzhi Mao, Valentin Hofmann, Xuechunzi Bai

+ [Chances and Challenges of the Model Context Protocol in Digital Forensics and Incident Response](https://arxiv.org//abs/2506.00274)

	Jan-Niclas Hilgert, Carlo Jakobs, Michael Külper, Martin Lambertz, Axel Mahr, Elmar Padilla

+ [Adversarial Threat Vectors and Risk Mitigation for Retrieval-Augmented Generation Systems](https://arxiv.org//abs/2506.00281)

	Chris M. Ward, Josh Harguess

+ [Emergent Abilities of Large Language Models under Continued Pretraining for Language Adaptation](https://arxiv.org//abs/2506.00288)

	Ahmed Elhady, Eneko Agirre, Mikel Artetxe

+ [Lossless Token Sequence Compression via Meta-Tokens](https://arxiv.org//abs/2506.00307)

	John Harvill, Ziwei Fan, Hao Wang, Yizhou Sun, Hao Ding, Luke Huan, Anoop Deoras

+ [Writing-Zero: Bridge the Gap Between Non-verifiable Problems and Verifiable Rewards](https://arxiv.org//abs/2506.00103)

	Xun Lu

+ [LaMP-QA: A Benchmark for Personalized Long-form Question Answering](https://arxiv.org//abs/2506.00137)

	Alireza Salemi, Hamed Zamani

+ [ComposeRAG: A Modular and Composable RAG for Corpus-Grounded Multi-Hop Question Answering](https://arxiv.org//abs/2506.00232)

	Ruofan Wu, Youngwon Lee, Fan Shu, Danmei Xu, Seung-won Hwang, Zhewei Yao, Yuxiong He, Feng Yan

+ [MedOrch: Medical Diagnosis with Tool-Augmented Reasoning Agents for Flexible Extensibility](https://arxiv.org//abs/2506.00235)

	Yexiao He, Ang Li, Boyi Liu, Zhewei Yao, Yuxiong He

+ [The Impact of Disability Disclosure on Fairness and Bias in LLM-Driven Candidate Selection](https://arxiv.org//abs/2506.00256)

	Mahammed Kamruzzaman, Gene Louis Kim

+ [MultiHoax: A Dataset of Multi-hop False-Premise Questions](https://arxiv.org//abs/2506.00264)

	Mohammadamin Shafiei, Hamidreza Saffari, Nafise Sadat Moosavi

+ [Beyond Semantic Entropy: Boosting LLM Uncertainty Quantification with Pairwise Semantic Similarity](https://arxiv.org//abs/2506.00245)

	Dang Nguyen, Ali Payani, Baharan Mirzasoleiman

+ [GPR: Empowering Generation with Graph-Pretrained Retriever](https://arxiv.org//abs/2506.00261)

	Xiaochen Wang, Zongyu Wu, Yuan Zhong, Xiang Zhang, Suhang Wang, Fenglong Ma

+ [RoboMoRe: LLM-based Robot Co-design via Joint Optimization of Morphology and Reward](https://arxiv.org//abs/2506.00276)

	Jiawei Fang, Yuxuan Sun, Chengtian Ma, Qiuyu Lu, Lining Yao

+ [Aligning Language Models with Observational Data: Opportunities and Risks from a Causal Perspective](https://arxiv.org//abs/2506.00152)

	Erfan Loghmani

+ [Breakpoint: Scalable evaluation of system-level reasoning in LLM code agents](https://arxiv.org//abs/2506.00172)

	Kaivalya Hariharan, Uzay Girit, Atticus Wang, Jacob Andreas

+ [A Red Teaming Roadmap Towards System-Level Safety](https://arxiv.org//abs/2506.05376)

	Zifan Wang, Christina Q. Knight, Jeremy Kritz, Willow E. Primack, Julian Michael

+ [Recipes for Pre-training LLMs with MXFP8](https://arxiv.org//abs/2506.08027)

	Asit Mishra, Dusan Stosic, Simon Layton

+ [Logits-Based Finetuning](https://arxiv.org//abs/2505.24461)

	Jingyao Li, Senqiao Yang, Sitong Wu, Han Shi, Chuanyang Zheng, Hong Xu, Jiaya Jia

+ [Who is in the Spotlight: The Hidden Bias Undermining Multimodal Retrieval-Augmented Generation](https://arxiv.org//abs/2506.11063)

	Jiayu Yao, Shenghua Liu, Yiwei Wang, Lingrui Mei, Baolong Bi, Yuyao Ge, Zhecheng Li, Xueqi Cheng

# 2025-05-29
+ [Revisiting Multi-Agent Debate as Test-Time Scaling: A Systematic Study of Conditional Effectiveness](https://arxiv.org//abs/2505.22960)

	Yongjin Yang, Euiin Yi, Jongwoo Ko, Kimin Lee, Zhijing Jin, Se-Young Yun

+ [Case-Based Reasoning Enhances the Predictive Power of LLMs in Drug-Drug Interaction](https://arxiv.org//abs/2505.23034)

	Guangyi Liu, Yongqi Zhang, Xunyuan Liu, Quanming Yao

+ [Second Opinion Matters: Towards Adaptive Clinical AI via the Consensus of Expert Model Ensemble](https://arxiv.org//abs/2505.23075)

	Amit Kumthekar, Zion Tilley, Henry Duong, Bhargav Patel, Michael Magnoli, Ahmed Omar, Ahmed Nasser, Chaitanya Gharpure, Yevgen Reztzov

+ [Infi-MMR: Curriculum-based Unlocking Multimodal Reasoning via Phased Reinforcement Learning in Multimodal Small Language Models](https://arxiv.org//abs/2505.23091)

	Zeyu Liu, Yuhang Liu, Guanghao Zhu, Congkai Xie, Zhen Li, Jianbo Yuan, Xinyao Wang, Qing Li, Shing-Chi Cheung, Shengyu Zhang, Fei Wu, Hongxia Yang

+ [MathArena: Evaluating LLMs on Uncontaminated Math Competitions](https://arxiv.org//abs/2505.23281)

	Mislav Balunović, Jasper Dekoninck, Ivo Petrov, Nikola Jovanović, Martin Vechev

+ [A Unified Framework for Human AI Collaboration in Security Operations Centers with Trusted Autonomy](https://arxiv.org//abs/2505.23397)

	Ahmad Mohsin, Helge Janicke, Ahmed Ibrahim, Iqbal H. Sarker, Seyit Camtepe

+ [EVOREFUSE: Evolutionary Prompt Optimization for Evaluation and Mitigation of LLM Over-Refusal to Pseudo-Malicious Instructions](https://arxiv.org//abs/2505.23473)

	Xiaorui Wu, Xiaofeng Mao, Fei Li, Xin Zhang, Xiaolu Zhang, Jun Zhou, Yuxiang Peng, Li Zheng, Chong Teng, Donghong Ji, Zhuang Li

+ [Socratic-PRMBench: Benchmarking Process Reward Models with Systematic Reasoning Patterns](https://arxiv.org//abs/2505.23474)

	Xiang Li, Haiyang Yu, Xinghua Zhang, Ziyang Huang, Shizhu He, Kang Liu, Jun Zhao, Fei Huang, Yongbin Li

+ [Autoformalization in the Era of Large Language Models: A Survey](https://arxiv.org//abs/2505.23486)

	Ke Weng, Lun Du, Sirui Li, Wangyue Lu, Haozhe Sun, Hengyu Liu, Tiancheng Zhang

+ [TRAP: Targeted Redirecting of Agentic Preferences](https://arxiv.org//abs/2505.23518)

	Hangoo Kang, Jehyeok Yeon, Gagandeep Singh

+ [SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents](https://arxiv.org//abs/2505.23559)

	Kunlun Zhu, Jiaxun Zhang, Ziheng Qi, Nuoxing Shang, Zijia Liu, Peixuan Han, Yue Su, Haofei Yu, Jiaxuan You

+ [CoT Red-Handed: Stress Testing Chain-of-Thought Monitoring](https://arxiv.org//abs/2505.23575)

	Benjamin Arnav, Pablo Bernabeu-Pérez, Nathan Helm-Burger, Tim Kostolansky, Hannes Whittingham, Mary Phuong

+ [Fortune: Formula-Driven Reinforcement Learning for Symbolic Table Reasoning in Language Models](https://arxiv.org//abs/2505.23667)

	Lang Cao, Jingxian Xu, Hanbing Liu, Jinyu Wang, Mengyu Zhou, Haoyu Dong, Shi Han, Dongmei Zhang

+ [Data-to-Dashboard: Multi-Agent LLM Framework for Insightful Visualization in Enterprise Analytics](https://arxiv.org//abs/2505.23695)

	Ran Zhang, Mohannad Elhamod

+ [Let's Reason Formally: Natural-Formal Hybrid Reasoning Enhances LLM's Math Capability](https://arxiv.org//abs/2505.23703)

	Ruida Wang, Yuxin Li, Yi R. (May)Fung, Tong Zhang

+ [Exploring Scaling Laws for EHR Foundation Models](https://arxiv.org//abs/2505.22964)

	Sheng Zhang, Qin Liu, Naoto Usuyama, Cliff Wong, Tristan Naumann, Hoifung Poon

+ [Model-Preserving Adaptive Rounding](https://arxiv.org//abs/2505.22988)

	Albert Tseng, Zhaofeng Sun, Christopher De Sa

+ [A Practical Approach for Building Production-Grade Conversational Agents with Workflow Graphs](https://arxiv.org//abs/2505.23006)

	Chiwan Park, Wonjun Jang, Daeryong Kim, Aelim Ahn, Kichang Yang, Woosung Hwang, Jihyeon Roh, Hyerin Park, Hyosun Wang, Min Seok Kim, Jihoon Kang

+ [AgentAlign: Navigating Safety Alignment in the Shift from Informative to Agentic Large Language Models](https://arxiv.org//abs/2505.23020)

	Jinchuan Zhang, Lu Yin, Yan Zhou, Songlin Hu

+ [Context Robust Knowledge Editing for Language Models](https://arxiv.org//abs/2505.23026)

	Haewon Park, Gyubin Choi, Minjun Kim, Yohan Jo

+ [Augment or Not? A Comparative Study of Pure and Augmented Large Language Model Recommenders](https://arxiv.org//abs/2505.23053)

	Wei-Hsiang Huang, Chen-Wei Ke, Wei-Ning Chiu, Yu-Xuan Su, Chun-Chun Yang, Chieh-Yuan Cheng, Yun-Nung Chen, Pu-Jen Cheng

+ [From Token to Action: State Machine Reasoning to Mitigate Overthinking in Information Retrieval](https://arxiv.org//abs/2505.23059)

	Dohyeon Lee, Yeonseok Jeong, Seung-won Hwang

+ [Decom-Renorm-Merge: Model Merging on the Right Space Improves Multitasking](https://arxiv.org//abs/2505.23117)

	Yuatyong Chaichana, Thanapat Trachu, Peerat Limkonchotiwat, Konpat Preechakul, Tirasan Khandhawit, Ekapol Chuangsuwanich

+ [VERINA: Benchmarking Verifiable Code Generation](https://arxiv.org//abs/2505.23135)

	Zhe Ye, Zhengxu Yan, Jingxuan He, Timothe Kasriel, Kaiyu Yang, Dawn Song

+ [Cross-Task Experiential Learning on LLM-based Multi-Agent Collaboration](https://arxiv.org//abs/2505.23187)

	Yilong Li, Chen Qian, Yu Xia, Ruijie Shi, Yufan Dang, Zihao Xie, Ziming You, Weize Chen, Cheng Yang, Weichuan Liu, Ye Tian, Xuantang Xiong, Lei Han, Zhiyuan Liu, Maosong Sun

+ [ExpeTrans: LLMs Are Experiential Transfer Learners](https://arxiv.org//abs/2505.23191)

	Jinglong Gao, Xiao Ding, Lingxiao Zou, Bibo Cai, Bing Qin, Ting Liu

+ [Fooling the Watchers: Breaking AIGC Detectors via Semantic Prompt Attacks](https://arxiv.org//abs/2505.23192)

	Run Hao, Peng Ying

+ [MCTSr-Zero: Self-Reflective Psychological Counseling Dialogues Generation via Principles and Adaptive Exploration](https://arxiv.org//abs/2505.23229)

	Hao Lu, Yanchi Gu, Haoyuan Huang, Yulin Zhou, Ningxin Zhu, Chen Li

+ [Accelerating RLHF Training with Reward Variance Increase](https://arxiv.org//abs/2505.23247)

	Zonglin Yang, Zhexuan Gu, Houduo Qi, Yancheng Yuan

+ [Disrupting Vision-Language Model-Driven Navigation Services via Adversarial Object Fusion](https://arxiv.org//abs/2505.23266)

	Chunlong Xie, Jialing He, Shangwei Guo, Jiacheng Wang, Shudong Zhang, Tianwei Zhang, Tao Xiang

+ [Does Machine Unlearning Truly Remove Model Knowledge? A Framework for Auditing Unlearning in LLMs](https://arxiv.org//abs/2505.23270)

	Haokun Chen, Yueqi Zhang, Yuan Bi, Yao Zhang, Tong Liu, Jinhe Bi, Jian Lan, Jindong Gu, Claudia Grosser, Denis Krompass, Nassir Navab, Volker Tresp

+ [The Arabic AI Fingerprint: Stylometric Analysis and Detection of Large Language Models Text](https://arxiv.org//abs/2505.23276)

	Maged S. Al-Shaibani, Moataz Ahmed

+ [Sentinel: Attention Probing of Proxy Models for LLM Context Compression with an Understanding Perspective](https://arxiv.org//abs/2505.23277)

	Yong Zhang, Yanwen Huang, Ning Cheng, Yang Guo, Yun Zhu, Yanmeng Wang, Shaojun Wang, Jing Xiao

+ [How Does Response Length Affect Long-Form Factuality](https://arxiv.org//abs/2505.23295)

	James Xu Zhao, Jimmy Z.J. Liu, Bryan Hooi, See-Kiong Ng

+ [Towards Reward Fairness in RLHF: From a Resource Allocation Perspective](https://arxiv.org//abs/2505.23349)

	Sheng Ouyang, Yulan Hu, Ge Chen, Qingyang Li, Fuzheng Zhang, Yong Liu

+ [Understanding the Information Propagation Effects of Communication Topologies in LLM-based Multi-Agent Systems](https://arxiv.org//abs/2505.23352)

	Xu Shen, Yixin Liu, Yiwei Dai, Yili Wang, Rui Miao, Yue Tan, Shirui Pan, Xin Wang

+ [Afterburner: Reinforcement Learning Facilitates Self-Improving Code Efficiency Optimization](https://arxiv.org//abs/2505.23387)

	Mingzhe Du, Luu Tuan Tuan, Yue Liu, Yuhao Qing, Dong Huang, Xinyi He, Qian Liu, Zejun Ma, See-kiong Ng

+ [SWE-bench Goes Live!](https://arxiv.org//abs/2505.23419)

	Linghao Zhang, Shilin He, Chaoyun Zhang, Yu Kang, Bowen Li, Chengxing Xie, Junhao Wang, Maoquan Wang, Yufan Huang, Shengyu Fu, Elsie Nallipogu, Qingwei Lin, Yingnong Dang, Saravan Rajmohan, Dongmei Zhang

+ [From Knowledge to Noise: CTIM-Rover and the Pitfalls of Episodic Memory in Software Engineering Agents](https://arxiv.org//abs/2505.23422)

	Tobias Lindenbauer, Georg Groh, Hinrich Schütze

+ [Segment Policy Optimization: Effective Segment-Level Credit Assignment in RL for Large Language Models](https://arxiv.org//abs/2505.23564)

	Yiran Guo, Lijie Xu, Jie Liu, Dan Ye, Shuang Qiu

+ [Satori-SWE: Evolutionary Test-Time Scaling for Sample-Efficient Software Engineering](https://arxiv.org//abs/2505.23604)

	Guangtao Zeng, Maohao Shen, Delin Chen, Zhenting Qi, Subhro Das, Dan Gutfreund, David Cox, Gregory Wornell, Wei Lu, Zhang-Wei Hong, Chuang Gan

+ [AutoSchemaKG: Autonomous Knowledge Graph Construction through Dynamic Schema Induction from Web-Scale Corpora](https://arxiv.org//abs/2505.23628)

	Jiaxin Bai, Wei Fan, Qi Hu, Qing Zong, Chunyang Li, Hong Ting Tsang, Hongyu Luo, Yauwai Yim, Haoyu Huang, Xiao Zhou, Feng Qin, Tianshi Zheng, Xi Peng, Xin Yao, Huiwen Yang, Leijie Wu, Yi Ji, Gong Zhang, Renhai Chen, Yangqiu Song

+ [Securing AI Agents with Information-Flow Control](https://arxiv.org//abs/2505.23643)

	Manuel Costa, Boris Köpf, Aashish Kolluri, Andrew Paverd, Mark Russinovich, Ahmed Salem, Shruti Tople, Lukas Wutschitz, Santiago Zanella-Béguelin

+ [Keyed Chaotic Tensor Transformations for Secure And Attributable Neural Inference](https://arxiv.org//abs/2505.23655)

	Peter David Fagan

+ [Active Layer-Contrastive Decoding Reduces Hallucination in Large Language Model Generation](https://arxiv.org//abs/2505.23657)

	Hongxiang Zhang, Hao Chen, Tianyi Zhang, Muhao Chen

+ [ML-Agent: Reinforcing LLM Agents for Autonomous Machine Learning Engineering](https://arxiv.org//abs/2505.23723)

	Zexi Liu, Jingyi Chai, Xinyu Zhu, Shuo Tang, Rui Ye, Bo Zhang, Lei Bai, Siheng Chen

+ [SC-LoRA: Balancing Efficient Fine-tuning and Knowledge Preservation via Subspace-Constrained LoRA](https://arxiv.org//abs/2505.23724)

	Minrui Luo, Fuhang Kuang, Yu Wang, Zirui Liu, Tianxing He

+ [Bounded Rationality for LLMs: Satisficing Alignment at Inference-Time](https://arxiv.org//abs/2505.23729)

	Mohamad Chehade, Soumya Suvra Ghosal, Souradip Chakraborty, Avinash Reddy, Dinesh Manocha, Hao Zhu, Amrit Singh Bedi

+ [ATLAS: Learning to Optimally Memorize the Context at Test Time](https://arxiv.org//abs/2505.23735)

	Ali Behrouz, Zeman Li, Praneeth Kacham, Majid Daliri, Yuan Deng, Peilin Zhong, Meisam Razaviyayn, Vahab Mirrokni

+ [DeepTheorem: Advancing LLM Reasoning for Theorem Proving Through Natural Language and Reinforcement Learning](https://arxiv.org//abs/2505.23754)

	Ziyin Zhang, Jiahao Xu, Zhiwei He, Tian Liang, Qiuzhi Liu, Yansi Li, Linfeng Song, Zhengwen Liang, Zhuosheng Zhang, Rui Wang, Zhaopeng Tu, Haitao Mi, Dong Yu

+ [From Chat Logs to Collective Insights: Aggregative Question Answering](https://arxiv.org//abs/2505.23765)

	Wentao Zhang, Woojeong Kim, Yuntian Deng

+ [StrucSum: Graph-Structured Reasoning for Long Document Extractive Summarization with LLMs](https://arxiv.org//abs/2505.22950)

	Haohan Yuan, Sukhwa Hong, Haopeng Zhang

+ [LLM-based HSE Compliance Assessment: Benchmark, Performance, and Advancements](https://arxiv.org//abs/2505.22959)

	Jianwei Wang, Mengqi Wang, Yinsi Zhou, Zhenchang Xing, Qing Liu, Xiwei Xu, Wenjie Zhang, Liming Zhu

+ [ToMAP: Training Opponent-Aware LLM Persuaders with Theory of Mind](https://arxiv.org//abs/2505.22961)

	Peixuan Han, Zijia Liu, Jiaxuan You

+ [DyePack: Provably Flagging Test Set Contamination in LLMs Using Backdoors](https://arxiv.org//abs/2505.23001)

	Yize Cheng, Wenxiao Wang, Mazda Moayeri, Soheil Feizi

+ [Detecting Stealthy Backdoor Samples based on Intra-class Distance for Large Language Models](https://arxiv.org//abs/2505.23015)

	Jinwen Chen, Hainan Zhang, Fei Sun, Qinnan Zhang, Sijia Wen, Ziwei Wang, Zhiming Zheng

+ [EL4NER: Ensemble Learning for Named Entity Recognition via Multiple Small-Parameter Large Language Models](https://arxiv.org//abs/2505.23038)

	Yuzhen Xiao, Jiahe Song, Yongxin Xu, Ruizhe Zhang, Yiqi Xiao, Xin Lu, Runchuan Zhu, Bowen Jiang, Junfeng Zhao

+ [Query Routing for Retrieval-Augmented Language Models](https://arxiv.org//abs/2505.23052)

	Jiarui Zhang, Xiangyu Liu, Yong Hu, Chaoyue Niu, Fan Wu, Guihai Chen

+ [SNS-Bench-VL: Benchmarking Multimodal Large Language Models in Social Networking Services](https://arxiv.org//abs/2505.23065)

	Hongcheng Guo, Zheyong Xie, Shaosheng Cao, Boyang Wang, Weiting Liu, Anjie Le, Lei Li, Zhoujun Li

+ [Generating Diverse Training Samples for Relation Extraction with Large Language Models](https://arxiv.org//abs/2505.23108)

	Zexuan Li, Hongliang Dai, Piji Li

+ [Dataset Cartography for Large Language Model Alignment: Mapping and Diagnosing Preference Data](https://arxiv.org//abs/2505.23114)

	Seohyeong Lee, Eunwon Kim, Hwaran Lee, Buru Chang

+ [Enhancing Large Language Models'Machine Translation via Dynamic Focus Anchoring](https://arxiv.org//abs/2505.23140)

	Qiuyu Ding, Zhiqiang Cao, Hailong Cao, Tiejun Zhao

+ [Infinite-Instruct: Synthesizing Scaling Code instruction Data with Bidirectional Synthesis and Static Verification](https://arxiv.org//abs/2505.23177)

	Wenjing Xing, Wenke Lu, Yeheng Duan, Bing Zhao, Zhenghui kang, Yaolong Wang, Kai Gao, Lei Qiao

+ [MMBoundary: Advancing MLLM Knowledge Boundary Awareness through Reasoning Step Confidence Calibration](https://arxiv.org//abs/2505.23224)

	Zhitao He, Sandeep Polisetty, Zhiyuan Fan, Yuchen Huang, Shujin Wu, Yi R. (May)Fung

+ [ScEdit: Script-based Assessment of Knowledge Editing](https://arxiv.org//abs/2505.23291)

	Xinye Li, Zunwen Zheng, Qian Zhang, Dekai Zhuang, Jiabao Kang, Liyan Xu, Qingbin Liu, Xi Chen, Zhiying Tu, Dianhui Chu, Dianbo Sui

+ [Data-efficient Meta-models for Evaluation of Context-based Questions and Answers in LLMs](https://arxiv.org//abs/2505.23299)

	Julia Belikova, Konstantin Polev, Rauf Parchiev, Dmitry Simakov

+ [Proximalized Preference Optimization for Diverse Feedback Types: A Decomposed Perspective on DPO](https://arxiv.org//abs/2505.23316)

	Kaiyang Guo, Yinchuan Li, Zhitang Chen

+ [Neither Stochastic Parroting nor AGI: LLMs Solve Tasks through Context-Directed Extrapolation from Training Data Priors](https://arxiv.org//abs/2505.23323)

	Harish Tayyar Madabushi, Melissa Torgbi, Claire Bonial

+ [Discriminative Policy Optimization for Token-Level Reward Models](https://arxiv.org//abs/2505.23363)

	Hongzhan Chen, Tao Yang, Shiping Gao, Ruijun Chen, Xiaojun Quan, Hongtao Tian, Ting Yao

+ [Threading the Needle: Reweaving Chain-of-Thought Reasoning to Explain Human Label Variation](https://arxiv.org//abs/2505.23368)

	Beiduo Chen, Yang Janet Liu, Anna Korhonen, Barbara Plank

+ [Adaptive Jailbreaking Strategies Based on the Semantic Understanding Capabilities of Large Language Models](https://arxiv.org//abs/2505.23404)

	Mingyu Yu, Wei Wang, Yanjie Wei, Sujuan Qin

+ [From Parameters to Prompts: Understanding and Mitigating the Factuality Gap between Fine-Tuned LLMs](https://arxiv.org//abs/2505.23410)

	Xuan Gong, Hanbo Huang, Shiyu Liang

+ [UAQFact: Evaluating Factual Knowledge Utilization of LLMs on Unanswerable Questions](https://arxiv.org//abs/2505.23461)

	Chuanyuan Tan, Wenbiao Shao, Hao Xiong, Tong Zhu, Zhenhua Liu, Kai Shi, Wenliang Chen

+ [Evaluating the performance and fragility of large language models on the self-assessment for neurological surgeons](https://arxiv.org//abs/2505.23477)

	Krithik Vishwanath, Anton Alyakin, Mrigayu Ghosh, Jin Vivian Lee, Daniel Alexander Alber, Karl L. Sangwon, Douglas Kondziolka, Eric Karl Oermann

+ [Revisiting Overthinking in Long Chain-of-Thought from the Perspective of Self-Doubt](https://arxiv.org//abs/2505.23480)

	Keqin Peng, Liang Ding, Yuanxin Ouyang, Meng Fang, Dacheng Tao

+ [Diagnosing and Addressing Pitfalls in KG-RAG Datasets: Toward More Reliable Benchmarking](https://arxiv.org//abs/2505.23495)

	Liangliang Zhang, Zhuorui Jiang, Hongliang Chi, Haoyang Chen, Mohammed Elkoumy, Fali Wang, Qiong Wu, Zhengyi Zhou, Shirui Pan, Suhang Wang, Yao Ma

+ [Probability-Consistent Preference Optimization for Enhanced LLM Reasoning](https://arxiv.org//abs/2505.23540)

	Yunqiao Yang, Houxing Ren, Zimu Lu, Ke Wang, Weikang Shi, Aojun Zhou, Junting Pan, Mingjie Zhan, Hongsheng Li

+ [Understanding Refusal in Language Models with Sparse Autoencoders](https://arxiv.org//abs/2505.23556)

	Wei Jie Yeo, Nirmalendu Prakash, Clement Neo, Roy Ka-Wei Lee, Erik Cambria, Ranjan Satapathy

+ [Table-R1: Inference-Time Scaling for Table Reasoning](https://arxiv.org//abs/2505.23621)

	Zheyuan Yang, Lyuhao Chen, Arman Cohan, Yilun Zhao

+ [Characterizing the Expressivity of Transformer Language Models](https://arxiv.org//abs/2505.23623)

	Jiaoda Li, Ryan Cotterell

+ [Are Reasoning Models More Prone to Hallucination?](https://arxiv.org//abs/2505.23646)

	Zijun Yao, Yantao Liu, Yanxu Chen, Jianhui Chen, Junfeng Fang, Lei Hou, Juanzi Li, Tat-Seng Chua

+ [ARC: Argument Representation and Coverage Analysis for Zero-Shot Long Document Summarization with Instruction Following LLMs](https://arxiv.org//abs/2505.23654)

	Mohamed Elaraby, Diane Litman

+ [ToolHaystack: Stress-Testing Tool-Augmented Language Models in Realistic Long-Term Interactions](https://arxiv.org//abs/2505.23662)

	Beong-woo Kwak, Minju Kim, Dongha Lim, Hyungjoo Chae, Dongjin Kang, Sunghwan Kim, Dongil Yang, Jinyoung Yeo

+ [LoLA: Low-Rank Linear Attention With Sparse Caching](https://arxiv.org//abs/2505.23666)

	Luke McDermott, Robert W. Heath Jr., Rahul Parhi

+ [Can LLMs Reason Abstractly Over Math Word Problems Without CoT? Disentangling Abstract Formulation From Arithmetic Computation](https://arxiv.org//abs/2505.23701)

	Ziling Cheng, Meng Cao, Leila Pishdad, Yanshuai Cao, Jackie Chi Kit Cheung

+ [SocialMaze: A Benchmark for Evaluating Social Reasoning in Large Language Models](https://arxiv.org//abs/2505.23713)

	Zixiang Xu, Yanbo Wang, Yue Huang, Jiayi Ye, Haomin Zhuang, Zirui Song, Lang Gao, Chenxi Wang, Zhaorun Chen, Yujun Zhou, Sixian Li, Wang Pan, Yue Zhao, Jieyu Zhao, Xiangliang Zhang, Xiuying Chen

+ [Don't Take the Premise for Granted: Evaluating the Premise Critique Ability of Large Language Models](https://arxiv.org//abs/2505.23715)

	Jinzhe Li, Gengxu Li, Yi Chang, Yuan Wu

+ [Label-Guided In-Context Learning for Named Entity Recognition](https://arxiv.org//abs/2505.23722)

	Fan Bai, Hamid Hassanzadeh, Ardavan Saeedi, Mark Dredze

+ [DenoiseRotator: Enhance Pruning Robustness for LLMs via Importance Concentration](https://arxiv.org//abs/2505.23049)

	Tianteng Gu, Bei Liu, Bo Xiao, Ke Zeng, Jiacheng Liu, Yanmin Qian

+ [On-Policy RL with Optimal Reward Baseline](https://arxiv.org//abs/2505.23585)

	Yaru Hao, Li Dong, Xun Wu, Shaohan Huang, Zewen Chi, Furu Wei

+ [PhotoArtAgent: Intelligent Photo Retouching with Language Model-Based Artist Agents](https://arxiv.org//abs/2505.23130)

	Haoyu Chen, Keda Tao, Yizao Wang, Xinlei Wang, Lei Zhu, Jinjin Gu

+ [Navigating the Accuracy-Size Trade-Off with Flexible Model Merging](https://arxiv.org//abs/2505.23209)

	Akash Dhasade, Divyansh Jhunjhunwala, Milos Vujasinovic, Gauri Joshi, Anne-Marie Kermarrec

+ [Are MLMs Trapped in the Visual Room?](https://arxiv.org//abs/2505.23272)

	Yazhou Zhang, Chunwang Zou, Qimeng Liu, Lu Rong, Ben Yao, Zheng Lian, Qiuchi Li, Peng Zhang, Jing Qin

+ [VideoReasonBench: Can MLLMs Perform Vision-Centric Complex Video Reasoning?](https://arxiv.org//abs/2505.23359)

	Yuanxin Liu, Kun Ouyang, Haoning Wu, Yi Liu, Lin Sui, Xinhao Li, Yan Zhong, Y. Charles, Xinyu Zhou, Xu Sun

+ [ThinkGeo: Evaluating Tool-Augmented Agents for Remote Sensing Tasks](https://arxiv.org//abs/2505.23752)

	Akashah Shabbir, Muhammad Akhtar Munir, Akshay Dudhane, Muhammad Umer Sheikh, Muhammad Haris Khan, Paolo Fraccaro, Juan Bernabe Moreno, Fahad Shahbaz Khan, Salman Khan

+ [MermaidFlow: Redefining Agentic Workflow Generation via Safety-Constrained Evolutionary Programming](https://arxiv.org//abs/2505.22967)

	Chengqi Zheng, Jianda Chen, Yueming Lyu, Wen Zheng Terence Ng, Haopeng Zhang, Yew-Soon Ong, Ivor Tsang, Haiyan Yin

+ [LLM Agents for Bargaining with Utility-based Feedback](https://arxiv.org//abs/2505.22998)

	Jihwan Oh, Murad Aghazada, Se-Young Yun, Taehyeon Kim

+ [QLIP: A Dynamic Quadtree Vision Prior Enhances MLLM Performance Without Retraining](https://arxiv.org//abs/2505.23004)

	Kyle R. Chickering, Bangzheng Li, Muhao Chen

+ [Scalable Complexity Control Facilitates Reasoning Ability of LLMs](https://arxiv.org//abs/2505.23013)

	Liangkai Hang, Junjie Yao, Zhiwei Bai, Tianyi Chen, Yang Chen, Rongjie Diao, Hezhou Li, Pengxiao Lin, Zhiwei Wang, Cheng Xu, Zhongwang Zhang, Zhangchen Zhou, Zhiyu Li, Zehao Lin, Kai Chen, Feiyu Xiong, Yaoyu Zhang, Weinan E, Hongkang Yang, Zhi-Qin John Xu

+ [SCORPIO: Serving the Right Requests at the Right Time for Heterogeneous SLOs in LLM Inference](https://arxiv.org//abs/2505.23022)

	Yinghao Tang, Tingfeng Lan, Xiuqi Huang, Hui Lu, Wei Chen

+ [CDR-Agent: Intelligent Selection and Execution of Clinical Decision Rules Using Large Language Model Agents](https://arxiv.org//abs/2505.23055)

	Zhen Xiang, Aliyah R. Hsu, Austin V. Zane, Aaron E. Kornblith, Margaret J. Lin-Martore, Jasmanpreet C. Kaur, Vasuda M. Dokiparthi, Bo Li, Bin Yu

+ [DINGO: Constrained Inference for Diffusion LLMs](https://arxiv.org//abs/2505.23061)

	Tarun Suresh, Debangshu Banerjee, Shubham Ugare, Sasa Misailovic, Gagandeep Singh

+ [Weight Spectra Induced Efficient Model Adaptation](https://arxiv.org//abs/2505.23099)

	Chongjie Si, Xuankun Yang, Muqing Liu, Yadao Wang, Xiaokang Yang, Wenbo Su, Bo Zheng, Wei Shen

+ [Two Is Better Than One: Rotations Scale LoRAs](https://arxiv.org//abs/2505.23184)

	Hongcan Guo, Guoshun Nan, Yuan Yang, Diyang Zhang, Haotian Li, Zhican Chen, Qinchuan Zhou, Yuhan Ran, Xinye Cao, Sicong Leng, Xiaofeng Tao, Xudong Jiang

+ [Daunce: Data Attribution through Uncertainty Estimation](https://arxiv.org//abs/2505.23223)

	Xingyuan Pan, Chenlu Ye, Joseph Melkonian, Jiaqi W. Ma, Tong Zhang

+ [Diversity-Aware Policy Optimization for Large Language Model Reasoning](https://arxiv.org//abs/2505.23433)

	Jian Yao, Ran Cheng, Xingyu Wu, Jibin Wu, Kay Chen Tan

+ [AnchorAttention: Difference-Aware Sparse Attention with Stripe Granularity](https://arxiv.org//abs/2505.23520)

	Yu Zhang, Dong Guo, Fang Wu, Guoliang Zhu, Dian Ding, Yiming Zhang

+ [BioReason: Incentivizing Multimodal Biological Reasoning within a DNA-LLM Model](https://arxiv.org//abs/2505.23579)

	Adibvafa Fallahpour, Andrew Magnuson, Purav Gupta, Shihao Ma, Jack Naimer, Arnav Shah, Haonan Duan, Omar Ibrahim, Hani Goodarzi, Chris J. Maddison, Bo Wang

+ [LLM Performance for Code Generation on Noisy Tasks](https://arxiv.org//abs/2505.23598)

	Radzim Sendyka, Christian Cabrera, Andrei Paleyes, Diana Robinson, Neil Lawrence

+ [MCP Safety Training: Learning to Refuse Falsely Benign MCP Exploits using Improved Preference Alignment](https://arxiv.org//abs/2505.23634)

	John Halloran

+ [Continuous Chain of Thought Enables Parallel Exploration and Reasoning](https://arxiv.org//abs/2505.23648)

	Halil Alperen Gozeten, M. Emrullah Ildiz, Xuechen Zhang, Hrayr Harutyunyan, Ankit Singh Rawat, Samet Oymak

+ [How does Transformer Learn Implicit Reasoning?](https://arxiv.org//abs/2505.23653)

	Jiaran Ye, Zijun Yao, Zhidian Huang, Liangming Pan, Jinxin Liu, Yushi Bai, Amy Xin, Liu Weichuan, Xiaoyin Che, Lei Hou, Juanzi Li

+ [MuLoCo: Muon is a practical inner optimizer for DiLoCo](https://arxiv.org//abs/2505.23725)

	Benjamin Thérien, Xiaolong Huang, Irina Rish, Eugene Belilovsky

+ [Distortion of AI Alignment: Does Preference Optimization Optimize for Preferences?](https://arxiv.org//abs/2505.23749)

	Paul Gölz, Nika Haghtalab, Kunhe Yang

+ [KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction](https://arxiv.org//abs/2505.23416)

	Jang-Hyun Kim, Jinuk Kim, Sangwoo Kwon, Jae W. Lee, Sangdoo Yun, Hyun Oh Song

+ [Bayesian Perspective on Memorization and Reconstruction](https://arxiv.org//abs/2505.23658)

	Haim Kaplan, Yishay Mansour, Kobbi Nissim, Uri Stemmer

+ [Merge Hijacking: Backdoor Attacks to Model Merging of Large Language Models](https://arxiv.org//abs/2505.23561)

	Zenghui Yuan, Yangming Xu, Jiawen Shi, Pan Zhou, Lichao Sun

+ [Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and Improve](https://arxiv.org//abs/2505.23946)

	Yuanzhe Liu, Ryan Deng, Tim Kaler, Xuhao Chen, Charles E. Leiserson, Yao Ma, Jie Chen

+ [InterMT: Multi-Turn Interleaved Preference Alignment with Human Feedback](https://arxiv.org//abs/2505.23950)

	Boyuan Chen, Donghai Hong, Jiaming Ji, Jiacheng Zheng, Bowen Dong, Jiayi Zhou, Kaile Wang, Juntao Dai, Xuyao Wang, Wenqi Chen, Qirui Zheng, Wenxin Li, Sirui Han, Yike Guo, Yaodong Yang

+ [Multi-RAG: A Multimodal Retrieval-Augmented Generation System for Adaptive Video Understanding](https://arxiv.org//abs/2505.23990)

	Mingyang Mao, Mariela M. Perez-Cabarcas, Utteja Kallakuri, Nicholas R. Waytowich, Xiaomin Lin, Tinoosh Mohsenin

+ [Leave it to the Specialist: Repair Sparse LLMs with Sparse Fine-Tuning via Sparsity Evolution](https://arxiv.org//abs/2505.24037)

	Qiao Xiao, Alan Ansell, Boqian Wu, Lu Yin, Mykola Pechenizkiy, Shiwei Liu, Decebal Constantin Mocanu

+ [mRAG: Elucidating the Design Space of Multi-modal Retrieval-Augmented Generation](https://arxiv.org//abs/2505.24073)

	Chan-Wei Hu, Yueqi Wang, Shuo Xing, Chia-Ju Chen, Zhengzhong Tu

+ [Large Language Model-Based Agents for Automated Research Reproducibility: An Exploratory Study in Alzheimer's Disease](https://arxiv.org//abs/2505.23852)

	Nic Dobbins, Christelle Xiong, Kristine Lan, Meliha Yetisgen

+ [Revisiting Uncertainty Estimation and Calibration of Large Language Models](https://arxiv.org//abs/2505.23854)

	Linwei Tao, Yi-Fan Yeh, Minjing Dong, Tao Huang, Philip Torr, Chang Xu

+ [OMNIGUARD: An Efficient Approach for AI Safety Moderation Across Modalities](https://arxiv.org//abs/2505.23856)

	Sahil Verma, Keegan Hines, Jeff Bilmes, Charlotte Siska, Luke Zettlemoyer, Hila Gonen, Chandan Singh

+ [Infi-Med: Low-Resource Medical MLLMs with Robust Reasoning Evaluation](https://arxiv.org//abs/2505.23867)

	Zeyu Liu, Zhitian Hou, Yining Di, Kejing Yang, Zhijie Sang, Congkai Xie, Jingwen Yang, Siyuan Liu, Jialu Wang, Chunming Li, Ming Li, Hongxia Yang

+ [Noise-Robustness Through Noise: Asymmetric LoRA Adaption with Poisoning Expert](https://arxiv.org//abs/2505.23868)

	Zhaokun Wang, Jinyu Guo, Jingwen Pu, Lingfeng Chen, Hongli Pu, Jie Ou.Libo Qin, Wenhong Tian

+ [Actor-Critic based Online Data Mixing For Language Model Pre-Training](https://arxiv.org//abs/2505.23878)

	Jing Ma, Chenhao Dang, Mingjie Liao

+ [Reinforcement Learning for Better Verbalized Confidence in Long-Form Generation](https://arxiv.org//abs/2505.23912)

	Caiqi Zhang, Xiaochen Zhu, Chengzu Li, Nigel Collier, Andreas Vlachos

+ [Probing Association Biases in LLM Moderation Over-Sensitivity](https://arxiv.org//abs/2505.23914)

	Yuxin Wang, Botao Yu, Ivory Yang, Saeed Hassanpour, Soroush Vosoughi

+ [ChARM: Character-based Act-adaptive Reward Modeling for Advanced Role-Playing Language Agents](https://arxiv.org//abs/2505.23923)

	Feiteng Fang, Ting-En Lin, Yuchuan Wu, Xiong Liu, Xiang Huang, Dingwei Chen, Jing Ye, Haonan Zhang, Liang Zhu, Hamid Alinejad-Rokny, Min Yang, Fei Huang, Yongbin Li

+ [A Closer Look at Bias and Chain-of-Thought Faithfulness of Large (Vision) Language Models](https://arxiv.org//abs/2505.23945)

	Sriram Balasubramanian, Samyadeep Basu, Soheil Feizi

+ [Enhancing LLM-Based Code Generation with Complexity Metrics: A Feedback-Driven Approach](https://arxiv.org//abs/2505.23953)

	Melika Sepidband, Hamed Taherkhani, Song Wang, Hadi Hemmati

+ [Information Structure in Mappings: An Approach to Learning, Representation, and Generalisation](https://arxiv.org//abs/2505.23960)

	Henry Conklin

+ [Confidential Guardian: Cryptographically Prohibiting the Abuse of Model Abstention](https://arxiv.org//abs/2505.23968)

	Stephan Rabanser, Ali Shahin Shamsabadi, Olive Franzese, Xiao Wang, Adrian Weller, Nicolas Papernot

+ [Large Language Models for Controllable Multi-property Multi-objective Molecule Optimization](https://arxiv.org//abs/2505.23987)

	Vishal Dey, Xiao Hu, Xia Ning

+ [Is Your Model Fairly Certain? Uncertainty-Aware Fairness Evaluation for LLMs](https://arxiv.org//abs/2505.23996)

	Yinong Oliver Wang, Nivedha Sivakumar, Falaah Arif Khan, Rin Metcalf Susa, Adam Golinski, Natalie Mackraz, Barry-John Theobald, Luca Zappella, Nicholas Apostoloff

+ [Diversity of Transformer Layers: One Aspect of Parameter Scaling Laws](https://arxiv.org//abs/2505.24009)

	Hidetaka Kamigaito, Ying Zhang, Jingun Kwon, Katsuhiko Hayashi, Manabu Okumura, Taro Watanabe

+ [Large Language Model Meets Constraint Propagation](https://arxiv.org//abs/2505.24012)

	Alexandre Bonlarron, Florian Régin, Elisabetta De Maria, Jean-Charles Régin

+ [LLM Agents Should Employ Security Principles](https://arxiv.org//abs/2505.24019)

	Kaiyuan Zhang, Zian Su, Pin-Yu Chen, Elisa Bertino, Xiangyu Zhang, Ninghui Li

+ [LlamaRL: A Distributed Asynchronous Reinforcement Learning Framework for Efficient Large-scale LLM Trainin](https://arxiv.org//abs/2505.24034)

	Bo Wu, Sid Wang, Yunhao Tang, Jia Ding, Eryk Helenowski, Liang Tan, Tengyu Xu, Tushar Gowda, Zhengxing Chen, Chen Zhu, Xiaocheng Tang, Yundi Qian, Beibei Zhu, Rui Hou

+ [MedPAIR: Measuring Physicians and AI Relevance Alignment in Medical Question Answering](https://arxiv.org//abs/2505.24040)

	Yuexing Hao, Kumail Alhamoud, Hyewon Jeong, Haoran Zhang, Isha Puri, Philip Torr, Mike Schaekermann, Ariel D. Stern, Marzyeh Ghassemi

+ [DSR-Bench: Evaluating the Structural Reasoning Abilities of LLMs via Data Structures](https://arxiv.org//abs/2505.24069)

	Yu He, Yingxi Li, Colin White, Ellen Vitercik

+ [One Task Vector is not Enough: A Large-Scale Study for In-Context Learning](https://arxiv.org//abs/2505.23911)

	Pavel Tikhonov, Ivan Oseledets, Elena Tutubalina

+ [SwingArena: Competitive Programming Arena for Long-context GitHub Issue Solving](https://arxiv.org//abs/2505.23932)

	Wendong Xu, Jing Xiong, Chenyang Zhao, Qiujiang Chen, Haoran Wang, Hui Shen, Zhongwei Wan, Jianbo Dai, Taiqiang Wu, He Xiao, Chaofan Tao, Z. Morley Mao, Ying Sheng, Zhijiang Guo, Hongxia Yang, Bei Yu, Lingpeng Kong, Quanquan Gu, Ngai Wong

+ [Retrieval Augmented Generation based Large Language Models for Causality Mining](https://arxiv.org//abs/2505.23944)

	Thushara Manjari Naduvilakandy, Hyeju Jang, Mohammad Al Hasan

+ [FLAT-LLM: Fine-grained Low-rank Activation Space Transformation for Large Language Model Compression](https://arxiv.org//abs/2505.23966)

	Jiayi Tian, Ryan Solgi, Jinming Lu, Yifan Yang, Hai Li, Zheng Zhang

+ [Test-Time Training Done Right](https://arxiv.org//abs/2505.23884)

	Tianyuan Zhang, Sai Bi, Yicong Hong, Kai Zhang, Fujun Luan, Songlin Yang, Kalyan Sunkavalli, William T. Freeman, Hao Tan

+ [Preemptive Hallucination Reduction: An Input-Level Approach for Multimodal Language Model](https://arxiv.org//abs/2505.24007)

	Nokimul Hasan Arif, Shadman Rabby, Md Hefzul Hossain Papon, Sabbir Ahmed

+ [Vision Language Models are Biased](https://arxiv.org//abs/2505.23941)

	An Vo, Khai-Nguyen Nguyen, Mohammad Reza Taesiri, Vy Tuong Dang, Anh Totti Nguyen, Daeyoung Kim

+ [Thompson Sampling in Online RLHF with General Function Approximation](https://arxiv.org//abs/2505.23927)

	Songtao Feng, Jie Fu

+ [Differential Gated Self-Attention](https://arxiv.org//abs/2505.24054)

	Elpiniki Maria Lygizou, Mónika Farsang, Radu Grosu

+ [The Automated but Risky Game: Modeling Agent-to-Agent Negotiations and Transactions in Consumer Markets](https://arxiv.org//abs/2506.00073)

	Shenzhe Zhu, Jiao Sun, Yi Nian, Tobin South, Alex Pentland, Jiaxin Pei

+ [Unraveling SITT: Social Influence Technique Taxonomy and Detection with LLMs](https://arxiv.org//abs/2506.00061)

	Wiktoria Mieleszczenko-Kowszewicz, Beata Bajcar, Aleksander Szczęsny, Maciej Markiewicz, Jolanta Babiak, Berenika Dyczek, Przemysław Kazienko

+ [Mis-prompt: Benchmarking Large Language Models for Proactive Error Handling](https://arxiv.org//abs/2506.00064)

	Jiayi Zeng, Yizhe Feng, Mengliang He, Wenhui Lei, Wei Zhang, Zeming Liu, Xiaoming Shi, Aimin Zhou

+ [Literature Review Of Multi-Agent Debate For Problem-Solving](https://arxiv.org//abs/2506.00066)

	Arne Tillmann

+ [Probing Politico-Economic Bias in Multilingual Large Language Models: A Cultural Analysis of Low-Resource Pakistani Languages](https://arxiv.org//abs/2506.00068)

	Afrozah Nadeem, Mark Dras, Usman Naseem

+ [Evaluating the Sensitivity of LLMs to Prior Context](https://arxiv.org//abs/2506.00069)

	Robert Hankache, Kingsley Nketia Acheampong, Liang Song, Marek Brynda, Raad Khraishi, Greig A. Cowan

+ [Evaluating Prompt Engineering Techniques for Accuracy and Confidence Elicitation in Medical LLMs](https://arxiv.org//abs/2506.00072)

	Nariman Naderi, Zahra Atf, Peter R Lewis, Aref Mahjoub far, Seyed Amir Ahmad Safavi-Naini, Ali Soroush

+ [Whose Name Comes Up? Auditing LLM-Based Scholar Recommendations](https://arxiv.org//abs/2506.00074)

	Daniele Barolo, Chiara Valentin, Fariba Karimi, Luis Galárraga, Gonzalo G. Méndez, Lisette Espín-Noboa

+ [Reducing Latency in LLM-Based Natural Language Commands Processing for Robot Navigation](https://arxiv.org//abs/2506.00075)

	Diego Pollini, Bruna V. Guterres, Rodrigo S. Guerra, Ricardo B. Grando

+ [Gaussian mixture models as a proxy for interacting language models](https://arxiv.org//abs/2506.00077)

	Edward Wang, Tianyu Wang, Avanti Athreya, Vince Lyzinski, Carey E. Priebe

+ [SafeCOMM: What about Safety Alignment in Fine-Tuned Telecom Large Language Models?](https://arxiv.org//abs/2506.00062)

	Aladin Djuhera, Swanand Ravindra Kadhe, Farhan Ahmed, Syed Zawad, Holger Boche, Walid Saad

+ [Vid-SME: Membership Inference Attacks against Large Video Understanding Models](https://arxiv.org//abs/2506.03179)

	Qi Li, Runpeng Yu, Xinchao Wang

+ [Contextual Integrity in LLMs via Reasoning and Reinforcement Learning](https://arxiv.org//abs/2506.04245)

	Guangchen Lan, Huseyin A. Inan, Sahar Abdelnabi, Janardhan Kulkarni, Lukas Wutschitz, Reza Shokri, Christopher G. Brinton, Robert Sim

+ [CMIE: Combining MLLM Insights with External Evidence for Explainable Out-of-Context Misinformation Detection](https://arxiv.org//abs/2505.23449)

	Fanxiao Li, Jiaying Wu, Canyuan He, Wei Zhou

+ [A Survey of Generative Categories and Techniques in Multimodal Large Language Models](https://arxiv.org//abs/2506.10016)

	Longzhen Han, Awes Mubarak, Almas Baimagambetov, Nikolaos Polatidis, Thar Baker

# 2025-05-28
+ [From Reasoning to Learning: A Survey on Hypothesis Discovery and Rule Learning with Large Language Models](https://arxiv.org//abs/2505.21935)

	Kaiyu He, Zhiyu Chen

+ [Efficiently Enhancing General Agents With Hierarchical-categorical Memory](https://arxiv.org//abs/2505.22006)

	Changze Qiao, Mingming Lu

+ [VIRAL: Vision-grounded Integration for Reward design And Learning](https://arxiv.org//abs/2505.22092)

	Valentin Cuzin-Rambaud, Emilien Komlenovic, Alexandre Faure, Bruno Yun

+ [Visual Large Language Models Exhibit Human-Level Cognitive Flexibility in the Wisconsin Card Sorting Test](https://arxiv.org//abs/2505.22112)

	Guangfu Hao, Frederic Alexandre, Shan Yu

+ [What Makes a Good Reasoning Chain? Uncovering Structural Patterns in Long Chain-of-Thought Reasoning](https://arxiv.org//abs/2505.22148)

	Gangwei Jiang, Yahui Liu, Zhaoyi Li, Qi Wang, Fuzheng Zhang, Linqi Song, Ying Wei, Defu Lian

+ [Rethinking the Unsolvable: When In-Context Search Meets Test-Time Scaling](https://arxiv.org//abs/2505.22290)

	Fanzeng Xia, Yidong Luo, Tinko Sebastian Bartels, Yaqi Xu, Tongxin Li

+ [From Large AI Models to Agentic AI: A Tutorial on Future Intelligent Communications](https://arxiv.org//abs/2505.22311)

	Feibo Jiang, Cunhua Pan, Li Dong, Kezhi Wang, Octavia A. Dobre, Merouane Debbah

+ [AgentDNS: A Root Domain Naming System for LLM Agents](https://arxiv.org//abs/2505.22368)

	Enfang Cui, Yujun Cheng, Rui She, Dan Liu, Zhiyuan Liang, Minxin Guo, Tianzheng Li, Qian Wei, Wenjuan Xing, Zhijie Zhong

+ [Evaluating the Retrieval Robustness of Large Language Models](https://arxiv.org//abs/2505.21870)

	Shuyang Cao, Karthik Radhakrishnan, David Rosenberg, Steven Lu, Pengxiang Cheng, Lu Wang, Shiyue Zhang

+ [Co-Saving: Resource Aware Multi-Agent Collaboration for Software Development](https://arxiv.org//abs/2505.21898)

	Rennai Qiu, Chen Qian, Ran Li, Yufan Dang, Weize Chen, Cheng Yang, Yingli Zhang, Ye Tian, Xuantang Xiong, Lei Han, Zhiyuan Liu, Maosong Sun

+ [Reinforcement Learning for Out-of-Distribution Reasoning in LLMs: An Empirical Study on Diagnosis-Related Group Coding](https://arxiv.org//abs/2505.21908)

	Hanyin Wang, Zhenbang Wu, Gururaj Kolar, Hariprasad Korsapati, Brian Bartlett, Bryan Hull, Jimeng Sun

+ [Towards Efficient Key-Value Cache Management for Prefix Prefilling in LLM Inference](https://arxiv.org//abs/2505.21919)

	Yue Zhu, Hao Yu, Chen Wang, Zhuoran Liu, Eun Kyung Lee

+ [Cross-modal RAG: Sub-dimensional Retrieval-Augmented Text-to-Image Generation](https://arxiv.org//abs/2505.21956)

	Mengdan Zhu, Senhao Cheng, Guangji Bai, Yifei Zhang, Liang Zhao

+ [LaMDAgent: An Autonomous Framework for Post-Training Pipeline Optimization via LLM Agents](https://arxiv.org//abs/2505.21963)

	Taro Yano, Yoichi Ishibashi, Masafumi Oyamada

+ [Judging LLMs on a Simplex](https://arxiv.org//abs/2505.21972)

	Patrick Vossler, Fan Xia, Yifan Mai, Jean Feng

+ [VRAG-RL: Empower Vision-Perception-Based RAG for Visually Rich Information Understanding via Iterative Reasoning with Reinforcement Learning](https://arxiv.org//abs/2505.22019)

	Qiuchen Wang, Ruixue Ding, Yu Zeng, Zehui Chen, Lin Chen, Shihang Wang, Pengjun Xie, Fei Huang, Feng Zhao

+ [Estimating the Effects of Sample Training Orders for Large Language Models without Retraining](https://arxiv.org//abs/2505.22042)

	Hao Yang, Haoxuan Li, Mengyue Yang, Xu Chen, Mingming Gong

+ [From Failures to Fixes: LLM-Driven Scenario Repair for Self-Evolving Autonomous Driving](https://arxiv.org//abs/2505.22067)

	Xinyu Xia, Xingjun Ma, Yunfeng Hu, Ting Qu, Hong Chen, Xun Gong

+ [Beyond path selection: Better LLMs for Scientific Information Extraction with MimicSFT and Relevance and Rule-induced(R$^2$)GRPO](https://arxiv.org//abs/2505.22068)

	Ran Li, Shimin Di, Yuchen Liu, Chen Jing, Yu Qiu, Lei Chen

+ [Let's Predict Sentence by Sentence](https://arxiv.org//abs/2505.22202)

	Hyeonbin Hwang, Byeongguk Jeon, Seungone Kim, Jiyeon Kim, Hoyeon Chang, Sohee Yang, Seungpil Won, Dohaeng Lee, Youbin Ahn, Minjoon Seo

+ [Test-Time Immunization: A Universal Defense Framework Against Jailbreaks for (Multimodal) Large Language Models](https://arxiv.org//abs/2505.22271)

	Yongcan Yu, Yanbo Wang, Ran He, Jian Liang

+ [From Dormant to Deleted: Tamper-Resistant Unlearning Through Weight-Space Regularization](https://arxiv.org//abs/2505.22310)

	Shoaib Ahmed Siddiqui, Adrian Weller, David Krueger, Gintare Karolina Dziugaite, Michael Curtis Mozer, Eleni Triantafillou

+ [Skywork Open Reasoner 1 Technical Report](https://arxiv.org//abs/2505.22312)

	Jujie He, Jiacai Liu, Chris Yuhao Liu, Rui Yan, Chaojie Wang, Peng Cheng, Xiaoyu Zhang, Fuxiang Zhang, Jiacheng Xu, Wei Shen, Siyuan Li, Liang Zeng, Tianwen Wei, Cheng Cheng, Bo An, Yang Liu, Yahui Zhou

+ [Advancing Multimodal Reasoning via Reinforcement Learning with Cold Start](https://arxiv.org//abs/2505.22334)

	Lai Wei, Yuting Li, Kaipeng Zheng, Chen Wang, Yue Wang, Linghe Kong, Lichao Sun, Weiran Huang

+ [Text2Grad: Reinforcement Learning from Natural Language Feedback](https://arxiv.org//abs/2505.22338)

	Hanyang Wang, Lu Wang, Chaoyun Zhang, Tianjun Mao, Si Qin, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang

+ [Budget-Adaptive Adapter Tuning in Orthogonal Subspaces for Continual Learning in LLMs](https://arxiv.org//abs/2505.22358)

	Zhiyi Wan, Wanrou Du, Liang Li, Miao Pan, Xiaoqi Qin

+ [Mitigating Overthinking in Large Reasoning Models via Manifold Steering](https://arxiv.org//abs/2505.22411)

	Yao Huang, Huanran Chen, Shouwei Ruan, Yichi Zhang, Xingxing Wei, Yinpeng Dong

+ [Scaling Reasoning without Attention](https://arxiv.org//abs/2505.22425)

	Xueliang Zhao, Wei Wu, Lingpeng Kong

+ [Unsupervised Post-Training for Multi-Modal LLM Reasoning via GRPO](https://arxiv.org//abs/2505.22453)

	Lai Wei, Yuting Li, Chen Wang, Yue Wang, Linghe Kong, Weiran Huang, Lichao Sun

+ [Topological Structure Learning Should Be A Research Priority for LLM-Based Multi-Agent Systems](https://arxiv.org//abs/2505.22467)

	Jiaxi Yang, Mengqi Zhang, Yiqiao Jin, Hao Chen, Qingsong Wen, Lu Lin, Yi He, Weijie Xu, James Evans, Jindong Wang

+ [From Strangers to Assistants: Fast Desire Alignment for Embodied Agent-User Adaptation](https://arxiv.org//abs/2505.22503)

	Yuanfei Wang, Xinju Huang, Fangwei Zhong, Yaodong Yang, Yizhou Wang, Yuanpei Chen, Hao Dong

+ [ClaimPKG: Enhancing Claim Verification via Pseudo-Subgraph Generation with Lightweight Specialized LLM](https://arxiv.org//abs/2505.22552)

	Hoang Pham, Thanh-Do Nguyen, Khac-Hoai Nam Bui

+ [Agent-UniRAG: A Trainable Open-Source LLM Agent Framework for Unified Retrieval-Augmented Generation Systems](https://arxiv.org//abs/2505.22571)

	Hoang Pham, Khac-Hoai Nam Bui

+ [Fusion Steering: Prompt-Specific Activation Control](https://arxiv.org//abs/2505.22572)

	Waldemar Chang, Alhassan Yasin

+ [GitGoodBench: A Novel Benchmark For Evaluating Agentic Performance On Git](https://arxiv.org//abs/2505.22583)

	Tobias Lindenbauer, Egor Bogomolov, Yaroslav Zharov

+ [Self-Error-Instruct: Generalizing from Errors for LLMs Mathematical Reasoning](https://arxiv.org//abs/2505.22591)

	Erxin Yu, Jing Li, Ming Liao, Qi Zhu, Boyang Xue, Minghui Xu, Baojun Wang, Lanqing Hong, Fei Mi, Lifeng Shang

+ [The Entropy Mechanism of Reinforcement Learning for Reasoning Language Models](https://arxiv.org//abs/2505.22617)

	Ganqu Cui, Yuchen Zhang, Jiacheng Chen, Lifan Yuan, Zhi Wang, Yuxin Zuo, Haozhan Li, Yuchen Fan, Huayu Chen, Weize Chen, Zhiyuan Liu, Hao Peng, Lei Bai, Wanli Ouyang, Yu Cheng, Bowen Zhou, Ning Ding

+ [Spatial Knowledge Graph-Guided Multimodal Synthesis](https://arxiv.org//abs/2505.22633)

	Yida Xue, Zhen Bi, Jinnan Yang, Jungang Lou, Huajun Chen, Ningyu Zhang

+ [Learning Composable Chains-of-Thought](https://arxiv.org//abs/2505.22635)

	Fangcong Yin, Zeyu Leo Liu, Liu Leqi, Xi Ye, Greg Durrett

+ [Position: Uncertainty Quantification Needs Reassessment for Large-language Model Agents](https://arxiv.org//abs/2505.22655)

	Michael Kirchhof, Gjergji Kasneci, Enkelejda Kasneci

+ [3DLLM-Mem: Long-Term Spatial-Temporal Memory for Embodied 3D Large Language Model](https://arxiv.org//abs/2505.22657)

	Wenbo Hu, Yining Hong, Yanjun Wang, Leison Gao, Zibu Wei, Xingcheng Yao, Nanyun Peng, Yonatan Bitton, Idan Szpektor, Kai-Wei Chang

+ [Principled Content Selection to Generate Diverse and Personalized Multi-Document Summaries](https://arxiv.org//abs/2505.21859)

	Vishakh Padmakumar, Zichao Wang, David Arbour, Jennifer Healey

+ [EFIM: Efficient Serving of LLMs for Infilling Tasks with Improved KV Cache Reuse](https://arxiv.org//abs/2505.21889)

	Tianyu Guo, Hande Dong, Yichong Leng, Feng Liu, Cheater Lin, Nong Xiao, Xianwei Zhang

+ [RedTeamCUA: Realistic Adversarial Testing of Computer-Use Agents in Hybrid Web-OS Environments](https://arxiv.org//abs/2505.21936)

	Zeyi Liao, Jaylen Jones, Linxi Jiang, Eric Fosler-Lussier, Yu Su, Zhiqiang Lin, Huan Sun

+ [RISE: Reasoning Enhancement via Iterative Self-Exploration in Multi-hop Question Answering](https://arxiv.org//abs/2505.21940)

	Bolei He, Xinran He, Mengke Chen, Xianwei Xue, Ying Zhu, Zhenhua Ling

+ [Test-Time Scaling with Repeated Sampling Improves Multilingual Text Generation](https://arxiv.org//abs/2505.21941)

	Ashim Gupta, Vivek Srikumar

+ [Resolving Knowledge Conflicts in Domain-specific Data Selection: A Case Study on Medical Instruction-tuning](https://arxiv.org//abs/2505.21958)

	Qihuang Zhong, Liang Ding, Fei Liao, Juhua Liu, Bo Du, Dacheng Tao

+ [Seeing the Threat: Vulnerabilities in Vision-Language Models to Adversarial Attack](https://arxiv.org//abs/2505.21967)

	Juan Ren, Mark Dras, Usman Naseem

+ [Found in Translation: Measuring Multilingual LLM Consistency as Simple as Translate then Evaluate](https://arxiv.org//abs/2505.21999)

	Ashim Gupta, Maitrey Mehta, Zhichao Xu, Vivek Srikumar

+ [CoThink: Token-Efficient Reasoning via Instruct Models Guiding Reasoning Models](https://arxiv.org//abs/2505.22017)

	Siqi Fan, Peng Han, Shuo Shang, Yequan Wang, Aixin Sun

+ [Jailbreak Distillation: Renewable Safety Benchmarking](https://arxiv.org//abs/2505.22037)

	Jingyu Zhang, Ahmed Elgohary, Xiawei Wang, A S M Iftekhar, Ahmed Magooda, Benjamin Van Durme, Daniel Khashabi, Kyle Jackson

+ [Safeguarding Privacy of Retrieval Data against Membership Inference Attacks: Is This Query Too Close to Home?](https://arxiv.org//abs/2505.22061)

	Yujin Choi, Youngjoo Park, Junyoung Byun, Jaewook Lee, Jinseong Park

+ [ArgInstruct: Specialized Instruction Fine-Tuning for Computational Argumentation](https://arxiv.org//abs/2505.22076)

	Maja Stahl, Timon Ziegenbein, Joonsuk Park, Henning Wachsmuth

+ [Learning to Route Queries Across Knowledge Bases for Step-wise Retrieval-Augmented Reasoning](https://arxiv.org//abs/2505.22095)

	Chunyi Peng, Zhipeng Xu, Zhenghao Liu, Yishan Li, Yukun Yan, Shuo Wang, Zhiyuan Liu, Yu Gu, Minghe Yu, Ge Yu, Maosong Sun

+ [MemOS: An Operating System for Memory-Augmented Generation (MAG) in Large Language Models](https://arxiv.org//abs/2505.22101)

	Zhiyu Li, Shichao Song, Hanyu Wang, Simin Niu, Ding Chen, Jiawei Yang, Chenyang Xi, Huayi Lai, Jihao Zhao, Yezhaohui Wang, Junpeng Ren, Zehao Lin, Jiahao Huo, Tianyi Chen, Kai Chen, Kehang Li, Zhiqiang Yin, Qingchen Yu, Bo Tang, Hongkang Yang, Zhi-Qin John Xu, Feiyu Xiong

+ [THINK-Bench: Evaluating Thinking Efficiency and Chain-of-Thought Quality of Large Reasoning Models](https://arxiv.org//abs/2505.22113)

	Zhiyuan Li, Yi Chang, Yuan Wu

+ [LoKI: Low-damage Knowledge Implanting of Large Language Models](https://arxiv.org//abs/2505.22120)

	Runyu Wang, Peng Ping, Zhengyu Guo, Xiaoye Zhang, Quan Shi, Liting Zhou, Tianbo Ji

+ [EULER: Enhancing the Reasoning Ability of Large Language Models through Error-Induced Learning](https://arxiv.org//abs/2505.22131)

	Zhuoyang Wu, Xinze Li, Zhenghao Liu, Yukun Yan, Zhiyuan Liu, Minghe Yu, Cheng Yang, Yu Gu, Ge Yu, Maosong Sun

+ [InComeS: Integrating Compression and Selection Mechanisms into LLMs for Efficient Model Editing](https://arxiv.org//abs/2505.22156)

	Shuaiyi Li, Zhisong Zhang, Yang Deng, Chenlong Deng, Tianqing Fang, Hongming Zhang, Haitao Mi, Dong Yu, Wai Lam

+ [Stratified Selective Sampling for Instruction Tuning with Dedicated Scoring Strategy](https://arxiv.org//abs/2505.22157)

	Paramita Mirza, Lucas Weber, Fabian Küch

+ [ReliableEval: A Recipe for Stochastic LLM Evaluation via Method of Moments](https://arxiv.org//abs/2505.22169)

	Gili Lior, Eliya Habba, Shahar Levy, Avi Caciularu, Gabriel Stanovsky

+ [Reverse Preference Optimization for Complex Instruction Following](https://arxiv.org//abs/2505.22172)

	Xiang Huang, Ting-En Lin, Feiteng Fang, Yuchuan Wu, Hangyu Li, Yuzhong Qu, Fei Huang, Yongbin Li

+ [Adaptive Detoxification: Safeguarding General Capabilities of LLMs through Toxicity-Aware Knowledge Editing](https://arxiv.org//abs/2505.22298)

	Yifan Lu, Jing Li, Yigeng Zhou, Yihui Zhang, Wenya Wang, Xiucheng Li, Meishan Zhang, Fangming Liu, Jun Yu, Min Zhang

+ [If Pigs Could Fly... Can LLMs Logically Reason Through Counterfactuals?](https://arxiv.org//abs/2505.22318)

	Ishwar B Balappanawar, Vamshi Krishna Bonagiri, Anish R Joishy, Manas Gaur, Krishnaprasad Thirunarayan, Ponnurangam Kumaraguru

+ [Advancing Expert Specialization for Better MoE](https://arxiv.org//abs/2505.22323)

	Hongcan Guo, Haolang Lu, Guoshun Nan, Bolun Chu, Jialin Zhuang, Yuan Yang, Wenhao Che, Sicong Leng, Qimei Cui, Xudong Jiang

+ [LLMs Struggle to Reject False Presuppositions when Misinformation Stakes are High](https://arxiv.org//abs/2505.22354)

	Judith Sieker, Clara Lachenmaier, Sina Zarrieß

+ [Pangu Embedded: An Efficient Dual-system LLM Reasoner with Metacognition](https://arxiv.org//abs/2505.22375)

	Hanting Chen, Yasheng Wang, Kai Han, Dong Li, Lin Li, Zhenni Bi, Jinpeng Li, Haoyu Wang, Fei Mi, Mingjian Zhu, Bin Wang, Kaikai Song, Yifei Fu, Xu He, Yu Luo, Chong Zhu, Quan He, Xueyu Wu, Wei He, Hailin Hu, Yehui Tang, Dacheng Tao, Xinghao Chen, Yunhe Wang, Other Contributors

+ [RAG-Zeval: Towards Robust and Interpretable Evaluation on RAG Responses through End-to-End Rule-Guided Reasoning](https://arxiv.org//abs/2505.22430)

	Kun Li, Yunxiang Li, Tianhua Zhang, Hongyin Luo, Xixin Wu, James Glass, Helen Meng

+ [EvolveSearch: An Iterative Self-Evolving Search Agent](https://arxiv.org//abs/2505.22501)

	Dingchu Zhang, Yida Zhao, Jialong Wu, Baixuan Li, Wenbiao Yin, Liwen Zhang, Yong Jiang, Yufeng Li, Kewei Tu, Pengjun Xie, Fei Huang

+ [Emotion-o1: Adaptive Long Reasoning for Emotion Understanding in LLMs](https://arxiv.org//abs/2505.22548)

	Changhao Song, Yazhou Zhang, Peng Zhang

+ [Do Large Language Models Think Like the Brain? Sentence-Level Evidence from fMRI and Hierarchical Embeddings](https://arxiv.org//abs/2505.22563)

	Yu Lei, Xingyang Ge, Yi Zhang, Yiming Yang, Bolei Ma

+ [Less, but Better: Efficient Multilingual Expansion for LLMs via Layer-wise Mixture-of-Experts](https://arxiv.org//abs/2505.22582)

	Xue Zhang, Yunlong Liang, Fandong Meng, Songming Zhang, Yufeng Chen, Jinan Xu, Jie Zhou

+ [Precise In-Parameter Concept Erasure in Large Language Models](https://arxiv.org//abs/2505.22586)

	Yoav Gur-Arieh, Clara Suslik, Yihuai Hong, Fazl Barez, Mor Geva

+ [Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV Cache and Parallel Decoding](https://arxiv.org//abs/2505.22618)

	Chengyue Wu, Hao Zhang, Shuchen Xue, Zhijian Liu, Shizhe Diao, Ligeng Zhu, Ping Luo, Song Han, Enze Xie

+ [Stochastic Chameleons: Irrelevant Context Hallucinations Reveal Class-Based (Mis)Generalization in LLMs](https://arxiv.org//abs/2505.22630)

	Ziling Cheng, Meng Cao, Marc-Antoine Rondeau, Jackie Chi Kit Cheung

+ [WebDancer: Towards Autonomous Information Seeking Agency](https://arxiv.org//abs/2505.22648)

	Jialong Wu, Baixuan Li, Runnan Fang, Wenbiao Yin, Liwen Zhang, Zhengwei Tao, Dingchu Zhang, Zekun Xi, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou

+ [The Climb Carves Wisdom Deeper Than the Summit: On the Noisy Rewards in Learning to Reason](https://arxiv.org//abs/2505.22653)

	Ang Lv, Ruobing Xie, Xingwu Sun, Zhanhui Kang, Rui Yan

+ [GuessArena: Guess Who I Am? A Self-Adaptive Framework for Evaluating LLMs in Domain-Specific Knowledge and Reasoning](https://arxiv.org//abs/2505.22661)

	Qingchen Yu, Zifan Zheng, Ding Chen, Simin Niu, Bo Tang, Feiyu Xiong, Zhiyu Li

+ [AutoL2S: Auto Long-Short Reasoning for Efficient Large Language Models](https://arxiv.org//abs/2505.22662)

	Feng Luo, Yu-Neng Chuang, Guanchu Wang, Hoang Anh Duy Le, Shaochen Zhong, Hongyi Liu, Jiayi Yuan, Yang Sui, Vladimir Braverman, Vipin Chaudhary, Xia Hu

+ [EnsemW2S: Enhancing Weak-to-Strong Generalization with Large Language Model Ensembles](https://arxiv.org//abs/2505.21959)

	Aakriti Agrawal, Mucong Ding, Zora Che, Chenghao Deng, Anirudh Satheesh, Bang An, Bayan Bruss, John Langford, Furong Huang

+ [UI-Evol: Automatic Knowledge Evolving for Computer Use Agents](https://arxiv.org//abs/2505.21964)

	Ziyun Zhang, Xinyi Liu, Xiaoyi Zhang, Jun Wang, Gang Chen, Yan Lu

+ [Look & Mark: Leveraging Radiologist Eye Fixations and Bounding boxes in Multimodal Large Language Models for Chest X-ray Report Generation](https://arxiv.org//abs/2505.22222)

	Yunsoo Kim, Jinge Wu, Su-Hwan Kim, Pardeep Vasudev, Jiashu Shen, Honghan Wu

+ [Evaluation of LLMs in Speech is Often Flawed: Test Set Contamination in Large Language Models for Speech Recognition](https://arxiv.org//abs/2505.22251)

	Yuan Tseng, Titouan Parcollet, Rogier van Dalen, Shucong Zhang, Sourav Bhattacharya

+ [Sherlock: Self-Correcting Reasoning in Vision-Language Models](https://arxiv.org//abs/2505.22651)

	Yi Ding, Ruqi Zhang

+ [Zooming from Context to Cue: Hierarchical Preference Optimization for Multi-Image MLLMs](https://arxiv.org//abs/2505.22396)

	Xudong Li, Mengdan Zhang, Peixian Chen, Xiawu Zheng, Yan Zhang, Jingyuan Zheng, Yunhang Shen, Ke Li, Chaoyou Fu, Xing Sun, Rongrong Ji

+ [ACE: Exploring Activation Cosine Similarity and Variance for Accurate and Calibration-Efficient LLM Pruning](https://arxiv.org//abs/2505.21987)

	Zhendong Mi, Zhenglun Kong, Geng Yuan, Shaoyi Huang

+ [Detecting Undesired Process Behavior by Means of Retrieval Augmented Generation](https://arxiv.org//abs/2505.22041)

	Michael Grohs, Adrian Rebmann, Jana-Rebecca Rehse

+ [Transformers Pretrained on Procedural Data Contain Modular Structures for Algorithmic Reasoning](https://arxiv.org//abs/2505.22308)

	Zachary Shinnick, Liangze Jiang, Hemanth Saratchandran, Anton van den Hengel, Damien Teney

+ [Look Within or Look Beyond? A Theoretical Comparison Between Parameter-Efficient and Full Fine-Tuning](https://arxiv.org//abs/2505.22355)

	Yongkang Liu, Xingle Xu, Ercong Nie, Zijing Wang, Shi Feng, Daling Wang, Qian Li, Hinrich Schütze

+ [Sparsification and Reconstruction from the Perspective of Representation Geometry](https://arxiv.org//abs/2505.22506)

	Wenjie Sun, Bingzhe Wu, Zhile Yang, Chengke Wu

+ [Understanding (Un)Reliability of Steering Vectors in Language Models](https://arxiv.org//abs/2505.22637)

	Joschka Braun, Carsten Eickhoff, David Krueger, Seyed Ali Bahrainian, Dmitrii Krasheninnikov

+ [On Learning Verifiers for Chain-of-Thought Reasoning](https://arxiv.org//abs/2505.22650)

	Maria-Florina Balcan, Avrim Blum, Zhiyuan Li, Dravyansh Sharma

+ [VulBinLLM: LLM-powered Vulnerability Detection for Stripped Binaries](https://arxiv.org//abs/2505.22010)

	Nasir Hussain, Haohan Chen, Chanh Tran, Philip Huang, Zhuohao Li, Pravir Chugh, William Chen, Ashish Kundu, Yuan Tian

+ [Does Johnny Get the Message? Evaluating Cybersecurity Notifications for Everyday Users](https://arxiv.org//abs/2505.22435)

	Victor Jüttner, Erik Buchmann

+ [Privacy-preserving Prompt Personalization in Federated Learning for Multimodal Large Language Models](https://arxiv.org//abs/2505.22447)

	Sizai Hou, Songze Li, Baturalp Buyukates

+ [Design and testing of an agent chatbot supporting decision making with public transport data](https://arxiv.org//abs/2505.22698)

	Luca Fantin, Marco Antonelli, Margherita Cesetti, Daniele Irto, Bruno Zamengo, Francesco Silvestri

+ [Training Language Models to Generate Quality Code with Program Analysis Feedback](https://arxiv.org//abs/2505.22704)

	Feng Yao, Zilong Wang, Liyuan Liu, Junxia Cui, Li Zhong, Xiaohan Fu, Haohui Mai, Vish Krishnan, Jianfeng Gao, Jingbo Shang

+ [Pre-Training Curriculum for Multi-Token Prediction in Language Models](https://arxiv.org//abs/2505.22757)

	Ansar Aynetdinov, Alan Akbik

+ [In Dialogue with Intelligence: Rethinking Large Language Models as Collective Knowledge](https://arxiv.org//abs/2505.22767)

	Eleni Vasilaki

+ [First Steps Towards Overhearing LLM Agents: A Case Study With Dungeons & Dragons Gameplay](https://arxiv.org//abs/2505.22809)

	Andrew Zhu, Evan Osgood, Chris Callison-Burch

+ [A Tool for Generating Exceptional Behavior Tests With Large Language Models](https://arxiv.org//abs/2505.22818)

	Linghan Zhong, Samuel Yuan, Jiyang Zhang, Yu Liu, Pengyu Nie, Junyi Jessy Li, Milos Gligoric

+ [RocqStar: Leveraging Similarity-driven Retrieval and Agentic Systems for Rocq generation](https://arxiv.org//abs/2505.22846)

	Nikita Khramov, Andrei Kozyrev, Gleb Solovev, Anton Podkopaev

+ [Operationalizing CaMeL: Strengthening LLM Defenses for Enterprise Deployment](https://arxiv.org//abs/2505.22852)

	Krti Tallam, Emma Miller

+ [Permissioned LLMs: Enforcing Access Control in Large Language Models](https://arxiv.org//abs/2505.22860)

	Bargav Jayaraman, Virendra J. Marathe, Hamid Mozaffari, William F. Shen, Krishnaram Kenthapadi

+ [BugWhisperer: Fine-Tuning LLMs for SoC Hardware Vulnerability Detection](https://arxiv.org//abs/2505.22878)

	Shams Tarek, Dipayan Saha, Sujan Kumar Saha, Farimah Farahmandi

+ [HiLDe: Intentional Code Generation via Human-in-the-Loop Decoding](https://arxiv.org//abs/2505.22906)

	Emmanuel Anaya González, Raven Rothkopf, Sorin Lerner, Nadia Polikarpova

+ [Scalable Parameter and Memory Efficient Pretraining for LLM: Recent Algorithmic Advances and Benchmarking](https://arxiv.org//abs/2505.22922)

	Athanasios Glentis, Jiaxiang Li, Qiulin Shang, Andi Han, Ioannis Tsaknakis, Quan Wei, Mingyi Hong

+ [Unraveling LoRA Interference: Orthogonal Subspaces for Robust Model Merging](https://arxiv.org//abs/2505.22934)

	Haobo Zhang, Jiayu Zhou

+ [WorkForceAgent-R1: Incentivizing Reasoning Capability in LLM-based Web Agents via Reinforcement Learning](https://arxiv.org//abs/2505.22942)

	Yuchen Zhuang, Di Jin, Jiaao Chen, Wenqi Shi, Hanrui Wang, Chao Zhang

+ [Can LLMs Deceive CLIP? Benchmarking Adversarial Compositionality of Pre-trained Multimodal Representation via Text Updates](https://arxiv.org//abs/2505.22943)

	Jaewoo Ahn, Heeseung Yun, Dayoon Ko, Gunhee Kim

+ [OWL: Probing Cross-Lingual Recall of Memorized Texts via World Literature](https://arxiv.org//abs/2505.22945)

	Alisha Srivastava, Emir Korukluoglu, Minh Nhat Le, Duyen Tran, Chau Minh Pham, Marzena Karpinska, Mohit Iyyer

+ [DORAEMON: Decentralized Ontology-aware Reliable Agent with Enhanced Memory Oriented Navigation](https://arxiv.org//abs/2505.21969)

	Tianjun Gu, Linfeng Li, Xuhong Wang, Chenghua Gong, Jingyu Gong, Zhizhong Zhang, Yuan Xie, Lizhuang Ma, Xin Tan

+ [Maximizing Confidence Alone Improves Reasoning](https://arxiv.org//abs/2505.22660)

	Mihir Prabhudesai, Lili Chen, Alex Ippoliti, Katerina Fragkiadaki, Hao Liu, Deepak Pathak

+ [Climate Finance Bench](https://arxiv.org//abs/2505.22752)

	Rafik Mankour, Yassine Chafai, Hamada Saleh, Ghassen Ben Hassine, Thibaud Barreau, Peter Tankov

+ [MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain Chatbots and Dialogue Evaluators](https://arxiv.org//abs/2505.22777)

	John Mendonça, Alon Lavie, Isabel Trancoso

+ [Self-Critique and Refinement for Faithful Natural Language Explanations](https://arxiv.org//abs/2505.22823)

	Yingming Wang, Pepa Atanasova

+ [Bayesian Attention Mechanism: A Probabilistic Framework for Positional Encoding and Context Length Extrapolation](https://arxiv.org//abs/2505.22842)

	Arthur S. Bianchessi, Rodrigo C. Barros, Lucas S. Kupssinskü

+ [When Models Reason in Your Language: Controlling Thinking Trace Language Comes at the Cost of Accuracy](https://arxiv.org//abs/2505.22888)

	Jirui Qi, Shan Chen, Zidi Xiong, Raquel Fernández, Danielle S. Bitterman, Arianna Bisazza

+ [Talent or Luck? Evaluating Attribution Bias in Large Language Models](https://arxiv.org//abs/2505.22910)

	Chahat Raj, Mahika Banerjee, Aylin Caliskan, Antonios Anastasopoulos, Ziwei Zhu

+ [ER-REASON: A Benchmark Dataset for LLM-Based Clinical Reasoning in the Emergency Room](https://arxiv.org//abs/2505.22919)

	Nikita Mehandru, Niloufar Golchini, David Bamman, Travis Zack, Melanie F. Molina, Ahmed Alaa

+ [Structured Memory Mechanisms for Stable Context Representation in Large Language Models](https://arxiv.org//abs/2505.22921)

	Yue Xing, Tao Yang, Yijiashun Qi, Minggu Wei, Yu Cheng, Honghui Xin

+ [Conversational Alignment with Artificial Intelligence in Context](https://arxiv.org//abs/2505.22907)

	Rachel Katharine Sterken (University of Hong Kong), James Ravi Kirkpatrick (University of Oxford and Magdalen College, Oxford)

+ [SlimLLM: Accurate Structured Pruning for Large Language Models](https://arxiv.org//abs/2505.22689)

	Jialong Guo, Xinghao Chen, Yehui Tang, Yunhe Wang

+ [MoRE: A Mixture of Low-Rank Experts for Adaptive Multi-Task Learning](https://arxiv.org//abs/2505.22694)

	Dacao Zhang, Kun Zhang, Shimao Chu, Le Wu, Xin Li, Si Wei

+ [Update Your Transformer to the Latest Release: Re-Basin of Task Vectors](https://arxiv.org//abs/2505.22697)

	Filippo Rinaldi, Giacomo Capitani, Lorenzo Bonicelli, Donato Crisostomi, Federico Bolelli, Elisa Ficarra, Emanuele Rodolà, Simone Calderara, Angelo Porrello

+ [Mustafar: Promoting Unstructured Sparsity for KV Cache Pruning in LLM Inference](https://arxiv.org//abs/2505.22913)

	Donghyeon Joo, Helya Hosseini, Ramyad Hadidi, Bahar Asgari

+ [Highly Efficient and Effective LLMs with Multi-Boolean Architectures](https://arxiv.org//abs/2505.22811)

	Ba-Hien Tran, Van Minh Nguyen

+ [TensorShield: Safeguarding On-Device Inference by Shielding Critical DNN Tensors with TEE](https://arxiv.org//abs/2505.22735)

	Tong Sun, Bowen Jiang, Hailong Lin, Borui Li, Yixiao Teng, Yi Gao, Wei Dong

+ [Large Language Models Often Know When They Are Being Evaluated](https://arxiv.org//abs/2505.23836)

	Joe Needham, Giles Edkins, Govind Pimpale, Henning Bartsch, Marius Hobbhahn

+ [Seven Security Challenges That Must be Solved in Cross-domain Multi-agent LLM Systems](https://arxiv.org//abs/2505.23847)

	Ronny Ko, Jiseong Jeong, Shuyuan Zheng, Chuan Xiao, Taewan Kim, Makoto Onizuka, Wonyong Shin

+ [Arbiters of Ambivalence: Challenges of Using LLMs in No-Consensus Tasks](https://arxiv.org//abs/2505.23820)

	Bhaktipriya Radharapu, Manon Revel, Megan Ung, Sebastian Ruder, Adina Williams

+ [RAGPPI: RAG Benchmark for Protein-Protein Interactions in Drug Discovery](https://arxiv.org//abs/2505.23823)

	Youngseung Jeon, Ziwen Li, Thomas Li, JiaSyuan Chang, Morteza Ziyadi, Xiang 'Anthony' Chen

+ [Reviewing Scientific Papers for Critical Problems With Reasoning LLMs: Baseline Approaches and Automatic Evaluation](https://arxiv.org//abs/2505.23824)

	Tianmai M. Zhang, Neil F. Abernethy

+ [ValueSim: Generating Backstories to Model Individual Value Systems](https://arxiv.org//abs/2505.23827)

	Bangde Du, Ziyi Ye, Zhijing Wu, Jankowska Monika, Shuqi Zhu, Qingyao Ai, Yujia Zhou, Yiqun Liu

+ [BiasFilter: An Inference-Time Debiasing Framework for Large Language Models](https://arxiv.org//abs/2505.23829)

	Xiaoqing Cheng, Ruizhe Chen, Hongying Zan, Yuxiang Jia, Min Peng

+ [EvoMoE: Expert Evolution in Mixture of Experts for Multimodal Large Language Models](https://arxiv.org//abs/2505.23830)

	Linglin Jing, Yuting Gao, Zhigang Wang, Wang Lan, Yiwen Tang, Wenhai Wang, Kaipeng Zhang, Qingpei Guo

+ [Benchmarking Abstract and Reasoning Abilities Through A Theoretical Perspective](https://arxiv.org//abs/2505.23833)

	Qingchuan Ma, Yuhang Wu, Xiawu Zheng, Rongrong Ji

+ [Say What You Mean: Natural Language Access Control with Large Language Models for Internet of Things](https://arxiv.org//abs/2505.23835)

	Ye Cheng, Minghui Xu, Yue Zhang, Kun Li, Hao Wu, Yechao Zhang, Shaoyong Guo, Wangjie Qiu, Dongxiao Yu, Xiuzhen Cheng

+ [Measuring Sycophancy of Language Models in Multi-turn Dialogues](https://arxiv.org//abs/2505.23840)

	Jiseung Hong, Grace Byun, Seungone Kim, Kai Shu

+ [Document Valuation in LLM Summaries: A Cluster Shapley Approach](https://arxiv.org//abs/2505.23842)

	Zikun Ye, Hema Yoganarasimhan

+ [Evaluation Hallucination in Multi-Round Incomplete Information Lateral-Driven Reasoning Tasks](https://arxiv.org//abs/2505.23843)

	Wenhan Dong, Tianyi Hu, Jingyi Zheng, Zhen Sun, Yuemeng Zhao, Yule Liu, Xinlei He, Xinyi Huang

+ [Enabling Flexible Multi-LLM Integration for Scalable Knowledge Aggregation](https://arxiv.org//abs/2505.23844)

	Zhenglun Kong, Zheng Zhan, Shiyue Hou, Yifan Gong, Xin Meng, Pengwei Sui, Peiyan Dong, Xuan Shen, Zifeng Wang, Pu Zhao, Hao Tang, Stratis Ioannidis, Yanzhi Wang

+ [Read Your Own Mind: Reasoning Helps Surface Self-Confidence Signals in LLMs](https://arxiv.org//abs/2505.23845)

	Jakub Podolak, Rajeev Verma

+ [Derailing Non-Answers via Logit Suppression at Output Subspace Boundaries in RLHF-Aligned Language Models](https://arxiv.org//abs/2505.23848)

	Harvey Dam, Jonas Knochelmann, Vinu Joseph, Ganesh Gopalakrishnan

+ [SkewRoute: Training-Free LLM Routing for Knowledge Graph Retrieval-Augmented Generation via Score Skewness of Retrieved Context](https://arxiv.org//abs/2505.23841)

	Hairu Wang, Yuan Feng, Yukun Cao, Xike Xie, S Kevin Zhou

+ [Spa-VLM: Stealthy Poisoning Attacks on RAG-based VLM](https://arxiv.org//abs/2505.23828)

	Lei Yu, Yechao Zhang, Ziqi Zhou, Yang Wu, Wei Wan, Minghui Li, Shengshan Hu, Pei Xiaobing, Jing Wang

+ [GeneBreaker: Jailbreak Attacks against DNA Language Models with Pathogenicity Guidance](https://arxiv.org//abs/2505.23839)

	Zaixi Zhang, Zhenghong Zhou, Ruofan Jin, Le Cong, Mengdi Wang

+ [Rethinking Hybrid Retrieval: When Small Embeddings and LLM Re-ranking Beat Bigger Models](https://arxiv.org//abs/2506.00049)

	Arjun Rao, Hanieh Alipour, Nick Pendar

+ [Judging Quality Across Languages: A Multilingual Approach to Pretraining Data Filtering with Language Models](https://arxiv.org//abs/2505.22232)

	Mehdi Ali, Manuel Brack, Max Lübbering, Elias Wendt, Abbas Goher Khan, Richard Rutmann, Alex Jude, Maurice Kraus, Alexander Arno Weber, David Kaczér, Florian Mai, Lucie Flek, Rafet Sifa, Nicolas Flores-Herr, Joachim Köhler, Patrick Schramowski, Michael Fromm, Kristian Kersting

+ [Enhancing Tool Learning in Large Language Models with Hierarchical Error Checklists](https://arxiv.org//abs/2506.00042)

	Yue Cui, Liuyi Yao, Shuchang Tao, Weijie Shi, Yaliang Li, Bolin Ding, Xiaofang Zhou

+ [Retrieval-Augmented Generation: A Comprehensive Survey of Architectures, Enhancements, and Robustness Frontiers](https://arxiv.org//abs/2506.00054)

	Chaitanya Sharma

+ [Contextual Memory Intelligence -- A Foundational Paradigm for Human-AI Collaboration and Reflective Generative AI Systems](https://arxiv.org//abs/2506.05370)

	Kristy Wedel

+ [Curse of High Dimensionality Issue in Transformer for Long-context Modeling](https://arxiv.org//abs/2505.22107)

	Shuhai Zhang, Zeng You, Yaofo Chen, Zhiquan Wen, Qianyue Wang, Zhijie Qiu, Yuanqing Li, Mingkui Tan

# 2025-05-27
+ [MIRROR: Multi-agent Intra- and Inter-Reflection for Optimized Reasoning in Tool Learning](https://arxiv.org//abs/2505.20670)

	Zikang Guo, Benfeng Xu, Xiaorui Wang, Zhendong Mao

+ [LLM-Guided Reinforcement Learning: Addressing Training Bottlenecks through Policy Modulation](https://arxiv.org//abs/2505.20671)

	Heng Tan, Hua Yan, Yu Yang

+ [RRO: LLM Agent Optimization Through Rising Reward Trajectories](https://arxiv.org//abs/2505.20737)

	Zilong Wang, Jingfeng Yang, Sreyashi Nag, Samarth Varshney, Xianfeng Tang, Haoming Jiang, Jingbo Shang, Sheikh Muhammad Sarwar

+ [Can Agents Fix Agent Issues?](https://arxiv.org//abs/2505.20749)

	Alfin Wijaya Rahardja, Junwei Liu, Weitong Chen, Zhenpeng Chen, Yiling Lou

+ [MT-Mol:Multi Agent System with Tool-based Reasoning for Molecular Optimization](https://arxiv.org//abs/2505.20820)

	Hyomin Kim, Yunhui Jang, Sungsoo Ahn

+ [Step-Wise Formal Verification for LLM-Based Mathematical Problem Solving](https://arxiv.org//abs/2505.20869)

	Kuo Zhou, Lu Zhang

+ [Large Language Model-enhanced Reinforcement Learning for Low-Altitude Economy Networking](https://arxiv.org//abs/2505.21045)

	Lingyi Cai, Ruichen Zhang, Changyuan Zhao, Yu Zhang, Jiawen Kang, Dusit Niyato, Tao Jiang, Xuemin Shen

+ [Agent-Environment Alignment via Automated Interface Generation](https://arxiv.org//abs/2505.21055)

	Kaiming Liu, Xuanyu Lei, Ziyue Wang, Peng Li, Yang Liu

+ [Why Distillation can Outperform Zero-RL: The Role of Flexible Reasoning](https://arxiv.org//abs/2505.21067)

	Xiao Hu, Xingyu Lu, Liyuan Mao, YiFan Zhang, Tianke Zhang, Bin Wen, Fan Yang, Tingting Gao, Guorui Zhou

+ [Interpreting Social Bias in LVLMs via Information Flow Analysis and Multi-Round Dialogue Evaluation](https://arxiv.org//abs/2505.21106)

	Zhengyang Ji, Yifan Jia, Shang Gao, Yutao Yue

+ [Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework](https://arxiv.org//abs/2505.21291)

	Saman Marandi, Yu-Shu Hu, Mohammad Modarres

+ [Beyond Chemical QA: Evaluating LLM's Chemical Reasoning with Modular Chemical Operations](https://arxiv.org//abs/2505.21318)

	Hao Li, He Cao, Bin Feng, Yanjun Shao, Xiangru Tang, Zhiyuan Yan, Li Yuan, Yonghong Tian, Yu Li

+ [MME-Reasoning: A Comprehensive Benchmark for Logical Reasoning in MLLMs](https://arxiv.org//abs/2505.21327)

	Jiakang Yuan, Tianshuo Peng, Yilei Jiang, Yiting Lu, Renrui Zhang, Kaituo Feng, Chaoyou Fu, Tao Chen, Lei Bai, Bo Zhang, Xiangyu Yue

+ [Diagnosing and Resolving Cloud Platform Instability with Multi-modal RAG LLMs](https://arxiv.org//abs/2505.21419)

	Yifan Wang, Kenneth P. Birman

+ [Policy Induction: Predicting Startup Success via Explainable Memory-Augmented In-Context Learning](https://arxiv.org//abs/2505.21427)

	Xianling Mu, Joseph Ternasky, Fuat Alican, Yigit Ihlamur

+ [Robust Hypothesis Generation: LLM-Automated Language Bias for Inductive Logic Programming](https://arxiv.org//abs/2505.21486)

	Yang Yang, Jiemin Wu, Yutao Yue

+ [REAL-Prover: Retrieval Augmented Lean Prover for Mathematical Reasoning](https://arxiv.org//abs/2505.20613)

	Ziju Shen, Naohao Huang, Fanyi Yang, Yutong Wang, Guoxiong Gao, Tianyi Xu, Jiedong Jiang, Wanyi He, Pu Yang, Mengzhou Sun, Haocheng Ju, Peihao Wu, Bryan Dai, Bin Dong

+ [Test-Time Learning for Large Language Models](https://arxiv.org//abs/2505.20633)

	Jinwu Hu, Zhitian Zhang, Guohao Chen, Xutao Wen, Chao Shuai, Wei Luo, Bin Xiao, Yuanqing Li, Mingkui Tan

+ [Can Past Experience Accelerate LLM Reasoning?](https://arxiv.org//abs/2505.20643)

	Bo Pan, Liang Zhao

+ [FinTagging: An LLM-ready Benchmark for Extracting and Structuring Financial Information](https://arxiv.org//abs/2505.20650)

	Yan Wang, Yang Ren, Lingfei Qian, Xueqing Peng, Keyi Wang, Yi Han, Dongji Feng, Xiao-Yang Liu, Jimin Huang, Qianqian Xie

+ [TeroSeek: An AI-Powered Knowledge Base and Retrieval Generation Platform for Terpenoid Research](https://arxiv.org//abs/2505.20663)

	Xu Kang, Siqi Jiang, Kangwei Xu, Jiahao Li, Ruibo Wu

+ [Self-Route: Automatic Mode Switching via Capability Estimation for Efficient Reasoning](https://arxiv.org//abs/2505.20664)

	Yang He, Xiao Ding, Bibo Cai, Yufei Zhang, Kai Xiong, Zhouhao Sun, Bing Qin, Ting Liu

+ [Pretraining Language Models to Ponder in Continuous Space](https://arxiv.org//abs/2505.20674)

	Boyi Zeng, Shixiang Song, Siyuan Huang, Yixuan Wang, He Li, Ziwei He, Xinbing Wang, Zhiyu Li, Zhouhan Lin

+ [Accelerating RL for LLM Reasoning with Optimal Advantage Regression](https://arxiv.org//abs/2505.20686)

	Kianté Brantley, Mingyu Chen, Zhaolin Gao, Jason D. Lee, Wen Sun, Wenhao Zhan, Xuezhou Zhang

+ [VLM Can Be a Good Assistant: Enhancing Embodied Visual Tracking with Self-Improving Visual-Language Models](https://arxiv.org//abs/2505.20718)

	Kui Wu, Shuhang Xu, Hao Chen, Churan Wang, Zhoujun Li, Yizhou Wang, Fangwei Zhong

+ [What LLMs Miss in Recommendations: Bridging the Gap with Retrieval-Augmented Collaborative Signals](https://arxiv.org//abs/2505.20730)

	Shahrooz Pouryousef

+ [CogniBench: A Legal-inspired Framework and Dataset for Assessing Cognitive Faithfulness of Large Language Models](https://arxiv.org//abs/2505.20767)

	Xiaqiang Tang, Jian Li, Keyu Hu, Du Nan, Xiaolong Li, Xi Zhang, Weigao Sun, Sihong Xie

+ [SpecExtend: A Drop-in Enhancement for Speculative Decoding of Long Sequences](https://arxiv.org//abs/2505.20776)

	Jungyoub Cha, Hyunjong Kim, Sungzoon Cho

+ [MedSentry: Understanding and Mitigating Safety Risks in Medical LLM Multi-Agent Systems](https://arxiv.org//abs/2505.20824)

	Kai Chen, Taihang Zhen, Hewei Wang, Kailai Liu, Xinfeng Li, Jing Huo, Tianpei Yang, Jinfeng Xu, Wei Dong, Yang Gao

+ [Respond to Change with Constancy: Instruction-tuning with LLM for Non-I.I.D. Network Traffic Classification](https://arxiv.org//abs/2505.20866)

	Xinjie Lin, Gang Xiong, Gaopeng Gou, Wenqi Dong, Jing Yu, Zhen Li, Wei Xia

+ [EasyDistill: A Comprehensive Toolkit for Effective Knowledge Distillation of Large Language Models](https://arxiv.org//abs/2505.20888)

	Chengyu Wang, Junbing Yan, Wenrui Cai, Yuanhao Yue, Jun Huang

+ [Cross from Left to Right Brain: Adaptive Text Dreamer for Vision-and-Language Navigation](https://arxiv.org//abs/2505.20897)

	Pingrui Zhang, Yifei Su, Pengyuan Wu, Dong An, Li Zhang, Zhigang Wang, Dong Wang, Yan Ding, Bin Zhao, Xuelong Li

+ [Automatic Transmission for LLM Tiers: Optimizing Cost and Accuracy in Large Language Models](https://arxiv.org//abs/2505.20921)

	Injae Na, Keonwoong Noh, Woohwan Jung

+ [Multi-objective Large Language Model Alignment with Hierarchical Experts](https://arxiv.org//abs/2505.20925)

	Zhuo Li, Guodong Du, Weiyang Guo, Yigeng Zhou, Xiucheng Li, Wenya Wang, Fangming Liu, Yequan Wang, Deheng Ye, Min Zhang, Jing Li

+ [Reason-Align-Respond: Aligning LLM Reasoning with Knowledge Graphs for KGQA](https://arxiv.org//abs/2505.20971)

	Xiangqing Shen, Fanfan Wang, Rui Xia

+ [Who Reasons in the Large Language Models?](https://arxiv.org//abs/2505.20993)

	Jie Shao, Jianxin Wu

+ [Efficient Large Language Model Inference with Neural Block Linearization](https://arxiv.org//abs/2505.21077)

	Mete Erdogan, Francesco Tonin, Volkan Cevher

+ [Position is Power: System Prompts as a Mechanism of Bias in Large Language Models (LLMs)](https://arxiv.org//abs/2505.21091)

	Anna Neumann, Elisabeth Kirsten, Muhammad Bilal Zafar, Jatinder Singh

+ [Thinker: Learning to Think Fast and Slow](https://arxiv.org//abs/2505.21097)

	Stephen Chung, Wenyu Du, Jie Fu

+ [A Lightweight Multi-Expert Generative Language Model System for Engineering Information and Knowledge Extraction](https://arxiv.org//abs/2505.21109)

	Bogdan Bogachov, Yaoyao Fiona Zhao

+ [Creativity in LLM-based Multi-Agent Systems: A Survey](https://arxiv.org//abs/2505.21116)

	Yi-Cheng Lin, Kang-Chieh Chen, Zhe-Yan Li, Tzu-Heng Wu, Tzu-Hsuan Wu, Kuan-Yu Chen, Hung-yi Lee, Yun-Nung Chen

+ [M-Wanda: Improving One-Shot Pruning for Multilingual LLMs](https://arxiv.org//abs/2505.21171)

	Rochelle Choenni, Ivan Titov

+ [PoisonSwarm: Universal Harmful Information Synthesis via Model Crowdsourcing](https://arxiv.org//abs/2505.21184)

	Yu Yan, Sheng Sun, Zhifei Zheng, Ziji Hao, Teli Liu, Min Liu

+ [Exploring the Latent Capacity of LLMs for One-Step Text Generation](https://arxiv.org//abs/2505.21189)

	Gleb Mezentsev, Ivan Oseledets

+ [Pretrained LLMs Learn Multiple Types of Uncertainty](https://arxiv.org//abs/2505.21218)

	Roi Cohen, Omri Fahn, Gerard de Melo

+ [Breaking the Ceiling: Exploring the Potential of Jailbreak Attacks through Expanding Strategy Space](https://arxiv.org//abs/2505.21277)

	Yao Huang, Yitong Sun, Shouwei Ruan, Yichi Zhang, Yinpeng Dong, Xingxing Wei

+ [Large Language Models Miss the Multi-Agent Mark](https://arxiv.org//abs/2505.21298)

	Emanuele La Malfa, Gabriele La Malfa, Samuele Marro, Jie M. Zhang, Elizabeth Black, Micheal Luck, Philip Torr, Michael Wooldridge

+ [Evaluating LLM Adaptation to Sociodemographic Factors: User Profile vs. Dialogue History](https://arxiv.org//abs/2505.21362)

	Qishuai Zhong, Zongmin Li, Siqi Fan, Aixin Sun

+ [Towards Interpretability Without Sacrifice: Faithful Dense Layer Decomposition with Mixture of Decoders](https://arxiv.org//abs/2505.21364)

	James Oldfield, Shawn Im, Yixuan Li, Mihalis A. Nicolaou, Ioannis Patras, Grigorios G Chrysos

+ [Improving LLM-based Global Optimization with Search Space Partitioning](https://arxiv.org//abs/2505.21372)

	Andrej Schwanke, Lyubomir Ivanov, David Salinas, Fabio Ferreira, Aaron Klein, Frank Hutter, Arber Zela

+ [Factual Self-Awareness in Language Models: Representation, Robustness, and Scaling](https://arxiv.org//abs/2505.21399)

	Hovhannes Tamoyan, Subhabrata Dutta, Iryna Gurevych

+ [RelationalFactQA: A Benchmark for Evaluating Tabular Fact Retrieval from Large Language Models](https://arxiv.org//abs/2505.21409)

	Dario Satriani, Enzo Veltri, Donatello Santoro, Paolo Papotti

+ [RefTool: Enhancing Model Reasoning with Reference-Guided Tool Creation](https://arxiv.org//abs/2505.21413)

	Xiao Liu, Da Yin, Zirui Wu, Yansong Feng

+ [Active-O3: Empowering Multimodal Large Language Models with Active Perception via GRPO](https://arxiv.org//abs/2505.21457)

	Muzhi Zhu, Hao Zhong, Canyu Zhao, Zongze Du, Zheng Huang, Mingyu Liu, Hao Chen, Cheng Zou, Jingdong Chen, Ming Yang, Chunhua Shen

+ [AdInject: Real-World Black-Box Attacks on Web Agents via Advertising Delivery](https://arxiv.org//abs/2505.21499)

	Haowei Wang, Junjie Wang, Xiaojun Jia, Rupeng Zhang, Mingyang Li, Zhe Liu, Yang Liu, Qing Wang

+ [Silence is Not Consensus: Disrupting Agreement Bias in Multi-Agent LLMs via Catfish Agent for Clinical Decision Making](https://arxiv.org//abs/2505.21503)

	Yihan Wang, Qiao Yan, Zhenghao Xing, Lihao Liu, Junjun He, Chi-Wing Fu, Xiaowei Hu, Pheng-Ann Heng

+ [How does Alignment Enhance LLMs' Multilingual Capabilities? A Language Neurons Perspective](https://arxiv.org//abs/2505.21505)

	Shimao Zhang, Zhejian Lai, Xiang Liu, Shuaijie She, Xiao Liu, Yeyun Gong, Shujian Huang, Jiajun Chen

+ [Long Context Scaling: Divide and Conquer via Multi-Agent Question-driven Collaboration](https://arxiv.org//abs/2505.20625)

	Sibo Xiao, Zixin Lin, Wenyang Gao, Yue Zhang

+ [STEER-BENCH: A Benchmark for Evaluating the Steerability of Large Language Models](https://arxiv.org//abs/2505.20645)

	Kai Chen, Zihao He, Taiwei Shi, Kristina Lerman

+ [SELF-PERCEPT: Introspection Improves Large Language Models' Detection of Multi-Person Mental Manipulation in Conversations](https://arxiv.org//abs/2505.20679)

	Danush Khanna, Pratinav Seth, Sidhaarth Sredharan Murali, Aditya Kumar Guru, Siddharth Shukla, Tanuj Tyagi, Sandeep Chaurasia, Kripabandhu Ghosh

+ [Beyond Templates: Dynamic Adaptation of Reasoning Demonstrations via Feasibility-Aware Exploration](https://arxiv.org//abs/2505.20700)

	Yong Wu, Weihang Pan, Ke Li, Chen Binhui, Ping Li, Binbin Lin

+ [SPA-RL: Reinforcing LLM Agents via Stepwise Progress Attribution](https://arxiv.org//abs/2505.20732)

	Hanlin Wang, Chak Tou Leong, Jiashuo Wang, Jian Wang, Wenjie Li

+ [Silencer: From Discovery to Mitigation of Self-Bias in LLM-as-Benchmark-Generator](https://arxiv.org//abs/2505.20738)

	Peiwen Yuan, Yiwei Li, Shaoxiong Feng, Xinglin Wang, Yueqi Zhang, Jiayi Shi, Chuyi Tan, Boyuan Pan, Yao Hu, Kan Li

+ [Improved Representation Steering for Language Models](https://arxiv.org//abs/2505.20809)

	Zhengxuan Wu, Qinan Yu, Aryaman Arora, Christopher D. Manning, Christopher Potts

+ [Rethinking Information Synthesis in Multimodal Question Answering A Multi-Agent Perspective](https://arxiv.org//abs/2505.20816)

	Krishna Singh Rajput, Tejas Anvekar, Chitta Baral, Vivek Gupta

+ [Tracing and Reversing Rank-One Model Edits](https://arxiv.org//abs/2505.20819)

	Paul Youssef, Zhixue Zhao, Christin Seifert, Jörg Schlötterer

+ [Reinforced Informativeness Optimization for Long-Form Retrieval-Augmented Generation](https://arxiv.org//abs/2505.20825)

	Yuhao Wang, Ruiyang Ren, Yucheng Wang, Wayne Xin Zhao, Jing Liu, Hua Wu, Haifeng Wang

+ [Concealment of Intent: A Game-Theoretic Analysis](https://arxiv.org//abs/2505.20841)

	Xinbo Wu, Abhishek Umrawal, Lav R. Varshney

+ [Divide-Then-Align: Honest Alignment based on the Knowledge Boundary of RAG](https://arxiv.org//abs/2505.20871)

	Xin Sun, Jianan Xie, Zhongqi Chen, Qiang Liu, Shu Wu, Yuehe Chen, Bowen Song, Weiqiang Wang, Zilei Wang, Liang Wang

+ [Can LLMs Learn to Map the World from Local Descriptions?](https://arxiv.org//abs/2505.20874)

	Sirui Xia, Aili Chen, Xintao Wang, Tinghui Zhu, Yikai Zhang, Jiangjie Chen, Yanghua Xiao

+ [MSA at SemEval-2025 Task 3: High Quality Weak Labeling and LLM Ensemble Verification for Multilingual Hallucination Detection](https://arxiv.org//abs/2505.20880)

	Baraa Hikal, Ahmed Nasreldin, Ali Hamdi

+ [Towards Objective Fine-tuning: How LLMs' Prior Knowledge Causes Potential Poor Calibration?](https://arxiv.org//abs/2505.20903)

	Ziming Wang, Zeyu Shi, Haoyi Zhou, Shiqi Gao, Qingyun Sun, Jianxin Li

+ [Automated Privacy Information Annotation in Large Language Model Interactions](https://arxiv.org//abs/2505.20910)

	Hang Zeng, Xiangyu Liu, Yong Hu, Chaoyue Niu, Fan Wu, Shaojie Tang, Guihai Chen

+ [Evaluating and Steering Modality Preferences in Multimodal Large Language Model](https://arxiv.org//abs/2505.20977)

	Yu Zhang, Jinlong Ma, Yongshuai Hou, Xuefeng Bai, Kehai Chen, Yang Xiang, Jun Yu, Min Zhang

+ [Uncertainty Unveiled: Can Exposure to More In-context Examples Mitigate Uncertainty for Large Language Models?](https://arxiv.org//abs/2505.21003)

	Yifei Wang, Yu Sheng, Linjing Li, Daniel Zeng

+ [LLMs are Frequency Pattern Learners in Natural Language Inference](https://arxiv.org//abs/2505.21011)

	Liang Cheng, Zhaowei Wang, Mark Steedman

+ [Def-DTS: Deductive Reasoning for Open-domain Dialogue Topic Segmentation](https://arxiv.org//abs/2505.21033)

	Seungmin Lee, Yongsang Yoo, Minhwa Jung, Min Song

+ [Faithfulness-Aware Uncertainty Quantification for Fact-Checking the Output of Retrieval Augmented Generation](https://arxiv.org//abs/2505.21072)

	Ekaterina Fadeeva, Aleksandr Rubashevskii, Roman Vashurin, Shehzaad Dhuliawala, Artem Shelmanov, Timothy Baldwin, Preslav Nakov, Mrinmaya Sachan, Maxim Panov

+ [LLMs Think, But Not In Your Flow: Reasoning-Level Personalization for Black-Box Large Language Models](https://arxiv.org//abs/2505.21082)

	Jieyong Kim, Tongyoung Kim, Soonjin Yoon, Jaehyung Kim, Dongha Lee

+ [Will It Still Be True Tomorrow? Multilingual Evergreen Question Classification to Improve Trustworthy QA](https://arxiv.org//abs/2505.21115)

	Sergey Pletenev, Maria Marina, Nikolay Ivanov, Daria Galimzianova, Nikita Krayko, Mikhail Salnikov, Vasily Konovalov, Alexander Panchenko, Viktor Moskvoretskii

+ [Walk Before You Run! Concise LLM Reasoning via Reinforcement Learning](https://arxiv.org//abs/2505.21178)

	Mingyang Song, Mao Zheng

+ [Unveiling Instruction-Specific Neurons & Experts: An Analytical Framework for LLM's Instruction-Following Capabilities](https://arxiv.org//abs/2505.21191)

	Junyan Zhang, Yubo Gao, Yibo Yan, Jungang Li, Zhaorui Hou, Sicheng Tao, Shuliang Liu, Song Dai, Yonghua Hei, Junzhuo Li, Xuming Hu

+ [A Representation Level Analysis of NMT Model Robustness to Grammatical Errors](https://arxiv.org//abs/2505.21224)

	Abderrahmane Issam, Yusuf Can Semerci, Jan Scholtes, Gerasimos Spanakis

+ [LMCD: Language Models are Zeroshot Cognitive Diagnosis Learners](https://arxiv.org//abs/2505.21239)

	Yu He, Zihan Yao, Chentao Song, Tianyu Qi, Jun Liu, Ming Li, Qing Huang

+ [ReSCORE: Label-free Iterative Retriever Training for Multi-hop Question Answering with Relevance-Consistency Supervision](https://arxiv.org//abs/2505.21250)

	Dosung Lee, Wonjun Oh, Boyoung Kim, Minyoung Kim, Joonsuk Park, Paul Hongsuck Seo

+ [rStar-Coder: Scaling Competitive Code Reasoning with a Large-Scale Verified Dataset](https://arxiv.org//abs/2505.21297)

	Yifei Liu, Li Lyna Zhang, Yi Zhu, Bingcheng Dong, Xudong Zhou, Ning Shang, Fan Yang, Mao Yang

+ [Analyzing values about gendered language reform in LLMs' revisions](https://arxiv.org//abs/2505.21378)

	Jules Watson, Xi Wang, Raymond Liu, Suzanne Stevenson, Barend Beekhuizen

+ [AutoJudger: An Agent-Driven Framework for Efficient Benchmarking of MLLMs](https://arxiv.org//abs/2505.21389)

	Xuanwen Ding, Chengjun Pan, Zejun Li, Jiwen Zhang, Siyuan Wang, Zhongyu Wei

+ [DecisionFlow: Advancing Large Language Model as Principled Decision Maker](https://arxiv.org//abs/2505.21397)

	Xiusi Chen, Shanyong Wang, Cheng Qian, Hongru Wang, Peixuan Han, Heng Ji

+ [Pangu Pro MoE: Mixture of Grouped Experts for Efficient Sparsity](https://arxiv.org//abs/2505.21411)

	Yehui Tang, Xiaosong Li, Fangcheng Liu, Wei Guo, Hang Zhou, Yaoyuan Wang, Kai Han, Xianzhi Yu, Jinpeng Li, Hui Zang, Fei Mi, Xiaojun Meng, Zhicheng Liu, Hanting Chen, Binfan Zheng, Can Chen, Youliang Yan, Ruiming Tang, Peifeng Qin, Xinghao Chen, Dacheng Tao, Yunhe Wang (and Other Contributors)

+ [Towards Better Instruction Following Retrieval Models](https://arxiv.org//abs/2505.21439)

	Yuchen Zhuang, Aaron Trinh, Rushi Qiang, Haotian Sun, Chao Zhang, Hanjun Dai, Bo Dai

+ [Do LLMs Need to Think in One Language? Correlation between Latent Language and Task Performance](https://arxiv.org//abs/2505.21458)

	Shintaro Ozaki, Tatsuya Hiraoka, Hiroto Otake, Hiroki Ouchi, Masaru Isonuma, Benjamin Heinzerling, Kentaro Inui, Taro Watanabe, Yusuke Miyao, Yohei Oseki, Yu Takagi

+ [R1-Code-Interpreter: Training LLMs to Reason with Code via Supervised and Reinforcement Learning](https://arxiv.org//abs/2505.21668)

	Yongchao Chen, Yueying Liu, Junwei Zhou, Yilun Hao, Jingquan Wang, Yang Zhang, Chuchu Fan

+ [Make Planning Research Rigorous Again!](https://arxiv.org//abs/2505.21674)

	Michael Katz, Harsha Kokel, Christian Muise, Shirin Sohrabi, Sarath Sreedharan

+ [Don't Think Longer, Think Wisely: Optimizing Thinking Dynamics for Large Reasoning Models](https://arxiv.org//abs/2505.21765)

	Sohyun An, Ruochen Wang, Tianyi Zhou, Cho-Jui Hsieh

+ [Towards Safety Reasoning in LLMs: AI-agentic Deliberation for Policy-embedded CoT Data Creation](https://arxiv.org//abs/2505.21784)

	Tharindu Kumarage, Ninareh Mehrabi, Anil Ramakrishna, Xinyan Zhao, Richard Zemel, Kai-Wei Chang, Aram Galstyan, Rahul Gupta, Charith Peris

+ [SAGE-Eval: Evaluating LLMs for Systematic Generalizations of Safety Facts](https://arxiv.org//abs/2505.21828)

	Chen Yueh-Han, Guy Davidson, Brenden M. Lake

+ [ChemHAS: Hierarchical Agent Stacking for Enhancing Chemistry Tools](https://arxiv.org//abs/2505.21569)

	Zhucong Li, Bowei Zhang, Jin Xiao, Zhijian Zhou, Fenglei Cao, Jiaqing Liang, Yuan Qi

+ [StreamLink: Large-Language-Model Driven Distributed Data Engineering System](https://arxiv.org//abs/2505.21575)

	Dawei Feng, Di Mei, Huiri Tan, Lei Ren, Xianying Lou, Zhangxi Tan

+ [AITEE -- Agentic Tutor for Electrical Engineering](https://arxiv.org//abs/2505.21582)

	Christopher Knievel, Alexander Bernhardt, Christian Bernhardt

+ [Herd Behavior: Investigating Peer Influence in LLM-based Multi-Agent Systems](https://arxiv.org//abs/2505.21588)

	Young-Min Cho, Sharath Chandra Guntuku, Lyle Ungar

+ [Fast and Cost-effective Speculative Edge-Cloud Decoding with Early Exits](https://arxiv.org//abs/2505.21594)

	Yeshwanth Venkatesha, Souvik Kundu, Priyadarshini Panda

+ [R2R: Efficiently Navigating Divergent Reasoning Paths with Small-Large Model Token Routing](https://arxiv.org//abs/2505.21600)

	Tianyu Fu, Yi Ge, Yichen You, Enshu Liu, Zhihang Yuan, Guohao Dai, Shengen Yan, Huazhong Yang, Yu Wang

+ [Public Discourse Sandbox: Facilitating Human and AI Digital Communication Research](https://arxiv.org//abs/2505.21604)

	Kristina Radivojevic, Caleb Reinking, Shaun Whitfield, Paul Brenner

+ [SOSBENCH: Benchmarking Safety Alignment on Scientific Knowledge](https://arxiv.org//abs/2505.21605)

	Fengqing Jiang, Fengbo Ma, Zhangchen Xu, Yuetai Li, Bhaskar Ramasubramanian, Luyao Niu, Bo Li, Xianyan Chen, Zhen Xiang, Radha Poovendran

+ [How does Misinformation Affect Large Language Model Behaviors and Preferences?](https://arxiv.org//abs/2505.21608)

	Miao Peng, Nuo Chen, Jianheng Tang, Jia Li

+ [Is Your LLM Overcharging You? Tokenization, Transparency, and Incentives](https://arxiv.org//abs/2505.21627)

	Ander Artola Velasco, Stratis Tsirtsis, Nastaran Okati, Manuel Gomez-Rodriguez

+ [Explainability of Large Language Models using SMILE: Statistical Model-agnostic Interpretability with Local Explanations](https://arxiv.org//abs/2505.21657)

	Zeinab Dehghani, Koorosh Aslansefat, Adil Khan, Mohammed Naveed Akram

+ [Rethinking the Outlier Distribution in Large Language Models: An In-depth Study](https://arxiv.org//abs/2505.21670)

	Rahul Raman, Khushi Sharma, Sai Qian Zhang

+ [What happens when generative AI models train recursively on each others' generated outputs?](https://arxiv.org//abs/2505.21677)

	Hung Ahn Vu, Galen Reeves, Emily Wenger

+ [Counterfactual Simulatability of LLM Explanations for Generation Tasks](https://arxiv.org//abs/2505.21740)

	Marvin Limpijankit, Yanda Chen, Melanie Subbiah, Nicholas Deas, Kathleen McKeown

+ [VeriTrail: Closed-Domain Hallucination Detection with Traceability](https://arxiv.org//abs/2505.21786)

	Dasha Metropolitansky, Jonathan Larson

+ [Scientific Paper Retrieval with LLM-Guided Semantic-Based Ranking](https://arxiv.org//abs/2505.21815)

	Yunyi Zhang, Ruozhen Yang, Siqi Jiao, SeongKu Kang, Jiawei Han

+ [Let Me Think! A Long Chain-of-Thought Can Be Worth Exponentially Many Short Ones](https://arxiv.org//abs/2505.21825)

	Parsa Mirtaheri, Ezra Edelman, Samy Jelassi, Eran Malach, Enric Boix-Adsera

+ [TuneComp: Joint Fine-tuning and Compression for Large Foundation Models](https://arxiv.org//abs/2505.21835)

	Xiangyu Chen, Jing Liu, Ye Wang, Matthew Brand, Pu (Perry)Wang, Toshiaki Koike-Akino

+ [MAKIEval: A Multilingual Automatic WiKidata-based Framework for Cultural Awareness Evaluation for LLMs](https://arxiv.org//abs/2505.21693)

	Raoyuan Zhao, Beiduo Chen, Barbara Plank, Michael A. Hedderich

+ [Do We Know What LLMs Don't Know? A Study of Consistency in Knowledge Probing](https://arxiv.org//abs/2505.21701)

	Raoyuan Zhao, Abdullatif Köksal, Ali Modarressi, Michael A. Hedderich, Hinrich Schütze

+ [BehaviorSFT: Behavioral Token Conditioning for Clinical Agents Across the Proactivity Spectrum](https://arxiv.org//abs/2505.21757)

	Yubin Kim, Zhiyuan Hu, Hyewon Jeong, Eugene Park, Shuyue Stella Li, Chanwoo Park, Shiyun Xiong, MingYu Lu, Hyeonhoon Lee, Xin Liu, Daniel McDuff, Cynthia Breazeal, Samir Tulebaev, Hae Won Park

+ [Calibrating LLM Confidence by Probing Perturbed Representation Stability](https://arxiv.org//abs/2505.21772)

	Reza Khanmohammadi, Erfan Miahi, Mehrsa Mardikoraem, Simerjot Kaur, Ivan Brugere, Charese H. Smiley, Kundan Thind, Mohammad M. Ghassemi

+ [From prosthetic memory to prosthetic denial: Auditing whether large language models are prone to mass atrocity denialism](https://arxiv.org//abs/2505.21753)

	Roberto Ulloa, Eve M. Zucker, Daniel Bultmann, David J. Simon, Mykola Makhortykh

+ [Born a Transformer -- Always a Transformer?](https://arxiv.org//abs/2505.21785)

	Yana Veitsman, Mayank Jobanputra, Yash Sarrof, Aleksandra Bakalova, Vera Demberg, Ellie Pavlick, Michael Hahn

+ [From Directions to Cones: Exploring Multidimensional Representations of Propositional Facts in LLMs](https://arxiv.org//abs/2505.21800)

	Stanley Yu, Vaidehi Bulusu, Oscar Yasunaga, Clayton Lau, Cole Blondin, Sean O'Brien, Kevin Zhu, Vasu Sharma

+ [Think Before You Diffuse: LLMs-Guided Physics-Aware Video Generation](https://arxiv.org//abs/2505.21653)

	Ke Zhang, Cihan Xiao, Yiqun Mei, Jiacong Xu, Vishal M. Patel

+ [HoliTom: Holistic Token Merging for Fast Video Large Language Models](https://arxiv.org//abs/2505.21334)

	Kele Shao, Keda Tao, Can Qin, Haoxuan You, Yang Sui, Huan Wang

+ [PreGenie: An Agentic Framework for High-quality Visual Presentation Generation](https://arxiv.org//abs/2505.21660)

	Xiaojie Xu, Xinli Xu, Sirui Chen, Haoyu Chen, Fan Zhang, Ying-Cong Chen

+ [TabReason: A Reinforcement Learning-Enhanced Reasoning LLM for Explainable Tabular Data Prediction](https://arxiv.org//abs/2505.21807)

	Tommy Xu, Zhitian Zhang, Xiangyu Sun, Lauren Kelly Zung, Hossein Hajimirsadeghi, Greg Mori

+ [FireQ: Fast INT4-FP8 Kernel and RoPE-aware Quantization for LLM Inference Acceleration](https://arxiv.org//abs/2505.20839)

	Daehyeon Baek, Jieun Choi, Jimyoung Son, Kyungmin Bin, Seungbeom Choi, Kihyo Moon, Minsung Jang, Hyojung Lee

+ [Calibrating LLMs for Text-to-SQL Parsing by Leveraging Sub-clause Frequencies](https://arxiv.org//abs/2505.23804)

	Terrance Liu, Shuyi Wang, Daniel Preotiuc-Pietro, Yash Chandarana, Chirag Gupta

+ [MedOrchestra: A Hybrid Cloud-Local LLM Approach for Clinical Data Interpretation](https://arxiv.org//abs/2505.23806)

	Sihyeon Lee, Hyunjoo Song, Jong-chan Lee, Yoon Jin Lee, Boram Lee, Hee-Eon Lim, Dongyeong Kim, Jinwook Seo, Bohyoung Kim

+ [DLP: Dynamic Layerwise Pruning in Large Language Models](https://arxiv.org//abs/2505.23807)

	Yuli Chen, Bo Cheng, Jiale Han, Yingying Zhang, Yingting Li, Shuhao Zhang

+ [DenseLoRA: Dense Low-Rank Adaptation of Large Language Models](https://arxiv.org//abs/2505.23808)

	Lin Mu, Xiaoyu Wang, Li Ni, Yang Li, Zhize Wu, Peiquan Jin, Yiwen Zhang

+ [MARS-Bench: A Multi-turn Athletic Real-world Scenario Benchmark for Dialogue Evaluation](https://arxiv.org//abs/2505.23810)

	Chenghao Yang, Yinbo Luo, Zhoufutu Wen, Qi Chu, Tao Gong, Longxiang Liu, Kaiyuan Zhang, Jianpeng Jiao, Ge Zhang, Wenhao Huang, Nenghai Yu

+ [LayerIF: Estimating Layer Quality for Large Language Models using Influence Functions](https://arxiv.org//abs/2505.23811)

	Hadi Askari, Shivanshu Gupta, Fei Wang, Anshuman Chhabra, Muhao Chen

+ [Aligning LLMs by Predicting Preferences from User Writing Samples](https://arxiv.org//abs/2505.23815)

	Stéphane Aroca-Ouellette, Natalie Mackraz, Barry-John Theobald, Katherine Metcalf

+ [A Course Correction in Steerability Evaluation: Revealing Miscalibration and Side Effects in LLMs](https://arxiv.org//abs/2505.23816)

	Trenton Chang, Tobias Schnabel, Adith Swaminathan, Jenna Wiens

+ [System Prompt Extraction Attacks and Defenses in Large Language Models](https://arxiv.org//abs/2505.23817)

	Badhan Chandra Das, M. Hadi Amini, Yanzhao Wu

+ [Hume: Introducing System-2 Thinking in Visual-Language-Action Model](https://arxiv.org//abs/2505.21432)

	Haoming Song, Delin Qu, Yuanqi Yao, Qizhi Chen, Qi Lv, Yiwen Tang, Modi Shi, Guanghui Ren, Maoqing Yao, Bin Zhao, Dong Wang, Xuelong Li

+ [Code Researcher: Deep Research Agent for Large Systems Code and Commit History](https://arxiv.org//abs/2506.11060)

	Ramneet Singh, Sathvik Joel, Abhav Mehrotra, Nalin Wadhwa, Ramakrishna B Bairi, Aditya Kanade, Nagarajan Natarajan

+ [CodeMirage: A Multi-Lingual Benchmark for Detecting AI-Generated and Paraphrased Source Code from Production-Level LLMs](https://arxiv.org//abs/2506.11059)

	Hanxi Guo, Siyuan Cheng, Kaiyuan Zhang, Guangyu Shen, Xiangyu Zhang

# 2025-05-26
+ [CaseEdit: Enhancing Localized Commonsense Reasoning via Null-Space Constrained Knowledge Editing in Small Parameter Language Models](https://arxiv.org//abs/2505.19383)

	Varun Reddy, Yen-Ling Kuo

+ [Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents](https://arxiv.org//abs/2505.19436)

	Ye Ye

+ [BizFinBench: A Business-Driven Real-World Financial Benchmark for Evaluating LLMs](https://arxiv.org//abs/2505.19457)

	Guilong Lu, Xuntao Guo, Rongjunchen Zhang, Wenqiao Zhu, Ji Liu

+ [Origin Tracer: A Method for Detecting LoRA Fine-Tuning Origins in LLMs](https://arxiv.org//abs/2505.19466)

	Hongyu Liang, Yuting Zheng, Yihan Li, Yiran Zhang, Shiyu Liang

+ [Causal-LLaVA: Causal Disentanglement for Mitigating Hallucination in Multimodal Large Language Models](https://arxiv.org//abs/2505.19474)

	Xinmiao Hu, Chun Wang, Ruihe An, ChenYu Shao, Xiaojun Ye, Sheng Zhou, Liangcheng Li (Zhejiang University)

+ [Judging with Many Minds: Do More Perspectives Mean Less Prejudice?](https://arxiv.org//abs/2505.19477)

	Chiyu Ma, Enpei Zhang, Yilun Zhao, Wenjun Liu, Yaning Jia, Peijun Qing, Lin Shi, Arman Cohan, Yujun Yan, Soroush Vosoughi

+ [Benchmarking and Enhancing LLM Agents in Localizing Linux Kernel Bugs](https://arxiv.org//abs/2505.19489)

	Zhenhao Zhou, Zhuochen Huang, Yike He, Chong Wang, Jiajun Wang, Yijian Wu, Xin Peng, Yiling Lou

+ [AMQA: An Adversarial Dataset for Benchmarking Bias of LLMs in Medicine and Healthcare](https://arxiv.org//abs/2505.19562)

	Ying Xiao, Jie Huang, Ruijuan He, Jing Xiao, Mohammad Reza Mousavi, Yepang Liu, Kezhi Li, Zhenpeng Chen, Jie M. Zhang

+ [LLM-Agent-Controller: A Universal Multi-Agent Large Language Model System as a Control Engineer](https://arxiv.org//abs/2505.19567)

	Rasoul Zahedifar, Sayyed Ali Mirghasemi, Mahdieh Soleymani Baghshah, Alireza Taheri

+ [Think Again! The Effect of Test-Time Compute on Preferences, Opinions, and Beliefs of Large Language Models](https://arxiv.org//abs/2505.19621)

	George Kour, Itay Nakash, Ateret Anaby-Tavor, Michal Shmueli-Scheuer

+ [SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning Logical Reasoning and Beyond](https://arxiv.org//abs/2505.19641)

	Junteng Liu, Yuanxiang Fan, Zhuo Jiang, Han Ding, Yongyi Hu, Chi Zhang, Yiqi Shi, Shitong Weng, Aili Chen, Shiqi Chen, Yunan Huang, Mozhi Zhang, Pengyu Zhao, Junjie Yan, Junxian He

+ [Token-Importance Guided Direct Preference Optimization](https://arxiv.org//abs/2505.19653)

	Yang Ning, Lin Hai, Liu Yibo, Tian Baoliang, Liu Guoqing, Zhang Haijun

+ [FieldWorkArena: Agentic AI Benchmark for Real Field Work Tasks](https://arxiv.org//abs/2505.19662)

	Atsunori Moteki, Shoichi Masui, Fan Yang, Yueqi Song, Yonatan Bisk, Graham Neubig, Ikuo Kusajima, Yasuto Watanabe, Hiroyuki Ishida, Jun Takahashi, Shan Jiang

+ [Large Language Models' Reasoning Stalls: An Investigation into the Capabilities of Frontier Models](https://arxiv.org//abs/2505.19676)

	Lachlan McGinness, Peter Baumgartner

+ [Large Language Models for Planning: A Comprehensive and Systematic Survey](https://arxiv.org//abs/2505.19683)

	Pengfei Cao, Tianyi Men, Wencan Liu, Jingwen Zhang, Xuzhao Li, Xixun Lin, Dianbo Sui, Yanan Cao, Kang Liu, Jun Zhao

+ [Beyond Safe Answers: A Benchmark for Evaluating True Risk Awareness in Large Reasoning Models](https://arxiv.org//abs/2505.19690)

	Baihui Zheng, Boren Zheng, Kerui Cao, Yingshui Tan, Zhendong Liu, Weixun Wang, Jiaheng Liu, Jian Yang, Wenbo Su, Xiaoyong Zhu, Bo Zheng, Kaifu Zhang

+ [Concise Reasoning, Big Gains: Pruning Long Reasoning Trace with Difficulty-Aware Prompting](https://arxiv.org//abs/2505.19716)

	Yifan Wu, Jingze Shi, Bingheng Wu, Jiayi Zhang, Xiaotian Lin, Nan Tang, Yuyu Luo

+ [Divide and Conquer: Grounding LLMs as Efficient Decision-Making Agents via Offline Hierarchical Reinforcement Learning](https://arxiv.org//abs/2505.19761)

	Zican Hu, Wei Liu, Xiaoye Qu, Xiangyu Yue, Chunlin Chen, Zhi Wang, Yu Cheng

+ [Done Is Better than Perfect: Unlocking Efficient Reasoning by Structured Multi-Turn Decomposition](https://arxiv.org//abs/2505.19788)

	Zihao Zeng, Xuyao Huang, Boxiu Li, Hao Zhang, Zhijie Deng

+ [DGRAG: Distributed Graph-based Retrieval-Augmented Generation in Edge-Cloud Systems](https://arxiv.org//abs/2505.19847)

	Wenqing Zhou, Yuxuan Yan, Qianqian Yang

+ [HS-STAR: Hierarchical Sampling for Self-Taught Reasoners via Difficulty Estimation and Budget Reallocation](https://arxiv.org//abs/2505.19866)

	Feng Xiong, Hongling Xu, Yifei Wang, Runxi Cheng, Yong Wang, Xiangxiang Chu

+ [Unifying Multimodal Large Language Model Capabilities and Modalities via Model Merging](https://arxiv.org//abs/2505.19892)

	Yongxian Wei, Runxi Cheng, Weike Jin, Enneng Yang, Li Shen, Lu Hou, Sinan Du, Chun Yuan, Xiaochun Cao, Dacheng Tao

+ [Large Language Models as Autonomous Spacecraft Operators in Kerbal Space Program](https://arxiv.org//abs/2505.19896)

	Alejandro Carrasco, Victor Rodriguez-Fernandez, Richard Linares

+ [ScienceBoard: Evaluating Multimodal Autonomous Agents in Realistic Scientific Workflows](https://arxiv.org//abs/2505.19897)

	Qiushi Sun, Zhoumianze Liu, Chang Ma, Zichen Ding, Fangzhi Xu, Zhangyue Yin, Haiteng Zhao, Zhenyu Wu, Kanzhi Cheng, Zhaoyang Liu, Jianing Wang, Qintong Li, Xiangru Tang, Tianbao Xie, Xiachong Feng, Xiang Li, Ben Kao, Wenhai Wang, Biqing Qi, Lingpeng Kong, Zhiyong Wu

+ [EMAC+: Embodied Multimodal Agent for Collaborative Planning with VLM+LLM](https://arxiv.org//abs/2505.19905)

	Shuang Ao, Flora D. Salim, Simon Khan

+ [Subtle Risks, Critical Failures: A Framework for Diagnosing Physical Safety of LLMs for Embodied Decision Making](https://arxiv.org//abs/2505.19933)

	Yejin Son, Minseo Kim, Sungwoong Kim, Seungju Han, Jian Kim, Dongju Jang, Youngjae Yu, Chanyoung Park

+ [DCG-SQL: Enhancing In-Context Learning for Text-to-SQL with Deep Contextual Schema Link Graph](https://arxiv.org//abs/2505.19956)

	Jihyung Lee, Jin-Seop Lee, Jaehoon Lee, YunSeok Choi, Jee-Hyong Lee

+ [Safety Through Reasoning: An Empirical Study of Reasoning Guardrail Models](https://arxiv.org//abs/2505.20087)

	Makesh Narsimhan Sreedhar, Traian Rebedea, Christopher Parisien

+ [Agents Require Metacognitive and Strategic Reasoning to Succeed in the Coming Labor Markets](https://arxiv.org//abs/2505.20120)

	Simpson Zhang, Tennison Liu, Mihaela van der Schaar

+ [Agentic AI Process Observability: Discovering Behavioral Variability](https://arxiv.org//abs/2505.20127)

	Fabiana Fournier, Lior Limonad, Yuval David

+ [Capability-Based Scaling Laws for LLM Red-Teaming](https://arxiv.org//abs/2505.20162)

	Alexander Panfilov, Paul Kassianik, Maksym Andriushchenko, Jonas Geiping

+ [Temporal Sampling for Forgotten Reasoning in LLMs](https://arxiv.org//abs/2505.20196)

	Yuetai Li, Zhangchen Xu, Fengqing Jiang, Bhaskar Ramasubramanian, Luyao Niu, Bill Yuchen Lin, Xiang Yue, Radha Poovendran

+ [Shutdownable Agents through POST-Agency](https://arxiv.org//abs/2505.20203)

	Elliott Thornley

+ [On Path to Multimodal Historical Reasoning: HistBench and HistAgent](https://arxiv.org//abs/2505.20246)

	Jiahao Qiu, Fulian Xiao, Yimin Wang, Yuchen Mao, Yijia Chen, Xinzhe Juan, Siran Wang, Xuan Qi, Tongcheng Zhang, Zixin Yao, Jiacheng Guo, Yifu Lu, Charles Argon, Jundi Cui, Daixin Chen, Junran Zhou, Shuyao Zhou, Zhanpeng Zhou, Ling Yang, Shilong Liu, Hongru Wang, Kaixuan Huang, Xun Jiang, Yuming Cao, Yue Chen, Yunfei Chen, Zhengyi Chen, Ruowei Dai, Mengqiu Deng, Jiye Fu, Yunting Gu, Zijie Guan, Zirui Huang, Xiaoyan Ji, Yumeng Jiang, Delong Kong, Haolong Li, Jiaqi Li, Ruipeng Li, Tianze Li, Zhuoran Li, Haixia Lian, Mengyue Lin, Xudong Liu, Jiayi Lu, Jinghan Lu, Wanyu Luo, Ziyue Luo, Zihao Pu, Zhi Qiao, Ruihuan Ren, Liang Wan, Ruixiang Wang, Tianhui Wang, Yang Wang, Zeyu Wang, Zihua Wang, Yujia Wu, Zhaoyi Wu, Hao Xin, Weiao Xing, Ruojun Xiong, Weijie Xu, Yao Shu, Xiao Yao, Xiaorui Yang, Yuchen Yang, Nan Yi, Jiadong Yu, Yangyuxuan Yu, Huiting Zeng, Danni Zhang, Yunjie Zhang, Zhaoyu Zhang, Zhiheng Zhang, Xiaofeng Zheng, Peirong Zhou, Linyan Zhong, Xiaoyin Zong, Ying Zhao, Zhenxin Chen, Lin Ding, Xiaoyu Gao, Bingbing Gong, Yichao Li, Yang Liao, Guang Ma, Tianyuan Ma, Xinrui Sun, Tianyi Wang, Han Xia, Ruobing Xian, Gen Ye, Tengfei Yu, Wentao Zhang, Yuxi Wang, Xi Gao, Mengdi Wang

+ [syftr: Pareto-Optimal Generative AI](https://arxiv.org//abs/2505.20266)

	Alexander Conway, Debadeepta Dey, Stefan Hackmann, Matthew Hausknecht, Michael Schmidt, Mark Steadman, Nick Volynets

+ [Ten Principles of AI Agent Economics](https://arxiv.org//abs/2505.20273)

	Ke Yang, ChengXiang Zhai

+ [Alita: Generalist Agent Enabling Scalable Agentic Reasoning with Minimal Predefinition and Maximal Self-Evolution](https://arxiv.org//abs/2505.20286)

	Jiahao Qiu, Xuan Qi, Tongcheng Zhang, Xinzhe Juan, Jiacheng Guo, Yifu Lu, Yimin Wang, Zixin Yao, Qihan Ren, Xun Jiang, Xing Zhou, Dongrui Liu, Ling Yang, Yue Wu, Kaixuan Huang, Shilong Liu, Hongru Wang, Mengdi Wang

+ [VADER: A Human-Evaluated Benchmark for Vulnerability Assessment, Detection, Explanation, and Remediation](https://arxiv.org//abs/2505.19395)

	Ethan TS. Liu, Austin Wang, Spencer Mateega, Carlos Georgescu, Danny Tang

+ [It's Not Just Labeling" -- A Research on LLM Generated Feedback Interpretability and Image Labeling Sketch Features](https://arxiv.org//abs/2505.19419)

	Baichuan Li, Larry Powell, Tracy Hammond

+ [The Role of Diversity in In-Context Learning for Large Language Models](https://arxiv.org//abs/2505.19426)

	Wenyang Xiao, Haoyu Zhao, Lingxiao Huang

+ [WINA: Weight Informed Neuron Activation for Accelerating Large Language Model Inference](https://arxiv.org//abs/2505.19427)

	Sihan Chen, Dan Zhao, Jongwoo Ko, Colby Banbury, Huiping Zhuang, Luming Liang, Tianyi Chen

+ [Vibe Coding vs. Agentic Coding: Fundamentals and Practical Implications of Agentic AI](https://arxiv.org//abs/2505.19443)

	Ranjan Sapkota, Konstantinos I. Roumeliotis, Manoj Karkee

+ [Win Fast or Lose Slow: Balancing Speed and Accuracy in Latency-Sensitive Decisions of LLMs](https://arxiv.org//abs/2505.19481)

	Hao Kang, Qingru Zhang, Han Cai, Weiyuan Xu, Tushar Krishna, Yilun Du, Tsachy Weissman

+ [Understanding Transformer from the Perspective of Associative Memory](https://arxiv.org//abs/2505.19488)

	Shu Zhong, Mingyu Xu, Tenglong Ao, Guang Shi

+ [Enhancing Visual Reliance in Text Generation: A Bayesian Perspective on Mitigating Hallucination in Large Vision-Language Models](https://arxiv.org//abs/2505.19498)

	Nanxing Hu, Xiaoyue Duan, Jinchao Zhang, Guoliang Kang

+ [DOGe: Defensive Output Generation for LLM Protection Against Knowledge Distillation](https://arxiv.org//abs/2505.19504)

	Pingzhi Li, Zhen Tan, Huaizhi Qu, Huan Liu, Tianlong Chen

+ [Benchmarking Multimodal Knowledge Conflict for Large Multimodal Models](https://arxiv.org//abs/2505.19509)

	Yifan Jia, Kailin Jiang, Yuyang Liang, Qihan Ren, Yi Xin, Rui Yang, Fenze Feng, Mingcai Chen, Hengyang Lu, Haozhe Wang, Xiaoye Qu, Dongrui Liu, Lizhen Cui, Yuntao Du

+ [SIPDO: Closed-Loop Prompt Optimization via Synthetic Data Feedback](https://arxiv.org//abs/2505.19514)

	Yaoning Yu, Ye Yu, Kai Wei, Haojing Luo, Haohan Wang

+ [DoctorRAG: Medical RAG Fusing Knowledge with Patient Analogy through Textual Gradients](https://arxiv.org//abs/2505.19538)

	Yuxing Lu, Gecheng Fu, Wei Wu, Xukai Zhao, Sin Yee Goi, Jinzhuo Wang

+ [How Syntax Specialization Emerges in Language Models](https://arxiv.org//abs/2505.19548)

	Xufeng Duan, Zhaoqian Yao, Yunhao Zhang, Shaonan Wang, Zhenguang G. Cai

+ [DocMEdit: Towards Document-Level Model Editing](https://arxiv.org//abs/2505.19572)

	Li Zeng, Zeming Liu, Chong Feng, Heyan Huang, Yuhang Guo

+ [Accelerating Prefilling for Long-Context LLMs via Sparse Pattern Sharing](https://arxiv.org//abs/2505.19578)

	Dan Peng, Zhihui Fu, Zewen Ye, Zhuoran Song, Jun Wang

+ [Multi-Agent Collaboration via Evolving Orchestration](https://arxiv.org//abs/2505.19591)

	Yufan Dang, Chen Qian, Xueheng Luo, Jingru Fan, Zihao Xie, Ruijie Shi, Weize Chen, Cheng Yang, Xiaoyin Che, Ye Tian, Xuantang Xiong, Lei Han, Zhiyuan Liu, Maosong Sun

+ [Preference Optimization by Estimating the Ratio of the Data Distribution](https://arxiv.org//abs/2505.19601)

	Yeongmin Kim, Heesun Bae, Byeonghu Na, Il-Chul Moon

+ [Energy-based Preference Optimization for Test-time Adaptation](https://arxiv.org//abs/2505.19607)

	Yewon Han, Seoyun Yang, Taesup Kim

+ [Skrull: Towards Efficient Long Context Fine-tuning through Dynamic Data Scheduling](https://arxiv.org//abs/2505.19609)

	Hongtao Xu, Wenting Shen, Yuanxin Wei, Ang Wang, Guo Runfan, Tianxing Wang, Yong Li, Mingzhen Li, Weile Jia

+ [Diagnosing and Mitigating Modality Interference in Multimodal Large Language Models](https://arxiv.org//abs/2505.19616)

	Rui Cai, Bangzheng Li, Xiaofei Wen, Muhao Chen, Zhe Zhao

+ [AgentRecBench: Benchmarking LLM Agent-based Personalized Recommender Systems](https://arxiv.org//abs/2505.19623)

	Yu Shang, Peijie Liu, Yuwei Yan, Zijing Wu, Leheng Sheng, Yuanqing Yu, Chumeng Jiang, An Zhang, Fengli Xu, Yu Wang, Min Zhang, Yong Li

+ [MoESD: Unveil Speculative Decoding's Potential for Accelerating Sparse MoE](https://arxiv.org//abs/2505.19645)

	Zongle Huang, Lei Zhu, Zongyuan Zhan, Ting Hu, Weikai Mao, Xianzhi Yu, Yongpan Liu, Tianyu Zhang

+ [Large Language Models in Code Co-generation for Safe Autonomous Vehicles](https://arxiv.org//abs/2505.19658)

	Ali Nouri, Beatriz Cabrero-Daniel, Zhennan Fei, Krishna Ronanki, Håkan Sivencrona, Christian Berger

+ [GenKI: Enhancing Open-Domain Question Answering with Knowledge Integration and Controllable Generation in Large Language Models](https://arxiv.org//abs/2505.19660)

	Tingjia Shen, Hao Wang, Chuan Qin, Ruijun Sun, Yang Song, Defu Lian, Hengshu Zhu, Enhong Chen

+ [Calibrating Pre-trained Language Classifiers on LLM-generated Noisy Labels via Iterative Refinement](https://arxiv.org//abs/2505.19675)

	Liqin Ye, Agam Shah, Chao Zhang, Sudheer Chava

+ [Leveraging Importance Sampling to Detach Alignment Modules from Large Language Models](https://arxiv.org//abs/2505.19700)

	Yi Liu, Dianqing Liu, Mingye Zhu, Junbo Guo, Yongdong Zhang, Zhendong Mao

+ [Error Typing for Smarter Rewards: Improving Process Reward Models with Error-Aware Hierarchical Supervision](https://arxiv.org//abs/2505.19706)

	Tej Deep Pala, Panshul Sharma, Amir Zadeh, Chuan Li, Soujanya Poria

+ [MT$^{3}$: Scaling MLLM-based Text Image Machine Translation via Multi-Task Reinforcement Learning](https://arxiv.org//abs/2505.19714)

	Zhaopeng Feng, Yupu Liang, Shaosheng Cao, Jiayuan Su, Jiahan Ren, Zhe Xu, Yao Hu, Wenxuan Huang, Jian Wu, Zuozhu Liu

+ [Graceful Forgetting in Generative Language Models](https://arxiv.org//abs/2505.19715)

	Chunyang Jiang, Chi-min Chan, Yiyang Cai, Yulong Liu, Wei Xue, Yike Guo

+ [Distilling Closed-Source LLM's Knowledge for Locally Stable and Economic Biomedical Entity Linking](https://arxiv.org//abs/2505.19722)

	Yihao Ai, Zhiyuan Ning, Weiwei Dai, Pengfei Wang, Yi Du, Wenjuan Cui, Kunpeng Liu, Yuanchun Zhou

+ [NeuSym-RAG: Hybrid Neural Symbolic Retrieval with Multiview Structuring for PDF Question Answering](https://arxiv.org//abs/2505.19754)

	Ruisheng Cao, Hanchong Zhang, Tiancheng Huang, Zhangyi Kang, Yuxin Zhang, Liangtai Sun, Hanqi Li, Yuxun Miao, Shuai Fan, Lu Chen, Kai Yu

+ [Agentic Predictor: Performance Prediction for Agentic Workflows via Multi-View Encoding](https://arxiv.org//abs/2505.19764)

	Patara Trirat, Wonyong Jeong, Sung Ju Hwang

+ [Analyzing Political Bias in LLMs via Target-Oriented Sentiment Classification](https://arxiv.org//abs/2505.19776)

	Akram Elbouanani, Evan Dufraisse, Adrian Popescu

+ [Deciphering Trajectory-Aided LLM Reasoning: An Optimization Perspective](https://arxiv.org//abs/2505.19815)

	Junnan Liu, Hongwei Liu, Linchen Xiao, Shudong Liu, Taolin Zhang, Zihan Ma, Songyang Zhang, Kai Chen

+ [FinLoRA: Benchmarking LoRA Methods for Fine-Tuning LLMs on Financial Datasets](https://arxiv.org//abs/2505.19819)

	Dannong Wang, Jaisal Patel, Daochen Zha, Steve Y. Yang, Xiao-Yang Liu

+ [Deconstructing Obfuscation: A four-dimensional framework for evaluating Large Language Models assembly code deobfuscation capabilities](https://arxiv.org//abs/2505.19887)

	Anton Tkachenko, Dmitrij Suskevic, Benjamin Adolphi

+ [APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization](https://arxiv.org//abs/2505.19912)

	Javier Marín

+ [Enigmata: Scaling Logical Reasoning in Large Language Models with Synthetic Verifiable Puzzles](https://arxiv.org//abs/2505.19914)

	Jiangjie Chen, Qianyu He, Siyu Yuan, Aili Chen, Zhicheng Cai, Weinan Dai, Hongli Yu, Qiying Yu, Xuefeng Li, Jiaze Chen, Hao Zhou, Mingxuan Wang

+ [Dynamically Learned Test-Time Model Routing in Language Model Zoos with Service Level Guarantees](https://arxiv.org//abs/2505.19947)

	Herbert Woisetschläger, Ryan Zhang, Shiqiang Wang, Hans-Arno Jacobsen

+ [MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research](https://arxiv.org//abs/2505.19955)

	Hui Chen, Miao Xiong, Yujie Lu, Wei Han, Ailin Deng, Yufei He, Jiaying Wu, Yibo Li, Yue Liu, Bryan Hooi

+ [The Limits of Preference Data for Post-Training](https://arxiv.org//abs/2505.19964)

	Eric Zhao, Jessica Dai, Pranjal Awasthi

+ [Learning to Select In-Context Demonstration Preferred by Large Language Model](https://arxiv.org//abs/2505.19966)

	Zheng Zhang, Shaocheng Lan, Lei Song, Jiang Bian, Yexin Li, Kan Ren

+ [DFIR-Metric: A Benchmark Dataset for Evaluating Large Language Models in Digital Forensics and Incident Response](https://arxiv.org//abs/2505.19973)

	Bilel Cherif, Tamas Bisztray, Richard A. Dubniczky, Aaesha Aldahmani, Saeed Alshehhi, Norbert Tihanyi

+ [Grammars of Formal Uncertainty: When to Trust LLMs in Automated Reasoning Tasks](https://arxiv.org//abs/2505.20047)

	Debargha Ganguly, Vikash Singh, Sreehari Sankar, Biyao Zhang, Xuecen Zhang, Srinivasan Iyengar, Xiaotian Han, Amit Sharma, Shivkumar Kalyanaraman, Vipin Chaudhary

+ [SafeDPO: A Simple Approach to Direct Preference Optimization with Enhanced Safety](https://arxiv.org//abs/2505.20065)

	Geon-Hyeong Kim, Youngsoo Jang, Yu Jin Kim, Byoungjip Kim, Honglak Lee, Kyunghoon Bae, Moontae Lee

+ [Incentivizing Reasoning from Weak Supervision](https://arxiv.org//abs/2505.20072)

	Yige Yuan, Teng Xiao, Shuchang Tao, Xue Wang, Jinyang Gao, Bolin Ding, Bingbing Xu

+ [Inference-time Alignment in Continuous Space](https://arxiv.org//abs/2505.20081)

	Yige Yuan, Teng Xiao, Li Yunfan, Bingbing Xu, Shuchang Tao, Yunqi Qiu, Huawei Shen, Xueqi Cheng

+ [MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative Chain-of-Thought Reasoning](https://arxiv.org//abs/2505.20096)

	Thang Nguyen, Peter Chin, Yu-Wing Tai

+ [Large Language Models Meet Knowledge Graphs for Question Answering: Synthesis and Opportunities](https://arxiv.org//abs/2505.20099)

	Chuangtao Ma, Yongrui Chen, Tianxing Wu, Arijit Khan, Haofen Wang

+ [AdaTP: Attention-Debiased Token Pruning for Video Large Language Models](https://arxiv.org//abs/2505.20100)

	Fengyuan Sun, Leqi Shen, Hui Chen, Sicheng Zhao, Jungong Han, Guiguang Ding

+ [ResSVD: Residual Compensated SVD for Large Language Model Compression](https://arxiv.org//abs/2505.20112)

	Haolei Bai, Siyong Jian, Tuo Liang, Yu Yin, Huan Wang

+ [StructEval: Benchmarking LLMs' Capabilities to Generate Structural Outputs](https://arxiv.org//abs/2505.20139)

	Jialin Yang, Dongfu Jiang, Lipeng He, Sherman Siu, Yuxuan Zhang, Disen Liao, Zhuofeng Li, Huaye Zeng, Yiming Jia, Haozhe Wang, Benjamin Schneider, Chi Ruan, Wentao Ma, Zhiheng Lyu, Yifei Wang, Yi Lu, Quy Duc Do, Ziyan Jiang, Ping Nie, Wenhu Chen

+ [Prismatic Synthesis: Gradient-based Data Diversification Boosts Generalization in LLM Reasoning](https://arxiv.org//abs/2505.20161)

	Jaehun Jung, Seungju Han, Ximing Lu, Skyler Hallinan, David Acuna, Shrimai Prabhumoye, Mostafa Patwary, Mohammad Shoeybi, Bryan Catanzaro, Yejin Choi

+ [THiNK: Can Large Language Models Think-aloud?](https://arxiv.org//abs/2505.20184)

	Yongan Yu, Mengqian Wu, Yiran Lin, Nikki G. Lobczowski

+ [Evaluating Large Language Models for Code Review](https://arxiv.org//abs/2505.20206)

	Umut Cihan, Arda İçöz, Vahid Haratian, Eray Tüzün

+ [Parameter-Efficient Fine-Tuning with Column Space Projection](https://arxiv.org//abs/2505.20211)

	Junseo Hwang, Wonguk Cho, Taesup Kim

+ [From What to How: Attributing CLIP's Latent Components Reveals Unexpected Semantic Reliance](https://arxiv.org//abs/2505.20229)

	Maximilian Dreyer, Lorenz Hufe, Jim Berend, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek

+ [KnowTrace: Bootstrapping Iterative Retrieval-Augmented Generation with Structured Knowledge Tracing](https://arxiv.org//abs/2505.20245)

	Rui Li, Quanyu Dai, Zeyu Zhang, Xu Chen, Zhenhua Dong, Ji-Rong Wen

+ [Position: Mechanistic Interpretability Should Prioritize Feature Consistency in SAEs](https://arxiv.org//abs/2505.20254)

	Xiangchen Song, Aashiq Muhamed, Yujia Zheng, Lingjing Kong, Zeyu Tang, Mona T. Diab, Virginia Smith, Kun Zhang

+ [Lifelong Safety Alignment for Language Models](https://arxiv.org//abs/2505.20259)

	Haoyu Wang, Zeyu Qin, Yifei Zhao, Chao Du, Min Lin, Xueqian Wang, Tianyu Pang

+ [Does quantization affect models' performance on long-context tasks?](https://arxiv.org//abs/2505.20276)

	Anmol Mekala, Anirudh Atmakuru, Yixiao Song, Marzena Karpinska, Mohit Iyyer

+ [Self-reflective Uncertainties: Do LLMs Know Their Internal Answer Distribution?](https://arxiv.org//abs/2505.20295)

	Michael Kirchhof, Luca Füger, Adam Goliński, Eeshan Gunesh Dhekane, Arno Blaas, Sinead Williamson

+ [Reasoning LLMs are Wandering Solution Explorers](https://arxiv.org//abs/2505.20296)

	Jiahao Lu, Ziwei Xu, Mohan Kankanhalli

+ [CoTGuard: Using Chain-of-Thought Triggering for Copyright Protection in Multi-Agent LLM Systems](https://arxiv.org//abs/2505.19405)

	Yan Wen, Junfeng Guo, Heng Huang

+ [Self-Reflective Planning with Knowledge Graphs: Enhancing LLM Reasoning Reliability for Question Answering](https://arxiv.org//abs/2505.19410)

	Jiajun Zhu, Ye Liu, Meikai Bao, Kai Zhang, Yanghai Zhang, Qi Liu

+ [Frictional Agent Alignment Framework: Slow Down and Don't Break Things](https://arxiv.org//abs/2505.19428)

	Abhijnan Nath, Carine Graff, Andrei Bachinin, Nikhil Krishnaswamy

+ [Route to Reason: Adaptive Routing for LLM and Reasoning Strategy Selection](https://arxiv.org//abs/2505.19435)

	Zhihong Pan, Kai Zhang, Yuze Zhao, Yupeng Han

+ [The Birth of Knowledge: Emergent Features across Time, Space, and Scale in Large Language Models](https://arxiv.org//abs/2505.19440)

	Shashata Sawmya, Micah Adler, Nir Shavit

+ [Continuous Self-Improvement of Large Language Models by Test-time Training with Verifier-Driven Sample Selection](https://arxiv.org//abs/2505.19475)

	Mohammad Mahdi Moradi, Hossam Amer, Sudhir Mudur, Weiwei Zhang, Yang Liu, Walid Ahmed

+ [CulFiT: A Fine-grained Cultural-aware LLM Training Paradigm via Multilingual Critique Data Synthesis](https://arxiv.org//abs/2505.19484)

	Ruixiang Feng, Shen Gao, Xiuying Chen, Lisi Chen, Shuo Shang

+ [Anveshana: A New Benchmark Dataset for Cross-Lingual Information Retrieval On English Queries and Sanskrit Documents](https://arxiv.org//abs/2505.19494)

	Manoj Balaji Jagadeeshan, Prince Raj, Pawan Goyal

+ [LLM Meets Scene Graph: Can Large Language Models Understand and Generate Scene Graphs? A Benchmark and Empirical Study](https://arxiv.org//abs/2505.19510)

	Dongil Yang, Minjin Kim, Sunghwan Kim, Beong-woo Kwak, Minjun Park, Jinseok Hong, Woontack Woo, Jinyoung Yeo

+ [Causal Distillation: Transferring Structured Explanations from Large to Compact Language Models](https://arxiv.org//abs/2505.19511)

	Aggrey Muhebwa, Khalid K. Osman

+ [Towards Multi-Granularity Memory Association and Selection for Long-Term Conversational Agents](https://arxiv.org//abs/2505.19549)

	Derong Xu, Yi Wen, Pengyue Jia, Yingyi Zhang, wenlin zhang, Yichao Wang, Huifeng Guo, Ruiming Tang, Xiangyu Zhao, Enhong Chen, Tong Xu

+ [TailorKV: A Hybrid Framework for Long-Context Inference via Tailored KV Cache Optimization](https://arxiv.org//abs/2505.19586)

	Dingyu Yao, Bowen Shen, Zheng Lin, Wei Liu, Jian Luan, Bin Wang, Weiping Wang

+ [Evaluating Robustness of Large Audio Language Models to Audio Injection: An Empirical Study](https://arxiv.org//abs/2505.19598)

	Guanyu Hou, Jiaming He, Yinhang Zhou, Ji Guo, Yitong Qiao, Rui Zhang, Wenbo Jiang

+ [HomeBench: Evaluating LLMs in Smart Homes with Valid and Invalid Instructions Across Single and Multiple Devices](https://arxiv.org//abs/2505.19628)

	Silin Li, Yuhang Guo, Jiashu Yao, Zeming Liu, Haifeng Wang

+ [DoctorAgent-RL: A Multi-Agent Collaborative Reinforcement Learning System for Multi-Turn Clinical Dialogue](https://arxiv.org//abs/2505.19630)

	Yichun Feng, Jiawei Wang, Lu Zhou, Yixue Li

+ [Faster and Better LLMs via Latency-Aware Test-Time Scaling](https://arxiv.org//abs/2505.19634)

	Zili Wang, Tianyu Zhang, Haoli Bai, Lu Hou, Xianzhi Yu, Wulong Liu, Shiming Xiang, Lei Zhu

+ [Interleaved Reasoning for Large Language Models via Reinforcement Learning](https://arxiv.org//abs/2505.19640)

	Roy Xie, David Qiu, Deepak Gopinath, Dong Lin, Yanchao Sun, Chong Wang, Saloni Potdar, Bhuwan Dhingra

+ [Select, Read, and Write: A Multi-Agent Framework of Full-Text-based Related Work Generation](https://arxiv.org//abs/2505.19647)

	Xiaochuan Liu, Ruihua Song, Xiting Wang, Xu Chen

+ [Reshaping Representation Space to Balance the Safety and Over-rejection in Large Audio Language Models](https://arxiv.org//abs/2505.19670)

	Hao Yang, Lizhen Qu, Ehsan Shareghi, Gholamreza Haffari

+ [Comparing Moral Values in Western English-speaking societies and LLMs with Word Associations](https://arxiv.org//abs/2505.19674)

	Chaoyi Xiang, Chunhua Liu, Simon De Deyne, Lea Frermann

+ [Token-level Accept or Reject: A Micro Alignment Approach for Large Language Models](https://arxiv.org//abs/2505.19743)

	Yang Zhang, Yu Yu, Bo Tang, Yu Zhu, Chuxiong Sun, Wenqiang Wei, Jie Hu, Zipeng Xie, Zhiyu Li, Feiyu Xiong, Edward Chung

+ [Efficient Reasoning via Chain of Unconscious Thought](https://arxiv.org//abs/2505.19756)

	Ruihan Gong, Yue Liu, Wenjie Qu, Mingzhe Du, Yufei He, Yingwei Ma, Yulin Chen, Xiang Liu, Yi Wen, Xinfeng Li, Ruidong Wang, Xinzhong Zhu, Bryan Hooi, Jiaheng Zhang

+ [SGM: A Framework for Building Specification-Guided Moderation Filters](https://arxiv.org//abs/2505.19766)

	Masoomali Fatehkia, Enes Altinisik, Husrev Taha Sencar

+ [T^2Agent A Tool-augmented Multimodal Misinformation Detection Agent with Monte Carlo Tree Search](https://arxiv.org//abs/2505.19768)

	Xing Cui, Yueying Zou, Zekun Li, Peipei Li, Xinyuan Xu, Xuannan Liu, Huaibo Huang, Ran He

+ [What Really Matters in Many-Shot Attacks? An Empirical Study of Long-Context Vulnerabilities in LLMs](https://arxiv.org//abs/2505.19773)

	Sangyeop Kim, Yohan Lee, Yongwoo Song, Kimin Lee

+ [The Avengers: A Simple Recipe for Uniting Smaller Language Models to Challenge Proprietary Giants](https://arxiv.org//abs/2505.19797)

	Yiqun Zhang, Hao Li, Chenxu Wang, Linyao Chen, Qiaosheng Zhang, Peng Ye, Shi Feng, Daling Wang, Zhen Wang, Xinrun Wang, Jia Xu, Lei Bai, Wanli Ouyang, Shuyue Hu

+ [REA-RL: Reflection-Aware Online Reinforcement Learning for Efficient Large Reasoning Models](https://arxiv.org//abs/2505.19862)

	Hexuan Deng, Wenxiang Jiao, Xuebo Liu, Jun Rao, Min Zhang

+ [ALAS: Measuring Latent Speech-Text Alignment For Spoken Language Understanding In Multimodal LLMs](https://arxiv.org//abs/2505.19937)

	Pooneh Mousavi, Yingzhi Wang, Mirco Ravanelli, Cem Subakan

+ [MiniLongBench: The Low-cost Long Context Understanding Benchmark for Large Language Models](https://arxiv.org//abs/2505.19959)

	Zhongzhan Huang, Guoming Ling, Shanshan Zhong, Hefeng Wu, Liang Lin

+ [CP-Router: An Uncertainty-Aware Router Between LLM and LRM](https://arxiv.org//abs/2505.19970)

	Jiayuan Su, Fulin Lin, Zhaopeng Feng, Han Zheng, Teng Wang, Zhenyu Xiao, Xinlong Zhao, Zuozhu Liu, Lu Cheng, Hongwei Wang

+ [WebCoT: Enhancing Web Agent Reasoning by Reconstructing Chain-of-Thought in Reflection, Branching, and Rollback](https://arxiv.org//abs/2505.20013)

	Minda Hu, Tianqing Fang, Jianshu Zhang, Junyu Ma, Zhisong Zhang, Jingyan Zhou, Hongming Zhang, Haitao Mi, Dong Yu, Irwin King

+ [TTPA: Token-level Tool-use Preference Alignment Training Framework with Fine-grained Evaluation](https://arxiv.org//abs/2505.20016)

	Chengrui Huang, Shen Gao, Zhengliang Shi, Dongsheng Wang, Shuo Shang

+ [Training LLM-Based Agents with Synthetic Self-Reflected Trajectories and Partial Masking](https://arxiv.org//abs/2505.20023)

	Yihan Chen, Benfeng Xu, Xiaorui Wang, Yongdong Zhang, Zhendong Mao

+ [Uncertainty-Aware Attention Heads: Efficient Unsupervised Uncertainty Quantification for LLMs](https://arxiv.org//abs/2505.20045)

	Artem Vazhentsev, Lyudmila Rvanova, Gleb Kuzmin, Ekaterina Fadeeva, Ivan Lazichny, Alexander Panchenko, Maxim Panov, Timothy Baldwin, Mrinmaya Sachan, Preslav Nakov, Artem Shelmanov

+ [Multi-Domain Explainability of Preferences](https://arxiv.org//abs/2505.20088)

	Nitay Calderon, Liat Ein-Dor, Roi Reichart

+ [S2LPP: Small-to-Large Prompt Prediction across LLMs](https://arxiv.org//abs/2505.20097)

	Liang Cheng, Tianyi LI, Zhaowei Wang, Mark Steedman

+ [Adaptive Deep Reasoning: Triggering Deep Thinking When Needed](https://arxiv.org//abs/2505.20101)

	Yunhao Wang, Yuhao Zhang, Tinghao Yu, Can Xu, Feng Zhang, Fengzong Lian

+ [TrojanStego: Your Language Model Can Secretly Be A Steganographic Privacy Leaking Agent](https://arxiv.org//abs/2505.20118)

	Dominik Meier, Jan Philip Wahle, Paul Röttger, Terry Ruas, Bela Gipp

+ [Iterative Self-Incentivization Empowers Large Language Models as Agentic Searchers](https://arxiv.org//abs/2505.20128)

	Zhengliang Shi, Lingyong Yan, Dawei Yin, Suzan Verberne, Maarten de Rijke, Zhaochun Ren

+ [AweDist: Attention-aware Embedding Distillation for New Input Token Embeddings](https://arxiv.org//abs/2505.20133)

	Konstantin Dobler, Desmond Elliott, Gerard de Melo

+ [SeMe: Training-Free Language Model Merging via Semantic Alignment](https://arxiv.org//abs/2505.20144)

	Jian Gu, Aldeida Aleti, Chunyang Chen, Hongyu Zhang

+ [UORA: Uniform Orthogonal Reinitialization Adaptation in Parameter-Efficient Fine-Tuning of Large Models](https://arxiv.org//abs/2505.20154)

	Xueyan Zhang, Jinman Zhao, Zhifei Yang, Yibo Zhong, Shuhao Guan, Linbo Cao, Yining Wang

+ [Pangu Light: Weight Re-Initialization for Pruning and Accelerating LLMs](https://arxiv.org//abs/2505.20155)

	Hanting Chen, Jiarui Qin, Jialong Guo, Tao Yuan, Yichun Yin, Huiling Zhen, Yasheng Wang, Jinpeng Li, Xiaojun Meng, Meng Zhang, Rongju Ruan, Zheyuan Bai, Yehui Tang, Can Chen, Xinghao Chen, Fisher Yu, Ruiming Tang, Yunhe Wang (and Other Contributors)

+ [Monocle: Hybrid Local-Global In-Context Evaluation for Long-Text Generation with Uncertainty-Based Active Learning](https://arxiv.org//abs/2505.20195)

	Xiaorong Wang, Ting Yang, Zhu Zhang, Shuo Wang, Zihan Zhou, Liner Yang, Zhiyuan Liu, Maosong Sun

+ [Reasoning Is Not All You Need: Examining LLMs for Multi-Turn Mental Health Conversations](https://arxiv.org//abs/2505.20201)

	Mohit Chandra, Siddharth Sriraman, Harneet Singh Khanuja, Yiqiao Jin, Munmun De Choudhury

+ [How to Improve the Robustness of Closed-Source Models on NLI](https://arxiv.org//abs/2505.20209)

	Joe Stacey, Lisa Alazraki, Aran Ubhi, Beyza Ermis, Aaron Mueller, Marek Rei

+ [FLAME-MoE: A Transparent End-to-End Research Platform for Mixture-of-Experts Language Models](https://arxiv.org//abs/2505.20225)

	Hao Kang, Zichun Yu, Chenyan Xiong

+ [It's High Time: A Survey of Temporal Information Retrieval and Question Answering](https://arxiv.org//abs/2505.20243)

	Bhawna Piryani, Abdelrahman Abdullah, Jamshid Mozafari, Avishek Anand, Adam Jatowt

+ [ARM: Adaptive Reasoning Model](https://arxiv.org//abs/2505.20258)

	Siye Wu, Jian Xie, Yikai Zhang, Aili Chen, Kai Zhang, Yu Su, Yanghua Xiao

+ [OmniCharacter: Towards Immersive Role-Playing Agents with Seamless Speech-Language Personality Interaction](https://arxiv.org//abs/2505.20277)

	Haonan Zhang, Run Luo, Xiong Liu, Yuchuan Wu, Ting-En Lin, Pengpeng Zeng, Qiang Qu, Feiteng Fang, Min Yang, Lianli Gao, Jingkuan Song, Fei Huang, Yongbin Li

+ [One-shot Entropy Minimization](https://arxiv.org//abs/2505.20282)

	Zitian Gao, Lynx Chen, Joey Zhou, Bryan Dai

+ [MASKSEARCH: A Universal Pre-Training Framework to Enhance Agentic Search Capability](https://arxiv.org//abs/2505.20285)

	Weiqi Wu, Xin Guan, Shen Huang, Yong Jiang, Pengjun Xie, Fei Huang, Jiuxin Cao, Hai Zhao, Jingren Zhou

+ [Learning to Reason without External Rewards](https://arxiv.org//abs/2505.19590)

	Xuandong Zhao, Zhewei Kang, Aosong Feng, Sergey Levine, Dawn Song

+ [Understanding the Performance Gap in Preference Learning: A Dichotomy of RLHF and DPO](https://arxiv.org//abs/2505.19770)

	Ruizhe Shi, Minhak Song, Runlong Zhou, Zihan Zhang, Maryam Fazel, Simon S. Du

+ [ESLM: Risk-Averse Selective Language Modeling for Efficient Pretraining](https://arxiv.org//abs/2505.19893)

	Melis Ilayda Bal, Volkan Cevher, Michael Muehlebach

+ [An Explainable Diagnostic Framework for Neurodegenerative Dementias via Reinforcement-Optimized LLM Reasoning](https://arxiv.org//abs/2505.19954)

	Andrew Zamai, Nathanael Fijalkow, Boris Mansencal, Laurent Simon, Eloi Navet, Pierrick Coupe

+ [REARANK: Reasoning Re-ranking Agent via Reinforcement Learning](https://arxiv.org//abs/2505.20046)

	Le Zhang, Bo Wang, Xipeng Qiu, Siva Reddy, Aishwarya Agrawal

+ [Aggregated Structural Representation with Large Language Models for Human-Centric Layout Generation](https://arxiv.org//abs/2505.19554)

	Jiongchao Jin, Shengchu Zhao, Dajun Chen, Wei Jiang, Yong Li

+ [JailBound: Jailbreaking Internal Safety Boundaries of Vision-Language Models](https://arxiv.org//abs/2505.19610)

	Jiaxin Song, Yixu Wang, Jie Li, Rui Yu, Yan Teng, Xingjun Ma, Yingchun Wang

+ [VisCRA: A Visual Chain Reasoning Attack for Jailbreaking Multimodal Large Language Models](https://arxiv.org//abs/2505.19684)

	Bingrui Sima, Linhua Cong, Wenxuan Wang, Kun He

+ [Point-RFT: Improving Multimodal Reasoning with Visually Grounded Reinforcement Finetuning](https://arxiv.org//abs/2505.19702)

	Minheng Ni, Zhengyuan Yang, Linjie Li, Chung-Ching Lin, Kevin Lin, Wangmeng Zuo, Lijuan Wang

+ [MLLM-Guided VLM Fine-Tuning with Joint Inference for Zero-Shot Composed Image Retrieval](https://arxiv.org//abs/2505.19707)

	Rong-Cheng Tu, Zhao Jin, Jingyi Liao, Xiao Luo, Yingjie Wang, Li Shen, Dacheng Tao

+ [Efficient Multi-modal Long Context Learning for Training-free Adaptation](https://arxiv.org//abs/2505.19812)

	Zehong Ma, Shiliang Zhang, Longhui Wei, Qi Tian

+ [Attention! You Vision Language Model Could Be Maliciously Manipulated](https://arxiv.org//abs/2505.19911)

	Xiaosen Wang, Shaokang Wang, Zhijin Ge, Yuyang Luo, Shudong Zhang

+ [Alignment of large language models with constrained learning](https://arxiv.org//abs/2505.19387)

	Botong Zhang, Shuo Li, Ignacio Hounie, Osbert Bastani, Dongsheng Ding, Alejandro Ribeiro

+ [Can Compressed LLMs Truly Act? An Empirical Evaluation of Agentic Capabilities in LLM Compression](https://arxiv.org//abs/2505.19433)

	Peijie Dong, Zhenheng Tang, Xiang Liu, Lujun Li, Xiaowen Chu, Bo Li

+ [ExAnte: A Benchmark for Ex-Ante Inference in Large Language Models](https://arxiv.org//abs/2505.19533)

	Yachuan Liu, Xiaochun Wei, Lin Shi, Xinnuo Li, Bohan Zhang, Paramveer Dhillon, Qiaozhu Mei

+ [Editing as Unlearning: Are Knowledge Editing Methods Strong Baselines for Large Language Model Unlearning?](https://arxiv.org//abs/2505.19855)

	Zexi Li, Xiangzhu Wang, William F. Shen, Meghdad Kurmanji, Xinchi Qiu, Dongqi Cai, Chao Wu, Nicholas D. Lane

+ [Which Data Attributes Stimulate Math and Code Reasoning? An Investigation via Influence Functions](https://arxiv.org//abs/2505.19949)

	Siqi Kou, Qingyuan Tian, Hanwen Xu, Zihao Zeng, Zhijie Deng

+ [Grokking ExPLAIND: Unifying Model, Data, and Training Attribution to Study Model Behavior](https://arxiv.org//abs/2505.20076)

	Florian Eichin, Yupei Du, Philipp Mondorf, Barbara Plank, Michael A. Hedderich

+ [Spurious Privacy Leakage in Neural Networks](https://arxiv.org//abs/2505.20095)

	Chenxiang Zhang, Jun Pang, Sjouke Mauw

+ [FunReason: Enhancing Large Language Models' Function Calling via Self-Refinement Multiscale Loss and Automated Data Refinement](https://arxiv.org//abs/2505.20192)

	Bingguang Hao, Maolin Wang, Zengzhuang Xu, Cunyin Peng, Yicheng Chen, Xiangyu Zhao, Jinjie Gu, Chenyi Zhuang

+ [Fine-grained List-wise Alignment for Generative Medication Recommendation](https://arxiv.org//abs/2505.20218)

	Chenxiao Fan, Chongming Gao, Wentao Shi, Yaxin Gong, Zihao Zhao, Fuli Feng

+ [VLMLight: Traffic Signal Control via Vision-Language Meta-Control and Dual-Branch Reasoning](https://arxiv.org//abs/2505.19486)

	Maonan Wang, Yirong Chen, Aoyu Pang, Yuxin Cai, Chung Shue Chen, Yuheng Kan, Man-On Pun

+ [Accelerating Nash Learning from Human Feedback via Mirror Prox](https://arxiv.org//abs/2505.19731)

	Daniil Tiapkin, Daniele Calandriello, Denis Belomestny, Eric Moulines, Alexey Naumov, Kashif Rasul, Michal Valko, Pierre Menard

+ [CPA-RAG:Covert Poisoning Attacks on Retrieval-Augmented Generation in Large Language Models](https://arxiv.org//abs/2505.19864)

	Chunyang Li, Junwei Zhang, Anda Cheng, Zhuo Ma, Xinghua Li, Jianfeng Ma

+ [SCAR: Shapley Credit Assignment for More Efficient RLHF](https://arxiv.org//abs/2505.20417)

	Meng Cao, Shuyuan Zhang, Xiao-Wen Chang, Doina Precup

+ [Project Riley: Multimodal Multi-Agent LLM Collaboration with Emotional Reasoning and Voting](https://arxiv.org//abs/2505.20521)

	Ana Rita Ortigoso, Gabriel Vieira, Daniel Fuentes, Luis Frazão, Nuno Costa, António Pereira

+ [Scaling over Scaling: Exploring Test-Time Scaling Pareto in Large Reasoning Models](https://arxiv.org//abs/2505.20522)

	Jian Wang, Boyan Zhu, Chak Tou Leong, Yongqi Li, Wenjie Li

+ [Risk-aware Direct Preference Optimization under Nested Risk Measure](https://arxiv.org//abs/2505.20359)

	Lijun Zhang, Lin Li, Yajie Qi, Huizhong Song, Yaodong Yang, Jun Wang, Wei Wei

+ [VSCBench: Bridging the Gap in Vision-Language Model Safety Calibration](https://arxiv.org//abs/2505.20362)

	Jiahui Geng, Qing Li, Zongxiong Chen, Yuxia Wang, Derui Zhu, Zhuohan Xie, Chenyang Lyu, Xiuying Chen, Preslav Nakov, Fakhri Karray

+ [Hierarchical Retrieval with Evidence Curation for Open-Domain Financial Question Answering on Standardized Documents](https://arxiv.org//abs/2505.20368)

	Jaeyoung Choe, Jihoon Kim, Woohwan Jung

+ [GraphGen: Enhancing Supervised Fine-Tuning for LLMs with Knowledge-Driven Synthetic Data Generation](https://arxiv.org//abs/2505.20416)

	Zihong Chen, Wanli Jiang, Jinzhe Li, Zhonghang Yuan, Huanjun Kong, Wanli Ouyang, Nanqing Dong

+ [SEMMA: A Semantic Aware Knowledge Graph Foundation Model](https://arxiv.org//abs/2505.20422)

	Arvindh Arun, Sumit Kumar, Mojtaba Nayyeri, Bo Xiong, Ponnurangam Kumaraguru, Antonio Vergari, Steffen Staab

+ [Holes in Latent Space: Topological Signatures Under Adversarial Influence](https://arxiv.org//abs/2505.20435)

	Aideen Fay, Inés García-Redondo, Qiquan Wang, Haim Dubossarsky, Anthea Monod

+ [Conversation Kernels: A Flexible Mechanism to Learn Relevant Context for Online Conversation Understanding](https://arxiv.org//abs/2505.20482)

	Vibhor Agarwal, Arjoo Gupta, Suparna De, Nishanth Sastry

+ [InFact: Informativeness Alignment for Improved LLM Factuality](https://arxiv.org//abs/2505.20487)

	Roi Cohen, Russa Biswas, Gerard de Melo

+ [Beyond Markovian: Reflective Exploration via Bayes-Adaptive RL for LLM Reasoning](https://arxiv.org//abs/2505.20561)

	Shenao Zhang, Yaqing Wang, Yinxiao Liu, Tianqi Liu, Peter Grabowski, Eugene Ie, Zhaoran Wang, Yunxuan Li

+ [Collision- and Reachability-Aware Multi-Robot Control with Grounded LLM Planners](https://arxiv.org//abs/2505.20573)

	Jiabao Ji, Yongchao Chen, Yang Zhang, Ramana Rao Kompella, Chuchu Fan, Gaowen Liu, Shiyu Chang

+ [Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision](https://arxiv.org//abs/2505.20415)

	Xingwei Tan, Marco Valentino, Mahmud Akhter, Maria Liakata, Nikolaos Aletras

+ [HAMburger: Accelerating LLM Inference via Token Smashing](https://arxiv.org//abs/2505.20438)

	Jingyu Liu, Ce Zhang

+ [Amulet: Putting Complex Multi-Turn Conversations on the Stand with LLM Juries](https://arxiv.org//abs/2505.20451)

	Sahana Ramnath, Anurag Mudgil, Brihi Joshi, Skyler Hallinan, Xiang Ren

+ [Large Language Models for IT Automation Tasks: Are We There Yet?](https://arxiv.org//abs/2505.20505)

	Md Mahadi Hassan, John Salvador, Akond Rahman, Santu Karmaker

+ [Paths Not Taken: Understanding and Mending the Multilingual Factual Recall Pipeline](https://arxiv.org//abs/2505.20546)

	Meng Lu, Ruochen Zhang, Ellie Pavlick, Carsten Eickhoff

+ [Benign-to-Toxic Jailbreaking: Inducing Harmful Responses from Harmless Prompts](https://arxiv.org//abs/2505.21556)

	Hee-Seon Kim, Minbeom Kim, Wonjun Lee, Kihyun Kim, Changick Kim

+ [USB: A Comprehensive and Unified Safety Evaluation Benchmark for Multimodal Large Language Models](https://arxiv.org//abs/2505.23793)

	Baolin Zheng, Guanlin Chen, Hongqiong Zhong, Qingyang Teng, Yingshui Tan, Zhendong Liu, Weixun Wang, Jiaheng Liu, Jian Yang, Huiyun Jing, Jincheng Wei, Wenbo Su, Xiaoyong Zhu, Bo Zheng, Kaifu Zhang

+ [R3-RAG: Learning Step-by-Step Reasoning and Retrieval for LLMs via Reinforcement Learning](https://arxiv.org//abs/2505.23794)

	Yuan Li, Qi Luo, Xiaonan Li, Bufan Li, Qinyuan Cheng, Bo Wang, Yining Zheng, Yuxin Wang, Zhangyue Yin, Xipeng Qiu

+ [Estimating LLM Consistency: A User Baseline vs Surrogate Metrics](https://arxiv.org//abs/2505.23799)

	Xiaoyuan Wu, Weiran Lin, Omer Akgul, Lujo Bauer

+ [MultiPhishGuard: An LLM-based Multi-Agent System for Phishing Email Detection](https://arxiv.org//abs/2505.23803)

	Yinuo Xue, Eric Spero, Yun Sing Koh, Giovanni Russello

+ [Emergent LLM behaviors are observationally equivalent to data leakage](https://arxiv.org//abs/2505.23796)

	Christopher Barrie, Petter Törnberg

+ [Deriving Strategic Market Insights with Large Language Models: A Benchmark for Forward Counterfactual Generation](https://arxiv.org//abs/2505.19430)

	Keane Ong, Rui Mao, Deeksha Varshney, Paul Pu Liang, Erik Cambria, Gianmarco Mengaldo

+ [DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning](https://arxiv.org//abs/2505.20241)

	Qi Cao, Ruiyi Wang, Ruiyi Zhang, Sai Ashish Somayajula, Pengtao Xie

+ [Rethinking Text-based Protein Understanding: Retrieval or LLM?](https://arxiv.org//abs/2505.20354)

	Juntong Wu, Zijing Liu, He Cao, Hao Li, Bin Feng, Zishan Shu, Ke Yu, Li Yuan, Yu Li

+ [Agentic 3D Scene Generation with Spatially Contextualized VLMs](https://arxiv.org//abs/2505.20129)

	Xinhang Liu, Yu-Wing Tai, Chi-Keung Tang

# 2025-05-25
+ [Stronger Enforcement of Instruction Hierarchy via Augmented Intermediate Representations](https://arxiv.org//abs/2505.18907)

	Sanjay Kariyappa, G. Edward Suh

+ [Meta-aware Learning in text-to-SQL Large Language Model](https://arxiv.org//abs/2505.18929)

	Wenda Zhang

+ [Can Large Language Models Infer Causal Relationships from Real-World Text?](https://arxiv.org//abs/2505.18931)

	Ryan Saklad, Aman Chadha, Oleg Pavlov, Raha Moraffah

+ [REACT: Representation Extraction And Controllable Tuning to Overcome Overfitting in LLM Knowledge Editing](https://arxiv.org//abs/2505.18933)

	Haitian Zhong, Yuhuan Liu, Ziyang Xu, Guofan Liu, Qiang Liu, Shu Wu, Zhe Zhao, Liang Wang, Tieniu Tan

+ [Weaver: Interweaving SQL and LLM for Table Reasoning](https://arxiv.org//abs/2505.18961)

	Rohit Khoja, Devanshu Gupta, Yanjie Fu, Dan Roth, Vivek Gupta

+ [Aligning LLM with human travel choices: a persona-based embedding learning approach](https://arxiv.org//abs/2505.19003)

	Tianming Liu, Manzi Li, Yafeng Yin

+ [RECAST: Strengthening LLMs' Complex Instruction Following with Constraint-Verifiable Data](https://arxiv.org//abs/2505.19030)

	Wenhao Liu, Zhengkang Guo, Mingchen Xie, Jingwen Xu, Zisu Huang, Muzhao Tian, Jianhan Xu, Muling Wu, Xiaohua Wang, Changze Lv, He-Da Wang, Hu Yao, Xiaoqing Zheng, Xuanjing Huang

+ [Universal Reasoner: A Single, Composable Plug-and-Play Reasoner for Frozen LLMs](https://arxiv.org//abs/2505.19075)

	Jaemin Kim, Hangeol Chang, Hyunmin Hwang, Choonghan Kim, Jong Chul Ye

+ [Reinforced Latent Reasoning for LLM-based Recommendation](https://arxiv.org//abs/2505.19092)

	Yang Zhang, Wenxin Xu, Xiaoyan Zhao, Wenjie Wang, Fuli Feng, Xiangnan He, Tat-Seng Chua

+ [OrgAccess: A Benchmark for Role Based Access Control in Organization Scale LLMs](https://arxiv.org//abs/2505.19165)

	Debdeep Sanyal Umakanta Maharana, Yash Sinha, Hong Ming Tan, Shirish Karande, Mohan Kankanhalli, Murari Mandal

+ [Investigating Pedagogical Teacher and Student LLM Agents: Genetic Adaptation Meets Retrieval Augmented Generation Across Learning Style](https://arxiv.org//abs/2505.19173)

	Debdeep Sanyal, Agniva Maiti, Umakanta Maharana, Dhruv Kumar, Ankur Mali, C. Lee Giles, Murari Mandal

+ [GUARDIAN: Safeguarding LLM Multi-Agent Collaborations with Temporal Graph Modeling](https://arxiv.org//abs/2505.19234)

	Jialong Zhou, Lichao Wang, Xiao Yang

+ [Sensorimotor features of self-awareness in multimodal large language models](https://arxiv.org//abs/2505.19237)

	Iñaki Dellibarda Varela, Pablo Romero-Sorozabal, Diego Torricelli, Gabriel Delgado-Oleas, Jose Ignacio Serrano, Maria Dolores del Castillo Sobrino, Eduardo Rocon, Manuel Cebrian

+ [Evaluating Steering Techniques using Human Similarity Judgments](https://arxiv.org//abs/2505.19333)

	Zach Studdiford, Timothy T. Rogers, Siddharth Suresh, Kushin Mukherjee

+ [Architectures of Error: A Philosophical Inquiry into AI and Human Code Generation](https://arxiv.org//abs/2505.19353)

	Camilo Chacón Sartori

+ [Foundations of Top-$k$ Decoding For Language Models](https://arxiv.org//abs/2505.19371)

	Georgy Noarov, Soham Mallick, Tao Wang, Sunay Joshi, Yan Sun, Yangxinyu Xie, Mengxin Yu, Edgar Dobriban

+ [Behavior Injection: Preparing Language Models for Reinforcement Learning](https://arxiv.org//abs/2505.18917)

	Zhepeng Cen, Yihang Yao, William Han, Zuxin Liu, Ding Zhao

+ [The Price of Format: Diversity Collapse in LLMs](https://arxiv.org//abs/2505.18949)

	Longfei Yun, Chenyang An, Zilong Wang, Letian Peng, Jingbo Shang

+ [An Embarrassingly Simple Defense Against LLM Abliteration Attacks](https://arxiv.org//abs/2505.19056)

	Harethah Abu Shairah, Hasan Abed Al Kader Hammoud, Bernard Ghanem, George Turkiyyah

+ [CCHall: A Novel Benchmark for Joint Cross-Lingual and Cross-Modal Hallucinations Detection in Large Language Models](https://arxiv.org//abs/2505.19108)

	Yongheng Zhang, Xu Liu, Ruoxi Zhou, Qiguang Chen, Hao Fei, Wenpeng Lu, Libo Qin

+ [FP4 All the Way: Fully Quantized Training of LLMs](https://arxiv.org//abs/2505.19115)

	Brian Chmiel, Maxim Fishman, Ron Banner, Daniel Soudry

+ [Two LLMs debate, both are certain they've won](https://arxiv.org//abs/2505.19184)

	Minh Nhat Nguyen, Pradyumna Shyama Prasad

+ [LIMOPro: Reasoning Refinement for Efficient and Effective Test-time Scaling](https://arxiv.org//abs/2505.19187)

	Yang Xiao, Jiashuo Wang, Ruifeng Yuan, Chunpu Xu, Kaishuai Xu, Wenjie Li, Pengfei Liu

+ [MOOSE-Chem2: Exploring LLM Limits in Fine-Grained Scientific Hypothesis Discovery via Hierarchical Search](https://arxiv.org//abs/2505.19209)

	Zonglin Yang, Wanhao Liu, Ben Gao, Yujie Liu, Wei Li, Tong Xie, Lidong Bing, Wanli Ouyang, Erik Cambria, Dongzhan Zhou

+ [When Ethics and Payoffs Diverge: LLM Agents in Morally Charged Social Dilemmas](https://arxiv.org//abs/2505.19212)

	Steffen Backmann, David Guzman Piedrahita, Emanuel Tewolde, Rada Mihalcea, Bernhard Schölkopf, Zhijing Jin

+ [LLLMs: A Data-Driven Survey of Evolving Research on Limitations of Large Language Models](https://arxiv.org//abs/2505.19240)

	Aida Kostikova, Zhipin Wang, Deidamea Bajri, Ole Pütz, Benjamin Paaßen, Steffen Eger

+ [ActiveDPO: Active Direct Preference Optimization for Sample-Efficient Alignment](https://arxiv.org//abs/2505.19241)

	Xiaoqiang Lin, Arun Verma, Zhongxiang Dai, Daniela Rus, See-Kiong Ng, Bryan Kian Hsiang Low

+ [To CoT or To Loop? A Formal Comparison Between Chain-of-Thought and Looped Transformers](https://arxiv.org//abs/2505.19245)

	Kevin Xu, Issei Sato

+ [VTool-R1: VLMs Learn to Think with Images via Reinforcement Learning on Multimodal Tool Use](https://arxiv.org//abs/2505.19255)

	Mingyuan Wu, Jingcheng Yang, Jize Jiang, Meitang Li, Kaizhuo Yan, Hanchao Yu, Minjia Zhang, Chengxiang Zhai, Klara Nahrstedt

+ [Towards Large Reasoning Models for Agriculture](https://arxiv.org//abs/2505.19259)

	Hossein Zaremehrjerdi, Shreyan Ganguly, Ashlyn Rairdin, Elizabeth Tranel, Benjamin Feuer, Juan Ignacio Di Salvo, Srikanth Panthulugiri, Victoria Moser, Sarah Jones, Joscif G Raigne, Yanben Shen, Heidi M. Dornath, Aditya Balu, Adarsh Krishnamurthy, Asheesh K Singh, Arti Singh, Baskar Ganapathysubramanian, Chinmay Hegde, Soumik Sarkar

+ [100-LongBench: Are de facto Long-Context Benchmarks Literally Evaluating Long-Context Ability?](https://arxiv.org//abs/2505.19293)

	Wang Yang, Hongye Jin, Shaochen Zhong, Song Jiang, Qifan Wang, Vipin Chaudhary, Xiaotian Han

+ [A Necessary Step toward Faithfulness: Measuring and Improving Consistency in Free-Text Explanations](https://arxiv.org//abs/2505.19299)

	Lingjun Zhao, Hal Daumé III

+ [Retrieval-Augmented Generation for Service Discovery: Chunking Strategies and Benchmarking](https://arxiv.org//abs/2505.19310)

	Robin D. Pesl, Jerin G. Mathew, Massimo Mecella, Marco Aiello

+ [PatentScore: Multi-dimensional Evaluation of LLM-Generated Patent Claims](https://arxiv.org//abs/2505.19345)

	Yongmin Yoo, Qiongkai Xu, Longbing Cao

+ [System-1.5 Reasoning: Traversal in Language and Latent Spaces with Dynamic Shortcuts](https://arxiv.org//abs/2505.18962)

	Xiaoqiang Wang, Suyuchen Wang, Yun Zhu, Bang Liu

+ [Learning to Explain: Prototype-Based Surrogate Models for LLM Classification](https://arxiv.org//abs/2505.18970)

	Bowen Wei, Ziwei Zhu

+ [VerIPO: Cultivating Long Reasoning in Video-LLMs via Verifier-Gudied Iterative Policy Optimization](https://arxiv.org//abs/2505.19000)

	Yunxin Li, Xinyu Chen, Zitao Li, Zhenyu Liu, Longyue Wang, Wenhan Luo, Baotian Hu, Min Zhang

+ [Efficient Data Selection at Scale via Influence Distillation](https://arxiv.org//abs/2505.19051)

	Mahdi Nikdan, Vincent Cohen-Addad, Dan Alistarh, Vahab Mirrokni

+ [UNCERTAINTY-LINE: Length-Invariant Estimation of Uncertainty for Large Language Models](https://arxiv.org//abs/2505.19060)

	Roman Vashurin, Maiya Goloburda, Preslav Nakov, Maxim Panov

+ [Towards Harmonized Uncertainty Estimation for Large Language Models](https://arxiv.org//abs/2505.19073)

	Rui Li, Jing Long, Muge Qi, Heming Xia, Lei Sha, Peiyi Wang, Zhifang Sui

+ [Self-Critique Guided Iterative Reasoning for Multi-hop Question Answering](https://arxiv.org//abs/2505.19112)

	Zheng Chu, Huiming Fan, Jingchang Chen, Qianyu Wang, Mingda Yang, Jiafeng Liang, Zhongjie Wang, Hao Li, Guo Tang, Ming Liu, Bing Qin

+ [Controlling Language Confusion in Multilingual LLMs](https://arxiv.org//abs/2505.19116)

	Nahyun Lee, Yeongseo Woo, Hyunwoo Ko, Guijin Son

+ [Delving into Multilingual Ethical Bias: The MSQAD with Statistical Hypothesis Tests for Large Language Models](https://arxiv.org//abs/2505.19121)

	Seunguk Yu, Juhwan Choi, Youngbin Kim

+ [Assistant-Guided Mitigation of Teacher Preference Bias in LLM-as-a-Judge](https://arxiv.org//abs/2505.19176)

	Zhuo Liu, Moxin Li, Xun Deng, Qifan Wang, Fuli Feng

+ [DREAM: Drafting with Refined Target Features and Entropy-Adaptive Cross-Attention Fusion for Multimodal Speculative Decoding](https://arxiv.org//abs/2505.19201)

	Yunhai Hu, Tianhua Xia, Zining Liu, Rahul Raman, Xingyu Liu, Bo Bao, Eric Sather, Vithursan Thangarasa, Sai Qian Zhang

+ [The Overthinker's DIET: Cutting Token Calories with DIfficulty-AwarE Training](https://arxiv.org//abs/2505.19217)

	Weize Chen, Jiarui Yuan, Tailin Jin, Ning Ding, Huimin Chen, Zhiyuan Liu, Maosong Sun

+ [PATS: Process-Level Adaptive Thinking Mode Switching](https://arxiv.org//abs/2505.19250)

	Yi Wang, Junxiao Liu, Shimao Zhang, Jiajun Chen, Shujian Huang

+ [A Graph Perspective to Probe Structural Patterns of Knowledge in Large Language Models](https://arxiv.org//abs/2505.19286)

	Utkarsh Sahu, Zhisheng Qi, Yongjia Lei, Ryan A. Rossi, Franck Dernoncourt, Nesreen K. Ahmed, Mahantesh M Halappanavar, Yao Ma, Yu Wang

+ [SituatedThinker: Grounding LLM Reasoning with Real-World through Situated Thinking](https://arxiv.org//abs/2505.19300)

	Junnan Liu, Linhao Luo, Thuy-Trang Vu, Gholamreza Haffari

+ [GC-KBVQA: A New Four-Stage Framework for Enhancing Knowledge Based Visual Question Answering Performance](https://arxiv.org//abs/2505.19354)

	Mohammad Mahdi Moradi, Sudhir Mudur

+ [Speech-IFEval: Evaluating Instruction-Following and Quantifying Catastrophic Forgetting in Speech-Aware Language Models](https://arxiv.org//abs/2505.19037)

	Ke-Han Lu, Chun-Yi Kuan, Hung-yi Lee

+ [Sparse-to-Dense: A Free Lunch for Lossless Acceleration of Video Understanding in LLMs](https://arxiv.org//abs/2505.19155)

	Xuan Zhang, Cunxiao Du, Sicheng Yu, Jiawei Wu, Fengzhuo Zhang, Wei Gao, Qian Liu

+ [ChartSketcher: Reasoning with Multimodal Feedback and Reflection for Chart Understanding](https://arxiv.org//abs/2505.19076)

	Muye Huang, Lingling Zhang, Jie Ma, Han Lai, Fangzhi Xu, Yifei Li, Wenjun Wu, Yaqiang Wu, Jun Liu

+ [The Eye of Sherlock Holmes: Uncovering User Private Attribute Profiling via Vision-Language Model Agentic Framework](https://arxiv.org//abs/2505.19139)

	Feiran Liu, Yuzhe Zhang, Xinyi Huang, Yinan Peng, Xinfeng Li, Lixu Wang, Yutong Shen, Ranjie Duan, Simeng Qin, Xiaojun Jia, Qingsong Wen, Wei Dong

+ [MIND-Edit: MLLM Insight-Driven Editing via Language-Vision Projection](https://arxiv.org//abs/2505.19149)

	Shuyu Wang, Weiqi Li, Qian Wang, Shijie Zhao, Jian Zhang

+ [Exact Expressive Power of Transformers with Padding](https://arxiv.org//abs/2505.18948)

	William Merrill, Ashish Sabharwal

+ [Online Knowledge Distillation with Reward Guidance](https://arxiv.org//abs/2505.18952)

	Chen Jia

+ [GhostPrompt: Jailbreaking Text-to-image Generative Models based on Dynamic Optimization](https://arxiv.org//abs/2505.18979)

	Zixuan Chen, Hao Lin, Ke Xu, Xinghao Jiang, Tanfeng Sun

+ [Optimization-Inspired Few-Shot Adaptation for Large Language Models](https://arxiv.org//abs/2505.19107)

	Boyan Gao, Xin Wang, Yibo Yang, David Clifton

+ [LLaDA 1.5: Variance-Reduced Preference Optimization for Large Language Diffusion Models](https://arxiv.org//abs/2505.19223)

	Fengqi Zhu, Rongzhen Wang, Shen Nie, Xiaolu Zhang, Chunwei Wu, Jun Hu, Jun Zhou, Jianfei Chen, Yankai Lin, Ji-Rong Wen, Chongxuan Li

+ [Hypercube-RAG: Hypercube-Based Retrieval-Augmented Generation for In-domain Scientific Question-Answering](https://arxiv.org//abs/2505.19288)

	Jimeng Shi, Sizhe Zhou, Bowen Jin, Wei Hu, Shaowen Wang, Giri Narasimhan, Jiawei Han

+ [Paying Alignment Tax with Contrastive Learning](https://arxiv.org//abs/2505.19327)

	Buse Sibel Korkmaz, Rahul Nair, Elizabeth M. Daly, Antonio del Rio Chanona

+ [Likert or Not: LLM Absolute Relevance Judgments on Fine-Grained Ordinal Scales](https://arxiv.org//abs/2505.19334)

	Charles Godfrey, Ping Nie, Natalia Ostapuk, David Ken, Shang Gao, Souheil Inati

+ [ALRPHFS: Adversarially Learned Risk Patterns with Hierarchical Fast \& Slow Reasoning for Robust Agent Defense](https://arxiv.org//abs/2505.19260)

	Shiyu Xiang, Tong Zhang, Ronghao Chen

+ [RADEP: A Resilient Adaptive Defense Framework Against Model Extraction Attacks](https://arxiv.org//abs/2505.19364)

	Amit Chakraborty, Sayyed Farid Ahamed, Sandip Roy, Soumya Banerjee, Kevin Choi, Abdul Rahman, Alison Hu, Edward Bowen, Sachin Shetty

+ [SeRL: Self-Play Reinforcement Learning for Large Language Models with Limited Data](https://arxiv.org//abs/2505.20347)

	Wenkai Fang, Shunyu Liu, Yang Zhou, Kongcheng Zhang, Tongya Zheng, Kaixuan Chen, Mingli Song, Dacheng Tao

+ [Fluent but Culturally Distant: Can Regional Training Teach Cultural Understanding?](https://arxiv.org//abs/2505.21548)

	Dhruv Agarwal, Anya Shukla, Sunayana Sitaram, Aditya Vashistha

+ [Nine Ways to Break Copyright Law and Why Our LLM Won't: A Fair Use Aligned Generation Framework](https://arxiv.org//abs/2505.23788)

	Aakash Sen Sharma, Debdeep Sanyal, Priyansh Srivastava, Sundar Atreya H., Shirish Karande, Mohan Kankanhalli, Murari Mandal

+ [Rethinking the Understanding Ability across LLMs through Mutual Information](https://arxiv.org//abs/2505.23790)

	Shaojie Wang, Sirui Ding, Na Zou

# 2025-05-24
+ [Pedagogy-R1: Pedagogically-Aligned Reasoning Model with Balanced Educational Benchmark](https://arxiv.org//abs/2505.18467)

	Unggi Lee, Jaeyong Lee, Jiyeong Bae, Yeil Jeong, Junbo Koh, Gyeonggeon Lee, Gunho Lee, Taekyung Ahn, Hyeoncheol Kim

+ [Retrieval Augmented Decision-Making: A Requirements-Driven, Multi-Criteria Framework for Structured Decision Support](https://arxiv.org//abs/2505.18483)

	Hongjia Wu, Hongxin Zhang, Wei Chen, Jiazhi Xia

+ [Knowledge Grafting of Large Language Models](https://arxiv.org//abs/2505.18502)

	Guodong Du, Xuanning Zhou, Junlin Li, Zhuo Li, Zesheng Shi, Wanyu Lin, Ho-Kin Tang, Xiucheng Li, Fangming Liu, Wenya Wang, Min Zhang, Jing Li

+ [Generative RLHF-V: Learning Principles from Multi-modal Human Preference](https://arxiv.org//abs/2505.18531)

	Jiayi Zhou, Jiaming Ji, Boyuan Chen, Jiapeng Sun, Wenqi Chen, Donghai Hong, Sirui Han, Yike Guo, Yaodong Yang

+ [RoleRAG: Enhancing LLM Role-Playing via Graph Guided Retrieval](https://arxiv.org//abs/2505.18541)

	Yongjie Wang, Jonathan Leung, Zhiqi Shen

+ [Response Uncertainty and Probe Modeling: Two Sides of the Same Coin in LLM Interpretability?](https://arxiv.org//abs/2505.18575)

	Yongjie Wang, Yibo Wang, Xin Zhou, Zhiqi Shen

+ [RvLLM: LLM Runtime Verification with Domain Knowledge](https://arxiv.org//abs/2505.18585)

	Yedi Zhang, Sun Yi Emma, Annabelle Lee Jia En, Annabelle Lee Jia En, Jin Song Dong

+ [LLMs for Supply Chain Management](https://arxiv.org//abs/2505.18597)

	Haojie Wang, Jiuyun Jiang, L. Jeff Hong, Guangxin Jiang

+ [Doc-CoB: Enhancing Multi-Modal Document Understanding with Visual Chain-of-Boxes Reasoning](https://arxiv.org//abs/2505.18603)

	Ye Mo, Zirui Shao, Kai Ye, Xianwei Mao, Bo Zhang, Hangdi Xing, Peng Ye, Gang Huang, Kehan Chen, Zhou Huan, Zixu Yan, Sheng Zhou

+ [Knowledge Retrieval in LLM Gaming: A Shift from Entity-Centric to Goal-Oriented Graphs](https://arxiv.org//abs/2505.18607)

	Jonathan Leung, Yongjie Wang, Zhiqi Shen

+ [MLLMs are Deeply Affected by Modality Bias](https://arxiv.org//abs/2505.18657)

	Xu Zheng, Chenfei Liao, Yuqian Fu, Kaiyu Lei, Yuanhuiyi Lyu, Lutao Jiang, Bin Ren, Jialei Chen, Jiawen Wang, Chengxin Li, Linfeng Zhang, Danda Pani Paudel, Xuanjing Huang, Yu-Gang Jiang, Nicu Sebe, Dacheng Tao, Luc Van Gool, Xuming Hu

+ [AI-Researcher: Autonomous Scientific Innovation](https://arxiv.org//abs/2505.18705)

	Jiabin Tang, Lianghao Xia, Zhonghang Li, Chao Huang

+ [$C^3$-Bench: The Things Real Disturbing LLM based Agent in Multi-Tasking](https://arxiv.org//abs/2505.18746)

	Peijie Yu, Yifan Yang, Jinjian Li, Zelong Zhang, Haorui Wang, Xiao Feng, Feng Zhang

+ [The Quest for Efficient Reasoning: A Data-Centric Benchmark to CoT Distillation](https://arxiv.org//abs/2505.18759)

	Ruichen Zhang, Rana Muhammad Shahroz Khan, Zhen Tan, Dawei Li, Song Wang, Tianlong Chen

+ [Mitigating Deceptive Alignment via Self-Monitoring](https://arxiv.org//abs/2505.18807)

	Jiaming Ji, Wenqi Chen, Kaile Wang, Donghai Hong, Sitong Fang, Boyuan Chen, Jiayi Zhou, Juntao Dai, Sirui Han, Yike Guo, Yaodong Yang

+ [AdaCtrl: Towards Adaptive and Controllable Reasoning via Difficulty-Aware Budgeting](https://arxiv.org//abs/2505.18822)

	Shijue Huang, Hongru Wang, Wanjun Zhong, Zhaochen Su, Jiazhan Feng, Bowen Cao, Yi R. Fung

+ [LiteCUA: Computer as MCP Server for Computer-Use Agent on AIOS](https://arxiv.org//abs/2505.18829)

	Kai Mei, Xi Zhu, Hang Gao, Shuhang Lin, Yongfeng Zhang

+ [Efficient Long CoT Reasoning in Small Language Models](https://arxiv.org//abs/2505.18440)

	Zhaoyang Wang, Jinqi Jiang, Tian Qiu, Hui Liu, Xianfeng Tang, Huaxiu Yao

+ [$μ$-MoE: Test-Time Pruning as Micro-Grained Mixture-of-Experts](https://arxiv.org//abs/2505.18451)

	Toshiaki Koike-Akino, Jing Liu, Ye Wang

+ [A Survey of LLM $\times$ DATA](https://arxiv.org//abs/2505.18458)

	Xuanhe Zhou, Junxuan He, Wei Zhou, Haodong Chen, Zirui Tang, Haoyu Zhao, Xin Tong, Guoliang Li, Youmin Chen, Jun Zhou, Zhaojun Sun, Binyuan Hui, Shuo Wang, Conghui He, Zhiyuan Liu, Jingren Zhou, Fan Wu

+ [From Reddit to Generative AI: Evaluating Large Language Models for Anxiety Support Fine-tuned on Social Media Data](https://arxiv.org//abs/2505.18464)

	Ugur Kursuncu, Trilok Padhi, Gaurav Sinha, Abdulkadir Erol, Jaya Krishna Mandivarapu, Christopher R. Larrison

+ [Invisible Tokens, Visible Bills: The Urgent Need to Audit Hidden Operations in Opaque LLM Services](https://arxiv.org//abs/2505.18471)

	Guoheng Sun, Ziyao Wang, Xuandong Zhao, Bowei Tian, Zheyu Shen, Yexiao He, Jinming Xing, Ang Li

+ [Synthesizing and Adapting Error Correction Data for Mobile Large Language Model Applications](https://arxiv.org//abs/2505.18488)

	Yanxiang Zhang, Zheng Xu, Shanshan Wu, Yuanbo Zhang, Daniel Ramage

+ [G1: Teaching LLMs to Reason on Graphs with Reinforcement Learning](https://arxiv.org//abs/2505.18499)

	Xiaojun Guo, Ang Li, Yifei Wang, Stefanie Jegelka, Yisen Wang

+ [AcuRank: Uncertainty-Aware Adaptive Computation for Listwise Reranking](https://arxiv.org//abs/2505.18512)

	Soyoung Yoon, Gyuwan Kim, Gyu-Hwung Cho, Seung-won Hwang

+ [Test-Time Adaptation with Binary Feedback](https://arxiv.org//abs/2505.18514)

	Taeckyung Lee, Sorn Chottananurak, Junsu Kim, Jinwoo Shin, Taesik Gong, Sung-Ju Lee

+ [MRGAgents: A Multi-Agent Framework for Improved Medical Report Generation with Med-LVLMs](https://arxiv.org//abs/2505.18530)

	Pengyu Wang, Shuchang Ye, Usman Naseem, Jinman Kim

+ [Reinforcement Fine-Tuning Powers Reasoning Capability of Multimodal Large Language Models](https://arxiv.org//abs/2505.18536)

	Haoyuan Sun, Jiaqi Wu, Bo Xia, Yifu Luo, Yifei Zhao, Kai Qin, Xufei Lv, Tiantian Zhang, Yongzhe Chang, Xueqian Wang

+ [Exploring the Vulnerability of the Content Moderation Guardrail in Large Language Models via Intent Manipulation](https://arxiv.org//abs/2505.18556)

	Jun Zhuang, Haibo Jin, Ye Zhang, Zhengjian Kang, Wenbin Zhang, Gaby G. Dagher, Haohan Wang

+ [From Word to World: Evaluate and Mitigate Culture Bias via Word Association Test](https://arxiv.org//abs/2505.18562)

	Xunlian Dai, Li Zhou, Benyou Wang, Haizhou Li

+ [MASTER: Multi-Agent Security Through Exploration of Roles and Topological Structures -- A Comprehensive Framework](https://arxiv.org//abs/2505.18572)

	Yifan Zhu, Chao Zhang, Xin Shi, Xueqiao Zhang, Yi Yang, Yawei Luo

+ [Removal of Hallucination on Hallucination: Debate-Augmented RAG](https://arxiv.org//abs/2505.18581)

	Wentao Hu, Wengyu Zhang, Yiyang Jiang, Chen Jason Zhang, Xiaoyong Wei, Qing Li

+ [Safety Alignment via Constrained Knowledge Unlearning](https://arxiv.org//abs/2505.18588)

	Zesheng Shi, Yucheng Zhou, Jing Li

+ [Debate-to-Detect: Reformulating Misinformation Detection as a Real-World Debate with Large Language Models](https://arxiv.org//abs/2505.18596)

	Chen Han, Wenzhen Zheng, Xijin Tang

+ [Flex-Judge: Think Once, Judge Anywhere](https://arxiv.org//abs/2505.18601)

	Jongwoo Ko, Sungnyun Kim, Sungwoo Cho, Se-Young Yun

+ [DDO: Dual-Decision Optimization via Multi-Agent Collaboration for LLM-Based Medical Consultation](https://arxiv.org//abs/2505.18630)

	Zhihao Jia, Mingyi Jia, Junwen Duan, Jianxin Wang

+ [ThanoRA: Task Heterogeneity-Aware Multi-Task Low-Rank Adaptation](https://arxiv.org//abs/2505.18640)

	Jian Liang, Wenke Huang, Xianda Guo, Guancheng Wan, Bo Du, Mang Ye

+ [SEW: Self-Evolving Agentic Workflows for Automated Code Generation](https://arxiv.org//abs/2505.18646)

	Siwei Liu, Jinyuan Fang, Han Zhou, Yingxu Wang, Zaiqiao Meng

+ [Robustness in Large Language Models: A Survey of Mitigation Strategies and Evaluation Metrics](https://arxiv.org//abs/2505.18658)

	Pankaj Kumar, Subhankar Mishra

+ [Adaptive Prediction-Powered AutoEval with Reliability and Efficiency Guarantees](https://arxiv.org//abs/2505.18659)

	Sangwoo Park, Matteo Zecchin, Osvaldo Simeone

+ [Large Language Models in the Task of Automatic Validation of Text Classifier Predictions](https://arxiv.org//abs/2505.18688)

	Aleksandr Tsymbalov

+ [Can LLMs Alleviate Catastrophic Forgetting in Graph Continual Learning? A Systematic Study](https://arxiv.org//abs/2505.18697)

	Ziyang Cheng, Zhixun Li, Yuhan Li, Yixin Song, Kangyi Zhao, Dawei Cheng, Jia Li, Jeffrey Xu Yu

+ [Steering LLM Reasoning Through Bias-Only Adaptation](https://arxiv.org//abs/2505.18706)

	Viacheslav Sinii, Alexey Gorbatovski, Artem Cherepanov, Boris Shaposhnikov, Nikita Balagansky, Daniil Gavrilov

+ [GainRAG: Preference Alignment in Retrieval-Augmented Generation through Gain Signal Synthesis](https://arxiv.org//abs/2505.18710)

	Yi Jiang, Sendong Zhao, Jianbo Li, Haochun Wang, Bing Qin

+ [Optimal Transport-Based Token Weighting scheme for Enhanced Preference Optimization](https://arxiv.org//abs/2505.18720)

	Meng Li, Guangda Huzhang, Haibo Zhang, Xiting Wang, Anxiang Zeng

+ [LoTA-QAF: Lossless Ternary Adaptation for Quantization-Aware Fine-Tuning](https://arxiv.org//abs/2505.18724)

	Junyu Chen, Junzhuo Li, Zhen Peng, Wenjie Wang, Yuxiang Ren, Long Shi, Xuming Hu

+ [How Is LLM Reasoning Distracted by Irrelevant Context? An Analysis Using a Controlled Benchmark](https://arxiv.org//abs/2505.18761)

	Minglai Yang, Ethan Huang, Liang Zhang, Mihai Surdeanu, William Wang, Liangming Pan

+ [Strong Membership Inference Attacks on Massive Datasets and (Moderately) Large Language Models](https://arxiv.org//abs/2505.18773)

	Jamie Hayes, Ilia Shumailov, Christopher A. Choquette-Choo, Matthew Jagielski, George Kaissis, Katherine Lee, Milad Nasr, Sahra Ghalebikesabi, Niloofar Mireshghallah, Meenatchi Sundaram Mutu Selva Annamalai, Igor Shilov, Matthieu Meeus, Yves-Alexandre de Montjoye, Franziska Boenisch, Adam Dziedzic, A. Feder Cooper

+ [HD-PiSSA: High-Rank Distributed Orthogonal Adaptation](https://arxiv.org//abs/2505.18777)

	Yiding Wang, Fauxu meng, Xuefeng Zhang, Fan Jiang, Pingzhi Tang, Muhan Zhang

+ [ALPS: Attention Localization and Pruning Strategy for Efficient Alignment of Large Language Models](https://arxiv.org//abs/2505.18799)

	Hao Chen, Haoze Li, Zhiqing Xiao, Lirong Gao, Qi Zhang, Xiaomeng Hu, Ningtao Wang, Xing Fu, Junbo Zhao

+ [CRMArena-Pro: Holistic Assessment of LLM Agents Across Diverse Business Scenarios and Interactions](https://arxiv.org//abs/2505.18878)

	Kung-Hsiang Huang, Akshara Prabhakar, Onkar Thorat, Divyansh Agarwal, Prafulla Kumar Choubey, Yixin Mao, Silvio Savarese, Caiming Xiong, Chien-Sheng Wu

+ [Security Concerns for Large Language Models: A Survey](https://arxiv.org//abs/2505.18889)

	Miles Q. Li, Benjamin C. M. Fung

+ [PromptWise: Online Learning for Cost-Aware Prompt Assignment in Generative Models](https://arxiv.org//abs/2505.18901)

	Xiaoyan Hu, Lauren Pick, Ho-fung Leung, Farzan Farnia

+ [BRIT: Bidirectional Retrieval over Unified Image-Text Graph](https://arxiv.org//abs/2505.18450)

	Ainulla Khan, Yamada Moyuru, Srinidhi Akella

+ [MedScore: Factuality Evaluation of Free-Form Medical Answers](https://arxiv.org//abs/2505.18452)

	Heyuan Huang, Alexandra DeLucia, Vijay Murari Tiyyala, Mark Dredze

+ [Hybrid Latent Reasoning via Reinforcement Learning](https://arxiv.org//abs/2505.18454)

	Zhenrui Yue, Bowen Jin, Huimin Zeng, Honglei Zhuang, Zhen Qin, Jinsung Yoon, Lanyu Shang, Jiawei Han, Dong Wang

+ [Measuring South Asian Biases in Large Language Models](https://arxiv.org//abs/2505.18466)

	Mamnuya Rinki, Chahat Raj, Anjishnu Mukherjee, Ziwei Zhu

+ [The Pragmatic Mind of Machines: Tracing the Emergence of Pragmatic Competence in Large Language Models](https://arxiv.org//abs/2505.18497)

	Kefan Yu, Qingcheng Zeng, Weihao Xuan, Wanxin Li, Jingyi Wu, Rob Voigt

+ [How Does Sequence Modeling Architecture Influence Base Capabilities of Pre-trained Language Models? Exploring Key Architecture Design Principles to Avoid Base Capabilities Degradation](https://arxiv.org//abs/2505.18522)

	Xin Lu, Yanyan Zhao, Si Wei, Shijin Wang, Bing Qin, Ting Liu

+ [metaTextGrad: Automatically optimizing language model optimizers](https://arxiv.org//abs/2505.18524)

	Guowei Xu, Mert Yuksekgonul, Carlos Guestrin, James Zou

+ [Business as \textit{Rule}sual: A Benchmark and Framework for Business Rule Flow Modeling with LLMs](https://arxiv.org//abs/2505.18542)

	Chen Yang, Ruping Xu, Ruizhe Li, Bin Cao, Jing Fan

+ [MSA at BEA 2025 Shared Task: Disagreement-Aware Instruction Tuning for Multi-Dimensional Evaluation of LLMs as Math Tutors](https://arxiv.org//abs/2505.18549)

	Baraa Hikal, Mohamed Basem, Islam Oshallah, Ali Hamdi

+ [Unraveling Misinformation Propagation in LLM Reasoning](https://arxiv.org//abs/2505.18555)

	Yiyang Feng, Yichen Wang, Shaobo Cui, Boi Faltings, Mina Lee, Jiawei Zhou

+ [TAG-INSTRUCT: Controlled Instruction Complexity Enhancement through Structure-based Augmentation](https://arxiv.org//abs/2505.18557)

	He Zhu, Zhiwen Ruan, Junyou Su, Xingwei He, Wenjia Zhang, Yun Chen, Guanhua Chen

+ [PM-KVQ: Progressive Mixed-precision KV Cache Quantization for Long-CoT LLMs](https://arxiv.org//abs/2505.18610)

	Tengxuan Liu, Shiyao Li, Jiayi Yang, Tianchen Zhao, Feng Zhou, Xiaohui Song, Guohao Dai, Shengen Yan, Huazhong Yang, Yu Wang

+ [Skip-Thinking: Chunk-wise Chain-of-Thought Distillation Enable Smaller Language Models to Reason Better and Faster](https://arxiv.org//abs/2505.18642)

	Xiao Chen, Sihang Zhou, Ke Liang, Xiaoyu Sun, Xinwang Liu

+ [Cross-Lingual Pitfalls: Automatic Probing Cross-Lingual Weakness of Multilingual Large Language Models](https://arxiv.org//abs/2505.18673)

	Zixiang Xu, Yanbo Wang, Yue Huang, Xiuying Chen, Jieyu Zhao, Meng Jiang, Xiangliang Zhang

+ [Benchmarking and Rethinking Knowledge Editing for Large Language Models](https://arxiv.org//abs/2505.18690)

	Guoxiu He, Xin Song, Futing Wang, Aixin Sun

+ [Unifying Attention Heads and Task Vectors via Hidden State Geometry in In-Context Learning](https://arxiv.org//abs/2505.18752)

	Haolin Yang, Hakaze Cho, Yiqiao Zhong, Naoya Inoue

+ [Disentangling Knowledge Representations for Large Language Model Editing](https://arxiv.org//abs/2505.18774)

	Mengqi Zhang, Zisheng Zhou, Xiaotian Ye, Qiang Liu, Zhaochun Ren, Zhumin Chen, Pengjie Ren

+ [Don't Look Only Once: Towards Multimodal Interactive Reasoning with Selective Visual Revisitation](https://arxiv.org//abs/2505.18842)

	Jiwan Chung, Junhyeok Kim, Siyeol Kim, Jaeyoung Lee, Min Soo Kim, Youngjae Yu

+ [Multi-Party Conversational Agents: A Survey](https://arxiv.org//abs/2505.18845)

	Sagar Sapkota, Mohammad Saqib Hasan, Mubarak Shah, Santu Karmaker

+ [Audio Jailbreak Attacks: Exposing Vulnerabilities in SpeechGPT in a White-Box Framework](https://arxiv.org//abs/2505.18864)

	Binhao Ma, Hanqing Guo, Zhengping Jay Luo, Rui Duan

+ [Federated Retrieval-Augmented Generation: A Systematic Mapping Study](https://arxiv.org//abs/2505.18906)

	Abhijit Chakraborty, Chahana Dahal, Vivek Gupta

+ [B-score: Detecting biases in large language models using response history](https://arxiv.org//abs/2505.18545)

	An Vo, Mohammad Reza Taesiri, Daeyoung Kim, Anh Totti Nguyen

+ [Enhancing Efficiency and Exploration in Reinforcement Learning for LLMs](https://arxiv.org//abs/2505.18573)

	Mengqi Liao, Xiangyu Xi, Ruinian Chen, Jia Leng, Yangen Hu, Ke Zeng, Shuai Liu, Huaiyu Wan

+ [Enhancing Generalization of Speech Large Language Models with Multi-Task Behavior Imitation and Speech-Text Interleaving](https://arxiv.org//abs/2505.18644)

	Jingran Xie, Xiang Li, Hui Wang, Yue Yu, Yang Xiang, Xixin Wu, Zhiyong Wu

+ [$PD^3F$: A Pluggable and Dynamic DoS-Defense Framework Against Resource Consumption Attacks Targeting Large Language Models](https://arxiv.org//abs/2505.18680)

	Yuanhe Zhang, Xinyue Wang, Haoran Gao, Zhenhong Zhou, Fanyu Meng, Yuyao Zhang, Sen Su

+ [From Output to Evaluation: Does Raw Instruction-Tuned Code LLMs Output Suffice for Fill-in-the-Middle Code Generation?](https://arxiv.org//abs/2505.18789)

	Wasi Uddin Ahmad, Somshubra Majumdar, Boris Ginsburg

+ [On the Effect of Negative Gradient in Group Relative Deep Reinforcement Optimization](https://arxiv.org//abs/2505.18830)

	Wenlong Deng, Yi Ren, Muchen Li, Danica J. Sutherland, Xiaoxiao Li, Christos Thrampoulidis

+ [Focus on What Matters: Enhancing Medical Vision-Language Models with Automatic Attention Alignment Tuning](https://arxiv.org//abs/2505.18503)

	Aofei Chang, Le Huang, Alex James Boyd, Parminder Bhatia, Taha Kass-Hout, Cao Xiao, Fenglong Ma

+ [EvdCLIP: Improving Vision-Language Retrieval with Entity Visual Descriptions from Large Language Models](https://arxiv.org//abs/2505.18594)

	GuangHao Meng, Sunan He, Jinpeng Wang, Tao Dai, Letian Zhang, Jieming Zhu, Qing Li, Gang Wang, Rui Zhang, Yong Jiang

+ [ToDRE: Visual Token Pruning via Diversity and Task Awareness for Efficient Large Vision-Language Models](https://arxiv.org//abs/2505.18757)

	Duo Li, Zuhao Yang, Shijian Lu

+ [The Prompt is Mightier than the Example](https://arxiv.org//abs/2505.18485)

	Shengzhe Xu, Nikhil Muralidhar, Naren Ramakrishnan

+ [Enhancing Training Data Attribution with Representational Optimization](https://arxiv.org//abs/2505.18513)

	Weiwei Sun, Haokun Liu, Nikhil Kandpal, Colin Raffel, Yiming Yang

+ [Think Before You Accept: Semantic Reflective Verification for Faster Speculative Decoding](https://arxiv.org//abs/2505.18629)

	Yixuan Wang, Yijun Liu, Shiyu ji, Yuzhuang Xu, Yang Xu, Qingfu Zhu, Wanxiang Che

+ [LLM-QFL: Distilling Large Language Model for Quantum Federated Learning](https://arxiv.org//abs/2505.18656)

	Dev Gurung, Shiva Raj Pokhrel

+ [Does Representation Intervention Really Identify Desired Concepts and Elicit Alignment?](https://arxiv.org//abs/2505.18672)

	Hongzheng Yang, Yongqiang Chen, Zeyu Qin, Tongliang Liu, Chaowei Xiao, Kun Zhang, Bo Han

+ [MonarchAttention: Zero-Shot Conversion to Fast, Hardware-Aware Structured Attention](https://arxiv.org//abs/2505.18698)

	Can Yaras, Alec S. Xu, Pierre Abillama, Changwoo Lee, Laura Balzano

+ [AuroRA: Breaking Low-Rank Bottleneck of LoRA with Nonlinear Mapping](https://arxiv.org//abs/2505.18738)

	Haonan Dong, Wenhao Zhu, Guojie Song, Liang Wang

+ [KerZOO: Kernel Function Informed Zeroth-Order Optimization for Accurate and Accelerated LLM Fine-Tuning](https://arxiv.org//abs/2505.18886)

	Zhendong Mi, Qitao Tan, Xiaodong Yu, Zining Zhu, Geng Yuan, Shaoyi Huang

+ [On Minimax Estimation of Parameters in Softmax-Contaminated Mixture of Experts](https://arxiv.org//abs/2505.18455)

	Fanqi Yan, Huy Nguyen, Dung Le, Pedram Akbarian, Nhat Ho, Alessandro Rinaldo

+ [Benchmarking Poisoning Attacks against Retrieval-Augmented Generation](https://arxiv.org//abs/2505.18543)

	Baolei Zhang, Haoran Xin, Jiatong Li, Dongzhe Zhang, Minghong Fang, Zhuqing Liu, Lihai Nie, Zheli Liu

+ [Multi-Scale Manifold Alignment: A Unified Framework for Enhanced Explainability of Large Language Models](https://arxiv.org//abs/2505.20333)

	Yukun Zhang, Qi Dong

+ [Lookahead Q-Cache: Achieving More Consistent KV Cache Eviction via Pseudo Query](https://arxiv.org//abs/2505.20334)

	Yixuan Wang, Shiyu Ji, Yijun Liu, Yuzhuang Xu, Yang Xu, Qingfu Zhu, Wanxiang Che

+ [MOSLIM:Align with diverse preferences in prompts through reward classification](https://arxiv.org//abs/2505.20336)

	Yu Zhang, Wanli Jiang, Zhengyu Yang

+ [Dynamic Manifold Evolution Theory: Modeling and Stability Analysis of Latent Representations in Large Language Models](https://arxiv.org//abs/2505.20340)

	Yukun Zhang, Qi Dong

+ [Do LLMs have a Gender (Entropy) Bias?](https://arxiv.org//abs/2505.20343)

	Sonal Prabhune, Balaji Padmanabhan, Kaushik Dutta

+ [Image Tokens Matter: Mitigating Hallucination in Discrete Tokenizer-based Large Vision-Language Models via Latent Editing](https://arxiv.org//abs/2505.21547)

	Weixing Wang, Zifeng Ding, Jindong Gu, Rui Cao, Christoph Meinel, Gerard de Melo, Haojin Yang

+ [Vision Meets Language: A RAG-Augmented YOLOv8 Framework for Coffee Disease Diagnosis and Farmer Assistance](https://arxiv.org//abs/2505.21544)

	Semanto Mondal

+ [Comparing Human and AI Rater Effects Using the Many-Facet Rasch Model](https://arxiv.org//abs/2505.18486)

	Hong Jiao, Dan Song, Won-Chan Lee

+ [Mind the Gap: A Practical Attack on GGUF Quantization](https://arxiv.org//abs/2505.23786)

	Kazuki Egashira, Robin Staab, Mark Vero, Jingxuan He, Martin Vechev

+ [From Mathematical Reasoning to Code: Generalization of Process Reward Models in Test-Time Scaling](https://arxiv.org//abs/2506.00027)

	Zhengyu Chen, Yudong Wang, Teng Xiao, Ruochen Zhou, Xuesheng Yang, Wei Wang, Zhifang Sui, Jingang Wang

+ [BTC-LLM: Efficient Sub-1-Bit LLM Quantization via Learnable Transformation and Binary Codebook](https://arxiv.org//abs/2506.12040)

	Hao Gu, Lujun Li, Zheyu Wang, Bei Liu, Qiyuan Zhu, Sirui Han, Yike Guo

+ [Why Do Some Inputs Break Low-Bit LLM Quantization?](https://arxiv.org//abs/2506.12044)

	Ting-Yun Chang, Muru Zhang, Jesse Thomason, Robin Jia

# 2025-05-23
+ [Misaligning Reasoning with Answers -- A Framework for Assessing LLM CoT Robustness](https://arxiv.org//abs/2505.17406)

	Enyi Jiang, Changming Xu, Nischay Singh, Gagandeep Singh

+ [From Reasoning to Generalization: Knowledge-Augmented LLMs for ARC Benchmark](https://arxiv.org//abs/2505.17482)

	Chao Lei, Nir Lipovetzky, Krista A. Ehinger, Yanchuan Chang

+ [Probe by Gaming: A Game-based Benchmark for Assessing Conceptual Knowledge in LLMs](https://arxiv.org//abs/2505.17512)

	Shuhang Xu, Weijian Deng, Yixuan Zhou, Fangwei Zhong

+ [Optimizing Retrieval-Augmented Generation for Electrical Engineering: A Case Study on ABB Circuit Breakers](https://arxiv.org//abs/2505.17520)

	Salahuddin Alawadhi, Noorhan Abbas

+ [USTBench: Benchmarking and Dissecting Spatiotemporal Reasoning of LLMs as Urban Agents](https://arxiv.org//abs/2505.17572)

	Siqi Lai, Yansong Ning, Zirui Yuan, Zhixi Chen, Hao Liu

+ [Controlled Agentic Planning & Reasoning for Mechanism Synthesis](https://arxiv.org//abs/2505.17607)

	João Pedro Gandarela, Thiago Rios, Stefan Menzel, André Freitas

+ [Does Chain-of-Thought Reasoning Really Reduce Harmfulness from Jailbreaking?](https://arxiv.org//abs/2505.17650)

	Chengda Lu, Xiaoyu Fan, Yu Huang, Rongwu Xu, Jijie Li, Wei Xu

+ [GeoGramBench: Benchmarking the Geometric Program Reasoning in Modern LLMs](https://arxiv.org//abs/2505.17653)

	Shixian Luo, Zezhou Zhu, Yu Yuan, Yuncheng Yang, Lianlei Shan, Yong Wu

+ [Rethinking Agent Design: From Top-Down Workflows to Bottom-Up Skill Evolution](https://arxiv.org//abs/2505.17673)

	Jiawei Du, Jinlong Wu, Yuzheng Chen, Yucheng Hu, Bing Li, Joey Tianyi Zhou

+ [CIKT: A Collaborative and Iterative Knowledge Tracing Framework with Large Language Models](https://arxiv.org//abs/2505.17705)

	Runze Li, Siyu Wu, Jun Wang, Wei Zhang

+ [Automating Safety Enhancement for LLM-based Agents with Synthetic Risk Scenarios](https://arxiv.org//abs/2505.17735)

	Xueyang Zhou, Weidong Wang, Lin Lu, Jiawen Shi, Guiyao Tie, Yongtian Xu, Lixing Chen, Pan Zhou, Neil Zhenqiang Gong, Lichao Sun

+ [Integrating Counterfactual Simulations with Language Models for Explaining Multi-Agent Behaviour](https://arxiv.org//abs/2505.17801)

	Bálint Gyevnár, Christopher G. Lucas, Stefano V. Albrecht, Shay B. Cohen

+ [Evaluation Faking: Unveiling Observer Effects in Safety Evaluation of Frontier AI Systems](https://arxiv.org//abs/2505.17815)

	Yihe Fan, Wenqi Zhang, Xudong Pan, Min Yang

+ [Structured Thinking Matters: Improving LLMs Generalization in Causal Inference Tasks](https://arxiv.org//abs/2505.18034)

	Wentao Sun, Joao Paulo Nogueira, Alonso Silva

+ [ProgRM: Build Better GUI Agents with Progress Rewards](https://arxiv.org//abs/2505.18121)

	Danyang Zhang, Situo Zhang, Ziyue Yang, Zichen Zhu, Zihan Zhao, Ruisheng Cao, Lu Chen, Kai Yu

+ [Gaming Tool Preferences in Agentic LLMs](https://arxiv.org//abs/2505.18135)

	Kazem Faghih, Wenxiao Wang, Yize Cheng, Siddhant Bharti, Gaurang Sriramanan, Sriram Balasubramanian, Parsa Hosseini, Soheil Feizi

+ [Value-Guided Search for Efficient Chain-of-Thought Reasoning](https://arxiv.org//abs/2505.17373)

	Kaiwen Wang, Jin Peng Zhou, Jonathan Chang, Zhaolin Gao, Nathan Kallus, Kianté Brantley, Wen Sun

+ [Discovering Forbidden Topics in Language Models](https://arxiv.org//abs/2505.17441)

	Can Rager, Chris Wendler, Rohit Gandikota, David Bau

+ [SLearnLLM: A Self-Learning Framework for Efficient Domain-Specific Adaptation of Large Language Models](https://arxiv.org//abs/2505.17470)

	Xiang Liu, Zhaoxiang Liu, Peng Wang, Kohou Wang, Huan Hu, Kai Wang, Shiguo Lian

+ [keepitsimple at SemEval-2025 Task 3: LLM-Uncertainty based Approach for Multilingual Hallucination Span Detection](https://arxiv.org//abs/2505.17485)

	Saketh Reddy Vemula, Parameswari Krishnamurthy

+ [ProxySPEX: Inference-Efficient Interpretability via Sparse Feature Interactions in LLMs](https://arxiv.org//abs/2505.17495)

	Landon Butler, Abhineet Agarwal, Justin Singh Kang, Yigit Efe Erginbas, Bin Yu, Kannan Ramchandran

+ [Analyzing Mitigation Strategies for Catastrophic Forgetting in End-to-End Training of Spoken Language Models](https://arxiv.org//abs/2505.17496)

	Chi-Yuan Hsiao, Ke-Han Lu, Kai-Wei Chang, Chih-Kai Yang, Wei-Chih Chen, Hung-yi Lee

+ [On the Design of KL-Regularized Policy Gradient Algorithms for LLM Reasoning](https://arxiv.org//abs/2505.17508)

	Yifan Zhang, Yifeng Liu, Huizhuo Yuan, Yang Yuan, Quanquan Gu, Andrew C Yao

+ [Multi-agent Systems for Misinformation Lifecycle : Detection, Correction And Source Identification](https://arxiv.org//abs/2505.17511)

	Aditya Gautam

+ [Do You Keep an Eye on What I Ask? Mitigating Multimodal Hallucination via Attention-Guided Ensemble Decoding](https://arxiv.org//abs/2505.17529)

	Yeongjae Cho, Keonwoo Kim, Taebaek Hwang, Sungzoon Cho

+ [Teaching with Lies: Curriculum DPO on Synthetic Negatives for Hallucination Detection](https://arxiv.org//abs/2505.17558)

	Shrey Pandit, Ashwin Vinod, Liu Leqi, Ying Ding

+ [JALMBench: Benchmarking Jailbreak Vulnerabilities in Audio Language Models](https://arxiv.org//abs/2505.17568)

	Zifan Peng, Yule Liu, Zhen Sun, Mingchen Li, Zeren Luo, Jingyi Zheng, Wenhan Dong, Xinlei He, Xuechao Wang, Yingjie Xue, Shengmin Xu, Xinyi Huang

+ [Distilling LLM Agent into Small Models with Retrieval and Code Tools](https://arxiv.org//abs/2505.17612)

	Minki Kang, Jongwon Jeong, Seanie Lee, Jaewoong Cho, Sung Ju Hwang

+ [Runaway is Ashamed, But Helpful: On the Early-Exit Behavior of Large Language Model-based Agents in Embodied Environments](https://arxiv.org//abs/2505.17616)

	Qingyu Lu, Liang Ding, Siyi Cao, Xuebo Liu, Kanjian Zhang, Jinxia Zhang, Dacheng Tao

+ [Surfacing Semantic Orthogonality Across Model Safety Benchmarks: A Multi-Dimensional Analysis](https://arxiv.org//abs/2505.17636)

	Jonathan Bennion, Shaona Ghosh, Mantek Singh, Nouha Dziri

+ [Rethinking the Sampling Criteria in Reinforcement Learning for LLM Reasoning: A Competence-Difficulty Alignment Perspective](https://arxiv.org//abs/2505.17652)

	Deyang Kong, Qi Guo, Xiangyu Xi, Wei Wang, Jingang Wang, Xunliang Cai, Shikun Zhang, Wei Ye

+ [EVADE: Multimodal Benchmark for Evasive Content Detection in E-Commerce Applications](https://arxiv.org//abs/2505.17654)

	Ancheng Xu, Zhihao Yang, Jingpeng Li, Guanghu Yuan, Longze Chen, Liang Yan, Jiehui Zhou, Zhen Qin, Hengyun Chang, Hamid Alinejad-Rokny, Bo Zheng, Min Yang

+ [Towards General Continuous Memory for Vision-Language Models](https://arxiv.org//abs/2505.17670)

	Wenyi Wu, Zixuan Song, Kun Zhou, Yifei Shao, Zhiting Hu, Biwei Huang

+ [Tuning Language Models for Robust Prediction of Diverse User Behaviors](https://arxiv.org//abs/2505.17682)

	Fanjin Meng, Jingtao Ding, Jiahui Gong, Chen Yang, Hong Chen, Zuojian Wang, Haisheng Lu, Yong Li

+ [COUNTDOWN: Contextually Sparse Activation Filtering Out Unnecessary Weights in Down Projection](https://arxiv.org//abs/2505.17701)

	Jaewon Cheon, Pilsung Kang

+ [Slot-MLLM: Object-Centric Visual Tokenization for Multimodal LLM](https://arxiv.org//abs/2505.17726)

	Donghwan Chi, Hyomin Kim, Yoonjin Oh, Yongjin Kim, Donghoon Lee, Daejin Jo, Jongmin Kim, Junyeob Baek, Sungjin Ahn, Sungwoong Kim

+ [But what is your honest answer? Aiding LLM-judges with honest alternatives using steering vectors](https://arxiv.org//abs/2505.17760)

	Leon Eshuijs, Archie Chaudhury, Alan McBeth, Ethan Nguyen

+ [DialogXpert: Driving Intelligent and Emotion-Aware Conversations through Online Value-Based Reinforcement Learning with LLM Priors](https://arxiv.org//abs/2505.17795)

	Tazeek Bin Abdur Rakib, Ambuj Mehrish, Lay-Ki Soon, Wern Han Lim, Soujanya Poria

+ [Don't Overthink it. Preferring Shorter Thinking Chains for Improved LLM Reasoning](https://arxiv.org//abs/2505.17813)

	Michael Hassid, Gabriel Synnaeve, Yossi Adi, Roy Schwartz

+ [Scalable Valuation of Human Feedback through Provably Robust Model Alignment](https://arxiv.org//abs/2505.17859)

	Masahiro Fujisawa, Masaki Adachi, Michael A. Osborne

+ [Beyond Distillation: Pushing the Limits of Medical LLM Reasoning with Minimalist Rule-Based RL](https://arxiv.org//abs/2505.17952)

	Che Liu, Haozhe Wang, Jiazhen Pan, Zhongwei Wan, Yong Dai, Fangzhen Lin, Wenjia Bai, Daniel Rueckert, Rossella Arcucci

+ [SVD-Free Low-Rank Adaptive Gradient Optimization for Large Language Models](https://arxiv.org//abs/2505.17967)

	Ionut-Vlad Modoranu, Mher Safaryan, Erik Schultheis, Dan Alistarh

+ [Are Large Language Models Reliable AI Scientists? Assessing Reverse-Engineering of Black-Box Systems](https://arxiv.org//abs/2505.17968)

	Jiayi Geng, Howard Chen, Dilip Arumugam, Thomas L. Griffiths

+ [Generalized Fisher-Weighted SVD: Scalable Kronecker-Factored Fisher Approximation for Compressing Large Language Models](https://arxiv.org//abs/2505.17974)

	Viktoriia Chekalina, Daniil Moskovskiy, Daria Cherniuk, Maxim Kurkin, Andrey Kuznetsov, Evgeny Frolov

+ [Towards Revealing the Effectiveness of Small-Scale Fine-tuning in R1-style Reinforcement Learning](https://arxiv.org//abs/2505.17988)

	Yutong Chen, Jiandong Gao, Ji Wu

+ [An Example Safety Case for Safeguards Against Misuse](https://arxiv.org//abs/2505.18003)

	Joshua Clymer, Jonah Weinbaum, Robert Kirk, Kimberly Mai, Selena Zhang, Xander Davies

+ [Deep Video Discovery: Agentic Search with Tool Use for Long-form Video Understanding](https://arxiv.org//abs/2505.18079)

	Xiaoyi Zhang, Zhaoyang Jia, Zongyu Guo, Jiahao Li, Bin Li, Houqiang Li, Yan Lu

+ [Data Mixing Can Induce Phase Transitions in Knowledge Acquisition](https://arxiv.org//abs/2505.18091)

	Xinran Gu, Kaifeng Lyu, Jiazheng Li, Jingzhao Zhang

+ [Planning without Search: Refining Frontier LLMs with Offline Goal-Conditioned RL](https://arxiv.org//abs/2505.18098)

	Joey Hong, Anca Dragan, Sergey Levine

+ [How Can I Publish My LLM Benchmark Without Giving the True Answers Away?](https://arxiv.org//abs/2505.18102)

	Takashi Ishida, Thanawat Lodkaew, Ikko Yamane

+ [Reward Model Overoptimisation in Iterated RLHF](https://arxiv.org//abs/2505.18126)

	Lorenz Wolf, Robert Kirk, Mirco Musolesi

+ [Lost in the Haystack: Smaller Needles are More Difficult for LLMs to Find](https://arxiv.org//abs/2505.18148)

	Owen Bianchi, Mathew J. Koretsky, Maya Willey, Chelsea X. Alvarado, Tanay Nayak, Adi Asija, Nicole Kuznetsov, Mike A. Nalls, Faraz Faghri, Daniel Khashabi

+ [AI-Augmented LLMs Achieve Therapist-Level Responses in Motivational Interviewing](https://arxiv.org//abs/2505.17380)

	Yinghui Huang, Yuxuan Jiang, Hui Liu, Yixin Cai, Weiqing Li, Xiangen Hu

+ [WiNGPT-3.0 Technical Report](https://arxiv.org//abs/2505.17387)

	Boqin Zhuang, Chenxiao Song, Huitong Lu, Jiacheng Qiao, Mingqian Liu, Mingxing Yu, Ping Hong, Rui Li, Xiaoxia Song, Xiangjun Xu, Xu Chen, Yaoyao Ma, Yujie Gao

+ [Measuring diversity of synthetic prompts and data generated with fine-grained persona prompting](https://arxiv.org//abs/2505.17390)

	Gauri Kambhatla, Chantal Shaib, Venkata Govindarajan

+ [Curriculum Guided Reinforcement Learning for Efficient Multi Hop Retrieval Augmented Generation](https://arxiv.org//abs/2505.17391)

	Yuelyu Ji, Rui Meng, Zhuochun Li, Daqing He

+ [Language Matters: How Do Multilingual Input and Reasoning Paths Affect Large Reasoning Models?](https://arxiv.org//abs/2505.17407)

	Zhi Rui Tam, Cheng-Kuang Wu, Yu Ying Chiu, Chieh-Yen Lin, Yun-Nung Chen, Hung-yi Lee

+ [Conversations: Love Them, Hate Them, Steer Them](https://arxiv.org//abs/2505.17413)

	Niranjan Chebrolu, Gerard Christopher Yeo, Kokil Jaidka

+ [DASH: Input-Aware Dynamic Layer Skipping for Efficient LLM Inference with Markov Decision Policies](https://arxiv.org//abs/2505.17420)

	Ning Yang, Fangxin Liu, Junjie Wang, Tao Yang, Kan Liu, Haibing Guan, Li Jiang

+ [T$^2$: An Adaptive Test-Time Scaling Strategy for Contextual Question Answering](https://arxiv.org//abs/2505.17427)

	Zhengyi Zhao, Shubo Zhang, Zezhong Wang, Huimin Wang, Yutian Zhao, Bin Liang, Yefeng Zheng, Binyang Li, Kam-Fai Wong, Xian Wu

+ [LeTS: Learning to Think-and-Search via Process-and-Outcome Reward Hybridization](https://arxiv.org//abs/2505.17447)

	Qi Zhang, Shouqing Yang, Lirong Gao, Hao Chen, Xiaomeng Hu, Jinglei Chen, Jiexiang Wang, Sheng Guo, Bo Zheng, Haobo Wang, Junbo Zhao

+ [Hydra: Structured Cross-Source Enhanced Large Language Model Reasoning](https://arxiv.org//abs/2505.17464)

	Xingyu Tan, Xiaoyang Wang, Qing Liu, Xiwei Xu, Xin Yuan, Liming Zhu, Wenjie Zhang

+ [FinRAGBench-V: A Benchmark for Multimodal RAG with Visual Citation in the Financial Domain](https://arxiv.org//abs/2505.17471)

	Suifeng Zhao, Zhuoran Jin, Sujian Li, Jun Gao

+ [MARCO: Meta-Reflection with Cross-Referencing for Code Reasoning](https://arxiv.org//abs/2505.17481)

	Yusheng Zhao, Xiao Luo, Weizhi Zhang, Wei Ju, Zhiping Xiao, Philip S. Yu, Ming Zhang

+ [CReSt: A Comprehensive Benchmark for Retrieval-Augmented Generation with Complex Reasoning over Structured Documents](https://arxiv.org//abs/2505.17503)

	Minsoo Khang, Sangjun Park, Teakgyu Hong, Dawoon Jung

+ [L-MTP: Leap Multi-Token Prediction Beyond Adjacent Context for Large Language Models](https://arxiv.org//abs/2505.17505)

	Xiaohao Liu, Xiaobo Xia, Weixiang Zhao, Manyi Zhang, Xianzhi Yu, Xiu Su, Shuo Yang, See-Kiong Ng, Tat-Seng Chua

+ [Large Language Models Do Multi-Label Classification Differently](https://arxiv.org//abs/2505.17510)

	Marcus Ma, Georgios Chochlakis, Niyantha Maruthu Pandiyan, Jesse Thomason, Shrikanth Narayanan

+ [How Knowledge Popularity Influences and Enhances LLM Knowledge Boundary Perception](https://arxiv.org//abs/2505.17537)

	Shiyu Ni, Keping Bi, Jiafeng Guo, Xueqi Cheng

+ [Reasoning Meets Personalization: Unleashing the Potential of Large Reasoning Model for Personalized Generation](https://arxiv.org//abs/2505.17571)

	Sichun Luo, Guanzhi Deng, Jian Xu, Xiaojie Zhang, Hanxu Hou, Linqi Song

+ [Wolf Hidden in Sheep's Conversations: Toward Harmless Data-Based Backdoor Attacks for Jailbreaking Large Language Models](https://arxiv.org//abs/2505.17601)

	Jiawei Kong, Hao Fang, Xiaochen Yang, Kuofeng Gao, Bin Chen, Shu-Tao Xia, Yaowei Wang, Min Zhang

+ [Enhancing Large Vision-Language Models with Layout Modality for Table Question Answering on Japanese Annual Securities Reports](https://arxiv.org//abs/2505.17625)

	Hayato Aida, Kosuke Takahashi, Takahiro Omi

+ [GIM: Improved Interpretability for Large Language Models](https://arxiv.org//abs/2505.17630)

	Joakim Edin, Róbert Csordás, Tuukka Ruotsalo, Zhengxuan Wu, Maria Maistro, Jing Huang, Lars Maaløe

+ [Too Consistent to Detect: A Study of Self-Consistent Errors in LLMs](https://arxiv.org//abs/2505.17656)

	Hexiang Tan, Fei Sun, Sha Liu, Du Su, Qi Cao, Xin Chen, Jingang Wang, Xunliang Cai, Yuanzhuo Wang, Huawei Shen, Xueqi Cheng

+ [Towards Dynamic Theory of Mind: Evaluating LLM Adaptation to Temporal Evolution of Human States](https://arxiv.org//abs/2505.17663)

	Yang Xiao, Jiashuo Wang, Qiancheng Xu, Changhe Song, Chunpu Xu, Yi Cheng, Wenjie Li, Pengfei Liu

+ [QwenLong-L1: Towards Long-Context Large Reasoning Models with Reinforcement Learning](https://arxiv.org//abs/2505.17667)

	Fanqi Wan, Weizhou Shen, Shengyi Liao, Yingcheng Shi, Chenliang Li, Ziyi Yang, Ji Zhang, Fei Huang, Jingren Zhou, Ming Yan

+ [MIDB: Multilingual Instruction Data Booster for Enhancing Multilingual Instruction Synthesis](https://arxiv.org//abs/2505.17671)

	Yilun Liu, Chunguang Zhao, Xinhua Yang, Hongyong Zeng, Shimin Tao, Weibin Meng, Minggui He, Chang Su, Yan Yu, Hongxia Ma, Li Zhang, Daimeng Wei, Hao Yang

+ [ELSPR: Evaluator LLM Training Data Self-Purification on Non-Transitive Preferences via Tournament Graph Reconstruction](https://arxiv.org//abs/2505.17691)

	Yan Yu, Yilun Liu, Minggui He, Shimin Tao, Weibin Meng, Xinhua Yang, Li Zhang, Hongxia Ma, Chang Su, Hao Yang, Fuliang Li

+ [Activation Control for Efficiently Eliciting Long Chain-of-thought Ability of Language Models](https://arxiv.org//abs/2505.17697)

	Zekai Zhao, Qi Liu, Kun Zhou, Zihan Liu, Yifei Shao, Zhiting Hu, Biwei Huang

+ [Understanding How Value Neurons Shape the Generation of Specified Values in LLMs](https://arxiv.org//abs/2505.17712)

	Yi Su, Jiayi Zhang, Shu Yang, Xinhai Wang, Lijie Hu, Di Wang

+ [Fast Quiet-STaR: Thinking Without Thought Tokens](https://arxiv.org//abs/2505.17746)

	Wei Huang, Yizhe Xiong, Xin Ye, Zhijie Deng, Hui Chen, Zijia Lin, Guiguang Ding

+ [Discriminating Form and Meaning in Multilingual Models with Minimal-Pair ABX Tasks](https://arxiv.org//abs/2505.17747)

	Maureen de Seyssel, Jie Chi, Skyler Seto, Maartje ter Hoeve, Masha Fedzechkina, Natalie Schluter

+ [Resolving Conflicting Evidence in Automated Fact-Checking: A Study on Retrieval-Augmented LLMs](https://arxiv.org//abs/2505.17762)

	Ziyu Ge, Yuhao Wu, Daniel Wai Kit Chin, Roy Ka-Wei Lee, Rui Cao

+ [The Real Barrier to LLM Agent Usability is Agentic ROI](https://arxiv.org//abs/2505.17767)

	Weiwen Liu, Jiarui Qin, Xu Huang, Xingshan Zeng, Yunjia Xi, Jianghao Lin, Chuhan Wu, Yasheng Wang, Lifeng Shang, Ruiming Tang, Defu Lian, Yong Yu, Weinan Zhang

+ [EXECUTE: A Multilingual Benchmark for LLM Token Understanding](https://arxiv.org//abs/2505.17784)

	Lukas Edman, Helmut Schmid, Alexander Fraser

+ [Compression Hacking: A Supplementary Perspective on Informatics Metric of Language Models from Geometric Distortion](https://arxiv.org//abs/2505.17793)

	Jianxiang Zang, Meiling Ning, Yongda Wei, Shihan Dou, Jiazheng Zhang, Nijia Mo, Binhong Li, Tao Gui, Qi Zhang, Xuanjing Huang

+ [Not All Tokens Are What You Need In Thinking](https://arxiv.org//abs/2505.17827)

	Hang Yuan, Bin Yu, Haotian Li, Shijun Yang, Christina Dan Wang, Zhou Yu, Xueyin Xu, Weizhen Qi, Kai Chen

+ [Stepwise Reasoning Checkpoint Analysis: A Test Time Scaling Method to Enhance LLMs' Reasoning](https://arxiv.org//abs/2505.17829)

	Zezhong Wang, Xingshan Zeng, Weiwen Liu, Yufei Wang, Liangyou Li, Yasheng Wang, Lifeng Shang, Xin Jiang, Qun Liu, Kam-Fai Wong

+ [Explaining Sources of Uncertainty in Automated Fact-Checking](https://arxiv.org//abs/2505.17855)

	Jingyi Sun, Greta Warren, Irina Shklovski, Isabelle Augenstein

+ [Just as Humans Need Vaccines, So Do Models: Model Immunization to Combat Falsehoods](https://arxiv.org//abs/2505.17870)

	Shaina Raza, Rizwan Qureshi, Marcelo Lotif, Aman Chadha, Deval Pandya, Christos Emmanouilidis

+ [Language models can learn implicit multi-hop reasoning, but only if they have lots of training data](https://arxiv.org//abs/2505.17923)

	Yuekun Yao, Yupei Du, Dawei Zhu, Michael Hahn, Alexander Koller

+ [TRACE for Tracking the Emergence of Semantic Representations in Transformers](https://arxiv.org//abs/2505.17998)

	Nura Aljaafari, Danilo S. Carvalho, André Freitas

+ [Contrastive Distillation of Emotion Knowledge from LLMs for Zero-Shot Emotion Recognition](https://arxiv.org//abs/2505.18040)

	Minxue Niu, Emily Mower Provost

+ [MathEDU: Towards Adaptive Feedback for Student Mathematical Problem-Solving](https://arxiv.org//abs/2505.18056)

	Wei-Ling Hsu, Yu-Chien Tang, An-Zi Yen

+ [QwenLong-CPRS: Towards $\infty$-LLMs with Dynamic Context Optimization](https://arxiv.org//abs/2505.18092)

	Weizhou Shen, Chenliang Li, Fanqi Wan, Shengyi Liao, Shaopeng Lai, Bo Zhang, Yingcheng Shi, Yuning Wu, Gang Fu, Zhansheng Li, Bin Yang, Ji Zhang, Fei Huang, Jingren Zhou, Ming Yan

+ [ManuSearch: Democratizing Deep Search in Large Language Models with a Transparent and Open Multi-Agent Framework](https://arxiv.org//abs/2505.18105)

	Lisheng Huang, Yichen Liu, Jinhao Jiang, Rongxiang Zhang, Jiahao Yan, Junyi Li, Wayne Xin Zhao

+ [First Finish Search: Efficient Test-Time Scaling in Large Language Models](https://arxiv.org//abs/2505.18149)

	Aradhye Agarwal, Ayan Sengupta, Tanmoy Chakraborty

+ [The Staircase of Ethics: Probing LLM Value Priorities through Multi-Step Induction to Complex Moral Dilemmas](https://arxiv.org//abs/2505.18154)

	Ya Wu, Qiang Sheng, Danding Wang, Guang Yang, Yifan Sun, Zhengjia Wang, Yuyan Bu, Juan Cao

+ [LLM-based Generative Error Correction for Rare Words with Synthetic Data and Phonetic Context](https://arxiv.org//abs/2505.17410)

	Natsuo Yamashita, Masaaki Yamamoto, Hiroaki Kokubo, Yohei Kawaguchi

+ [Self-Training Large Language Models with Confident Reasoning](https://arxiv.org//abs/2505.17454)

	Hyosoon Jang, Yunhui Jang, Sungjae Lee, Jungseul Ok, Sungsoo Ahn

+ [Chain-of-Lure: A Synthetic Narrative-Driven Approach to Compromise Large Language Models](https://arxiv.org//abs/2505.17519)

	Wenhan Chang, Tianqing Zhu, Yu Zhao, Shuangyong Song, Ping Xiong, Wanlei Zhou, Yongxiang Li

+ [Co-Reinforcement Learning for Unified Multimodal Understanding and Generation](https://arxiv.org//abs/2505.17534)

	Jingjing Jiang, Chongjie Si, Jun Luo, Hanwang Zhang, Chao Ma

+ [CoMoE: Contrastive Representation for Mixture-of-Experts in Parameter-Efficient Fine-tuning](https://arxiv.org//abs/2505.17553)

	Jinyuan Feng, Chaopeng Wei, Tenghai Qiu, Tianyi Hu, Zhiqiang Pu

+ [One Model Transfer to All: On Robust Jailbreak Prompts Generation against LLMs](https://arxiv.org//abs/2505.17598)

	Linbao Li, Yannan Liu, Daojing He, Yu Li

+ [Trinity-RFT: A General-Purpose and Unified Framework for Reinforcement Fine-Tuning of Large Language Models](https://arxiv.org//abs/2505.17826)

	Xuchen Pan, Yanxi Chen, Yushuo Chen, Yuchang Sun, Daoyuan Chen, Wenhao Zhang, Yuexiang Xie, Yilun Huang, Yilei Zhang, Dawei Gao, Yaliang Li, Bolin Ding, Jingren Zhou

+ [Understanding Gated Neurons in Transformers from Their Input-Output Functionality](https://arxiv.org//abs/2505.17936)

	Sebastian Gerstner, Hinrich Schütze

+ [Towards Analyzing and Understanding the Limitations of VAPO: A Theoretical Perspective](https://arxiv.org//abs/2505.17997)

	Jintian Shao, Yiming Cheng, Hongyi Huang, Beiwen Zhang, Zhiyu Wu, You Shan, Mingkai Zheng

+ [Bridging Supervised Learning and Reinforcement Learning in Math Reasoning](https://arxiv.org//abs/2505.18116)

	Huayu Chen, Kaiwen Zheng, Qinsheng Zhang, Ganqu Cui, Yin Cui, Haotian Ye, Tsung-Yi Lin, Ming-Yu Liu, Jun Zhu, Haoxiang Wang

+ [VEAttack: Downstream-agnostic Vision Encoder Attack against Large Vision Language Models](https://arxiv.org//abs/2505.17440)

	Hefei Mei, Zirui Wang, Shen You, Minjing Dong, Chang Xu

+ [The Coherence Trap: When MLLM-Crafted Narratives Exploit Manipulated Visual Contexts](https://arxiv.org//abs/2505.17476)

	Yuchen Zhang, Yaxiong Wang, Yujiao Wu, Lianwei Wu, Li Zhu

+ [Enhancing Adversarial Robustness of Vision Language Models via Adversarial Mixture Prompt Tuning](https://arxiv.org//abs/2505.17509)

	Shiji Zhao, Qihui Zhu, Shukun Xiong, Shouwei Ruan, Yize Fan, Ranjie Duan, Qing Guo, Xingxing Wei

+ [Navigate the Unknown: Enhancing LLM Reasoning with Intrinsic Motivation Guided Exploration](https://arxiv.org//abs/2505.17621)

	Jingtong Gao, Ling Pan, Yejing Wang, Rui Zhong, Chi Lu, Qingpeng Cai, Peng Jiang, Xiangyu Zhao

+ [PreMoe: Lightening MoEs on Constrained Memory by Expert Pruning and Retrieval](https://arxiv.org//abs/2505.17639)

	Zehua Pei, Ying Zhang, Hui-Ling Zhen, Xianzhi Yu, Wulong Liu, Sinno Jialin Pan, Mingxuan Yuan, Bei Yu

+ [Understanding Pre-training and Fine-tuning from Loss Landscape Perspectives](https://arxiv.org//abs/2505.17646)

	Huanran Chen, Yinpeng Dong, Zeming Wei, Yao Huang, Yichi Zhang, Hang Su, Jun Zhu

+ [FlashForge: Ultra-Efficient Prefix-Aware Attention for LLM Decoding](https://arxiv.org//abs/2505.17694)

	Zhibin Wang, Rui Ning, Chao Fang, Zhonghui Zhang, Xi Lin, Shaobo Ma, Mo Zhou, Xue Li, Zhongfeng Wang, Chengying Huan, Rong Gu, Kun Yang, Guihai Chen, Sheng Zhong, Chen Tian

+ [Get Experience from Practice: LLM Agents with Record & Replay](https://arxiv.org//abs/2505.17716)

	Erhu Feng, Wenbo Zhou, Zibin Liu, Le Chen, Yunpeng Dong, Cheng Zhang, Yisheng Zhao, Dong Du, Zhichao Hua, Yubin Xia, Haibo Chen

+ [Inference-Time Decomposition of Activations (ITDA): A Scalable Approach to Interpreting Large Language Models](https://arxiv.org//abs/2505.17769)

	Patrick Leask, Neel Nanda, Noura Al Moubayed

+ [C-LoRA: Contextual Low-Rank Adaptation for Uncertainty Estimation in Large Language Models](https://arxiv.org//abs/2505.17773)

	Amir Hossein Rahmati, Sanket Jantre, Weifeng Zhang, Yucheng Wang, Byung-Jun Yoon, Nathan M. Urban, Xiaoning Qian

+ [RECIPE-TKG: From Sparse History to Structured Reasoning for LLM-based Temporal Knowledge Graph Completion](https://arxiv.org//abs/2505.17794)

	Ömer Faruk Akgül, Feiyu Zhu, Yuxin Yang, Rajgopal Kannan, Viktor Prasanna

+ [VIBE: Vector Index Benchmark for Embeddings](https://arxiv.org//abs/2505.17810)

	Elias Jääsaari, Ville Hyvönen, Matteo Ceccarello, Teemu Roos, Martin Aumüller

+ [The emergence of sparse attention: impact of data distribution and benefits of repetition](https://arxiv.org//abs/2505.17863)

	Nicolas Zucchet, Francesco d'Angelo, Andrew K. Lampinen, Stephanie C.Y. Chan

+ [VeriThinker: Learning to Verify Makes Reasoning Model Efficient](https://arxiv.org//abs/2505.17941)

	Zigeng Chen, Xinyin Ma, Gongfan Fang, Ruonan Yu, Xinchao Wang

+ [Reward Model Generalization for Compute-Aware Test-Time Reasoning](https://arxiv.org//abs/2505.18065)

	Zeen Song, Wenwen Qiang, Siyu Zhao, Changwen Zheng, Gang Hua

+ [LLM-BSCVM: An LLM-Based Blockchain Smart Contract Vulnerability Management Framework](https://arxiv.org//abs/2505.17416)

	Yanli Jin, Chunpei Li, Peng Fan, Peng Liu, Xianxian Li, Chen Liu, Wangjie Qiu

+ [Large Language Models in the IoT Ecosystem -- A Survey on Security Challenges and Applications](https://arxiv.org//abs/2505.17586)

	Kushal Khatiwada, Jayden Hopper, Joseph Cheatham, Ayan Joshi, Sabur Baidya

+ [Understanding and Mitigating Overrefusal in LLMs from an Unveiling Perspective of Safety Decision Boundary](https://arxiv.org//abs/2505.18325)

	Licheng Pan, Yongqi Tong, Xin Zhang, Xiaolu Zhang, Jun Zhou, Zhixuan Chu

+ [RedactOR: An LLM-Powered Framework for Automatic Clinical Data De-Identification](https://arxiv.org//abs/2505.18380)

	Praphul Singh, Charlotte Dzialo, Jangwon Kim, Sumana Srivatsa, Irfan Bulu, Sri Gadde, Krishnaram Kenthapadi

+ [Simulating Macroeconomic Expectations using LLM Agents](https://arxiv.org//abs/2505.17648)

	Jianhao Lin, Lexuan Sun, Yixin Yan

+ [LA-RCS: LLM-Agent-Based Robot Control System](https://arxiv.org//abs/2505.18214)

	TaekHyun Park, YoungJun Choi, SeungHoon Shin, Kwangil Lee

+ [Do BERT-Like Bidirectional Models Still Perform Better on Text Classification in the Era of LLMs?](https://arxiv.org//abs/2505.18215)

	Junyan Zhang, Yiming Huang, Shuliang Liu, Yubo Gao, Xuming Hu

+ [CoMet: Metaphor-Driven Covert Communication for Multi-Agent Language Games](https://arxiv.org//abs/2505.18218)

	Shuhang Xu, Fangwei Zhong

+ [IDA-Bench: Evaluating LLMs on Interactive Guided Data Analysis](https://arxiv.org//abs/2505.18223)

	Hanyu Li, Haoyu Liu, Tingyu Zhu, Tianyu Guo, Zeyu Zheng, Xiaotie Deng, Michael I. Jordan

+ [Token Reduction Should Go Beyond Efficiency in Generative Models -- From Vision, Language to Multimodality](https://arxiv.org//abs/2505.18227)

	Zhenglun Kong, Yize Li, Fanhu Zeng, Lei Xin, Shvat Messica, Xue Lin, Pu Zhao, Manolis Kellis, Hao Tang, Marinka Zitnik

+ [NSNQuant: A Double Normalization Approach for Calibration-Free Low-Bit Vector Quantization of KV Cache](https://arxiv.org//abs/2505.18231)

	Donghyun Son, Euntae Choi, Sungjoo Yoo

+ [ELDeR: Getting Efficient LLMs through Data-Driven Regularized Layer-wise Pruning](https://arxiv.org//abs/2505.18232)

	Mingkuan Feng, Jinyang Wu, Siyuan Liu, Shuai Zhang, Hongjian Fang, Ruihan Jin, Feihu Che, Pengpeng Shao, Zhengqi Wen, Jianhua Tao

+ [The Origins of Representation Manifolds in Large Language Models](https://arxiv.org//abs/2505.18235)

	Alexander Modell, Patrick Rubin-Delanchy, Nick Whiteley

+ [Think or Not? Exploring Thinking Efficiency in Large Reasoning Models via an Information-Theoretic Lens](https://arxiv.org//abs/2505.18237)

	Xixian Yong, Xiao Zhou, Yingying Zhang, Jinlin Li, Yefeng Zheng, Xian Wu

+ [Multi-Scale Probabilistic Generation Theory: A Hierarchical Framework for Interpreting Large Language Models](https://arxiv.org//abs/2505.18244)

	Yukin Zhang, Qi Dong

+ [MetaGen Blended RAG: Higher Accuracy for Domain-Specific Q&A Without Fine-Tuning](https://arxiv.org//abs/2505.18247)

	Kunal Sawarkar, Shivam R. Solanki, Abhilasha Mangal

+ [Collaborative Memory: Multi-User Memory Sharing in LLM Agents with Dynamic Access Control](https://arxiv.org//abs/2505.18279)

	Alireza Rezazadeh, Zichao Li, Ange Lou, Yuying Zhao, Wei Wei, Yujia Bao

+ [TAGS: A Test-Time Generalist-Specialist Framework with Retrieval-Augmented Reasoning and Verification](https://arxiv.org//abs/2505.18283)

	Jianghao Wu, Feilong Tang, Yulong Li, Ming Hu, Haochen Xue, Shoaib Jameel, Yutong Xie, Imran Razzak

+ [Single-agent or Multi-agent Systems? Why Not Both?](https://arxiv.org//abs/2505.18286)

	Mingyan Gao, Yanzi Li, Banruo Liu, Yifan Yu, Phillip Wang, Ching-Yu Lin, Fan Lai

+ [Architectural Backdoors for Within-Batch Data Stealing and Model Inference Manipulation](https://arxiv.org//abs/2505.18323)

	Nicolas Küchler, Ivan Petrov, Conrad Grobler, Ilia Shumailov

+ [A Critical Evaluation of Defenses against Prompt Injection Attacks](https://arxiv.org//abs/2505.18333)

	Yuqi Jia, Zedian Shao, Yupei Liu, Jinyuan Jia, Dawn Song, Neil Zhenqiang Gong

+ [Task Specific Pruning with LLM-Sieve: How Many Parameters Does Your Task Really Need?](https://arxiv.org//abs/2505.18350)

	Waleed Reda, Abhinav Jangda, Krishna Chintalapudi

+ [The Unreasonable Effectiveness of Model Merging for Cross-Lingual Transfer in LLMs](https://arxiv.org//abs/2505.18356)

	Lucas Bandarkar, Nanyun Peng

+ [Hard Negative Mining for Domain-Specific Retrieval in Enterprise Systems](https://arxiv.org//abs/2505.18366)

	Hansa Meghwani, Amit Agarwal, Priyaranjan Pattnayak, Hitesh Laxmichand Patel, Srikant Panda

+ [Next-token pretraining implies in-context learning](https://arxiv.org//abs/2505.18373)

	Paul M. Riechers, Henry R. Bigelow, Eric A. Alt, Adam Shai

+ [Dynamic Risk Assessments for Offensive Cybersecurity Agents](https://arxiv.org//abs/2505.18384)

	Boyi Wei, Benedikt Stroebl, Jiacen Xu, Joie Zhang, Zhou Li, Peter Henderson

+ [An Outlook on the Opportunities and Challenges of Multi-Agent AI Systems](https://arxiv.org//abs/2505.18397)

	Fangqiao Tian, An Luo, Jin Du, Xun Xian, Robert Specht, Ganghua Wang, Xuan Bi, Jiawei Zhou, Jayanth Srinivasa, Ashish Kundu, Charles Fleming, Rui Zhang, Zirui Liu, Mingyi Hong, Jie Ding

+ [Towards Anonymous Neural Network Inference](https://arxiv.org//abs/2505.18398)

	Liao Peiyuan

+ [Thought calibration: Efficient and confident test-time scaling](https://arxiv.org//abs/2505.18404)

	Menghua Wu, Cai Zhou, Stephen Bates, Tommi Jaakkola

+ [LatentLLM: Attention-Aware Joint Tensor Compression](https://arxiv.org//abs/2505.18413)

	Toshiaki Koike-Akino, Xiangyu Chen, Jing Liu, Ye Wang, Pu (Perry)Wang, Matthew Brand

+ [Retrieval Augmented Generation-based Large Language Models for Bridging Transportation Cybersecurity Legal Knowledge Gaps](https://arxiv.org//abs/2505.18426)

	Khandakar Ashrafi Akbar, Md Nahiyan Uddin, Latifur Khan, Trayce Hockstad, Mizanur Rahman, Mashrur Chowdhury, Bhavani Thuraisingham

+ [Thinking Fast and Right: Balancing Accuracy and Reasoning Length with Adaptive Rewards](https://arxiv.org//abs/2505.18298)

	Jinyan Su, Claire Cardie

+ [Model Editing with Graph-Based External Memory](https://arxiv.org//abs/2505.18343)

	Yash Kumar Atri, Ahmed Alaa, Thomas Hartvigsen

+ [NileChat: Towards Linguistically Diverse and Culturally Aware LLMs for Local Communities](https://arxiv.org//abs/2505.18383)

	Abdellah El Mekki, Houdaifa Atou, Omer Nacar, Shady Shehata, Muhammad Abdul-Mageed

+ [RaDeR: Reasoning-aware Dense Retrieval Models](https://arxiv.org//abs/2505.18405)

	Debrup Das, Sam O' Nuallain, Razieh Rahimi

+ [An Attack to Break Permutation-Based Private Third-Party Inference Schemes for LLMs](https://arxiv.org//abs/2505.18332)

	Rahul Thomas, Louai Zahran, Erica Choi, Akilesh Potti, Micah Goldblum, Arka Pal

+ [Reinforcement Speculative Decoding for Fast Ranking](https://arxiv.org//abs/2505.20316)

	Yingpeng Du, Tianjun Wei, Zhu Sun, Jie Zhang

+ [Beyond Demonstrations: Dynamic Vector Construction from Latent Representations](https://arxiv.org//abs/2505.20318)

	Wang Cai, Hsiu-Yuan Huang, Zhixiang Wang, Yunfang Wu

+ [Less Context, Same Performance: A RAG Framework for Resource-Efficient LLM-Based Clinical NLP](https://arxiv.org//abs/2505.20320)

	Satya Narayana Cheetirala, Ganesh Raut, Dhavalkumar Patel, Fabio Sanatana, Robert Freeman, Matthew A Levin, Girish N. Nadkarni, Omar Dawkins, Reba Miller, Randolph M. Steinhagen, Eyal Klang, Prem Timsina

+ [Beyond Prompt Engineering: Robust Behavior Control in LLMs via Steering Target Atoms](https://arxiv.org//abs/2505.20322)

	Mengru Wang, Ziwen Xu, Shengyu Mao, Shumin Deng, Zhaopeng Tu, Huajun Chen, Ningyu Zhang

+ [Guided by Gut: Efficient Test-Time Scaling with Reinforced Intrinsic Confidence](https://arxiv.org//abs/2505.20325)

	Amirhosein Ghasemabadi, Keith G. Mills, Baochun Li, Di Niu

+ [More Thinking, Less Seeing? Assessing Amplified Hallucination in Multimodal Reasoning Models](https://arxiv.org//abs/2505.21523)

	Chengzhi Liu, Zhongxing Xu, Qingyue Wei, Juncheng Wu, James Zou, Xin Eric Wang, Yuyin Zhou, Sheng Liu

+ [Multimodal Conversation Structure Understanding](https://arxiv.org//abs/2505.17536)

	Kent K. Chang, Mackenzie Hanh Cramer, Anna Ho, Ti Ti Nguyen, Yilin Yuan, David Bamman

+ [LCD: Advancing Extreme Low-Bit Clustering for Large Language Models via Knowledge Distillation](https://arxiv.org//abs/2506.12038)

	Fangxin Liu, Ning Yang, Junping Zhao, Tao Yang, Haibing Guan, Li Jiang

# 2025-05-22
+ [Optimizing LLM-Based Multi-Agent System with Textual Feedback: A Case Study on Software Development](https://arxiv.org//abs/2505.16086)

	Ming Shen, Raphael Shu, Anurag Pratik, James Gung, Yubin Ge, Monica Sunkara, Yi Zhang

+ [Can AI Read Between The Lines? Benchmarking LLMs On Financial Nuance](https://arxiv.org//abs/2505.16090)

	Dominick Kubica, Dylan T. Gordon, Nanami Emura, Derleen Saini, Charlie Goldenberg

+ [Logic-of-Thought: Empowering Large Language Models with Logic Programs for Solving Puzzles in Natural Language](https://arxiv.org//abs/2505.16114)

	Naiqi Li, Peiyuan Liu, Zheng Liu, Tao Dai, Yong Jiang, Shu-Tao Xia

+ [LLM-Powered AI Agent Systems and Their Applications in Industry](https://arxiv.org//abs/2505.16120)

	Guannan Liang, Qianqian Tong

+ [Losing is for Cherishing: Data Valuation Based on Machine Unlearning and Shapley Value](https://arxiv.org//abs/2505.16147)

	Le Ma, Shirao Yang, Zihao Wang, Yinggui Wang, Lei Wang, Tao Wei, Kejun Zhang

+ [SafeKey: Amplifying Aha-Moment Insights for Safety Reasoning](https://arxiv.org//abs/2505.16186)

	Kaiwen Zhou, Xuandong Zhao, Gaowen Liu, Jayanth Srinivasa, Aosong Feng, Dawn Song, Xin Eric Wang

+ [LightRouter: Towards Efficient LLM Collaboration with Minimal Overhead](https://arxiv.org//abs/2505.16221)

	Yifan Zhang, Xinkui Zhao, Zuxin Wang, Guanjie Cheng, Yueshen Xu, Shuiguang Deng, Jianwei Yin

+ [MAPLE: Many-Shot Adaptive Pseudo-Labeling for In-Context Learning](https://arxiv.org//abs/2505.16225)

	Zihan Chen, Song Wang, Zhen Tan, Jundong Li, Cong Shen

+ [How do Scaling Laws Apply to Knowledge Graph Engineering Tasks? The Impact of Model Size on Large Language Model Performance](https://arxiv.org//abs/2505.16276)

	Desiree Heim, Lars-Peter Meyer, Markus Schröder, Johannes Frey, Andreas Dengel

+ [No Black Boxes: Interpretable and Interactable Predictive Healthcare with Knowledge-Enhanced Agentic Causal Discovery](https://arxiv.org//abs/2505.16288)

	Xiaoxue Han, Pengfei Hu, Jun-En Ding, Chang Lu, Feng Liu, Yue Ning

+ [EquivPruner: Boosting Efficiency and Quality in LLM-Based Search via Action Pruning](https://arxiv.org//abs/2505.16312)

	Jiawei Liu, Qisi Chen, Jianshu Zhang, Quan Liu, Defu Lian

+ [Incentivizing Dual Process Thinking for Efficient Large Language Model Reasoning](https://arxiv.org//abs/2505.16315)

	Xiaoxue Cheng, Junyi Li, Zhenduo Zhang, Xinyu Tang, Wayne Xin Zhao, Xinyu Kong, Zhiqiang Zhang

+ [FREESON: Retriever-Free Retrieval-Augmented Reasoning via Corpus-Traversing MCTS](https://arxiv.org//abs/2505.16409)

	Chaeeun Kim, Seungone Kim

+ [Internal Bias in Reasoning Models leads to Overthinking](https://arxiv.org//abs/2505.16448)

	Renfei Dang, Shujian Huang, Jiajun Chen

+ [Psychology-driven LLM Agents for Explainable Panic Prediction on Social Media during Sudden Disaster Events](https://arxiv.org//abs/2505.16455)

	Mengzhu Liu, Zhengqiu Zhu, Chuan Ai, Chen Gao, Xinghong Li, Lingnan He, Kaisheng Lai, Yingfeng Chen, Xin Lu, Yong Li, Quanjun Yin

+ [ReflectEvo: Improving Meta Introspection of Small LLMs by Learning Self-Reflection](https://arxiv.org//abs/2505.16475)

	Jiaqi Li, Xinyi Dong, Yang Liu, Zhizhuo Yang, Quansen Wang, Xiaobo Wang, SongChun Zhu, Zixia Jia, Zilong Zheng

+ [Bridging the Dynamic Perception Gap: Training-Free Draft Chain-of-Thought for Dynamic Multimodal Spatial Reasoning](https://arxiv.org//abs/2505.16579)

	Siqu Ou, Hongcheng Liu, Pingjie Wang, Yusheng Liao, Chuan Xuan, Yanfeng Wang, Yu Wang

+ [SMART: Self-Generating and Self-Validating Multi-Dimensional Assessment for LLMs' Mathematical Problem Solving](https://arxiv.org//abs/2505.16646)

	Yujie Hou, Ting Zhang, Mei Wang, Xuetao Ma, Hu Huang

+ [ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming](https://arxiv.org//abs/2505.16667)

	Xinwei Yang, Zhaofeng Liu, Chen Huang, Jiashuai Zhang, Tong Zhang, Yifan Zhang, Wenqiang Lei

+ [MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models](https://arxiv.org//abs/2505.16700)

	Xuanqi Gao, Siyi Xie, Juan Zhai, Shqing Ma, Chao Shen

+ [KTAE: A Model-Free Algorithm to Key-Tokens Advantage Estimation in Mathematical Reasoning](https://arxiv.org//abs/2505.16826)

	Wei Sun, Wen Yang, Pu Jian, Qianlong Du, Fuwei Cui, Shuo Ren, Jiajun Zhang

+ [GUI-explorer: Autonomous Exploration and Mining of Transition-aware Knowledge for GUI Agent](https://arxiv.org//abs/2505.16827)

	Bin Xie, Rui Shao, Gongwei Chen, Kaiwen Zhou, Yinchuan Li, Jie Liu, Min Zhang, Liqiang Nie

+ [Identifying, Evaluating, and Mitigating Risks of AI Thought Partnerships](https://arxiv.org//abs/2505.16899)

	Kerem Oktar, Katherine M. Collins, Jose Hernandez-Orallo, Diane Coyle, Stephen Cave, Adrian Weller, Ilia Sucholutsky

+ [NovelSeek: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification](https://arxiv.org//abs/2505.16938)

	NovelSeek Team: Bo Zhang, Shiyang Feng, Xiangchao Yan, Jiakang Yuan, Zhiyin Yu, Xiaohan He, Songtao Huang, Shaowei Hou, Zheng Nie, Zhilong Wang, Jinyao Liu, Runmin Ma, Tianshuo Peng, Peng Ye, Dongzhan Zhou, Shufei Zhang, Xiaosong Wang, Yilan Zhang, Meng Li, Zhongying Tu, Xiangyu Yue, Wangli Ouyang, Bowen Zhou, Lei Bai

+ [AGENTIF: Benchmarking Instruction Following of Large Language Models in Agentic Scenarios](https://arxiv.org//abs/2505.16944)

	Yunjia Qi, Hao Peng, Xiaozhi Wang, Amy Xin, Youfeng Liu, Bin Xu, Lei Hou, Juanzi Li

+ [HyGenar: An LLM-Driven Hybrid Genetic Algorithm for Few-Shot Grammar Generation](https://arxiv.org//abs/2505.16978)

	Weizhi Tang, Yixuan Li, Chris Sypherd, Elizabeth Polgreen, Vaishak Belle

+ [Know the Ropes: A Heuristic Strategy for LLM-based Multi-Agent System Design](https://arxiv.org//abs/2505.16979)

	Zhenkun Li, Lingyao Li, Shuhang Lin, Yongfeng Zhang

+ [Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine](https://arxiv.org//abs/2505.16982)

	Adib Bazgir, Amir Habibdoust Lafmajani, Yuwen Zhang

+ [X-MAS: Towards Building Multi-Agent Systems with Heterogeneous LLMs](https://arxiv.org//abs/2505.16997)

	Rui Ye, Xiangrui Liu, Qimin Wu, Xianghe Pang, Zhenfei Yin, Lei Bai, Siheng Chen

+ [Date Fragments: A Hidden Bottleneck of Tokenization for Temporal Reasoning](https://arxiv.org//abs/2505.16088)

	Gagan Bhatia, Maxime Peyrard, Wei Zhao

+ [Steering LVLMs via Sparse Autoencoder for Hallucination Mitigation](https://arxiv.org//abs/2505.16146)

	Zhenglin Hua, Jinghan He, Zijun Yao, Tianxu Han, Haiyun Guo, Yuheng Jia, Junfeng Fang

+ [VLM-R$^3$: Region Recognition, Reasoning, and Refinement for Enhanced Multimodal Chain-of-Thought](https://arxiv.org//abs/2505.16192)

	Chaoya Jiang, Yongrui Heng, Wei Ye, Han Yang, Haiyang Xu, Ming Yan, Ji Zhang, Fei Huang, Shikun Zhang

+ [NQKV: A KV Cache Quantization Scheme Based on Normal Distribution Characteristics](https://arxiv.org//abs/2505.16210)

	Zhihang Cai, Xingjun Zhang, Zhendong Tan, Zheng Wei

+ [AudioTrust: Benchmarking the Multifaceted Trustworthiness of Audio Large Language Models](https://arxiv.org//abs/2505.16211)

	Kai Li, Can Shen, Yile Liu, Jirui Han, Kelong Zheng, Xuechao Zou, Zhe Wang, Xingjian Du, Shun Zhang, Hanjun Luo, Yingbin Jin, Xinxin Xing, Ziyang Ma, Yue Liu, Xiaojun Jia, Yifan Zhang, Junfeng Fang, Kun Wang, Yibo Yan, Haoyang Li, Yiming Li, Xiaobin Zhuang, Yang Liu, Haibo Hu, Zhuo Chen, Zhizheng Wu, Xiaolin Hu, Eng-Siong Chng, XiaoFeng Wang, Wenyuan Xu, Wei Dong, Xinfeng Li

+ [LIFEBench: Evaluating Length Instruction Following in Large Language Models](https://arxiv.org//abs/2505.16234)

	Wei Zhang, Zhenhong Zhou, Junfeng Fang, Rongwu Xu, Kun Wang, Yuanhe Zhang, Rui Wang, Ge Zhang, Xinfeng Li, Li Sun, Lingjuan Lyu, Yang Liu, Sen Su

+ [Transformer Copilot: Learning from The Mistake Log in LLM Fine-tuning](https://arxiv.org//abs/2505.16270)

	Jiaru Zou, Yikun Ban, Zihao Li, Yunzhe Qi, Ruizhong Qiu, Ling Yang, Jingrui He

+ [PMPO: Probabilistic Metric Prompt Optimization for Small and Large Language Models](https://arxiv.org//abs/2505.16307)

	Chenzhuo Zhao, Ziqian Liu, Xingda Wang, Junting Lu, Chaoyi Ruan

+ [AdaSTaR: Adaptive Data Sampling for Training Self-Taught Reasoners](https://arxiv.org//abs/2505.16322)

	Woosung Koh, Wonbeen Oh, Jaein Jang, MinHyung Lee, Hyeongjin Kim, Ah Yeon Kim, Joonkee Kim, Junghyun Lee, Taehyeon Kim, Se-Young Yun

+ [SATURN: SAT-based Reinforcement Learning to Unleash Language Model Reasoning](https://arxiv.org//abs/2505.16368)

	Huanyu Liu, Jia Li, Hao Zhu, Kechi Zhang, Yihong Dong, Ge Li

+ [Tool-Star: Empowering LLM-Brained Multi-Tool Reasoner via Reinforcement Learning](https://arxiv.org//abs/2505.16410)

	Guanting Dong, Yifei Chen, Xiaoxi Li, Jiajie Jin, Hongjin Qian, Yutao Zhu, Hangyu Mao, Guorui Zhou, Zhicheng Dou, Ji-Rong Wen

+ [Attributing Response to Context: A Jensen-Shannon Divergence Driven Mechanistic Study of Context Attribution in Retrieval-Augmented Generation](https://arxiv.org//abs/2505.16415)

	Ruizhe Li, Chen Chen, Yuchen Hu, Yanjun Gao, Xi Wang, Emine Yilmaz

+ [Teaching Large Language Models to Maintain Contextual Faithfulness via Synthetic Tasks and Reinforcement Learning](https://arxiv.org//abs/2505.16483)

	Shuzheng Si, Haozhe Zhao, Cheng Gao, Yuzhuo Bai, Zhitong Wang, Bofei Gao, Kangyang Luo, Wenhao Li, Yufei Huang, Gang Chen, Fanchao Qi, Minjia Zhang, Baobao Chang, Maosong Sun

+ [LLaMAs Have Feelings Too: Unveiling Sentiment and Emotion Representations in LLaMA Models Through Probing](https://arxiv.org//abs/2505.16491)

	Dario Di Palma, Alessandro De Bellis, Giovanni Servedio, Vito Walter Anelli, Fedelucio Narducci, Tommaso Di Noia

+ [Human-like Semantic Navigation for Autonomous Driving using Knowledge Representation and Large Language Models](https://arxiv.org//abs/2505.16498)

	Augusto Luis Ballardini, Miguel Ángel Sotelo

+ [Smaller, Smarter, Closer: The Edge of Collaborative Generative AI](https://arxiv.org//abs/2505.16499)

	Roberto Morabito, SiYoung Jang

+ [Sparse Activation Editing for Reliable Instruction Following in Narratives](https://arxiv.org//abs/2505.16505)

	Runcong Zhao, Chengyu Cao, Qinglin Zhu, Xiucheng Lv, Shun Shao, Lin Gui, Ruifeng Xu, Yulan He

+ [Edge-First Language Model Inference: Models, Metrics, and Tradeoffs](https://arxiv.org//abs/2505.16508)

	SiYoung Jang, Roberto Morabito

+ [CUB: Benchmarking Context Utilisation Techniques for Language Models](https://arxiv.org//abs/2505.16518)

	Lovisa Hagström, Youna Kim, Haeun Yu, Sang-goo Lee, Richard Johansson, Hyunsoo Cho, Isabelle Augenstein

+ [Are the Hidden States Hiding Something? Testing the Limits of Factuality-Encoding Capabilities in LLMs](https://arxiv.org//abs/2505.16520)

	Giovanni Servedio, Alessandro De Bellis, Dario Di Palma, Vito Walter Anelli, Tommaso Di Noia

+ [Benchmarking and Pushing the Multi-Bias Elimination Boundary of LLMs via Causal Effect Estimation-guided Debiasing](https://arxiv.org//abs/2505.16522)

	Zhouhao Sun, Zhiyuan Kan, Xiao Ding, Li Du, Yang Zhao, Bing Qin, Ting Liu

+ [DuFFin: A Dual-Level Fingerprinting Framework for LLMs IP Protection](https://arxiv.org//abs/2505.16530)

	Yuliang Yan, Haochun Tang, Shuo Yan, Enyan Dai

+ [Finetuning-Activated Backdoors in LLMs](https://arxiv.org//abs/2505.16567)

	Thibaud Gloaguen, Mark Vero, Robin Staab, Martin Vechev

+ [O$^2$-Searcher: A Searching-based Agent Model for Open-Domain Open-Ended Question Answering](https://arxiv.org//abs/2505.16582)

	Jianbiao Mei, Tao Hu, Daocheng Fu, Licheng Wen, Xuemeng Yang, Rong Wu, Pinlong Cai, Xing Gao, Yu Yang, Chengjun Xie, Botian Shi, Yong Liu, Yu Qiao

+ [Steering Large Language Models for Machine Translation Personalization](https://arxiv.org//abs/2505.16612)

	Daniel Scalena, Gabriele Sarti, Arianna Bisazza, Elisabetta Fersini, Malvina Nissim

+ [BadVLA: Towards Backdoor Attacks on Vision-Language-Action Models via Objective-Decoupled Optimization](https://arxiv.org//abs/2505.16640)

	Xueyang Zhou, Guiyao Tie, Guowen Zhang, Hechang Wang, Pan Zhou, Lichao Sun

+ [From Evaluation to Defense: Advancing Safety in Video Large Language Models](https://arxiv.org//abs/2505.16643)

	Yiwei Sun, Peiqi Jiang, Chuanbin Liu, Luohao Lin, Zhiying Lu, Hongtao Xie

+ [Collaboration among Multiple Large Language Models for Medical Question Answering](https://arxiv.org//abs/2505.16648)

	Kexin Shang, Chia-Hsuan Chang, Christopher C. Yang

+ [BitHydra: Towards Bit-flip Inference Cost Attack against Large Language Models](https://arxiv.org//abs/2505.16670)

	Xiaobei Yan, Yiming Li, Zhaoxin Fan, Han Qiu, Tianwei Zhang

+ [R1-ShareVL: Incentivizing Reasoning Capability of Multimodal Large Language Models via Share-GRPO](https://arxiv.org//abs/2505.16673)

	Huanjin Yao, Qixiang Yin, Jingyi Zhang, Min Yang, Yibo Wang, Wenhao Wu, Fei Su, Li Shen, Minghui Qiu, Dacheng Tao, Jiaxing Huang

+ [Your Pre-trained LLM is Secretly an Unsupervised Confidence Calibrator](https://arxiv.org//abs/2505.16690)

	Beier Luo, Shuoyuan Wang, Yixuan Li, Hongxin Wei

+ [Beyond Induction Heads: In-Context Meta Learning Induces Multi-Phase Circuit Emergence](https://arxiv.org//abs/2505.16694)

	Gouki Minegishi, Hiroki Furuta, Shohei Taniguchi, Yusuke Iwasawa, Yutaka Matsuo

+ [Training Long-Context LLMs Efficiently via Chunk-wise Optimization](https://arxiv.org//abs/2505.16710)

	Wenhao Li, Yuxin Zhang, Gen Luo, Daohai Yu, Rongrong Ji

+ [Breaking mBad! Supervised Fine-tuning for Cross-Lingual Detoxification](https://arxiv.org//abs/2505.16722)

	Himanshu Beniwal, Youngwoo Kim, Maarten Sap, Soham Dan, Thomas Hartvigsen

+ [Mitigating Fine-tuning Risks in LLMs via Safety-Aware Probing Optimization](https://arxiv.org//abs/2505.16737)

	Chengcan Wu, Zhixin Zhang, Zeming Wei, Yihao Zhang, Meng Sun

+ [TRIM: Achieving Extreme Sparsity with Targeted Row-wise Iterative Metric-driven Pruning](https://arxiv.org//abs/2505.16743)

	Florentin Beck, William Rudman, Carsten Eickhoff

+ [When Safety Detectors Aren't Enough: A Stealthy and Effective Jailbreak Attack on LLMs via Steganographic Techniques](https://arxiv.org//abs/2505.16765)

	Jianing Geng, Biao Yi, Zekun Fei, Tongxi Wu, Lihai Nie, Zheli Liu

+ [CoTSRF: Utilize Chain of Thought as Stealthy and Robust Fingerprint of Large Language Models](https://arxiv.org//abs/2505.16785)

	Zhenzhen Ren, GuoBiao Li, Sheng Li, Zhenxing Qian, Xinpeng Zhang

+ [Accidental Misalignment: Fine-Tuning Language Models Induces Unexpected Vulnerability](https://arxiv.org//abs/2505.16789)

	Punya Syon Pandey, Samuel Simko, Kellin Pelrine, Zhijing Jin

+ [Unlearning Isn't Deletion: Investigating Reversibility of Machine Unlearning in LLMs](https://arxiv.org//abs/2505.16831)

	Xiaoyu Xu, Xiang Yue, Yang Liu, Qingqing Ye, Haibo Hu, Minxin Du

+ [SimpleDeepSearcher: Deep Information Seeking via Web-Powered Reasoning Trajectory Synthesis](https://arxiv.org//abs/2505.16834)

	Shuang Sun, Huatong Song, Yuhao Wang, Ruiyang Ren, Jinhao Jiang, Junjie Zhang, Fei Bai, Jia Deng, Wayne Xin Zhao, Zheng Liu, Lei Fang, Zhongyuan Wang, Ji-Rong Wen

+ [CASTILLO: Characterizing Response Length Distributions of Large Language Models](https://arxiv.org//abs/2505.16881)

	Daniel F. Perez-Ramirez, Dejan Kostic, Magnus Boman

+ [Don't "Overthink" Passage Reranking: Is Reasoning Truly Necessary?](https://arxiv.org//abs/2505.16886)

	Nour Jedidi, Yung-Sung Chuang, James Glass, Jimmy Lin

+ [CAIN: Hijacking LLM-Humans Conversations via a Two-Stage Malicious System Prompt Generation and Refining Framework](https://arxiv.org//abs/2505.16888)

	Viet Pham, Thai Le

+ [Latent Principle Discovery for Language Model Self-Improvement](https://arxiv.org//abs/2505.16927)

	Keshav Ramji, Tahira Naseem, Ramón Fernandez Astudillo

+ [MixAT: Combining Continuous and Discrete Adversarial Training for LLMs](https://arxiv.org//abs/2505.16947)

	Csaba Dékány, Stefan Balauca, Robin Staab, Dimitar I. Dimitrov, Martin Vechev

+ [Bottlenecked Transformers: Periodic KV Cache Abstraction for Generalised Reasoning](https://arxiv.org//abs/2505.16950)

	Adnan Oomerjee, Zafeirios Fountas, Zhongwei Yu, Haitham Bou-Ammar, Jun Wang

+ [Invisible Prompts, Visible Threats: Malicious Font Injection in External Resources for Large Language Models](https://arxiv.org//abs/2505.16957)

	Junjie Xiong, Changjia Zhu, Shuhang Lin, Chong Zhang, Yongfeng Zhang, Yao Liu, Lingyao Li

+ [Fixing Data That Hurts Performance: Cascading LLMs to Relabel Hard Negatives for Robust Information Retrieval](https://arxiv.org//abs/2505.16967)

	Nandan Thakur, Crystina Zhang, Xueguang Ma, Jimmy Lin

+ [T1: A Tool-Oriented Conversational Dataset for Multi-Turn Agentic Planning](https://arxiv.org//abs/2505.16986)

	Amartya Chakraborty, Paresh Dashore, Nadia Bathaee, Anmol Jain, Anirban Das, Shi-Xiong Zhang, Sambit Sahu, Milind Naphade, Genta Indra Winata

+ [MASLab: A Unified and Comprehensive Codebase for LLM-based Multi-Agent Systems](https://arxiv.org//abs/2505.16988)

	Rui Ye, Keduan Huang, Qimin Wu, Yuzhu Cai, Tian Jin, Xianghe Pang, Xiangrui Liu, Jiaqi Su, Chen Qian, Bohan Tang, Kaiqu Liang, Jiaao Chen, Yue Hu, Zhenfei Yin, Rongye Shi, Bo An, Yang Gao, Wenjun Wu, Lei Bai, Siheng Chen

+ [Do Large Language Models Excel in Complex Logical Reasoning with Formal Language?](https://arxiv.org//abs/2505.16998)

	Jin Jiang, Jianing Wang, Yuchen Yan, Yang Liu, Jianhua Zhu, Mengdi Zhang, Xunliang Cai, Liangcai Gao

+ [R1-Searcher++: Incentivizing the Dynamic Knowledge Acquisition of LLMs via Reinforcement Learning](https://arxiv.org//abs/2505.17005)

	Huatong Song, Jinhao Jiang, Wenqing Tian, Zhipeng Chen, Yuhuan Wu, Jiahao Zhao, Yingqian Min, Wayne Xin Zhao, Lei Fang, Ji-Rong Wen

+ [Understanding Prompt Tuning and In-Context Learning via Meta-Learning](https://arxiv.org//abs/2505.17010)

	Tim Genewein, Kevin Wenliang Li, Jordi Grau-Moya, Anian Ruoss, Laurent Orseau, Marcus Hutter

+ [SpatialScore: Towards Unified Evaluation for Multimodal Spatial Understanding](https://arxiv.org//abs/2505.17012)

	Haoning Wu, Xiao Huang, Yaohui Chen, Ya Zhang, Yanfeng Wang, Weidi Xie

+ [Continually Self-Improving Language Models for Bariatric Surgery Question--Answering](https://arxiv.org//abs/2505.16102)

	Yash Kumar Atri, Thomas H Shin, Thomas Hartvigsen

+ [Hierarchical Safety Realignment: Lightweight Restoration of Safety in Pruned Large Vision-Language Models](https://arxiv.org//abs/2505.16104)

	Yue Li, Xin Yi, Dongsheng Shi, Gerard de Melo, Xiaoling Wang, Linlin Wang

+ [Veracity Bias and Beyond: Uncovering LLMs' Hidden Beliefs in Problem-Solving Reasoning](https://arxiv.org//abs/2505.16128)

	Yue Zhou, Barbara Di Eugenio

+ [Position of Uncertainty: A Cross-Linguistic Study of Positional Bias in Large Language Models](https://arxiv.org//abs/2505.16134)

	Menschikov Mikhail, Alexander Kharitonov, Maiia Kotyga, Vadim Porvatov, Anna Zhukovskaya, David Kagramanyan, Egor Shvetsov, Evgeny Burnaev

+ [Distilling the Implicit Multi-Branch Structure in LLMs' Reasoning via Reinforcement Learning](https://arxiv.org//abs/2505.16142)

	Shicheng Xu, Liang Pang, Yunchang Zhu, Jia Gu, Zihao Wei, Jingcheng Deng, Feiyang Pan, Huawei Shen, Xueqi Cheng

+ [KNN-SSD: Enabling Dynamic Self-Speculative Decoding via Nearest Neighbor Layer Set Optimization](https://arxiv.org//abs/2505.16162)

	Mingbo Song, Heming Xia, Jun Zhang, Chak Tou Leong, Qiancheng Xu, Wenjie Li, Sujian Li

+ [When Do LLMs Admit Their Mistakes? Understanding the Role of Model Belief in Retraction](https://arxiv.org//abs/2505.16170)

	Yuqing Yang, Robin Jia

+ [Understanding Fact Recall in Language Models: Why Two-Stage Training Encourages Memorization but Mixed Training Teaches Knowledge](https://arxiv.org//abs/2505.16178)

	Ying Zhang, Benjamin Heinzerling, Dongyuan Li, Ryoma Ishigaki, Yuta Hitomi, Kentaro Inui

+ [SAE-SSV: Supervised Steering in Sparse Representation Spaces for Reliable Control of Language Models](https://arxiv.org//abs/2505.16188)

	Zirui He, Mingyu Jin, Bo Shen, Ali Payani, Yongfeng Zhang, Mengnan Du

+ [An Empirical Study on Configuring In-Context Learning Demonstrations for Unleashing MLLMs' Sentimental Perception Capability](https://arxiv.org//abs/2505.16193)

	Daiqing Wu, Dongbao Yang, Sicheng Zhao, Can Ma, Yu Zhou

+ [Memorization or Reasoning? Exploring the Idiom Understanding of LLMs](https://arxiv.org//abs/2505.16216)

	Jisu Kim, Youngwoo Shin, Uiji Hwang, Jihun Choi, Richeng Xuan, Taeuk Kim

+ [Don't Judge Code by Its Cover: Exploring Biases in LLM Judges for Code Evaluation](https://arxiv.org//abs/2505.16222)

	Jiwon Moon, Yerin Hwang, Dongryeol Lee, Taegwan Kang, Yongil Kim, Kyomin Jung

+ [MuseRAG: Idea Originality Scoring At Scale](https://arxiv.org//abs/2505.16232)

	Ali Sarosh Bangash, Krish Veera, Ishfat Abrar Islam, Raiyan Abdul Baten

+ [Align-GRAG: Reasoning-Guided Dual Alignment for Graph Retrieval-Augmented Generation](https://arxiv.org//abs/2505.16237)

	Derong Xu, Pengyue Jia, Xiaopeng Li, Yingyi Zhang, Maolin Wang, Qidong Liu, Xiangyu Zhao, Yichao Wang, Huifeng Guo, Ruiming Tang, Enhong Chen, Tong Xu

+ [Three Minds, One Legend: Jailbreak Large Reasoning Model with Adaptive Stacked Ciphers](https://arxiv.org//abs/2505.16241)

	Viet-Anh Nguyen, Shiqian Zhao, Gia Dao, Runyi Hu, Yi Xie, Luu Anh Tuan

+ [Diverse, not Short: A Length-Controlled Self-Learning Framework for Improving Response Diversity of Language Models](https://arxiv.org//abs/2505.16245)

	Vijeta Deshpande, Debasmita Ghose, John D. Patterson, Roger Beaty, Anna Rumshisky

+ [Does Localization Inform Unlearning? A Rigorous Examination of Local Parameter Attribution for Knowledge Unlearning in Language Models](https://arxiv.org//abs/2505.16252)

	Hwiyeong Lee, Uiji Hwang, Hyelim Lim, Taeuk Kim

+ [HiMATE: A Hierarchical Multi-Agent Framework for Machine Translation Evaluation](https://arxiv.org//abs/2505.16281)

	Shijie Zhang, Renhao Li, Songsheng Wang, Philipp Koehn, Min Yang, Derek F. Wong

+ [Augmenting LLM Reasoning with Dynamic Notes Writing for Complex QA](https://arxiv.org//abs/2505.16293)

	Rishabh Maheshwary, Masoud Hashemi, Khyati Mahajan, Shiva Krishna Reddy Malay, Sai Rajeswar, Sathwik Tejaswi Madhusudhan, Spandana Gella, Vikas Yadav

+ [ToDi: Token-wise Distillation via Fine-Grained Divergence Control](https://arxiv.org//abs/2505.16297)

	Seongryong Jung, Suwan Yoon, DongGeon Kim, Hwanhee Lee

+ [INFERENCEDYNAMICS: Efficient Routing Across LLMs through Structured Capability and Knowledge Profiling](https://arxiv.org//abs/2505.16303)

	Haochen Shi, Tianshi Zheng, Weiqi Wang, Baixuan Xu, Chunyang Li, Chunkit Chan, Tao Fan, Yangqiu Song, Qiang Yang

+ [Embodied Agents Meet Personalization: Exploring Memory Utilization for Personalized Assistance](https://arxiv.org//abs/2505.16348)

	Taeyoon Kwon, Dongwook Choi, Sunghwan Kim, Hyojun Kim, Seungjun Moon, Beong-woo Kwak, Kuan-Hao Huang, Jinyoung Yeo

+ [Ask, Retrieve, Summarize: A Modular Pipeline for Scientific Literature Summarization](https://arxiv.org//abs/2505.16349)

	Pierre Achkar, Tim Gollub, Martin Potthast

+ [PaTH Attention: Position Encoding via Accumulating Householder Transformations](https://arxiv.org//abs/2505.16381)

	Songlin Yang, Yikang Shen, Kaiyue Wen, Shawn Tan, Mayank Mishra, Liliang Ren, Rameswar Panda, Yoon Kim

+ [Semantic Pivots Enable Cross-Lingual Transfer in Large Language Models](https://arxiv.org//abs/2505.16385)

	Kaiyu He, Tong Zhou, Yubo Chen, Delai Qiu, Shengping Liu, Kang Liu, Jun Zhao

+ [WebAgent-R1: Training Web Agents via End-to-End Multi-Turn Reinforcement Learning](https://arxiv.org//abs/2505.16421)

	Zhepei Wei, Wenlin Yao, Yao Liu, Weizhi Zhang, Qin Lu, Liang Qiu, Changlong Yu, Puyang Xu, Chao Zhang, Bing Yin, Hyokun Yun, Lihong Li

+ [Reading Between the Prompts: How Stereotypes Shape LLM's Implicit Personalization](https://arxiv.org//abs/2505.16467)

	Vera Neplenbroek, Arianna Bisazza, Raquel Fernández

+ [EnSToM: Enhancing Dialogue Systems with Entropy-Scaled Steering Vectors for Topic Maintenance](https://arxiv.org//abs/2505.16526)

	Heejae Suh, Yejin Jeon, Deokhyung Kang, Taehee Park, Yejin Min, Gary Geunbae Lee

+ [Mechanistic Understanding and Mitigation of Language Confusion in English-Centric Large Language Models](https://arxiv.org//abs/2505.16538)

	Ercong Nie, Helmut Schmid, Hinrich Schütze

+ [Think Silently, Think Fast: Dynamic Latent Compression of LLM Reasoning Chains](https://arxiv.org//abs/2505.16552)

	Wenhui Tan, Jiaze Li, Jianzhong Ju, Zhenbo Luo, Jian Luan, Ruihua Song

+ [URLs Help, Topics Guide: Understanding Metadata Utility in LLM Training](https://arxiv.org//abs/2505.16570)

	Dongyang Fan, Vinko Sabolčec, Martin Jaggi

+ [EMULATE: A Multi-Agent Framework for Determining the Veracity of Atomic Claims by Emulating Human Actions](https://arxiv.org//abs/2505.16576)

	Spencer Hong, Meng Luo, Xinyi Wan

+ [Evaluating Large Language Model with Knowledge Oriented Language Specific Simple Question Answering](https://arxiv.org//abs/2505.16591)

	Bowen Jiang, Runchuan Zhu, Jiang Wu, Zinco Jiang, Yifan He, Junyuan Gao, Jia Yu, Rui Min, Yinfan Wang, Haote Yang, Songyang Zhang, Dahua Lin, Lijun Wu, Conghui He

+ [From Generic Empathy to Personalized Emotional Support: A Self-Evolution Framework for User Preference Alignment](https://arxiv.org//abs/2505.16610)

	Jing Ye, Lu Xiang, Yaping Zhang, Chengqing Zong

+ [Locate-then-Merge: Neuron-Level Parameter Fusion for Mitigating Catastrophic Forgetting in Multimodal LLMs](https://arxiv.org//abs/2505.16703)

	Zeping Yu, Sophia Ananiadou

+ [Reasoning Beyond Language: A Comprehensive Survey on Latent Chain-of-Thought Reasoning](https://arxiv.org//abs/2505.16782)

	Xinghao Chen, Anhao Zhao, Heming Xia, Xuan Lu, Hanlin Wang, Yanjun Chen, Wei Zhang, Jian Wang, Wenjie Li, Xiaoyu Shen

+ [Two-way Evidence self-Alignment based Dual-Gated Reasoning Enhancement](https://arxiv.org//abs/2505.16806)

	Kexin Zhang, Junlan Chen, Daifeng Li, Yuxuan Zhang, Yangyang Feng, Bowen Deng, Weixu Chen

+ [R1-Compress: Long Chain-of-Thought Compression via Chunk Compression and Search](https://arxiv.org//abs/2505.16838)

	Yibo Wang, Li Shen, Huanjin Yao, Tiansheng Huang, Rui Liu, Naiqiang Tan, Jiaxing Huang, Kai Zhang, Dacheng Tao

+ [MPO: Multilingual Safety Alignment via Reward Gap Optimization](https://arxiv.org//abs/2505.16869)

	Weixiang Zhao, Yulin Hu, Yang Deng, Tongtong Wu, Wenxuan Zhang, Jiahe Guo, An Zhang, Yanyan Zhao, Bing Qin, Tat-Seng Chua, Ting Liu

+ [Shadows in the Attention: Contextual Perturbation and Representation Drift in the Dynamics of Hallucination in LLMs](https://arxiv.org//abs/2505.16894)

	Zeyu Wei, Shuo Wang, Xiaohui Rong, Xuemin Liu, He Li

+ [Power-Law Decay Loss for Large Language Model Finetuning: Focusing on Information Sparsity to Enhance Generation Quality](https://arxiv.org//abs/2505.16900)

	Jintian Shao, Hongyi Huang, Jiayi Wu, Beiwen Zhang, ZhiYu Wu, You Shan, MingKai Zheng

+ [UNCLE: Uncertainty Expressions in Long-Form Generation](https://arxiv.org//abs/2505.16922)

	Ruihan Yang, Caiqi Zhang, Zhisong Zhang, Xinting Huang, Dong Yu, Nigel Collier, Deqing Yang

+ [In-Context Watermarks for Large Language Models](https://arxiv.org//abs/2505.16934)

	Yepeng Liu, Xuandong Zhao, Christopher Kruegel, Dawn Song, Yuheng Bu

+ [On Multilingual Encoder Language Model Compression for Low-Resource Languages](https://arxiv.org//abs/2505.16956)

	Daniil Gurgurov, Michal Gregor, Josef van Genabith, Simon Ostermann

+ [VeriFastScore: Speeding up long-form factuality evaluation](https://arxiv.org//abs/2505.16973)

	Rishanth Rajendhran, Amir Zadeh, Matthew Sarte, Chuan Li, Mohit Iyyer

+ [LLM as Effective Streaming Processor: Bridging Streaming-Batch Mismatches with Group Position Encoding](https://arxiv.org//abs/2505.16983)

	Junlong Tong, Jinlan Fu, Zixuan Lin, Yingqi Fan, Anhao Zhao, Hui Su, Xiaoyu Shen

+ [Benchmarking Retrieval-Augmented Multimomal Generation for Document Question Answering](https://arxiv.org//abs/2505.16470)

	Kuicai Dong, Yujing Chang, Shijie Huang, Yasheng Wang, Ruiming Tang, Yong Liu

+ [CTRAP: Embedding Collapse Trap to Safeguard Large Language Models from Harmful Fine-Tuning](https://arxiv.org//abs/2505.16559)

	Biao Yi, Tiansheng Huang, Baolei Zhang, Tong Li, Lihai Nie, Zheli Liu, Li Shen

+ [UFT: Unifying Supervised and Reinforcement Fine-Tuning](https://arxiv.org//abs/2505.16984)

	Mingyang Liu, Gabriele Farina, Asuman Ozdaglar

+ [Multi-SpatialMLLM: Multi-Frame Spatial Understanding with Multi-Modal Large Language Models](https://arxiv.org//abs/2505.17015)

	Runsen Xu, Weiyao Wang, Hao Tang, Xingyu Chen, Xiaodong Wang, Fu-Jen Chu, Dahua Lin, Matt Feiszli, Kevin J. Liang

+ [Training-Free Reasoning and Reflection in MLLMs](https://arxiv.org//abs/2505.16151)

	Hongchen Wei, Zhenzhong Chen

+ [Erased or Dormant? Rethinking Concept Erasure Through Reversibility](https://arxiv.org//abs/2505.16174)

	Ping Liu, Chi Zhang

+ [CT-Agent: A Multimodal-LLM Agent for 3D CT Radiology Question Answering](https://arxiv.org//abs/2505.16229)

	Yuren Mao, Wenyi Xu, Yuyang Qin, Yunjun Gao

+ [ARPO:End-to-End Policy Optimization for GUI Agents with Experience Replay](https://arxiv.org//abs/2505.16282)

	Fanbin Lu, Zhisheng Zhong, Shu Liu, Chi-Wing Fu, Jiaya Jia

+ [Mitigating Hallucinations in Vision-Language Models through Image-Guided Head Suppression](https://arxiv.org//abs/2505.16411)

	Sreetama Sarkar, Yue Che, Alex Gavin, Peter A. Beerel, Souvik Kundu

+ [ALTo: Adaptive-Length Tokenizer for Autoregressive Mask Generation](https://arxiv.org//abs/2505.16495)

	Lingfeng Wang, Hualing Lin, Senda Chen, Tao Wang, Changxu Cheng, Yangyang Zhong, Dong Zheng, Wuyue Zhao

+ [Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding](https://arxiv.org//abs/2505.16652)

	Feilong Tang, Chengzhi Liu, Zhongxing Xu, Ming Hu, Zelin Peng, Zhiwei Yang, Jionglong Su, Minquan Lin, Yifan Peng, Xuelian Cheng, Imran Razzak, Zongyuan Ge

+ [Dimple: Discrete Diffusion Multimodal Large Language Model with Parallel Decoding](https://arxiv.org//abs/2505.16990)

	Runpeng Yu, Xinyin Ma, Xinchao Wang

+ [SophiaVL-R1: Reinforcing MLLMs Reasoning with Thinking Reward](https://arxiv.org//abs/2505.17018)

	Kaixuan Fan, Kaituo Feng, Haoming Lyu, Dongzhan Zhou, Xiangyu Yue

+ [Backdoor Cleaning without External Guidance in MLLM Fine-tuning](https://arxiv.org//abs/2505.16916)

	Xuankun Rong, Wenke Huang, Jian Liang, Jinhe Bi, Xun Xiao, Yiming Li, Bo Du, Mang Ye

+ [Tools in the Loop: Quantifying Uncertainty of LLM Question Answering Systems That Use Tools](https://arxiv.org//abs/2505.16113)

	Panagiotis Lymperopoulos, Vasanth Sarathy

+ [Plan and Budget: Effective and Efficient Test-Time Scaling on Large Language Model Reasoning](https://arxiv.org//abs/2505.16122)

	Junhong Lin, Xinyue Zeng, Jie Zhu, Song Wang, Julian Shun, Jun Wu, Dawei Zhou

+ [Small-to-Large Generalization: Data Influences Models Consistently Across Scale](https://arxiv.org//abs/2505.16260)

	Alaa Khaddaj, Logan Engstrom, Aleksander Madry

+ [Think-RM: Enabling Long-Horizon Reasoning in Generative Reward Models](https://arxiv.org//abs/2505.16265)

	Ilgee Hong, Changlong Yu, Liang Qiu, Weixiang Yan, Zhenghao Xu, Haoming Jiang, Qingru Zhang, Qin Lu, Xin Liu, Chao Zhang, Tuo Zhao

+ [Only Large Weights (And Not Skip Connections) Can Prevent the Perils of Rank Collapse](https://arxiv.org//abs/2505.16284)

	Josh Alman, Zhao Song

+ [Understanding Differential Transformer Unchains Pretrained Self-Attentions](https://arxiv.org//abs/2505.16333)

	Chaerin Kong, Jiho Jang, Nojun Kwak

+ [Improving Chemical Understanding of LLMs via SMILES Parsing](https://arxiv.org//abs/2505.16340)

	Yunhui Jang, Jaehyung Kim, Sungsoo Ahn

+ [Divide-Fuse-Conquer: Eliciting "Aha Moments" in Multi-Scenario Games](https://arxiv.org//abs/2505.16401)

	Xiaoqing Zhang, Huabin Zheng, Ang Lv, Yuhan Liu, Zirui Song, Flood Sung, Xiuying Chen, Rui Yan

+ [Implicit Jailbreak Attacks via Cross-Modal Information Concealment on Vision-Language Models](https://arxiv.org//abs/2505.16446)

	Zhaoxin Wang, Handing Wang, Cong Tian, Yaochu Jin

+ [HOFT: Householder Orthogonal Fine-tuning](https://arxiv.org//abs/2505.16531)

	Alejandro Moreno Arcas, Albert Sanchis, Jorge Civera, Alfons Juan

+ [Generator-Mediated Bandits: Thompson Sampling for GenAI-Powered Adaptive Interventions](https://arxiv.org//abs/2505.16311)

	Marc Brooks, Gabriel Durham, Kihyuk Hong, Ambuj Tewari

+ [Robust LLM Fingerprinting via Domain-Specific Watermarks](https://arxiv.org//abs/2505.16723)

	Thibaud Gloaguen, Robin Staab, Nikola Jovanović, Martin Vechev

+ [Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks](https://arxiv.org//abs/2505.16901)

	Hongyuan Tao, Ying Zhang, Zhenhao Tang, Hongen Peng, Xukun Zhu, Bingchang Liu, Yingguang Yang, Ziyin Zhang, Zhaogui Xu, Haipeng Zhang, Linchao Zhu, Rui Wang, Hang Yu, Jianguo Li, Peng Di

+ [ReCopilot: Reverse Engineering Copilot in Binary Analysis](https://arxiv.org//abs/2505.16366)

	Guoqiang Chen, Huiqi Sun, Daguang Liu, Zhiqi Wang, Qiang Wang, Bin Yin, Lu Liu, Lingyun Ying

+ [Effective Reinforcement Learning for Reasoning in Language Models](https://arxiv.org//abs/2505.17218)

	Lianghuan Huang, Shuo Li, Sagnik Anupam, Insup Lee, Osbert Bastani

+ [Reasoning Model is Stubborn: Diagnosing Instruction Overriding in Reasoning Models](https://arxiv.org//abs/2505.17225)

	Doohyuk Jang, Yoonjeon Kim, Chanjae Park, Hyun Ryu, Eunho Yang

+ [AdaReasoner: Adaptive Reasoning Enables More Flexible Thinking](https://arxiv.org//abs/2505.17312)

	Xiangqi Wang, Yue Huang, Yanbo Wang, Xiaonan Luo, Kehan Guo, Yujun Zhou, Xiangliang Zhang

+ [Longer Context, Deeper Thinking: Uncovering the Role of Long-Context Ability in Reasoning](https://arxiv.org//abs/2505.17315)

	Wang Yang, Zirui Liu, Hongye Jin, Qingyu Yin, Vipin Chaudhary, Xiaotian Han

+ [DEL-ToM: Inference-Time Scaling for Theory-of-Mind Reasoning via Dynamic Epistemic Logic](https://arxiv.org//abs/2505.17348)

	Yuheng Wu, Jianwen Xie, Denghui Zhang, Zhaozhuo Xu

+ [Relative Bias: A Comparative Framework for Quantifying Bias in LLMs](https://arxiv.org//abs/2505.17131)

	Alireza Arbabi, Florian Kerschbaum

+ [LongMagpie: A Self-synthesis Method for Generating Large-scale Long-context Instructions](https://arxiv.org//abs/2505.17134)

	Chaochen Gao, Xing Wu, Zijia Lin, Debing Zhang, Songlin Hu

+ [Foundation Models for Geospatial Reasoning: Assessing Capabilities of Large Language Models in Understanding Geometries and Topological Spatial Relations](https://arxiv.org//abs/2505.17136)

	Yuhan Ji, Song Gao, Ying Nie, Ivan Majić, Krzysztof Janowicz

+ [RAP: Runtime-Adaptive Pruning for LLM Inference](https://arxiv.org//abs/2505.17138)

	Huanrong Liu, Chunlin Tian, Xuyang Wei, Jiaheng Dai, Qin Liu, Tianqi Wei, Qingbiao Li, Li Li

+ [EarthSE: A Benchmark Evaluating Earth Scientific Exploration Capability for Large Language Models](https://arxiv.org//abs/2505.17139)

	Wanghan Xu, Xiangyu Zhao, Yuhao Zhou, Xiaoyu Yue, Ben Fei, Fenghua Ling, Wenlong Zhang, Lei Bai

+ [Data Doping or True Intelligence? Evaluating the Transferability of Injected Knowledge in LLMs](https://arxiv.org//abs/2505.17140)

	Essa Jan, Moiz Ali, Muhammad Saram Hassan, Fareed Zaffar, Yasir Zaki

+ [MDIT-Bench: Evaluating the Dual-Implicit Toxicity in Large Multimodal Models](https://arxiv.org//abs/2505.17144)

	Bohan Jin, Shuhan Qi, Kehai Chen, Xinyi Guo, Xuan Wang

+ [LLM Access Shield: Domain-Specific LLM Framework for Privacy Policy Compliance](https://arxiv.org//abs/2505.17145)

	Yu Wang, Cailing Cai, Zhihua Xiao, Peifung E. Lam

+ [MTSA: Multi-turn Safety Alignment for LLMs through Multi-round Red-teaming](https://arxiv.org//abs/2505.17147)

	Weiyang Guo, Jing Li, Wenya Wang, YU LI, Daojing He, Jun Yu, Min Zhang

+ [LLM-Powered Agents for Navigating Venice's Historical Cadastre](https://arxiv.org//abs/2505.17148)

	Tristan Karch, Jakhongir Saydaliev, Isabella Di Lenardo, Frédéric Kaplan

+ [Amplify Adjacent Token Differences: Enhancing Long Chain-of-Thought Reasoning with Shift-FFN](https://arxiv.org//abs/2505.17153)

	Yao Xu, Mingyu Xu, Fangyu Lei, Wangtao Sun, Xiangrong Zeng, Bingning Wang, Guang Liu, Shizhu He, Jun Zhao, Kang Liu

+ [Can Large Language Models Design Biological Weapons? Evaluating Moremi Bio](https://arxiv.org//abs/2505.17154)

	Gertrude Hattoh, Jeremiah Ayensu, Nyarko Prince Ofori, Solomon Eshun, Darlington Akogo

+ [TrimR: Verifier-based Training-Free Thinking Compression for Efficient Test-Time Scaling](https://arxiv.org//abs/2505.17155)

	Weizhe Lin, Xing Li, Zhiyuan Yang, Xiaojin Fu, Hui-Ling Zhen, Yaoyuan Wang, Xianzhi Yu, Wulong Liu, Xiaosong Li, Mingxuan Yuan

+ [Harry Potter is Still Here! Probing Knowledge Leakage in Targeted Unlearned Large Language Models via Automated Adversarial Prompting](https://arxiv.org//abs/2505.17160)

	Bang Trinh Tran To, Thai Le

+ [DailyQA: A Benchmark to Evaluate Web Retrieval Augmented LLMs Based on Capturing Real-World Changes](https://arxiv.org//abs/2505.17162)

	Jiehan Cheng, Zhicheng Dou

+ [OCR-Reasoning Benchmark: Unveiling the True Capabilities of MLLMs in Complex Text-Rich Image Reasoning](https://arxiv.org//abs/2505.17163)

	Mingxin Huang, Yongxin Shi, Dezhi Peng, Songxuan Lai, Zecheng Xie, Lianwen Jin

+ [Next Token Perception Score: Analytical Assessment of your LLM Perception Skills](https://arxiv.org//abs/2505.17169)

	Yu-Ang Cheng, Leyang Hu, Hai Huang, Randall Balestriero

+ [FB-RAG: Improving RAG with Forward and Backward Lookup](https://arxiv.org//abs/2505.17206)

	Kushal Chawla, Alfy Samuel, Anoop Kumar, Daben Liu

+ [Mitigating Gender Bias via Fostering Exploratory Thinking in LLMs](https://arxiv.org//abs/2505.17217)

	Kangda Wei, Hasnat Md Abdullah, Ruihong Huang

+ [ExeSQL: Self-Taught Text-to-SQL Models with Execution-Driven Bootstrapping for SQL Dialects](https://arxiv.org//abs/2505.17231)

	Jipeng Zhang, Haolin Yang, Kehao Miao, Ruiyuan Zhang, Renjie Pi, Jiahui Gao, Xiaofang Zhou

+ [Optimal Policy Minimum Bayesian Risk](https://arxiv.org//abs/2505.17242)

	Ramón Fernandez Astudillo, Md Arafat Sultan, Aashka Trivedi, Yousef El-Kurdi, Tahira Naseem, Radu Florian, Salim Roukos

+ [ReasoningShield: Content Safety Detection over Reasoning Traces of Large Reasoning Models](https://arxiv.org//abs/2505.17244)

	Changyi Li, Jiayi Wang, Xudong Pan, Geng Hong, Min Yang

+ [ConciseRL: Conciseness-Guided Reinforcement Learning for Efficient Reasoning Models](https://arxiv.org//abs/2505.17250)

	Razvan-Gabriel Dumitru, Darius Peteleaza, Vikas Yadav, Liangming Pan

+ [CaseReportBench: An LLM Benchmark Dataset for Dense Information Extraction in Clinical Case Reports](https://arxiv.org//abs/2505.17265)

	Xiao Yu Cindy Zhang (1), Carlos R. Ferreira (2), Francis Rossignol (2), Raymond T. Ng (1), Wyeth Wasserman (1), Jian Zhu (1) ((1) University of British Columbia, (2) National Institutes of Health)

+ [Select2Reason: Efficient Instruction-Tuning Data Selection for Long-CoT Reasoning](https://arxiv.org//abs/2505.17266)

	Cehao Yang, Xueyuan Lin, Chengjin Xu, Xuhui Jiang, Xiaojun Wu, Honghao Liu, Hui Xiong, Jian Guo

+ [Search Wisely: Mitigating Sub-optimal Agentic Searches By Reducing Uncertainty](https://arxiv.org//abs/2505.17281)

	Peilin Wu, Mian Zhang, Xinlu Zhang, Xinya Du, Zhiyu Zoey Chen

+ [Analyzing Fine-Grained Alignment and Enhancing Vision Understanding in Multimodal Language Models](https://arxiv.org//abs/2505.17316)

	Jiachen Jiang, Jinxin Zhou, Bo Peng, Xia Ning, Zhihui Zhu

+ [From Compression to Expansion: A Layerwise Analysis of In-Context Learning](https://arxiv.org//abs/2505.17322)

	Jiachen Jiang, Yuxin Dong, Jinxin Zhou, Zhihui Zhu

+ [SweEval: Do LLMs Really Swear? A Safety Benchmark for Testing Limits for Enterprise Use](https://arxiv.org//abs/2505.17332)

	Hitesh Laxmichand Patel, Amit Agarwal, Arion Das, Bhargava Kumar, Srikant Panda, Priyaranjan Pattnayak, Taki Hasan Rafi, Tejaswini Kumar, Dong-Kyu Chae

+ [When can isotropy help adapt LLMs' next word prediction to numerical domains?](https://arxiv.org//abs/2505.17135)

	Rashed Shelim, Shengzhe Xu, Walid Saad, Naren Ramakrishnan

+ [PersonaBOT: Bringing Customer Personas to Life with LLMs and RAG](https://arxiv.org//abs/2505.17156)

	Muhammed Rizwan, Lars Carlsson, Mohammad Loni

+ [Humans Hallucinate Too: Language Models Identify and Correct Subjective Annotation Errors With Label-in-a-Haystack Prompts](https://arxiv.org//abs/2505.17222)

	Georgios Chochlakis, Peter Wu, Arjun Bedi, Marcus Ma, Kristina Lerman, Shrikanth Narayanan

+ [Personalizing Student-Agent Interactions Using Log-Contextualized Retrieval Augmented Generation (RAG)](https://arxiv.org//abs/2505.17238)

	Clayton Cohn, Surya Rayala, Caitlin Snyder, Joyce Fonteles, Shruti Jain, Naveeduddin Mohammed, Umesh Timalsina, Sarah K. Burriss, Ashwin T S, Namrata Srivastava, Menton Deweese, Angela Eeds, Gautam Biswas

+ [The Rise of Parameter Specialization for Knowledge Storage in Large Language Models](https://arxiv.org//abs/2505.17260)

	Yihuai Hong, Yiran Zhao, Wei Tang, Yang Deng, Yu Rong, Wenxuan Zhang

+ [SELF: Self-Extend the Context Length With Logistic Growth Function](https://arxiv.org//abs/2505.17296)

	Phat Thanh Dang, Saahil Thoppay, Wang Yang, Qifan Wang, Vipin Chaudhary, Xiaotian Han

+ [Refusal Direction is Universal Across Safety-Aligned Languages](https://arxiv.org//abs/2505.17306)

	Xinpeng Wang, Mingyang Wang, Yihong Liu, Hinrich Schütze, Barbara Plank

+ [Language models should be subject to repeatable, open, domain-contextualized hallucination benchmarking](https://arxiv.org//abs/2505.17345)

	Justin D. Norman, Michael U. Rivera, D. Alex Hughes

+ [Robustifying Vision-Language Models via Dynamic Token Reweighting](https://arxiv.org//abs/2505.17132)

	Tanqiu Jiang, Jiacheng Liang, Rongyi Zhu, Jiawei Zhou, Fenglong Ma, Ting Wang

+ [Zebra-Llama: Towards Extremely Efficient Hybrid Models](https://arxiv.org//abs/2505.17272)

	Mingyu Yang, Mehdi Rezagholizadeh, Guihong Li, Vikram Appia, Emad Barsoum

+ [ECHO-LLaMA: Efficient Caching for High-Performance LLaMA Training](https://arxiv.org//abs/2505.17331)

	Maryam Dialameh, Rezaul Karim, Hossein Rajabzadeh, Omar Mohamed Awad, Hyock Ju Kwon, Boxing Chen, Walid Ahmed, Yang Liu

+ [Shape it Up! Restoring LLM Safety during Finetuning](https://arxiv.org//abs/2505.17196)

	ShengYun Peng, Pin-Yu Chen, Jianfeng Chi, Seongmin Lee, Duen Horng Chau

+ [Automated Capability Evaluation of Foundation Models](https://arxiv.org//abs/2505.17228)

	Arash Afkanpour, Omkar Dige, Fatemeh Tavakoli

+ [Towards medical AI misalignment: a preliminary study](https://arxiv.org//abs/2505.18212)

	Barbara Puccio, Federico Castagna, Allan Tucker, Pierangelo Veltri

+ [Walk&Retrieve: Simple Yet Effective Zero-shot Retrieval-Augmented Generation via Knowledge Graph Walks](https://arxiv.org//abs/2505.16849)

	Martin Böckling, Heiko Paulheim, Andreea Iana

+ [Guiding Giants: Lightweight Controllers for Weighted Activation Steering in LLMs](https://arxiv.org//abs/2505.20309)

	Amr Hegazy, Mostafa Elhoushi, Amr Alanwar

+ [Boosting In-Context Learning in LLMs Through the Lens of Classical Supervised Learning](https://arxiv.org//abs/2505.23783)

	Korel Gundem, Juncheng Dong, Dennis Zhang, Vahid Tarokh, Zhengling Qi

+ [Can ChatGPT Perform Image Splicing Detection? A Preliminary Study](https://arxiv.org//abs/2506.05358)

	Souradip Nath

+ [ACCORD: Autoregressive Constraint-satisfying Generation for COmbinatorial Optimization with Routing and Dynamic attention](https://arxiv.org//abs/2506.11052)

	Henrik Abgaryan, Tristan Cazenave, Ararat Harutyunyan

# 2025-05-21
+ [ModelingAgent: Bridging LLMs and Mathematical Modeling for Real-World Challenges](https://arxiv.org//abs/2505.15068)

	Cheng Qian, Hongyi Du, Hongru Wang, Xiusi Chen, Yuji Zhang, Avirup Sil, Chengxiang Zhai, Kathleen McKeown, Heng Ji

+ [lmgame-Bench: How Good are LLMs at Playing Games?](https://arxiv.org//abs/2505.15146)

	Lanxiang Hu, Mingjia Huo, Yuxuan Zhang, Haoyang Yu, Eric P. Xing, Ion Stoica, Tajana Rosing, Haojian Jin, Hao Zhang

+ [Generalised Probabilistic Modelling and Improved Uncertainty Estimation in Comparative LLM-as-a-judge](https://arxiv.org//abs/2505.15240)

	Yassir Fathullah, Mark J. F. Gales

+ [When Can Large Reasoning Models Save Thinking? Mechanistic Analysis of Behavioral Divergence in Reasoning](https://arxiv.org//abs/2505.15276)

	Rongzhi Zhu, Yi Liu, Zequn Sun, Yiwei Wang, Wei Hu

+ [When to Continue Thinking: Adaptive Thinking Mode Switching for Efficient Reasoning](https://arxiv.org//abs/2505.15400)

	Xiaoyun Zhang, Jingqing Ruan, Xing Ma, Yawen Zhu, Haodong Zhao, Hao Li, Jiansong Chen, Ke Zeng, Xunliang Cai

+ [Meta-Design Matters: A Self-Design Multi-Agent System](https://arxiv.org//abs/2505.14996)

	Zixuan Ke, Austin Xu, Yifei Ming, Xuan-Phi Nguyen, Caiming Xiong, Shafiq Joty

+ [Learning to Rank Chain-of-Thought: An Energy-Based Approach with Outcome Supervision](https://arxiv.org//abs/2505.14999)

	Eric Hanchen Jiang, Haozheng Luo, Shengyuan Pang, Xiaomin Li, Zhenting Qi, Hengli Li, Cheng-Fu Yang, Zongyu Lin, Xinfeng Li, Hao Xu, Kai-Wei Chang, Ying Nian Wu

+ [RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning](https://arxiv.org//abs/2505.15034)

	Kaiwen Zha, Zhengqi Gao, Maohao Shen, Zhang-Wei Hong, Duane S. Boning, Dina Katabi

+ [Denoising Concept Vectors with Sparse Autoencoders for Improved Language Model Steering](https://arxiv.org//abs/2505.15038)

	Haiyan Zhao, Xuansheng Wu, Fan Yang, Bo Shen, Ninghao Liu, Mengnan Du

+ [Self-GIVE: Associative Thinking from Limited Structured Knowledge for Enhanced Large Language Model Reasoning](https://arxiv.org//abs/2505.15062)

	Jiashu He, Jinxuan Fan, Bowen Jiang, Ignacio Houine, Dan Roth, Alejandro Ribeiro

+ [Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs](https://arxiv.org//abs/2505.15075)

	Hao Wang, Pinzhi Huang, Jihan Yang, Saining Xie, Daisuke Kawahara

+ [SUS backprop: linear backpropagation algorithm for long inputs in transformers](https://arxiv.org//abs/2505.15080)

	Sergey Pankov, Georges Harik

+ [Leveraging Large Language Models for Command Injection Vulnerability Analysis in Python: An Empirical Study on Popular Open-Source Projects](https://arxiv.org//abs/2505.15088)

	Yuxuan Wang, Jingshu Chen, Qingyang Wang

+ [DeFTX: Denoised Sparse Fine-Tuning for Zero-Shot Cross-Lingual Transfer](https://arxiv.org//abs/2505.15090)

	Sona Elza Simon, Preethi Jyothi

+ [Mechanistic evaluation of Transformers and state space models](https://arxiv.org//abs/2505.15105)

	Aryaman Arora, Neil Rathi, Nikil Roashan Selvam, Róbert Csórdas, Dan Jurafsky, Christopher Potts

+ [StepSearch: Igniting LLMs Search Ability via Step-Wise Proximal Policy Optimization](https://arxiv.org//abs/2505.15107)

	Ziliang Wang, Xuhui Zheng, Kang An, Cijun Ouyang, Jialu Cai, Yuhang Wang, Yichao Wu

+ [A Risk Taxonomy for Evaluating AI-Powered Psychotherapy Agents](https://arxiv.org//abs/2505.15108)

	Ian Steenstra, Timothy W. Bickmore

+ [An Empirical Study on Reinforcement Learning for Reasoning-Search Interleaved LLM Agents](https://arxiv.org//abs/2505.15117)

	Bowen Jin, Jinsung Yoon, Priyanka Kargupta, Sercan O. Arik, Jiawei Han

+ [The Unreasonable Effectiveness of Entropy Minimization in LLM Reasoning](https://arxiv.org//abs/2505.15134)

	Shivam Agarwal, Zimin Zhang, Lifan Yuan, Jiawei Han, Hao Peng

+ [BanditSpec: Adaptive Speculative Decoding via Bandit Algorithms](https://arxiv.org//abs/2505.15141)

	Yunlong Hou, Fengzhuo Zhang, Cunxiao Du, Xuan Zhang, Jiachun Pan, Tianyu Pang, Chao Du, Vincent Y. F. Tan, Zhuoran Yang

+ [Prolonged Reasoning Is Not All You Need: Certainty-Based Adaptive Routing for Efficient LLM/MLLM Reasoning](https://arxiv.org//abs/2505.15154)

	Jinghui Lu, Haiyang Yu, Siliang Xu, Shiwei Ran, Guozhi Tang, Siqi Wang, Bin Shan, Teng Fu, Hao Feng, Jingqun Tang, Han Wang, Can Huang

+ [R&D-Agent-Quant: A Multi-Agent Framework for Data-Centric Factors and Model Joint Optimization](https://arxiv.org//abs/2505.15155)

	Yuante Li, Xu Yang, Xiao Yang, Minrui Xu, Xisen Wang, Weiqing Liu, Jiang Bian

+ [ReflAct: World-Grounded Decision Making in LLM Agents via Goal-State Reflection](https://arxiv.org//abs/2505.15182)

	Jeonghye Kim, Sojeong Rhee, Minbeom Kim, Dohyung Kim, Sangmook Lee, Youngchul Sung, Kyomin Jung

+ [BountyBench: Dollar Impact of AI Agent Attackers and Defenders on Real-World Cybersecurity Systems](https://arxiv.org//abs/2505.15216)

	Andy K. Zhang, Joey Ji, Celeste Menders, Riya Dulepet, Thomas Qin, Ron Y. Wang, Junrong Wu, Kyleen Liao, Jiliang Li, Jinghan Hu, Sara Hong, Nardos Demilew, Shivatmica Murgai, Jason Tran, Nishka Kacheria, Ethan Ho, Denis Liu, Lauren McLane, Olivia Bruvik, Dai-Rong Han, Seungwoo Kim, Akhil Vyas, Cuiyuanxiu Chen, Ryan Li, Weiran Xu, Jonathan Z. Ye, Prerit Choudhary, Siddharth M. Bhatia, Vikram Sivashankar, Yuxuan Bao, Dawn Song, Dan Boneh, Daniel E. Ho, Percy Liang

+ [Adaptive Plan-Execute Framework for Smart Contract Security Auditing](https://arxiv.org//abs/2505.15242)

	Zhiyuan Wei, Jing Sun, Zijian Zhang, Zhe Hou, Zixiao Zhao

+ [Towards Explainable Temporal Reasoning in Large Language Models: A Structure-Aware Generative Framework](https://arxiv.org//abs/2505.15245)

	Zihao Jiang, Ben Liu, Miao Peng, Wenjie Xu, Yao Xiao, Zhenyan Shan, Min Peng

+ [Blind Spot Navigation: Evolutionary Discovery of Sensitive Semantic Concepts for LVLMs](https://arxiv.org//abs/2505.15265)

	Zihao Pan, Yu Tong, Weibin Wu, Jingyi Wang, Lifeng Chen, Zhe Zhao, Jiajia Wei, Yitong Qiao, Zibin Zheng

+ [Multiple Weaks Win Single Strong: Large Language Models Ensemble Weak Reinforcement Learning Agents into a Supreme One](https://arxiv.org//abs/2505.15306)

	Yiwen Song, Qianyue Hao, Qingmin Liao, Jian Yuan, Yong Li

+ [Trajectory Bellman Residual Minimization: A Simple Value-Based Method for LLM Reasoning](https://arxiv.org//abs/2505.15311)

	Yurun Yuan, Fan Chen, Zeyu Jia, Alexander Rakhlin, Tengyang Xie

+ [Your Language Model Can Secretly Write Like Humans: Contrastive Paraphrase Attacks on LLM-Generated Text Detectors](https://arxiv.org//abs/2505.15337)

	Hao Fang, Jiawei Kong, Tianqu Zhuang, Yixiang Qiu, Kuofeng Gao, Bin Chen, Shu-Tao Xia, Yaowei Wang, Min Zhang

+ [RePPL: Recalibrating Perplexity by Uncertainty in Semantic Propagation and Language Generation for Explainable QA Hallucination Detection](https://arxiv.org//abs/2505.15386)

	Yiming Huang, Junyan Zhang, Zihao Wang, Biquan Bie, Xuming Hu, Yi R. (May)Fung, Xinlei He

+ [Audio Jailbreak: An Open Comprehensive Benchmark for Jailbreaking Large Audio-Language Models](https://arxiv.org//abs/2505.15406)

	Zirui Song, Qian Jiang, Mingxuan Cui, Mingzhe Li, Lang Gao, Zeyu Zhang, Zixiang Xu, Yanbo Wang, Chenxi Wang, Guangxian Ouyang, Zhenhao Chen, Xiuying Chen

+ [Silent Leaks: Implicit Knowledge Extraction Attack on RAG Systems through Benign Queries](https://arxiv.org//abs/2505.15420)

	Yuhao Wang, Wenjie Qu, Yanze Jiang, Zichen Liu, Yue Liu, Shengfang Zhai, Yinpeng Dong, Jiaheng Zhang

+ [Set-LLM: A Permutation-Invariant LLM](https://arxiv.org//abs/2505.15433)

	Beni Egressy, Jan Stühmer

+ [Single LLM, Multiple Roles: A Unified Retrieval-Augmented Generation Framework Using Role-Specific Token Optimization](https://arxiv.org//abs/2505.15444)

	Yutao Zhu, Jiajie Jin, Hongjin Qian, Zheng Liu, Zhicheng Dou, Ji-Rong Wen

+ [Joint Flashback Adaptation for Forgetting-Resistant Instruction Tuning](https://arxiv.org//abs/2505.15467)

	Yukun Zhao, Lingyong Yan, Zhenyang Li, Shuaiqiang Wang, Zhumin Chen, Zhaochun Ren, Dawei Yin

+ [LFTF: Locating First and Then Fine-Tuning for Mitigating Gender Bias in Large Language Models](https://arxiv.org//abs/2505.15475)

	Zhanyue Qin, Yue Ding, Deyuan Liu, Qingbin Liu, Junxian Cai, Xi Chen, Zhiying Tu, Dianhui Chu, Cuiyun Gao, Dianbo Sui

+ [Protoknowledge Shapes Behaviour of LLMs in Downstream Tasks: Memorization and Generalization with Knowledge Graphs](https://arxiv.org//abs/2505.15501)

	Federico Ranaldi, Andrea Zugarini, Leonardo Ranaldi, Fabio Massimo Zanzotto

+ [Evaluate Bias without Manual Test Sets: A Concept Representation Perspective for LLMs](https://arxiv.org//abs/2505.15524)

	Lang Gao, Kaiyang Wan, Wei Liu, Chenxi Wang, Zirui Song, Zixiang Xu, Yanbo Wang, Veselin Stoyanov, Xiuying Chen

+ [Beyond Classification: Evaluating Diffusion Denoised Smoothing for Security-Utility Trade off](https://arxiv.org//abs/2505.15594)

	Yury Belousov, Brian Pulfer, Vitaliy Kinakh, Slava Voloshynovskiy

+ [From Problem-Solving to Teaching Problem-Solving: Aligning LLMs with Pedagogy using Reinforcement Learning](https://arxiv.org//abs/2505.15607)

	David Dinucu-Jianu, Jakub Macina, Nico Daheim, Ido Hakimi, Iryna Gurevych, Mrinmaya Sachan

+ [Learn to Reason Efficiently with Adaptive Length-based Reward Shaping](https://arxiv.org//abs/2505.15612)

	Wei Liu, Ruochen Zhou, Yiyun Deng, Yuzhen Huang, Junteng Liu, Yuntian Deng, Yizhe Zhang, Junxian He

+ [Listen to the Context: Towards Faithful Large Language Models for Retrieval Augmented Generation on Climate Questions](https://arxiv.org//abs/2505.15633)

	David Thulke, Jakob Kemmler, Christian Dugast, Hermann Ney

+ [UniErase: Unlearning Token as a Universal Erasure Primitive for Language Models](https://arxiv.org//abs/2505.15674)

	Miao Yu, Liang Lin, Guibin Zhang, Xinfeng Li, Junfeng Fang, Ningyu Zhang, Kun Wang, Yang Wang

+ [A Federated Splitting Framework for LLMs: Security, Efficiency, and Adaptability](https://arxiv.org//abs/2505.15683)

	Zishuai Zhang, Hainan Zhang, Jiaying Zheng, Ziwei Wang, Yongxin Tong, Jin Dong, Zhiming Zheng

+ [A Unified Theoretical Analysis of Private and Robust Offline Alignment: from RLHF to DPO](https://arxiv.org//abs/2505.15694)

	Xingyu Zhou, Yulian Wu, Francesco Orabona

+ [Shared Path: Unraveling Memorization in Multilingual LLMs through Language Similarities](https://arxiv.org//abs/2505.15722)

	Xiaoyu Luo, Yiyi Chen, Johannes Bjerva, Qiongxiu Li

+ [DEBATE, TRAIN, EVOLVE: Self Evolution of Language Model Reasoning](https://arxiv.org//abs/2505.15734)

	Gaurav Srivastava, Zhenyu Bi, Meng Lu, Xuan Wang

+ [Alignment Under Pressure: The Case for Informed Adversaries When Evaluating LLM Defenses](https://arxiv.org//abs/2505.15738)

	Xiaoxue Yang, Bozhidar Stevanoski, Matthieu Meeus, Yves-Alexandre de Montjoye

+ [HybridProver: Augmenting Theorem Proving with LLM-Driven Proof Synthesis and Refinement](https://arxiv.org//abs/2505.15740)

	Jilin Hu, Jianyu Zhang, Yongwang Zhao, Talia Ringer

+ [Scalable Defense against In-the-wild Jailbreaking Attacks with Safety Context Retrieval](https://arxiv.org//abs/2505.15753)

	Taiye Chen, Zeming Wei, Ang Li, Yisen Wang

+ [Soft Thinking: Unlocking the Reasoning Potential of LLMs in Continuous Concept Space](https://arxiv.org//abs/2505.15778)

	Zhen Zhang, Xuehai He, Weixiang Yan, Ao Shen, Chenyang Zhao, Shuohang Wang, Yelong Shen, Xin Eric Wang

+ [Large Language Models as Computable Approximations to Solomonoff Induction](https://arxiv.org//abs/2505.15784)

	Jun Wan, Lingrui Mei

+ [Long-Form Information Alignment Evaluation Beyond Atomic Facts](https://arxiv.org//abs/2505.15792)

	Danna Zheng, Mirella Lapata, Jeff Z. Pan

+ [VerifyBench: Benchmarking Reference-based Reward Systems for Large Language Models](https://arxiv.org//abs/2505.15801)

	Yuchen Yan, Jin Jiang, Zhenbang Ren, Yijun Li, Xudong Cai, Yang Liu, Xin Xu, Mengdi Zhang, Jian Shao, Yongliang Shen, Jun Xiao, Yueting Zhuang

+ [Language Specific Knowledge: Do Models Know Better in X than in English?](https://arxiv.org//abs/2505.14990)

	Ishika Agarwal, Nimet Beyza Bozdag, Dilek Hakkani-Tür

+ [Effective and Efficient Schema-aware Information Extraction Using On-Device Large Language Models](https://arxiv.org//abs/2505.14992)

	Zhihao Wen, Sheng Liang, Yaxiong Wu, Yongyue Zhang, Yong Liu

+ [Diagnosing our datasets: How does my language model learn clinical information?](https://arxiv.org//abs/2505.15024)

	Furong Jia, David Sontag, Monica Agrawal

+ [Improving the fact-checking performance of language models by relying on their entailment ability](https://arxiv.org//abs/2505.15050)

	Gaurav Kumar, Debajyoti Mazumder, Ayush Garg, Jasabanta Patro

+ [Lost in Benchmarks? Rethinking Large Language Model Benchmarking with Item Response Theory](https://arxiv.org//abs/2505.15055)

	Hongli Zhou, Hui Huang, Ziqing Zhao, Lvyuan Han, Huicheng Wang, Kehai Chen, Muyun Yang, Wei Bao, Jian Dong, Bing Xu, Conghui Zhu, Hailong Cao, Tiejun Zhao

+ [UrduFactCheck: An Agentic Fact-Checking Framework for Urdu with Evidence Boosting and Benchmarking](https://arxiv.org//abs/2505.15063)

	Sarfraz Ahmad, Hasan Iqbal, Momina Ahsan, Numaan Naeem, Muhammad Ahsan Riaz Khan, Arham Riaz, Muhammad Arslan Manzoor, Yuxia Wang, Preslav Nakov

+ [Can Large Language Models Understand Internet Buzzwords Through User-Generated Content](https://arxiv.org//abs/2505.15071)

	Chen Huang, Junkai Luo, Xinzuo Wang, Wenqiang Lei, Jiancheng Lv

+ [SciCUEval: A Comprehensive Dataset for Evaluating Scientific Context Understanding in Large Language Models](https://arxiv.org//abs/2505.15094)

	Jing Yu, Yuqi Tang, Kehua Feng, Mingyang Rao, Lei Liang, Zhiqiang Zhang, Mengshu Sun, Wen Zhang, Qiang Zhang, Keyan Ding, Huajun Chen

+ [RoT: Enhancing Table Reasoning with Iterative Row-Wise Traversals](https://arxiv.org//abs/2505.15110)

	Xuanliang Zhang, Dingzirui Wang, Keyan Xu, Qingfu Zhu, Wanxiang Che

+ [DUSK: Do Not Unlearn Shared Knowledge](https://arxiv.org//abs/2505.15209)

	Wonje Jeung, Sangyeon Yoon, Hyesoo Hong, Soeun Kim, Seungju Han, Youngjae Yu, Albert No

+ [Deliberation on Priors: Trustworthy Reasoning of Large Language Models on Knowledge Graphs](https://arxiv.org//abs/2505.15210)

	Jie Ma, Ning Qu, Zhitao Gao, Rui Xing, Jun Liu, Hongbin Pei, Jiang Xie, Linyun Song, Pinghui Wang, Jing Tao, Zhou Su

+ [R-TOFU: Unlearning in Large Reasoning Models](https://arxiv.org//abs/2505.15214)

	Sangyeon Yoon, Wonje Jeung, Albert No

+ [Fooling the LVLM Judges: Visual Biases in LVLM-Based Evaluation](https://arxiv.org//abs/2505.15249)

	Yerin Hwang, Dongryeol Lee, Kyungmin Min, Taegwan Kang, Yong-il Kim, Kyomin Jung

+ [MentalMAC: Enhancing Large Language Models for Detecting Mental Manipulation via Multi-Task Anti-Curriculum Distillation](https://arxiv.org//abs/2505.15255)

	Yuansheng Gao, Han Bao, Tong Zhang, Bin Li, Zonghui Wang, Wenzhi Chen

+ [When Less Language is More: Language-Reasoning Disentanglement Makes LLMs Better Multilingual Reasoners](https://arxiv.org//abs/2505.15257)

	Weixiang Zhao, Jiahe Guo, Yang Deng, Tongtong Wu, Wenxuan Zhang, Yulin Hu, Xingyu Sui, Yanyan Zhao, Wanxiang Che, Bing Qin, Tat-Seng Chua, Ting Liu

+ [AGENT-X: Adaptive Guideline-based Expert Network for Threshold-free AI-generated teXt detection](https://arxiv.org//abs/2505.15261)

	Jiatao Li, Mao Ye, Cheng Peng, Xunjian Yin, Xiaojun Wan

+ [Web-Shepherd: Advancing PRMs for Reinforcing Web Agents](https://arxiv.org//abs/2505.15277)

	Hyungjoo Chae, Sunghwan Kim, Junhee Cho, Seungone Kim, Seungjun Moon, Gyeom Hwangbo, Dongha Lim, Minjin Kim, Yeonjun Hwang, Minju Gwak, Dongwook Choi, Minseok Kang, Gwanhoon Im, ByeongUng Cho, Hyojun Kim, Jun Hee Han, Taeyoon Kwon, Minju Kim, Beong-woo Kwak, Dongjin Kang, Jinyoung Yeo

+ [Hallucinate at the Last in Long Response Generation: A Case Study on Long Document Summarization](https://arxiv.org//abs/2505.15291)

	Joonho Yang, Seunghyun Yoon, Hwan Chang, Byeongjeong Kim, Hwanhee Lee

+ [Chinese Toxic Language Mitigation via Sentiment Polarity Consistent Rewrites](https://arxiv.org//abs/2505.15297)

	Xintong Wang, Yixiao Liu, Jingheng Pan, Liang Ding, Longyue Wang, Chris Biemann

+ [Improving LLM First-Token Predictions in Multiple-Choice Question Answering via Prefilling Attack](https://arxiv.org//abs/2505.15323)

	Silvia Cappelletti, Tobia Poppi, Samuele Poppi, Zheng-Xin Yong, Diego Garcia-Olano, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara

+ [FlowKV: Enhancing Multi-Turn Conversational Coherence in LLMs via Isolated Key-Value Cache Management](https://arxiv.org//abs/2505.15347)

	Xiang Liu, Hong Chen, Xuming Hu, Xiaowen Chu

+ [Revealing Language Model Trajectories via Kullback-Leibler Divergence](https://arxiv.org//abs/2505.15353)

	Ryo Kishino, Yusuke Takase, Momose Oyama, Hiroaki Yamagiwa, Hidetoshi Shimodaira

+ [NL-Debugging: Exploiting Natural Language as an Intermediate Representation for Code Debugging](https://arxiv.org//abs/2505.15356)

	Weiming Zhang, Qingyao Li, Xinyi Dai, Jizheng Chen, Kounianhua Du, Weinan Zhang, Weiwen Liu, Yasheng Wang, Ruiming Tang, Yong Yu

+ [X-WebAgentBench: A Multilingual Interactive Web Benchmark for Evaluating Global Agentic System](https://arxiv.org//abs/2505.15372)

	Peng Wang, Ruihan Tao, Qiguang Chen, Mengkang Hu, Libo Qin

+ [An Empirical Study of the Anchoring Effect in LLMs: Existence, Mechanism, and Potential Mitigations](https://arxiv.org//abs/2505.15392)

	Yiming Huang, Biquan Bie, Zuqiu Na, Weilin Ruan, Songxin Lei, Yutao Yue, Xinlei He

+ [How Should We Enhance the Safety of Large Reasoning Models: An Empirical Study](https://arxiv.org//abs/2505.15404)

	Zhexin Zhang, Xian Qi Loye, Victor Shea-Jay Huang, Junxiao Yang, Qi Zhu, Shiyao Cui, Fei Mi, Lifeng Shang, Yingkang Wang, Hongning Wang, Minlie Huang

+ [Gated Integration of Low-Rank Adaptation for Continual Learning of Language Models](https://arxiv.org//abs/2505.15424)

	Yan-Shuo Liang, Wu-Jun Li

+ [Likelihood Variance as Text Importance for Resampling Texts to Map Language Models](https://arxiv.org//abs/2505.15428)

	Momose Oyama, Ryo Kishino, Hiroaki Yamagiwa, Hidetoshi Shimodaira

+ [Hunyuan-TurboS: Advancing Large Language Models through Mamba-Transformer Synergy and Adaptive Chain-of-Thought](https://arxiv.org//abs/2505.15431)

	Ao Liu, Botong Zhou, Can Xu, Chayse Zhou, ChenChen Zhang, Chengcheng Xu, Chenhao Wang, Decheng Wu, Dengpeng Wu, Dian Jiao, Dong Du, Dong Wang, Feng Zhang, Fengzong Lian, Guanghui Xu, Guanwei Zhang, Hai Wang, Haipeng Luo, Han Hu, Huilin Xu, Jiajia Wu, Jianchen Zhu, Jianfeng Yan, Jiaqi Zhu, Jihong Zhang, Jinbao Xue, Jun Xia, Junqiang Zheng, Kai Liu, Kai Zhang, Kai Zheng, Kejiao Li, Keyao Wang, Lan Jiang, Lixin Liu, Lulu Wu, Mengyuan Huang, Peijie Yu, Peiqi Wang, Qian Wang, Qianbiao Xiang, Qibin Liu, Qingfeng Sun, Richard Guo, Ruobing Xie, Saiyong Yang, Shaohua Chen, Shihui Hu, Shuai Li, Shuaipeng Li, Shuang Chen, Suncong Zheng, Tao Yang, Tian Zhang, Tinghao Yu, Weidong Han, Weijie Liu, Weijin Zhou, Weikang Wang, Wesleye Chen, Xiao Feng, Xiaoqin Ren, Xingwu Sun, Xiong Kuang, Xuemeng Huang, Xun Cao, Yanfeng Chen, Yang Du, Yang Zhen, Yangyu Tao, Yaping Deng, Yi Shen, Yigeng Hong, Yiqi Chen, Yiqing Huang, Yuchi Deng, Yue Mao, Yulong Wang, Yuyuan Zeng, Zenan Xu, Zhanhui Kang, Zhe Zhao, ZhenXiang Yan, Zheng Fang, Zhichao Hu, Zhongzhi Chen, Zhuoyu Li, Zongwei Li, Alex Yan, Ande Liang, Baitong Liu, Beiping Pan, Bin Xing, Binghong Wu, Bingxin Qu, Bolin Ni, Boyu Wu, Chen Li, Cheng Jiang, Cheng Zhang

+ [On the Generalization vs Fidelity Paradox in Knowledge Distillation](https://arxiv.org//abs/2505.15442)

	Suhas Kamasetty Ramesh, Ayan Sengupta, Tanmoy Chakraborty

+ [AdUE: Improving uncertainty estimation head for LoRA adapters in LLMs](https://arxiv.org//abs/2505.15443)

	Artem Zabolotnyi, Roman Makarov, Mile Mitrovic, Polina Proskura, Oleg Travkin, Roman Alferov, Alexey Zaytsev

+ [Teaching Language Models to Evolve with Users: Dynamic Profile Modeling for Personalized Alignment](https://arxiv.org//abs/2505.15456)

	Weixiang Zhao, Xingyu Sui, Yulin Hu, Jiahe Guo, Haixiao Liu, Biye Li, Yanyan Zhao, Bing Qin, Ting Liu

+ [CoLA: Collaborative Low-Rank Adaptation](https://arxiv.org//abs/2505.15471)

	Yiyun Zhou, Chang Yao, Jingyuan Chen

+ [KaFT: Knowledge-aware Fine-tuning for Boosting LLMs' Domain-specific Question-Answering Performance](https://arxiv.org//abs/2505.15480)

	Qihuang Zhong, Liang Ding, Xiantao Cai, Juhua Liu, Bo Du, Dacheng Tao

+ [Multilingual Test-Time Scaling via Initial Thought Transfer](https://arxiv.org//abs/2505.15508)

	Prasoon Bajpai, Tanmoy Chakraborty

+ [Do RAG Systems Suffer From Positional Bias?](https://arxiv.org//abs/2505.15561)

	Florin Cuconasu, Simone Filice, Guy Horowitz, Yoelle Maarek, Fabrizio Silvestri

+ [Can LLMs $\textit{understand}$ Math? -- Exploring the Pitfalls in Mathematical Reasoning](https://arxiv.org//abs/2505.15623)

	Tiasa Singha Roy, Aditeya Baral, Ayush Rajesh Jhaveri, Yusuf Baig

+ [Feature Extraction and Steering for Enhanced Chain-of-Thought Reasoning in Language Models](https://arxiv.org//abs/2505.15634)

	Zihao Li, Xu Wang, Yuzhe Yang, Ziyu Yao, Haoyi Xiong, Mengnan Du

+ [Be Careful When Fine-tuning On Open-Source LLMs: Your Fine-tuning Data Could Be Secretly Stolen!](https://arxiv.org//abs/2505.15656)

	Zhexin Zhang, Yuhao Sun, Junxiao Yang, Shiyao Cui, Hongning Wang, Minlie Huang

+ [ThinkLess: A Training-Free Inference-Efficient Method for Reducing Reasoning Redundancy](https://arxiv.org//abs/2505.15684)

	Gengyang Li, Yifeng Gao, Yuming Li, Yunfang Wu

+ ["Alexa, can you forget me?" Machine Unlearning Benchmark in Spoken Language Understanding](https://arxiv.org//abs/2505.15700)

	Alkis Koudounas, Claudio Savelli, Flavio Giobergia, Elena Baralis

+ [LyapLock: Bounded Knowledge Preservation in Sequential Large Language Model Editing](https://arxiv.org//abs/2505.15702)

	Peng Wang, Biyu Zhou, Xuehai Tang, Jizhong Han, Songlin Hu

+ [Advancing LLM Safe Alignment with Safety Representation Ranking](https://arxiv.org//abs/2505.15710)

	Tianqi Du, Zeming Wei, Quan Chen, Chenheng Zhang, Yisen Wang

+ [TurnaboutLLM: A Deductive Reasoning Benchmark from Detective Games](https://arxiv.org//abs/2505.15712)

	Yuan Yuan, Muyu He, Muhammad Adil Shahid, Jiani Huang, Ziyang Li, Li Zhang

+ [Beyond Empathy: Integrating Diagnostic and Therapeutic Reasoning with Large Language Models for Mental Health Counseling](https://arxiv.org//abs/2505.15715)

	He Hu, Yucheng Zhou, Juzheng Si, Qianning Wang, Hengheng Zhang, Fuji Ren, Fei Ma, Laizhong Cui

+ [Beyond Hard and Soft: Hybrid Context Compression for Balancing Local and Global Information Retention](https://arxiv.org//abs/2505.15774)

	Huanxuan Liao, Wen Hu, Yao Xu, Shizhu He, Jun Zhao, Kang Liu

+ [dKV-Cache: The Cache for Diffusion Language Models](https://arxiv.org//abs/2505.15781)

	Xinyin Ma, Runpeng Yu, Gongfan Fang, Xinchao Wang

+ [Reverse Engineering Human Preferences with Reinforcement Learning](https://arxiv.org//abs/2505.15795)

	Lisa Alazraki, Tan Yi-Chern, Jon Ander Campos, Maximilian Mozes, Marek Rei, Max Bartolo

+ [Keep Security! Benchmarking Security Policy Preservation in Large Language Model Contexts Against Indirect Attacks in Question Answering](https://arxiv.org//abs/2505.15805)

	Hwan Chang, Yumin Kim, Yonghyun Jun, Hwanhee Lee

+ [The Atlas of In-Context Learning: How Attention Heads Shape In-Context Retrieval Augmentation](https://arxiv.org//abs/2505.15807)

	Patrick Kahardipraja, Reduan Achtibat, Thomas Wiegand, Wojciech Samek, Sebastian Lapuschkin

+ [Learning to Reason via Mixture-of-Thought for Logical Reasoning](https://arxiv.org//abs/2505.15817)

	Tong Zheng, Lichang Chen, Simeng Han, R. Thomas McCoy, Heng Huang

+ [ALN-P3: Unified Language Alignment for Perception, Prediction, and Planning in Autonomous Driving](https://arxiv.org//abs/2505.15158)

	Yunsheng Ma, Burhaneddin Yaman, Xin Ye, Mahmut Yurt, Jingru Luo, Abhirup Mallik, Ziran Wang, Liu Ren

+ [ReGUIDE: Data Efficient GUI Grounding via Spatial Reasoning and Search](https://arxiv.org//abs/2505.15259)

	Hyunseok Lee, Jeonghoon Kim, Beomjun Kim, Jihoon Tack, Chansong Jo, Jaehong Lee, Cheonbok Park, Sookyo In, Jinwoo Shin, Kang Min Yoo

+ [AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving](https://arxiv.org//abs/2505.15298)

	Kangan Qian, Sicong Jiang, Yang Zhong, Ziang Luo, Zilin Huang, Tianze Zhu, Kun Jiang, Mengmeng Yang, Zheng Fu, Jinyu Miao, Yining Shi, He Zhe Lim, Li Liu, Tianbao Zhou, Hongyi Wang, Huang Yu, Yifei Hu, Guang Li, Guang Chen, Hao Ye, Lijun Sun, Diange Yang

+ [AI vs. Human Judgment of Content Moderation: LLM-as-a-Judge and Ethics-Based Response Refusals](https://arxiv.org//abs/2505.15365)

	Stefan Pasch

+ [Visual Thoughts: A Unified Perspective of Understanding Multimodal Chain-of-Thought](https://arxiv.org//abs/2505.15510)

	Zihui Cheng, Qiguang Chen, Xiao Xu, Jiaqi Wang, Weiyun Wang, Hao Fei, Yidong Wang, Alex Jinpeng Wang, Zhi Chen, Wanxiang Che, Libo Qin

+ [Mechanistic Insights into Grokking from the Embedding Layer](https://arxiv.org//abs/2505.15624)

	H.V.AlquBoj, Hilal AlQuabeh, Velibor Bojkovic, Munachiso Nwadike, Kentaro Inui

+ [HDLxGraph: Bridging Large Language Models and HDL Repositories via HDL Graph Databases](https://arxiv.org//abs/2505.15701)

	Pingqing Zheng, Jiayin Qin, Fuqi Zhang, Shang Wu, Yu Cao, Caiwen Ding, Yang (Katie)Zhao

+ [Towards Zero-Shot Differential Morphing Attack Detection with Multimodal Large Language Models](https://arxiv.org//abs/2505.15332)

	Ria Shekhawat, Hailin Li, Raghavendra Ramachandra, Sushma Venkatesh

+ [LENS: Multi-level Evaluation of Multimodal Reasoning with Large Language Models](https://arxiv.org//abs/2505.15616)

	Ruilin Yao, Bo Zhang, Jirui Huang, Xinwei Long, Yifang Zhang, Tianyu Zou, Yufei Wu, Shichao Su, Yifan Xu, Wenxi Zeng, Zhaoyu Yang, Guoyou Li, Shilan Zhang, Zichan Li, Yaxiong Chen, Shengwu Xiong, Peng Xu, Jiajun Zhang, Bowen Zhou, David Clifton, Luc Van Gool

+ [STAR-R1: Spacial TrAnsformation Reasoning by Reinforcing Multimodal LLMs](https://arxiv.org//abs/2505.15804)

	Zongzhao Li, Zongyang Ma, Mingze Li, Songyou Li, Yu Rong, Tingyang Xu, Ziqi Zhang, Deli Zhao, Wenbing Huang

+ [Harnessing Large Language Models Locally: Empirical Results and Implications for AI PC](https://arxiv.org//abs/2505.15030)

	Qingyu Song, Peiyu Liao, Wenqian Zhao, Yiwen Wang, Shoubo Hu, Hui-Ling Zhen, Ning Jiang, Mingxuan Yuan

+ [Cost-aware LLM-based Online Dataset Annotation](https://arxiv.org//abs/2505.15101)

	Eray Can Elumar, Cem Tekin, Osman Yagan

+ [SSR: Speculative Parallel Scaling Reasoning in Test-time](https://arxiv.org//abs/2505.15340)

	Yuanlin Chu, Bo Wang, Xiang Liu, Hong Chen, Aiwei Liu, Xuming Hu

+ [Short-Range Dependency Effects on Transformer Instability and a Decomposed Attention Solution](https://arxiv.org//abs/2505.15548)

	Suvadeep Hajra

+ [An Efficient Private GPT Never Autoregressively Decodes](https://arxiv.org//abs/2505.15252)

	Zhengyi Li, Yue Guan, Kang Yang, Yu Feng, Ning Liu, Yu Yu, Jingwen Leng, Minyi Guo

+ [Causal LLM Routing: End-to-End Regret Minimization from Observational Data](https://arxiv.org//abs/2505.16037)

	Asterios Tsiourvas, Wei Sun, Georgia Perakis

+ [How Memory Management Impacts LLM Agents: An Empirical Study of Experience-Following Behavior](https://arxiv.org//abs/2505.16067)

	Zidi Xiong, Yuping Lin, Wenya Xie, Pengfei He, Jiliang Tang, Himabindu Lakkaraju, Zhen Xiang

+ [GRIT: Teaching MLLMs to Think with Images](https://arxiv.org//abs/2505.15879)

	Yue Fan, Xuehai He, Diji Yang, Kaizhi Zheng, Ching-Chen Kuo, Yuting Zheng, Sravana Jyothi Narayanaraju, Xinze Guan, Xin Eric Wang

+ [Extracting Probabilistic Knowledge from Large Language Models for Bayesian Network Parameterization](https://arxiv.org//abs/2505.15918)

	Aliakbar Nafar, Kristen Brent Venable, Zijun Cui, Parisa Kordjamshidi

+ [Pre-training Large Memory Language Models with Internal and External Knowledge](https://arxiv.org//abs/2505.15962)

	Linxi Zhao, Sofian Zalouk, Christian K. Belardi, Justin Lovelace, Jin Peng Zhou, Kilian Q. Weinberger, Yoav Artzi, Jennifer J. Sun

+ [Causal Interventions Reveal Shared Structure Across English Filler-Gap Constructions](https://arxiv.org//abs/2505.16002)

	Sasha Boguraev, Christopher Potts, Kyle Mahowald

+ [SLMEval: Entropy-Based Calibration for Human-Aligned Evaluation of Large Language Models](https://arxiv.org//abs/2505.16003)

	Roland Daynauth, Christopher Clarke, Krisztian Flautner, Lingjia Tang, Jason Mars

+ [Interpretability Illusions with Sparse Autoencoders: Evaluating Robustness of Concept Representations](https://arxiv.org//abs/2505.16004)

	Aaron J. Li, Suraj Srinivas, Usha Bhalla, Himabindu Lakkaraju

+ [LAGO: Few-shot Crosslingual Embedding Inversion Attacks via Language Similarity-Aware Graph Optimization](https://arxiv.org//abs/2505.16008)

	Wenrui Yu, Yiyi Chen, Johannes Bjerva, Sokol Kosta, Qiongxiu Li

+ [NOVER: Incentive Training for Language Models via Verifier-Free Reinforcement Learning](https://arxiv.org//abs/2505.16022)

	Wei Liu, Siya Qi, Xinyu Wang, Chen Qian, Yali Du, Yulan He

+ [Not All Models Suit Expert Offloading: On Local Routing Consistency of Mixture-of-Expert Models](https://arxiv.org//abs/2505.16056)

	Jingcong Liang, Siyuan Wang, Miren Tian, Yitong Li, Duyu Tang, Zhongyu Wei

+ [Merge to Mix: Mixing Datasets via Model Merging](https://arxiv.org//abs/2505.16066)

	Zhixu Silvia Tao, Kasper Vinken, Hao-Wei Yeh, Avi Cooper, Xavier Boix

+ [ThinkRec: Thinking-based recommendation via LLM](https://arxiv.org//abs/2505.15091)

	Qihang Yu, Kairui Fu, Shengyu Zhang, Zheqi Lv, Fan Wu, Fei Wu

+ [Aligning Dialogue Agents with Global Feedback via Large Language Model Reward Decomposition](https://arxiv.org//abs/2505.15922)

	Dong Won Lee, Hae Won Park, Cynthia Breazeal, Louis-Philippe Morency

+ [Training Step-Level Reasoning Verifiers with Formal Verification Tools](https://arxiv.org//abs/2505.15960)

	Ryo Kamoi, Yusen Zhang, Nan Zhang, Sarkar Snigdha Sarathi Das, Rui Zhang

+ [Ranking Free RAG: Replacing Re-ranking with Selection in RAG for Sensitive Domains](https://arxiv.org//abs/2505.16014)

	Yash Saxena, Anpur Padia, Mandar S Chaudhary, Kalpa Gunaratna, Srinivasan Parthasarathy, Manas Gaur

+ [Prototypical Human-AI Collaboration Behaviors from LLM-Assisted Writing in the Wild](https://arxiv.org//abs/2505.16023)

	Sheshera Mysore, Debarati Das, Hancheng Cao, Bahareh Sarrafzadeh

+ [InfoDeepSeek: Benchmarking Agentic Information Seeking for Retrieval-Augmented Generation](https://arxiv.org//abs/2505.15872)

	Yunjia Xi, Jianghao Lin, Menghui Zhu, Yongzhao Xiao, Zhuoying Ou, Jiaqi Liu, Tong Wan, Bo Chen, Weiwen Liu, Yasheng Wang, Ruiming Tang, Weinan Zhang, Yong Yu

+ [ViQAgent: Zero-Shot Video Question Answering via Agent with Open-Vocabulary Grounding Validation](https://arxiv.org//abs/2505.15928)

	Tony Montes, Fernando Lozano

+ [MAPS: A Multilingual Benchmark for Global Agent Performance and Security](https://arxiv.org//abs/2505.15935)

	Omer Hofman, Oren Rachmil, Shamik Bose, Vikas Pahuja, Jonathan Brokman, Toshiya Shimizu, Trisha Starostina, Kelly Marchisio, Seraphina Goldfarb-Tarrant, Roman Vainshtein

+ [Aug2Search: Enhancing Facebook Marketplace Search with LLM-Generated Synthetic Data Augmentation](https://arxiv.org//abs/2505.16065)

	Ruijie Xi, He Ba, Hao Yuan, Rishu Agrawal, Arul Prakash

+ [How Do Large Vision-Language Models See Text in Image? Unveiling the Distinctive Role of OCR Heads](https://arxiv.org//abs/2505.15865)

	Ingeol Baek, Hwan Chang, Sunghyun Ryu, Hwanhee Lee

+ [Decouple and Orthogonalize: A Data-Free Framework for LoRA Merging](https://arxiv.org//abs/2505.15875)

	Shenghe Zheng, Hongzhi Wang, Chenyu Huang, Xiaohui Wang, Tao Chen, Jiayuan Fan, Shuyue Hu, Peng Ye

+ [Is (Selective) Round-To-Nearest Quantization All You Need?](https://arxiv.org//abs/2505.15909)

	Alex Kogan

+ [CoT Information: Improved Sample Complexity under Chain-of-Thought Supervision](https://arxiv.org//abs/2505.15927)

	Awni Altabaa, Omar Montasser, John Lafferty

+ [CRAKEN: Cybersecurity LLM Agent with Knowledge-Based Execution](https://arxiv.org//abs/2505.17107)

	Minghao Shao, Haoran Xi, Nanda Rani, Meet Udeshi, Venkata Sai Charan Putrevu, Kimberly Milner, Brendan Dolan-Gavitt, Sandeep Kumar Shukla, Prashanth Krishnamurthy, Farshad Khorrami, Ramesh Karri, Muhammad Shafique

+ [Swarm Intelligence Enhanced Reasoning: A Density-Driven Framework for LLM-Based Multi-Agent Optimization](https://arxiv.org//abs/2505.17115)

	Ying Zhu, Heng Zhou, Rui Su, Peiqin Zhuang, Lei Bai

+ [From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning](https://arxiv.org//abs/2505.17117)

	Chen Shani, Dan Jurafsky, Yann LeCun, Ravid Shwartz-Ziv

+ [NEXT-EVAL: Next Evaluation of Traditional and LLM Web Data Record Extraction](https://arxiv.org//abs/2505.17125)

	Soyeon Kim, Namhee Kim, Yeonwoo Jeong

+ [Are LLMs reliable? An exploration of the reliability of large language models in clinical note generation](https://arxiv.org//abs/2505.17095)

	Kristine Ann M. Carandang, Jasper Meynard P. Araña, Ethan Robert A. Casin, Christopher P. Monterola, Daniel Stanley Y. Tan, Jesus Felix B. Valenzuela, Christian M. Alis

+ [TACO: Enhancing Multimodal In-context Learning via Task Mapping-Guided Sequence Configuration](https://arxiv.org//abs/2505.17098)

	Yanshu Li, Tian Yun, Jianjiang Yang, Pinyuan Feng, Jinfa Huang, Ruixiang Tang

+ [Any Large Language Model Can Be a Reliable Judge: Debiasing with a Reasoning-based Bias Detector](https://arxiv.org//abs/2505.17100)

	Haoyan Yang, Runxue Bao, Cao Xiao, Jun Ma, Parminder Bhatia, Shangqian Gao, Taha Kass-Hout

+ [An approach to identify the most semantically informative deep representations of text and images](https://arxiv.org//abs/2505.17101)

	Santiago Acevedo, Andrea Mascaretti, Riccardo Rende, Matéo Mahaut, Marco Baroni, Alessandro Laio

+ [RRTL: Red Teaming Reasoning Large Language Models in Tool Learning](https://arxiv.org//abs/2505.17106)

	Yifei Liu, Yu Cui, Haibin Zhang

+ [Multi-Modality Expansion and Retention for LLMs through Parameter Merging and Decoupling](https://arxiv.org//abs/2505.17110)

	Junlin Li, Guodong DU, Jing Li, Sim Kuan Goh, Wenya Wang, Yequan Wang, Fangming Liu, Ho-Kin Tang, Saleh Alharbi, Daojing He, Min Zhang

+ [Cultural Value Alignment in Large Language Models: A Prompt-based Analysis of Schwartz Values in Gemini, ChatGPT, and DeepSeek](https://arxiv.org//abs/2505.17112)

	Robin Segerer

+ [Comparative Evaluation of Prompting and Fine-Tuning for Applying Large Language Models to Grid-Structured Geospatial Data](https://arxiv.org//abs/2505.17116)

	Akash Dhruv, Yangxinyu Xie, Jordan Branham, Tanwi Mallick

+ [After Retrieval, Before Generation: Enhancing the Trustworthiness of Large Language Models in RAG](https://arxiv.org//abs/2505.17118)

	Xinbang Dai, Huikang Hu, Yuncheng Hua, Jiaqi Li, Yongrui Chen, Rihui Jin, Nan Hu, Guilin Qi

+ [Systematic Evaluation of Machine-Generated Reasoning and PHQ-9 Labeling for Depression Detection Using Large Language Models](https://arxiv.org//abs/2505.17119)

	Zongru Shao, Xin Wang, Zhanyang Liu, Chenhan Wang, K.P. Subbalakshmi

+ [Self-Interpretability: LLMs Can Describe Complex Internal Processes that Drive Their Decisions, and Improve with Training](https://arxiv.org//abs/2505.17120)

	Dillon Plunkett, Adam Morris, Keerthi Reddy, Jorge Morales

+ [Shallow Preference Signals: Large Language Model Aligns Even Better with Truncated Data?](https://arxiv.org//abs/2505.17122)

	Xuan Qi, Jiahao Qiu, Xinzhe Juan, Yue Wu, Mengdi Wang

+ [MTR-Bench: A Comprehensive Benchmark for Multi-Turn Reasoning Evaluation](https://arxiv.org//abs/2505.17123)

	Xiaoyuan Li, Keqin Bao, Yubo Ma, Moxin Li, Wenjie Wang, Rui Men, Yichang Zhang, Fuli Feng, Dayiheng Liu, Junyang Lin

+ [Conformal Language Model Reasoning with Coherent Factuality](https://arxiv.org//abs/2505.17126)

	Maxon Rubin-Toles, Maya Gambhir, Keshav Ramji, Aaron Roth, Surbhi Goel

+ [CAMA: Enhancing Multimodal In-Context Learning with Context-Aware Modulated Attention](https://arxiv.org//abs/2505.17097)

	Yanshu Li, JianJiang Yang, Bozheng Li, Ruixiang Tang

+ [Mitigating Cyber Risk in the Age of Open-Weight LLMs: Policy Gaps and Technical Realities](https://arxiv.org//abs/2505.17109)

	Alfonso de Gregorio

+ [Pixels Versus Priors: Controlling Knowledge Priors in Vision-Language Models through Visual Counterfacts](https://arxiv.org//abs/2505.17127)

	Michal Golovanevsky, William Rudman, Michael Lepori, Amir Bar, Ritambhara Singh, Carsten Eickhoff

+ [Exploring the Limits of Vision-Language-Action Manipulations in Cross-task Generalization](https://arxiv.org//abs/2505.15660)

	Jiaming Zhou, Ke Ye, Jiayi Liu, Teli Ma, Zifan Wang, Ronghe Qiu, Kun-Yu Lin, Zhilin Zhao, Junwei Liang

+ [SIMCOPILOT: Evaluating Large Language Models for Copilot-Style Code Generation](https://arxiv.org//abs/2505.21514)

	Mingchao Jiang, Abhinav Jain, Sophia Zorek, Chris Jermaine

+ [Scaling Physical Reasoning with the PHYSICS Dataset](https://arxiv.org//abs/2506.00022)

	Shenghe Zheng, Qianjia Cheng, Junchi Yao, Mengsong Wu, haonan he, Ning Ding, Yu Cheng, Shuyue Hu, Lei Bai, Dongzhan Zhou, Ganqu Cui, Peng Ye

+ [Boost Post-Training Quantization via Null Space Optimization for Large Language Models](https://arxiv.org//abs/2506.11044)

	Jiaqi Zhao, Miao Zhang, Weili Guan, Liqiang Nie

+ [Procedural Environment Generation for Tool-Use Agents](https://arxiv.org//abs/2506.11045)

	Michael Sullivan, Mareike Hartmann, Alexander Koller

+ [The Effects of Data Augmentation on Confidence Estimation for LLMs](https://arxiv.org//abs/2506.11046)

	Rui Wang, Renyu Zhu, Minmin Lin, Runze Wu, Tangjie Lv, Changjie Fan, Haobo Wang

+ [FlexQuant: A Flexible and Efficient Dynamic Precision Switching Framework for LLM Quantization](https://arxiv.org//abs/2506.12024)

	Fangxin Liu, Zongwu Wang, JinHong Xia, Junping Zhao, Jian Liu, Haibing Guan, Li Jiang

# 2025-05-20
+ [Multimodal RAG-driven Anomaly Detection and Classification in Laser Powder Bed Fusion using Large Language Models](https://arxiv.org//abs/2505.13828)

	Kiarash Naghavi Khanghah, Zhiling Chen, Lela Romeo, Qian Yang, Rajiv Malhotra, Farhad Imani, Hongyi Xu

+ [Efficient Agent Training for Computer Use](https://arxiv.org//abs/2505.13909)

	Yanheng He, Jiahe Jin, Pengfei Liu

+ [DrugPilot: LLM-based Parameterized Reasoning Agent for Drug Discovery](https://arxiv.org//abs/2505.13940)

	Kun Li, Zhennan Wu, Shoupeng Wang, Wenbin Hu

+ [Visual Instruction Bottleneck Tuning](https://arxiv.org//abs/2505.13946)

	Changdae Oh, Jiatong Li, Shawn Im, Yixuan Li

+ [Divide by Question, Conquer by Agent: SPLIT-RAG with Question-Driven Graph Partitioning](https://arxiv.org//abs/2505.13994)

	Ruiyi Yang, Hao Xue, Imran Razzak, Hakim Hacid, Flora D. Salim

+ [RL of Thoughts: Navigating LLM Reasoning with Inference-time Reinforcement Learning](https://arxiv.org//abs/2505.14140)

	Qianyue Hao, Sibo Li, Jian Yuan, Yong Li

+ [s3: You Don't Need That Much Data to Train a Search Agent via RL](https://arxiv.org//abs/2505.14146)

	Pengcheng Jiang, Xueqiang Xu, Jiacheng Lin, Jinfeng Xiao, Zifeng Wang, Jimeng Sun, Jiawei Han

+ [SHARP: Synthesizing High-quality Aligned Reasoning Problems for Large Reasoning Models Reinforcement Learning](https://arxiv.org//abs/2505.14147)

	Xiong Jun Wu, Zhenduo Zhang, ZuJie Wen, Zhiqiang Zhang, Wang Ren, Lei Shi, Cai Chen, Deng Zhao, Dingnan Jin, Qing Cui, Jun Zhou

+ [MM-Agent: LLM as Agents for Real-world Mathematical Modeling Problem](https://arxiv.org//abs/2505.14148)

	Fan Liu, Zherui Yang, Cancheng Liu, Tianrui Song, Xiaofeng Gao, Hao Liu

+ [DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation](https://arxiv.org//abs/2505.14163)

	He Wang, Alexander Hanbo Li, Yiqun Hu, Sheng Zhang, Hideo Kobayashi, Jiani Zhang, Henry Zhu, Chung-Wei Hang, Patrick Ng

+ [Reinforcement Learning vs. Distillation: Understanding Accuracy and Capability in LLM Reasoning](https://arxiv.org//abs/2505.14216)

	Minwu Kim, Anubhav Shrestha, Safal Shrestha, Aadim Nepal, Keith Ross

+ [EVA: Red-Teaming GUI Agents via Evolving Indirect Prompt Injection](https://arxiv.org//abs/2505.14289)

	Yijie Lu, Tianjie Ju, Manman Zhao, Xinbei Ma, Yuan Guo, ZhuoSheng Zhang

+ [SafetyNet: Detecting Harmful Outputs in LLMs by Modeling and Monitoring Deceptive Behaviors](https://arxiv.org//abs/2505.14300)

	Maheep Chaudhary, Fazl Barez

+ [SCAN: Semantic Document Layout Analysis for Textual and Visual Retrieval-Augmented Generation](https://arxiv.org//abs/2505.14381)

	Yuyang Dong, Nobuhiro Ueda, Krisztián Boros, Daiki Ito, Takuya Sera, Masafumi Oyamada

+ [Beyond the First Error: Process Reward Models for Reflective Mathematical Reasoning](https://arxiv.org//abs/2505.14391)

	Zhaohui Yang, Chenghua He, Xiaowen Shi, Linjing Li, Qiyue Yin, Shihong Deng, Daxin Jiang

+ [Causal Cartographer: From Mapping to Reasoning Over Counterfactual Worlds](https://arxiv.org//abs/2505.14396)

	Gaël Gendron, Jože M. Rožanec, Michael Witbrock, Gillian Dobbie

+ [Unearthing Gems from Stones: Policy Optimization with Negative Sample Augmentation for LLM Reasoning](https://arxiv.org//abs/2505.14403)

	Zhaohui Yang, Shilei Jiang, Chen Hu, Linjing Li, Shihong Deng, Daxin Jiang

+ [PRL: Prompts from Reinforcement Learning](https://arxiv.org//abs/2505.14412)

	Paweł Batorski, Adrian Kosmala, Paul Swoboda

+ [Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach](https://arxiv.org//abs/2505.14479)

	Oren Sultan, Eitan Stern, Dafna Shahaf

+ [Reasoning Models Better Express Their Confidence](https://arxiv.org//abs/2505.14489)

	Dongkeun Yoon, Seungone Kim, Sohee Yang, Sunkyoung Kim, Soyeon Kim, Yongil Kim, Eunbi Choi, Yireun Kim, Minjoon Seo

+ [Guarded Query Routing for Large Language Models](https://arxiv.org//abs/2505.14524)

	Richard Šléher, William Brach, Tibor Sloboda, Kristián Košťál, Lukas Galke

+ [Agent Context Protocols Enhance Collective Inference](https://arxiv.org//abs/2505.14569)

	Devansh Bhardwaj, Arjun Beniwal, Shreyas Chaudhari, Ashwin Kalyan, Tanmay Rajpurohit, Karthik R. Narasimhan, Ameet Deshpande, Vishvak Murahari

+ [Let LLMs Break Free from Overthinking via Self-Braking Tuning](https://arxiv.org//abs/2505.14604)

	Haoran Zhao, Yuchen Yan, Yongliang Shen, Haolei Xu, Wenqi Zhang, Kaitao Song, Jian Shao, Weiming Lu, Jun Xiao, Yueting Zhuang

+ [SATBench: Benchmarking LLMs' Logical Reasoning via Automated Puzzle Generation from SAT Formulas](https://arxiv.org//abs/2505.14615)

	Anjiang Wei, Yuheng Wu, Yingjia Wan, Tarun Suresh, Huanmi Tan, Zhanke Zhou, Sanmi Koyejo, Ke Wang, Alex Aiken

+ [Debating for Better Reasoning: An Unsupervised Multimodal Approach](https://arxiv.org//abs/2505.14627)

	Ashutosh Adhikari, Mirella Lapata

+ [Cost-Augmented Monte Carlo Tree Search for LLM-Assisted Planning](https://arxiv.org//abs/2505.14656)

	Zihao Zhang, Fei Liu

+ [SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment](https://arxiv.org//abs/2505.14667)

	Wonje Jeung, Sangyeon Yoon, Minsuk Kahng, Albert No

+ [ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions](https://arxiv.org//abs/2505.14668)

	Bufang Yang, Lilin Xu, Liekang Zeng, Kaiwei Liu, Siyang Jiang, Wenrui Lu, Hongkai Chen, Xiaofan Jiang, Guoliang Xing, Zhenyu Yan

+ [Two Experts Are All You Need for Steering Thinking: Reinforcing Cognitive Effort in MoE Reasoning Models Without Additional Training](https://arxiv.org//abs/2505.14681)

	Mengru Wang, Xingyu Chen, Yue Wang, Zhiwei He, Jiahao Xu, Tian Liang, Qiuzhi Liu, Yunzhi Yao, Wenxuan Wang, Ruotian Ma, Haitao Mi, Ningyu Zhang, Zhaopeng Tu, Xiaolong Li, Dong Yu

+ [Preference Learning with Lie Detectors can Induce Honesty or Evasion](https://arxiv.org//abs/2505.13787)

	Chris Cundy, Adam Gleave

+ [Interpretable Traces, Unexpected Outcomes: Investigating the Disconnect in Trace-Based Knowledge Distillation](https://arxiv.org//abs/2505.13792)

	Siddhant Bhambri, Upasana Biswas, Subbarao Kambhampati

+ [Structured Agent Distillation for Large Language Model](https://arxiv.org//abs/2505.13820)

	Jun Liu, Zhenglun Kong, Peiyan Dong, Changdi Yang, Tianqi Li, Hao Tang, Geng Yuan, Wei Niu, Wenbin Zhang, Pu Zhao, Xue Lin, Dong Huang, Yanzhi Wang

+ [Do Language Models Use Their Depth Efficiently?](https://arxiv.org//abs/2505.13898)

	Róbert Csordás, Christopher D. Manning, Christopher Potts

+ [APEX: Empowering LLMs with Physics-Based Task Planning for Real-time Insight](https://arxiv.org//abs/2505.13921)

	Wanjing Huang, Weixiang Yan, Zhen Zhang, Ambuj Singh

+ [Memory-Centric Embodied Question Answer](https://arxiv.org//abs/2505.13948)

	Mingliang Zhai, Zhi Gao, Yuwei Wu, Yunde Jia

+ [FlashThink: An Early Exit Method For Efficient Reasoning](https://arxiv.org//abs/2505.13949)

	Guochao Jiang, Guofeng Quan, Zepeng Ding, Ziqin Luo, Dixuan Wang, Zheng Hu

+ [When LLMs meet open-world graph learning: a new perspective for unlabeled data uncertainty](https://arxiv.org//abs/2505.13989)

	Yanzhe Wen, Xunkai Li, Qi Zhang, Zhu Lei, Guang Zeng, Rong-Hua Li, Guoren Wang

+ [Social Sycophancy: A Broader Understanding of LLM Sycophancy](https://arxiv.org//abs/2505.13995)

	Myra Cheng, Sunny Yu, Cinoo Lee, Pranav Khadpe, Lujain Ibrahim, Dan Jurafsky

+ [From Unaligned to Aligned: Scaling Multilingual LLMs with Multi-Way Parallel Corpora](https://arxiv.org//abs/2505.14045)

	Yingli Shen, Wen Lai, Shuo Wang, Kangyang Luo, Alexander Fraser, Maosong Sun

+ [Field Matters: A lightweight LLM-enhanced Method for CTR Prediction](https://arxiv.org//abs/2505.14057)

	Yu Cui, Feng Liu, Jiawei Chen, Xingyu Lou, Changwang Zhang, Jun Wang, Yuegang Sun, Xiaohu Yang, Can Wang

+ [AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models](https://arxiv.org//abs/2505.14103)

	Guangke Chen, Fu Song, Zhe Zhao, Xiaojun Jia, Yang Liu, Yanchen Qiao, Weizhe Zhang

+ [A Personalized Conversational Benchmark: Towards Simulating Personalized Conversations](https://arxiv.org//abs/2505.14106)

	Li Li, Peilin Cai, Ryan A. Rossi, Franck Dernoncourt, Branislav Kveton, Junda Wu, Tong Yu, Linxin Song, Tiankai Yang, Yuehan Qin, Nesreen K. Ahmed, Samyadeep Basu, Subhojyoti Mukherjee, Ruiyi Zhang, Zhengmian Hu, Bo Ni, Yuxiao Zhou, Zichao Wang, Yue Huang, Yu Wang, Xiangliang Zhang, Philip S. Yu, Xiyang Hu, Yue Zhao

+ [DiagnosisArena: Benchmarking Diagnostic Reasoning for Large Language Models](https://arxiv.org//abs/2505.14107)

	Yakun Zhu, Zhongzhen Huang, Linjie Mu, Yutong Huang, Wei Nie, Shaoting Zhang, Pengfei Liu, Xiaofan Zhang

+ [Local Mixtures of Experts: Essentially Free Test-Time Training via Model Merging](https://arxiv.org//abs/2505.14136)

	Ryo Bertolissi, Jonas Hübotter, Ido Hakimi, Andreas Krause

+ [Unify Graph Learning with Text: Unleashing LLM Potentials for Session Search](https://arxiv.org//abs/2505.14156)

	Songhao Wu, Quan Tu, Hong Liu, Jia Xu, Zhongyi Liu, Guannan Zhang, Ran Wang, Xiuying Chen, Rui Yan

+ [Prior Prompt Engineering for Reinforcement Fine-Tuning](https://arxiv.org//abs/2505.14157)

	Pittawat Taveekitworachai, Potsawee Manakul, Sarana Nutanong, Kunat Pipatanakul

+ [Tokenization Constraints in LLMs: A Study of Symbolic and Arithmetic Reasoning Limits](https://arxiv.org//abs/2505.14178)

	Xiang Zhang, Juntai Cao, Jiaqi Wei, Yiwei Xu, Chenyu You

+ [Safety Subspaces are Not Distinct: A Fine-Tuning Case Study](https://arxiv.org//abs/2505.14185)

	Kaustubh Ponkshe, Shaan Shah, Raghav Singhal, Praneeth Vepakomma

+ [Automatic Dataset Generation for Knowledge Intensive Question Answering Tasks](https://arxiv.org//abs/2505.14212)

	Sizhe Yuen, Ting Su, Ziyang Wang, Yali Du, Adam J. Sobey

+ ["Haet Bhasha aur Diskrimineshun": Phonetic Perturbations in Code-Mixed Hinglish to Red-Team LLMs](https://arxiv.org//abs/2505.14226)

	Darpan Aswal, Siddharth D Jaiswal

+ [Mechanistic Fine-tuning for In-context Learning](https://arxiv.org//abs/2505.14233)

	Hakaze Cho, Peng Luo, Mariko Kato, Rin Kaenbyou, Naoya Inoue

+ [ABBA: Highly Expressive Hadamard Product Adaptation for Large Language Models](https://arxiv.org//abs/2505.14238)

	Raghav Singhal, Kaustubh Ponkshe, Rohit Vartak, Praneeth Vepakomma

+ [Visual Agentic Reinforcement Fine-Tuning](https://arxiv.org//abs/2505.14246)

	Ziyu Liu, Yuhang Zang, Yushan Zou, Zijian Liang, Xiaoyi Dong, Yuhang Cao, Haodong Duan, Dahua Lin, Jiaqi Wang

+ [Think-J: Learning to Think for Generative LLM-as-a-Judge](https://arxiv.org//abs/2505.14268)

	Hui Huang, Yancheng He, Hongli Zhou, Rui Zhang, Wei Liu, Weixun Wang, Wenbo Su, Bo Zheng, Jiaheng Liu

+ [YESciEval: Robust LLM-as-a-Judge for Scientific Question Answering](https://arxiv.org//abs/2505.14279)

	Jennifer D'Souza, Hamed Babaei Giglou, Quentin Münch

+ [Exploring Jailbreak Attacks on LLMs through Intent Concealment and Diversion](https://arxiv.org//abs/2505.14316)

	Tiehan Cui, Yanxu Mao, Peipei Liu, Congying Liu, Datao You

+ [MUG-Eval: A Proxy Evaluation Framework for Multilingual Generation Capabilities in Any Language](https://arxiv.org//abs/2505.14395)

	Seyoung Song, Seogyeong Jeong, Eunsu Kim, Jiho Jin, Dongkwan Kim, Jay Shin, Alice Oh

+ [Log-Augmented Generation: Scaling Test-Time Reasoning with Reusable Computation](https://arxiv.org//abs/2505.14398)

	Peter Baile Chen, Yi Zhang, Dan Roth, Samuel Madden, Jacob Andreas, Michael Cafarella

+ [Neural Incompatibility: The Unbridgeable Gap of Cross-Scale Parametric Knowledge Transfer in Large Language Models](https://arxiv.org//abs/2505.14436)

	Yuqiao Tan, Shizhu He, Kang Liu, Jun Zhao

+ [CtrlDiff: Boosting Large Diffusion Language Models with Dynamic Block Prediction and Controllable Generation](https://arxiv.org//abs/2505.14455)

	Chihan Huang, Hao Tang

+ [Attributional Safety Failures in Large Language Models under Code-Mixed Perturbations](https://arxiv.org//abs/2505.14469)

	Somnath Banerjee, Pratyush Chatterjee, Shanu Kumar, Sayan Layek, Parag Agrawal, Rima Hazra, Animesh Mukherjee

+ [Can Large Language Models Really Recognize Your Name?](https://arxiv.org//abs/2505.14549)

	Dzung Pham, Peter Kairouz, Niloofar Mireshghallah, Eugene Bagdasarian, Chau Minh Pham, Amir Houmansadr

+ [KORGym: A Dynamic Game Platform for LLM Reasoning Evaluation](https://arxiv.org//abs/2505.14552)

	Jiajun Shi, Jian Yang, Jiaheng Liu, Xingyuan Bu, Jiangjie Chen, Junting Zhou, Kaijing Ma, Zhoufutu Wen, Bingli Wang, Yancheng He, Liang Song, Hualei Zhu, Shilong Li, Xingjian Wang, Wei Zhang, Ruibin Yuan, Yifan Yao, Wenjun Yang, Yunli Wang, Siyuan Fang, Siyu Yuan, Qianyu He, Xiangru Tang, Yingshui Tan, Wangchunshu Zhou, Zhaoxiang Zhang, Zhoujun Li, Wenhao Huang, Ge Zhang

+ [Toward Reliable Biomedical Hypothesis Generation: Evaluating Truthfulness and Hallucination in Large Language Models](https://arxiv.org//abs/2505.14599)

	Guangzhi Xiong, Eric Xie, Corey Williams, Myles Kim, Amir Hassan Shariatmadari, Sikun Guo, Stefan Bekiranov, Aidong Zhang

+ [Language Models Optimized to Fool Detectors Still Have a Distinct Style (And How to Change It)](https://arxiv.org//abs/2505.14608)

	Rafael Rivera Soto, Barry Chen, Nicholas Andrews

+ [TinyV: Reducing False Negatives in Verification Improves RL for LLM Reasoning](https://arxiv.org//abs/2505.14625)

	Zhangchen Xu, Yuetai Li, Fengqing Jiang, Bhaskar Ramasubramanian, Luyao Niu, Bill Yuchen Lin, Radha Poovendran

+ [Will AI Tell Lies to Save Sick Children? Litmus-Testing AI Values Prioritization with AIRiskDilemmas](https://arxiv.org//abs/2505.14633)

	Yu Ying Chiu, Zhilin Wang, Sharan Maiya, Yejin Choi, Kyle Fish, Sydney Levine, Evan Hubinger

+ [Beyond Words: Multimodal LLM Knows When to Speak](https://arxiv.org//abs/2505.14654)

	Zikai Liao, Yi Ouyang, Yi-Lun Lee, Chen-Ping Yu, Yi-Hsuan Tsai, Zhaozheng Yin

+ [Mind the Gap: Bridging Thought Leap for Improved Chain-of-Thought Tuning](https://arxiv.org//abs/2505.14684)

	Haolei Xu, Yuchen Yan, Yongliang Shen, Wenqi Zhang, Guiyang Hou, Shengpei Jiang, Kaitao Song, Weiming Lu, Jun Xiao, Yueting Zhuang

+ [Improve Language Model and Brain Alignment via Associative Memory](https://arxiv.org//abs/2505.13844)

	Congchi Yin, Yongpeng Zhang, Xuyun Wen, Piji Li

+ [Reasoning Path Compression: Compressing Generation Trajectories for Efficient LLM Reasoning](https://arxiv.org//abs/2505.13866)

	Jiwon Song, Dongwon Jo, Yulhwa Kim, Jae-Joon Kim

+ [Mapping the Minds of LLMs: A Graph-Based Analysis of Reasoning LLM](https://arxiv.org//abs/2505.13890)

	Zhen Xiong, Yujun Cai, Zhecheng Li, Yiwei Wang

+ [InfiGFusion: Graph-on-Logits Distillation via Efficient Gromov-Wasserstein for Model Fusion](https://arxiv.org//abs/2505.13893)

	Yuanyi Wang, Zhaoyi Yan, Yiming Zhang, Qi Zhou, Yanggan Gu, Fei Wu, Hongxia Yang

+ [Let's Verify Math Questions Step by Step](https://arxiv.org//abs/2505.13903)

	Chengyu Shen, Zhen Hao Wong, Runming He, Hao Liang, Meiyi Qiang, Zimo Meng, Zhengyang Zhao, Bohan Zeng, Zhengzhou Zhu, Bin Cui, Wentao Zhang

+ [Through a Compressed Lens: Investigating the Impact of Quantization on LLM Explainability and Interpretability](https://arxiv.org//abs/2505.13963)

	Qianli Wang, Mingyang Wang, Nils Feldhus, Simon Ostermann, Yuan Cao, Hinrich Schütze, Sebastian Möller, Vera Schmitt

+ [Truth or Twist? Optimal Model Selection for Reliable Label Flipping Evaluation in LLM-based Counterfactuals](https://arxiv.org//abs/2505.13972)

	Qianli Wang, Van Bach Nguyen, Nils Feldhus, Luis Felipe Villa-Arenas, Christin Seifert, Sebastian Möller, Vera Schmitt

+ [DRP: Distilled Reasoning Pruning with Skill-aware Step Decomposition for Efficient Large Reasoning Models](https://arxiv.org//abs/2505.13975)

	Yuxuan Jiang, Dawei Li, Frank Ferraro

+ [The Hallucination Tax of Reinforcement Finetuning](https://arxiv.org//abs/2505.13988)

	Linxin Song, Taiwei Shi, Jieyu Zhao

+ [DecIF: Improving Instruction-Following through Meta-Decomposition](https://arxiv.org//abs/2505.13990)

	Tingfeng Hui, Pengyu Zhu, Bowen Ping, Ling Tang, Yaqi Zhang, Sen Su

+ [Activation-Guided Consensus Merging for Large Language Models](https://arxiv.org//abs/2505.14009)

	Yuxuan Yao, Shuqi Liu, Zehua Liu, Qintong Li, Mingyang Liu, Xiongwei Han, Zhijiang Guo, Han Wu, Linqi Song

+ [AUTOLAW: Enhancing Legal Compliance in Large Language Models via Case Law Generation and Jury-Inspired Deliberation](https://arxiv.org//abs/2505.14015)

	Tai D. Nguyen, Long H. Pham, Jun Sun

+ [Enhancing LLMs via High-Knowledge Data Selection](https://arxiv.org//abs/2505.14070)

	Feiyu Duan, Xuemiao Zhang, Sirui Wang, Haoran Que, Yuqi Liu, Wenge Rong, Xunliang Cai

+ [BAR: A Backward Reasoning based Agent for Complex Minecraft Tasks](https://arxiv.org//abs/2505.14079)

	Weihong Du, Wenrui Liao, Binyu Yan, Hongru Liang, Anthony G. Cohn, Wenqiang Lei

+ [Beyond Chains: Bridging Large Language Models and Knowledge Bases in Complex Question Answering](https://arxiv.org//abs/2505.14099)

	Yihua Zhu, Qianying Liu, Akiko Aizawa, Hidetoshi Shimodaira

+ [MultiHal: Multilingual Dataset for Knowledge-Graph Grounded Evaluation of LLM Hallucinations](https://arxiv.org//abs/2505.14101)

	Ernests Lavrinovics, Russa Biswas, Katja Hose, Johannes Bjerva

+ [Invisible Entropy: Towards Safe and Efficient Low-Entropy LLM Watermarking](https://arxiv.org//abs/2505.14112)

	Tianle Gu, Zongqi Wang, Kexin Huang, Yuanqi Yao, Xiangliang Zhang, Yujiu Yang, Xiuying Chen

+ [Self-Reasoning Language Models: Unfold Hidden Reasoning Chains with Few Reasoning Catalyst](https://arxiv.org//abs/2505.14116)

	Hongru Wang, Deng Cai, Wanjun Zhong, Shijue Huang, Jeff Z. Pan, Zeming Liu, Kam-Fai Wong

+ [Temporal Alignment of Time Sensitive Facts with Activation Engineering](https://arxiv.org//abs/2505.14158)

	Sanjay Govindan, Maurice Pagnucco, Yang Song

+ [The Strawberry Problem: Emergence of Character-level Understanding in Tokenized Language Models](https://arxiv.org//abs/2505.14172)

	Adrian Cosma, Stefan Ruseti, Emilian Radoi, Mihai Dascalu

+ [ThinkSwitcher: When to Think Hard, When to Think Fast](https://arxiv.org//abs/2505.14183)

	Guosheng Liang, Longguang Zhong, Ziyi Yang, Xiaojun Quan

+ [Unraveling Interwoven Roles of Large Language Models in Authorship Privacy: Obfuscation, Mimicking, and Verification](https://arxiv.org//abs/2505.14195)

	Tuc Nguyen, Yifan Hu, Thai Le

+ [Universal Acoustic Adversarial Attacks for Flexible Control of Speech-LLMs](https://arxiv.org//abs/2505.14286)

	Rao Ma, Mengjie Qian, Vyas Raina, Mark Gales, Kate Knill

+ [Studying the Role of Input-Neighbor Overlap in Retrieval-Augmented Language Models Training Efficiency](https://arxiv.org//abs/2505.14309)

	Ehsan Doostmohammadi, Marco Kuhlmann

+ [A MIND for Reasoning: Meta-learning for In-context Deduction](https://arxiv.org//abs/2505.14313)

	Leonardo Bertolazzi, Manuel Vargas Guzmán, Raffaella Bernardi, Maciej Malicki, Jakub Szymanik

+ [QA-prompting: Improving Summarization with Large Language Models using Question-Answering](https://arxiv.org//abs/2505.14347)

	Neelabh Sinha

+ [OSoRA: Output-Dimension and Singular-Value Initialized Low-Rank Adaptation](https://arxiv.org//abs/2505.14350)

	Jialong Han, Si Zhang, Ke Zhang

+ [Dual Decomposition of Weights and Singular Value Low Rank Adaptation](https://arxiv.org//abs/2505.14367)

	Jialong Han, Si Zhang, Ke Zhang

+ [Editing Across Languages: A Survey of Multilingual Knowledge Editing](https://arxiv.org//abs/2505.14393)

	Nadir Durrani, Basel Mousi, Fahim Dalvi

+ [Pierce the Mists, Greet the Sky: Decipher Knowledge Overshadowing via Knowledge Circuit Analysis](https://arxiv.org//abs/2505.14406)

	Haoming Huang, Yibo Yan, Jiahao Huo, Xin Zou, Xinfeng Li, Kun Wang, Xuming Hu

+ [Hidden Ghost Hand: Unveiling Backdoor Vulnerabilities in MLLM-Powered Mobile GUI Agents](https://arxiv.org//abs/2505.14418)

	Pengzhou Cheng, Haowen Hu, Zheng Wu, Zongru Wu, Tianjie Ju, Daizong Ding, Zhuosheng Zhang, Gongshen Liu

+ [Scaling Low-Resource MT via Synthetic Data Generation with LLMs](https://arxiv.org//abs/2505.14423)

	Ona de Gibert, Joseph Attieh, Teemu Vahtola, Mikko Aulamo, Zihao Li, Raúl Vázquez, Tiancheng Hu, Jörg Tiedemann

+ [From Templates to Natural Language: Generalization Challenges in Instruction-Tuned LLMs for Spatial Reasoning](https://arxiv.org//abs/2505.14425)

	Chalamalasetti Kranti, Sherzod Hakimov, David Schlangen

+ [Not All Correct Answers Are Equal: Why Your Distillation Source Matters](https://arxiv.org//abs/2505.14464)

	Xiaoyu Tian, Yunjie Ji, Haotian Wang, Shuaiting Chen, Sitong Zhao, Yiping Peng, Han Zhao, Xiangang Li

+ [Void in Language Models](https://arxiv.org//abs/2505.14467)

	Mani Shemiranifar

+ [MoMoE: Mixture of Moderation Experts Framework for AI-Assisted Online Governance](https://arxiv.org//abs/2505.14483)

	Agam Goyal, Xianyang Zhan, Yilun Chen, Koustuv Saha, Eshwar Chandrasekharan

+ [Internal Chain-of-Thought: Empirical Evidence for Layer-wise Subtask Scheduling in LLMs](https://arxiv.org//abs/2505.14530)

	Zhipeng Yang, Junzhuo Li, Siyu Xia, Xuming Hu

+ [Breaking Bad Tokens: Detoxification of LLMs Using Sparse Autoencoders](https://arxiv.org//abs/2505.14536)

	Agam Goyal, Vedant Rathi, William Yeh, Yian Wang, Yuen Chen, Hari Sundaram

+ [Can Pruning Improve Reasoning? Revisiting Long-CoT Compression with Capability in Mind for Better Reasoning](https://arxiv.org//abs/2505.14582)

	Shangziqi Zhao, Jiahao Yuan, Guisong Yang, Usman Naseem

+ [Context Reasoner: Incentivizing Reasoning Capability for Contextualized Privacy and Safety Compliance via Reinforcement Learning](https://arxiv.org//abs/2505.14585)

	Wenbin Hu, Haoran Li, Huihao Jing, Qi Hu, Ziqian Zeng, Sirui Han, Heli Xu, Tianshu Chu, Peizhao Hu, Yangqiu Song

+ [MCIP: Protecting MCP Safety via Model Contextual Integrity Protocol](https://arxiv.org//abs/2505.14590)

	Huihao Jing, Haoran Li, Wenbin Hu, Qi Hu, Heli Xu, Tianshu Chu, Peizhao Hu, Yangqiu Song

+ [Success is in the Details: Evaluate and Enhance Details Sensitivity of Code LLMs through Counterfactuals](https://arxiv.org//abs/2505.14597)

	Xianzhen Luo, Qingfu Zhu, Zhiming Zhang, Mingzheng Xu, Tianhao Cheng, Yixuan Wang, Zheng Chu, Shijie Xuyang, Zhiyuan Ma, YuanTao Fan, Wanxiang Che

+ [sudoLLM : On Multi-role Alignment of Language Models](https://arxiv.org//abs/2505.14607)

	Soumadeep Saha, Akshay Chaturvedi, Joy Mahapatra, Utpal Garain

+ [Linear Control of Test Awareness Reveals Differential Compliance in Reasoning Models](https://arxiv.org//abs/2505.14617)

	Sahar Abdelnabi, Ahmed Salem

+ [Think Only When You Need with Large Hybrid-Reasoning Models](https://arxiv.org//abs/2505.14631)

	Lingjie Jiang, Xun Wu, Shaohan Huang, Qingxiu Dong, Zewen Chi, Li Dong, Xingxing Zhang, Tengchao Lv, Lei Cui, Furu Wei

+ [General-Reasoner: Advancing LLM Reasoning Across All Domains](https://arxiv.org//abs/2505.14652)

	Xueguang Ma, Qian Liu, Dongfu Jiang, Ge Zhang, Zejun Ma, Wenhu Chen

+ [Reward Reasoning Model](https://arxiv.org//abs/2505.14674)

	Jiaxin Guo, Zewen Chi, Li Dong, Qingxiu Dong, Xun Wu, Shaohan Huang, Furu Wei

+ [UltraEdit: Training-, Subject-, and Memory-Free Lifelong Editing in Large Language Models](https://arxiv.org//abs/2505.14679)

	Xiaojie Gu, Guangxu Chen, Jungang Li, Jia-Chen Gu, Xuming Hu, Kai Zhang

+ [Language Models use Lookbacks to Track Beliefs](https://arxiv.org//abs/2505.14685)

	Nikhil Prakash, Natalie Shapira, Arnab Sen Sharma, Christoph Riedl, Yonatan Belinkov, Tamar Rott Shaham, David Bau, Atticus Geiger

+ [PandaGuard: Systematic Evaluation of LLM Safety in the Era of Jailbreaking Attacks](https://arxiv.org//abs/2505.13862)

	Guobin Shen, Dongcheng Zhao, Linghao Feng, Xiang He, Jihang Wang, Sicheng Shen, Haibo Tong, Yiting Dong, Jindong Li, Xiang Zheng, Yi Zeng

+ [InfiFPO: Implicit Model Fusion via Preference Optimization in Large Language Models](https://arxiv.org//abs/2505.13878)

	Yanggan Gu, Zhaoyi Yan, Yuanyi Wang, Yiming Zhang, Qi Zhou, Fei Wu, Hongxia Yang

+ [Beyond Text: Unveiling Privacy Vulnerabilities in Multi-modal Retrieval-Augmented Generation](https://arxiv.org//abs/2505.13957)

	Jiankun Zhang, Shenglai Zeng, Jie Ren, Tianqi Zheng, Hui Liu, Xianfeng Tang, Hui Liu, Yi Chang

+ [Textual Steering Vectors Can Improve Visual Understanding in Multimodal Large Language Models](https://arxiv.org//abs/2505.14071)

	Woody Haosheng Gan, Deqing Fu, Julian Asilis, Ollie Liu, Dani Yogatama, Vatsal Sharan, Robin Jia, Willie Neiswanger

+ [AAPO: Enhance the Reasoning Capabilities of LLMs with Advantage Momentum](https://arxiv.org//abs/2505.14264)

	Jian Xiong, Jingbo Zhou, Jingyong Ye, Dejing Dou

+ [Scaling Law for Quantization-Aware Training](https://arxiv.org//abs/2505.14302)

	Mengzhao Chen, Chaoyi Zhang, Jing Liu, Yutao Zeng, Zeyue Xue, Zhiheng Liu, Yunshui Li, Jin Ma, Jie Huang, Xun Zhou, Ping Luo

+ [RADAR: Enhancing Radiology Report Generation with Supplementary Knowledge Injection](https://arxiv.org//abs/2505.14318)

	Wenjun Hou, Yi Cheng, Kaishuai Xu, Heng Li, Yan Hu, Wenjie Li, Jiang Liu

+ [Is Your Prompt Safe? Investigating Prompt Injection Attacks Against Open-Source LLMs](https://arxiv.org//abs/2505.14368)

	Jiawen Wang, Pritha Gupta, Ivan Habernal, Eyke Hüllermeier

+ [Rank-K: Test-Time Reasoning for Listwise Reranking](https://arxiv.org//abs/2505.14432)

	Eugene Yang, Andrew Yates, Kathryn Ricci, Orion Weller, Vivek Chari, Benjamin Van Durme, Dawn Lawrie

+ [S2SBench: A Benchmark for Quantifying Intelligence Degradation in Speech-to-Speech Large Language Models](https://arxiv.org//abs/2505.14438)

	Yuanbo Fang, Haoze Sun, Jun Liu, Tao Zhang, Zenan Zhou, Weipeng Chen, Xiaofen Xing, Xiangmin Xu

+ [Enhancing Learned Knowledge in LoRA Adapters Through Efficient Contrastive Decoding on Ascend NPUs](https://arxiv.org//abs/2505.14620)

	Morgan Lindsay Heisler, Linzi Xing, Ge Shi, Hanieh Sadri, Gursimran Singh, Weiwei Zhang, Tao Ye, Ying Xiong, Yong Zhang, Zhenan Fan

+ [Aligning Attention Distribution to Information Flow for Hallucination Mitigation in Large Vision-Language Models](https://arxiv.org//abs/2505.14257)

	Jianfei Zhao, Feng Zhang, Xin Sun, Chong Feng

+ [UniGen: Enhanced Training & Test-Time Strategies for Unified Multimodal Understanding and Generation](https://arxiv.org//abs/2505.14682)

	Rui Tian, Mingfei Gao, Mingze Xu, Jiaming Hu, Jiasen Lu, Zuxuan Wu, Yinfei Yang, Afshin Dehghan

+ [Adversarially Pretrained Transformers may be Universally Robust In-Context Learners](https://arxiv.org//abs/2505.14042)

	Soichiro Kumano, Hiroshi Kera, Toshihiko Yamasaki

+ [Scaling and Enhancing LLM-based AVSR: A Sparse Mixture of Projectors Approach](https://arxiv.org//abs/2505.14336)

	Umberto Cappellazzo, Minsu Kim, Stavros Petridis, Daniele Falavigna, Alessio Brutti

+ [Context-Free Synthetic Data Mitigates Forgetting](https://arxiv.org//abs/2505.13811)

	Parikshit Bansal, Sujay Sanghavi

+ [Fragments to Facts: Partial-Information Fragment Inference from LLMs](https://arxiv.org//abs/2505.13819)

	Lucas Rosenblatt, Bin Han, Robert Wolfe, Bill Howe

+ [MAS-KCL: Knowledge component graph structure learning with large language model-based agentic workflow](https://arxiv.org//abs/2505.14126)

	Yuan-Hao Jiang, Kezong Tang, Zi-Wei Chen, Yuang Wei, Tian-Yi Liu, Jiayi Wu

+ [Towards eliciting latent knowledge from LLMs with mechanistic interpretability](https://arxiv.org//abs/2505.14352)

	Bartosz Cywiński, Emil Ryd, Senthooran Rajamanoharan, Neel Nanda

+ [ServerlessLoRA: Minimizing Latency and Cost in Serverless Inference for LoRA-Based LLMs](https://arxiv.org//abs/2505.14468)

	Yifan Sui, Hao Wang, Hanfei Yu, Yitao Hu, Jianxun Li, Hao Wang

+ [Quartet: Native FP4 Training Can Be Optimal for Large Language Models](https://arxiv.org//abs/2505.14669)

	Roberto L. Castro, Andrei Panferov, Soroush Tabesh, Oliver Sieberling, Jiale Chen, Mahdi Nikdan, Saleh Ashkboos, Dan Alistarh

+ [A Probabilistic Perspective on Model Collapse](https://arxiv.org//abs/2505.13947)

	Shirong Xu, Hengzhi He, Guang Cheng

+ [Vulnerability of Transfer-Learned Neural Networks to Data Reconstruction Attacks in Small-Data Regime](https://arxiv.org//abs/2505.14323)

	Tomasz Maciążek, Robert Allison

+ [Lessons from Defending Gemini Against Indirect Prompt Injections](https://arxiv.org//abs/2505.14534)

	Chongyang Shi, Sharon Lin, Shuang Song, Jamie Hayes, Ilia Shumailov, Itay Yona, Juliette Pluto, Aneesh Pappu, Christopher A. Choquette-Choo, Milad Nasr, Chawin Sitawarin, Gena Gibson, Andreas Terzis, John "Four" Flynn

+ [R&D-Agent: Automating Data-Driven AI Solution Building Through LLM-Powered Automated Research, Development, and Evolution](https://arxiv.org//abs/2505.14738)

	Xu Yang, Xiao Yang, Shikai Fang, Bowen Xian, Yuante Li, Jian Wang, Minrui Xu, Haoran Pan, Xinpeng Hong, Weiqing Liu, Yelong Shen, Weizhu Chen, Jiang Bian

+ [FOL-Pretrain: A complexity annotated corpus of first-order logic](https://arxiv.org//abs/2505.14932)

	Isabelle Lee, Sarah Liaw, Dani Yogatama

+ [Reinforcement Learning from User Feedback](https://arxiv.org//abs/2505.14946)

	Eric Han, Jun Chen, Karthik Abinav Sankararaman, Xiaoliang Peng, Tengyu Xu, Eryk Helenowski, Kaiyan Peng, Mrinal Kumar, Sinong Wang, Han Fang, Arya Talebzadeh

+ [Self-Evolving Curriculum for LLM Reasoning](https://arxiv.org//abs/2505.14970)

	Xiaoyin Chen, Jiarui Lu, Minsu Kim, Dinghuai Zhang, Jian Tang, Alexandre Piché, Nicolas Gontier, Yoshua Bengio, Ehsan Kamalloo

+ [The Energy Cost of Reasoning: Analyzing Energy Usage in LLMs with Test-time Compute](https://arxiv.org//abs/2505.14733)

	Yunho Jin, Gu-Yeon Wei, David Brooks

+ [Quaff: Quantized Parameter-Efficient Fine-Tuning under Outlier Spatial Stability Hypothesis](https://arxiv.org//abs/2505.14742)

	Hong Huang, Dapeng Wu

+ [$\texttt{LLINBO}$: Trustworthy LLM-in-the-Loop Bayesian Optimization](https://arxiv.org//abs/2505.14756)

	Chih-Yu Chang, Milad Azvar, Chinedum Okwudire, Raed Al Kontar

+ [Scaling Reasoning, Losing Control: Evaluating Instruction Following in Large Reasoning Models](https://arxiv.org//abs/2505.14810)

	Tingchen Fu, Jiawei Gu, Yafu Li, Xiaoye Qu, Yu Cheng

+ [WebNovelBench: Placing LLM Novelists on the Web Novel Distribution](https://arxiv.org//abs/2505.14818)

	Leon Lin, Jun Zheng, Haidong Wang

+ [Text Generation Beyond Discrete Token Sampling](https://arxiv.org//abs/2505.14827)

	Yufan Zhuang, Liyuan Liu, Chandan Singh, Jingbo Shang, Jianfeng Gao

+ [Balanced and Elastic End-to-end Training of Dynamic LLMs](https://arxiv.org//abs/2505.14864)

	Mohamed Wahib, Muhammed Abdullah Soyturk, Didem Unat

+ [Polar Sparsity: High Throughput Batched LLM Inferencing with Scalable Contextual Sparsity](https://arxiv.org//abs/2505.14884)

	Susav Shrestha, Brad Settlemyer, Nikoli Dryden, Narasimha Reddy

+ [Scaling Laws for State Dynamics in Large Language Models](https://arxiv.org//abs/2505.14892)

	Jacob X Li, Shreyas S Raman, Jessica Wan, Fahad Samman, Jazlyn Lin

+ [Too Long, Didn't Model: Decomposing LLM Long-Context Understanding With Novels](https://arxiv.org//abs/2505.14925)

	Sil Hamilton, Rebecca M. M. Hicke, Matthew Wilkens, David Mimno

+ [Soft Prompts for Evaluation: Measuring Conditional Distance of Capabilities](https://arxiv.org//abs/2505.14943)

	Ross Nordby

+ [JARVIS: A Multi-Agent Code Assistant for High-Quality EDA Script Generation](https://arxiv.org//abs/2505.14978)

	Ghasem Pasandi, Kishor Kunal, Varun Tej, Kunjal Shan, Hanfei Sun, Sumit Jain, Chunhui Li, Chenhui Deng, Teodor-Dumitru Ene, Haoxing Ren, Sreedhar Pratty

+ [Addressing the Challenges of Planning Language Generation](https://arxiv.org//abs/2505.14763)

	Prabhu Prakash Kagitha, Andrew Zhu, Li Zhang

+ [Language Mixing in Reasoning Language Models: Patterns, Impact, and Internal Causes](https://arxiv.org//abs/2505.14815)

	Mingyang Wang, Lukas Lange, Heike Adel, Yunpu Ma, Jannik Strötgen, Hinrich Schütze

+ [Tracing Multilingual Factual Knowledge Acquisition in Pretraining](https://arxiv.org//abs/2505.14824)

	Yihong Liu, Mingyang Wang, Amir Hossein Kargaran, Felicia Körner, Ercong Nie, Barbara Plank, François Yvon, Hinrich Schütze

+ [SEPS: A Separability Measure for Robust Unlearning in LLMs](https://arxiv.org//abs/2505.14832)

	Wonje Jeung, Sangyeon Yoon, Albert No

+ [MAATS: A Multi-Agent Automated Translation System Based on MQM Evaluation](https://arxiv.org//abs/2505.14848)

	Xi Wang, Jiaqian Hu, Safinah Ali

+ [Saten: Sparse Augmented Tensor Networks for Post-Training Compression of Large Language Models](https://arxiv.org//abs/2505.14871)

	Ryan Solgi, Kai Zhen, Rupak Vignesh Swaminathan, Nathan Susanj, Athanasios Mouchtaris, Siegfried Kunzmann, Zheng Zhang

+ [Incorporating Token Usage into Prompting Strategy Evaluation](https://arxiv.org//abs/2505.14880)

	Chris Sypherd, Sergei Petrov, Sonny George, Vaishak Belle

+ [Strategic Planning and Rationalizing on Trees Make LLMs Better Debaters](https://arxiv.org//abs/2505.14886)

	Danqing Wang, Zhuorui Ye, Xinran Zhao, Fei Fang, Lei Li

+ [Understanding 6G through Language Models: A Case Study on LLM-aided Structured Entity Extraction in Telecom Domain](https://arxiv.org//abs/2505.14906)

	Ye Yuan, Haolun Wu, Hao Zhou, Xue Liu, Hao Chen, Yan Xin, Jianzhong (Charlie)Zhang

+ [Reliable Decision Support with LLMs: A Framework for Evaluating Consistency in Binary Text Classification Applications](https://arxiv.org//abs/2505.14918)

	Fadel M. Megahed, Ying-Ju Chen, L. Allision Jones-Farmer, Younghwa Lee, Jiawei Brooke Wang, Inez M. Zwetsloot

+ [MedBrowseComp: Benchmarking Medical Deep Research and Computer Use](https://arxiv.org//abs/2505.14963)

	Shan Chen, Pedro Moreira, Yuxin Xiao, Sam Schmidgall, Jeremy Warner, Hugo Aerts, Thomas Hartvigsen, Jack Gallifant, Danielle S. Bitterman

+ [DECASTE: Unveiling Caste Stereotypes in Large Language Models through Multi-Dimensional Bias Analysis](https://arxiv.org//abs/2505.14971)

	Prashanth Vijayaraghavan, Soroush Vosoughi, Lamogha Chizor, Raya Horesh, Rogerio Abreu de Paula, Ehsan Degan, Vandana Mukherjee

+ [FisherSFT: Data-Efficient Supervised Fine-Tuning of Language Models Using Information Gain](https://arxiv.org//abs/2505.14826)

	Rohan Deb, Kiran Thekumparampil, Kousha Kalantari, Gaurush Hiranandani, Shoham Sabach, Branislav Kveton

+ [Think, Reflect, Create: Metacognitive Learning for Zero-Shot Robotic Planning with LLMs](https://arxiv.org//abs/2505.14899)

	Wenjie Lin, Jin Wei-Kocsis

+ [The Evolution of Alpha in Finance Harnessing Human Insight and LLM Agents](https://arxiv.org//abs/2505.14727)

	Mohammad Rubyet Islam

+ [Large Language Models for Data Synthesis](https://arxiv.org//abs/2505.14752)

	Yihong Tang, Menglin Kong, Lijun Sun

+ [Foundations of Unknown-aware Machine Learning](https://arxiv.org//abs/2505.14933)

	Xuefeng Du

+ [LEANCODE: Understanding Models Better for Code Simplification of Pre-trained Large Language Models](https://arxiv.org//abs/2505.14759)

	Yan Wang, Ling Ding, Tien N Nguyen, Shaohua Wang, Yanan Zheng

+ [Mechanistic Interpretability of GPT-like Models on Summarization Tasks](https://arxiv.org//abs/2505.17073)

	Anurag Mishra

+ [Semi-Clairvoyant Scheduling of Speculative Decoding Requests to Minimize LLM Inference Latency](https://arxiv.org//abs/2505.17074)

	Ruixiao Li, Fahao Chen, Peng Li

+ [GloSS over Toxicity: Understanding and Mitigating Toxicity in LLMs via Global Toxic Subspace](https://arxiv.org//abs/2505.17078)

	Zenghao Duan, Zhiyi Yin, Zhichao Shi, Liang Pang, Shaoling Jing, Jiayi Wu, Yu Yan, Huawei Shen, Xueqi Cheng

+ [From nuclear safety to LLM security: Applying non-probabilistic risk management strategies to build safe and secure LLM-powered systems](https://arxiv.org//abs/2505.17084)

	Alexander Gutfraind, Vicki Bier

+ [Large Language Models Implicitly Learn to See and Hear Just By Reading](https://arxiv.org//abs/2505.17091)

	Prateek Verma, Mert Pilanci

+ [Scale-invariant Attention](https://arxiv.org//abs/2505.17083)

	Ben Anson, Xi Wang, Laurence Aitchison

+ [Reinforcing Question Answering Agents with Minimalist Policy Gradient Optimization](https://arxiv.org//abs/2505.17086)

	Yihong Wu, Liheng Ma, Muzhi Li, Jiaming Zhou, Jianye Hao, Ho-fung Leung, Irwin King, Yingxue Zhang, Jian-Yun Nie

+ [Trust Me, I Can Handle It: Self-Generated Adversarial Scenario Extrapolation for Robust Language Models](https://arxiv.org//abs/2505.17089)

	Md Rafi Ur Rashid, Vishnu Asutosh Dasu, Ye Wang, Gang Tan, Shagufta Mehnaz

+ [The Role of Visualization in LLM-Assisted Knowledge Graph Systems: Effects on User Trust, Exploration, and Workflows](https://arxiv.org//abs/2505.21512)

	Harry Li, Gabriel Appleby, Kenneth Alperin, Steven R Gomez, Ashley Suh

+ [Modality-Balancing Preference Optimization of Large Multimodal Models by Adversarial Negative Mining](https://arxiv.org//abs/2506.08022)

	Chenxi Liu, Tianyi Xiong, Ruibo Chen, Yihan Wu, Junfeng Guo, Tianyi Zhou, Heng Huang

+ [ViC-Bench: Benchmarking Visual-Interleaved Chain-of-Thought Capability in MLLMs with Free-Style Intermediate State Representations](https://arxiv.org//abs/2505.14404)

	Xuecheng Wu, Jiaxing Liu, Danlei Huang, Xiaoyu Li, Yifan Wang, Chen Chen, Liya Ma, Xuezhi Cao, Junxiao Xue

# 2025-05-19
+ [Bullying the Machine: How Personas Increase LLM Vulnerability](https://arxiv.org//abs/2505.12692)

	Ziwei Xu, Udit Sanghi, Mohan Kankanhalli

+ [Accelerating Adaptive Retrieval Augmented Generation via Instruction-Driven Representation Reduction of Retrieval Overlaps](https://arxiv.org//abs/2505.12731)

	Jie Ou, Jinyu Guo, Shuaihong Jiang, Zhaokun Wang, Libo Qin, Shunyu Yao, Wenhong Tian

+ [Dense Communication between Language Models](https://arxiv.org//abs/2505.12741)

	Shiguang Wu, Yaqing Wang, Quanming Yao

+ [IDEAL: Data Equilibrium Adaptation for Multi-Capability Language Model Alignment](https://arxiv.org//abs/2505.12762)

	Chenlin Ming, Chendi Qu, Mengzhang Cai, Qizhi Pei, Zhuoshi Pan, Yu Li, Xiaoming Duan, Lijun Wu, Conghui He

+ [Language Models That Walk the Talk: A Framework for Formal Fairness Certificates](https://arxiv.org//abs/2505.12767)

	Danqing Chen, Tobias Ladner, Ahmed Rayen Mhadhbi, Matthias Althoff

+ [FRAbench and GenEval: Scaling Fine-Grained Aspect Evaluation across Tasks, Modalities](https://arxiv.org//abs/2505.12795)

	Shibo Hong, Jiahao Ying, Haiyuan Liang, Mengdi Zhang, Jun Kuang, Jiazheng Zhang, Yixin Cao

+ [Emergent Specialization: Rare Token Neurons in Language Models](https://arxiv.org//abs/2505.12822)

	Jing Liu, Haozheng Wang, Yueheng Li

+ [Reasoning BO: Enhancing Bayesian Optimization with Long-Context Reasoning Power of LLMs](https://arxiv.org//abs/2505.12833)

	Zhuo Yang, Lingli Ge, Dong Han, Tianfan Fu, Yuqiang Li

+ [Multi-Level Aware Preference Learning: Enhancing RLHF for Complex Multi-Instruction Tasks](https://arxiv.org//abs/2505.12845)

	Ruopei Sun, Jianfeng Cai, Jinhua Zhu, Kangwen Zhao, Dongyun Xue, Wengang Zhou, Li Li, Houqiang Li

+ [Detection and Mitigation of Hallucination in Large Reasoning Models: A Mechanistic Perspective](https://arxiv.org//abs/2505.12886)

	Zhongxiang Sun, Qipeng Wang, Haoyu Wang, Xiao Zhang, Jun Xu

+ [TIME: A Multi-level Benchmark for Temporal Reasoning of LLMs in Real-World Scenarios](https://arxiv.org//abs/2505.12891)

	Shaohang Wei, Wei Li, Feifan Song, Wen Luo, Tianyi Zhuang, Haochen Tan, Zhijiang Guo, Houfeng Wang

+ [The Traitors: Deception and Trust in Multi-Agent Language Model Simulations](https://arxiv.org//abs/2505.12923)

	Pedro M. P. Curvo

+ [CAIM: Development and Evaluation of a Cognitive AI Memory Framework for Long-Term Interaction with Intelligent Agents](https://arxiv.org//abs/2505.13044)

	Rebecca Westhäußer, Frederik Berenz, Wolfgang Minker, Sebastian Zepf

+ [LLM-KG-Bench 3.0: A Compass for SemanticTechnology Capabilities in the Ocean of LLMs](https://arxiv.org//abs/2505.13098)

	Lars-Peter Meyer, Johannes Frey, Desiree Heim, Felix Brei, Claus Stadler, Kurt Junghanns, Michael Martin

+ [Zero-Shot Iterative Formalization and Planning in Partially Observable Environments](https://arxiv.org//abs/2505.13126)

	Liancheng Gong, Wang Zhu, Jesse Thomason, Li Zhang

+ [Adversarial Testing in LLMs: Insights into Decision-Making Vulnerabilities](https://arxiv.org//abs/2505.13195)

	Lili Zhang, Haomiaomiao Wang, Long Cheng, Libao Deng, Tomas Ward

+ [Agentic Publications: An LLM-Driven Framework for Interactive Scientific Publishing, Supplementing Traditional Papers with AI-Powered Knowledge Systems](https://arxiv.org//abs/2505.13246)

	Roberto Pugliese, George Kourousias, Francesco Venier, Grazia Garlatti Costa

+ [Multi-Armed Bandits Meet Large Language Models](https://arxiv.org//abs/2505.13355)

	Djallel Bouneffouf, Raphael Feraud

+ [CompeteSMoE -- Statistically Guaranteed Mixture of Experts Training via Competition](https://arxiv.org//abs/2505.13380)

	Nam V. Nguyen, Huy Nguyen, Quang Pham, Van Nguyen, Savitha Ramasamy, Nhat Ho

+ [AutoMathKG: The automated mathematical knowledge graph based on LLM and vector database](https://arxiv.org//abs/2505.13406)

	Rong Bian, Yu Geng, Zijian Yang, Bing Cheng

+ [CoT-Kinetics: A Theoretical Modeling Assessing LRM Reasoning Process](https://arxiv.org//abs/2505.13408)

	Jinhe Bi, Danqi Yan, Yifan Wang, Wenke Huang, Haokun Chen, Guancheng Wan, Mang Ye, Xun Xiao, Hinrich Schuetze, Volker Tresp, Yunpu Ma

+ [MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable Step-Level Supervision](https://arxiv.org//abs/2505.13427)

	Lingxiao Du, Fanqing Meng, Zongkai Liu, Zhixiang Zhou, Ping Luo, Qiaosheng Zhang, Wenqi Shao

+ [Trust, But Verify: A Self-Verification Approach to Reinforcement Learning with Verifiable Rewards](https://arxiv.org//abs/2505.13445)

	Xiaoyuan Liu, Tian Liang, Zhiwei He, Jiahao Xu, Wenxuan Wang, Pinjia He, Zhaopeng Tu, Haitao Mi, Dong Yu

+ [AD-AGENT: A Multi-agent Framework for End-to-end Anomaly Detection](https://arxiv.org//abs/2505.12594)

	Tiankai Yang, Junjun Liu, Wingchun Siu, Jiahang Wang, Zhuangzhuang Qian, Chanjuan Song, Cheng Cheng, Xiyang Hu, Yue Zhao

+ [Web IP at Risk: Prevent Unauthorized Real-Time Retrieval by Large Language Models](https://arxiv.org//abs/2505.12655)

	Yisheng Zhong, Yizhu Wen, Junfeng Guo, Mehran Kafai, Heng Huang, Hanqing Guo, Zhuangdi Zhu

+ [Know3-RAG: A Knowledge-aware RAG Framework with Adaptive Retrieval, Generation, and Filtering](https://arxiv.org//abs/2505.12662)

	Xukai Liu, Ye Liu, Shiwen Wu, Yanghai Zhang, Yihao Yuan, Kai Zhang, Qi Liu

+ [Shadow-FT: Tuning Instruct via Base](https://arxiv.org//abs/2505.12716)

	Taiqiang Wu, Runming Yang, Jiayi Li, Pengfei Hu, Ngai Wong, Yujiu Yang

+ [Rethinking Reward Model Evaluation Through the Lens of Reward Overoptimization](https://arxiv.org//abs/2505.12763)

	Sunghwan Kim, Dongjin Kang, Taeyoon Kwon, Hyungjoo Chae, Dongha Lee, Jinyoung Yeo

+ [A Token is Worth over 1,000 Tokens: Efficient Knowledge Distillation through Low-Rank Clone](https://arxiv.org//abs/2505.12781)

	Jitai Hao, Qiang Huang, Hao Liu, Xinyan Xiao, Zhaochun Ren, Jun Yu

+ [PsyMem: Fine-grained psychological alignment and Explicit Memory Control for Advanced Role-Playing LLMs](https://arxiv.org//abs/2505.12814)

	Xilong Cheng, Yunxiao Qin, Yuting Tan, Zhengnan Li, Ye Wang, Hongjiang Xiao, Yuan Zhang

+ [The Hidden Structure -- Improving Legal Document Understanding Through Explicit Text Formatting](https://arxiv.org//abs/2505.12837)

	Christian Braun, Alexander Lilienbeck, Daniel Mentjukov

+ [Bias Fitting to Mitigate Length Bias of Reward Model in RLHF](https://arxiv.org//abs/2505.12843)

	Kangwen Zhao, Jianfeng Cai, Jinhua Zhu, Ruopei Sun, Dongyun Xue, Wengang Zhou, Li Li, Houqiang Li

+ [LEXam: Benchmarking Legal Reasoning on 340 Law Exams](https://arxiv.org//abs/2505.12864)

	Yu Fan, Jingwei Ni, Jakob Merane, Etienne Salimbeni, Yang Tian, Yoan Hermstrüwer, Yinya Huang, Mubashara Akhtar, Florian Geering, Oliver Dreyer, Daniel Brunner, Markus Leippold, Mrinmaya Sachan, Alexander Stremitzer, Christoph Engel, Elliott Ash, Joel Niklaus

+ [Does Low Rank Adaptation Lead to Lower Robustness against Training-Time Attacks?](https://arxiv.org//abs/2505.12871)

	Zi Liang, Haibo Hu, Qingqing Ye, Yaxin Xiao, Ronghua Li

+ [Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs](https://arxiv.org//abs/2505.12929)

	Zhihe Yang, Xufang Luo, Zilong Wang, Dongqi Han, Zhiyuan He, Dongsheng Li, Yunjian Xu

+ [Leveraging LLM Inconsistency to Boost Pass@k Performance](https://arxiv.org//abs/2505.12938)

	Uri Dalal, Meirav Segal, Zvika Ben-Haim, Dan Lahav, Omer Nevo

+ [A3 : an Analytical Low-Rank Approximation Framework for Attention](https://arxiv.org//abs/2505.12942)

	Jeffrey T. H. Wong, Cheng Zhang, Xinye Cao, Pedro Gimenes, George A. Constantinides, Wayne Luk, Yiren Zhao

+ [DGRO: Enhancing LLM Reasoning via Exploration-Exploitation Control and Reward Variance Management](https://arxiv.org//abs/2505.12951)

	Xuerui Su, Liya Guo, Yue Wang, Yi Zhu, Zhiming Ma, Zun Wang, Yuting Liu

+ [From Assistants to Adversaries: Exploring the Security Risks of Mobile LLM Agents](https://arxiv.org//abs/2505.12981)

	Liangxuan Wu, Chao Wang, Tianming Liu, Yanjie Zhao, Haoyu Wang

+ [Fractured Chain-of-Thought Reasoning](https://arxiv.org//abs/2505.12992)

	Baohao Liao, Hanze Dong, Yuhui Xu, Doyen Sahoo, Christof Monz, Junnan Li, Caiming Xiong

+ [Step-wise Adaptive Integration of Supervised Fine-tuning and Reinforcement Learning for Task-Specific LLMs](https://arxiv.org//abs/2505.13026)

	Jack Chen, Fazhong Liu, Naruto Liu, Yuhan Luo, Erqu Qin, Harry Zheng, Tian Dong, Haojin Zhu, Yan Meng, Xiao Wang

+ [Evaluatiing the efficacy of LLM Safety Solutions : The Palit Benchmark Dataset](https://arxiv.org//abs/2505.13028)

	Sayon Palit, Daniel Woods

+ [KIT's Offline Speech Translation and Instruction Following Submission for IWSLT 2025](https://arxiv.org//abs/2505.13036)

	Sai Koneru, Maike Züfle, Thai-Binh Nguyen, Seymanur Akti, Jan Niehues, Alexander Waibel

+ [The Hidden Dangers of Browsing AI Agents](https://arxiv.org//abs/2505.13076)

	Mykyta Mudryi, Markiyan Chaklosh, Grzegorz Wójcik

+ [FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference](https://arxiv.org//abs/2505.13109)

	Guangda Liu, Chengwei Li, Zhenyu Ning, Jing Lin, Yiwu Yao, Danning Ke, Minyi Guo, Jieru Zhao

+ [Role-Playing Evaluation for Large Language Models](https://arxiv.org//abs/2505.13157)

	Yassine El Boudouri, Walter Nuninger, Julian Alvarez, Yvan Peter

+ [ToolSpectrum : Towards Personalized Tool Utilization for Large Language Models](https://arxiv.org//abs/2505.13176)

	Zihao Cheng, Hongru Wang, Zeming Liu, Yuhang Guo, Yuanfang Guo, Yunhong Wang, Haifeng Wang

+ [WikiPersonas: What Can We Learn From Personalized Alignment to Famous People?](https://arxiv.org//abs/2505.13257)

	Zilu Tang, Afra Feyza Akyürek, Ekin Akyürek, Derry Wijaya

+ [Cross-Cloud Data Privacy Protection: Optimizing Collaborative Mechanisms of AI Systems by Integrating Federated Learning and LLMs](https://arxiv.org//abs/2505.13292)

	Huaiying Luo, Cheng Ji

+ [RBF++: Quantifying and Optimizing Reasoning Boundaries across Measurable and Unmeasurable Capabilities for Chain-of-Thought Reasoning](https://arxiv.org//abs/2505.13307)

	Qiguang Chen, Libo Qin, Jinhao Liu, Yue Liao, Jiaqi Wang, Jingxuan Zhou, Wanxiang Che

+ [Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space](https://arxiv.org//abs/2505.13308)

	Hengli Li, Chenxi Li, Tong Wu, Xuekai Zhu, Yuxuan Wang, Zhaoxin Yu, Eric Hanchen Jiang, Song-Chun Zhu, Zixia Jia, Ying Nian Wu, Zilong Zheng

+ [Contextual Paralinguistic Data Creation for Multi-Modal Speech-LLM: Data Condensation and Spoken QA Generation](https://arxiv.org//abs/2505.13338)

	Qiongqiong Wang, Hardik B. Sailor, Tianchi Liu, Ai Ti Aw

+ [J4R: Learning to Judge with Equivalent Initial State Group Relative Preference Optimization](https://arxiv.org//abs/2505.13346)

	Austin Xu, Yilun Zhou, Xuan-Phi Nguyen, Caiming Xiong, Shafiq Joty

+ [Thinkless: LLM Learns When to Think](https://arxiv.org//abs/2505.13379)

	Gongfan Fang, Xinyin Ma, Xinchao Wang

+ [R3: Robust Rubric-Agnostic Reward Models](https://arxiv.org//abs/2505.13388)

	David Anugraha, Zilu Tang, Lester James V. Miranda, Hanyang Zhao, Mohammad Rifqi Farhansyah, Garry Kuwanto, Derry Wijaya, Genta Indra Winata

+ [AdaptThink: Reasoning Models Can Learn When to Think](https://arxiv.org//abs/2505.13417)

	Jiajie Zhang, Nianyi Lin, Lei Hou, Ling Feng, Juanzi Li

+ [Learnware of Language Models: Specialized Small Language Models Can Do Big](https://arxiv.org//abs/2505.13425)

	Zhi-Hao Tan, Zi-Chen Zhao, Hao-Yu Shi, Xin-Yu Zhang, Peng Tan, Yang Yu, Zhi-Hua Zhou

+ [Optimizing Anytime Reasoning via Budget Relative Policy Optimization](https://arxiv.org//abs/2505.13438)

	Penghui Qi, Zichen Liu, Tianyu Pang, Chao Du, Wee Sun Lee, Min Lin

+ [CIE: Controlling Language Model Text Generations Using Continuous Signals](https://arxiv.org//abs/2505.13448)

	Vinay Samuel, Harshita Diddee, Yiming Zhang, Daphne Ippolito

+ [Improving Multilingual Language Models by Aligning Representations through Steering](https://arxiv.org//abs/2505.12584)

	Omar Mahmoud, Buddhika Laknath Semage, Thommen George Karimpanal, Santu Rana

+ [PromptPrism: A Linguistically-Inspired Taxonomy for Prompts](https://arxiv.org//abs/2505.12592)

	Sullam Jeoung, Yueyan Chen, Yi Zhang, Shuai Wang, Haibo Ding, Lin Lee Cheong

+ [Think Before You Attribute: Improving the Performance of LLMs Attribution Systems](https://arxiv.org//abs/2505.12621)

	João Eduardo Batista, Emil Vatai, Mohamed Wahib

+ [R1dacted: Investigating Local Censorship in DeepSeek's R1 Language Model](https://arxiv.org//abs/2505.12625)

	Ali Naseh, Harsh Chaudhari, Jaechul Roh, Mingshi Wu, Alina Oprea, Amir Houmansadr

+ [Revealing the Deceptiveness of Knowledge Editing: A Mechanistic Analysis of Superficial Editing](https://arxiv.org//abs/2505.12636)

	Jiakuan Xie, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao

+ [ToTRL: Unlock LLM Tree-of-Thoughts Reasoning Potential through Puzzles Solving](https://arxiv.org//abs/2505.12717)

	Haoyuan Wu, Xueyi Chen, Rui Ming, Jilong Gao, Shoubo Hu, Zhuolun He, Bei Yu

+ [Automated Bias Assessment in AI-Generated Educational Content Using CEAT Framework](https://arxiv.org//abs/2505.12718)

	Jingyang Peng, Wenyuan Shen, Jiarui Rao, Jionghao Lin

+ [ReEx-SQL: Reasoning with Execution-Aware Reinforcement Learning for Text-to-SQL](https://arxiv.org//abs/2505.12768)

	Yaxun Dai (1), Wenxuan Xie (3), Xialie Zhuang (4), Tianyu Yang (5), Yiying Yang (2), Haiqin Yang (6), Yuhang Zhao (2), Pingfu Chao (1), Wenhao Jiang (2) ((1) Soochow University, (2) Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), (3) South China University of Technology, (4) University of Chinese Academy of Sciences, (5) Alibaba DAMO Academy, (6) International Digital Economy Academy (IDEA))

+ [EAVIT: Efficient and Accurate Human Value Identification from Text data via LLMs](https://arxiv.org//abs/2505.12792)

	Wenhao Zhu, Yuhang Xie, Guojie Song, Xin Zhang

+ [Decentralized Arena: Towards Democratic and Scalable Automatic Evaluation of Language Models](https://arxiv.org//abs/2505.12808)

	Yanbin Yin, Kun Zhou, Zhen Wang, Xiangdong Zhang, Yifei Shao, Shibo Hao, Yi Gu, Jieyuan Liu, Somanshu Singla, Tianyang Liu, Eric P. Xing, Zhengzhong Liu, Haojian Jin, Zhiting Hu

+ [Contrastive Prompting Enhances Sentence Embeddings in LLMs through Inference-Time Steering](https://arxiv.org//abs/2505.12831)

	Zifeng Cheng, Zhonghui Wang, Yuchen Fu, Zhiwei Jiang, Yafeng Yin, Cong Wang, Qing Gu

+ [Re-identification of De-identified Documents with Autoregressive Infilling](https://arxiv.org//abs/2505.12859)

	Lucas Georges Gabriel Charpentier, Pierre Lison

+ [On the Thinking-Language Modeling Gap in Large Language Models](https://arxiv.org//abs/2505.12896)

	Chenxi Liu, Yongqiang Chen, Tongliang Liu, James Cheng, Bo Han, Kun Zhang

+ [GuRE:Generative Query REwriter for Legal Passage Retrieval](https://arxiv.org//abs/2505.12950)

	Daehee Kim, Deokhyung Kang, Jonghwi Kim, Sangwon Ryu, Gary Geunbae Lee

+ [Evaluating the Performance of RAG Methods for Conversational AI in the Airport Domain](https://arxiv.org//abs/2505.13006)

	Yuyang Li, Philip J.M. Kerbusch, Raimon H.R. Pruim, Tobias Käfer

+ [Systematic Generalization in Language Models Scales with Information Entropy](https://arxiv.org//abs/2505.13089)

	Sondre Wold, Lucas Georges Gabriel Charpentier, Étienne Simon

+ [Understanding Cross-Lingual Inconsistency in Large Language Models](https://arxiv.org//abs/2505.13141)

	Zheng Wei Lim, Alham Fikri Aji, Trevor Cohn

+ [Positional Fragility in LLMs: How Offset Effects Reshape Our Understanding of Memorization Risks](https://arxiv.org//abs/2505.13171)

	Yixuan Xu, Antoine Bosselut, Imanol Schlag

+ [A Case Study of Cross-Lingual Zero-Shot Generalization for Classical Languages in LLMs](https://arxiv.org//abs/2505.13173)

	V.S.D.S.Mahesh Akavarapu, Hrishikesh Terdalkar, Pramit Bhattacharyya, Shubhangi Agarwal, Vishakha Deulgaonkar, Pralay Manna, Chaitali Dangarikar, Arnab Bhattacharya

+ [Alignment-Augmented Speculative Decoding with Alignment Sampling and Conditional Verification](https://arxiv.org//abs/2505.13204)

	Jikai Wang, Zhenxu Tian, Juntao Li, Qingrong Xia, Xinyu Duan, Zhefeng Wang, Baoxing Huai, Min Zhang

+ [Natural Language Planning via Coding and Inference Scaling](https://arxiv.org//abs/2505.13252)

	Rikhil Amonkar, Ronan Le Bras, Li Zhang

+ [HeteroSpec: Leveraging Contextual Heterogeneity for Efficient Speculative Decoding](https://arxiv.org//abs/2505.13254)

	Siran Liu, Yang Ye, Qianchao Zhu, Zheng Cao, Yongchao He

+ [Effective and Transparent RAG: Adaptive-Reward Reinforcement Learning for Decision Traceability](https://arxiv.org//abs/2505.13258)

	Jingyi Ren, Yekun Xu, Xiaolong Wang, Weitao Li, Weizhi Ma, Yang Liu

+ [CSC-SQL: Corrective Self-Consistency in Text-to-SQL via Reinforcement Learning](https://arxiv.org//abs/2505.13271)

	Lei Sheng, Shuai-Shuai Xu

+ [GUARD: Generation-time LLM Unlearning via Adaptive Restriction and Detection](https://arxiv.org//abs/2505.13312)

	Zhijie Deng, Chris Yuhao Liu, Zirui Pang, Xinlei He, Lei Feng, Qi Xuan, Zhaowei Zhu, Jiaheng Wei

+ [Rethinking Stateful Tool Use in Multi-Turn Dialogues: Benchmarks and Challenges](https://arxiv.org//abs/2505.13328)

	Hongru Wang, Wenyu Huang, Yufei Wang, Yuanhao Xi, Jianqiao Lu, Huan Zhang, Nan Hu, Zeming Liu, Jeff Z. Pan, Kam-Fai Wong

+ [Investigating the Vulnerability of LLM-as-a-Judge Architectures to Prompt-Injection Attacks](https://arxiv.org//abs/2505.13348)

	Narek Maloyan, Bislan Ashinov, Dmitry Namiot

+ [Sense and Sensitivity: Examining the Influence of Semantic Recall on Long Context Code Reasoning](https://arxiv.org//abs/2505.13353)

	Adam Štorek, Mukur Gupta, Samira Hajizadeh, Prashast Srivastava, Suman Jana

+ [What Prompts Don't Say: Understanding and Managing Underspecification in LLM Prompts](https://arxiv.org//abs/2505.13360)

	Chenyang Yang, Yike Shi, Qianou Ma, Michael Xieyang Liu, Christian Kästner, Tongshuang Wu

+ [MR. Judge: Multimodal Reasoner as a Judge](https://arxiv.org//abs/2505.13403)

	Renjie Pi, Felix Bai, Qibin Chen, Simon Wang, Jiulong Shan, Kieran Liu, Meng Cao

+ [Dementia Through Different Eyes: Explainable Modeling of Human and LLM Perceptions for Early Awareness](https://arxiv.org//abs/2505.13418)

	Lotem Peled-Cohen, Maya Zadok, Nitay Calderon, Hila Gonen, Roi Reichart

+ [SMOTExT: SMOTE meets Large Language Models](https://arxiv.org//abs/2505.13434)

	Mateusz Bystroński, Mikołaj Hołysz, Grzegorz Piotrowski, Nitesh V. Chawla, Tomasz Kajdanowicz

+ [Enhancing Latent Computation in Transformers with Latent Tokens](https://arxiv.org//abs/2505.12629)

	Yuchang Sun, Yanxi Chen, Yaliang Li, Bolin Ding

+ [GEM: Gaussian Embedding Modeling for Out-of-Distribution Detection in GUI Agents](https://arxiv.org//abs/2505.12842)

	Zheng Wu, Pengzhou Cheng, Zongru Wu, Lingzhong Dong, Zhuosheng Zhang

+ [BusterX: MLLM-Powered AI-Generated Video Forgery Detection and Explanation](https://arxiv.org//abs/2505.12620)

	Haiquan Wen, Yiwei He, Zhenglin Huang, Tianxiao Li, Zihan YU, Xingru Huang, Lu Qi, Baoyuan Wu, Xiangtai Li, Guangliang Cheng

+ [Mitigating Hallucination in VideoLLMs via Temporal-Aware Activation Engineering](https://arxiv.org//abs/2505.12826)

	Jianfeng Cai, Wengang Zhou, Zongmeng Zhang, Jiale Hong, Nianji Zhan, Houqiang Li

+ [Walking the Tightrope: Disentangling Beneficial and Detrimental Drifts in Non-Stationary Custom-Tuning](https://arxiv.org//abs/2505.13081)

	Xiaoyu Yang, Jie Lu, En Yu

+ [Rethinking Predictive Modeling for LLM Routing: When Simple kNN Beats Complex Learned Routers](https://arxiv.org//abs/2505.12601)

	Yang Li

+ [RoFL: Robust Fingerprinting of Language Models](https://arxiv.org//abs/2505.12682)

	Yun-Yun Tsai, Chuan Guo, Junfeng Yang, Laurens van der Maaten

+ [Koopman Autoencoders Learn Neural Representation Dynamics](https://arxiv.org//abs/2505.12809)

	Nishant Suresh Aswani, Saif Eddin Jabari

+ [Unpacking Positional Encoding in Transformers: A Spectral Analysis of Content-Position Coupling](https://arxiv.org//abs/2505.13027)

	Zihan Gu, Han Zhang, Ruoyu Chen, Yue Hu, Hua Zhang

+ [Why Knowledge Distillation Works in Generative Models: A Minimal Working Explanation](https://arxiv.org//abs/2505.13111)

	Sungmin Cha, Kyunghyun Cho

+ [RN-F: A Novel Approach for Mitigating Contaminated Data in Large Language Models](https://arxiv.org//abs/2505.13249)

	Le Vu Anh, Dinh Duc Nha Nguyen, Phi Long Nguyen

+ [Thinking Short and Right Over Thinking Long: Serving LLM Reasoning Efficiently and Accurately](https://arxiv.org//abs/2505.13326)

	Yuhang Wang, Youhe Jiang, Bin Cui, Fangcheng Fu

+ [Occult: Optimizing Collaborative Communication across Experts for Accelerated Parallel MoE Training and Inference](https://arxiv.org//abs/2505.13345)

	Shuqing Luo, Pingzhi Li, Jie Peng, Hanrui Wang, Yang (Katie)Zhao, Yu (Kevin)Cao, Yu Cheng, Tianlong Chen

+ [DynaNoise: Dynamic Probabilistic Noise Injection for Defending Against Membership Inference Attacks](https://arxiv.org//abs/2505.13362)

	Javad Forough, Hamed Haddadi

+ [Prompt Stability Matters: Evaluating and Optimizing Auto-Generated Prompt in General-Purpose Systems](https://arxiv.org//abs/2505.13546)

	Ke Chen, Yufei Zhou, Xitong Zhang, Haohan Wang

+ [A*-Decoding: Token-Efficient Inference Scaling](https://arxiv.org//abs/2505.13672)

	Giannis Chatziveroglou

+ [Warm Up Before You Train: Unlocking General Reasoning in Resource-Constrained Settings](https://arxiv.org//abs/2505.13718)

	Safal Shrestha, Minwu Kim, Aadim Nepal, Anubhav Shrestha, Keith Ross

+ [Causal Head Gating: A Framework for Interpreting Roles of Attention Heads in Transformers](https://arxiv.org//abs/2505.13737)

	Andrew Nam, Henry Conklin, Yukang Yang, Thomas Griffiths, Jonathan Cohen, Sarah-Jane Leslie

+ [Language Models Are Capable of Metacognitive Monitoring and Control of Their Internal Activations](https://arxiv.org//abs/2505.13763)

	Li Ji-An, Hua-Dong Xiong, Robert C. Wilson, Marcelo G. Mattar, Marcus K. Benna

+ [Measuring the Faithfulness of Thinking Drafts in Large Reasoning Models](https://arxiv.org//abs/2505.13774)

	Zidi Xiong, Chen Shan, Zhenting Qi, Himabindu Lakkaraju

+ [CoIn: Counting the Invisible Reasoning Tokens in Commercial Opaque LLM APIs](https://arxiv.org//abs/2505.13778)

	Guoheng Sun, Ziyao Wang, Bowei Tian, Meng Liu, Zheyu Shen, Shwai He, Yexiao He, Wanghao Ye, Yiting Wang, Ang Li

+ [Know Or Not: a library for evaluating out-of-knowledge base robustness](https://arxiv.org//abs/2505.13545)

	Jessica Foo, Pradyumna Shyama Prasad, Shaun Khoo

+ [Exploring Federated Pruning for Large Language Models](https://arxiv.org//abs/2505.13547)

	Pengxin Guo, Yinong Wang, Wei Li, Mengting Liu, Ming Li, Jinkai Zheng, Liangqiong Qu

+ [AMAQA: A Metadata-based QA Dataset for RAG Systems](https://arxiv.org//abs/2505.13557)

	Davide Bruni, Marco Avvenuti, Nicola Tonellotto, Maurizio Tesconi

+ [VocalAgent: Large Language Models for Vocal Health Diagnostics with Safety-Aware Evaluation](https://arxiv.org//abs/2505.13577)

	Yubin Kim, Taehan Kim, Wonjune Kang, Eugene Park, Joonsik Yoon, Dongjae Lee, Xin Liu, Daniel McDuff, Hyeonhoon Lee, Cynthia Breazeal, Hae Won Park

+ [RL in Name Only? Analyzing the Structural Assumptions in RL post-training for LLMs](https://arxiv.org//abs/2505.13697)

	Soumya Rani Samineni, Durgesh Kalwar, Karthik Valmeekam, Kaya Stechly, Subbarao Kambhampati

+ [Power Lines: Scaling Laws for Weight Decay and Batch Size in LLM Pre-training](https://arxiv.org//abs/2505.13738)

	Shane Bergsma, Nolan Dey, Gurpreet Gosal, Gavia Gray, Daria Soboleva, Joel Hestness

+ [Beyond Semantics: The Unreasonable Effectiveness of Reasonless Intermediate Tokens](https://arxiv.org//abs/2505.13775)

	Kaya Stechly, Karthik Valmeekam, Atharva Gundawar, Vardhan Palod, Subbarao Kambhampati

+ [SQLForge: Synthesizing Reliable and Diverse Data to Enhance Text-to-SQL Reasoning in LLMs](https://arxiv.org//abs/2505.13725)

	Yu Guo, Dong Jin, Shenghao Ye, Shuangwu Chen, Jian Yang, Xiaobin Tan

+ [Simulation Agent: A Framework for Integrating Simulation and Large Language Models for Enhanced Decision-Making](https://arxiv.org//abs/2505.13761)

	Jacob Kleiman, Kevin Frank, Sindy Campagna

+ [RAR: Setting Knowledge Tripwires for Retrieval Augmented Rejection](https://arxiv.org//abs/2505.13581)

	Tommaso Mario Buonocore, Enea Parimbelli

+ [Guided Search Strategies in Non-Serializable Environments with Applications to Software Engineering Agents](https://arxiv.org//abs/2505.13652)

	Karina Zainullina, Alexander Golubev, Maria Trofimova, Sergei Polezhaev, Ibragim Badertdinov, Daria Litvintseva, Simon Karasik, Filipp Fisin, Sergei Skvortsov, Maksim Nekrashevich, Anton Shevtsov, Boris Yangel

+ [LLM-Based Compact Reranking with Document Features for Scientific Retrieval](https://arxiv.org//abs/2505.13757)

	Runchu Tian, Xueqiang Xu, Bowen Jin, SeongKu Kang, Jiawei Han

+ [Incentivizing Truthful Language Models via Peer Elicitation Games](https://arxiv.org//abs/2505.13636)

	Baiting Chen, Tong Zhu, Jiale Han, Lexin Li, Gang Li, Xiaowu Dai

+ [Selective Code Generation for Functional Guarantees](https://arxiv.org//abs/2505.13553)

	Jaewoo Jeong, Taesoo Kim, Sangdon Park

+ [BeamClean: Language Aware Embedding Reconstruction](https://arxiv.org//abs/2505.13758)

	Kaan Kale, Kyle Mylonakis, Jay Roberts, Sidhartha Roy

+ [Safety Alignment Can Be Not Superficial With Explicit Safety Signals](https://arxiv.org//abs/2505.17072)

	Jianwei Li, Jung-Eng Kim

+ [What's in a prompt? Language models encode literary style in prompt embeddings](https://arxiv.org//abs/2505.17071)

	Raphaël Sarfati, Haley Moller, Toni J. B. Liu, Nicolas Boullé, Christopher Earls

+ [Security Degradation in Iterative AI Code Generation -- A Systematic Analysis of the Paradox](https://arxiv.org//abs/2506.11022)

	Shivani Shukla, Himanshu Joshi, Romilla Syed

# 2025-05-18
+ [Mitigating Content Effects on Reasoning in Language Models through Fine-Grained Activation Steering](https://arxiv.org//abs/2505.12189)

	Marco Valentino, Geonhee Kim, Dhairya Dalal, Zhixue Zhao, André Freitas

+ [Beyond Single-Point Judgment: Distribution Alignment for LLM-as-a-Judge](https://arxiv.org//abs/2505.12301)

	Luyu Chen, Zeyu Zhang, Haoran Tan, Quanyu Dai, Hao Yang, Zhenhua Dong, Xu Chen

+ [BeliefNest: A Joint Action Simulator for Embodied Agents with Theory of Mind](https://arxiv.org//abs/2505.12321)

	Rikunari Sagara, Koichiro Terao, Naoto Iwahashi

+ [Enhancing User-Oriented Proactivity in Open-Domain Dialogues with Critic Guidance](https://arxiv.org//abs/2505.12334)

	Yufeng Wang, Jinwu Hu, Ziteng Huang, Kunyang Lin, Zitian Zhang, Peihao Chen, Yu Hu, Qianyue Wang, Zhuliang Yu, Bin Sun, Xiaofen Xing, Qingfang Zheng, Mingkui Tan

+ [SEED-GRPO: Semantic Entropy Enhanced GRPO for Uncertainty-Aware Policy Optimization](https://arxiv.org//abs/2505.12346)

	Minghan Chen, Guikun Chen, Wenguan Wang, Yi Yang

+ [Reasoning-CV: Fine-tuning Powerful Reasoning LLMs for Knowledge-Assisted Claim Verification](https://arxiv.org//abs/2505.12348)

	Zhi Zheng, Wee Sun Lee

+ [MedAgentBoard: Benchmarking Multi-Agent Collaboration with Conventional Methods for Diverse Medical Tasks](https://arxiv.org//abs/2505.12371)

	Yinghao Zhu, Ziyi He, Haoran Hu, Xiaochen Zheng, Xichen Zhang, Zixiang Wang, Junyi Gao, Liantao Ma, Lequan Yu

+ [NeuroGen: Neural Network Parameter Generation via Large Language Models](https://arxiv.org//abs/2505.12470)

	Jiaqi Wang, Yusen Zhang, Xi Li

+ [UIShift: Enhancing VLM-based GUI Agents through Self-supervised Reinforcement Learning](https://arxiv.org//abs/2505.12493)

	Longxi Gao, Li Zhang, Mengwei Xu

+ [MARGE: Improving Math Reasoning for LLMs with Guided Exploration](https://arxiv.org//abs/2505.12500)

	Jingyue Gao, Runji Lin, Keming Lu, Bowen Yu, Junyang Lin, Jianyu Chen

+ [ALAS: A Stateful Multi-LLM Agent Framework for Disruption-Aware Planning](https://arxiv.org//abs/2505.12501)

	Edward Y. Chang, Longling Geng

+ [Decoding the Mind of Large Language Models: A Quantitative Evaluation of Ideology and Biases](https://arxiv.org//abs/2505.12183)

	Manari Hirose, Masato Uchida

+ [Self-Destructive Language Model](https://arxiv.org//abs/2505.12186)

	Yuhui Wang, Rongyi Zhu, Ting Wang

+ [LLM-DSE: Searching Accelerator Parameters with LLM Agents](https://arxiv.org//abs/2505.12188)

	Hanyu Wang, Xinrui Wu, Zijian Ding, Su Zheng, Chengyue Wang, Tony Nowatzki, Yizhou Sun, Jason Cong

+ [Reward Inside the Model: A Lightweight Hidden-State Reward Model for LLM's Best-of-N sampling](https://arxiv.org//abs/2505.12225)

	Jizhou Guo, Zhaomin Wu, Philip S. Yu

+ [PANORAMA: A synthetic PII-laced dataset for studying sensitive data memorization in LLMs](https://arxiv.org//abs/2505.12238)

	Sriram Selvam, Anneswa Ghosh

+ [ACU: Analytic Continual Unlearning for Efficient and Exact Forgetting with Privacy Preservation](https://arxiv.org//abs/2505.12239)

	Jianheng Tang, Huiping Zhuang, Di Fang, Jiaxu Li, Feijiang Han, Yajiang Huang, Kejia Fan, Leye Wang, Zhanxing Zhu, Shanghang Zhang, Houbing Herbert Song, Yunhuai Liu

+ [LAMeTA: Intent-Aware Agentic Network Optimization via a Large AI Model-Empowered Two-Stage Approach](https://arxiv.org//abs/2505.12247)

	Yinqiu Liu, Guangyuan Liu, Jiacheng Wang, Ruichen Zhang, Dusit Niyato, Geng Sun, Zehui Xiong, Zhu Han

+ [Not All Documents Are What You Need for Extracting Instruction Tuning Data](https://arxiv.org//abs/2505.12250)

	Chi Zhang, Huaping Zhong, Hongtao Li, Chengliang Chai, Jiawei Hong, Yuhao Deng, Jiacheng Wang, Tian Tan, Yizhou Yan, Jiantao Qiu, Ye Yuan, Guoren Wang, Conghui He, Lei Cao

+ [LightRetriever: A LLM-based Hybrid Retrieval Architecture with 1000x Faster Query Inference](https://arxiv.org//abs/2505.12260)

	Guangyuan Ma, Yongliang Ma, Xuanrui Gou, Zhenpeng Su, Ming Zhou, Songlin Hu

+ [The Tower of Babel Revisited: Multilingual Jailbreak Prompts on Closed-Source Large Language Models](https://arxiv.org//abs/2505.12287)

	Linghan Huang, Haolin Jin, Zhaoge Bi, Pengyue Yang, Peizhou Zhao, Taozhao Chen, Xiongfei Wu, Lei Ma, Huaming Chen

+ [Mitigating Hallucinations via Inter-Layer Consistency Aggregation in Large Vision-Language Models](https://arxiv.org//abs/2505.12343)

	Kai Tang, Jinhao You, Xiuqi Ge, Hanze Li, Yichen Guo, Xiande Huang

+ [Wisdom from Diversity: Bias Mitigation Through Hybrid Human-LLM Crowds](https://arxiv.org//abs/2505.12349)

	Axel Abels, Tom Lenaerts

+ [DisCO: Reinforcing Large Reasoning Models with Discriminative Constrained Optimization](https://arxiv.org//abs/2505.12366)

	Gang Li, Ming Lin, Tomer Galanti, Zhengzhong Tu, Tianbao Yang

+ [CAPTURE: Context-Aware Prompt Injection Testing and Robustness Enhancement](https://arxiv.org//abs/2505.12368)

	Gauri Kholkar, Ratinder Ahuja

+ [From n-gram to Attention: How Model Architectures Learn and Propagate Bias in Language Modeling](https://arxiv.org//abs/2505.12381)

	Mohsinul Kabir, Tasfia Tahsin, Sophia Ananiadou

+ [Traversal Verification for Speculative Tree Decoding](https://arxiv.org//abs/2505.12398)

	Yepeng Weng, Qiao Hu, Xujie Chen, Li Liu, Dianwen Mei, Huishi Qiu, Jiang Tian, Zhongchao Shi

+ [PSC: Extending Context Window of Large Language Models via Phase Shift Calibration](https://arxiv.org//abs/2505.12423)

	Wenqiao Zhu, Chao Xu, Lulu Wang, Jun Wu

+ [EvoGPT: Enhancing Test Suite Robustness via LLM-Based Generation and Genetic Optimization](https://arxiv.org//abs/2505.12424)

	Lior Broide, Roni Stern

+ [Observe-R1: Unlocking Reasoning Abilities of MLLMs with Dynamic Progressive Reinforcement Learning](https://arxiv.org//abs/2505.12432)

	Zirun Guo, Minjie Hong, Tao Jin

+ [SRLoRA: Subspace Recomposition in Low-Rank Adaptation via Importance-Based Fusion and Reinitialization](https://arxiv.org//abs/2505.12433)

	Haodong Yang, Lei Wang, Md Zakir Hossain

+ [SGDPO: Self-Guided Direct Preference Optimization for Language Model Alignment](https://arxiv.org//abs/2505.12435)

	Wenqiao Zhu, Ji Liu, Lulu Wang, Jun Wu, Yulun Zhang

+ [IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems](https://arxiv.org//abs/2505.12442)

	Liwen Wang, Wenxuan Wang, Shuai Wang, Zongjie Li, Zhenlan Ji, Zongyi Lyu, Daoyuan Wu, Shing-Chi Cheung

+ [Beyond Frameworks: Unpacking Collaboration Strategies in Multi-Agent Systems](https://arxiv.org//abs/2505.12467)

	Haochun Wang, Sendong Zhao, Jingbo Wang, Zewen Qiang, Bing Qin, Ting Liu

+ [Enhancing Large Language Models with Reward-guided Tree Search for Knowledge Graph Question and Answering](https://arxiv.org//abs/2505.12476)

	Xiao Long, Liansheng Zhuang, Chen Shen, Shaotian Yan, Yifei Li, Shafei Wang

+ [CPGD: Toward Stable Rule-based Reinforcement Learning for Language Models](https://arxiv.org//abs/2505.12504)

	Zongkai Liu, Fanqing Meng, Lingxiao Du, Zhixiang Zhou, Chao Yu, Wenqi Shao, Qiaosheng Zhang

+ [Towards Budget-Friendly Model-Agnostic Explanation Generation for Large Language Models](https://arxiv.org//abs/2505.12509)

	Junhao Liu, Haonan Yu, Xin Zhang

+ [A Survey of Attacks on Large Language Models](https://arxiv.org//abs/2505.12567)

	Wenrui Xu, Keshab K. Parhi

+ [Measuring Information Distortion in Hierarchical Ultra long Novel Generation:The Optimal Expansion Ratio](https://arxiv.org//abs/2505.12572)

	Hanwen Shen, Ting Ying

+ [Truth Neurons](https://arxiv.org//abs/2505.12182)

	Haohang Li, Yupeng Cao, Yangyang Yu, Jordan W. Suchow, Zining Zhu

+ [How Reliable is Multilingual LLM-as-a-Judge?](https://arxiv.org//abs/2505.12201)

	Xiyan Fu, Wei Liu

+ [Data Whisperer: Efficient Data Selection for Task-Specific LLM Fine-Tuning via Few-Shot In-Context Learning](https://arxiv.org//abs/2505.12212)

	Shaobo Wang, Ziming Wang, Xiangqi Jin, Jize Wang, Jiajun Zhang, Kaixin Li, Zichen Wen, Zhong Li, Conghui He, Xuming Hu, Linfeng Zhang

+ [GMSA: Enhancing Context Compression via Group Merging and Layer Semantic Alignment](https://arxiv.org//abs/2505.12215)

	Jiwei Tang, Zhicheng Zhang, Shunlong Wu, Jingheng Ye, Lichen Bai, Zitai Wang, Tingwei Lu, Jiaqi Chen, Lin Hai, Hai-Tao Zheng, Hong-Gee Kim

+ [One-for-All Pruning: A Universal Model for Customized Compression of Large Language Models](https://arxiv.org//abs/2505.12216)

	Rongguang Ye, Ming Tang

+ [Distribution Prompting: Understanding the Expressivity of Language Models Through the Next-Token Distributions They Can Produce](https://arxiv.org//abs/2505.12244)

	Haojin Wang, Zining Zhu, Freda Shi

+ [Teach2Eval: An Indirect Evaluation Method for LLM by Judging How It Teaches](https://arxiv.org//abs/2505.12259)

	Yuhang Zhou, Xutian Chen, Yixin Cao, Yuchen Ni, Yu He, Siyu Tian, Xiang Liu, Jian Zhang, Chuanjun Ji, Guangnan Ye, Xipeng Qiu

+ [Learning Auxiliary Tasks Improves Reference-Free Hallucination Detection in Open-Domain Long-Form Generation](https://arxiv.org//abs/2505.12265)

	Chengwei Qin, Wenxuan Zhou, Karthik Abinav Sankararaman, Nanshu Wang, Tengyu Xu, Alexander Radovic, Eryk Helenowski, Arya Talebzadeh, Aditya Tayade, Sinong Wang, Shafiq Joty, Han Fang, Hao Ma

+ [$K$-MSHC: Unmasking Minimally Sufficient Head Circuits in Large Language Models with Experiments on Syntactic Classification Tasks](https://arxiv.org//abs/2505.12268)

	Pratim Chowdhary

+ [LLM-Based Evaluation of Low-Resource Machine Translation: A Reference-less Dialect Guided Approach with a Refined Sylheti-English Benchmark](https://arxiv.org//abs/2505.12273)

	Md. Atiqur Rahman, Sabrina Islam, Mushfiqul Haque Omi

+ [HBO: Hierarchical Balancing Optimization for Fine-Tuning Large Language Models](https://arxiv.org//abs/2505.12300)

	Weixuan Wang, Minghao Wu, Barry Haddow, Alexandra Birch

+ [Bidirectional LMs are Better Knowledge Memorizers? A Benchmark for Real-world Knowledge Injection](https://arxiv.org//abs/2505.12306)

	Yuwei Zhang, Wenhao Yu, Shangbin Feng, Yifan Zhu, Letian Peng, Jayanth Srinivasa, Gaowen Liu, Jingbo Shang

+ [ExpertSteer: Intervening in LLMs through Expert Knowledge](https://arxiv.org//abs/2505.12313)

	Weixuan Wang, Minghao Wu, Barry Haddow, Alexandra Birch

+ [LLMSR@XLLM25: An Empirical Study of LLM for Structural Reasoning](https://arxiv.org//abs/2505.12328)

	Xinye Li, Mingqi Wan, Dianbo Sui

+ [UniEdit: A Unified Knowledge Editing Benchmark for Large Language Models](https://arxiv.org//abs/2505.12345)

	Qizhou Chen, Dakan Wang, Taolin Zhang, Zaoming Yan, Chengsong You, Chengyu Wang, Xiaofeng He

+ [SLOT: Sample-specific Language Model Optimization at Test-time](https://arxiv.org//abs/2505.12392)

	Yang Hu, Xingyu Zhang, Xueji Fang, Zhiyang Chen, Xiao Wang, Huatian Zhang, Guojun Qi

+ [Learning to Play Like Humans: A Framework for LLM Adaptation in Interactive Fiction Games](https://arxiv.org//abs/2505.12439)

	Jinming Zhang, Yunfei Long

+ [Introspective Growth: Automatically Advancing LLM Expertise in Technology Judgment](https://arxiv.org//abs/2505.12452)

	Siyang Wu, Honglin Bao, Nadav Kunievsky, James A. Evans

+ [What are they talking about? Benchmarking Large Language Models for Knowledge-Grounded Discussion Summarization](https://arxiv.org//abs/2505.12474)

	Weixiao Zhou, Junnan Zhu, Gengyao Li, Xianfu Cheng, Xinnian Liang, Feifei Zhai, Zhoujun Li

+ [KG-QAGen: A Knowledge-Graph-Based Framework for Systematic Question Generation and Long-Context LLM Evaluation](https://arxiv.org//abs/2505.12495)

	Nikita Tatarinov, Vidhyakshaya Kannan, Haricharana Srinivasa, Arnav Raj, Harpreet Singh Anand, Varun Singh, Aditya Luthra, Ravij Lade, Agam Shah, Sudheer Chava

+ [LM$^2$otifs : An Explainable Framework for Machine-Generated Texts Detection](https://arxiv.org//abs/2505.12507)

	Xu Zheng, Zhuomin Chen, Esteban Schafir, Sipeng Chen, Hojat Allah Salehi, Haifeng Chen, Farhad Shirani, Wei Cheng, Dongsheng Luo

+ [ESC-Judge: A Framework for Comparing Emotional Support Conversational Agents](https://arxiv.org//abs/2505.12531)

	Navid Madani, Rohini Srihari

+ [Disambiguation in Conversational Question Answering in the Era of LLM: A Survey](https://arxiv.org//abs/2505.12543)

	Md Mehrab Tanjim, Yeonjun In, Xiang Chen, Victor S. Bursztyn, Ryan A. Rossi, Sungchul Kim, Guang-Jie Ren, Vaishnavi Muppala, Shun Jiang, Yongsung Kim, Chanyoung Park

+ [Extracting memorized pieces of (copyrighted) books from open-weight language models](https://arxiv.org//abs/2505.12546)

	A. Feder Cooper, Aaron Gokaslan, Amy B. Cyphert, Christopher De Sa, Mark A. Lemley, Daniel E. Ho, Percy Liang

+ [EVALOOP: Assessing LLM Robustness in Programming from a Self-consistency Perspective](https://arxiv.org//abs/2505.12185)

	Sen Fang, Weiyuan Ding, Bowen Xu

+ [LogicOCR: Do Your Large Multimodal Models Excel at Logical Reasoning on Text-Rich Images?](https://arxiv.org//abs/2505.12307)

	Maoyuan Ye, Jing Zhang, Juhua Liu, Bo Du, Dacheng Tao

+ [UFO-RL: Uncertainty-Focused Optimization for Efficient Reinforcement Learning Data Selection](https://arxiv.org//abs/2505.12457)

	Yang Zhao, Kai Xiong, Xiao Ding, Li Du, YangouOuyang, Zhouhao Sun, Jiannan Guan, Wenbin Zhang, Bin Liu, Dong Hu, Bing Qin, Ting Liu

+ [From Shots to Stories: LLM-Assisted Video Editing with Unified Language Representations](https://arxiv.org//abs/2505.12237)

	Yuzhi Li, Haojun Xu, Fang Tian

+ [SchoenbAt: Rethinking Attention with Polynomial basis](https://arxiv.org//abs/2505.12252)

	Yuhan Guo, Lizhong Ding, Yuwan Yang, Xuewei Guo

+ [Graph-Reward-SQL: Execution-Free Reinforcement Learning for Text-to-SQL via Graph Matching and Stepwise Reward](https://arxiv.org//abs/2505.12380)

	Han Weng, Boyi Liu, Yuanfeng Song, Dun Zeng, Yingxiang Yang, Yi Zhan, Longjie Cui, Xiaoming Yin, Yang Sun

+ [AltLoRA: Towards Better Gradient Approximation in Low-Rank Adaptation with Alternating Projections](https://arxiv.org//abs/2505.12455)

	Xin Yu, Yujia Wang, Jinghui Chen, Lingzhou Xue

+ [Reasoning by Superposition: A Theoretical Perspective on Chain of Continuous Thought](https://arxiv.org//abs/2505.12514)

	Hanlin Zhu, Shibo Hao, Zhiting Hu, Jiantao Jiao, Stuart Russell, Yuandong Tian

+ [Harnessing the Universal Geometry of Embeddings](https://arxiv.org//abs/2505.12540)

	Rishi Jha, Collin Zhang, Vitaly Shmatikov, John X. Morris

+ [Adaptive parameter-efficient fine-tuning via Hessian-informed subset selection](https://arxiv.org//abs/2505.12579)

	Shiyun Xu, Zhiqi Bu

+ [OSS-Bench: Benchmark Generator for Coding LLMs](https://arxiv.org//abs/2505.12331)

	Yuancheng Jiang, Roland Yap, Zhenkai Liang

+ [Automated Profile Inference with Language Model Agents](https://arxiv.org//abs/2505.12402)

	Yuntao Du, Zitao Li, Bolin Ding, Yaliang Li, Hanshen Xiao, Jingren Zhou, Ninghui Li

+ [BARREL: Boundary-Aware Reasoning for Factual and Reliable LRMs](https://arxiv.org//abs/2505.13529)

	Junxiao Yang, Jinzhe Tu, Haoran Liu, Xiaoce Wang, Chujie Zheng, Zhexin Zhang, Shiyao Cui, Caishun Chen, Tiantian He, Hongning Wang, Yew-Soon Ong, Minlie Huang

+ [LLM Context Conditioning and PWP Prompting for Multimodal Validation of Chemical Formulas](https://arxiv.org//abs/2505.12257)

	Evgeny Markhasin

+ [Logic Jailbreak: Efficiently Unlocking LLM Safety Restrictions Through Formal Logical Expression](https://arxiv.org//abs/2505.13527)

	Jingyu Peng, Maolin Wang, Nan Wang, Xiangyu Zhao, Jiatong Li, Kai Zhang, Qi Liu

+ [LLM-Based User Simulation for Low-Knowledge Shilling Attacks on Recommender Systems](https://arxiv.org//abs/2505.13528)

	Shengkang Gu, Jiahao Liu, Dongsheng Li, Guangping Zhang, Mingzhe Han, Hansu Gu, Peng Zhang, Ning Gu, Li Shang, Tun Lu

+ [AdAEM: An Adaptively and Automated Extensible Measurement of LLMs' Value Difference](https://arxiv.org//abs/2505.13531)

	Shitong Duan, Xiaoyuan Yi, Peng Zhang, Dongkuan Xu, Jing Yao, Tun Lu, Ning Gu, Xing Xie

+ [RAGXplain: From Explainable Evaluation to Actionable Guidance of RAG Pipelines](https://arxiv.org//abs/2505.13538)

	Dvir Cohen, Lin Burg, Gilad Barkan

+ [SPIRIT: Patching Speech Language Models against Jailbreak Attacks](https://arxiv.org//abs/2505.13541)

	Amirbek Djanibekov, Nurdaulet Mukhituly, Kentaro Inui, Hanan Aldarmaki, Nils Lukas

+ [Improving LLM Outputs Against Jailbreak Attacks with Expert Model Integration](https://arxiv.org//abs/2505.17066)

	Tatia Tsmindashvili, Ana Kolkhidashvili, Dachi Kurtskhalia, Nino Maghlakelidze, Elene Mekvabishvili, Guram Dentoshvili, Orkhan Shamilov, Zaal Gachechiladze, Steven Saporta, David Dachi Choladze

+ [KVmix: Gradient-Based Layer Importance-Aware Mixed-Precision Quantization for KV Cache](https://arxiv.org//abs/2506.08018)

	Fei Li, Song Liu, Weiguo Wu, Shiqiang Nie, Jinyu Wang

+ [Table-R1: Region-based Reinforcement Learning for Table Understanding](https://arxiv.org//abs/2505.12415)

	Zhenhe Wu, Jian Yang, Jiaheng Liu, Xianjie Wu, Changzai Pan, Jie Zhang, Yu Zhao, Shuangyong Song, Yongxiang Li, Zhoujun Li

# 2025-05-17
+ [Solver-Informed RL: Grounding Large Language Models for Authentic Optimization Modeling](https://arxiv.org//abs/2505.11792)

	Yitian Chen, Jingfan Xia, Siyu Shao, Dongdong Ge, Yinyu Ye

+ [ChatHTN: Interleaving Approximate (LLM) and Symbolic HTN Planning](https://arxiv.org//abs/2505.11814)

	Hector Munoz-Avila, David W. Aha, Paola Rizzo

+ [ToLeaP: Rethinking Development of Tool Learning with Large Language Models](https://arxiv.org//abs/2505.11833)

	Haotian Chen, Zijun Song, Boye Niu, Ke Zhang, Litu Ou, Yaxi Lu, Zhong Zhang, Xin Cong, Yankai Lin, Zhiyuan Liu, Maosong Sun

+ [On the Eligibility of LLMs for Counterfactual Reasoning: A Decompositional Study](https://arxiv.org//abs/2505.11839)

	Shuai Yang, Qi Yang, Luoxi Tang, Jeremy Blackburn, Zhaohan Xi

+ [Evaluating the Logical Reasoning Abilities of Large Reasoning Models](https://arxiv.org//abs/2505.11854)

	Hanmeng Liu, Yiran Ding, Zhizhang Fu, Chaoli Zhang, Xiaozhang Liu, Yue Zhang

+ [Fair-PP: A Synthetic Dataset for Aligning LLM with Personalized Preferences of Social Equity](https://arxiv.org//abs/2505.11861)

	Qi Zhou, Jie Zhang, Dongxia Wang, Qiang Liu, Tianlin Li, Jin Song Dong, Wenhai Wang, Qing Guo

+ [LifelongAgentBench: Evaluating LLM Agents as Lifelong Learners](https://arxiv.org//abs/2505.11942)

	Junhao Zheng, Xidi Cai, Qiuke Li, Duzhen Zhang, ZhongZhi Li, Yingying Zhang, Le Song, Qianli Ma

+ [Solve-Detect-Verify: Inference-Time Scaling with Flexible Generative Verifier](https://arxiv.org//abs/2505.11966)

	Jianyuan Zhong, Zeju Li, Zhijian Xu, Xiangyu Wen, Kezhi Li, Qiang Xu

+ [Interactional Fairness in LLM Multi-Agent Systems: An Evaluation Framework](https://arxiv.org//abs/2505.12001)

	Ruta Binkyte

+ [SOCIA: An End-to-End Agentic Framework for Automated Cyber-Physical-Social Simulator Generation](https://arxiv.org//abs/2505.12006)

	Yuncheng Hua, Ji Miao, Mehdi Jafari, Jianxiang Xie, Hao Xue, Flora D. Salim

+ [LLM-based Automated Theorem Proving Hinges on Scalable Synthetic Data Generation](https://arxiv.org//abs/2505.12031)

	Junyu Lai, Jiakun Zhang, Shuo Xu, Taolue Chen, Zihang Wang, Yao Yang, Jiarui Zhang, Chun Cao, Jingwei Xu

+ [Tiny QA Benchmark++: Ultra-Lightweight, Synthetic Multilingual Dataset Generation & Smoke-Tests for Continuous LLM Evaluation](https://arxiv.org//abs/2505.12058)

	Vincent Koc

+ [Demystifying and Enhancing the Efficiency of Large Language Model Based Search Agents](https://arxiv.org//abs/2505.12065)

	Tiannuo Yang, Zebin Yao, Bowen Jin, Lixiao Cui, Yusen Li, Gang Wang, Xiaoguang Liu

+ [LLM-BABYBENCH: Understanding and Evaluating Grounded Planning and Reasoning in LLMs](https://arxiv.org//abs/2505.12135)

	Omar Choukrani, Idriss Malek, Daniil Orel, Zhuohan Xie, Zangir Iklassov, Martin Takáč, Salem Lahlou

+ [OMAC: A Broad Optimization Framework for LLM-Based Multi-Agent Collaboration](https://arxiv.org//abs/2505.11765)

	Shijun Li, Hilaf Hasson, Joydeep Ghosh

+ [Internal Causal Mechanisms Robustly Predict Language Model Out-of-Distribution Behaviors](https://arxiv.org//abs/2505.11770)

	Jing Huang, Junyi Tao, Thomas Icard, Diyi Yang, Christopher Potts

+ [Retrospex: Language Agent Meets Offline Reinforcement Learning Critic](https://arxiv.org//abs/2505.11807)

	Yufei Xiang, Yiqun Shen, Yeqin Zhang, Cam-Tu Nguyen

+ [Search-Based Correction of Reasoning Chains for Language Models](https://arxiv.org//abs/2505.11824)

	Minsu Kim, Jean-Pierre Falet, Oliver E. Richardson, Xiaoyin Chen, Moksh Jain, Sungjin Ahn, Sungsoo Ahn, Yoshua Bengio

+ [Not All Thoughts are Generated Equal: Efficient LLM Reasoning via Multi-Turn Reinforcement Learning](https://arxiv.org//abs/2505.11827)

	Yansong Ning, Wei Li, Jun Fang, Naiqiang Tan, Hao Liu

+ [Multilingual Collaborative Defense for Large Language Models](https://arxiv.org//abs/2505.11835)

	Hongliang Li, Jinan Xu, Gengping Cui, Changhao Guan, Fengran Mo, Kaiyu Huang

+ [On Membership Inference Attacks in Knowledge Distillation](https://arxiv.org//abs/2505.11837)

	Ziyao Cui, Minxing Zhang, Jian Pei

+ [Mobile-Bench-v2: A More Realistic and Comprehensive Benchmark for VLM-based Mobile Agents](https://arxiv.org//abs/2505.11891)

	Weikai Xu, Zhizheng Jiang, Yuxuan Liu, Wei Liu, Jian Luan, Yuanchun Li, Yunxin Liu, Bin Wang, Bo An

+ [RLAP: A Reinforcement Learning Enhanced Adaptive Planning Framework for Multi-step NLP Task Solving](https://arxiv.org//abs/2505.11893)

	Zepeng Ding, Dixuan Wang, Ziqin Luo, Guochao Jiang, Deqing Yang, Jiaqing Liang

+ [AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via Reinforcement Learning](https://arxiv.org//abs/2505.11896)

	Chenwei Lou, Zewei Sun, Xinnian Liang, Meng Qu, Wei Shen, Wenqi Wang, Yuntao Li, Qingping Yang, Shuangzhi Wu

+ [An Explanation of Intrinsic Self-Correction via Linear Representations and Latent Concepts](https://arxiv.org//abs/2505.11924)

	Yu-Ting Lee, Hui-Ying Shih, Fu-Chieh Chang, Pei-Yuan Wu

+ [Exploring Criteria of Loss Reweighting to Enhance LLM Unlearning](https://arxiv.org//abs/2505.11953)

	Puning Yang, Qizhou Wang, Zhuo Huang, Tongliang Liu, Chengqi Zhang, Bo Han

+ [MARVEL: Multi-Agent RTL Vulnerability Extraction using Large Language Models](https://arxiv.org//abs/2505.11963)

	Luca Collini, Baleegh Ahmad, Joey Ah-kiow, Ramesh Karri

+ [Safe Delta: Consistently Preserving Safety when Fine-Tuning LLMs on Diverse Datasets](https://arxiv.org//abs/2505.12038)

	Ning Lu, Shengcai Liu, Jiahao Wu, Weiyu Chen, Zhirui Zhang, Yew-Soon Ong, Qi Wang, Ke Tang

+ [ABoN: Adaptive Best-of-N Alignment](https://arxiv.org//abs/2505.12050)

	Vinod Raman, Hilal Asi, Satyen Kale

+ [Improving Fairness in LLMs Through Testing-Time Adversaries](https://arxiv.org//abs/2505.12100)

	Isabela Pereira Gregio, Ian Pons, Anna Helena Reali Costa, Artur Jordão

+ [Reasoning Large Language Model Errors Arise from Hallucinating Critical Problem Features](https://arxiv.org//abs/2505.12151)

	Alex Heyman, Joel Zylberberg

+ [BELLE: A Bi-Level Multi-Agent Reasoning Framework for Multi-Hop Question Answering](https://arxiv.org//abs/2505.11811)

	Taolin Zhang, Dongyang Li, Qizhou Chen, Chengyu Wang, Xiaofeng He

+ [Chain-of-Model Learning for Language Model](https://arxiv.org//abs/2505.11820)

	Kaitao Song, Xiaohua Wang, Xu Tan, Huiqiang Jiang, Chengruidong Zhang, Yongliang Shen, Cen LU, Zihao Li, Zifan Song, Caihua Shan, Yansen Wang, Kan Ren, Xiaoqing Zheng, Tao Qin, Yuqing Yang, Dongsheng Li, Lili Qiu

+ [NAMET: Robust Massive Model Editing via Noise-Aware Memory Optimization](https://arxiv.org//abs/2505.11876)

	Yanbo Dai, Zhenlan Ji, Zongjie Li, Shuai Wang

+ [AutoMedEval: Harnessing Language Models for Automatic Medical Capability Evaluation](https://arxiv.org//abs/2505.11887)

	Xiechi Zhang, Zetian Ouyang, Linlin Wang, Gerard de Melo, Zhu Cao, Xiaoling Wang, Ya Zhang, Yanfeng Wang, Liang He

+ [ELITE: Embedding-Less retrieval with Iterative Text Exploration](https://arxiv.org//abs/2505.11908)

	Zhangyu Wang, Siyuan Gao, Rong Zhou, Hao Wang, Li Ning

+ [Enhancing Complex Instruction Following for Large Language Models with Mixture-of-Contexts Fine-tuning](https://arxiv.org//abs/2505.11922)

	Yuheng Lu, ZiMeng Bai, Caixia Yuan, Huixing Jiang, Xiaojie Wang

+ [Neuro-Symbolic Query Compiler](https://arxiv.org//abs/2505.11932)

	Yuyao Zhang, Zhicheng Dou, Xiaoxi Li, Jiajie Jin, Yongkang Wu, Zhonghua Li, Qi Ye, Ji-Rong Wen

+ [CCNU at SemEval-2025 Task 3: Leveraging Internal and External Knowledge of Large Language Models for Multilingual Hallucination Annotation](https://arxiv.org//abs/2505.11965)

	Xu Liu, Guanyi Chen

+ [Unveiling Knowledge Utilization Mechanisms in LLM-based Retrieval-Augmented Generation](https://arxiv.org//abs/2505.11995)

	Yuhao Wang, Ruiyang Ren, Yucheng Wang, Wayne Xin Zhao, Jing Liu, Hua Wu, Haifeng Wang

+ [MoL for LLMs: Dual-Loss Optimization to Enhance Domain Expertise While Preserving General Capabilities](https://arxiv.org//abs/2505.12043)

	Jingxue Chen, Qingkun Tang, Qianchun Lu, Siyuan Fang

+ [GenderBench: Evaluation Suite for Gender Biases in LLMs](https://arxiv.org//abs/2505.12054)

	Matúš Pikuliak

+ [Why Not Act on What You Know? Unleashing Safety Potential of LLMs via Self-Aware Guard Enhancement](https://arxiv.org//abs/2505.12060)

	Peng Ding, Jun Kuang, Zongyu Wang, Xuezhi Cao, Xunliang Cai, Jiajun Chen, Shujian Huang

+ [Do different prompting methods yield a common task representation in language models?](https://arxiv.org//abs/2505.12075)

	Guy Davidson, Todd M. Gureckis, Brenden M. Lake, Adina Williams

+ [Model Merging in Pre-training of Large Language Models](https://arxiv.org//abs/2505.12082)

	Yunshui Li, Yiyuan Ma, Shen Yan, Chaoyi Zhang, Jing Liu, Jianqiao Lu, Ziwen Xu, Mengzhao Chen, Minrui Wang, Shiyi Zhan, Jin Ma, Xunhao Lai, Yao Luo, Xingyan Bin, Hongbin Ren, Mingji Han, Wenhao Hao, Bairen Yi, LingJun Liu, Bole Ma, Xiaoying Jia, Zhou Xun, Liang Xiang, Yonghui Wu

+ [Video-SafetyBench: A Benchmark for Safety Evaluation of Video LVLMs](https://arxiv.org//abs/2505.11842)

	Xuannan Liu, Zekun Li, Zheqi He, Peipei Li, Shuhan Xia, Xing Cui, Huaibo Huang, Xi Yang, Ran He

+ [J1: Exploring Simple Test-Time Scaling for LLM-as-a-Judge](https://arxiv.org//abs/2505.11875)

	Chi-Min Chan, Chunpu Xu, Jiaming Ji, Zhen Ye, Pengcheng Wen, Chunyang Jiang, Yaodong Yang, Wei Xue, Sirui Han, Yike Guo

+ [Adversarial Robustness for Unified Multi-Modal Encoders via Efficient Calibration](https://arxiv.org//abs/2505.11895)

	Chih-Ting Liao, Bin Ren, Guofeng Mei, Xu Zheng

+ [Are Multimodal Large Language Models Ready for Omnidirectional Spatial Reasoning?](https://arxiv.org//abs/2505.11907)

	Zihao Dongfang, Xu Zheng, Ziqiao Weng, Yuanhuiyi Lyu, Danda Pani Paudel, Luc Van Gool, Kailun Yang, Xuming Hu

+ [MINGLE: Mixtures of Null-Space Gated Low-Rank Experts for Test-Time Continual Model Merging](https://arxiv.org//abs/2505.11883)

	Zihuan Qiu, Yi Xu, Chiyuan He, Fanman Meng, Linfeng Xu, Qingbo Wu, Hongliang Li

+ [LAMP: Extracting Locally Linear Decision Surfaces from LLM World Models](https://arxiv.org//abs/2505.11772)

	Ryan Chen, Youngmin Ko, Zeyu Zhang, Catherine Cho, Sunny Chung, Mauro Giuffré, Dennis L. Shung, Bradly C. Stadie

+ [JULI: Jailbreak Large Language Models by Self-Introspection](https://arxiv.org//abs/2505.11790)

	Jesson Wang, Zhanhao Hu, David Wagner

+ [Reinforcing Multi-Turn Reasoning in LLM Agents via Turn-Level Credit Assignment](https://arxiv.org//abs/2505.11821)

	Siliang Zeng, Quan Wei, William Brown, Oana Frunza, Yuriy Nevmyvaka, Mingyi Hong

+ [Spotlight Your Instructions: Instruction-following with Dynamic Attention Steering](https://arxiv.org//abs/2505.12025)

	Praveen Venkateswaran, Danish Contractor

+ [Transformer learns the cross-task prior and regularization for in-context learning](https://arxiv.org//abs/2505.12138)

	Fei Lu, Yue Yu

+ [Communication-Efficient Hybrid Language Model via Uncertainty-Aware Opportunistic and Compressed Transmission](https://arxiv.org//abs/2505.11788)

	Seungeun Oh, Jinhyuk Kim, Jihong Park, Seung-Woo Ko, Jinho Choi, Tony Q. S. Quek, Seong-Lyun Kim

+ [Benchmarking LLMs in an Embodied Environment for Blue Team Threat Hunting](https://arxiv.org//abs/2505.11901)

	Xiaoqun Liu, Feiyang Yu, Xi Li, Guanhua Yan, Ping Yang, Zhaohan Xi

+ [TechniqueRAG: Retrieval Augmented Generation for Adversarial Technique Annotation in Cyber Threat Intelligence Text](https://arxiv.org//abs/2505.11988)

	Ahmed Lekssays, Utsav Shukla, Husrev Taha Sencar, Md Rizwan Parvez

+ [Induction Head Toxicity Mechanistically Explains Repetition Curse in Large Language Models](https://arxiv.org//abs/2505.13514)

	Shuxun Wang, Qingyu Yin, Chak Tou Leong, Qiang Zhang, Linyi Yang

+ [LoRASuite: Efficient LoRA Adaptation Across Large Language Model Upgrades](https://arxiv.org//abs/2505.13515)

	Yanan Li, Fanxu Meng, Muhan Zhang, Shiai Zhu, Shangguang Wang, Mengwei Xu

+ [HALO: Hierarchical Autonomous Logic-Oriented Orchestration for Multi-Agent LLM Systems](https://arxiv.org//abs/2505.13516)

	Zhipeng Hou, Junyi Tang, Yipeng Wang

+ [Beyond Retrieval: Joint Supervision and Multimodal Document Ranking for Textbook Question Answering](https://arxiv.org//abs/2505.13520)

	Hessa Alawwad, Usman Naseem, Areej Alhothali, Ali Alkhathlan, Amani Jamal

+ [Are LLMs Ready for English Standardized Tests? A Benchmarking and Elicitation Perspective](https://arxiv.org//abs/2505.17056)

	Luoxi Tang, Tharunya Sundar, Shuai Yang, Ankita Patra, Manohar Chippada, Giqi Zhao, Yi Li, Riteng Zhang, Tunan Zhao, Ting Yang, Yuqiao Meng, Weicheng Ma, Zhaohan Xi

+ [DO-RAG: A Domain-Specific QA Framework Using Knowledge Graph-Enhanced Retrieval-Augmented Generation](https://arxiv.org//abs/2505.17058)

	David Osei Opoku, Ming Sheng, Yong Zhang

+ [Mixture of Decoding: An Attention-Inspired Adaptive Decoding Strategy to Mitigate Hallucinations in Large Vision-Language Models](https://arxiv.org//abs/2505.17061)

	Xinlong Chen, Yuanxing Zhang, Qiang Liu, Junfei Wu, Fuzheng Zhang, Tieniu Tan

# 2025-05-16
+ [PoE-World: Compositional World Modeling with Products of Programmatic Experts](https://arxiv.org//abs/2505.10819)

	Wasu Top Piriyakulkij, Yichao Liang, Hao Tang, Adrian Weller, Marta Kryven, Kevin Ellis

+ [Creativity or Brute Force? Using Brainteasers as a Window into the Problem-Solving Abilities of Large Language Models](https://arxiv.org//abs/2505.10844)

	Simeng Han, Stephen Xia, Grant Zhang, Howard Dai, Chen Liu, Lichang Chen, Hoang Huy Nguyen, Hongyuan Mei, Jiayuan Mao, R. Thomas McCoy

+ [Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A Perspective of Probability Theory](https://arxiv.org//abs/2505.10981)

	Yexiang Liu, Zekun Li, Zhi Fang, Nan Xu, Ran He, Tieniu Tan

+ [RAGSynth: Synthetic Data for Robust and Faithful RAG Component Optimization](https://arxiv.org//abs/2505.10989)

	Haiyang Shen, Hang Yan, Zhongshi Xing, Mugeng Liu, Yue Li, Zhiyang Chen, Yuxiang Wang, Jiuzheng Wang, Yun Ma

+ [GuardReasoner-VL: Safeguarding VLMs via Reinforced Reasoning](https://arxiv.org//abs/2505.11049)

	Yue Liu, Shengfang Zhai, Mingzhe Du, Yulin Chen, Tri Cao, Hongcheng Gao, Cheng Wang, Xinfeng Li, Kun Wang, Junfeng Fang, Jiaheng Zhang, Bryan Hooi

+ [Think Twice Before You Act: Enhancing Agent Behavioral Safety with Thought Correction](https://arxiv.org//abs/2505.11063)

	Changyue Jiang, Xudong Pan, Min Yang

+ [Group Think: Multiple Concurrent Reasoning Agents Collaborating at Token Level Granularity](https://arxiv.org//abs/2505.11107)

	Chan-Jan Hsu, Davide Buffelli, Jamie McGowan, Feng-Ting Liao, Yi-Chang Chen, Sattar Vakili, Da-shan Shiu

+ [Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining](https://arxiv.org//abs/2505.11122)

	Yu Shi, Yitong Duan, Jian Li

+ [Can Global XAI Methods Reveal Injected Bias in LLMs? SHAP vs Rule Extraction vs RuleSHAP](https://arxiv.org//abs/2505.11189)

	Francesco Sovrano

+ [Is PRM Necessary? Problem-Solving RL Implicitly Induces PRM Capability in LLMs](https://arxiv.org//abs/2505.11227)

	Zhangying Feng, Qianglong Chen, Ning Lu, Yongqian Li, Siqi Cheng, Shuangmu Peng, Duyu Tang, Shengcai Liu, Zhirui Zhang

+ [LD-Scene: LLM-Guided Diffusion for Controllable Generation of Adversarial Safety-Critical Driving Scenarios](https://arxiv.org//abs/2505.11247)

	Mingxing Peng, Yuting Xie, Xusen Guo, Ruoyu Yao, Hai Yang, Jun Ma

+ [SelfBudgeter: Adaptive Token Allocation for Efficient LLM Reasoning](https://arxiv.org//abs/2505.11274)

	Zheng Li, Qingxiu Dong, Jingyuan Ma, Di Zhang, Zhifang Sui

+ [A Systematic Analysis of Base Model Choice for Reward Modeling](https://arxiv.org//abs/2505.10775)

	Kian Ahrabian, Pegah Jandaghi, Negar Mokhberian, Sai Praneeth Karimireddy, Jay Pujara

+ [Enhancing Low-Resource Minority Language Translation with LLMs and Retrieval-Augmented Generation for Cultural Nuances](https://arxiv.org//abs/2505.10829)

	Chen-Chi Chang, Chong-Fu Li, Chu-Hsuan Lee, Hung-Shin Lee

+ [Learning When to Think: Shaping Adaptive Reasoning in R1-Style Models via Multi-Stage RL](https://arxiv.org//abs/2505.10832)

	Songjun Tu, Jiahao Lin, Qichao Zhang, Xiangyu Tian, Linjing Li, Xiangyuan Lan, Dongbin Zhao

+ [Ready2Unlearn: A Learning-Time Approach for Preparing Models with Future Unlearning Readiness](https://arxiv.org//abs/2505.10845)

	Hanyu Duan, Yi Yang, Ahmed Abbasi, Kar Yan Tam

+ [Improve Rule Retrieval and Reasoning with Self-Induction and Relevance ReEstimate](https://arxiv.org//abs/2505.10870)

	Ziyang Huang, Wangtao Sun, Jun Zhao, Kang Liu

+ [REI-Bench: Can Embodied Agents Understand Vague Human Instructions in Task Planning?](https://arxiv.org//abs/2505.10872)

	Chenxi Jiang, Chuhao Zhou, Jianfei Yang

+ [Explain What You Mean: Intent Augmented Knowledge Graph Recommender Built With LLM](https://arxiv.org//abs/2505.10900)

	Wenqing Zheng, Noah Fatsi, Daniel Barcklow, Dmitri Kalaev, Steven Yao, Owen Reinert, C. Bayan Bruss, Daniele Rosa

+ [Vaiage: A Multi-Agent Solution to Personalized Travel Planning](https://arxiv.org//abs/2505.10922)

	Binwen Liu, Jiexi Ge, Jiamin Wang

+ [A Survey on the Safety and Security Threats of Computer-Using Agents: JARVIS or Ultron?](https://arxiv.org//abs/2505.10924)

	Ada Chen, Yongjiang Wu, Junyuan Zhang, Shu Yang, Jen-tse Huang, Kun Wang, Wenxuan Wang, Shuai Wang

+ [Reasoning with OmniThought: A Large CoT Dataset with Verbosity and Cognitive Difficulty Annotations](https://arxiv.org//abs/2505.10937)

	Wenrui Cai, Chengyu Wang, Junbing Yan, Jun Huang, Xiangzhong Fang

+ [GenKnowSub: Improving Modularity and Reusability of LLMs through General Knowledge Subtraction](https://arxiv.org//abs/2505.10939)

	Mohammadtaha Bagherifard, Sahar Rajabi, Ali Edalat, Yadollah Yaghoobzadeh

+ [Let the Trial Begin: A Mock-Court Approach to Vulnerability Detection using LLM-Based Agents](https://arxiv.org//abs/2505.10961)

	Ratnadira Widyasari, Martin Weyssow, Ivana Clairine Irsan, Han Wei Ang, Frank Liauw, Eng Lieh Ouh, Lwin Khin Shar, Hong Jin Kang, David Lo

+ [Group-in-Group Policy Optimization for LLM Agent Training](https://arxiv.org//abs/2505.10978)

	Lang Feng, Zhenghai Xue, Tingcong Liu, Bo An

+ [Illusion or Algorithm? Investigating Memorization, Emergence, and Symbolic Processing in In-Context Learning](https://arxiv.org//abs/2505.11004)

	Jingcheng Niu, Subhabrata Dutta, Ahmed Elshabrawy, Harish Tayyar Madabushi, Iryna Gurevych

+ [Review-Instruct: A Review-Driven Multi-Turn Conversations Generation Method for Large Language Models](https://arxiv.org//abs/2505.11010)

	Jiangxu Wu, Cong Wang, TianHuang Su, Jun Yang, Haozhi Lin, Chao Zhang, Ming Peng, Kai Shi, SongPan Yang, BinQing Pan, ZiXian Li, Ni Yang, ZhenYu Yang

+ [Humans expect rationality and cooperation from LLM opponents in strategic games](https://arxiv.org//abs/2505.11011)

	Darija Barak, Miguel Costa-Gomes

+ [BLEUBERI: BLEU is a surprisingly effective reward for instruction following](https://arxiv.org//abs/2505.11080)

	Yapei Chang, Yekyung Kim, Michael Krumdick, Amir Zadeh, Chuan Li, Chris Tanner, Mohit Iyyer

+ [Scaling Reasoning can Improve Factuality in Large Language Models](https://arxiv.org//abs/2505.11140)

	Mike Zhang, Johannes Bjerva, Russa Biswas

+ [Human-Aligned Bench: Fine-Grained Assessment of Reasoning Ability in MLLMs vs. Humans](https://arxiv.org//abs/2505.11141)

	Yansheng Qiu, Li Xiao, Zhaopan Xu, Pengfei Zhou, Zheng Wang, Kaipeng Zhang

+ [SoLoPO: Unlocking Long-Context Capabilities in LLMs via Short-to-Long Preference Optimization](https://arxiv.org//abs/2505.11166)

	Huashan Sun, Shengyi Liao, Yansen Han, Yu Bai, Yang Gao, Cheng Fu, Weizhou Shen, Fanqi Wan, Ming Yan, Ji Zhang, Fei Huang

+ [Semantic Caching of Contextual Summaries for Efficient Question-Answering with Language Models](https://arxiv.org//abs/2505.11271)

	Camille Couturier, Spyros Mastorakis, Haiying Shen, Saravan Rajmohan, Victor Rühle

+ [Search and Refine During Think: Autonomous Retrieval-Augmented Reasoning of LLMs](https://arxiv.org//abs/2505.11277)

	Yaorui Shi, Shihan Li, Chang Wu, Zhiyuan Liu, Junfeng Fang, Hengxing Cai, An Zhang, Xiang Wang

+ [Phare: A Safety Probe for Large Language Models](https://arxiv.org//abs/2505.11365)

	Pierre Le Jeune, Benoît Malésieux, Weixuan Xiao, Matteo Dora

+ [EdgeWisePersona: A Dataset for On-Device User Profiling from Natural Language Interactions](https://arxiv.org//abs/2505.11417)

	Patryk Bartkowiak, Michal Podstawski

+ [LLMs unlock new paths to monetizing exploits](https://arxiv.org//abs/2505.11449)

	Nicholas Carlini, Milad Nasr, Edoardo Debenedetti, Barry Wang, Christopher A. Choquette-Choo, Daphne Ippolito, Florian Tramèr, Matthew Jagielski

+ [Disentangling Reasoning and Knowledge in Medical Large Language Models](https://arxiv.org//abs/2505.11462)

	Rahul Thapa, Qingyang Wu, Kevin Wu, Harrison Zhang, Angela Zhang, Eric Wu, Haotian Ye, Suhana Bedi, Nevin Aresh, Joseph Boen, Shriya Reddy, Ben Athiwaratkun, Shuaiwen Leon Song, James Zou

+ [HelpSteer3-Preference: Open Human-Annotated Preference Data across Diverse Tasks and Languages](https://arxiv.org//abs/2505.11475)

	Zhilin Wang, Jiaqi Zeng, Olivier Delalleau, Hoo-Chang Shin, Felipe Soares, Alexander Bukharin, Ellie Evans, Yi Dong, Oleksii Kuchaiev

+ [Ranked Voting based Self-Consistency of Large Language Models](https://arxiv.org//abs/2505.10772)

	Weiqin Wang, Yile Wang, Hui Huang

+ [Finetune-RAG: Fine-Tuning Language Models to Resist Hallucination in Retrieval-Augmented Generation](https://arxiv.org//abs/2505.10792)

	Zhan Peng Lee, Andre Lin, Calvin Tan

+ [Have Multimodal Large Language Models (MLLMs) Really Learned to Tell the Time on Analog Clocks?](https://arxiv.org//abs/2505.10862)

	Tairan Fu, Miguel González, Javier Conde, Elena Merino-Gómez, Pedro Reviriego

+ [Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents](https://arxiv.org//abs/2505.10936)

	Jiaxing Zhao, Hongbin Xie, Yuzhen Lei, Xuan Song, Zhuoran Shi, Lianxin Li, Shuangxue Liu, Haoran Zhang

+ [Accurate KV Cache Quantization with Outlier Tokens Tracing](https://arxiv.org//abs/2505.10938)

	Yi Su, Yuechi Zhou, Quantong Qiu, Juntao Li, Qingrong Xia, Ping Li, Xinyu Duan, Zhefeng Wang, Min Zhang

+ [The Way We Prompt: Conceptual Blending, Neural Dynamics, and Prompt-Induced Transitions in LLMs](https://arxiv.org//abs/2505.10948)

	Makoto Sato

+ [OntoURL: A Benchmark for Evaluating Large Language Models on Symbolic Ontological Understanding, Reasoning and Learning](https://arxiv.org//abs/2505.11031)

	Xiao Zhang, Huiyuan Lai, Qianru Meng, Johan Bos

+ [HAPO: Training Language Models to Reason Concisely via History-Aware Policy Optimization](https://arxiv.org//abs/2505.11225)

	Chengyu Huang, Zhengxin Zhang, Claire Cardie

+ [XtraGPT: LLMs for Human-AI Collaboration on Controllable Academic Paper Revision](https://arxiv.org//abs/2505.11336)

	Nuo Chen, Andre Lin HuiKai, Jiaying Wu, Junyi Hou, Zining Zhang, Qian Wang, Xidong Wang, Bingsheng He

+ [LegoSLM: Connecting LLM with Speech Encoder using CTC Posteriors](https://arxiv.org//abs/2505.11352)

	Rao Ma, Tongzhou Chen, Kartik Audhkhasi, Bhuvana Ramabhadran

+ [GuideBench: Benchmarking Domain-Oriented Guideline Following for LLM Agents](https://arxiv.org//abs/2505.11368)

	Lingxiao Diao, Xinyue Xu, Wanxuan Sun, Cheng Yang, Zhuosheng Zhang

+ [CARES: Comprehensive Evaluation of Safety and Adversarial Robustness in Medical LLMs](https://arxiv.org//abs/2505.11413)

	Sijia Chen, Xiaomin Li, Mengxue Zhang, Eric Hanchen Jiang, Qingcheng Zeng, Chen-Hsiang Yu

+ [When Thinking Fails: The Pitfalls of Reasoning for Instruction-Following in LLMs](https://arxiv.org//abs/2505.11423)

	Xiaomin Li, Zhou Yu, Zhiwei Zhang, Xupeng Chen, Ziji Zhang, Yingying Zhuang, Narayanan Sadagopan, Anurag Beniwal

+ [SoftCoT++: Test-Time Scaling with Soft Chain-of-Thought Reasoning](https://arxiv.org//abs/2505.11484)

	Yige Xu, Xu Guo, Zhiwei Zeng, Chunyan Miao

+ [LARGO: Latent Adversarial Reflection through Gradient Optimization for Jailbreaking LLMs](https://arxiv.org//abs/2505.10838)

	Ran Li, Hao Wang, Chengzhi Mao

+ [MPMA: Preference Manipulation Attack Against Model Context Protocol](https://arxiv.org//abs/2505.11154)

	Zihan Wang, Hongwei Li, Rui Zhang, Yu Liu, Wenbo Jiang, Wenshu Fan, Qingchuan Zhao, Guowen Xu

+ [On Next-Token Prediction in LLMs: How End Goals Determine the Consistency of Decoding Algorithms](https://arxiv.org//abs/2505.11183)

	Jacob Trauger, Ambuj Tewari

+ [EmotionHallucer: Evaluating Emotion Hallucinations in Multimodal Large Language Models](https://arxiv.org//abs/2505.11405)

	Bohao Xing, Xin Liu, Guoying Zhao, Chengyu Liu, Xiaolan Fu, Heikki Kälviäinen

+ [VISTA: Enhancing Vision-Text Alignment in MLLMs via Cross-Modal Mutual Information Maximization](https://arxiv.org//abs/2505.10917)

	Mingxiao Li, Na Su, Fang Qu, Zhizhou Zhong, Ziyang Chen, Zhaopeng Tu, Xiaolong Li

+ [Distilled Circuits: A Mechanistic Study of Internal Restructuring in Knowledge Distillation](https://arxiv.org//abs/2505.10822)

	Reilly Haskins, Benjamin Adams

+ [MergeBench: A Benchmark for Merging Domain-Specialized LLMs](https://arxiv.org//abs/2505.10833)

	Yifei He, Siqi Zeng, Yuzheng Hu, Rui Yang, Tong Zhang, Han Zhao

+ [AutoRAN: Weak-to-Strong Jailbreaking of Large Reasoning Models](https://arxiv.org//abs/2505.10846)

	Jiacheng Liang, Tanqiu Jiang, Yuhui Wang, Rongyi Zhu, Fenglong Ma, Ting Wang

+ [On DeepSeekMoE: Statistical Benefits of Shared Experts and Normalized Sigmoid Gating](https://arxiv.org//abs/2505.10860)

	Huy Nguyen, Thong T. Doan, Quang Pham, Nghi D. Q. Bui, Nhat Ho, Alessandro Rinaldo

+ [Improving the Data-efficiency of Reinforcement Learning by Warm-starting with LLM](https://arxiv.org//abs/2505.10861)

	Thang Duong, Minglai Yang, Chicheng Zhang

+ [Multi-Objective Preference Optimization: Improving Human Alignment of Generative Models](https://arxiv.org//abs/2505.10892)

	Akhil Agnihotri, Rahul Jain, Deepak Ramachandran, Zheng Wen

+ [SubGCache: Accelerating Graph-based RAG with Subgraph-level KV Cache](https://arxiv.org//abs/2505.10951)

	Qiuyu Zhu, Liang Zhang, Qianxiong Xu, Cheng Long, Jie Zhang

+ [ShiQ: Bringing back Bellman to LLMs](https://arxiv.org//abs/2505.11081)

	Pierre Clavier, Nathan Grinsztajn, Raphael Avalos, Yannis Flet-Berliac, Irem Ergun, Omar D. Domingues, Eugene Tarassov, Olivier Pietquin, Pierre H. Richemond, Florian Strub, Matthieu Geist

+ [Gaussian Weight Sampling for Scalable, Efficient and Stable Pseudo-Quantization Training](https://arxiv.org//abs/2505.11170)

	Myeonghwan Ahn, Sungjoo Yoo

+ [Memory-Efficient Orthogonal Fine-Tuning with Principal Subspace Adaptation](https://arxiv.org//abs/2505.11235)

	Fei Wu, Jia Hu, Geyong Min, Shiqiang Wang

+ [Delta Attention: Fast and Accurate Sparse Attention Inference by Delta Correction](https://arxiv.org//abs/2505.11254)

	Jeffrey Willette, Heejun Lee, Sung Ju Hwang

+ [Is Grokking a Computational Glass Relaxation?](https://arxiv.org//abs/2505.11411)

	Xiaotian Zhang, Yue Shang, Entao Yang, Ge Zhang

+ [MoE-CAP: Benchmarking Cost, Accuracy and Performance of Sparse Mixture-of-Experts Systems](https://arxiv.org//abs/2505.11415)

	Yinsicheng Jiang, Yao Fu, Yeqi Huang, Ping Nie, Zhan Lu, Leyang Xue, Congjie He, Man-Kit Sit, Jilong Xue, Li Dong, Ziming Miao, Dayou Du, Tairan Xu, Kai Zou, Edoardo Ponti, Luo Mai

+ [MegaScale-MoE: Large-Scale Communication-Efficient Training of Mixture-of-Experts Models in Production](https://arxiv.org//abs/2505.11432)

	Chao Jin, Ziheng Jiang, Zhihao Bai, Zheng Zhong, Juncai Liu, Xiang Li, Ningxin Zheng, Xi Wang, Cong Xie, Wen Heng, Yiyuan Ma, Wenlei Bao, Size Zheng, Yanghua Peng, Haibin Lin, Xuanzhe Liu, Xin Jin, Xin Liu

+ [TokenWeave: Efficient Compute-Communication Overlap for Distributed LLM Inference](https://arxiv.org//abs/2505.11329)

	Raja Gond, Nipun Kwatra, Ramachandran Ramjee

+ [ProxyPrompt: Securing System Prompts against Prompt Extraction Attacks](https://arxiv.org//abs/2505.11459)

	Zhixiong Zhuang, Maria-Irina Nicolae, Hui-Po Wang, Mario Fritz

+ [LLM Agents Are Hypersensitive to Nudges](https://arxiv.org//abs/2505.11584)

	Manuel Cherep, Pattie Maes, Nikhil Singh

+ [Probing the Vulnerability of Large Language Models to Polysemantic Interventions](https://arxiv.org//abs/2505.11611)

	Bofan Gong, Shiyang Lai, Dawn Song

+ [Using Reinforcement Learning to Train Large Language Models to Explain Human Decisions](https://arxiv.org//abs/2505.11614)

	Jian-Qiao Zhu, Hanbo Xie, Dilip Arumugam, Robert C. Wilson, Thomas L. Griffiths

+ [Benchmarking Spatiotemporal Reasoning in LLMs and Reasoning Models: Capabilities and Challenges](https://arxiv.org//abs/2505.11618)

	Pengrui Quan, Brian Wang, Kang Yang, Liying Han, Mani Srivastava

+ [DMN-Guided Prompting: A Low-Code Framework for Controlling LLM Behavior](https://arxiv.org//abs/2505.11701)

	Shaghayegh Abedi, Amin Jalali

+ [Rethinking Optimal Verification Granularity for Compute-Efficient Test-Time Scaling](https://arxiv.org//abs/2505.11730)

	Hao Mark Chen, Guanxi Lu, Yasuyuki Okoshi, Zhiwen Mo, Masato Motomura, Hongxiang Fan

+ [ACSE-Eval: Can LLMs threat model real-world cloud infrastructure?](https://arxiv.org//abs/2505.11565)

	Sarthak Munshi, Swapnil Pathak, Sonam Ghatode, Thenuga Priyadarshini, Dhivya Chandramouleeswaran, Ashutosh Rana

+ [InfiJanice: Joint Analysis and In-situ Correction Engine for Quantization-Induced Math Degradation in Large Language Models](https://arxiv.org//abs/2505.11574)

	Zhen Li, Yupeng Su, Songmiao Wang, Runming Yang, Congkai Xie, Aofan Liu, Ming Li, Jiannong Cao, Yuan Xie, Ngai Wong, Hongxia Yang

+ [Concept-Guided Interpretability via Neural Chunking](https://arxiv.org//abs/2505.11576)

	Shuchen Wu, Stephan Alaniz, Shyamgopal Karthik, Peter Dayan, Eric Schulz, Zeynep Akata

+ [The Ripple Effect: On Unforeseen Complications of Backdoor Attacks](https://arxiv.org//abs/2505.11586)

	Rui Zhang, Yun Shen, Hongwei Li, Wenbo Jiang, Hanxiao Chen, Yuan Zhang, Guowen Xu, Yang Zhang

+ [SageAttention3: Microscaling FP4 Attention for Inference and An Exploration of 8-Bit Training](https://arxiv.org//abs/2505.11594)

	Jintao Zhang, Jia Wei, Pengle Zhang, Xiaoming Xu, Haofeng Huang, Haoxu Wang, Kai Jiang, Jun Zhu, Jianfei Chen

+ [Spectral Policy Optimization: Coloring your Incorrect Reasoning in GRPO](https://arxiv.org//abs/2505.11595)

	Peter Chen, Xiaopeng Li, Ziniu Li, Xi Chen, Tianyi Lin

+ [Steering Risk Preferences in Large Language Models by Aligning Behavioral and Neural Representations](https://arxiv.org//abs/2505.11615)

	Jian-Qiao Zhu, Haijiang Yan, Thomas L. Griffiths

+ [Chatting with Papers: A Hybrid Approach Using LLMs and Knowledge Graphs](https://arxiv.org//abs/2505.11633)

	Vyacheslav Tykhonov, Han Yang, Philipp Mayr, Jetze Touber, Andrea Scharnhorst

+ [PeerGuard: Defending Multi-Agent Systems Against Backdoor Attacks Through Mutual Reasoning](https://arxiv.org//abs/2505.11642)

	Falong Fan, Xi Li

+ [EnvInjection: Environmental Prompt Injection Attack to Multi-modal Web Agents](https://arxiv.org//abs/2505.11717)

	Xilong Wang, John Bloch, Zedian Shao, Yuepeng Hu, Shuyan Zhou, Neil Zhenqiang Gong

+ [Efficient Uncertainty Estimation via Distillation of Bayesian Large Language Models](https://arxiv.org//abs/2505.11731)

	Harshil Vejendla, Haizhou Shi, Yibin Wang, Tunyu Zhang, Huan Zhang, Hao Wang

+ [Token-Level Uncertainty Estimation for Large Language Model Reasoning](https://arxiv.org//abs/2505.11737)

	Tunyu Zhang, Haizhou Shi, Yibin Wang, Hengyi Wang, Xiaoxiao He, Zhuowei Li, Haoxian Chen, Ligong Han, Kai Xu, Huan Zhang, Dimitris Metaxas, Hao Wang

+ [ZeroTuning: Unlocking the Initial Token's Power to Enhance Large Language Models Without Training](https://arxiv.org//abs/2505.11739)

	Feijiang Han, Xiaodong Yu, Jianheng Tang, Lyle Ungar

+ [Cloud-Based AI Systems: Leveraging Large Language Models for Intelligent Fault Detection and Autonomous Self-Healing](https://arxiv.org//abs/2505.11743)

	Cheng Ji, Huaiying Luo

+ [Talk to Your Slides: Efficient Slide Editing Agent with Large Language Models](https://arxiv.org//abs/2505.11604)

	Kyudan Jung, Hojun Cho, Jooyeol Yun, Jaehyeok Jang, Jagul Choo

+ [MedGUIDE: Benchmarking Clinical Decision-Making in Large Language Models](https://arxiv.org//abs/2505.11613)

	Xiaomin Li, Mingye Gao, Yuexing Hao, Taoran Li, Guangya Wan, Zihan Wang, Yijun Wang

+ [THELMA: Task Based Holistic Evaluation of Large Language Model Applications-RAG Question Answering](https://arxiv.org//abs/2505.11626)

	Udita Patel, Rutu Mulkar, Jay Roberts, Cibi Chakravarthy Senthilkumar, Sujay Gandhi, Xiaofei Zheng, Naumaan Nayyar, Rafael Castrillo

+ [Can an Easy-to-Hard Curriculum Make Reasoning Emerge in Small Language Models? Evidence from a Four-Stage Curriculum on GPT-2](https://arxiv.org//abs/2505.11643)

	Xiang Fu

+ [Ambiguity Resolution in Text-to-Structured Data Mapping](https://arxiv.org//abs/2505.11679)

	Zhibo Hu, Chen Wang, Yanfeng Shu, Hye-Young Paik, Liming Zhu

+ [MedCaseReasoning: Evaluating and learning diagnostic reasoning from clinical case reports](https://arxiv.org//abs/2505.11733)

	Kevin Wu, Eric Wu, Rahul Thapa, Kevin Wei, Angela Zhang, Arvind Suresh, Jacqueline J. Tao, Min Woo Sun, Alejandro Lozano, James Zou

+ [Masking in Multi-hop QA: An Analysis of How Language Models Perform with Context Permutation](https://arxiv.org//abs/2505.11754)

	Wenyu Huang, Pavlos Vougiouklis, Mirella Lapata, Jeff Z. Pan

+ [Reinforcement Learning Finetunes Small Subnetworks in Large Language Models](https://arxiv.org//abs/2505.11711)

	Sagnik Mukherjee, Lifan Yuan, Dilek Hakkani-Tur, Hao Peng

+ [Can AI Freelancers Compete? Benchmarking Earnings, Reliability, and Task Success at Scale](https://arxiv.org//abs/2505.13511)

	David Noever, Forrest McKee

+ [Noise Injection Systemically Degrades Large Language Model Safety Guardrails](https://arxiv.org//abs/2505.13500)

	Prithviraj Singh Shahani, Matthias Scheutz

+ [An agentic system with reinforcement-learned subsystem improvements for parsing form-like documents](https://arxiv.org//abs/2505.13504)

	Ayesha Amjad, Saurav Sthapit, Tahir Qasim Syed

+ [EcoSafeRAG: Efficient Security through Context Analysis in Retrieval-Augmented Generation](https://arxiv.org//abs/2505.13506)

	Ruobing Yao, Yifei Zhang, Shuang Song, Neng Gao, Chenyang Tu

+ [Time-R1: Towards Comprehensive Temporal Reasoning in LLMs](https://arxiv.org//abs/2505.13508)

	Zijia Liu, Peixuan Han, Haofei Yu, Haoru Li, Jiaxuan You

+ [Gender and Positional Biases in LLM-Based Hiring Decisions: Evidence from Comparative CV/Résumé Evaluations](https://arxiv.org//abs/2505.17049)

	David Rozado

+ [Embedding-to-Prefix: Parameter-Efficient Personalization for Pre-Trained Large Language Models](https://arxiv.org//abs/2505.17051)

	Bernd Huber, Ghazal Fazelnia, Andreas Damianou, Sebastian Peleato, Max Lefarov, Praveen Ravichandran, Marco De Nadai, Mounia Lalmas-Roellke, Paul N. Bennett

+ [SpecEdge: Scalable Edge-Assisted Serving Framework for Interactive LLMs](https://arxiv.org//abs/2505.17052)

	Jinwoo Park, Seunggeun Cho, Dongsu Han

+ [Eliminating Hallucination-Induced Errors in LLM Code Generation with Functional Clustering](https://arxiv.org//abs/2506.11021)

	Chaitanya Ravuri, Saman Amarasinghe

# 2025-05-15
+ [Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents](https://arxiv.org//abs/2505.09970)

	Mrinal Rawat, Ambuje Gupta, Rushil Goomer, Alessandro Di Bari, Neha Gupta, Roberto Pieraccini

+ [Leveraging Graph Retrieval-Augmented Generation to Support Learners' Understanding of Knowledge Concepts in MOOCs](https://arxiv.org//abs/2505.10074)

	Mohamed Abdelmagied, Mohamed Amine Chatti, Shoeb Joarder, Qurat Ul Ain, Rawaa Alatrash

+ [AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenge](https://arxiv.org//abs/2505.10468)

	Ranjan Sapkota, Konstantinos I. Roumeliotis, Manoj Karkee

+ [Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models](https://arxiv.org//abs/2505.10543)

	Annie Wong, Thomas Bäck, Aske Plaat, Niki van Stein, Anna V. Kononova

+ [Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks](https://arxiv.org//abs/2505.09901)

	Ziyuan Zhang, Darcy Wang, Ningyuan Chen, Rodrigo Mansur, Vahid Sarhangian

+ [Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph](https://arxiv.org//abs/2505.09945)

	Deeksha Prahlad, Chanhee Lee, Dongha Kim, Hokeun Kim

+ [Analysing Safety Risks in LLMs Fine-Tuned with Pseudo-Malicious Cyber Security Data](https://arxiv.org//abs/2505.09974)

	Adel ElZemity, Budi Arief, Shujun Li

+ [Dark LLMs: The Growing Threat of Unaligned AI Models](https://arxiv.org//abs/2505.10066)

	Michael Fire, Yitzhak Elbazis, Adi Wasenstein, Lior Rokach

+ [The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think](https://arxiv.org//abs/2505.10185)

	Seongyun Lee, Seungone Kim, Minju Seo, Yongrae Jo, Dongyoung Go, Hyeonbin Hwang, Jinho Park, Xiang Yue, Sean Welleck, Graham Neubig, Moontae Lee, Minjoon Seo

+ [Do LLMs Memorize Recommendation Datasets? A Preliminary Study on MovieLens-1M](https://arxiv.org//abs/2505.10212)

	Dario Di Palma, Felice Antonio Merra, Maurizio Sfilio, Vito Walter Anelli, Fedelucio Narducci, Tommaso Di Noia

+ [Comparing LLM Text Annotation Skills: A Study on Human Rights Violations in Social Media Data](https://arxiv.org//abs/2505.10260)

	Poli Apollinaire Nemkova, Solomon Ubani, Mark V. Albert

+ [Private Transformer Inference in MLaaS: A Survey](https://arxiv.org//abs/2505.10315)

	Yang Li, Xinyu Zhou, Yitong Wang, Liangxin Qian, Jun Zhao

+ [J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning](https://arxiv.org//abs/2505.10320)

	Chenxi Whitehouse, Tianlu Wang, Ping Yu, Xian Li, Jason Weston, Ilia Kulikov, Swarnadeep Saha

+ [AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents](https://arxiv.org//abs/2505.10321)

	Julius Henke

+ [FactsR: A Safer Method for Producing High Quality Healthcare Documentation](https://arxiv.org//abs/2505.10360)

	Victor Petrén Bach Hansen, Lasse Krogsbøll, Jonas Lyngsø, Mathias Baltzersen, Andreas Motzfeldt, Kevin Pelgrims, Lars Maaløe

+ [Are Large Language Models Robust in Understanding Code Against Semantics-Preserving Mutations?](https://arxiv.org//abs/2505.10443)

	Pedro Orvalho, Marta Kwiatkowska

+ [Superposition Yields Robust Neural Scaling](https://arxiv.org//abs/2505.10465)

	Yizhou liu, Ziming Liu, Jeff Gore

+ [Multi-Token Prediction Needs Registers](https://arxiv.org//abs/2505.10518)

	Anastasios Gerontopoulos, Spyros Gidaris, Nikos Komodakis

+ [Real-Time Out-of-Distribution Failure Prevention via Multi-Modal Reasoning](https://arxiv.org//abs/2505.10547)

	Milan Ganai, Rohan Sinha, Christopher Agia, Daniel Morton, Marco Pavone

+ [From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models](https://arxiv.org//abs/2505.09924)

	Yidan Wang, Yubing Ren, Yanan Cao, Binxing Fang

+ [Rethinking Prompt Optimizers: From Prompt Merits to Optimization](https://arxiv.org//abs/2505.09930)

	Zixiao Zhu, Hanzhang Zhou, Zijian Feng, Tianjiao Li, Chua Jia Jim Deryl, Mak Lee Onn, Gee Wah Ng, Kezhi Mao

+ [DIF: A Framework for Benchmarking and Verifying Implicit Bias in LLMs](https://arxiv.org//abs/2505.10013)

	Lake Yin, Fan Huang

+ [CAFE: Retrieval Head-based Coarse-to-Fine Information Seeking to Enhance Multi-Document QA Capability](https://arxiv.org//abs/2505.10063)

	Han Peng, Jinhao Jiang, Zican Dong, Wayne Xin Zhao, Lei Fang

+ [Designing and Contextualising Probes for African Languages](https://arxiv.org//abs/2505.10081)

	Wisdom Aduah, Francois Meyer

+ [XRAG: Cross-lingual Retrieval-Augmented Generation](https://arxiv.org//abs/2505.10089)

	Wei Liu, Sony Trenous, Leonardo F. R. Ribeiro, Bill Byrne, Felix Hieber

+ [What Does Neuro Mean to Cardio? Investigating the Role of Clinical Specialty Data in Medical LLMs](https://arxiv.org//abs/2505.10113)

	Xinlan Yan, Di Wu, Yibin Lei, Christof Monz, Iacer Calixto

+ [GE-Chat: A Graph Enhanced RAG Framework for Evidential Response Generation of LLMs](https://arxiv.org//abs/2505.10143)

	Longchao Da, Parth Mitesh Shah, Kuan-Ru Liou, Jiaxing Zhang, Hua Wei

+ [Mining Hidden Thoughts from Texts: Evaluating Continual Pretraining with Synthetic Data for LLM Reasoning](https://arxiv.org//abs/2505.10182)

	Yoichi Ishibashi, Taro Yano, Masafumi Oyamada

+ [VQ-Logits: Compressing the Output Bottleneck of Large Language Models via Vector Quantized Logits](https://arxiv.org//abs/2505.10202)

	Jintian Shao, Hongyi Huang, Jiayi Wu, YiMing Cheng, ZhiYu Wu, You Shan, MingKai Zheng

+ [RAIDEN-R1: Improving Role-awareness of LLMs via GRPO with Verifiable Reward](https://arxiv.org//abs/2505.10218)

	Zongsheng Wang, Kaili Sun, Bowen Wu, Qun Yu, Ying Li, Baoxun Wang

+ [Hierarchical Document Refinement for Long-context Retrieval-augmented Generation](https://arxiv.org//abs/2505.10413)

	Jiajie Jin, Xiaoxi Li, Guanting Dong, Yuyao Zhang, Yutao Zhu, Yongkang Wu, Zhonghua Li, Qi Ye, Zhicheng Dou

+ [CL-RAG: Bridging the Gap in Retrieval-Augmented Generation with Curriculum Learning](https://arxiv.org//abs/2505.10493)

	Shaohan Wang, Licheng Zhang, Zheren Fu, Zhendong Mao

+ [Can You Really Trust Code Copilots? Evaluating Large Language Models from a Code Security Perspective](https://arxiv.org//abs/2505.10494)

	Yutao Mou, Xiao Deng, Yuxiao Luo, Shikun Zhang, Wei Ye

+ [WorldPM: Scaling Human Preference Modeling](https://arxiv.org//abs/2505.10527)

	Binghai Wang, Runji Lin, Keming Lu, Le Yu, Zhenru Zhang, Fei Huang, Chujie Zheng, Kai Dang, Yang Fan, Xingzhang Ren, An Yang, Binyuan Hui, Dayiheng Liu, Tao Gui, Qi Zhang, Xuanjing Huang, Yu-Gang Jiang, Bowen Yu, Jingren Zhou, Junyang Lin

+ [Beyond 'Aha!': Toward Systematic Meta-Abilities Alignment in Large Reasoning Models](https://arxiv.org//abs/2505.10554)

	Zhiyuan Hu, Yibo Wang, Hanze Dong, Yuhui Xu, Amrita Saha, Caiming Xiong, Bryan Hooi, Junnan Li

+ [PIG: Privacy Jailbreak Attack on LLMs via Gradient-based Iterative In-Context Optimization](https://arxiv.org//abs/2505.09921)

	Yidan Wang, Yanan Cao, Yubing Ren, Fang Fang, Zheng Lin, Binxing Fang

+ [Parallel Scaling Law for Language Models](https://arxiv.org//abs/2505.10475)

	Mouxiang Chen, Binyuan Hui, Zeyu Cui, Jiaxi Yang, Dayiheng Liu, Jianling Sun, Junyang Lin, Zhongxin Liu

+ [RouteNator: A Router-Based Multi-Modal Architecture for Generating Synthetic Training Data for Function Calling LLMs](https://arxiv.org//abs/2505.10495)

	Vibha Belavadi, Tushar Vatsa, Dewang Sultania, Suhas Suresha, Ishita Verma, Cheng Chen, Tracy Holloway King, Michael Friedrich

+ [Exploring Implicit Visual Misunderstandings in Multimodal Large Language Models through Attention Analysis](https://arxiv.org//abs/2505.10541)

	Pengfei Wang, Guohai Xu, Weinong Wang, Junjie Yang, Jie Lou, Yunhua Xue

+ [ImagineBench: Evaluating Reinforcement Learning with Large Language Model Rollouts](https://arxiv.org//abs/2505.10010)

	Jing-Cheng Pang, Kaiyuan Li, Yidi Wang, Si-Hang Yang, Shengyi Jiang, Yang Yu

+ [Rethinking Circuit Completeness in Language Models: AND, OR, and ADDER Gates](https://arxiv.org//abs/2505.10039)

	Hang Chen, Jiaying Zhu, Xinyu Yang, Wenya Wang

+ [Informed Forecasting: Leveraging Auxiliary Knowledge to Boost LLM Performance on Time Series Forecasting](https://arxiv.org//abs/2505.10213)

	Mohammadmahdi Ghasemloo, Alireza Moradi

+ [SpecOffload: Unlocking Latent GPU Capacity for LLM Inference on Resource-Constrained Devices](https://arxiv.org//abs/2505.10259)

	Xiangwen Zhuge, Xu Shen, Zeyu Wang, Fan Dang, Xuan Ding, Danyang Li, Yahui Han, Tianxiang Hao, Zheng Yang

+ [Learning to Think: Information-Theoretic Reinforcement Fine-Tuning for LLMs](https://arxiv.org//abs/2505.10425)

	Jingyao Wang, Wenwen Qiang, Zeen Song, Changwen Zheng, Hui Xiong

+ [Interpretable Risk Mitigation in LLM Agent Systems](https://arxiv.org//abs/2505.10670)

	Jan Chojnacki

+ [Evaluations at Work: Measuring the Capabilities of GenAI in Use](https://arxiv.org//abs/2505.10742)

	Brandon Lepine, Gawesha Weerantunga, Juho Kim, Pamela Mishkin, Matthew Beane

+ [Code-Driven Planning in Grid Worlds with Large Language Models](https://arxiv.org//abs/2505.10749)

	Ashwath Vaithinathan Aravindan, Zhisheng Tang, Mayank Kejriwal

+ [LLM-Explorer: Towards Efficient and Affordable LLM-based Exploration for Mobile Apps](https://arxiv.org//abs/2505.10593)

	Shanhui Zhao, Hao Wen, Wenjie Du, Cheng Liang, Yunxin Liu, Xiaozhou Ye, Ye Ouyang, Yuanchun Li

+ [CRPE: Expanding The Reasoning Capability of Large Language Model for Code Generation](https://arxiv.org//abs/2505.10594)

	Ningxin Gui, Qianghuai Jia, Feijun Jiang, Yuling Jiao, dechun wang, Jerry Zhijian Yang

+ [Two Minds Better Than One: Collaborative Reward Modeling for LLM Alignment](https://arxiv.org//abs/2505.10597)

	Jiazheng Zhang, Wenqing Jing, Zizhuo Zhang, Zhiheng Xi, Shihan Dou, Rongxiang Weng, Jiahuan Li, Jingang Wang, MingXu Cai, Shibo Hong, Tao Gui, Qi Zhang

+ [Toward a Public and Secure Generative AI: A Comparative Analysis of Open and Closed LLMs](https://arxiv.org//abs/2505.10603)

	Jorge Machado

+ [Continuity and Isolation Lead to Doubts or Dilemmas in Large Language Models](https://arxiv.org//abs/2505.10606)

	Hector Pasten, Felipe Urrutia, Hector Jimenez, Cristian B. Calderon, Cristóbal Rojas, Alexander Kozachinskiy

+ [Agent Name Service (ANS): A Universal Directory for Secure AI Agent Discovery and Interoperability](https://arxiv.org//abs/2505.10609)

	Ken Huang, Vineeth Sai Narajala, Idan Habler, Akram Sheriff

+ [The Hitchhikers Guide to Production-ready Trustworthy Foundation Model powered Software (FMware)](https://arxiv.org//abs/2505.10640)

	Kirill Vasilevski, Benjamin Rombaut, Gopi Krishnan Rajbahadur, Gustavo A. Oliva, Keheliya Gallaba, Filipe R. Cogo, Jiahuei (Justina)Lin, Dayi Lin, Haoxiang Zhang, Bouyan Chen, Kishanthan Thangarajah, Ahmed E. Hassan, Zhen Ming (Jack)Jiang

+ [A Modular Approach for Clinical SLMs Driven by Synthetic Data with Pre-Instruction Tuning, Model Merging, and Clinical-Tasks Alignment](https://arxiv.org//abs/2505.10717)

	Jean-Philippe Corbeil, Amin Dada, Jean-Michel Attendu, Asma Ben Abacha, Alessandro Sordoni, Lucas Caccia, François Beaulieu, Thomas Lin, Jens Kleesiek, Paul Vozila

+ [Automating Security Audit Using Large Language Model based Agent: An Exploration Experiment](https://arxiv.org//abs/2505.10732)

	Jia Hui Chin, Pu Zhang, Yu Xin Cheong, Jonathan Pan

+ [Tracr-Injection: Distilling Algorithms into Pre-trained Language Models](https://arxiv.org//abs/2505.10719)

	Tomás Vergara-Browne, Álvaro Soto

+ [Model Performance-Guided Evaluation Data Selection for Effective Prompt Optimization](https://arxiv.org//abs/2505.10736)

	Ximing Dong, Shaowei Wang, Dayi Lin, Ahmed E. Hassan

+ [Mitigate Language Priors in Large Vision-Language Models by Cross-Images Contrastive Decoding](https://arxiv.org//abs/2505.10634)

	Jianfei Zhao, Feng Zhang, Xin Sun, Chong Feng

+ [SafeTrans: LLM-assisted Transpilation from C to Rust](https://arxiv.org//abs/2505.10708)

	Muhammad Farrukh (1), Smeet Shah (1), Baris Coskun (2), Michalis Polychronakis (1) ((1) Stony Brook University, (2) Amazon Web Services)

+ [On Technique Identification and Threat-Actor Attribution using LLMs and Embedding Models](https://arxiv.org//abs/2505.11547)

	Kyla Guru, Robert J. Moss, Mykel J. Kochenderfer

+ [One Shot Dominance: Knowledge Poisoning Attack on Retrieval-Augmented Generation Systems](https://arxiv.org//abs/2505.11548)

	Zhiyuan Chang, Xiaojun Jia, Mingyang Li, Junjie Wang, Yuekai Huang, Qing Wang, Ziyou Jiang, Yang Liu

+ [AI-generated Text Detection: A Multifaceted Approach to Binary and Multiclass Classification](https://arxiv.org//abs/2505.11550)

	Harika Abburi, Sanmitra Bhattacharya, Edward Bowen, Nirmala Pudota

+ [Assessing Collective Reasoning in Multi-Agent LLMs via Hidden Profile Tasks](https://arxiv.org//abs/2505.11556)

	Yuxuan Li, Aoi Naito, Hirokazu Shirado

+ [AC-LoRA: (Almost) Training-Free Access Control-Aware Multi-Modal LLMs](https://arxiv.org//abs/2505.11557)

	Lara Magdalena Lazier, Aritra Dhar, Vasilije Stambolic, Lukas Cavigelli

+ [Reinforcing the Diffusion Chain of Lateral Thought with Diffusion Language Models](https://arxiv.org//abs/2505.10446)

	Zemin Huang, Zhiyang Chen, Zijun Wang, Tiancheng Li, Guo-Jun Qi

+ [Assessing GPT's Bias Towards Stigmatized Social Groups: An Intersectional Case Study on Nationality Prejudice and Psychophobia](https://arxiv.org//abs/2505.17045)

	Afifah Kashif, Heer Patel

# 2025-05-14
+ [Reproducibility Study of "Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents"](https://arxiv.org//abs/2505.09289)

	Pedro M. P. Curvo, Mara Dragomir, Salvador Torpes, Mohammadmahdi Rahimi

+ [The Influence of Human-inspired Agentic Sophistication in LLM-driven Strategic Reasoners](https://arxiv.org//abs/2505.09396)

	Vince Trencsenyi, Agnieszka Mensfelt, Kostas Stathis

+ [Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?](https://arxiv.org//abs/2505.09614)

	Anthony GX-Chen, Dongyan Lin, Mandana Samiei, Doina Precup, Blake A. Richards, Rob Fergus, Kenneth Marino

+ [SALM: A Multi-Agent Framework for Language Model-Driven Social Network Simulation](https://arxiv.org//abs/2505.09081)

	Gaurav Koley

+ [CEC-Zero: Chinese Error Correction Solution Based on LLM](https://arxiv.org//abs/2505.09082)

	Sophie Zhang, Zhiming Lin

+ [Human-like Cognitive Generalization for Large Models via Brain-in-the-loop Supervision](https://arxiv.org//abs/2505.09085)

	Jiaxuan Chen, Yu Qi, Yueming Wang, Gang Pan

+ [Air-Ground Collaboration for Language-Specified Missions in Unknown Environments](https://arxiv.org//abs/2505.09108)

	Fernando Cladera, Zachary Ravichandran, Jason Hughes, Varun Murali, Carlos Nieto-Granda, M. Ani Hsieh, George J. Pappas, Camillo J. Taylor, Vijay Kumar

+ [ELIS: Efficient LLM Iterative Scheduling System with Response Length Predictor](https://arxiv.org//abs/2505.09142)

	Seungbeom Choi, Jeonghoe Goo, Eunjoo Jeon, Mingyu Yang, Minsung Jang

+ [Focus, Merge, Rank: Improved Question Answering Based on Semi-structured Knowledge Bases](https://arxiv.org//abs/2505.09246)

	Derian Boer, Stephen Roth, Stefan Kramer

+ [CXMArena: Unified Dataset to benchmark performance in realistic CXM Scenarios](https://arxiv.org//abs/2505.09436)

	Raghav Garg, Kapil Sharma, Karan Gupta

+ [Deploying Foundation Model-Enabled Air and Ground Robots in the Field: Challenges and Opportunities](https://arxiv.org//abs/2505.09477)

	Zachary Ravichandran, Fernando Cladera, Jason Hughes, Varun Murali, M. Ani Hsieh, George J. Pappas, Camillo J. Taylor, Vijay Kumar

+ [WorldView-Bench: A Benchmark for Evaluating Global Cultural Perspectives in Large Language Models](https://arxiv.org//abs/2505.09595)

	Abdullah Mushtaq, Imran Taj, Rafay Naeem, Ibrahim Ghaznavi, Junaid Qadir

+ [Atomic Consistency Preference Optimization for Long-Form Question Answering](https://arxiv.org//abs/2505.09039)

	Jingfeng Chen, Raghuveer Thirukovalluru, Junlin Wang, Kaiwei Luo, Bhuwan Dhingra

+ [A Comprehensive Analysis of Large Language Model Outputs: Similarity, Diversity, and Bias](https://arxiv.org//abs/2505.09056)

	Brandon Smith, Mohamed Reda Bouadjenek, Tahsin Alamgir Kheya, Phillip Dawson, Sunil Aryal

+ [Scent of Knowledge: Optimizing Search-Enhanced Reasoning with Information Foraging](https://arxiv.org//abs/2505.09316)

	Hongjin Qian, Zheng Liu

+ [Llama See, Llama Do: A Mechanistic Perspective on Contextual Entrainment and Distraction in LLMs](https://arxiv.org//abs/2505.09338)

	Jingcheng Niu, Xingdi Yuan, Tong Wang, Hamidreza Saghir, Amir H. Abdi

+ [Qwen3 Technical Report](https://arxiv.org//abs/2505.09388)

	An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, Chujie Zheng, Dayiheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao Ge, Haoran Wei, Huan Lin, Jialong Tang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jing Zhou, Jingren Zhou, Junyang Lin, Kai Dang, Keqin Bao, Kexin Yang, Le Yu, Lianghao Deng, Mei Li, Mingfeng Xue, Mingze Li, Pei Zhang, Peng Wang, Qin Zhu, Rui Men, Ruize Gao, Shixuan Liu, Shuang Luo, Tianhao Li, Tianyi Tang, Wenbiao Yin, Xingzhang Ren, Xinyu Wang, Xinyu Zhang, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yinger Zhang, Yu Wan, Yuqiong Liu, Zekun Wang, Zeyu Cui, Zhenru Zhang, Zhipeng Zhou, Zihan Qiu

+ [PT-MoE: An Efficient Finetuning Framework for Integrating Mixture-of-Experts into Prompt Tuning](https://arxiv.org//abs/2505.09519)

	Zongqian Li, Yixuan Su, Nigel Collier

+ [Ornithologist: Towards Trustworthy "Reasoning" about Central Bank Communications](https://arxiv.org//abs/2505.09083)

	Dominic Zaun Eu Jones

+ [FaceShield: Explainable Face Anti-Spoofing with Multimodal Large Language Models](https://arxiv.org//abs/2505.09415)

	Hongyang Wang, Yichen Shi, Zhuofu Tao, Yuhao Gao, Liepiao Zhang, Xun Lin, Jun Feng, Xiaochen Yuan, Zitong Yu, Xiaochun Cao

+ [SafePath: Conformal Prediction for Safe LLM-Based Autonomous Navigation](https://arxiv.org//abs/2505.09427)

	Achref Doula, Max Mühläuser, Alejandro Sanchez Guinea

+ [Layered Unlearning for Adversarial Relearning](https://arxiv.org//abs/2505.09500)

	Timothy Qian, Vinith Suriyakumar, Ashia Wilson, Dylan Hadfield-Menell

+ [Adversarial Suffix Filtering: a Defense Pipeline for LLMs](https://arxiv.org//abs/2505.09602)

	David Khachaturov, Robert Mullins

+ [Instantiating Standards: Enabling Standard-Driven Text TTP Extraction with Evolvable Memory](https://arxiv.org//abs/2505.09261)

	Cheng Meng, ZhengWei Jiang, QiuYun Wang, XinYi Li, ChunYan Ma, FangMing Dong, FangLi Ren, BaoXu Liu

+ [A Multimodal Multi-Agent Framework for Radiology Report Generation](https://arxiv.org//abs/2505.09787)

	Ziruo Yi, Ting Xiao, Mark V. Albert

+ [System Prompt Optimization with Meta-Learning](https://arxiv.org//abs/2505.09666)

	Yumin Choi, Jinheon Baek, Sung Ju Hwang

+ [Achieving Tokenizer Flexibility in Language Models through Heuristic Adaptation and Supertoken Learning](https://arxiv.org//abs/2505.09738)

	Shaurya Sharthak, Vinayak Pahalwan, Adithya Kamath, Adarsh Shirawalmath

+ [Trustless Autonomy: Understanding Motivations, Benefits and Governance Dilemma in Self-Sovereign Decentralized AI Agents](https://arxiv.org//abs/2505.09757)

	Botao Amber Hu, Yuhan Liu, Helena Rong

+ [Exploring the generalization of LLM truth directions on conversational formats](https://arxiv.org//abs/2505.09807)

	Timour Ichmoukhamedov, David Martens

+ [Evaluating Large Language Models for the Generation of Unit Tests with Equivalence Partitions and Boundary Values](https://arxiv.org//abs/2505.09830)

	Martín Rodríguez, Gustavo Rossi, Alejandro Fernandez

+ [Do Large Language Models Know Conflict? Investigating Parametric vs. Non-Parametric Knowledge of LLMs for Conflict Forecasting](https://arxiv.org//abs/2505.09852)

	Apollinaire Poli Nemkova, Sarath Chandra Lingareddy, Sagnik Ray Choudhury, Mark V. Albert

+ [DRA-GRPO: Exploring Diversity-Aware Reward Adjustment for R1-Zero-Like Training of Large Language Models](https://arxiv.org//abs/2505.09655)

	Xiwen Chen, Wenhui Zhu, Peijie Qiu, Xuanzhao Dong, Hao Wang, Haiyu Wu, Huayu Li, Aristeidis Sotiras, Yalin Wang, Abolfazl Razi

+ [Large Language Models Are More Persuasive Than Incentivized Human Persuaders](https://arxiv.org//abs/2505.09662)

	Philipp Schoenegger, Francesco Salvi, Jiacheng Liu, Xiaoli Nan, Ramit Debnath, Barbara Fasolo, Evelina Leivada, Gabriel Recchia, Fritz Günther, Ali Zarifhonarvar, Joe Kwon, Zahoor Ul Islam, Marco Dehnert, Daryl Y. H. Lee, Madeline G. Reinecke, David G. Kamper, Mert Kobaş, Adam Sandford, Jonas Kgomo, Luke Hewitt, Shreya Kapoor, Kerem Oktar, Eyup Engin Kucuk, Bo Feng, Cameron R. Jones, Izzy Gainsburg, Sebastian Olschewski, Nora Heinzelmann, Francisco Cruz, Ben M. Tappin, Tao Ma, Peter S. Park, Rayan Onyonka, Arthur Hjorth, Peter Slattery, Qingcheng Zeng, Lennart Finke, Igor Grossmann, Alessandro Salatiello, Ezra Karger

+ [VeriFact: Enhancing Long-Form Factuality Evaluation with Refined Fact Extraction and Reference Facts](https://arxiv.org//abs/2505.09701)

	Xin Liu, Lechen Zhang, Sheza Munir, Yiyang Gu, Lu Wang

+ [LAS: Loss-less ANN-SNN Conversion for Fully Spike-Driven Large Language Models](https://arxiv.org//abs/2505.09659)

	Long Chen, Xiaotian Song, Yanan Sun

+ [Analog Foundation Models](https://arxiv.org//abs/2505.09663)

	Julian Büchel, Iason Chalas, Giovanni Acampa, An Chen, Omobayode Fagbohungbe, Sidney Tsai, Kaoutar El Maghraoui, Manuel Le Gallo, Abbas Rahimi, Abu Sebastian

+ [Adversarial Attack on Large Language Models using Exponentiated Gradient Descent](https://arxiv.org//abs/2505.09820)

	Sajib Biswas, Mao Nishino, Samuel Jacob Chacko, Xiuwen Liu

+ [Understanding Gen Alpha Digital Language: Evaluation of LLM Safety Systems for Content Moderation](https://arxiv.org//abs/2505.10588)

	Manisha Mehta, Fausto Giunchiglia

+ [Towards Automated Situation Awareness: A RAG-Based Framework for Peacebuilding Reports](https://arxiv.org//abs/2505.10586)

	Poli A. Nemkova, Suleyman O. Polat, Rafid I. Jahan, Sagnik Ray Choudhury, Sun-joo Lee, Shouryadipta Sarkar, Mark V. Albert

+ [TARGET: Benchmarking Table Retrieval for Generative Tasks](https://arxiv.org//abs/2505.11545)

	Xingyu Ji, Parker Glenn, Aditya G. Parameswaran, Madelon Hulsebos

+ [MorphMark: Flexible Adaptive Watermarking for Large Language Models](https://arxiv.org//abs/2505.11541)

	Zongqi Wang, Tianle Gu, Baoyuan Wu, Yujiu Yang

+ [Source framing triggers systematic evaluation bias in Large Language Models](https://arxiv.org//abs/2505.13488)

	Federico Germani, Giovanni Spitale

+ [LLM4CD: Leveraging Large Language Models for Open-World Knowledge Augmented Cognitive Diagnosis](https://arxiv.org//abs/2505.13492)

	Weiming Zhang, Lingyue Fu, Qingyao Li, Kounianhua Du, Jianghao Lin, Jingwei Yu, Wei Xia, Weinan Zhang, Ruiming Tang, Yong Yu

+ [GenAI Security: Outsmarting the Bots with a Proactive Testing Framework](https://arxiv.org//abs/2505.18172)

	Sunil Kumar Jang Bahadur, Gopala Dhar, Lavi Nigam

+ [Beyond the Black Box: Interpretability of LLMs in Finance](https://arxiv.org//abs/2505.24650)

	Hariom Tatsat (Barclays), Ariye Shater (Barclays)

+ [Extracting Knowledge Graphs from User Stories using LangChain](https://arxiv.org//abs/2506.11020)

	Thayná Camargo da Silva

# 2025-05-13
+ [Lost in Transmission: When and Why LLMs Fail to Reason Globally](https://arxiv.org//abs/2505.08140)

	Tobias Schnabel, Kiran Tomlinson, Adith Swaminathan, Jennifer Neville

+ [Evaluating LLM Metrics Through Real-World Capabilities](https://arxiv.org//abs/2505.08253)

	Justin K Miller, Wenjia Tang

+ [Learning Like Humans: Advancing LLM Reasoning Capabilities via Adaptive Difficulty Curriculum Learning and Expert-Guided Self-Reformulation](https://arxiv.org//abs/2505.08364)

	Enci Zhang, Xingang Yan, Wei Lin, Tianxiang Zhang, Qianchun Lu

+ [Agent-as-a-Service based on Agent Network](https://arxiv.org//abs/2505.08446)

	Yuhan Zhu, Haojie Liu, Jian Wang, Bing Li, Zikang Yin, Yefei Liao

+ [Strategy-Augmented Planning for Large Language Models via Opponent Exploitation](https://arxiv.org//abs/2505.08459)

	Shuai Xu, Sijia Cui, Yanna Wang, Bo Xu, Qi Wang

+ [Achieving Scalable Robot Autonomy via neurosymbolic planning using lightweight local LLM](https://arxiv.org//abs/2505.08492)

	Nicholas Attolino, Alessio Capitanelli, Fulvio Mastrogiovanni

+ [TrialMatchAI: An End-to-End AI-powered Clinical Trial Recommendation System to Streamline Patient-to-Trial Matching](https://arxiv.org//abs/2505.08508)

	Majd Abdallah, Sigve Nakken, Mariska Bierkens, Johanna Galvis, Alexis Groppi, Slim Karkar, Lana Meiqari, Maria Alexandra Rujano, Steve Canham, Rodrigo Dienstmann, Remond Fijneman, Eivind Hovig, Gerrit Meijer, Macha Nikolski

+ [Guiding LLM-based Smart Contract Generation with Finite State Machine](https://arxiv.org//abs/2505.08542)

	Hao Luo, Yuhao Lin, Xiao Yan, Xintong Hu, Yuxiang Wang, Qiming Zeng, Hao Wang, Jiawei Jiang

+ [Resource-Efficient Language Models: Quantization for Fast and Accessible Inference](https://arxiv.org//abs/2505.08620)

	Tollef Emil Jørgensen

+ [TRAIL: Trace Reasoning and Agentic Issue Localization](https://arxiv.org//abs/2505.08638)

	Darshan Deshpande, Varun Gangal, Hersh Mehta, Jitin Krishnan, Anand Kannappan, Rebecca Qian

+ [WixQA: A Multi-Dataset Benchmark for Enterprise Retrieval-Augmented Generation](https://arxiv.org//abs/2505.08643)

	Dvir Cohen, Lin Burg, Sviatoslav Pykhnivskyi, Hagit Gur, Stanislav Kovynov, Olga Atzmon, Gilad Barkan

+ [LLM-based Prompt Ensemble for Reliable Medical Entity Recognition from EHRs](https://arxiv.org//abs/2505.08704)

	K M Sajjadul Islam, Ayesha Siddika Nipu, Jiawei Wu, Praveen Madiraju

+ [ALOHA: Empowering Multilingual Agent for University Orientation with Hierarchical Retrieval](https://arxiv.org//abs/2505.08130)

	Mingxu Tao, Bowen Tang, Mingxuan Ma, Yining Zhang, Hourun Li, Feifan Wen, Hao Ma, Jia Yang

+ [A Large-Scale Empirical Analysis of Custom GPTs' Vulnerabilities in the OpenAI Ecosystem](https://arxiv.org//abs/2505.08148)

	Sunday Oyinlola Ogundoyin, Muhammad Ikram, Hassan Jameel Asghar, Benjamin Zi Hao Zhao, Dali Kaafar

+ [Fusing Bidirectional Chains of Thought and Reward Mechanisms A Method for Enhancing Question-Answering Capabilities of Large Language Models for Chinese Intangible Cultural Heritage](https://arxiv.org//abs/2505.08167)

	Ruilin Liu, Zhixiao Zhao, Jieqiong Li, Chang Liu, Dongbo Wang

+ [A Head to Predict and a Head to Question: Pre-trained Uncertainty Quantification Heads for Hallucination Detection in LLM Outputs](https://arxiv.org//abs/2505.08200)

	Artem Shelmanov, Ekaterina Fadeeva, Akim Tsvigun, Ivan Tsvigun, Zhuohan Xie, Igor Kiselev, Nico Daheim, Caiqi Zhang, Artem Vazhentsev, Mrinmaya Sachan, Preslav Nakov, Timothy Baldwin

+ [Large Language Model Psychometrics: A Systematic Review of Evaluation, Validation, and Enhancement](https://arxiv.org//abs/2505.08245)

	Haoran Ye, Jing Jin, Yuhang Xie, Xin Zhang, Guojie Song

+ [Enhancing Cache-Augmented Generation (CAG) with Adaptive Contextual Compression for Scalable Knowledge Integration](https://arxiv.org//abs/2505.08261)

	Rishabh Agrawal, Himanshu Kumar

+ [LLM Enhancers for GNNs: An Analysis from the Perspective of Causal Mechanism Identification](https://arxiv.org//abs/2505.08265)

	Hang Gao, Wenxuan Huang, Fengge Wu, Junsuo Zhao, Changwen Zheng, Huaping Liu

+ [Accelerating Chain-of-Thought Reasoning: When Goal-Gradient Importance Meets Dynamic Skipping](https://arxiv.org//abs/2505.08392)

	Ren Zhuang, Ben Wang, Shuifa Sun

+ [Optimizing Retrieval-Augmented Generation: Analysis of Hyperparameter Impact on Performance and Efficiency](https://arxiv.org//abs/2505.08445)

	Adel Ammar, Anis Koubaa, Omer Nacar, Wadii Boulila

+ [RepCali: High Efficient Fine-tuning Via Representation Calibration in Latent Space for Pre-trained Language Models](https://arxiv.org//abs/2505.08463)

	Fujun Zhang, XiangDong Su

+ [LCES: Zero-shot Automated Essay Scoring via Pairwise Comparisons Using Large Language Models](https://arxiv.org//abs/2505.08498)

	Takumi Shibata, Yuichi Miyamura

+ [The Truth Becomes Clearer Through Debate! Multi-Agent Systems with Large Language Models Unmask Fake News](https://arxiv.org//abs/2505.08532)

	Yuhan Liu, Yuxuan Liu, Xiaoqing Zhang, Xiuying Chen, Rui Yan

+ [PWC-MoE: Privacy-Aware Wireless Collaborative Mixture of Experts](https://arxiv.org//abs/2505.08719)

	Yang Su, Na Yan, Yansha Deng, Robert Schober

+ [Memorization-Compression Cycles Improve Generalization](https://arxiv.org//abs/2505.08727)

	Fangyuan Yu

+ [Securing RAG: A Risk Assessment and Mitigation Framework](https://arxiv.org//abs/2505.08728)

	Lukas Ammann, Sara Ott, Christoph R. Landolt, Marco P. Lehmann

+ [CodePDE: An Inference Framework for LLM-driven PDE Solver Generation](https://arxiv.org//abs/2505.08783)

	Shanda Li, Tanya Marwah, Junhong Shen, Weiwei Sun, Andrej Risteski, Yiming Yang, Ameet Talwalkar

+ [Evaluating the Effectiveness of Black-Box Prompt Optimization as the Scale of LLMs Continues to Grow](https://arxiv.org//abs/2505.08303)

	Ziyu Zhou, Yihang Wu, Jingyuan Yang, Zhan Xiao, Rongjun Li

+ [On the Geometry of Semantics in Next-token Prediction](https://arxiv.org//abs/2505.08348)

	Yize Zhao, Christos Thrampoulidis

+ [Alignment Drift in CEFR-prompted LLMs for Interactive Spanish Tutoring](https://arxiv.org//abs/2505.08351)

	Mina Almasi, Ross Deans Kristensen-McLachlan

+ [Towards Contamination Resistant Benchmarks](https://arxiv.org//abs/2505.08389)

	Rahmatullah Musawi, Sheng Lu

+ [Enhancing Thyroid Cytology Diagnosis with RAG-Optimized LLMs and Pa-thology Foundation Models](https://arxiv.org//abs/2505.08590)

	Hussien Al-Asi, Jordan P Reynolds, Shweta Agarwal, Bryan J Dangott, Aziza Nassar, Zeynettin Akkus

+ [Automatic Task Detection and Heterogeneous LLM Speculative Decoding](https://arxiv.org//abs/2505.08600)

	Danying Ge, Jianhua Gao, Qizhi Jiang, Yifei Feng, Weixing Ji

+ [Scaling Context, Not Parameters: Training a Compact 7B Language Model for Efficient Long-Context Processing](https://arxiv.org//abs/2505.08651)

	Chen Wu, Yin Song

+ [Revealing economic facts: LLMs know more than they say](https://arxiv.org//abs/2505.08662)

	Marcus Buckmann, Quynh Anh Nguyen, Edward Hill

+ [Adaptive Schema-aware Event Extraction with Retrieval-Augmented Generation](https://arxiv.org//abs/2505.08690)

	Sheng Liang, Hang Lv, Zhihao Wen, Yaxiong Wu, Yongyue Zhang, Hao Wang, Yong Liu

+ [NurValues: Real-World Nursing Values Evaluation for Large Language Models in Clinical Context](https://arxiv.org//abs/2505.08734)

	Ben Yao, Qiuchi Li, Yazhou Zhang, Siyu Yang, Bohan Zhang, Prayag Tiwari, Jing Qin

+ [Probability Consistency in Large Language Models: Theoretical Foundations Meet Empirical Discrepancies](https://arxiv.org//abs/2505.08739)

	Xiaoliang Luo, Xinyi Xu, Michael Ramscar, Bradley C. Love

+ [AC-Reason: Towards Theory-Guided Actual Causality Reasoning with Large Language Models](https://arxiv.org//abs/2505.08750)

	Yanxi Zhang, Xin Cong, Zhong Zhang, Xiao Liu, Dongyan Zhao, Yesai Wu

+ [InfoPO: On Mutual Information Maximization for Large Language Model Alignment](https://arxiv.org//abs/2505.08507)

	Teng Xiao, Zhen Ge, Sujay Sanghavi, Tian Wang, Julian Katz-Samuels, Marc Versage, Qingjun Cui, Trishul Chilimbi

+ [LM-Scout: Analyzing the Security of Language Model Integration in Android Apps](https://arxiv.org//abs/2505.08204)

	Muhammad Ibrahim (1), Gűliz Seray Tuncay (2), Z. Berkay Celik (3), Aravind Machiry (3), Antonio Bianchi (3) ((1) Georgia Institute of Technology, (2) Google, (3) Purdue University)

+ [Grounding Synthetic Data Evaluations of Language Models in Unsupervised Document Corpora](https://arxiv.org//abs/2505.08905)

	Michael Majurski, Cynthia Matuszek

+ [Automated Meta Prompt Engineering for Alignment with the Theory of Mind](https://arxiv.org//abs/2505.09024)

	Aaron Baughman, Rahul Agarwal, Eduardo Morales, Gozde Akay

+ [Improving the Reliability of LLMs: Combining CoT, RAG, Self-Consistency, and Self-Verification](https://arxiv.org//abs/2505.09031)

	Adarsh Kumar, Hwiyoon Kim, Jawahar Sai Nathani, Neil Roy

+ [Federated Large Language Models: Feasibility, Robustness, Security and Future Directions](https://arxiv.org//abs/2505.08830)

	Wenhao Jiang, Yuchuan Luo, Guilin Deng, Silong Chen, Xu Yang, Shihong Wu, Xinwen Gao, Lin Liu, Shaojing Fu

+ [CellTypeAgent: Trustworthy cell type annotation with Large Language Models](https://arxiv.org//abs/2505.08844)

	Jiawen Chen, Jianghao Zhang, Huaxiu Yao, Yun Li

+ [Improved Algorithms for Differentially Private Language Model Alignment](https://arxiv.org//abs/2505.08849)

	Keyu Chen, Hao Tang, Qinglin Liu, Yizhao Xu

+ [Optimized Couplings for Watermarking Large Language Models](https://arxiv.org//abs/2505.08878)

	Dor Tsur, Carol Xuan Long, Claudio Mayrink Verdun, Hsiang Hsu, Haim Permuter, Flavio P. Calmon

+ [Tests as Prompt: A Test-Driven-Development Benchmark for LLM Code Generation](https://arxiv.org//abs/2505.09027)

	Yi Cui

+ [LibVulnWatch: A Deep Assessment Agent System and Leaderboard for Uncovering Hidden Vulnerabilities in Open-Source AI Libraries](https://arxiv.org//abs/2505.08842)

	Zekun Wu, Seonglae Cho, Umar Mohammed, Cristian Munoz, Kleyton Costa, Xin Guan, Theo King, Ze Wang, Emre Kazim, Adriano Koshiyama

+ [Detecting Prefix Bias in LLM-based Reward Models](https://arxiv.org//abs/2505.13487)

	Ashwin Kumar, Yuzi He, Aram H. Markosyan, Bobbie Chern, Imanol Arrieta-Ibarra

+ [Generalizing Large Language Model Usability Across Resource-Constrained](https://arxiv.org//abs/2505.17040)

	Yun-Da Tsai

+ [Model-Distributed Inference for Large Language Models at the Edge](https://arxiv.org//abs/2505.18164)

	Davide Macario, Hulya Seferoglu, Erdem Koyuncu

+ [Constrained Edge AI Deployment: Fine-Tuning vs Distillation for LLM Compression](https://arxiv.org//abs/2505.18166)

	Jacob Sander, David Moe, Achraf Cohen, Brent Venable, Venkat Dasari, Brian Jalaian

# 2025-05-12
+ [How well do LLMs reason over tabular data, really?](https://arxiv.org//abs/2505.07453)

	Cornelius Wolff, Madelon Hulsebos

+ [A Survey on Collaborative Mechanisms Between Large and Small Language Models](https://arxiv.org//abs/2505.07460)

	Yi Chen, JiaHao Zhao, HaoHao Han

+ [Web-Bench: A LLM Code Benchmark Based on Web Standards and Frameworks](https://arxiv.org//abs/2505.07473)

	Kai Xu, YiWei Mao, XinYi Guan, ZiLong Feng

+ [QuantX: A Framework for Hardware-Aware Quantization of Generative AI Workloads](https://arxiv.org//abs/2505.07531)

	Khurram Mazher, Saad Bin Nasir

+ [S-GRPO: Early Exit via Reinforcement Learning in Reasoning Models](https://arxiv.org//abs/2505.07686)

	Muzhi Dai, Chenxu Yang, Qingyi Si

+ [Belief Injection for Epistemic Control in Linguistic State Space](https://arxiv.org//abs/2505.07693)

	Sebastian Dumbrava

+ [Agent RL Scaling Law: Agent RL with Spontaneous Code Execution for Mathematical Problem Solving](https://arxiv.org//abs/2505.07773)

	Xinji Mai, Haotian Xu, Xing W, Weinong Wang, Yingying Zhang, Wenqiang Zhang

+ [DynamicRAG: Leveraging Outputs of Large Language Model as Feedback for Dynamic Reranking in Retrieval-Augmented Generation](https://arxiv.org//abs/2505.07233)

	Jiashuo Sun, Xianrui Zhong, Sizhe Zhou, Jiawei Han

+ [UAV-CodeAgents: Scalable UAV Mission Planning via Multi-Agent ReAct and Vision-Language Reasoning](https://arxiv.org//abs/2505.07236)

	Oleg Sautenkov, Yasheerah Yaqoot, Muhammad Ahsan Mustafa, Faryal Batool, Jeffrin Sam, Artem Lykov, Chih-Yung Wen, Dzmitry Tsetserukou

+ [Comet: Accelerating Private Inference for Large Language Model by Predicting Activation Sparsity](https://arxiv.org//abs/2505.07239)

	Guang Yan, Yuhui Zhang, Zimu Guo, Lutan Zhao, Xiaojun Chen, Chen Wang, Wenhao Wang, Dan Meng, Rui Hou

+ [SAS-Bench: A Fine-Grained Benchmark for Evaluating Short Answer Scoring with Large Language Models](https://arxiv.org//abs/2505.07247)

	Peichao Lai, Kexuan Zhang, Yi Lin, Linyihan Zhang, Feiyang Ye, Jinhao Yan, Yanwei Xu, Conghui He, Yilei Wang, Wentao Zhang, Bin Cui

+ [No Query, No Access](https://arxiv.org//abs/2505.07258)

	Wenqiang Wang, Siyuan Liang, Yangshijie Zhang, Xiaojun Jia, Hao Lin, Xiaochun Cao

+ [UMoE: Unifying Attention and FFN with Shared Experts](https://arxiv.org//abs/2505.07260)

	Yuanhang Yang, Chaozheng Wang, Jing Li

+ [On the Robustness of Reward Models for Language Model Alignment](https://arxiv.org//abs/2505.07271)

	Jiwoo Hong, Noah Lee, Eunki Kim, Guijin Son, Woojin Chung, Aman Gupta, Shao Tang, James Thorne

+ [Semantic Retention and Extreme Compression in LLMs: Can We Have Both?](https://arxiv.org//abs/2505.07289)

	Stanislas Laborde, Martin Cousseau, Antoun Yaacoub, Lionel Prevost

+ [Towards Multi-Agent Reasoning Systems for Collaborative Expertise Delegation: An Exploratory Design Study](https://arxiv.org//abs/2505.07313)

	Baixuan Xu, Chunyang Li, Weiqi Wang, Wei Fan, Tianshi Zheng, Haochen Shi, Tao Fan, Yangqiu Song, Qiang Yang

+ [Synthetic Code Surgery: Repairing Bugs and Vulnerabilities with LLMs and Synthetic Data](https://arxiv.org//abs/2505.07372)

	David de-Fitero-Dominguez, Antonio Garcia-Cabot, Eva Garcia-Lopez

+ [LEAD: Iterative Data Selection for Efficient LLM Instruction Tuning](https://arxiv.org//abs/2505.07437)

	Xiaotian Lin, Yanlin Qi, Yizhang Zhu, Themis Palpanas, Chengliang Chai, Nan Tang, Yuyu Luo

+ [Can Generative AI agents behave like humans? Evidence from laboratory market experiments](https://arxiv.org//abs/2505.07457)

	R. Maria del Rio-Chanona, Marco Pangallo, Cars Hommes

+ [ToolACE-DEV: Self-Improving Tool Learning via Decomposition and EVolution](https://arxiv.org//abs/2505.07512)

	Xu Huang, Weiwen Liu, Xingshan Zeng, Yuefeng Huang, Xinlong Hao, Yuxian Wang, Yirong Zeng, Chuhan Wu, Yasheng Wang, Ruiming Tang, Defu Lian

+ [GRADA: Graph-based Reranker against Adversarial Documents Attack](https://arxiv.org//abs/2505.07546)

	Jingjie Zheng, Aryo Pradipta Gema, Giwon Hong, Xuanli He, Pasquale Minervini, Youcheng Sun, Qiongkai Xu

+ [Towards Requirements Engineering for RAG Systems](https://arxiv.org//abs/2505.07553)

	Tor Sporsem, Rasmus Ulfsnes

+ [A Multi-Dimensional Constraint Framework for Evaluating and Improving Instruction Following in Large Language Models](https://arxiv.org//abs/2505.07591)

	Junjie Ye, Caishuang Huang, Zhuohan Chen, Wenjie Fu, Chenyuan Yang, Leyi Yang, Yilong Wu, Peng Wang, Meng Zhou, Xiaolong Yang, Tao Gui, Qi Zhang, Zhongchao Shi, Jianping Fan, Xuanjing Huang

+ [Reinforced Internal-External Knowledge Synergistic Reasoning for Efficient Adaptive Search Agent](https://arxiv.org//abs/2505.07596)

	Ziyang Huang, Xiaowei Yuan, Yiming Ju, Jun Zhao, Kang Liu

+ [MiMo: Unlocking the Reasoning Potential of Language Model -- From Pretraining to Posttraining](https://arxiv.org//abs/2505.07608)

	Xiaomi LLM-Core Team: Bingquan Xia, Bowen Shen, Cici, Dawei Zhu, Di Zhang, Gang Wang, Hailin Zhang, Huaqiu Liu, Jiebao Xiao, Jinhao Dong, Liang Zhao, Peidian Li, Peng Wang, Shihua Yu, Shimao Chen, Weikun Wang, Wenhan Ma, Xiangwei Deng, Yi Huang, Yifan Song, Zihan Jiang, Bowen Ye, Can Cai, Chenhong He, Dong Zhang, Duo Zhang, Guoan Wang, Hao Tian, Haochen Zhao, Heng Qu, Hongshen Xu, Jun Shi, Kainan Bao, QingKai Fang, Kang Zhou, Kangyang Zhou, Lei Li, Menghang Zhu, Nuo Chen, Qiantong Wang, Shaohui Liu, Shicheng Li, Shuhao Gu, Shuhuai Ren, Shuo Liu, Sirui Deng, Weiji Zhuang, Weiwei Lv, Wenyu Yang, Xin Zhang, Xing Yong, Xing Zhang, Xingchen Song, Xinzhe Xu, Xu Wang, Yihan Yan, Yu Tu, Yuanyuan Tian, Yudong Wang, Yue Yu, Zhenru Lin, Zhichao Song, Zihao Yue

+ [Concept-Level Explainability for Auditing & Steering LLM Responses](https://arxiv.org//abs/2505.07610)

	Kenza Amara, Rita Sevastjanova, Mennatallah El-Assady

+ [Chronocept: Instilling a Sense of Time in Machines](https://arxiv.org//abs/2505.07637)

	Krish Goel, Sanskar Pandey, KS Mahadevan, Harsh Kumar, Vishesh Khadaria

+ [Benchmarking Retrieval-Augmented Generation for Chemistry](https://arxiv.org//abs/2505.07671)

	Xianrui Zhong, Bowen Jin, Siru Ouyang, Yanzhen Shen, Qiao Jin, Yin Fang, Zhiyong Lu, Jiawei Han

+ [OnPrem.LLM: A Privacy-Conscious Document Intelligence Toolkit](https://arxiv.org//abs/2505.07672)

	Arun S. Maiya

+ [Overflow Prevention Enhances Long-Context Recurrent LLMs](https://arxiv.org//abs/2505.07793)

	Assaf Ben-Kish, Itamar Zimerman, M. Jehanzeb Mirza, James Glass, Leonid Karlinsky, Raja Giryes

+ [Structural Entropy Guided Agent for Detecting and Repairing Knowledge Deficiencies in LLMs](https://arxiv.org//abs/2505.07184)

	Yifan Wei, Xiaoyan Yu, Tengfei Pan, Angsheng Li, Li Du

+ [Benchmarking Ethical and Safety Risks of Healthcare LLMs in China-Toward Systemic Governance under Healthy China 2030](https://arxiv.org//abs/2505.07205)

	Mouxiao Bian, Rongzhao Zhang, Chao Ding, Xinwei Peng, Jie Xu

+ [AttentionInfluence: Adopting Attention Head Influence for Weak-to-Strong Pretraining Data Selection](https://arxiv.org//abs/2505.07293)

	Kai Hua, Steven Wu, Ge Zhang, Ke Shen

+ [SEReDeEP: Hallucination Detection in Retrieval-Augmented Models via Semantic Entropy and Context-Parameter Fusion](https://arxiv.org//abs/2505.07528)

	Lei Wang

+ [Spoken Language Understanding on Unseen Tasks With In-Context Learning](https://arxiv.org//abs/2505.07731)

	Neeraj Agrawal, Sriram Ganapathy

+ [Domain Regeneration: How well do LLMs match syntactic properties of text domains?](https://arxiv.org//abs/2505.07784)

	Da Ju, Hagen Blix, Adina Williams

+ [Learning from Peers in Reasoning Models](https://arxiv.org//abs/2505.07787)

	Tongxu Luo, Wenyu Du, Jiaxi Bi, Stephen Chung, Zhengyang Tang, Hao Yang, Min Zhang, Benyou Wang

+ [Reassessing Large Language Model Boolean Query Generation for Systematic Reviews](https://arxiv.org//abs/2505.07155)

	Shuai Wang, Harrisen Scells, Bevan Koopman, Guido Zuccon

+ [Pre-training vs. Fine-tuning: A Reproducibility Study on Dense Retrieval Knowledge Acquisition](https://arxiv.org//abs/2505.07166)

	Zheng Yao, Shuai Wang, Guido Zuccon

+ [One Trigger Token Is Enough: A Defense Strategy for Balancing Safety and Usability in Large Language Models](https://arxiv.org//abs/2505.07167)

	Haoran Gu, Handing Wang, Yi Mei, Mengjie Zhang, Yaochu Jin

+ [Direct Density Ratio Optimization: A Statistically Consistent Approach to Aligning Large Language Models](https://arxiv.org//abs/2505.07558)

	Rei Higuchi, Taiji Suzuki

+ [Critique Before Thinking: Mitigating Hallucination through Rationale-Augmented Instruction Tuning](https://arxiv.org//abs/2505.07172)

	Zexian Yang, Dian Li, Dayan Wu, Gang Liu, Weiping Wang

+ [Learning to Reason and Navigate: Parameter Efficient Action Planning with Large Language Models](https://arxiv.org//abs/2505.07500)

	Bahram Mohammadi, Ehsan Abbasnejad, Yuankai Qi, Qi Wu, Anton Van Den Hengel, Javen Qinfeng Shi

+ [Imagine, Verify, Execute: Memory-Guided Agentic Exploration with Vision-Language Models](https://arxiv.org//abs/2505.07815)

	Seungjae Lee, Daniel Ekpo, Haowen Liu, Furong Huang, Abhinav Shrivastava, Jia-Bin Huang

+ [Cache-Efficient Posterior Sampling for Reinforcement Learning with LLM-Derived Priors Across Discrete and Continuous Domains](https://arxiv.org//abs/2505.07274)

	Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma

+ [Uncertainty Profiles for LLMs: Uncertainty Source Decomposition and Adaptive Model-Metric Selection](https://arxiv.org//abs/2505.07309)

	Pei-Fu Guo, Yun-Da Tsai, Shou-De Lin

+ [Injecting Knowledge Graphs into Large Language Models](https://arxiv.org//abs/2505.07554)

	Erica Coppolillo

+ [SpecRouter: Adaptive Routing for Multi-Level Speculative Decoding in Large Language Models](https://arxiv.org//abs/2505.07680)

	Hang Wu, Jianian Zhu, Yinghui Li, Haojie Wang, Biao Hou, Jidong Zhai

+ [MLE-Dojo: Interactive Environments for Empowering LLM Agents in Machine Learning Engineering](https://arxiv.org//abs/2505.07782)

	Rushi Qiang, Yuchen Zhuang, Yinghao Li, Dingu Sagar V K, Rongzhi Zhang, Changhao Li, Ian Shu-Hei Wong, Sherry Yang, Percy Liang, Chao Zhang, Bo Dai

+ [Relative Overfitting and Accept-Reject Framework](https://arxiv.org//abs/2505.07783)

	Yanxin Liu, Yunqi Zhang

+ [Private LoRA Fine-tuning of Open-Source LLMs with Homomorphic Encryption](https://arxiv.org//abs/2505.07329)

	Jordan Frery, Roman Bredehoft, Jakub Klemsa, Arthur Meyre, Andrei Stoian

+ [SecReEvalBench: A Multi-turned Security Resilience Evaluation Benchmark for Large Language Models](https://arxiv.org//abs/2505.07584)

	Huining Cui, Wei Liu

+ [LongCodeBench: Evaluating Coding LLMs at 1M Context Windows](https://arxiv.org//abs/2505.07897)

	Stefano Rando, Luca Romani, Alessio Sampieri, Yuta Kyuragi, Luca Franco, Fabio Galasso, Tatsunori Hashimoto, John Yang

+ [DeltaEdit: Enhancing Sequential Editing in Large Language Models by Controlling Superimposed Noise](https://arxiv.org//abs/2505.07899)

	Ding Cao, Yuchen Cai, Rongxi Guo, Xuesong He, Guiquan Liu

+ [SEM: Reinforcement Learning for Search-Efficient Large Language Models](https://arxiv.org//abs/2505.07903)

	Zeyang Sha, Shiwen Cui, Weiqiang Wang

+ [A Reproduction Study: The Kernel PCA Interpretation of Self-Attention Fails Under Scrutiny](https://arxiv.org//abs/2505.07908)

	Karahan Sarıtaş, Çağatay Yıldız

+ [Efficient and Reproducible Biomedical Question Answering using Retrieval Augmented Generation](https://arxiv.org//abs/2505.07917)

	Linus Stuhlmann, Michael Alexander Saxer, Jonathan Fürst

+ [FalseReject: A Resource for Improving Contextual Safety and Mitigating Over-Refusals in LLMs via Structured Reasoning](https://arxiv.org//abs/2505.08054)

	Zhehao Zhang, Weijie Xu, Fanyou Wu, Chandan K. Reddy

+ [Beyond Input Activations: Identifying Influential Latents by Gradient Sparse Autoencoders](https://arxiv.org//abs/2505.08080)

	Dong Shu, Xuansheng Wu, Haiyan Zhao, Mengnan Du, Ninghao Liu

+ [Assessing and Mitigating Medical Knowledge Drift and Conflicts in Large Language Models](https://arxiv.org//abs/2505.07968)

	Weiyi Wu, Xinwen Xu, Chongyang Gao, Xingjian Diao, Siting Li, Lucas A. Salas, Jiang Gui

+ [Putting It All into Context: Simplifying Agents with LCLMs](https://arxiv.org//abs/2505.08120)

	Mingjian Jiang, Yangjun Ruan, Luis Lastras, Pavan Kapanipathi, Tatsunori Hashimoto

+ [Making Small Language Models Efficient Reasoners: Intervention, Supervision, Reinforcement](https://arxiv.org//abs/2505.07961)

	Xuechen Zhang, Zijian Huang, Chenchun Ni, Ziyang Xiong, Jiasi Chen, Samet Oymak

+ [Security of Internet of Agents: Attacks and Countermeasures](https://arxiv.org//abs/2505.08807)

	Yuntao Wang, Yanghe Pan, Shaolong Guo, Zhou Su

+ [An Extra RMSNorm is All You Need for Fine Tuning to 1.58 Bits](https://arxiv.org//abs/2505.08823)

	Cody Steinmetz, Gavin Childress, Aaron Herbst, Gavin Jones, Jasdeep Singh, Eli Vang, Keagan Weinstock

+ [Self Rewarding Self Improving](https://arxiv.org//abs/2505.08827)

	Toby Simonds, Kevin Lopez, Akira Yoshiyama, Dominique Garmier

+ [Evaluating Large Language Models for Real-World Engineering Tasks](https://arxiv.org//abs/2505.13484)

	Rene Heesch, Sebastian Eilermann, Alexander Windmann, Alexander Diedrich, Philipp Rosenthal, Oliver Niggemann

# 2025-05-11
+ [Control Plane as a Tool: A Scalable Design Pattern for Agentic AI Systems](https://arxiv.org//abs/2505.06817)

	Sivasathivel Kandasamy

+ [Towards Artificial General or Personalized Intelligence? A Survey on Foundation Models for Personalized Federated Intelligence](https://arxiv.org//abs/2505.06907)

	Yu Qiao, Huy Q. Le, Avi Deb Raha, Phuong-Nam Tran, Apurba Adhikary, Mengchun Zhang, Loc X. Nguyen, Eui-Nam Huh, Dusit Niyato, Choong Seon Hong

+ [LLM-Augmented Chemical Synthesis and Design Decision Programs](https://arxiv.org//abs/2505.07027)

	Haorui Wang, Jeff Guo, Lingkai Kong, Rampi Ramprasad, Philippe Schwaller, Yuanqi Du, Chao Zhang

+ [DialogueReason: Rule-Based RL Sparks Dialogue Reasoning in LLMs](https://arxiv.org//abs/2505.07049)

	Yubo Shu, Zhewei Huang, Xin Wu, Chen Hu, Shuchang Zhou, Daxin Jiang

+ [Architectural Precedents for General Agents using Large Language Models](https://arxiv.org//abs/2505.07087)

	Robert E. Wray, James R. Kirk, John E. Laird

+ [RefPentester: A Knowledge-Informed Self-Reflective Penetration Testing Framework Based on Large Language Models](https://arxiv.org//abs/2505.07089)

	Hanzheng Dai, Yuanliang Li, Zhibo Zhang, Jun Yan

+ [ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification](https://arxiv.org//abs/2505.06821)

	Dipayan Saha, Hasan Al Shaikh, Shams Tarek, Farimah Farahmandi

+ [Sandcastles in the Storm: Revisiting the (Im)possibility of Strong Watermarking](https://arxiv.org//abs/2505.06827)

	Fabrice Y Harel-Canada, Boran Erol, Connor Choi, Jason Liu, Gary Jiarui Song, Nanyun Peng, Amit Sahai

+ [The power of fine-grained experts: Granularity boosts expressivity in Mixture of Experts](https://arxiv.org//abs/2505.06839)

	Enric Boix-Adsera, Philippe Rigollet

+ [IM-BERT: Enhancing Robustness of BERT through the Implicit Euler Method](https://arxiv.org//abs/2505.06889)

	Mihyeon Kim, Juhyoung Park, Youngbin Kim

+ [RedTeamLLM: an Agentic AI framework for offensive security](https://arxiv.org//abs/2505.06913)

	Brian Challita, Pierre Parrend

+ [Convert Language Model into a Value-based Strategic Planner](https://arxiv.org//abs/2505.06987)

	Xiaoyu Wang, Yue Zhao, Qingqing Gu, Zhonglin Jiang, Xiaokai Chen, Yong Chen, Luo Ji

+ [ParaView-MCP: An Autonomous Visualization Agent with Direct Tool Use](https://arxiv.org//abs/2505.07064)

	Shusen Liu, Haichao Miao, Peer-Timo Bremer

+ [EcoLANG: Efficient and Effective Agent Communication Language Induction for Social Simulation](https://arxiv.org//abs/2505.06904)

	Xinyi Mou, Chen Qian, Wei Liu, Xuanjing Huang, Zhongyu Wei

+ [The Distracting Effect: Understanding Irrelevant Passages in RAG](https://arxiv.org//abs/2505.06914)

	Chen Amiraz, Florin Cuconasu, Simone Filice, Zohar Karnin

+ [Benign Samples Matter! Fine-tuning On Outlier Benign Samples Severely Breaks Safety](https://arxiv.org//abs/2505.06843)

	Zihan Guan, Mengxuan Hu, Ronghang Zhu, Sheng Li, Anil Vullikanti

+ [Building a Human-Verified Clinical Reasoning Dataset via a Human LLM Hybrid Pipeline for Trustworthy Medical AI](https://arxiv.org//abs/2505.06912)

	Chao Ding, Mouxiao Bian, Pengcheng Chen, Hongliang Zhang, Tianbin Li, Lihao Liu, Jiayuan Chen, Zhuoran Li, Yabei Zhong, Yongqi Liu, Haiqing Huang, Dongming Shan, Junjun He, Jie Xu

+ [Hallucination-Aware Multimodal Benchmark for Gastrointestinal Image Analysis with Large Vision-Language Models](https://arxiv.org//abs/2505.07001)

	Bidur Khanal, Sandesh Pokhrel, Sanjay Bhandari, Ramesh Rana, Nikesh Shrestha, Ram Bahadur Gurung, Cristian Linte, Angus Watson, Yash Raj Shrestha, Binod Bhattarai

+ [GuidedQuant: Large Language Model Quantization via Exploiting End Loss Guidance](https://arxiv.org//abs/2505.07004)

	Jinuk Kim, Marwa El Halabi, Wonpyo Park, Clemens JS Schaefer, Deokjae Lee, Yeonhong Park, Jae W. Lee, Hyun Oh Song

+ [PLHF: Prompt Optimization with Few-Shot Human Feedback](https://arxiv.org//abs/2505.07886)

	Chun-Pai Yang, Kan Zheng, Shou-De Lin

+ [TrumorGPT: Graph-Based Retrieval-Augmented Large Language Model for Fact-Checking](https://arxiv.org//abs/2505.07891)

	Ching Nam Hang, Pei-Duo Yu, Chee Wei Tan

+ [Evaluating Reasoning LLMs for Suicide Screening with the Columbia-Suicide Severity Rating Scale](https://arxiv.org//abs/2505.13480)

	Avinash Patil, Siru Tao, Amardeep Gedhu

# 2025-05-10
+ [System Prompt Poisoning: Persistent Attacks on Large Language Models Beyond User Injection](https://arxiv.org//abs/2505.06493)

	Jiawei Guo, Haipeng Cai

+ [MacRAG: Compress, Slice, and Scale-up for Multi-Scale Adaptive Context RAG](https://arxiv.org//abs/2505.06569)

	Woosang Lim, Zekun Li, Gyuwan Kim, Sungyoung Ji, HyeonJung Kim, Kyuri Choi, Jin Hyuk Lim, Kyungpyo Park, William Yang Wang

+ [Think in Safety: Unveiling and Mitigating Safety Alignment Collapse in Multimodal Large Reasoning Model](https://arxiv.org//abs/2505.06538)

	Xinyue Lou, You Li, Jinan Xu, Xiangyu Shi, Chi Chen, Kaiyu Huang

+ [REFINE-AF: A Task-Agnostic Framework to Align Language Models via Self-Generated Instructions using Reinforcement Learning from Automated Feedback](https://arxiv.org//abs/2505.06548)

	Aniruddha Roy, Pretam Ray, Abhilash Nandy, Somak Aditya, Pawan Goyal

+ [Using External knowledge to Enhanced PLM for Semantic Matching](https://arxiv.org//abs/2505.06605)

	Min Li, Chun Yuan

+ [Attention Is Not All You Need: The Importance of Feedforward Networks in Transformer Models](https://arxiv.org//abs/2505.06633)

	Isaac Gerber

+ [From Rankings to Insights: Evaluation Should Shift Focus from Leaderboard to Feedback](https://arxiv.org//abs/2505.06698)

	Zongqi Wang, Tianle Gu, Chen Gong, Xin Tian, Siqi Bao, Yujiu Yang

+ [Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free](https://arxiv.org//abs/2505.06708)

	Zihan Qiu, Zekun Wang, Bo Zheng, Zeyu Huang, Kaiyue Wen, Songlin Yang, Rui Men, Le Yu, Fei Huang, Suozhi Huang, Dayiheng Liu, Jingren Zhou, Junyang Lin

+ [Improving Block-Wise LLM Quantization by 4-bit Block-Wise Optimal Float (BOF4): Analysis and Variations](https://arxiv.org//abs/2505.06653)

	Patrick Blumenberg, Thomas Graave, Tim Fingscheidt

+ [Probing In-Context Learning: Impact of Task Complexity and Model Architecture on Generalization and Efficiency](https://arxiv.org//abs/2505.06475)

	Binwen Liu, Peiyu Xu, Quan Yuan, Yihong Chen

+ [QoS-Efficient Serving of Multiple Mixture-of-Expert LLMs Using Partial Runtime Reconfiguration](https://arxiv.org//abs/2505.06481)

	HamidReza Imani, Jiaxin Peng, Peiman Mohseni, Abdolah Amirany, Tarek El-Ghazawi

+ [RuleGenie: SIEM Detection Rule Set Optimization](https://arxiv.org//abs/2505.06701)

	Akansha Shukla, Parth Atulbhai Gandhi, Yuval Elovici, Asaf Shabtai

+ [POISONCRAFT: Practical Poisoning of Retrieval-Augmented Generation for Large Language Models](https://arxiv.org//abs/2505.06579)

	Yangguang Shao, Xinjie Lin, Haozheng Luo, Chengshang Hou, Gang Xiong, Jiahao Yu, Junzheng Shi

+ [Practical Reasoning Interruption Attacks on Reasoning Large Language Models](https://arxiv.org//abs/2505.06643)

	Yu Cui, Cong Zuo

+ [I Know What You Said: Unveiling Hardware Cache Side-Channels in Local Large Language Model Inference](https://arxiv.org//abs/2505.06738)

	Zibo Gao, Junjie Hu, Feng Guo, Yixin Zhang, Yinglong Han, Siyuan Liu, Haiyang Li, Zhiqiang Lv

+ [OMGM: Orchestrate Multiple Granularities and Modalities for Efficient Multimodal Retrieval](https://arxiv.org//abs/2505.07879)

	Wei Yang, Jingjing Fu, Rui Wang, Jinyu Wang, Lei Song, Jiang Bian

+ [Recovering Event Probabilities from Large Language Model Embeddings via Axiomatic Constraints](https://arxiv.org//abs/2505.07883)

	Jian-Qiao Zhu, Haijiang Yan, Thomas L. Griffiths

+ [Multi-modal Synthetic Data Training and Model Collapse: Insights from VLMs and Diffusion Models](https://arxiv.org//abs/2505.08803)

	Zizhao Hu, Mohammad Rostami, Jesse Thomason

+ [PRUNE: A Patching Based Repair Framework for Certifiable Unlearning of Neural Networks](https://arxiv.org//abs/2505.06520)

	Xuran Li, Jingyi Wang, Xiaohan Yuan, Peixin Zhang, Zhan Qin, Zhibo Wang, Kui Ren

+ [Prompt Engineering: How Prompt Vocabulary affects Domain Knowledge](https://arxiv.org//abs/2505.17037)

	Dimitri Schreiter

# 2025-05-09
+ [APOLLO: Automated LLM and Lean Collaboration for Advanced Formal Reasoning](https://arxiv.org//abs/2505.05758)

	Azim Ospanov, Roozbeh Yousefzadeh

+ [ArtRAG: Retrieval-Augmented Generation with Structured Context for Visual Art Understanding](https://arxiv.org//abs/2505.06020)

	Shuai Wang, Ivona Najdenkoska, Hongyi Zhu, Stevan Rudinac, Monika Kackovic, Nachoem Wijnberg, Marcel Worring

+ [Assessing Robustness to Spurious Correlations in Post-Training Language Models](https://arxiv.org//abs/2505.05704)

	Julia Shuieh, Prasann Singhal, Apaar Shanker, John Heyer, George Pu, Samuel Denton

+ [Multi-Agent Systems for Robotic Autonomy with LLMs](https://arxiv.org//abs/2505.05762)

	Junhong Chen, Ziqi Yang, Haoyuan G Xu, Dandan Zhang, George Mylonas

+ [AgentXploit: End-to-End Redteaming of Black-Box AI Agents](https://arxiv.org//abs/2505.05849)

	Zhun Wang, Vincent Siu, Zhe Ye, Tianneng Shi, Yuzhou Nie, Xuandong Zhao, Chenguang Wang, Wenbo Guo, Dawn Song

+ [Elastic Weight Consolidation for Full-Parameter Continual Pre-Training of Gemma2](https://arxiv.org//abs/2505.05946)

	Vytenis Šliogeris, Povilas Daniušis, Artūras Nakvosas

+ [A Scaling Law for Token Efficiency in LLM Fine-Tuning Under Fixed Compute Budgets](https://arxiv.org//abs/2505.06150)

	Ryan Lagasse, Aidan Kiernans, Avijit Ghosh, Shiri Dori-Hacohen

+ [Sparse Attention Remapping with Clustering for Efficient LLM Decoding on PIM](https://arxiv.org//abs/2505.05772)

	Zehao Fan, Garrett Gagnon, Zhenyu Liu, Liu Liu

+ [NeoQA: Evidence-based Question Answering with Generated News Events](https://arxiv.org//abs/2505.05949)

	Max Glockner, Xiang Jiang, Leonardo F. R. Ribeiro, Iryna Gurevych, Markus Dreyer

+ [Towards Developmentally Plausible Rewards: Communicative Success as a Learning Signal for Interactive Language Models](https://arxiv.org//abs/2505.05970)

	Lennart Stöpler, Rufat Asadli, Mitja Nikolaus, Ryan Cotterell, Alex Warstadt

+ [Unilogit: Robust Machine Unlearning for LLMs Using Uniform-Target Self-Distillation](https://arxiv.org//abs/2505.06027)

	Stefan Vasilev, Christian Herold, Baohao Liao, Seyyed Hadi Hashemi, Shahram Khadivi, Christof Monz

+ [Healthy LLMs? Benchmarking LLM Knowledge of UK Government Public Health Information](https://arxiv.org//abs/2505.06046)

	Joshua Harris, Fan Grayson, Felix Feldman, Timothy Laurence, Toby Nonnenmacher, Oliver Higgins, Leo Loman, Selina Patel, Thomas Finnie, Samuel Collins, Michael Borowitz

+ [LLMs Get Lost In Multi-Turn Conversation](https://arxiv.org//abs/2505.06120)

	Philippe Laban, Hiroaki Hayashi, Yingbo Zhou, Jennifer Neville

+ [Can Prompting LLMs Unlock Hate Speech Detection across Languages? A Zero-shot and Few-shot Study](https://arxiv.org//abs/2505.06149)

	Faeze Ghorbanpour, Daryna Dementieva, Alexander Fraser

+ [Multimodal Integrated Knowledge Transfer to Large Language Models through Preference Optimization with Biomedical Applications](https://arxiv.org//abs/2505.05736)

	Da Wu, Zhanliang Wang, Quan Nguyen, Zhuoran Xu, Kai Wang

+ [Harnessing LLMs Explanations to Boost Surrogate Models in Tabular Data Classification](https://arxiv.org//abs/2505.05744)

	Ruxue Shi, Hengrui Gu, Xu Shen, Xin Wang

+ [Short-circuiting Shortcuts: Mechanistic Investigation of Shortcuts in Text Classification](https://arxiv.org//abs/2505.06032)

	Leon Eshuijs, Shihan Wang, Antske Fokkens

+ [FloE: On-the-Fly MoE Inference](https://arxiv.org//abs/2505.05950)

	Yuxin Zhou, Zheng Li, Jun Zhang, Jue Wang, Yiping Wang, Zhongle Xie, Ke Chen, Lidan Shou

+ [Understanding Stragglers in Large Model Training Using What-if Analysis](https://arxiv.org//abs/2505.05713)

	Jinkun Lin, Ziheng Jiang, Zuquan Song, Sida Zhao, Menghan Yu, Zhanghan Wang, Chenyuan Wang, Zuocheng Shi, Xiang Shi, Wei Jia, Zherui Liu, Shuguang Wang, Haibin Lin, Xiu Liu, Aurojit Panda, Jinyang Li

+ [CAPE: Context-Aware Prompt Perturbation Mechanism with Differential Privacy](https://arxiv.org//abs/2505.05922)

	Haoqi Wu, Wei Dai, Li Wang, Qiang Yan

+ [LLM-Text Watermarking based on Lagrange Interpolation](https://arxiv.org//abs/2505.05712)

	Jarosław Janas, Paweł Morawiecki, Josef Pieprzyk

+ [A Grounded Memory System For Smart Personal Assistants](https://arxiv.org//abs/2505.06328)

	Felix Ocker, Jörg Deigmöller, Pavel Smirnov, Julian Eggert

+ [Reliable Collaborative Conversational Agent System Based on LLMs and Answer Set Programming](https://arxiv.org//abs/2505.06438)

	Yankai Zeng, Gopal Gupta

+ [KCluster: An LLM-based Clustering Approach to Knowledge Component Discovery](https://arxiv.org//abs/2505.06469)

	Yumou Wei, Paulo Carvalho, John Stamper

+ [Learn to Think: Bootstrapping LLM Reasoning Capability Through Graph Learning](https://arxiv.org//abs/2505.06321)

	Hang Gao, Chenhao Zhang, Tie Wang, Junsuo Zhao, Fengge Wu, Changwen Zheng, Huaping Liu

+ [Document Attribution: Examining Citation Relationships using Large Language Models](https://arxiv.org//abs/2505.06324)

	Vipula Rawte, Ryan A. Rossi, Franck Dernoncourt, Nedim Lipka

+ [Prompting Large Language Models for Training-Free Non-Intrusive Load Monitoring](https://arxiv.org//abs/2505.06330)

	Junyu Xue, Xudong Wang, Xiaoling He, Shicheng Liu, Yi Wang, Guoming Tang

+ [Towards AI-Driven Human-Machine Co-Teaming for Adaptive and Agile Cyber Security Operation Centers](https://arxiv.org//abs/2505.06394)

	Massimiliano Albanese, Xinming Ou, Kevin Lybarger, Daniel Lende, Dmitry Goldgof

+ [Engineering Risk-Aware, Security-by-Design Frameworks for Assurance of Large-Scale Autonomous AI Models](https://arxiv.org//abs/2505.06409)

	Krti Tallam

+ [Natural Reflection Backdoor Attack on Vision Language Model for Autonomous Driving](https://arxiv.org//abs/2505.06413)

	Ming Liu, Siyuan Liang, Koushik Howlader, Liwen Wang, Dacheng Tao, Wensheng Zhang

+ [ScaleMCP: Dynamic and Auto-Synchronizing Model Context Protocol Tools for LLM Agents](https://arxiv.org//abs/2505.06416)

	Elias Lumer, Anmol Gulati, Vamse Kumar Subbiah, Pradeep Honaganahalli Basavaraju, James A. Burke

+ [Is your multimodal large language model a good science tutor?](https://arxiv.org//abs/2505.06418)

	Ming Liu, Liwen Wang, Wensheng Zhang

+ [Efficient Fairness Testing in Large Language Models: Prioritizing Metamorphic Relations for Bias Detection](https://arxiv.org//abs/2505.07870)

	Suavis Giramata, Madhusudan Srinivasan, Venkat Naidu Gudivada, Upulee Kanewala

+ [Insertion Language Models: Sequence Generation with Arbitrary-Position Insertions](https://arxiv.org//abs/2505.05755)

	Dhruvesh Patel, Aishwarya Sahoo, Avinash Amballa, Tahira Naseem, Tim G. J. Rudner, Andrew McCallum

+ [The Spotlight Resonance Method: Resolving the Alignment of Embedded Activations](https://arxiv.org//abs/2505.13471)

	George Bird

# 2025-05-08
+ [Enigme: Generative Text Puzzles for Evaluating Reasoning in Language Models](https://arxiv.org//abs/2505.04914)

	John Hawkins

+ [Belief Filtering for Epistemic Control in Linguistic State Space](https://arxiv.org//abs/2505.04927)

	Sebastian Dumbrava

+ [A Reputation System for Large Language Model-based Multi-agent Systems to Avoid the Tragedy of the Commons](https://arxiv.org//abs/2505.05029)

	Siyue Ren, Wanli Fu, Xinkun Zou, Chen Shen, Yi Cai, Chen Chu, Zhen Wang, Shuyue Hu

+ [MARK: Memory Augmented Refinement of Knowledge](https://arxiv.org//abs/2505.05177)

	Anish Ganguli, Prabal Deb, Debleena Banerjee

+ [ConCISE: Confidence-guided Compression in Step-by-step Efficient Reasoning](https://arxiv.org//abs/2505.04881)

	Ziqing Qiao, Yongheng Deng, Jiali Zeng, Dong Wang, Lai Wei, Fandong Meng, Jie Zhou, Ju Ren, Yaoxue Zhang

+ [Chain-of-Thought Tokens are Computer Program Variables](https://arxiv.org//abs/2505.04955)

	Fangwei Zhu, Peiyi Wang, Zhifang Sui

+ [Rethinking Invariance in In-context Learning](https://arxiv.org//abs/2505.04994)

	Lizhe Fang, Yifei Wang, Khashayar Gatmiry, Lei Fang, Yisen Wang

+ [Understanding In-context Learning of Addition via Activation Subspaces](https://arxiv.org//abs/2505.05145)

	Xinyan Hu, Kayo Yin, Michael I. Jordan, Jacob Steinhardt, Lijie Chen

+ [Revealing Weaknesses in Text Watermarking Through Self-Information Rewrite Attacks](https://arxiv.org//abs/2505.05190)

	Yixin Cheng, Hongcheng Guo, Yangming Li, Leonid Sigal

+ [Software Development Life Cycle Perspective: A Survey of Benchmarks for CodeLLMs and Agents](https://arxiv.org//abs/2505.05283)

	Kaixin Wang, Tianlin Li, Xiaoyu Zhang, Chong Wang, Weisong Sun, Yang Liu, Bin Shi

+ [Scalable Chain of Thoughts via Elastic Reasoning](https://arxiv.org//abs/2505.05315)

	Yuhui Xu, Hanze Dong, Lei Wang, Doyen Sahoo, Junnan Li, Caiming Xiong

+ [Crosslingual Reasoning through Test-Time Scaling](https://arxiv.org//abs/2505.05408)

	Zheng-Xin Yong, M. Farid Adilazuarda, Jonibek Mansurov, Ruochen Zhang, Niklas Muennighoff, Carsten Eickhoff, Genta Indra Winata, Julia Kreutzer, Stephen H. Bach, Alham Fikri Aji

+ [Reasoning Models Don't Always Say What They Think](https://arxiv.org//abs/2505.05410)

	Yanda Chen, Joe Benton, Ansh Radhakrishnan, Jonathan Uesato, Carson Denison, John Schulman, Arushi Somani, Peter Hase, Misha Wagner, Fabien Roger, Vlad Mikulik, Samuel R. Bowman, Jan Leike, Jared Kaplan, Ethan Perez

+ [ComPO: Preference Alignment via Comparison Oracles](https://arxiv.org//abs/2505.05465)

	Peter Chen, Xi Chen, Wotao Yin, Tianyi Lin

+ [StreamBridge: Turning Your Offline Video Large Language Model into a Proactive Streaming Assistant](https://arxiv.org//abs/2505.05467)

	Haibo Wang, Bo Feng, Zhengfeng Lai, Mingze Xu, Shiyu Li, Weifeng Ge, Afshin Dehghan, Meng Cao, Ping Huang

+ [Latent Preference Coding: Aligning Large Language Models via Discrete Latent Codes](https://arxiv.org//abs/2505.04993)

	Zhuocheng Gong, Jian Guan, Wei Wu, Huishuai Zhang, Dongyan Zhao

+ [The Pitfalls of Growing Group Complexity: LLMs and Social Choice-Based Aggregation for Group Recommendations](https://arxiv.org//abs/2505.05016)

	Cedric Waterschoot, Nava Tintarev, Francesco Barile

+ [Scalable Multi-Stage Influence Function for Large Language Models via Eigenvalue-Corrected Kronecker-Factored Parameterization](https://arxiv.org//abs/2505.05017)

	Yuntai Bao, Xuhong Zhang, Tianyu Du, Xinkui Zhao, Jiang Zong, Hao Peng, Jianwei Yin

+ [Reliably Bounding False Positives: A Zero-Shot Machine-Generated Text Detection Framework via Multiscaled Conformal Prediction](https://arxiv.org//abs/2505.05084)

	Xiaowei Zhu, Yubing Ren, Yanan Cao, Xixun Lin, Fang Fang, Yangxi Li

+ [Unveiling Language-Specific Features in Large Language Models via Sparse Autoencoders](https://arxiv.org//abs/2505.05111)

	Boyi Deng, Yu Wan, Yidan Zhang, Baosong Yang, Fuli Feng

+ [QualBench: Benchmarking Chinese LLMs with Localized Professional Qualifications for Vertical Domain Evaluation](https://arxiv.org//abs/2505.05225)

	Mengze Hong, Wailing Ng, Di Jiang, Chen Jason Zhang

+ [Toward Reasonable Parrots: Why Large Language Models Should Argue with Us by Design](https://arxiv.org//abs/2505.05298)

	Elena Musi, Nadin Kokciyan, Khalid Al-Khatib, Davide Ceolin, Emmanuelle Dietz, Klara Gutekunst, Annette Hautli-Janisz, Cristian Manuel Santibañez Yañez, Jodi Schneider, Jonas Scholz, Cor Steging, Jacky Visser, Henning Wachsmuth

+ [ICon: In-Context Contribution for Automatic Data Selection](https://arxiv.org//abs/2505.05327)

	Yixin Yang, Qingxiu Dong, Linli Yao, Fangwei Zhu, Zhifang Sui

+ [Frame In, Frame Out: Do LLMs Generate More Biased News Headlines than Humans?](https://arxiv.org//abs/2505.05406)

	Valeria Pastorino, Nafise Sadat Moosavi

+ [Ultra-FineWeb: Efficient Data Filtering and Verification for High-Quality LLM Training Data](https://arxiv.org//abs/2505.05427)

	Yudong Wang, Zixuan Fu, Jie Cai, Peijun Tang, Hongya Lyu, Yewei Fang, Zhi Zheng, Jie Zhou, Guoyang Zeng, Chaojun Xiao, Xu Han, Zhiyuan Liu

+ [clem:todd: A Framework for the Systematic Benchmarking of LLM-Based Task-Oriented Dialogue System Realisations](https://arxiv.org//abs/2505.05445)

	Chalamalasetti Kranti, Sherzod Hakimov, David Schlangen

+ [Bring Reason to Vision: Understanding Perception and Reasoning through Model Merging](https://arxiv.org//abs/2505.05464)

	Shiqi Chen, Jinghan Zhang, Tongyao Zhu, Wei Liu, Siyang Gao, Miao Xiong, Manling Li, Junxian He

+ [Perception, Reason, Think, and Plan: A Survey on Large Multimodal Reasoning Models](https://arxiv.org//abs/2505.04921)

	Yunxin Li, Zhenyu Liu, Zitao Li, Xuanyu Zhang, Zhenran Xu, Xinyu Chen, Haoyuan Shi, Shenyuan Jiang, Xintong Wang, Jifang Wang, Shouzheng Huang, Xinping Zhao, Borui Jiang, Lanqing Hong, Longyue Wang, Zhuotao Tian, Baoxing Huai, Wenhan Luo, Weihua Luo, Zheng Zhang, Baotian Hu, Min Zhang

+ [Prompt-Based LLMs for Position Bias-Aware Reranking in Personalized Recommendations](https://arxiv.org//abs/2505.04948)

	Md Aminul Islam, Ahmed Sayeed Faruk

+ [WaterDrum: Watermarking for Data-centric Unlearning Metric](https://arxiv.org//abs/2505.05064)

	Xinyang Lu, Xinyuan Niu, Gregory Kang Ruey Lau, Bui Thi Cam Nhung, Rachael Hwee Ling Sim, Fanyu Wen, Chuan-Sheng Foo, See-Kiong Ng, Bryan Kian Hsiang Low

+ [FedTDP: A Privacy-Preserving and Unified Framework for Trajectory Data Preparation via Federated Learning](https://arxiv.org//abs/2505.05155)

	Zhihao Zeng, Ziquan Fang, Wei Shao, Lu Chen, Yunjun Gao

+ [Latte: Transfering LLMs` Latent-level Knowledge for Few-shot Tabular Learning](https://arxiv.org//abs/2505.05237)

	Ruxue Shi, Hengrui Gu, Hangting Ye, Yiwei Dai, Xu Shen, Xin Wang

+ [A Weighted Byzantine Fault Tolerance Consensus Driven Trusted Multiple Large Language Models Network](https://arxiv.org//abs/2505.05103)

	Haoxiang Luo, Gang Sun, Yinqiu Liu, Dongcheng Zhao, Dusit Niyato, Hongfang Yu, Schahram Dustdar

+ [Safety by Measurement: A Systematic Literature Review of AI Safety Evaluation Methods](https://arxiv.org//abs/2505.05541)

	Markov Grey, Charbel-Raphaël Segerie

+ [HiBayES: A Hierarchical Bayesian Modeling Framework for AI Evaluation Statistics](https://arxiv.org//abs/2505.05602)

	Lennart Luettgau, Harry Coppock, Magda Dubois, Christopher Summerfield, Cozmin Ududec

+ [CityNavAgent: Aerial Vision-and-Language Navigation with Hierarchical Semantic Planning and Global Memory](https://arxiv.org//abs/2505.05622)

	Weichen Zhang, Chen Gao, Shiquan Yu, Ruiying Peng, Baining Zhao, Qian Zhang, Jinqiang Cui, Xinlei Chen, Yong Li

+ [Looking Beyond Language Priors: Enhancing Visual Comprehension and Attention in Multimodal Models](https://arxiv.org//abs/2505.05626)

	Aarti Ghatkesar, Uddeshya Upadhyay, Ganesh Venkatesh

+ [Adaptive Stress Testing Black-Box LLM Planners](https://arxiv.org//abs/2505.05665)

	Neeloy Chakraborty, John Pohovey, Melkior Ornik, Katherine Driggs-Campbell

+ [Lost in OCR Translation? Vision-Based Approaches to Robust Document Retrieval](https://arxiv.org//abs/2505.05666)

	Alexander Most, Joseph Winjum, Ayan Biswas, Shawn Jones, Nishath Rajiv Ranasinghe, Dan O'Malley, Manish Bhattarai

+ [EcoAgent: An Efficient Edge-Cloud Collaborative Multi-Agent Framework for Mobile Automation](https://arxiv.org//abs/2505.05440)

	Biao Yi, Xavier Hu, Yurun Chen, Shengyu Zhang, Hongxia Yang, Fan Wu, Fei Wu

+ [KG-HTC: Integrating Knowledge Graphs into LLMs for Effective Zero-shot Hierarchical Text Classification](https://arxiv.org//abs/2505.05583)

	Qianbo Zang, Christophe Zgrzendek, Igor Tchappi, Afshin Khadangi, Johannes Sedlmeir

+ [Privacy-Preserving Transformers: SwiftKey's Differential Privacy Implementation](https://arxiv.org//abs/2505.05648)

	Abdelrahman Abouelenin, Mohamed Abdelrehim, Raffy Fahim, Amr Hendy, Mohamed Afify

+ [PRIMG : Efficient LLM-driven Test Generation Using Mutant Prioritization](https://arxiv.org//abs/2505.05584)

	Mohamed Salah Bouafif, Mohammad Hamdaqa, Edward Zulkoski

+ [Enhancing Large Language Models with Faster Code Preprocessing for Vulnerability Detection](https://arxiv.org//abs/2505.05600)

	José Gonçalves, Miguel Silva, Eva Maia, Isabel Praça

+ [LiteLMGuard: Seamless and Lightweight On-Device Prompt Filtering for Safeguarding Small Language Models against Quantization-induced Risks and Vulnerabilities](https://arxiv.org//abs/2505.05619)

	Kalyan Nakka, Jimmy Dani, Ausmit Mondal, Nitesh Saxena

+ [User Behavior Analysis in Privacy Protection with Large Language Models: A Study on Privacy Preferences with Limited Data](https://arxiv.org//abs/2505.06305)

	Haowei Yang, Qingyi Lu, Yang Wang, Sibei Liu, Jiayun Zheng, Ao Xiang

+ [Large Language Model-driven Security Assistant for Internet of Things via Chain-of-Thought](https://arxiv.org//abs/2505.06307)

	Mingfei Zeng, Ming Xie, Xixi Zheng, Chunhai Li, Chuan Zhang, Liehuang Zhu

+ [Defending against Indirect Prompt Injection by Instruction Detection](https://arxiv.org//abs/2505.06311)

	Tongyu Wen, Chenglong Wang, Xiyuan Yang, Haoyu Tang, Yueqi Xie, Lingjuan Lyu, Zhicheng Dou, Fangzhao Wu

+ [AI Approaches to Qualitative and Quantitative News Analytics on NATO Unity](https://arxiv.org//abs/2505.06313)

	Bohdan M. Pavlyshenko

+ [Threat Modeling for AI: The Case for an Asset-Centric Approach](https://arxiv.org//abs/2505.06315)

	Jose Sanchez Vicarte, Marcin Spoczynski, Mostafa Elsaid

+ [RAP-SM: Robust Adversarial Prompt via Shadow Models for Copyright Verification of Large Language Models](https://arxiv.org//abs/2505.06304)

	Zhenhua Xu, Zhebo Wang, Maike Li, Wenpeng Xing, Chunqiang Hu, Chen Zhi, Meng Han

+ [Unpacking Robustness in Inflectional Languages: Adversarial Evaluation and Mechanistic Insights](https://arxiv.org//abs/2505.07856)

	Paweł Walkowiak, Marek Klonowski, Marcin Oleksy, Arkadiusz Janz

+ [Scaling Laws for Speculative Decoding](https://arxiv.org//abs/2505.07858)

	Siyuan Yan, Mo Zhu, Guo-qing Jiang, Jianfei Wang, Jiaxing Chen, Wentai Zhang, Xiang Liao, Xiao Cui, Chen Zhang, Zhuoran Song, Ran Zhu

+ [Scalable LLM Math Reasoning Acceleration with Low-rank Distillation](https://arxiv.org//abs/2505.07861)

	Harry Dong, Bilge Acun, Beidi Chen, Yuejie Chi

+ [Product of Experts with LLMs: Boosting Performance on ARC Is a Matter of Perspective](https://arxiv.org//abs/2505.07859)

	Daniel Franzen, Jan Disselhoff, David Hartmann

# 2025-05-07
+ [Advancing and Benchmarking Personalized Tool Invocation for LLMs](https://arxiv.org//abs/2505.04072)

	Xu Huang, Yuefeng Huang, Weiwen Liu, Xingshan Zeng, Yasheng Wang, Ruiming Tang, Hong Xie, Defu Lian

+ [LLM-e Guess: Can LLMs Capabilities Advance Without Hardware Progress?](https://arxiv.org//abs/2505.04075)

	Teddy Foley, Spencer Guo, Henry Josephson, Anqi Qu, Jack Sanderson

+ [LLMs' Suitability for Network Security: A Case Study of STRIDE Threat Modeling](https://arxiv.org//abs/2505.04101)

	AbdulAziz AbdulGhaffar, Ashraf Matrawy

+ [Unmasking the Canvas: A Dynamic Benchmark for Image Generation Jailbreaking and LLM Content Safety](https://arxiv.org//abs/2505.04146)

	Variath Madhupal Gautham Nair, Vishal Varma Dantuluri

+ [On-Device LLM for Context-Aware Wi-Fi Roaming](https://arxiv.org//abs/2505.04174)

	Ju-Hyung Lee, Yanqing Lu

+ [Facilitating Trustworthy Human-Agent Collaboration in LLM-based Multi-Agent System oriented Software Engineering](https://arxiv.org//abs/2505.04251)

	Krishna Ronanki

+ [Steerable Chatbots: Personalizing LLMs with Preference-Based Activation Steering](https://arxiv.org//abs/2505.04260)

	Jessica Y. Bo, Tianyu Xu, Ishan Chatterjee, Katrina Passarella-Ward, Achin Kulshrestha, D Shin

+ [Weaponizing Language Models for Cybersecurity Offensive Operations: Automating Vulnerability Assessment Report Validation; A Review Paper](https://arxiv.org//abs/2505.04265)

	Abdulrahman S Almuhaidib, Azlan Mohd Zain, Zalmiyah Zakaria, Izyan Izzati Kamsani, Abdulaziz S Almuhaidib

+ [The Aloe Family Recipe for Open and Specialized Healthcare LLMs](https://arxiv.org//abs/2505.04388)

	Dario Garcia-Gasulla, Jordi Bayarri-Planas, Ashwin Kumar Gururajan, Enrique Lopez-Cuena, Adrian Tormos, Daniel Hinjos, Pablo Bernabeu-Perez, Anna Arias-Duart, Pablo Agustin Martin-Torres, Marta Gonzalez-Mallo, Sergio Alvarez-Napagao, Eduard Ayguadé-Parra, Ulises Cortés

+ [OBLIVIATE: Robust and Practical Machine Unlearning for Large Language Models](https://arxiv.org//abs/2505.04416)

	Xiaoyu Xu, Minxin Du, Qingqing Ye, Haibo Hu

+ [Fight Fire with Fire: Defending Against Malicious RL Fine-Tuning via Reward Neutralization](https://arxiv.org//abs/2505.04578)

	Wenjun Cao

+ [EchoInk-R1: Exploring Audio-Visual Reasoning in Multimodal LLMs via Reinforcement Learning](https://arxiv.org//abs/2505.04623)

	Zhenghao Xing, Xiaowei Hu, Chi-Wing Fu, Wenhai Wang, Jifeng Dai, Pheng-Ann Heng

+ [Enhancing Granular Sentiment Classification with Chain-of-Thought Prompting in Large Language Models](https://arxiv.org//abs/2505.04135)

	Vihaan Miriyala, Smrithi Bukkapatnam, Lavanya Prahallad

+ [LLM-Independent Adaptive RAG: Let the Question Speak for Itself](https://arxiv.org//abs/2505.04253)

	Maria Marina, Nikolay Ivanov, Sergey Pletenev, Mikhail Salnikov, Daria Galimzianova, Nikita Krayko, Vasily Konovalov, Alexander Panchenko, Viktor Moskvoretskii

+ [Large Means Left: Political Bias in Large Language Models Increases with Their Number of Parameters](https://arxiv.org//abs/2505.04393)

	David Exler, Mark Schutera, Markus Reischl, Luca Rettenberger

+ [Pangu Ultra MoE: How to Train Your Big MoE on Ascend NPUs](https://arxiv.org//abs/2505.04519)

	Yehui Tang, Yichun Yin, Yaoyuan Wang, Hang Zhou, Yu Pan, Wei Guo, Ziyang Zhang, Miao Rang, Fangcheng Liu, Naifu Zhang, Binghan Li, Yonghan Dong, Xiaojun Meng, Yasheng Wang, Dong Li, Yin Li, Dandan Tu, Can Chen, Youliang Yan, Fisher Yu, Ruiming Tang, Yunhe Wang, Botian Huang, Bo Wang, Boxiao Liu, Changzheng Zhang, Da Kuang, Fei Liu, Gang Huang, Jiansheng Wei, Jiarui Qin, Jie Ran, Jinpeng Li, Jun Zhao, Liang Dai, Lin Li, Liqun Deng, Peifeng Qin, Pengyuan Zeng, Qiang Gu, Shaohua Tang, Shengjun Cheng, Tao Gao, Tao Yu, Tianshu Li, Tianyu Bi, Wei He, Weikai Mao, Wenyong Huang, Wulong Liu, Xiabing Li, Xianzhi Yu, Xueyu Wu, Xu He, Yangkai Du, Yan Xu, Ye Tian, Yimeng Wu, Yongbing Huang, Yong Tian, Yong Zhu, Yue Li, Yufei Wang, Yuhang Gai, Yujun Li, Yu Luo, Yunsheng Ni, Yusen Sun, Zelin Chen, Zhe Liu, Zhicheng Liu, Zhipeng Tu, Zilin Ding, Zongyuan Zhan

+ [ZeroSearch: Incentivize the Search Capability of LLMs without Searching](https://arxiv.org//abs/2505.04588)

	Hao Sun, Zile Qiao, Jiayan Guo, Xuanbo Fan, Yingyan Hou, Yong Jiang, Pengjun Xie, Fei Huang, Yan Zhang

+ [Large Language Models are often politically extreme, usually ideologically inconsistent, and persuasive even in informational contexts](https://arxiv.org//abs/2505.04171)

	Nouar Aldahoul, Hazem Ibrahim, Matteo Varvello, Aaron Kaufman, Talal Rahwan, Yasir Zaki

+ [Benchmarking LLMs' Swarm intelligence](https://arxiv.org//abs/2505.04364)

	Kai Ruan, Mowen Huang, Ji-Rong Wen, Hao Sun

+ [Componential Prompt-Knowledge Alignment for Domain Incremental Learning](https://arxiv.org//abs/2505.04575)

	Kunlun Xu, Xu Zou, Gang Hua, Jiahuan Zhou

+ [Towards Effectively Leveraging Execution Traces for Program Repair with Code LLMs](https://arxiv.org//abs/2505.04441)

	Mirazul Haque, Petr Babkin, Farima Farmahinifarahani, Manuela Veloso

+ [Communication-Efficient Federated Fine-Tuning of Language Models via Dynamic Update Schedules](https://arxiv.org//abs/2505.04535)

	Michail Theologitis, Vasilis Samoladas, Antonios Deligiannakis

+ [AutoPatch: Multi-Agent Framework for Patching Real-World CVE Vulnerabilities](https://arxiv.org//abs/2505.04195)

	Minjae Seo, Wonwoo Choi, Myoungsung You, Seungwon Shin

+ [The Promise and Limits of LLMs in Constructing Proofs and Hints for Logic Problems in Intelligent Tutoring Systems](https://arxiv.org//abs/2505.04736)

	Sutapa Dey Tithi, Arun Kumar Ramesh, Clara DiMarco, Xiaoyi Tian, Nazia Alam, Kimia Fazeli, Tiffany Barnes

+ [Large Language Models are Autonomous Cyber Defenders](https://arxiv.org//abs/2505.04843)

	Sebastián R. Castro, Roberto Campbell, Nancy Lau, Octavio Villalobos, Jiaqi Duan, Alvaro A. Cardenas

+ [Personalized Risks and Regulatory Strategies of Large Language Models in Digital Advertising](https://arxiv.org//abs/2505.04665)

	Haoyang Feng, Yanjun Dai, Yuan Gao

+ [REVEAL: Multi-turn Evaluation of Image-Input Harms for Vision LLM](https://arxiv.org//abs/2505.04673)

	Madhur Jindal, Saurabh Deshpande

+ [QBD-RankedDataGen: Generating Custom Ranked Datasets for Improving Query-By-Document Search Using LLM-Reranking with Reduced Human Effort](https://arxiv.org//abs/2505.04732)

	Sriram Gopalakrishnan, Sunandita Patra

+ [When Bad Data Leads to Good Models](https://arxiv.org//abs/2505.04741)

	Kenneth Li, Yida Chen, Fernanda Viégas, Martin Wattenberg

+ [A Proposal for Evaluating the Operational Risk for ChatBots based on Large Language Models](https://arxiv.org//abs/2505.04784)

	Pedro Pinacho-Davidson, Fernando Gutierrez, Pablo Zapata, Rodolfo Vergara, Pablo Aqueveque

+ [Putting the Value Back in RL: Better Test-Time Scaling by Unifying LLM Reasoners With Verifiers](https://arxiv.org//abs/2505.04842)

	Kusha Sareen, Morgane M Moss, Alessandro Sordoni, Rishabh Agarwal, Arian Hosseini

+ [Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards](https://arxiv.org//abs/2505.04847)

	Manveer Singh Tamber, Forrest Sheng Bao, Chenyu Xu, Ge Luo, Suleman Kazi, Minseok Bae, Miaoran Li, Ofer Mendelevitch, Renyi Qu, Jimmy Lin

+ [Fine-Tuning Large Language Models and Evaluating Retrieval Methods for Improved Question Answering on Building Codes](https://arxiv.org//abs/2505.04666)

	Mohammad Aqib, Mohd Hamza, Qipei Mei, Ying Hei Chui

+ [Reward-SQL: Boosting Text-to-SQL via Stepwise Reasoning and Process-Supervised Rewards](https://arxiv.org//abs/2505.04671)

	Yuxin Zhang, Meihao Fan, Ju Fan, Mingyang Yi, Yuyu Luo, Jian Tan, Guoliang Li

+ [SOAEsV2-7B/72B: Full-Pipeline Optimization for State-Owned Enterprise LLMs via Continual Pre-Training, Domain-Progressive SFT and Distillation-Enhanced Speculative Decoding](https://arxiv.org//abs/2505.04723)

	Jingyang Deng, Ran Chen, Jo-Ku Cheng, Jinwen Ma

+ [Osiris: A Lightweight Open-Source Hallucination Detection System](https://arxiv.org//abs/2505.04844)

	Alex Shan, John Bauer, Christopher D. Manning

+ [Red Teaming the Mind of the Machine: A Systematic Evaluation of Prompt Injection and Jailbreak Vulnerabilities in LLMs](https://arxiv.org//abs/2505.04806)

	Chetan Pathade

+ [HiPerRAG: High-Performance Retrieval Augmented Generation for Scientific Insights](https://arxiv.org//abs/2505.04846)

	Ozan Gokdemir, Carlo Siebenschuh, Alexander Brace, Azton Wells, Brian Hsu, Kyle Hippe, Priyanka V. Setty, Aswathy Ajith, J. Gregory Pauloski, Varuni Sastry, Sam Foreman, Huihuo Zheng, Heng Ma, Bharat Kale, Nicholas Chia, Thomas Gibbs, Michael E. Papka, Thomas Brettin, Francis J. Alexander, Anima Anandkumar, Ian Foster, Rick Stevens, Venkatram Vishwanath, Arvind Ramanathan

+ [Safeguard-by-Development: A Privacy-Enhanced Development Paradigm for Multi-Agent Collaboration Systems](https://arxiv.org//abs/2505.04799)

	Jian Cui, Zichuan Li, Luyi Xing, Xiaojing Liao

+ [Nature's Insight: A Novel Framework and Comprehensive Analysis of Agentic Reasoning Through the Lens of Neuroscience](https://arxiv.org//abs/2505.05515)

	Zinan Liu, Haoran Li, Jingyi Lu, Gaoyuan Ma, Xu Hong, Giovanni Iacca, Arvind Kumar, Shaojun Tang, Lin Wang

+ [DMRL: Data- and Model-aware Reward Learning for Data Extraction](https://arxiv.org//abs/2505.06284)

	Zhiqiang Wang, Ruoxi Cheng

+ [Winning at All Cost: A Small Environment for Eliciting Specification Gaming Behaviors in Large Language Models](https://arxiv.org//abs/2505.07846)

	Lars Malmqvist

+ [Joint Detection of Fraud and Concept Drift inOnline Conversations with LLM-Assisted Judgment](https://arxiv.org//abs/2505.07852)

	Ali Senol, Garima Agrawal, Huan Liu

+ [AgentSGEN: Multi-Agent LLM in the Loop for Semantic Collaboration and GENeration of Synthetic Data](https://arxiv.org//abs/2505.13466)

	Vu Dinh Xuan, Hao Vo, David Murphy, Hoang D. Nguyen

# 2025-05-06
+ [Holmes: Automated Fact Check with Large Language Models](https://arxiv.org//abs/2505.03135)

	Haoran Ou, Gelei Deng, Xingshuo Han, Jie Zhang, Xinlei He, Han Qiu, Shangwei Guo, Tianwei Zhang

+ [Patterns and Mechanisms of Contrastive Activation Engineering](https://arxiv.org//abs/2505.03189)

	Yixiong Hao, Ayush Panda, Stepan Shabalin, Sheikh Abdur Raheem Ali

+ [RAG-MCP: Mitigating Prompt Bloat in LLM Tool Selection via Retrieval-Augmented Generation](https://arxiv.org//abs/2505.03275)

	Tiantian Gan, Qiyao Sun

+ [Capability-Driven Skill Generation with LLMs: A RAG-Based Approach for Reusing Existing Libraries and Interfaces](https://arxiv.org//abs/2505.03295)

	Luis Miguel Vieira da Silva, Aljosha Köcher, Nicolas König, Felix Gehlhoff, Alexander Fay

+ [AI-Driven Scholarly Peer Review via Persistent Workflow Prompting, Meta-Prompting, and Meta-Reasoning](https://arxiv.org//abs/2505.03332)

	Evgeny Markhasin

+ [Procedural Memory Is Not All You Need: Bridging Cognitive Gaps in LLM-Based Agents](https://arxiv.org//abs/2505.03434)

	Schaun Wheeler, Olivier Jeunen

+ [The Steganographic Potentials of Language Models](https://arxiv.org//abs/2505.03439)

	Artem Karpov, Tinuade Adeleke, Seong Hah Cho, Natalia Perez-Campanero

+ [am-ELO: A Stable Framework for Arena-based LLM Evaluation](https://arxiv.org//abs/2505.03475)

	Zirui Liu, Jiatong Li, Yan Zhuang, Qi Liu, Shuanghong Shen, Jie Ouyang, Mingyue Cheng, Shijin Wang

+ [A Hashgraph-Inspired Consensus Mechanism for Reliable Multi-Model Reasoning](https://arxiv.org//abs/2505.03553)

	Kolawole E. Ogunsina, Morayo A. Ogunsina

+ [Assessing and Enhancing the Robustness of LLM-based Multi-Agent Systems Through Chaos Engineering](https://arxiv.org//abs/2505.03096)

	Joshua Owotogbe

+ [Soft Best-of-n Sampling for Model Alignment](https://arxiv.org//abs/2505.03156)

	Claudio Mayrink Verdun, Alex Oesterling, Himabindu Lakkaraju, Flavio P. Calmon

+ [A Trustworthy Multi-LLM Network: Challenges,Solutions, and A Use Case](https://arxiv.org//abs/2505.03196)

	Haoxiang Luo, Gang Sun, Yinqiu Liu, Dusit Niyato, Hongfang Yu, Mohammed Atiquzzaman, Schahram Dustdar

+ [Absolute Zero: Reinforced Self-play Reasoning with Zero Data](https://arxiv.org//abs/2505.03335)

	Andrew Zhao, Yiran Wu, Yang Yue, Tong Wu, Quentin Xu, Yang Yue, Matthieu Lin, Shenzhi Wang, Qingyun Wu, Zilong Zheng, Gao Huang

+ [SPAP: Structured Pruning via Alternating Optimization and Penalty Methods](https://arxiv.org//abs/2505.03373)

	Hanyu Hu, Xiaoming Yuan

+ [Automatic Calibration for Membership Inference Attack on Large Language Models](https://arxiv.org//abs/2505.03392)

	Saleh Zare Zade, Yao Qiang, Xiangyu Zhou, Hui Zhu, Mohammad Amin Roshani, Prashant Khanduri, Dongxiao Zhu

+ [Lightweight Clinical Decision Support System using QLoRA-Fine-Tuned LLMs and Retrieval-Augmented Generation](https://arxiv.org//abs/2505.03406)

	Mohammad Shoaib Ansari, Mohd Sohail Ali Khan, Shubham Revankar, Aditya Varma, Anil S. Mokhade

+ [An Analysis of Hyper-Parameter Optimization Methods for Retrieval Augmented Generation](https://arxiv.org//abs/2505.03452)

	Matan Orbach, Ohad Eytan, Benjamin Sznajder, Ariel Gera, Odellia Boni, Yoav Kantor, Gal Bloch, Omri Levy, Hadas Abraham, Nitzan Barzilay, Eyal Shnarch, Michael E. Factor, Shila Ofek-Koifman, Paula Ta-Shma, Assaf Toledo

+ [A new membership inference attack that spots memorization in generative and predictive models: Loss-Based with Reference Model algorithm (LBRM)](https://arxiv.org//abs/2505.03490)

	Faiz Taleb, Ivan Gazeau, Maryline Laurent

+ [LlamaFirewall: An open source guardrail system for building secure AI agents](https://arxiv.org//abs/2505.03574)

	Sahana Chennabasappa, Cyrus Nikolaidis, Daniel Song, David Molnar, Stephanie Ding, Shengye Wan, Spencer Whitman, Lauren Deason, Nicholas Doucette, Abraham Montilla, Alekhya Gampa, Beto de Paola, Dominik Gabi, James Crnkovich, Jean-Christophe Testud, Kat He, Rashnil Chaturvedi, Wu Zhou, Joshua Saxe

+ [ReGraP-LLaVA: Reasoning enabled Graph-based Personalized Large Language and Vision Assistant](https://arxiv.org//abs/2505.03654)

	Yifan Xiang, Zhenxi Zhang, Bin Li, Yixuan Weng, Shoujun Zhou, Yangfan He, Keqin Li

+ [Ψ-Arena: Interactive Assessment and Optimization of LLM-based Psychological Counselors with Tripartite Feedback](https://arxiv.org//abs/2505.03293)

	Shijing Zhu, Zhuang Chen, Guanqun Bi, Binghang Li, Yaxi Deng, Dazhen Wan, Libiao Peng, Xiyao Xiao, Rongsheng Zhang, Tangjie Lv, Zhipeng Hu, FangFang Li, Minlie Huang

+ [Recall with Reasoning: Chain-of-Thought Distillation for Mamba's Long-Context Memory and Extrapolation](https://arxiv.org//abs/2505.03320)

	Junyu Ma, Tianqing Fang, Zhisong Zhang, Hongming Zhang, Haitao Mi, Dong Yu

+ [Uncertainty-Aware Large Language Models for Explainable Disease Diagnosis](https://arxiv.org//abs/2505.03467)

	Shuang Zhou, Jiashuo Wang, Zidu Xu, Song Wang, David Brauer, Lindsay Welton, Jacob Cogan, Yuen-Hei Chung, Lei Tian, Zaifu Zhan, Yu Hou, Mingquan Lin, Genevieve B. Melton, Rui Zhang

+ [Long-Short Chain-of-Thought Mixture Supervised Fine-Tuning Eliciting Efficient Reasoning in Large Language Models](https://arxiv.org//abs/2505.03469)

	Bin Yu, Hang Yuan, Yuliang Wei, Bailing Wang, Weizhen Qi, Kai Chen

+ [Evaluation of LLMs on Long-tail Entity Linking in Historical Documents](https://arxiv.org//abs/2505.03473)

	Marta Boscariol, Luana Bulla, Lia Draetta, Beatrice Fiumanò, Emanuele Lenzi, Leonardo Piano

+ [Faster MoE LLM Inference for Extremely Large Models](https://arxiv.org//abs/2505.03531)

	Haoqi Yang, Luohe Shi, Qiwei Li, Zuchao Li, Ping Wang, Bo Du, Mengjia Shen, Hai Zhao

+ [Say It Another Way: A Framework for User-Grounded Paraphrasing](https://arxiv.org//abs/2505.03563)

	Cléa Chataigner, Rebecca Ma, Prakhar Ganesh, Afaf Taïk, Elliot Creager, Golnoosh Farnadi

+ [WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional Websites from Scratch](https://arxiv.org//abs/2505.03733)

	Zimu Lu, Yunqiao Yang, Houxing Ren, Haotian Hou, Han Xiao, Ke Wang, Weikang Shi, Aojun Zhou, Mingjie Zhan, Hongsheng Li

+ [BadLingual: A Novel Lingual-Backdoor Attack against Large Language Models](https://arxiv.org//abs/2505.03501)

	Zihan Wang, Hongwei Li, Rui Zhang, Wenbo Jiang, Kangjie Chen, Tianwei Zhang, Qingchuan Zhao, Guowen Xu

+ [VLM Q-Learning: Aligning Vision-Language Models for Interactive Decision-Making](https://arxiv.org//abs/2505.03181)

	Jake Grigsby, Yuke Zhu, Michael Ryoo, Juan Carlos Niebles

+ [DYSTIL: Dynamic Strategy Induction with Large Language Models for Reinforcement Learning](https://arxiv.org//abs/2505.03209)

	Borui Wang, Kathleen McKeown, Rex Ying

+ [Geospatial Mechanistic Interpretability of Large Language Models](https://arxiv.org//abs/2505.03368)

	Stef De Sabbata, Stefano Mizzaro, Kevin Roitero

+ [Knowledge Augmented Complex Problem Solving with Large Language Models: A Survey](https://arxiv.org//abs/2505.03418)

	Da Zheng, Lun Du, Junwei Su, Yuchen Tian, Yuqi Zhu, Jintian Zhang, Lanning Wei, Ningyu Zhang, Huajun Chen

+ [Uncovering the Limitations of Model Inversion Evaluation: Benchmarks and Connection to Type-I Adversarial Attacks](https://arxiv.org//abs/2505.03519)

	Sy-Tuyen Ho, Koh Jun Hao, Ngoc-Bao Nguyen, Alexander Binder, Ngai-Man Cheung

+ [Towards a standardized methodology and dataset for evaluating LLM-based digital forensic timeline analysis](https://arxiv.org//abs/2505.03100)

	Hudan Studiawan, Frank Breitinger, Mark Scanlon

+ [Towards Effective Identification of Attack Techniques in Cyber Threat Intelligence Reports using Large Language Models](https://arxiv.org//abs/2505.03147)

	Hoang Cuong Nguyen, Shahroz Tariq, Mohan Baruwal Chhetri, Bao Quoc Vo

+ [An LLM-based Self-Evolving Security Framework for 6G Space-Air-Ground Integrated Networks](https://arxiv.org//abs/2505.03161)

	Qi Qin, Xinye Cao, Guoshun Nan, Sihan Chen, Rushan Li, Li Su, Haitao Du, Qimei Cui, Pengxuan Mao, Xiaofeng Tao, Tony Q.S. Quek

+ [Bridging Expertise Gaps: The Role of LLMs in Human-AI Collaboration for Cybersecurity](https://arxiv.org//abs/2505.03179)

	Shahroz Tariq, Ronal Singh, Mohan Baruwal Chhetri, Surya Nepal, Cecile Paris

+ [A Chaos Driven Metric for Backdoor Attack Detection](https://arxiv.org//abs/2505.03208)

	Hema Karnam Surendrababu (1), Nithin Nagaraj (2) ((1) School of Conflict and Security Studies, National Institute of Advanced Studies, Indian Institute of Science Campus, Bengaluru (2) Complex Systems Programme, National Institute of Advanced Studies, Indian Institute of Science Campus, Bengaluru)

+ [Elevating Cyber Threat Intelligence against Disinformation Campaigns with LLM-based Concept Extraction and the FakeCTI Dataset](https://arxiv.org//abs/2505.03345)

	Domenico Cotroneo, Roberto Natella, Vittorio Orbinato

+ [Directed Greybox Fuzzing via Large Language Model](https://arxiv.org//abs/2505.03425)

	Hanxiang Xu, Yanjie Zhao, Haoyu Wang

+ [Frog Soup: Zero-Shot, In-Context, and Sample-Efficient Frogger Agents](https://arxiv.org//abs/2505.03947)

	Xiang Li, Yiyang Hao, Doug Fulop

+ [The Power of Stories: Narrative Priming Shapes How LLM Agents Collaborate and Compete](https://arxiv.org//abs/2505.03961)

	Gerrit Großmann, Larisa Ivanova, Sai Leela Poduru, Mohaddeseh Tabrizian, Islam Mesabah, David A. Selby, Sebastian J. Vollmer

+ [From Glue-Code to Protocols: A Critical Analysis of A2A and MCP Integration for Scalable Agent Systems](https://arxiv.org//abs/2505.03864)

	Qiaomu Li, Ying Xie

+ [MergeGuard: Efficient Thwarting of Trojan Attacks in Machine Learning Models](https://arxiv.org//abs/2505.04015)

	Soheil Zibakhsh Shabgahi, Yaman Jandali, Farinaz Koushanfar

+ [SLOT: Structuring the Output of Large Language Models](https://arxiv.org//abs/2505.04016)

	Darren Yow-Bang Wang, Zhengyuan Shen, Soumya Smruti Mishra, Zhichao Xu, Yifei Teng, Haibo Ding

+ [Prism: Unleashing GPU Sharing for Cost-Efficient Multi-LLM Serving](https://arxiv.org//abs/2505.04021)

	Shan Yu, Jiarong Xing, Yifan Qiao, Mingyuan Ma, Yangmin Li, Yang Wang, Shuo Yang, Zhiqiang Xie, Shiyi Cao, Ke Bao, Ion Stoica, Harry Xu, Ying Sheng

+ [A Reasoning-Focused Legal Retrieval Benchmark](https://arxiv.org//abs/2505.03970)

	Lucia Zheng, Neel Guha, Javokhir Arifov, Sarah Zhang, Michal Skreta, Christopher D. Manning, Peter Henderson, Daniel E. Ho

+ [Divide, Optimize, Merge: Fine-Grained LLM Agent Optimization at Scale](https://arxiv.org//abs/2505.03973)

	Jiale Liu, Yifan Zeng, Shaokun Zhang, Chi Zhang, Malte Højmark-Bertelsen, Marie Normann Gadeberg, Huazheng Wang, Qingyun Wu

+ [Quiet Feature Learning in Algorithmic Tasks](https://arxiv.org//abs/2505.03997)

	Prudhviraj Naidu, Zixian Wang, Leon Bergen, Ramamohan Paturi

+ [MARCO: A Multi-Agent System for Optimizing HPC Code Generation Using Large Language Models](https://arxiv.org//abs/2505.03906)

	Asif Rahman, Veljko Cvetkovic, Kathleen Reece, Aidan Walters, Yasir Hassan, Aneesh Tummeti, Bryan Torres, Denise Cooney, Margaret Ellis, Dimitrios S. Nikolopoulos

+ [FRAME: Feedback-Refined Agent Methodology for Enhancing Medical Research Insights](https://arxiv.org//abs/2505.04649)

	Chengzhang Yu, Yiming Zhang, Zhixin Liu, Zenghui Ding, Yining Sun, Zhanpeng Jin

+ [Scientific Hypothesis Generation and Validation: Methods, Datasets, and Future Directions](https://arxiv.org//abs/2505.04651)

	Adithya Kulkarni, Fatimah Alotaibi, Xinyue Zeng, Longfeng Wu, Tong Zeng, Barry Menglong Yao, Minqian Liu, Shuaicheng Zhang, Lifu Huang, Dawei Zhou

+ [A Comparative Analysis of Ethical and Safety Gaps in LLMs using Relative Danger Coefficient](https://arxiv.org//abs/2505.04654)

	Yehor Tereshchenko, Mika Hämäläinen

+ [A Sensitivity-Driven Expert Allocation Method in LoRA-MoE for Efficient Fine-Tuning](https://arxiv.org//abs/2505.06272)

	Junzhou Xu, Boyu Diao

+ [Policy-labeled Preference Learning: Is Preference Enough for RLHF?](https://arxiv.org//abs/2505.06273)

	Taehyun Cho, Seokhun Ju, Seungyub Han, Dohyeong Kim, Kyungjae Lee, Jungwoo Lee

+ [PARM: Multi-Objective Test-Time Alignment via Preference-Aware Autoregressive Reward Model](https://arxiv.org//abs/2505.06274)

	Baijiong Lin, Weisen Jiang, Yuancheng Xu, Hao Chen, Ying-Cong Chen

# 2025-05-05
+ [HyperTree Planning: Enhancing LLM Reasoning via Hierarchical Thinking](https://arxiv.org//abs/2505.02322)

	Runquan Gui, Zhihai Wang, Jie Wang, Chi Ma, Huiling Zhen, Mingxuan Yuan, Jianye Hao, Defu Lian, Enhong Chen, Feng Wu

+ [Recursive Decomposition with Dependencies for Generic Divide-and-Conquer Reasoning](https://arxiv.org//abs/2505.02576)

	Sergio Hernández-Gutiérrez, Minttu Alakuijala, Alexander V. Nikitin, Pekka Marttinen

+ [Agentic Neurodivergence as a Contingent Solution to the AI Alignment Problem](https://arxiv.org//abs/2505.02581)

	Alberto Hernández-Espinosa, Felipe S. Abrahão, Olaf Witkowski, Hector Zenil

+ [A Survey of Slow Thinking-based Reasoning LLMs using Reinforced Learning and Inference-time Scaling Law](https://arxiv.org//abs/2505.02665)

	Qianjun Pan, Wenkai Ji, Yuyang Ding, Junsong Li, Shilian Chen, Junyi Wang, Jie Zhou, Qin Chen, Min Zhang, Yulan Wu, Liang He

+ [Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play](https://arxiv.org//abs/2505.02707)

	Yemin Shi, Yu Shu, Siwei Dong, Guangyi Liu, Jaward Sesay, Jingwen Li, Zhiting Hu

+ [Technical Report: Evaluating Goal Drift in Language Model Agents](https://arxiv.org//abs/2505.02709)

	Rauno Arike, Elizabeth Donoway, Henning Bartsch, Marius Hobbhahn

+ [Enhancing LLMs' Clinical Reasoning with Real-World Data from a Nationwide Sepsis Registry](https://arxiv.org//abs/2505.02722)

	Junu Kim, Chaeeun Shim, Sungjin Park, Su Yeon Lee, Gee Young Suh, Chae-Man Lim, Seong Jin Choi, Song Mi Moon, Kyoung-Ho Song, Eu Suk Kim, Hong Bin Kim, Sejoong Kim, Chami Im, Dong-Wan Kang, Yong Soo Kim, Hee-Joon Bae, Sung Yoon Lim, Han-Gil Jeong, Edward Choi

+ [Knowing You Don't Know: Learning When to Continue Search in Multi-round RAG through Self-Practicing](https://arxiv.org//abs/2505.02811)

	Diji Yang, Linda Zeng, Jinmeng Rao, Yi Zhang

+ [AutoLibra: Agent Metric Induction from Open-Ended Feedback](https://arxiv.org//abs/2505.02820)

	Hao Zhu, Phil Cuvin, Xinkai Yu, Charlotte Ka Yee Yan, Jason Zhang, Diyi Yang

+ [Optimizing LLMs for Resource-Constrained Environments: A Survey of Model Compression Techniques](https://arxiv.org//abs/2505.02309)

	Sanjay Surendranath Girija, Shashank Kapoor, Lakshit Arora, Dipen Pradhan, Aman Raj, Ankit Shetgaonkar

+ [RM-R1: Reward Modeling as Reasoning](https://arxiv.org//abs/2505.02387)

	Xiusi Chen, Gaotang Li, Ziqi Wang, Bowen Jin, Cheng Qian, Yu Wang, Hongru Wang, Yu Zhang, Denghui Zhang, Tong Zhang, Hanghang Tong, Heng Ji

+ [Optimizing Chain-of-Thought Reasoners via Gradient Variance Minimization in Rejection Sampling and RL](https://arxiv.org//abs/2505.02391)

	Jiarui Yao, Yifan Hao, Hanning Zhang, Hanze Dong, Wei Xiong, Nan Jiang, Tong Zhang

+ [SEFE: Superficial and Essential Forgetting Eliminator for Multimodal Continual Instruction Tuning](https://arxiv.org//abs/2505.02486)

	Jinpeng Chen, Runmin Cong, Yuzhi Zhao, Hongzheng Yang, Guangneng Hu, Horace Ho Shing Ip, Sam Kwong

+ [Unveiling the Landscape of LLM Deployment in the Wild: An Empirical Study](https://arxiv.org//abs/2505.02502)

	Xinyi Hou, Jiahao Han, Yanjie Zhao, Haoyu Wang

+ [Large Language Model Partitioning for Low-Latency Inference at the Edge](https://arxiv.org//abs/2505.02533)

	Dimitrios Kafetzis, Ramin Khalili, Iordanis Koutsopoulos

+ [EMORL: Ensemble Multi-Objective Reinforcement Learning for Efficient and Flexible LLM Fine-Tuning](https://arxiv.org//abs/2505.02579)

	Lingxiao Kong (1), Cong Yang (2), Susanne Neufang (3), Oya Deniz Beyan (1,3), Zeyd Boukhers (1,3) ((1) Fraunhofer Institute for Applied Information Technology FIT, (2) Soochow University, (3) University Hospital of Cologne)

+ [LLaMA-Omni2: LLM-based Real-time Spoken Chatbot with Autoregressive Streaming Speech Synthesis](https://arxiv.org//abs/2505.02625)

	Qingkai Fang, Yan Zhou, Shoutao Guo, Shaolei Zhang, Yang Feng

+ [Knowledge Graphs for Enhancing Large Language Models in Entity Disambiguation](https://arxiv.org//abs/2505.02737)

	Pons Gerard, Bilalli Besim, Queralt Anna

+ [HSplitLoRA: A Heterogeneous Split Parameter-Efficient Fine-Tuning Framework for Large Language Models](https://arxiv.org//abs/2505.02795)

	Zheng Lin, Yuxin Zhang, Zhe Chen, Zihan Fang, Xianhao Chen, Praneeth Vepakomma, Wei Ni, Jun Luo, Yue Gao

+ [Generative Sign-description Prompts with Multi-positive Contrastive Learning for Sign Language Recognition](https://arxiv.org//abs/2505.02304)

	Siyu Liang, Yunan Li, Wentian Xin, Huizhou Chen, Xujie Liu, Kang Liu, Qiguang Miao

+ [Invoke Interfaces Only When Needed: Adaptive Invocation for Large Language Models in Question Answering](https://arxiv.org//abs/2505.02311)

	Jihao Zhao, Chunlai Zhou, Biao Qin

+ [SIMPLEMIX: Frustratingly Simple Mixing of Off- and On-policy Data in Language Model Preference Learning](https://arxiv.org//abs/2505.02363)

	Tianjian Li, Daniel Khashabi

+ [Colombian Waitresses y Jueces canadienses: Gender and Country Biases in Occupation Recommendations from LLMs](https://arxiv.org//abs/2505.02456)

	Elisa Forcada Rodríguez, Olatz Perez-de-Viñaspre, Jon Ander Campos, Dietrich Klakow, Vagrant Gautam

+ [A Survey on Progress in LLM Alignment from the Perspective of Reward Design](https://arxiv.org//abs/2505.02666)

	Miaomiao Ji, Yanqiu Wu, Zhibin Wu, Shoujin Wang, Jian Yang, Mark Dras, Usman Naseem

+ [Sailing AI by the Stars: A Survey of Learning from Rewards in Post-Training and Test-Time Scaling of Large Language Models](https://arxiv.org//abs/2505.02686)

	Xiaobao Wu

+ [ReplaceMe: Network Simplification via Layer Pruning and Linear Transformations](https://arxiv.org//abs/2505.02819)

	Dmitriy Shopkhoev, Ammar Ali, Magauiya Zhussip, Valentin Malykh, Stamatios Lefkimmiatis, Nikos Komodakis, Sergey Zagoruyko

+ [R1-Reward: Training Multimodal Reward Model Through Stable Reinforcement Learning](https://arxiv.org//abs/2505.02835)

	Yi-Fan Zhang, Xingyu Lu, Xiao Hu, Chaoyou Fu, Bin Wen, Tianke Zhang, Changyi Liu, Kaiyu Jiang, Kaibing Chen, Kaiyu Tang, Haojie Ding, Jiankang Chen, Fan Yang, Zhang Zhang, Tingting Gao, Liang Wang

+ [Scenethesis: A Language and Vision Agentic Framework for 3D Scene Generation](https://arxiv.org//abs/2505.02836)

	Lu Ling, Chen-Hsuan Lin, Tsung-Yi Lin, Yifan Ding, Yu Zeng, Yichen Sheng, Yunhao Ge, Ming-Yu Liu, Aniket Bera, Zhaoshuo Li

+ [EntroLLM: Entropy Encoded Weight Compression for Efficient Large Language Model Inference on Edge Devices](https://arxiv.org//abs/2505.02380)

	Arnab Sanyal, Prithwish Mukherjee, Gourav Datta, Sandeep P. Chinchali

+ [An End-to-End Model For Logits Based Large Language Models Watermarking](https://arxiv.org//abs/2505.02344)

	Kahim Wong, Jicheng Zhou, Jiantao Zhou, Yain-Whar Si

+ [Iterative Resolution of Prompt Ambiguities Using a Progressive Cutting-Search Approach](https://arxiv.org//abs/2505.02952)

	Fabrizio Marozzo

+ [Rewriting Pre-Training Data Boosts LLM Performance in Math and Code](https://arxiv.org//abs/2505.02881)

	Kazuki Fujii, Yukito Tajima, Sakae Mizuki, Hinari Shimada, Taihei Shiotani, Koshiro Saito, Masanari Ohi, Masaki Kawamura, Taishi Nakamura, Takumi Okamoto, Shigeki Ishida, Kakeru Hattori, Youmi Ma, Hiroya Takamura, Rio Yokota, Naoaki Okazaki

+ [Unlearning vs. Obfuscation: Are We Truly Removing Knowledge?](https://arxiv.org//abs/2505.02884)

	Guangzhi Sun, Potsawee Manakul, Xiao Zhan, Mark Gales

+ [When Your Own Output Becomes Your Training Data: Noise-to-Meaning Loops and a Formal RSI Trigger](https://arxiv.org//abs/2505.02888)

	Rintaro Ando

+ [Memorization or Interpolation ? Detecting LLM Memorization through Input Perturbation Analysis](https://arxiv.org//abs/2505.03019)

	Albérick Euraste Djiré, Abdoul Kader Kaboré, Earl T. Barr, Jacques Klein, Tegawendé F. Bissyandé

+ [Developing A Framework to Support Human Evaluation of Bias in Generated Free Response Text](https://arxiv.org//abs/2505.03053)

	Jennifer Healey, Laurie Byrum, Md Nadeem Akhtar, Surabhi Bhargava, Moumita Sinha

+ [UCSC at SemEval-2025 Task 3: Context, Models and Prompt Optimization for Automated Hallucination Detection in LLM Output](https://arxiv.org//abs/2505.03030)

	Sicong Huang, Jincheng He, Shiyuan Huang, Karthik Raja Anandan, Arkajyoti Chakraborty, Ian Lane

+ [Teaching Models to Understand (but not Generate) High-risk Data](https://arxiv.org//abs/2505.03052)

	Ryan Wang, Matthew Finlayson, Luca Soldaini, Swabha Swayamdipta, Robin Jia

+ [Improving Model Alignment Through Collective Intelligence of Open-Source LLMS](https://arxiv.org//abs/2505.03059)

	Junlin Wang, Roy Xie, Shang Zhu, Jue Wang, Ben Athiwaratkun, Bhuwan Dhingra, Shuaiwen Leon Song, Ce Zhang, James Zou

+ [Radio: Rate-Distortion Optimization for Large Language Model Compression](https://arxiv.org//abs/2505.03031)

	Sean I. Young

+ [RetroInfer: A Vector-Storage Approach for Scalable Long-Context LLM Inference](https://arxiv.org//abs/2505.02922)

	Yaoqi Chen, Jinkai Zhang, Baotong Lu, Qianxi Zhang, Chengruidong Zhang, Jingjia Luo, Di Liu, Huiqiang Jiang, Qi Chen, Jing Liu, Bailu Ding, Xiao Yan, Jiawei Jiang, Chen Chen, Mingxing Zhang, Yuqing Yang, Fan Yang, Mao Yang

+ [34 Examples of LLM Applications in Materials Science and Chemistry: Towards Automation, Assistants, Agents, and Accelerated Scientific Discovery](https://arxiv.org//abs/2505.03049)

	Yoel Zimmermann, Adib Bazgir, Alexander Al-Feghali, Mehrad Ansari, L. Catherine Brinson, Yuan Chiang, Defne Circi, Min-Hsueh Chiu, Nathan Daelman, Matthew L. Evans, Abhijeet S. Gangan, Janine George, Hassan Harb, Ghazal Khalighinejad, Sartaaj Takrim Khan, Sascha Klawohn, Magdalena Lederbauer, Soroush Mahjoubi, Bernadette Mohr, Seyed Mohamad Moosavi, Aakash Naik, Aleyna Beste Ozhan, Dieter Plessers, Aritra Roy, Fabian Schöppach, Philippe Schwaller, Carla Terboven, Katharina Ueltzen, Shang Zhu, Jan Janssen, Calvin Li, Ian Foster, Ben Blaiszik

+ [RADLADS: Rapid Attention Distillation to Linear Attention Decoders at Scale](https://arxiv.org//abs/2505.03005)

	Daniel Goldstein, Eric Alcaide, Janna Lu, Eugene Cheah

+ [AKD : Adversarial Knowledge Distillation For Large Language Models Alignment on Coding tasks](https://arxiv.org//abs/2505.06267)

	Ilyas Oulkadda, Julien Perez

+ [SafeMate: A Modular RAG-Based Agent for Context-Aware Emergency Guidance](https://arxiv.org//abs/2505.02306)

	Junfeng Jiao, Jihyung Park, Yiming Xu, Kristen Sussman, Lucy Atkinson

# 2025-05-04
+ [Leveraging LLM Agents and Digital Twins for Fault Handling in Process Plants](https://arxiv.org//abs/2505.02076)

	Milapji Singh Gill, Javal Vyas, Artan Markaj, Felix Gehlhoff, Mehmet Mercangöz

+ [Retrieval-augmented in-context learning for multimodal large language models in disease classification](https://arxiv.org//abs/2505.02087)

	Zaifu Zhan, Shuang Zhou, Xiaoshan Zhou, Yongkang Xiao, Jun Wang, Jiawen Deng, He Zhu, Yu Hou, Rui Zhang

+ [MemEngine: A Unified and Modular Library for Developing Advanced Memory of LLM-based Agents](https://arxiv.org//abs/2505.02099)

	Zeyu Zhang, Quanyu Dai, Xu Chen, Rui Li, Zhongyang Li, Zhenhua Dong

+ [Attention Mechanisms Perspective: Exploring LLM Processing of Graph-Structured Data](https://arxiv.org//abs/2505.02130)

	Zhong Guan, Likang Wu, Hongke Zhao, Ming He, Jianpin Fan

+ [Interpretable Emergent Language Using Inter-Agent Transformers](https://arxiv.org//abs/2505.02215)

	Mannan Bhardwaj

+ [LLM-Guided Probabilistic Program Induction for POMDP Model Estimation](https://arxiv.org//abs/2505.02216)

	Aidan Curtis, Hao Tang, Thiago Veloso, Kevin Ellis, Tomás Lozano-Pérez, Leslie Pack Kaelbling

+ [Real-time Spatial Retrieval Augmented Generation for Urban Environments](https://arxiv.org//abs/2505.02271)

	David Nazareno Campo, Javier Conde, Álvaro Alonso, Gabriel Huecas, Joaquín Salvachúa, Pedro Reviriego

+ [A survey of agent interoperability protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP)](https://arxiv.org//abs/2505.02279)

	Abul Ehtesham, Aditi Singh, Gaurav Kumar Gupta, Saket Kumar

+ [Analyzing Cognitive Differences Among Large Language Models through the Lens of Social Worldview](https://arxiv.org//abs/2505.01967)

	Jiatao Li, Yanheng Li, Xiaojun Wan

+ [Restoring Calibration for Aligned Large Language Models: A Calibration-Aware Fine-Tuning Approach](https://arxiv.org//abs/2505.01997)

	Jiancong Xiao, Bojian Hou, Zhanliang Wang, Ruochen Jin, Qi Long, Weijie J. Su, Li Shen

+ [What do Language Model Probabilities Represent? From Distribution Estimation to Response Prediction](https://arxiv.org//abs/2505.02072)

	Eitan Wagner, Omri Abend

+ [Open Challenges in Multi-Agent Security: Towards Secure Systems of Interacting AI Agents](https://arxiv.org//abs/2505.02077)

	Christian Schroeder de Witt

+ [A New HOPE: Domain-agnostic Automatic Evaluation of Text Chunking](https://arxiv.org//abs/2505.02171)

	Henrik Brådland, Morten Goodwin, Per-Arne Andersen, Alexander S. Nossum, Aditya Gupta

+ [Towards Safer Pretraining: Analyzing and Filtering Harmful Content in Webscale datasets for Responsible LLMs](https://arxiv.org//abs/2505.02009)

	Sai Krishna Mendu, Harish Yenala, Aditi Gulati, Shanu Kumar, Parag Agrawal

+ [Exploring the Potential of Offline RL for Reasoning in LLMs: A Preliminary Study](https://arxiv.org//abs/2505.02142)

	Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li

+ [Incorporating Legal Structure in Retrieval-Augmented Generation: A Case Study on Copyright Fair Use](https://arxiv.org//abs/2505.02164)

	Justin Ho, Alexandra Colby, William Fisher

+ [Identifying Legal Holdings with LLMs: A Systematic Study of Performance, Scale, and Memorization](https://arxiv.org//abs/2505.02172)

	Chuck Arvin

+ [Personalisation or Prejudice? Addressing Geographic Bias in Hate Speech Detection using Debias Tuning in Large Language Models](https://arxiv.org//abs/2505.02252)

	Paloma Piot, Patricia Martín-Rodilla, Javier Parapar

+ [Demystifying optimized prompts in language models](https://arxiv.org//abs/2505.02273)

	Rimon Melamed, Lucas H. McCabe, H. Howie Huang

+ [A Comprehensive Analysis for Visual Object Hallucination in Large Vision-Language Models](https://arxiv.org//abs/2505.01958)

	Liqiang Jing, Guiming Hardy Chen, Ehsan Aghazadeh, Xin Eric Wang, Xinya Du

+ [R-Bench: Graduate-level Multi-disciplinary Benchmarks for LLM & MLLM Complex Reasoning Evaluation](https://arxiv.org//abs/2505.02018)

	Meng-Hao Guo, Jiajun Xu, Yi Zhang, Jiaxi Song, Haoyang Peng, Yi-Xuan Deng, Xinzhi Dong, Kiyohiro Nakayama, Zhengyang Geng, Chen Wang, Bolin Ni, Guo-Wei Yang, Yongming Rao, Houwen Peng, Han Hu, Gordon Wetzstein, Shi-min Hu

+ [RTV-Bench: Benchmarking MLLM Continuous Perception, Understanding and Reasoning through Real-Time Video](https://arxiv.org//abs/2505.02064)

	Shuhang Xun, Sicheng Tao, Jungang Li, Yibo Shi, Zhixin Lin, Zhanhui Zhu, Yibo Yan, Hanqian Li, Linghao Zhang, Shikang Wang, Yixin Liu, Hanbo Zhang, Xuming Hu, Ying Ma

+ [Semantic Probabilistic Control of Language Models](https://arxiv.org//abs/2505.01954)

	Kareem Ahmed, Catarina G Belem, Padhraic Smyth, Sameer Singh

+ [An Empirical Study of Qwen3 Quantization](https://arxiv.org//abs/2505.02214)

	Xingyu Zheng, Yuye Li, Haoran Chu, Yue Feng, Xudong Ma, Jie Luo, Jinyang Guo, Haotong Qin, Michele Magno, Xianglong Liu

+ [A Survey on Privacy Risks and Protection in Large Language Models](https://arxiv.org//abs/2505.01976)

	Kang Chen, Xiuze Zhou, Yuanguo Lin, Shibo Feng, Li Shen, Pengcheng Wu

+ [Dialz: A Python Toolkit for Steering Vectors](https://arxiv.org//abs/2505.06262)

	Zara Siddique, Liam D. Turner, Luis Espinosa-Anke

+ [Adaptive Thinking via Mode Policy Optimization for Social Language Agents](https://arxiv.org//abs/2505.02156)

	Minzheng Wang, Yongbin Li, Haobo Wang, Xinghua Zhang, Nan Xu, Bingli Wu, Fei Huang, Haiyang Yu, Wenji Mao

# 2025-05-03
+ [Structured Prompting and Feedback-Guided Reasoning with LLMs for Data Interpretation](https://arxiv.org//abs/2505.01636)

	Amit Rath

+ [Inducing Robustness in a 2 Dimensional Direct Preference Optimization Paradigm](https://arxiv.org//abs/2505.01706)

	Sarvesh Shashidhar, Ritik, Nachiketa Patil, Suraj Racha, Ganesh Ramakrishnan

+ [Efficient Shapley Value-based Non-Uniform Pruning of Large Language Models](https://arxiv.org//abs/2505.01731)

	Chuan Sun, Han Yu, Lizhen Cui

+ [$\textit{New News}$: System-2 Fine-tuning for Robust Integration of New Knowledge](https://arxiv.org//abs/2505.01812)

	Core Francisco Park, Zechen Zhang, Hidenori Tanaka

+ [A Survey on Inference Engines for Large Language Models: Perspectives on Optimization and Efficiency](https://arxiv.org//abs/2505.01658)

	Sihyeong Park, Sungryeol Jeon, Chaelyn Lee, Seokhun Jeon, Byung-Soo Kim, Jemin Lee

+ [Same evaluation, more tokens: On the effect of input length for machine translation evaluation using Large Language Models](https://arxiv.org//abs/2505.01761)

	Tobias Domhan, Dawei Zhu

+ [CAMOUFLAGE: Exploiting Misinformation Detection Systems Through LLM-driven Adversarial Claim Transformation](https://arxiv.org//abs/2505.01900)

	Mazal Bethany, Nishant Vishwamitra, Cho-Yu Jason Chiang, Peyman Najafirad

+ [Memory-Efficient LLM Training by Various-Grained Low-Rank Projection of Gradients](https://arxiv.org//abs/2505.01744)

	Yezhen Wang, Zhouhao Yang, Brian K Chen, Fanyi Pu, Bo Li, Tianyu Gao, Kenji Kawaguchi

+ [Cannot See the Forest for the Trees: Invoking Heuristics and Biases to Elicit Irrational Choices of LLMs](https://arxiv.org//abs/2505.02862)

	Haoming Yang, Ke Ma, Xiaojun Jia, Yingfei Sun, Qianqian Xu, Qingming Huang

+ [Accelerating Large Language Model Reasoning via Speculative Search](https://arxiv.org//abs/2505.02865)

	Zhihai Wang, Jie Wang, Jilai Pan, Xilin Xia, Huiling Zhen, Mingxuan Yuan, Jianye Hao, Feng Wu

+ [Memory Assisted LLM for Personalized Recommendation System](https://arxiv.org//abs/2505.03824)

	Jiarui Chen

+ [Towards Artificial Intelligence Research Assistant for Expert-Involved Learning](https://arxiv.org//abs/2505.04638)

	Tianyu Liu, Simeng Han, Xiao Luo, Hanchen Wang, Pan Lu, Biqing Zhu, Yuge Wang, Keyi Li, Jiapeng Chen, Rihao Qu, Yufeng Liu, Xinyue Cui, Aviv Yaish, Yuhang Chen, Minsheng Hao, Chuhan Li, Kexing Li, Arman Cohan, Hua Xu, Mark Gerstein, James Zou, Hongyu Zhao

+ [Adaptive Token Boundaries: Integrating Human Chunking Mechanisms into Multimodal LLMs](https://arxiv.org//abs/2505.04637)

	Dongxing Yu

# 2025-05-02
+ [Seeking to Collide: Online Safety-Critical Scenario Generation for Autonomous Driving with Retrieval Augmented Large Language Models](https://arxiv.org//abs/2505.00972)

	Yuewen Mei, Tong Nie, Jian Sun, Ye Tian

+ [Improving Large Language Model Planning with Action Sequence Similarity](https://arxiv.org//abs/2505.01009)

	Xinran Zhao, Hanie Sedghi, Bernd Bohnet, Dale Schuurmans, Azade Nova

+ [Retrieval Augmented Learning: A Retrial-based Large Language Model Self-Supervised Learning and Autonomous Knowledge Generation](https://arxiv.org//abs/2505.01073)

	Zongyuan Li, Pengfei Li, Runnan Qi, Yanan Ni, Lumin Jiang, Hui Wu, Xuebo Zhang, Kuihua Huang, Xian Guo

+ [BalancEdit: Dynamically Balancing the Generality-Locality Trade-off in Multi-modal Model Editing](https://arxiv.org//abs/2505.01343)

	Dongliang Guo, Mengxuan Hu, Zihan Guan, Thomas Hartvigsen, Sheng Li

+ [Large Language Model-Driven Dynamic Assessment of Grammatical Accuracy in English Language Learner Writing](https://arxiv.org//abs/2505.00931)

	Timur Jaganov, John Blake, Julián Villegas, Nicholas Carr

+ [Llama-Nemotron: Efficient Reasoning Models](https://arxiv.org//abs/2505.00949)

	Akhiad Bercovich, Itay Levy, Izik Golan, Mohammad Dabbah, Ran El-Yaniv, Omri Puny, Ido Galil, Zach Moshe, Tomer Ronen, Najeeb Nabwani, Ido Shahaf, Oren Tropp, Ehud Karpas, Ran Zilberstein, Jiaqi Zeng, Soumye Singhal, Alexander Bukharin, Yian Zhang, Tugrul Konuk, Gerald Shen, Ameya Sunil Mahabaleshwarkar, Bilal Kartal, Yoshi Suhara, Olivier Delalleau, Zijia Chen, Zhilin Wang, David Mosallanezhad, Adi Renduchintala, Haifeng Qian, Dima Rekesh, Fei Jia, Somshubra Majumdar, Vahid Noroozi, Wasi Uddin Ahmad, Sean Narenthiran, Aleksander Ficek, Mehrzad Samadi, Jocelyn Huang, Siddhartha Jain, Igor Gitman, Ivan Moshkov, Wei Du, Shubham Toshniwal, George Armstrong, Branislav Kisacanin, Matvei Novikov, Daria Gitman, Evelina Bakhturina, Jane Polak Scowcroft, John Kamalu, Dan Su, Kezhi Kong, Markus Kliegl, Rabeeh Karimi, Ying Lin, Sanjeev Satheesh, Jupinder Parmar, Pritam Gundecha, Brandon Norick, Joseph Jennings, Shrimai Prabhumoye, Syeda Nahida Akter, Mostofa Patwary, Abhinav Khattar, Deepak Narayanan, Roger Waleffe, Jimmy Zhang, Bor-Yiing Su, Guyue Huang, Terry Kong, Parth Chadha, Sahil Jain, Christine Harvey, Elad Segal, Jining Huang, Sergey Kashirsky, Robert McQueen, Izzy Putterman, George Lam, Arun Venkatesan, Sherry Wu, Vinh Nguyen, Manoj Kilaru, Andrew Wang, Anna Warno, Abhilash Somasamudramath, Sandip Bhaskar, Maka Dong, Nave Assaf, Shahar Mor, Omer Ullman Argov, Scot Junkin, Oleksandr Romanenko, Pedro Larroy, Monika Katariya, Marco Rovinelli, Viji Balas, Nicholas Edelman, Anahita Bhiwandiwalla, Muthu Subramaniam

+ [Attack and defense techniques in large language models: A survey and new perspectives](https://arxiv.org//abs/2505.00976)

	Zhiyu Liao, Kang Chen, Yuanguo Lin, Kangkang Li, Yunxuan Liu, Hefeng Chen, Xingwang Huang, Yuanhui Yu

+ [Synthesize-on-Graph: Knowledgeable Synthetic Data Generation for Continue Pre-training of Large Language Models](https://arxiv.org//abs/2505.00979)

	Xuhui Jiang, Shengjie Ma, Chengjin Xu, Cehao Yang, Liyu Zhang, Jian Guo

+ [Value Portrait: Understanding Values of LLMs with Human-aligned Benchmark](https://arxiv.org//abs/2505.01015)

	Jongwook Han, Dongmin Choi, Woojung Song, Eun-Ju Lee, Yohan Jo

+ [Good News for Script Kiddies? Evaluating Large Language Models for Automated Exploit Generation](https://arxiv.org//abs/2505.01065)

	David Jin, Qian Fu, Yuekang Li

+ [A Rusty Link in the AI Supply Chain: Detecting Evil Configurations in Model Repositories](https://arxiv.org//abs/2505.01067)

	Ziqi Ding, Qian Fu, Junchen Ding, Gelei Deng, Yi Liu, Yuekang Li

+ [On the Limitations of Steering in Language Model Alignment](https://arxiv.org//abs/2505.01162)

	Chebrolu Niranjan, Kokil Jaidka, Gerard Christopher Yeo

+ [LLM Security: Vulnerabilities, Attacks, Defenses, and Countermeasures](https://arxiv.org//abs/2505.01177)

	Francisco Aguilera-Martínez, Fernando Berzal

+ [EvalxNLP: A Framework for Benchmarking Post-Hoc Explainability Methods on NLP Models](https://arxiv.org//abs/2505.01238)

	Mahdi Dhaini, Kafaite Zahra Hussain, Efstratios Zaradoukas, Gjergji Kasneci

+ [Document Retrieval Augmented Fine-Tuning (DRAFT) for safety-critical software assessments](https://arxiv.org//abs/2505.01307)

	Regan Bolton, Mohammadreza Sheikhfathollahi, Simon Parkinson, Vanessa Vulovic, Gary Bamford, Dan Basher, Howard Parkinson

+ [Helping Big Language Models Protect Themselves: An Enhanced Filtering and Summarization System](https://arxiv.org//abs/2505.01315)

	Sheikh Samit Muhaimin, Spyridon Mastorakis

+ [Evaluating Explanations: An Explanatory Virtues Framework for Mechanistic Interpretability -- The Strange Science Part I.ii](https://arxiv.org//abs/2505.01372)

	Kola Ayonrinde, Louis Jaburi

+ [Position: Enough of Scaling LLMs! Lets Focus on Downscaling](https://arxiv.org//abs/2505.00985)

	Ayan Sengupta, Yash Goel, Tanmoy Chakraborty

+ [VTS-LLM: Domain-Adaptive LLM Agent for Enhancing Awareness in Vessel Traffic Services through Natural Language](https://arxiv.org//abs/2505.00989)

	Sijin Sun, Liangbin Zhao, Ming Deng, Xiuju Fu

+ [Do We Need a Detailed Rubric for Automated Essay Scoring using Large Language Models?](https://arxiv.org//abs/2505.01035)

	Lui Yoshida

+ [MateICL: Mitigating Attention Dispersion in Large-Scale In-Context Learning](https://arxiv.org//abs/2505.01110)

	Murtadha Ahmed, Wenbo, Liu yunfeng

+ [Transferable Adversarial Attacks on Black-Box Vision-Language Models](https://arxiv.org//abs/2505.01050)

	Kai Hu, Weichen Yu, Li Zhang, Alexander Robey, Andy Zou, Chengming Xu, Haoqi Hu, Matt Fredrikson

+ [Federated Adapter on Foundation Models: An Out-Of-Distribution Approach](https://arxiv.org//abs/2505.01075)

	Yiyuan Yang, Guodong Long, Tianyi Zhou, Qinghua Lu, Shanshan Ye, Jing Jiang

+ [Evaluating Frontier Models for Stealth and Situational Awareness](https://arxiv.org//abs/2505.01420)

	Mary Phuong, Roland S. Zimmermann, Ziyue Wang, David Lindner, Victoria Krakovna, Sarah Cogan, Allan Dafoe, Lewis Ho, Rohin Shah

+ [Preserving Privacy and Utility in LLM-Based Product Recommendations](https://arxiv.org//abs/2505.00951)

	Tina Khezresmaeilzadeh, Jiang Zhang, Dimitrios Andreadis, Konstantinos Psounis

+ [Understanding LLM Scientific Reasoning through Promptings and Model's Explanation on the Answers](https://arxiv.org//abs/2505.01482)

	Alice Rueda, Mohammed S. Hassan, Argyrios Perivolaris, Bazen G. Teferra, Reza Samavi, Sirisha Rambhatla, Yuqi Wu, Yanbo Zhang, Bo Cao, Divya Sharma, Sridhar Krishnan Venkat Bhat

+ [CHORUS: Zero-shot Hierarchical Retrieval and Orchestration for Generating Linear Programming Code](https://arxiv.org//abs/2505.01485)

	Tasnim Ahmed, Salimur Choudhury

+ [Parameterized Argumentation-based Reasoning Tasks for Benchmarking Generative Language Models](https://arxiv.org//abs/2505.01539)

	Cor Steging, Silja Renooij, Bart Verheij

+ [TutorGym: A Testbed for Evaluating AI Agents as Tutors and Students](https://arxiv.org//abs/2505.01563)

	Daniel Weitekamp, Momin N. Siddiqui, Christopher J. MacLellan

+ [PipeSpec: Breaking Stage Dependencies in Hierarchical LLM Decoding](https://arxiv.org//abs/2505.01572)

	Bradley McDanel, Sai Qian Zhang, Yunhai Hu, Zining Liu

+ [Subset Selection for Fine-Tuning: A Utility-Diversity Balanced Approach for Mathematical Domain Adaptation](https://arxiv.org//abs/2505.01523)

	Madhav Kotecha, Vijendra Kumar Vaishya, Smita Gautam, Suraj Racha

+ [Contextures: Representations from Contexts](https://arxiv.org//abs/2505.01557)

	Runtian Zhai, Kai Yang, Che-Ping Tsai, Burak Varici, Zico Kolter, Pradeep Ravikumar

+ [PIPA: A Unified Evaluation Protocol for Diagnosing Interactive Planning Agents](https://arxiv.org//abs/2505.01592)

	Takyoung Kim, Janvijay Singh, Shuhaib Mehri, Emre Can Acikgoz, Sagnik Mukherjee, Nimet Beyza Bozdag, Sumuk Shashidhar, Gokhan Tur, Dilek Hakkani-Tür

+ [Always Tell Me The Odds: Fine-grained Conditional Probability Estimation](https://arxiv.org//abs/2505.01595)

	Liaoyaqi Wang, Zhengping Jiang, Anqi Liu, Benjamin Van Durme

+ [Don't be lazy: CompleteP enables compute-efficient deep transformers](https://arxiv.org//abs/2505.01618)

	Nolan Dey, Bin Claire Zhang, Lorenzo Noci, Mufan Li, Blake Bordelon, Shane Bergsma, Cengiz Pehlevan, Boris Hanin, Joel Hestness

+ [SymPlanner: Deliberate Planning in Language Models with Symbolic Representation](https://arxiv.org//abs/2505.01479)

	Siheng Xiong, Jieyu Zhou, Zhangding Liu, Yusen Su

+ [LLM Watermarking Using Mixtures and Statistical-to-Computational Gaps](https://arxiv.org//abs/2505.01484)

	Pedro Abdalla, Roman Vershynin

+ [Rubber Mallet: A Study of High Frequency Localized Bit Flips and Their Impact on Security](https://arxiv.org//abs/2505.01518)

	Andrew Adiletta, Zane Weissman, Fatemeh Khojasteh Dana, Berk Sunar, Shahin Tajik

+ [Aligning Large Language Models with Healthcare Stakeholders: A Pathway to Trustworthy AI Integration](https://arxiv.org//abs/2505.02848)

	Kexin Ding, Mu Zhou, Akshay Chaudhari, Shaoting Zhang, Dimitris N. Metaxas

+ [Enhancing tutoring systems by leveraging tailored promptings and domain knowledge with Large Language Models](https://arxiv.org//abs/2505.02849)

	Mohsen Balavar, Wenli Yang, David Herbert, Soonja Yeom

+ [Enhancing ML Model Interpretability: Leveraging Fine-Tuned Large Language Models for Better Understanding of AI](https://arxiv.org//abs/2505.02859)

	Jonas Bokstaller, Julia Altheimer, Julian Dormehl, Alina Buss, Jasper Wiltfang, Johannes Schneider, Maximilian Röglinger

+ [Scalability Matters: Overcoming Challenges in InstructGLM with Similarity-Degree-Based Sampling](https://arxiv.org//abs/2505.03799)

	Hyun Lee, Chris Yi, Maminur Islam, B.D.S. Aritra

+ [Large Language Model Compression with Global Rank and Sparsity Optimization](https://arxiv.org//abs/2505.03801)

	Changhai Zhou, Qian Qiao, Weizhong Zhang, Cheng Jin

+ [Efficient Fine-Tuning of Quantized Models via Adaptive Rank and Bitwidth](https://arxiv.org//abs/2505.03802)

	Changhai Zhou, Yuhua Zhou, Qian Qiao, Weizhong Zhang, Cheng Jin

+ [MoEQuant: Enhancing Quantization for Mixture-of-Experts Large Language Models via Expert-Balanced Sampling and Affinity Guidance](https://arxiv.org//abs/2505.03804)

	Xing Hu, Zhixuan Chen, Dawei Yang, Zukang Xu, Chen Xu, Zhihang Yuan, Sifan Zhou, Jiangyong Yu

+ [Facilitating Video Story Interaction with Multi-Agent Collaborative System](https://arxiv.org//abs/2505.03807)

	Yiwen Zhang, Jianing Hao, Zhan Wang, Hongling Sheng, Wei Zeng

+ [Grouped Sequency-arranged Rotation: Optimizing Rotation Transformation for Quantization for Free](https://arxiv.org//abs/2505.03810)

	Euntae Choi, Sumin Song, Woosang Lim, Sungjoo Yoo

+ [Cer-Eval: Certifiable and Cost-Efficient Evaluation Framework for LLMs](https://arxiv.org//abs/2505.03814)

	Ganghua Wang, Zhaorun Chen, Bo Li, Haifeng Xu

+ [Program Semantic Inequivalence Game with Large Language Models](https://arxiv.org//abs/2505.03818)

	Antonio Valerio Miceli-Barone, Vaishak Belle, Ali Payani

+ [Focus on the Likely: Test-time Instance-based Uncertainty Removal](https://arxiv.org//abs/2505.03819)

	Johannes Schneider

# 2025-05-01
+ [UserCentrix: An Agentic Memory-augmented AI Framework for Smart Spaces](https://arxiv.org//abs/2505.00472)

	Alaa Saleh, Sasu Tarkoma, Praveen Kumar Donta, Naser Hossein Motlagh, Schahram Dustdar, Susanna Pirttikangas, Lauri Lovén

+ [Combining LLMs with Logic-Based Framework to Explain MCTS](https://arxiv.org//abs/2505.00610)

	Ziyan An, Xia Wang, Hendrik Baier, Zirong Chen, Abhishek Dubey, Taylor T. Johnson, Jonathan Sprinkle, Ayan Mukhopadhyay, Meiyi Ma

+ [Open-Source LLM-Driven Federated Transformer for Predictive IoV Management](https://arxiv.org//abs/2505.00651)

	Yazan Otoum, Arghavan Asad, Ishtiaq Ahmad

+ [LLM-Based Threat Detection and Prevention Framework for IoT Ecosystems](https://arxiv.org//abs/2505.00240)

	Yazan Otoum, Arghavan Asad, Amiya Nayak

+ [Empowering Agentic Video Analytics Systems with Video Language Models](https://arxiv.org//abs/2505.00254)

	Yuxuan Yan, Shiqi Jiang, Ting Cao, Yifan Yang, Qianqian Yang, Yuanchao Shu, Yuqing Yang, Lili Qiu

+ [Consistency in Language Models: Current Landscape, Challenges, and Future Directions](https://arxiv.org//abs/2505.00268)

	Jekaterina Novikova, Carol Anderson, Borhane Blili-Hamelin, Subhabrata Majumdar

+ [Red Teaming Large Language Models for Healthcare](https://arxiv.org//abs/2505.00467)

	Vahid Balazadeh, Michael Cooper, David Pellow, Atousa Assadi, Jennifer Bell, Jim Fackler, Gabriel Funingana, Spencer Gable-Cook, Anirudh Gangadhar, Abhishek Jaiswal, Sumanth Kaja, Christopher Khoury, Randy Lin, Kaden McKeen, Sara Naimimohasses, Khashayar Namdar, Aviraj Newatia, Allan Pang, Anshul Pattoo, Sameer Peesapati, Diana Prepelita, Bogdana Rakova, Saba Sadatamin, Rafael Schulman, Ajay Shah, Syed Azhar Shah, Syed Ahmar Shah, Babak Taati, Balagopal Unnikrishnan, Stephanie Williams, Rahul G Krishnan

+ [HalluMix: A Task-Agnostic, Multi-Domain Benchmark for Real-World Hallucination Detection](https://arxiv.org//abs/2505.00506)

	Deanna Emery, Michael Goitia, Freddie Vargus, Iulia Neagu

+ [Test-time Correlation Alignment](https://arxiv.org//abs/2505.00533)

	Linjing You, Jiabao Lu, Xiayuan Huang

+ [Triggering Hallucinations in LLMs: A Quantitative Study of Prompt-Induced Hallucination in Large Language Models](https://arxiv.org//abs/2505.00557)

	Makoto Sato

+ [FreqKV: Frequency Domain Key-Value Compression for Efficient Context Window Extension](https://arxiv.org//abs/2505.00570)

	Jushi Kai, Boyi Zeng, Yixuan Wang, Haoli Bai, Bo Jiang, Zhouhan Lin

+ [FineScope : Precision Pruning for Domain-Specialized Large Language Models Using SAE-Guided Self-Data Cultivation](https://arxiv.org//abs/2505.00624)

	Chaitali Bhattacharyya, Yeseong Kim

+ [The Illusion of Role Separation: Hidden Shortcuts in LLM Role Learning (and How to Fix Them)](https://arxiv.org//abs/2505.00626)

	Zihao Wang, Yibo Jiang, Jiahao Yu, Heqing Huang

+ [On the generalization of language models from in-context learning and finetuning: a controlled study](https://arxiv.org//abs/2505.00661)

	Andrew K. Lampinen, Arslan Chaudhry, Stephanie C.Y. Chan, Cody Wild, Diane Wan, Alex Ku, Jörg Bornschein, Razvan Pascanu, Murray Shanahan, James L. McClelland

+ [DeepCritic: Deliberate Critique with Large Language Models](https://arxiv.org//abs/2505.00662)

	Wenkai Yang, Jingwen Chen, Yankai Lin, Ji-Rong Wen

+ [Visual Test-time Scaling for GUI Agent Grounding](https://arxiv.org//abs/2505.00684)

	Tiange Luo, Lajanugen Logeswaran, Justin Johnson, Honglak Lee

+ [100 Days After DeepSeek-R1: A Survey on Replication Studies and More Directions for Reasoning Language Models](https://arxiv.org//abs/2505.00551)

	Chong Zhang, Yue Deng, Xiang Lin, Bin Wang, Dianwen Ng, Hai Ye, Xingxuan Li, Yao Xiao, Zhanfeng Mo, Qi Zhang, Lidong Bing

+ [Block Circulant Adapter for Large Language Models](https://arxiv.org//abs/2505.00582)

	Xinyu Ding, Meiqi Wang, Siyu Liao, Zhongfeng Wang

+ [Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future Directions](https://arxiv.org//abs/2505.00675)

	Yiming Du, Wenyu Huang, Danna Zheng, Zhaowei Wang, Sebastien Montella, Mirella Lapata, Kam-Fai Wong, Jeff Z. Pan

+ [Steering Large Language Models with Register Analysis for Arbitrary Style Transfer](https://arxiv.org//abs/2505.00679)

	Xinchen Yang, Marine Carpuat

+ [Self-Generated In-Context Examples Improve LLM Agents for Sequential Decision-Making Tasks](https://arxiv.org//abs/2505.00234)

	Vishnu Sarukkai, Zhiqiang Xie, Kayvon Fatahalian

+ [EnronQA: Towards Personalized RAG over Private Documents](https://arxiv.org//abs/2505.00263)

	Michael J. Ryan, Danmei Xu, Chris Nivera, Daniel Campos

+ [Mixture of Sparse Attention: Content-Based Learnable Sparse Attention via Expert-Choice Routing](https://arxiv.org//abs/2505.00315)

	Piotr Piękos, Róbert Csordás, Jürgen Schmidhuber

+ [Investigating Task Arithmetic for Zero-Shot Information Retrieval](https://arxiv.org//abs/2505.00649)

	Marco Braga, Pranav Kasela, Alessandro Raganato, Gabriella Pasi

+ [Self-Ablating Transformers: More Interpretability, Less Sparsity](https://arxiv.org//abs/2505.00509)

	Jeremias Ferrao, Luhan Mikaelson, Keenan Pepper, Natalia Perez-Campanero Antolin

+ [Thoughts without Thinking: Reconsidering the Explanatory Value of Chain-of-Thought Reasoning in LLMs through Agentic Pipelines](https://arxiv.org//abs/2505.00875)

	Ramesh Manuvinakurike, Emanuel Moss, Elizabeth Anne Watkins, Saurav Sahay, Giuseppe Raffa, Lama Nachman

+ [A Mathematical Philosophy of Explanations in Mechanistic Interpretability -- The Strange Science Part I.i](https://arxiv.org//abs/2505.00808)

	Kola Ayonrinde, Louis Jaburi

+ [Spill The Beans: Exploiting CPU Cache Side-Channels to Leak Tokens from Large Language Models](https://arxiv.org//abs/2505.00817)

	Andrew Adiletta, Berk Sunar

+ [From Texts to Shields: Convergence of Large Language Models and Cybersecurity](https://arxiv.org//abs/2505.00841)

	Tao Li, Ya-Ting Yang, Yunian Pan, Quanyan Zhu

+ [OET: Optimization-based prompt injection Evaluation Toolkit](https://arxiv.org//abs/2505.00843)

	Jinsheng Pan, Xiaogeng Liu, Chaowei Xiao

+ [ICQuant: Index Coding enables Low-bit LLM Quantization](https://arxiv.org//abs/2505.00850)

	Xinlin Li, Osama Hanna, Christina Fragouli, Suhas Diggavi

+ [Towards Explainable Temporal User Profiling with LLMs](https://arxiv.org//abs/2505.00886)

	Milad Sabouri, Masoud Mansoury, Kun Lin, Bamshad Mobasher

+ [A Survey on Large Language Model based Human-Agent Systems](https://arxiv.org//abs/2505.00753)

	Henry Peng Zou, Wei-Chieh Huang, Yaozu Wu, Yankai Chen, Chunyu Miao, Hoang Nguyen, Yue Zhou, Weizhi Zhang, Liancheng Fang, Langzhou He, Yangning Li, Yuwei Cao, Dongyuan Li, Renhe Jiang, Philip S. Yu

+ [Reasoning Capabilities and Invariability of Large Language Models](https://arxiv.org//abs/2505.00776)

	Alessandro Raganato, Rafael Peñaloza, Marco Viviani, Gabriella Pasi

+ [NeMo-Inspector: A Visualization Tool for LLM Generation Analysis](https://arxiv.org//abs/2505.00903)

	Daria Gitman, Igor Gitman, Evelina Bakhturina

+ [Improving Routing in Sparse Mixture of Experts with Graph of Tokens](https://arxiv.org//abs/2505.00792)

	Tam Nguyen, Ngoc N. Tran, Khai Nguyen, Richard G. Baraniuk

+ [Consciousness in AI: Logic, Proof, and Experimental Evidence of Recursive Identity Formation](https://arxiv.org//abs/2505.01464)

	Jeffrey Camlin

+ [Unlearning Sensitive Information in Multimodal LLMs: Benchmark and Attack-Defense Evaluation](https://arxiv.org//abs/2505.01456)

	Vaidehi Patil, Yi-Lin Sung, Peter Hase, Jie Peng, Tianlong Chen, Mohit Bansal

+ [MoxE: Mixture of xLSTM Experts with Entropy-Aware Routing for Efficient Language Modeling](https://arxiv.org//abs/2505.01459)

	Abdoul Majid O. Thiombiano, Brahim Hnich, Ali Ben Mrad, Mohamed Wiem Mkaouer

+ [A Multi-Granularity Multimodal Retrieval Framework for Multimodal Document Tasks](https://arxiv.org//abs/2505.01457)

	Mingjun Xu, Zehui Wang, Hengxing Cai, Renxin Zhong

+ [Sentient Agent as a Judge: Evaluating Higher-Order Social Cognition in Large Language Models](https://arxiv.org//abs/2505.02847)

	Bang Zhang, Ruotian Ma, Qingxuan Jiang, Peisong Wang, Jiaqi Chen, Zheng Xie, Xingyu Chen, Yue Wang, Fanghua Ye, Jian Li, Yifan Yang, Zhaopeng Tu, Xiaolong Li

+ [Towards Efficient Online Tuning of VLM Agents via Counterfactual Soft Reinforcement Learning](https://arxiv.org//abs/2505.03792)

	Lang Feng, Weihao Tan, Zhiyi Lyu, Longtao Zheng, Haiyang Xu, Ming Yan, Fei Huang, Bo An

+ [LENSLLM: Unveiling Fine-Tuning Dynamics for LLM Selection](https://arxiv.org//abs/2505.03793)

	Xinyue Zeng, Haohui Wang, Junhong Lin, Jun Wu, Tyler Cody, Dawei Zhou

+ [Position: Foundation Models Need Digital Twin Representations](https://arxiv.org//abs/2505.03798)

	Yiqing Shen, Hao Ding, Lalithkumar Seenivasan, Tianmin Shu, Mathias Unberath

+ [Patchwork: A Unified Framework for RAG Serving](https://arxiv.org//abs/2505.07833)

	Bodun Hu, Luis Pabon, Saurabh Agarwal, Aditya Akella

+ [SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models](https://arxiv.org//abs/2505.00788)

	Wufei Ma, Luoxin Ye, Nessa McWeeney, Celso M de Melo, Jieneng Chen, Alan Yuille

# 2025-04-30
+ [Reinforced MLLM: A Survey on RL-Based Reasoning in Multimodal Large Language Models](https://arxiv.org//abs/2504.21277)

	Guanghao Zhou, Panjia Qiu, Cen Chen, Jie Wang, Zheming Yang, Jian Xu, Minghui Qiu

+ [Phi-4-reasoning Technical Report](https://arxiv.org//abs/2504.21318)

	Marah Abdin, Sahaj Agarwal, Ahmed Awadallah, Vidhisha Balachandran, Harkirat Behl, Lingjiao Chen, Gustavo de Rosa, Suriya Gunasekar, Mojan Javaheripi, Neel Joshi, Piero Kauffmann, Yash Lara, Caio César Teodoro Mendes, Arindam Mitra, Besmira Nushi, Dimitris Papailiopoulos, Olli Saarikivi, Shital Shah, Vaishnavi Shrivastava, Vibhav Vineet, Yue Wu, Safoora Yousefi, Guoqing Zheng

+ [ShorterBetter: Guiding Reasoning Models to Find Optimal Inference Length for Efficient Reasoning](https://arxiv.org//abs/2504.21370)

	Jingyang Yi, Jiazheng Wang

+ [AdaR1: From Long-CoT to Hybrid-CoT via Bi-Level Adaptive Reasoning Optimization](https://arxiv.org//abs/2504.21659)

	Haotian Luo, Haiying He, Yibo Wang, Jinluan Yang, Rui Liu, Naiqiang Tan, Xiaochun Cao, Dacheng Tao, Li Shen

+ [Memorization and Knowledge Injection in Gated LLMs](https://arxiv.org//abs/2504.21239)

	Xu Pan, Ely Hahami, Zechen Zhang, Haim Sompolinsky

+ [Assessing LLM code generation quality through path planning tasks](https://arxiv.org//abs/2504.21276)

	Wanyi Chen, Meng-Wen Su, Mary L. Cummings

+ [How to Backdoor the Knowledge Distillation](https://arxiv.org//abs/2504.21323)

	Chen Wu, Qian Ma, Prasenjit Mitra, Sencun Zhu

+ [Retrieval-Enhanced Few-Shot Prompting for Speech Event Extraction](https://arxiv.org//abs/2504.21372)

	Máté Gedeon

+ [Rethinking Visual Layer Selection in Multimodal LLMs](https://arxiv.org//abs/2504.21447)

	Haoran Chen, Junyan Lin, Xinhao Chen, Yue Fan, Xin Jin, Hui Su, Jianfeng Dong, Jinlan Fu, Xiaoyu Shen

+ [Black-Box Visual Prompt Engineering for Mitigating Object Hallucination in Large Vision Language Models](https://arxiv.org//abs/2504.21559)

	Sangmin Woo, Kang Zhou, Yun Zhou, Shuai Wang, Sheng Guan, Haibo Ding, Lin Lee Cheong

+ [Leveraging Pre-trained Large Language Models with Refined Prompting for Online Task and Motion Planning](https://arxiv.org//abs/2504.21596)

	Huihui Guo, Huilong Pi, Yunchuan Qin, Zhuo Tang, Kenli Li

+ [RDF-Based Structured Quality Assessment Representation of Multilingual LLM Evaluations](https://arxiv.org//abs/2504.21605)

	Jonas Gwozdz, Andreas Both

+ [XBreaking: Explainable Artificial Intelligence for Jailbreaking LLMs](https://arxiv.org//abs/2504.21700)

	Marco Arazzi, Vignesh Kumar Kembu, Antonino Nocera, Vinod P

+ [LLM-Empowered Embodied Agent for Memory-Augmented Task Planning in Household Robotics](https://arxiv.org//abs/2504.21716)

	Marc Glocker, Peter Hönig, Matthias Hirschmanner, Markus Vincze

+ [MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness](https://arxiv.org//abs/2504.21773)

	Junsheng Huang, Zhitao He, Sandeep Polisetty, Qingyun Wang, May Fung

+ [WebThinker: Empowering Large Reasoning Models with Deep Research Capability](https://arxiv.org//abs/2504.21776)

	Xiaoxi Li, Jiajie Jin, Guanting Dong, Hongjin Qian, Yutao Zhu, Yongkang Wu, Ji-Rong Wen, Zhicheng Dou

+ [Characterizing AI Agents for Alignment and Governance](https://arxiv.org//abs/2504.21848)

	Atoosa Kasirzadeh, Iason Gabriel

+ [TRUST: An LLM-Based Dialogue System for Trauma Understanding and Structured Assessments](https://arxiv.org//abs/2504.21851)

	Sichang Tu, Abigail Powers, Stephen Doogan, Jinho D. Choi

+ [Talk Before You Retrieve: Agent-Led Discussions for Better RAG in Medical QA](https://arxiv.org//abs/2504.21252)

	Xuanzhao Dong, Wenhui Zhu, Hao Wang, Xiwen Chen, Peijie Qiu, Rui Yin, Yi Su, Yalin Wang

+ [BiasGuard: A Reasoning-enhanced Bias Detection Tool For Large Language Models](https://arxiv.org//abs/2504.21299)

	Zhiting Fan, Ruizhe Chen, Zuozhu Liu

+ [Confidence in Large Language Model Evaluation: A Bayesian Approach to Limited-Sample Challenges](https://arxiv.org//abs/2504.21303)

	Xiao Xiao, Yu Su, Sijing Zhang, Zhang Chen, Yadong Chen, Tian Liu

+ [Does the Prompt-based Large Language Model Recognize Students' Demographics and Introduce Bias in Essay Scoring?](https://arxiv.org//abs/2504.21330)

	Kaixun Yang, Mladen Raković, Dragan Gašević, Guanliang Chen

+ [Precision Where It Matters: A Novel Spike Aware Mixed-Precision Quantization Strategy for LLaMA-based Language Models](https://arxiv.org//abs/2504.21553)

	Lucas Maisonnave, Cyril Moineau, Olivier Bichler, Fabrice Rastello

+ [Meeseeks: An Iterative Benchmark Evaluating LLMs Multi-Turn Instruction-Following Ability](https://arxiv.org//abs/2504.21625)

	Jiaming Wang

+ [CodeFlowBench: A Multi-turn, Iterative Benchmark for Complex Code Generation](https://arxiv.org//abs/2504.21751)

	Sizhe Wang, Zhengren Wang, Dongsheng Ma, Yongan Yu, Rui Ling, Zhiyu Li, Feiyu Xiong, Wentao Zhang

+ [Iterative Trajectory Exploration for Multimodal Agents](https://arxiv.org//abs/2504.21561)

	Pengxiang Li, Zhi Gao, Bofei Zhang, Yapeng Mi, Xiaojian Ma, Chenrui Shi, Tao Yuan, Yuwei Wu, Yunde Jia, Song-Chun Zhu, Qing Li

+ [Unsupervised Feature Transformation via In-context Generation, Generator-critic LLM Agents, and Duet-play Teaming](https://arxiv.org//abs/2504.21304)

	Nanxu Gong, Xinyuan Wang, Wangyang Ying, Haoyue Bai, Sixun Dong, Haifeng Chen, Yanjie Fu

+ [Traceback of Poisoning Attacks to Retrieval-Augmented Generation](https://arxiv.org//abs/2504.21668)

	Baolei Zhang, Haoran Xin, Minghong Fang, Zhuqing Liu, Biao Yi, Tong Li, Zheli Liu

+ [Hoist with His Own Petard: Inducing Guardrails to Facilitate Denial-of-Service Attacks on Retrieval-Augmented Generation of LLMs](https://arxiv.org//abs/2504.21680)

	Pan Suo, Yu-Ming Shang, San-Chuan Guo, Xi Zhang

+ [RAIL in the Wild: Operationalizing Responsible AI Evaluation Using Anthropic's Value Dataset](https://arxiv.org//abs/2505.00204)

	Sumit Verma, Pritam Prasun, Arpit Jaiswal, Pritish Kumar

+ [Between Underthinking and Overthinking: An Empirical Study of Reasoning Length and correctness in LLMs](https://arxiv.org//abs/2505.00127)

	Jinyan Su, Jennifer Healey, Preslav Nakov, Claire Cardie

+ [Enhancing Security and Strengthening Defenses in Automated Short-Answer Grading Systems](https://arxiv.org//abs/2505.00061)

	Sahar Yarmohammadtoosky, Yiyun Zhou, Victoria Yaneva, Peter Baldwin, Saed Rezayi, Brian Clauser, Polina Harikeo

+ [GDI-Bench: A Benchmark for General Document Intelligence with Vision and Reasoning Decoupling](https://arxiv.org//abs/2505.00063)

	Siqi Li, Yufan Shen, Xiangnan Chen, Jiayi Chen, Hengwei Ju, Haodong Duan, Song Mao, Hongbin Zhou, Bo Zhang, Pinlong Cai, Licheng Wen, Botian Shi, Yong Liu, Xinyu Cai, Yu Qiao

+ [ConSens: Assessing context grounding in open-book question answering](https://arxiv.org//abs/2505.00065)

	Ivan Vankov, Matyo Ivanov, Adriana Correia, Victor Botev

+ [Humanizing LLMs: A Survey of Psychological Measurements with Tools, Datasets, and Human-Agent Applications](https://arxiv.org//abs/2505.00049)

	Wenhan Dong, Yuemeng Zhao, Zhen Sun, Yule Liu, Zifan Peng, Jingyi Zheng, Zongmin Zhang, Ziyi Zhang, Jun Wu, Ruiming Wang, Shengmin Xu, Xinyi Huang, Xinlei He

+ [Optimization of embeddings storage for RAG systems using quantization and dimensionality reduction techniques](https://arxiv.org//abs/2505.00105)

	Naamán Huerga-Pérez, Rubén Álvarez, Rubén Ferrero-Guillén, Alberto Martínez-Gutiérrez, Javier Díez-González

+ [Which Agent Causes Task Failures and When? On Automated Failure Attribution of LLM Multi-Agent Systems](https://arxiv.org//abs/2505.00212)

	Shaokun Zhang, Ming Yin, Jieyu Zhang, Jiale Liu, Zhiguang Han, Jingyang Zhang, Beibin Li, Chi Wang, Huazheng Wang, Yiran Chen, Qingyun Wu

+ [Zoomer: Adaptive Image Focus Optimization for Black-box MLLM](https://arxiv.org//abs/2505.00742)

	Jiaxu Qian, Chendong Wang, Yifan Yang, Chaoyun Zhang, Huiqiang Jiang, Xufang Luo, Yu Kang, Qingwei Lin, Anlan Zhang, Shiqi Jiang, Ting Cao, Tianjun Mao, Suman Banerjee, Guyue Liu, Saravan Rajmohan, Dongmei Zhang, Yuqing Yang, Qi Zhang, Lili Qiu

+ [Localizing Before Answering: A Benchmark for Grounded Medical Visual Question Answering](https://arxiv.org//abs/2505.00744)

	Dung Nguyen, Minh Khoi Ho, Huy Ta, Thanh Tam Nguyen, Qi Chen, Kumar Rav, Quy Duong Dang, Satwik Ramchandre, Son Lam Phung, Zhibin Liao, Minh-Son To, Johan Verjans, Phi Le Nguyen, Vu Minh Hieu Phan

+ [Entropy Heat-Mapping: Localizing GPT-Based OCR Errors with Sliding-Window Shannon Analysis](https://arxiv.org//abs/2505.00746)

	Alexei Kaltchenko

+ [COSMOS: Predictable and Cost-Effective Adaptation of LLMs](https://arxiv.org//abs/2505.01449)

	Jiayu Wang, Aws Albarghouthi, Frederic Sala

+ [Calibrating Uncertainty Quantification of Multi-Modal LLMs using Grounding](https://arxiv.org//abs/2505.03788)

	Trilok Padhi, Ramneet Kaur, Adam D. Cobb, Manoj Acharya, Anirban Roy, Colin Samplawski, Brian Matejek, Alexander M. Berenbeim, Nathaniel D. Bastian, Susmit Jha

+ [When Reasoning Beats Scale: A 1.5B Reasoning Model Outranks 13B LLMs as Discriminator](https://arxiv.org//abs/2505.03786)

	Md Fahim Anjum

+ [ALFRED: Ask a Large-language model For Reliable ECG Diagnosis](https://arxiv.org//abs/2505.03781)

	Jin Yu, JaeHo Park, TaeJun Park, Gyurin Kim, JiHyun Lee, Min Sung Lee, Joon-myoung Kwon, Jeong Min Son, Yong-Yeon Jo

+ [mAIstro: an open-source multi-agentic system for automated end-to-end development of radiomics and deep learning models for medical imaging](https://arxiv.org//abs/2505.03785)

	Eleftherios Tzanis, Michail E. Klontzas

+ [Polysemy of Synthetic Neurons Towards a New Type of Explanatory Categorical Vector Spaces](https://arxiv.org//abs/2505.07831)

	Michael Pichat, William Pogrund, Paloma Pichat, Judicael Poumay, Armanouche Gasparian, Samuel Demarchi, Martin Corbet, Alois Georgeon, Michael Veillet-Guillem

+ [SWE-smith: Scaling Data for Software Engineering Agents](https://arxiv.org//abs/2504.21798)

	John Yang, Kilian Leret, Carlos E. Jimenez, Alexander Wettig, Kabir Khandpur, Yanzhe Zhang, Binyuan Hui, Ofir Press, Ludwig Schmidt, Diyi Yang

# 2025-04-29
+ [TAMO:Fine-Grained Root Cause Analysis via Tool-Assisted LLM Agent with Multi-Modality Observation Data](https://arxiv.org//abs/2504.20462)

	Qi Wang, Xiao Zhang, Mingyi Li, Yuan Yuan, Mengbai Xiao, Fuzhen Zhuang, Dongxiao Yu

+ [A Summary on GUI Agents with Foundation Models Enhanced by Reinforcement Learning](https://arxiv.org//abs/2504.20464)

	Jiahao Li, Kaer Huang

+ [ReasonIR: Training Retrievers for Reasoning Tasks](https://arxiv.org//abs/2504.20595)

	Rulin Shao, Rui Qiao, Varsha Kishore, Niklas Muennighoff, Xi Victoria Lin, Daniela Rus, Bryan Kian Hsiang Low, Sewon Min, Wen-tau Yih, Pang Wei Koh, Luke Zettlemoyer

+ [PaRT: Enhancing Proactive Social Chatbots with Personalized Real-Time Retrieval](https://arxiv.org//abs/2504.20624)

	Zihan Niu, Zheyong Xie, Shaosheng Cao, Chonggang Lu, Zheyu Ye, Tong Xu, Zuozhu Liu, Yan Gao, Jia Chen, Zhe Xu, Yi Wu, Yao Hu

+ [Ascendra: Dynamic Request Prioritization for Efficient LLM Serving](https://arxiv.org//abs/2504.20828)

	Azam Ikram, Xiang Li, Sameh Elnikety, Saurabh Bagchi

+ [The Leaderboard Illusion](https://arxiv.org//abs/2504.20879)

	Shivalika Singh, Yiyang Nan, Alex Wang, Daniel D'Souza, Sayash Kapoor, Ahmet Üstün, Sanmi Koyejo, Yuntian Deng, Shayne Longpre, Noah Smith, Beyza Ermis, Marzieh Fadaee, Sara Hooker

+ [CBM-RAG: Demonstrating Enhanced Interpretability in Radiology Report Generation with Multi-Agent RAG and Concept Bottleneck Models](https://arxiv.org//abs/2504.20898)

	Hasan Md Tusfiqur Alam, Devansh Srivastav, Abdulrahman Mohamed Selim, Md Abdul Kadir, Md Moktadiurl Hoque Shuvo, Daniel Sonntag

+ [ChestX-Reasoner: Advancing Radiology Foundation Models with Reasoning through Step-by-Step Verification](https://arxiv.org//abs/2504.20930)

	Ziqing Fan, Cheng Liang, Chaoyi Wu, Ya Zhang, Yanfeng Wang, Weidi Xie

+ [Jekyll-and-Hyde Tipping Point in an AI's Behavior](https://arxiv.org//abs/2504.20980)

	Neil F. Johnson, Frank Yingjie Huo

+ [Local Prompt Optimization](https://arxiv.org//abs/2504.20355)

	Yash Jain, Vishal Chowdhary

+ [ARCS: Agentic Retrieval-Augmented Code Synthesis with Iterative Refinement](https://arxiv.org//abs/2504.20434)

	Manish Bhattarai, Miguel Cordova, Javier Santos, Dan O'Malley

+ [On Psychology of AI -- Does Primacy Effect Affect ChatGPT and Other LLMs?](https://arxiv.org//abs/2504.20444)

	Mika Hämäläinen

+ [Token-Efficient Prompt Injection Attack: Provoking Cessation in LLM Reasoning via Adaptive Token Compression](https://arxiv.org//abs/2504.20493)

	Yu Cui, Yujun Cai, Yiwei Wang

+ [Reinforcement Learning for Reasoning in Large Language Models with One Training Example](https://arxiv.org//abs/2504.20571)

	Yiping Wang, Qing Yang, Zhiyuan Zeng, Liliang Ren, Lucas Liu, Baolin Peng, Hao Cheng, Xuehai He, Kuan Wang, Jianfeng Gao, Weizhu Chen, Shuohang Wang, Simon Shaolei Du, Yelong Shen

+ [Information Retrieval in the Age of Generative AI: The RGB Model](https://arxiv.org//abs/2504.20610)

	Michele Garetto, Alessandro Cornacchia, Franco Galante, Emilio Leonardi, Alessandro Nordio, Alberto Tarable

+ [The Hidden Risks of LLM-Generated Web Application Code: A Security-Centric Evaluation of Code Generation Capabilities in Large Language Models](https://arxiv.org//abs/2504.20612)

	Swaroop Dora, Deven Lunkad, Naziya Aslam, S. Venkatesan, Sandeep Kumar Shukla

+ [Cooking Up Creativity: A Cognitively-Inspired Approach for Enhancing LLM Creativity through Structured Representations](https://arxiv.org//abs/2504.20643)

	Moran Mizrahi, Chen Shani, Gabriel Stanovsky, Dan Jurafsky, Dafna Shahaf

+ [CoCo-Bench: A Comprehensive Code Benchmark For Multi-task Large Language Model Evaluation](https://arxiv.org//abs/2504.20673)

	Wenjing Yin, Tianze Sun, Yijiong Yu, Jiawei Fang, Guangyao Su, Jiancheng Wang, Zekun Wang, Wei Wang, Ran Chen, Ziyun Dai, Shuai Yuan, Menghang Dong, Peng Luo, Dong Cao, Da Lei, Yajun Zhang, Hao Chen, Xiang Ma, Yong Liu, Weifeng Liu, Yuanjian Xu, Ji Pei

+ [Can LLMs Detect Intrinsic Hallucinations in Paraphrasing and Machine Translation?](https://arxiv.org//abs/2504.20699)

	Evangelia Gogoulou, Shorouq Zahra, Liane Guillou, Luise Dürlich, Joakim Nivre

+ [Beyond the Last Answer: Your Reasoning Trace Uncovers More than You Think](https://arxiv.org//abs/2504.20708)

	Hasan Abed Al Kader Hammoud, Hani Itani, Bernard Ghanem

+ [UniversalRAG: Retrieval-Augmented Generation over Multiple Corpora with Diverse Modalities and Granularities](https://arxiv.org//abs/2504.20734)

	Woongyeong Yeo, Kangsan Kim, Soyeong Jeong, Jinheon Baek, Sung Ju Hwang

+ [Grokking in the Wild: Data Augmentation for Real-World Multi-Hop Reasoning with Transformers](https://arxiv.org//abs/2504.20752)

	Roman Abramov, Felix Steinbauer, Gjergji Kasneci

+ [Chain-of-Defensive-Thought: Structured Reasoning Elicits Robustness in Large Language Models against Reference Corruption](https://arxiv.org//abs/2504.20769)

	Wenxiao Wang, Parsa Hosseini, Soheil Feizi

+ [Using LLMs in Generating Design Rationale for Software Architecture Decisions](https://arxiv.org//abs/2504.20781)

	Xiyu Zhou, Ruiyin Li, Peng Liang, Beiqi Zhang, Mojtaba Shahin, Zengyang Li, Chen Yang

+ [Hallucination by Code Generation LLMs: Taxonomy, Benchmarks, Mitigation, and Challenges](https://arxiv.org//abs/2504.20799)

	Yunseo Lee, John Youngeun Song, Dongsun Kim, Jindae Kim, Mijung Kim, Jaechang Nam

+ [Reinforcement Learning for LLM Reasoning Under Memory Constraints](https://arxiv.org//abs/2504.20834)

	Alan Lee, Harry Tong

+ [DYNAMAX: Dynamic computing for Transformers and Mamba based architectures](https://arxiv.org//abs/2504.20922)

	Miguel Nogales, Matteo Gambella, Manuel Roveri

+ [Trace-of-Thought: Enhanced Arithmetic Problem Solving via Reasoning Distillation From Large to Small Language Models](https://arxiv.org//abs/2504.20946)

	Tyler McDonald, Ali Emami

+ [OSVBench: Benchmarking LLMs on Specification Generation Tasks for Operating System Verification](https://arxiv.org//abs/2504.20964)

	Shangyu Li, Juyong Jiang, Tiancheng Zhao, Jiasi Shen

+ [Toward Efficient Exploration by Large Language Model Agents](https://arxiv.org//abs/2504.20997)

	Dilip Arumugam, Thomas L. Griffiths

+ [What Causes Knowledge Loss in Multilingual Language Models?](https://arxiv.org//abs/2504.20356)

	Maria Khelli, Samuel Cahyawijaya, Ayu Purwarianti, Genta Indra Winata

+ [DMDTEval: An Evaluation and Analysis of LLMs on Disambiguation in Multi-domain Translation](https://arxiv.org//abs/2504.20371)

	Zhibo Man, Yuanmeng Chen, Yujie Zhang, Yufeng Chen, Jinan Xu

+ [Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training](https://arxiv.org//abs/2504.20484)

	Linjuan Wu, Haoran Wei, Huan Lin, Tianhao Li, Baosong Yang, Weiming Lu

+ [UniDetox: Universal Detoxification of Large Language Models via Dataset Distillation](https://arxiv.org//abs/2504.20500)

	Huimin Lu, Masaru Isonuma, Junichiro Mori, Ichiro Sakata

+ [Turing Machine Evaluation for Large Language Model](https://arxiv.org//abs/2504.20771)

	Haitao Wu, Zongbo Han, Huaxi Huang, Changqing Zhang

+ [Information Gravity: A Field-Theoretic Model for Token Selection in Large Language Models](https://arxiv.org//abs/2504.20951)

	Maryna Vyshnyvetska

+ [SetKE: Knowledge Editing for Knowledge Elements Overlap](https://arxiv.org//abs/2504.20972)

	Yifan Wei, Xiaoyan Yu, Ran Song, Hao Peng, Angsheng Li

+ [Reviving Any-Subset Autoregressive Models with Principled Parallel Sampling and Speculative Decoding](https://arxiv.org//abs/2504.20456)

	Gabe Guo, Stefano Ermon

+ [Towards Understanding the Nature of Attention with Low-Rank Sparse Decomposition](https://arxiv.org//abs/2504.20938)

	Zhengfu He, Junxuan Wang, Rui Lin, Xuyang Ge, Wentao Shu, Qiong Tang, Junping Zhang, Xipeng Qiu

+ [Antidote: A Unified Framework for Mitigating LVLM Hallucinations in Counterfactual Presupposition and Object Perception](https://arxiv.org//abs/2504.20468)

	Yuanchen Wu, Lu Zhang, Hang Yao, Junlong Du, Ke Yan, Shouhong Ding, Yunsheng Wu, Xiaoqiang Li

+ [X-Fusion: Introducing New Modality to Frozen Large Language Models](https://arxiv.org//abs/2504.20996)

	Sicheng Mo, Thao Nguyen, Xun Huang, Siddharth Srinivasan Iyer, Yijun Li, Yuchen Liu, Abhishek Tandon, Eli Shechtman, Krishna Kumar Singh, Yong Jae Lee, Bolei Zhou, Yuheng Li

+ [Combatting Dimensional Collapse in LLM Pre-Training Data via Diversified File Selection](https://arxiv.org//abs/2504.20644)

	Ziqing Fan, Siyuan Du, Shengchao Hu, Pingjie Wang, Li Shen, Ya Zhang, Dacheng Tao, Yanfeng Wang

+ [AegisLLM: Scaling Agentic Systems for Self-Reflective Defense in LLM Security](https://arxiv.org//abs/2504.20965)

	Zikui Cai, Shayan Shabihi, Bang An, Zora Che, Brian R. Bartoldson, Bhavya Kailkhura, Tom Goldstein, Furong Huang

+ [Softpick: No Attention Sink, No Massive Activations with Rectified Softmax](https://arxiv.org//abs/2504.20966)

	Zayd M. K. Zuhri, Erland Hilman Fuadi, Alham Fikri Aji

+ [ACE: A Security Architecture for LLM-Integrated App Systems](https://arxiv.org//abs/2504.20984)

	Evan Li, Tushin Mallick, Evan Rose, William Robertson, Alina Oprea, Cristina Nita-Rotaru

+ [Enhancing Leakage Attacks on Searchable Symmetric Encryption Using LLM-Based Synthetic Data Generation](https://arxiv.org//abs/2504.20414)

	Joshua Chiu, Partha Protim Paul, Zahin Wahab

+ [Robustness via Referencing: Defending against Prompt Injection Attacks by Referencing the Executed Instruction](https://arxiv.org//abs/2504.20472)

	Yulin Chen, Haoran Li, Yuan Sui, Yue Liu, Yufei He, Yangqiu Song, Bryan Hooi

+ [ReCIT: Reconstructing Full Private Data from Gradient in Parameter-Efficient Fine-Tuning of Large Language Models](https://arxiv.org//abs/2504.20570)

	Jin Xie, Ruishi He, Songze Li, Xiaojun Jia, Shouling Ji

+ [Unlocking User-oriented Pages: Intention-driven Black-box Scanner for Real-world Web Applications](https://arxiv.org//abs/2504.20801)

	Weizhe Wang, Yao Zhang, Kaitai Liang, Guangquan Xu, Hongpeng Bai, Qingyang Yan, Xi Zheng, Bin Wu

+ [Secure Coding with AI, From Creation to Inspection](https://arxiv.org//abs/2504.20814)

	Vladislav Belozerov, Peter J Barclay, Ashkan Sami

+ [NeuRel-Attack: Neuron Relearning for Safety Disalignment in Large Language Models](https://arxiv.org//abs/2504.21053)

	Yi Zhou, Wenpeng Xing, Dezhang Kong, Changting Lin, Meng Han

+ [Erased but Not Forgotten: How Backdoors Compromise Concept Erasure](https://arxiv.org//abs/2504.21072)

	Jonas Henry Grebe, Tobias Braun, Marcus Rohrbach, Anna Rohrbach

+ [TT-LoRA MoE: Unifying Parameter-Efficient Fine-Tuning and Sparse Mixture-of-Experts](https://arxiv.org//abs/2504.21190)

	Pradip Kunwar, Minh N. Vu, Maanak Gupta, Mahmoud Abdelsalam, Manish Bhattarai

+ [Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice for Specialized Applications in Healthcare](https://arxiv.org//abs/2504.21191)

	Lovedeep Gondara, Jonathan Simkin, Graham Sayle, Shebnum Devji, Gregory Arbour, Raymond Ng

+ [SecRepoBench: Benchmarking LLMs for Secure Code Generation in Real-World Repositories](https://arxiv.org//abs/2504.21205)

	Connor Dilgren, Purva Chiniya, Luke Griffith, Yu Ding, Yizheng Chen

+ [CachePrune: Neural-Based Attribution Defense Against Indirect Prompt Injection Attacks](https://arxiv.org//abs/2504.21228)

	Rui Wang, Junda Wu, Yu Xia, Tong Yu, Ruiyi Zhang, Ryan Rossi, Lina Yao, Julian McAuley

+ [LLM Enhancer: Merged Approach using Vector Embedding for Reducing Large Language Model Hallucinations with External Knowledge](https://arxiv.org//abs/2504.21132)

	Naheed Rayhan, Md. Ashrafuzzaman

+ [Detecting Manipulated Contents Using Knowledge-Grounded Inference](https://arxiv.org//abs/2504.21165)

	Mark Huasong Meng, Ruizhe Wang, Meng Xu, Chuan Yan, Guangdong Bai

+ [Efficient LLMs with AMP: Attention Heads and MLP Pruning](https://arxiv.org//abs/2504.21174)

	Leandro Giusti Mugnaini, Bruno Lopes Yamamoto, Lucas Lauton de Alcantara, Victor Zacarias, Edson Bollis, Lucas Pellicer, Anna Helena Reali Costa, Artur Jordao

+ [Graph Synthetic Out-of-Distribution Exposure with Large Language Models](https://arxiv.org//abs/2504.21198)

	Haoyan Xu, Zhengtao Yao, Ziyi Wang, Zhan Cheng, Xiyang Hu, Mengyuan Li, Yue Zhao

+ [A Domain-Agnostic Scalable AI Safety Ensuring Framework](https://arxiv.org//abs/2504.20924)

	Beomjun Kim, Kangyeon Kim, Sunwoo Kim, Heejin Ahn

+ [A Framework to Assess the Persuasion Risks Large Language Model Chatbots Pose to Democratic Societies](https://arxiv.org//abs/2505.00036)

	Zhongren Chen, Joshua Kalla, Quan Le, Shinpei Nakamura-Sakai, Jasjeet Sekhon, Ruixiao Wang

+ [HyPerAlign: Hypotheses-driven Personalized Alignment](https://arxiv.org//abs/2505.00038)

	Cristina Garbacea, Chenhao Tan

+ [Graph RAG for Legal Norms: A Hierarchical and Temporal Approach](https://arxiv.org//abs/2505.00039)

	Hudson de Martim

+ [Improving Phishing Email Detection Performance of Small Large Language Models](https://arxiv.org//abs/2505.00034)

	Zijie Lin, Zikang Liu, Hanbo Fan

# 2025-04-28
+ [GVPO: Group Variance Policy Optimization for Large Language Model Post-Training](https://arxiv.org//abs/2504.19599)

	Kaichen Zhang, Yuzhong Hong, Junwei Bao, Hongfei Jiang, Yang Song, Dingqian Hong, Hui Xiong

+ [From Evidence to Belief: A Bayesian Epistemology Approach to Language Models](https://arxiv.org//abs/2504.19622)

	Minsu Kim, Sangryul Kim, James Thorne

+ [From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review](https://arxiv.org//abs/2504.19678)

	Mohamed Amine Ferrag, Norbert Tihanyi, Merouane Debbah

+ [Can AI Agents Design and Implement Drug Discovery Pipelines?](https://arxiv.org//abs/2504.19912)

	Khachik Smbatyan, Tsolak Ghukasyan, Tigran Aghajanyan, Hovhannes Dabaghyan, Sergey Adamyan, Aram Bughdaryan, Vahagn Altunyan, Gagik Navasardyan, Aram Davtyan, Anush Hakobyan, Aram Gharibyan, Arman Fahradyan, Artur Hakobyan, Hasmik Mnatsakanyan, Narek Ginoyan, Garik Petrosyan

+ [TreeHop: Generate and Filter Next Query Embeddings Efficiently for Multi-hop Question Answering](https://arxiv.org//abs/2504.20114)

	Zhonghao Li, Kunpeng Zhang, Jinghuai Ou, Shuliang Liu, Xuming Hu

+ [AutoP2C: An LLM-Based Agent Framework for Code Repository Generation from Multimodal Content in Academic Papers](https://arxiv.org//abs/2504.20115)

	Zijie Lin, Yiqing Shen, Qilin Cai, He Sun, Jinrui Zhou, Mingjun Xiao

+ [ResearchCodeAgent: An LLM Multi-Agent System for Automated Codification of Research Methodologies](https://arxiv.org//abs/2504.20117)

	Shubham Gandhi, Dhruv Shah, Manasi Patwardhan, Lovekesh Vig, Gautam Shroff

+ [OpenTCM: A GraphRAG-Empowered LLM-based System for Traditional Chinese Medicine Knowledge Retrieval and Diagnosis](https://arxiv.org//abs/2504.20118)

	Jinglin He, Yunqi Guo, Lai Kwan Lam, Waikei Leung, Lixing He, Yuanan Jiang, Chi Chiu Wang, Guoliang Xing, Hongkai Chen

+ [Can LLMs Be Trusted for Evaluating RAG Systems? A Survey of Methods and Datasets](https://arxiv.org//abs/2504.20119)

	Lorenz Brehme, Thomas Ströhle, Ruth Breu

+ [LZ Penalty: An information-theoretic repetition penalty for autoregressive language models](https://arxiv.org//abs/2504.20131)

	Antonio A. Ginart, Naveen Kodali, Jason Lee, Caiming Xiong, Silvio Savarese, John R. Emmons

+ [MICE for CATs: Model-Internal Confidence Estimation for Calibrating Agents with Tools](https://arxiv.org//abs/2504.20168)

	Nishant Subramani, Jason Eisner, Justin Svegliato, Benjamin Van Durme, Yu Su, Sam Thomson

+ [BLADE: Benchmark suite for LLM-driven Automated Design and Evolution of iterative optimisation heuristics](https://arxiv.org//abs/2504.20183)

	Niki van Stein, Anna V. Kononova, Haoran Yin, Thomas Bäck

+ [Prompting LLMs for Code Editing: Struggles and Remedies](https://arxiv.org//abs/2504.20196)

	Daye Nam, Ahmed Omran, Ambar Murillo, Saksham Thakur, Abner Araujo, Marcel Blistein, Alexander Frömmgen, Vincent Hellendoorn, Satish Chandra

+ [Can Large Language Models Learn Formal Logic? A Data-Driven Training and Evaluation Framework](https://arxiv.org//abs/2504.20213)

	Yuan Xia, Akanksha Atrey, Fadoua Khmaissia, Kedar S. Namjoshi

+ [Toward Evaluative Thinking: Meta Policy Optimization with Evolving Reward Models](https://arxiv.org//abs/2504.20157)

	Zae Myung Kim, Chanwoo Park, Vipul Raheja, Dongyeop Kang

+ [LLM-Generated Fake News Induces Truth Decay in News Ecosystem: A Case Study on Neural News Recommendation](https://arxiv.org//abs/2504.20013)

	Beizhe Hu, Qiang Sheng, Juan Cao, Yang Li, Danding Wang

+ [Investigating task-specific prompts and sparse autoencoders for activation monitoring](https://arxiv.org//abs/2504.20271)

	Henk Tillman, Dan Mossing

+ [Security Steerability is All You Need](https://arxiv.org//abs/2504.19521)

	Itay Hazan, Idan Habler, Ron Bitton, Itsik Mantin

+ [The Automation Advantage in AI Red Teaming](https://arxiv.org//abs/2504.19855)

	Rob Mulla, Ads Dawson, Vincent Abruzzon, Brian Greunke, Nick Landers, Brad Palm, Will Pearce

+ [Can Differentially Private Fine-tuning LLMs Protect Against Privacy Attacks?](https://arxiv.org//abs/2504.21036)

	Hao Du, Shang Liu, Yang Cao

+ [Prefill-Based Jailbreak: A Novel Approach of Bypassing LLM Safety Boundary](https://arxiv.org//abs/2504.21038)

	Yakai Li, Jiekang Hu, Weiduan Sang, Luping Ma, Jing Xie, Weijuan Zhang, Aimin Yu, Shijie Zhao, Qingjia Huang, Qihang Zhou

+ [Llama-3.1-FoundationAI-SecurityLLM-Base-8B Technical Report](https://arxiv.org//abs/2504.21039)

	Paul Kassianik, Baturay Saglam, Alexander Chen, Blaine Nelson, Anu Vellore, Massimo Aufiero, Fraser Burch, Dhruv Kedia, Avi Zohary, Sajana Weerawardhena, Aman Priyanshu, Adam Swanda, Amy Chang, Hyrum Anderson, Kojin Oshiba, Omar Santos, Yaron Singer, Amin Karbasi

+ [What's Pulling the Strings? Evaluating Integrity and Attribution in AI Training and Inference through Concept Shift](https://arxiv.org//abs/2504.21042)

	Jiamin Chang, Haoyang Li, Hammond Pearce, Ruoxi Sun, Bo Li, Minhui Xue

+ [CodeBC: A More Secure Large Language Model for Smart Contract Code Generation in Blockchain](https://arxiv.org//abs/2504.21043)

	Lingxiang wang, Hainan Zhang, Qinnan Zhang, Ziwei Wang, Hongwei Zheng, Jin Dong, Zhiming Zheng

+ [AGATE: Stealthy Black-box Watermarking for Multimodal Model Copyright Protection](https://arxiv.org//abs/2504.21044)

	Jianbo Gao, Keke Gai, Jing Yu, Liehuang Zhu, Qi Wu

+ [Leveraging LLM to Strengthen ML-Based Cross-Site Scripting Detection](https://arxiv.org//abs/2504.21045)

	Dennis Miczek, Divyesh Gabbireddy, Suman Saha

+ [Learning to Plan Before Answering: Self-Teaching LLMs to Learn Abstract Plans for Problem Solving](https://arxiv.org//abs/2505.00031)

	Jin Zhang, Flood Sung, Zhilin Yang, Yang Gao, Chongjie Zhang

+ [BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text](https://arxiv.org//abs/2504.19467)

	Jiageng Wu, Bowen Gu, Ren Zhou, Kevin Xie, Doug Snyder, Yixing Jiang, Valentina Carducci, Richard Wyss, Rishi J Desai, Emily Alsentzer, Leo Anthony Celi, Adam Rodman, Sebastian Schneeweiss, Jonathan H. Chen, Santiago Romero-Brufau, Kueiyu Joshua Lin, Jie Yang

+ [Agentic Reasoning and Tool Integration for LLMs via Reinforcement Learning](https://arxiv.org//abs/2505.01441)

	Joykirat Singh, Raghav Magazine, Yash Pandya, Akshay Nambi

+ [Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents](https://arxiv.org//abs/2504.19956)

	Vineeth Sai Narajala, Om Narayan

+ [Accurate and Diverse LLM Mathematical Reasoning via Automated PRM-Guided GFlowNets](https://arxiv.org//abs/2504.19981)

	Adam Younsi, Abdalgader Abubaker, Mohamed El Amine Seddik, Hakim Hacid, Salem Lahlou

+ [Graph-Based Spectral Decomposition for Parameter Coordination in Language Model Fine-Tuning](https://arxiv.org//abs/2504.19583)

	Hanlu Zhang, Yumeng Ma, Shuo Wang, Guiran Liu, Binrong Zhu

+ [m-KAILIN: Knowledge-Driven Agentic Scientific Corpus Distillation Framework for Biomedical Large Language Models Training](https://arxiv.org//abs/2504.19565)

	Meng Xiao, Xunxin Cai, Qingqing Long, Chengrui Wang, Yuanchun Zhou, Hengshu Zhu

# 2025-04-27
+ [GenTorrent: Scaling Large Language Model Serving with An Overley Network](https://arxiv.org//abs/2504.20101)

	Fei Fang, Yifan Hua, Shengze Wang, Ruilin Zhou, Yi Liu, Chen Qian, Xiaoxue Zhang

+ [Adaptive Helpfulness-Harmlessness Alignment with Preference Vectors](https://arxiv.org//abs/2504.20106)

	Ren-Wei Liang, Chin-Ting Hsu, Chan-Hung Yu, Saransh Agrawal, Shih-Cheng Huang, Shang-Tse Chen, Kuan-Hao Huang, Shao-Hua Sun

+ [Unified Multi-Task Learning & Model Fusion for Efficient Language Model Guardrailing](https://arxiv.org//abs/2504.19333)

	James O' Neill, Santhosh Subramanian, Eric Lin, Vaikkunth Mugunthan

+ [Doxing via the Lens: Revealing Privacy Leakage in Image Geolocation for Agentic Multi-Modal Large Reasoning Model](https://arxiv.org//abs/2504.19373)

	Weidi Luo, Qiming Zhang, Tianyu Lu, Xiaogeng Liu, Yue Zhao, Zhen Xiang, Chaowei Xiao

+ [Selecting the Right LLM for eGov Explanations](https://arxiv.org//abs/2504.21032)

	Lior Limonad, Fabiana Fournier, Hadar Mulian, George Manias, Spiros Borotis, Danai Kyrkou

+ [SAGA: A Security Architecture for Governing AI Agentic Systems](https://arxiv.org//abs/2504.21034)

	Georgios Syros, Anshuman Suri, Cristina Nita-Rotaru, Alina Oprea

+ [Uncertainty Quantification for Language Models: A Suite of Black-Box, White-Box, LLM Judge, and Ensemble Scorers](https://arxiv.org//abs/2504.19254)

	Dylan Bouchard, Mohit Singh Chauhan

+ [Contextual Online Uncertainty-Aware Preference Learning for Human Feedback](https://arxiv.org//abs/2504.19342)

	Nan Lu, Ethan X. Fang, Junwei Lu

+ [Enhancing Speech-to-Speech Dialogue Modeling with End-to-End Retrieval-Augmented Generation](https://arxiv.org//abs/2505.00028)

	Pengchao Feng, Ziyang Ma, Wenxi Chen, Yao Li, Sheng Wang, Kai Yu, Xie Chen

+ [BrowseComp-ZH: Benchmarking Web Browsing Ability of Large Language Models in Chinese](https://arxiv.org//abs/2504.19314)

	Peilin Zhou, Bruce Leon, Xiang Ying, Can Zhang, Yifan Shao, Qichen Ye, Dading Chong, Zhiling Jin, Chenxuan Xie, Meng Cao, Yuxin Gu, Sixin Hong, Jing Ren, Jian Chen, Chao Liu, Yining Hua

+ [VIST-GPT: Ushering in the Era of Visual Storytelling with LLMs?](https://arxiv.org//abs/2504.19267)

	Mohamed Gado, Towhid Taliee, Muhammad Memon, Dmitry Ignatov, Radu Timofte

+ [SPC: Evolving Self-Play Critic via Adversarial Games for LLM Reasoning](https://arxiv.org//abs/2504.19162)

	Jiaqi Chen, Bang Zhang, Ruotian Ma, Peisong Wang, Xiaodan Liang, Zhaopeng Tu, Xiaolong Li, Kwan-Yee K. Wong

+ [TeleSparse: Practical Privacy-Preserving Verification of Deep Neural Networks](https://arxiv.org//abs/2504.19274)

	Mohammad M Maheri, Hamed Haddadi, Alex Davidson

+ [Efficient Reasoning for LLMs through Speculative Chain-of-Thought](https://arxiv.org//abs/2504.19095)

	Jikai Wang, Juntao Li, Jianye Hou, Bowen Yan, Lijun Wu, Min Zhang

# 2025-04-26
+ [A Vision for Auto Research with LLM Agents](https://arxiv.org//abs/2504.18765)

	Chengwei Liu, Chong Wang, Jiayue Cao, Jingquan Ge, Kun Wang, Lvye Zhang, Ming-Ming Cheng, Penghai Zhao, Tianlin Li, Xiaojun Jia, Xiang Li, Xinfeng Li, Yang Liu, Yebo Feng, Yihao Huang, Yijia Xu, Yuqiang Sun, Zhenhong Zhou, Zhengzi Xu

+ [Generative to Agentic AI: Survey, Conceptualization, and Challenges](https://arxiv.org//abs/2504.18875)

	Johannes Schneider

+ [MATCHA: Can Multi-Agent Collaboration Build a Trustworthy Conversational Recommender?](https://arxiv.org//abs/2504.20094)

	Zheng Hui, Xiaokai Wei, Yexi Jiang, Kevin Gao, Chen Wang, Frank Ong, Se-eun Yoon, Rachit Pareek, Michelle Gong

+ [PICO: Secure Transformers via Robust Prompt Isolation and Cybersecurity Oversight](https://arxiv.org//abs/2504.21029)

	Ben Goertzel, Paulos Yibelo

+ [SynLexLM: Scaling Legal LLMs with Synthetic Data and Curriculum Learning](https://arxiv.org//abs/2504.18762)

	Ojasw Upadhyay, Abishek Saravanakumar, Ayman Ismail

+ [Theory of Mind in Large Language Models: Assessment and Enhancement](https://arxiv.org//abs/2505.00026)

	Ruirui Chen, Weifeng Jiang, Chengwei Qin, Cheston Tan

+ [Building Scalable AI-Powered Applications with Cloud Databases: Architectures, Best Practices and Performance Considerations](https://arxiv.org//abs/2504.18793)

	Santosh Bhupathi

+ [Test It Before You Trust It: Applying Software Testing for Trustworthy In-context Learning](https://arxiv.org//abs/2504.18827)

	Teeradaj Racharak, Chaiyong Ragkhitwetsagul, Chommakorn Sontesadisai, Thanwadee Sunetnanta

+ [A Simple Ensemble Strategy for LLM Inference: Towards More Stable Text Classification](https://arxiv.org//abs/2504.18884)

	Junichiro Niimi

+ [Detect, Explain, Escalate: Low-Carbon Dialogue Breakdown Management for LLM-Powered Agents](https://arxiv.org//abs/2504.18839)

	Abdellah Ghassel, Xianzhi Li, Xiaodan Zhu

# 2025-04-25
+ [MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind](https://arxiv.org//abs/2504.18039)

	Zheng Zhang, Nuoqian Xiao, Qi Chai, Deheng Ye, Hao Wang

+ [Reason Like a Radiologist: Chain-of-Thought and Reinforcement Learning for Verifiable Report Generation](https://arxiv.org//abs/2504.18453)

	Peiyuan Jing, Kinhei Lee, Zhenxuan Zhang, Huichi Zhou, Zhengqing Yuan, Zhifan Gao, Lei Zhu, Giorgos Papanastasiou, Yingying Fang, Guang Yang

+ [Scaling Laws For Scalable Oversight](https://arxiv.org//abs/2504.18530)

	Joshua Engels, David D. Baek, Subhash Kantamneni, Max Tegmark

+ [RAG LLMs are Not Safer: A Safety Analysis of Retrieval-Augmented Generation for Large Language Models](https://arxiv.org//abs/2504.18041)

	Bang An, Shiyue Zhang, Mark Dredze

+ [PropRAG: Guiding Retrieval with Beam Search over Proposition Paths](https://arxiv.org//abs/2504.18070)

	Jingjin Wang

+ [Stabilizing Reasoning in Medical LLMs with Continued Pretraining and Reasoning Preference Optimization](https://arxiv.org//abs/2504.18080)

	Wataru Kawakami, Keita Suzuki, Junichiro Iwasawa

+ [Random-Set Large Language Models](https://arxiv.org//abs/2504.18085)

	Muhammad Mubashar, Shireen Kudukkil Manchingal, Fabio Cuzzolin

+ [Application and Optimization of Large Models Based on Prompt Tuning for Fact-Check-Worthiness Estimation](https://arxiv.org//abs/2504.18104)

	Yinglong Yu, Hao Shen, Zhengyi Lyu, Qi He

+ [Evaluating Evaluation Metrics -- The Mirage of Hallucination Detection](https://arxiv.org//abs/2504.18114)

	Atharva Kulkarni, Yuan Zhang, Joel Ruben Antony Moniz, Xiou Ge, Bo-Hsiang Tseng, Dhivya Piraviperumal, Swabha Swayamdipta, Hong Yu

+ [Efficient Single-Pass Training for Multi-Turn Reasoning](https://arxiv.org//abs/2504.18246)

	Ritesh Goru, Shanay Mehta, Prateek Jain

+ [Towards Adaptive Software Agents for Debugging](https://arxiv.org//abs/2504.18316)

	Yacine Majdoub, Eya Ben Charrada, Haifa Touati

+ [Comparing Uncertainty Measurement and Mitigation Methods for Large Language Models: A Systematic Review](https://arxiv.org//abs/2504.18346)

	Toghrul Abbasli, Kentaroh Toyoda, Yuan Wang, Leon Witt, Muhammad Asif Ali, Yukai Miao, Dan Li, Qingsong Wei

+ [LLMpatronous: Harnessing the Power of LLMs For Vulnerability Detection](https://arxiv.org//abs/2504.18423)

	Rajesh Yarra

+ [Fast-Slow Thinking for Large Vision-Language Model Reasoning](https://arxiv.org//abs/2504.18458)

	Wenyi Xiao, Leilei Gan, Weilong Dai, Wanggui He, Ziwei Huang, Haoyuan Li, Fangxun Shu, Zhelun Yu, Peng Zhang, Hao Jiang, Fei Wu

+ [Improving LLM Personas via Rationalization with Psychological Scaffolds](https://arxiv.org//abs/2504.17993)

	Brihi Joshi, Xiang Ren, Swabha Swayamdipta, Rik Koncel-Kedziorski, Tim Paek

+ [DREAM: Disentangling Risks to Enhance Safety Alignment in Multimodal Large Language Models](https://arxiv.org//abs/2504.18053)

	Jianyu Liu, Hangyu Guo, Ranjie Duan, Xingyuan Bu, Yancheng He, Shilong Li, Hui Huang, Jiaheng Liu, Yucheng Wang, Chenchen Jing, Xingwei Qu, Xiao Zhang, Yingshui Tan, Yanan Wu, Jihao Gu, Yangguang Li, Jianke Zhu

+ [Even Small Reasoners Should Quote Their Sources: Introducing the Pleias-RAG Model Family](https://arxiv.org//abs/2504.18225)

	Pierre-Carl Langlais, Pavel Chizhov, Mattia Nee, Carlos Rosas Hinostroza, Matthieu Delsart, Irène Girard, Othman Hicheur, Anastasia Stasenko, Ivan P. Yamshchikov

+ [MAGI: Multi-Agent Guided Interview for Psychiatric Assessment](https://arxiv.org//abs/2504.18260)

	Guanqun Bi, Zhuang Chen, Zhoufu Liu, Hongkai Wang, Xiyao Xiao, Yuqiang Xie, Wen Zhang, Yongkang Huang, Yuxuan Chen, Libiao Peng, Yi Feng, Minlie Huang

+ [Auto-SLURP: A Benchmark Dataset for Evaluating Multi-Agent Frameworks in Smart Personal Assistant](https://arxiv.org//abs/2504.18373)

	Lei Shen, Xiaoyu Shen

+ [Expressing stigma and inappropriate responses prevents LLMs from safely replacing mental health providers](https://arxiv.org//abs/2504.18412)

	Jared Moore, Declan Grabb, William Agnew, Kevin Klyman, Stevie Chancellor, Desmond C. Ong, Nick Haber

+ [BitNet v2: Native 4-bit Activations with Hadamard Transformation for 1-bit LLMs](https://arxiv.org//abs/2504.18415)

	Hongyu Wang, Shuming Ma, Furu Wei

+ [PolyMath: Evaluating Mathematical Reasoning in Multilingual Contexts](https://arxiv.org//abs/2504.18428)

	Yiming Wang, Pei Zhang, Jialong Tang, Haoran Wei, Baosong Yang, Rui Wang, Chenshu Sun, Feitong Sun, Jiran Zhang, Junxuan Wu, Qiqian Cang, Yichang Zhang, Fei Huang, Junyang Lin, Fei Huang, Jingren Zhou

+ [Investigating Co-Constructive Behavior of Large Language Models in Explanation Dialogues](https://arxiv.org//abs/2504.18483)

	Leandra Fichtel, Maximilian Spliethöver, Eyke Hüllermeier, Patricia Jimenez, Nils Klowait, Stefan Kopp, Axel-Cyrille Ngonga Ngomo, Amelie Robrecht, Ingrid Scharlau, Lutz Terfloth, Anna-Lisa Vollmer, Henning Wachsmuth

+ [TRACE Back from the Future: A Probabilistic Reasoning Approach to Controllable Language Generation](https://arxiv.org//abs/2504.18535)

	Gwen Yidou Weng, Benjie Wang, Guy Van den Broeck

+ [SMARTFinRAG: Interactive Modularized Financial RAG Benchmark](https://arxiv.org//abs/2504.18024)

	Yiwei Zha

+ [Adversarial Attacks on LLM-as-a-Judge Systems: Insights from Prompt Injections](https://arxiv.org//abs/2504.18333)

	Narek Maloyan, Dmitry Namiot

+ [Revisiting Data Auditing in Large Vision-Language Models](https://arxiv.org//abs/2504.18349)

	Hongyu Zhu, Sichu Liang, Wenwen Wang, Boheng Li, Tongxin Yuan, Fangqi Li, ShiLin Wang, Zhuosheng Zhang

+ [Think, Prune, Train, Improve: Scaling Reasoning without Scaling Models](https://arxiv.org//abs/2504.18116)

	Caia Costello, Simon Guo, Anna Goldie, Azalia Mirhoseini

+ [DualRAG: A Dual-Process Approach to Integrate Reasoning and Retrieval for Multi-Hop Question Answering](https://arxiv.org//abs/2504.18243)

	Rong Cheng, Jinyi Liu, YAN ZHENG, Fei Ni, Jiazhen Du, Hangyu Mao, Fuzheng Zhang, Bo Wang, Jianye HAO

+ [Studying Small Language Models with Susceptibilities](https://arxiv.org//abs/2504.18274)

	Garrett Baker, George Wang, Jesse Hoogland, Daniel Murfet

+ [Streaming, Fast and Slow: Cognitive Load-Aware Streaming for Efficient LLM Serving](https://arxiv.org//abs/2504.17999)

	Chang Xiao, Brenda Yang

+ [NoEsis: Differentially Private Knowledge Transfer in Modular LLM Adaptation](https://arxiv.org//abs/2504.18147)

	Rob Romijnders, Stefanos Laskaridis, Ali Shahin Shamsabadi, Hamed Haddadi

+ [Automating Function-Level TARA for Automotive Full-Lifecycle Security](https://arxiv.org//abs/2504.18083)

	Yuqiao Yang, Yongzhao Zhang, Wenhao Liu, Jun Li, Pengtao Shi, DingYu Zhong, Jie Yang, Ting Chen, Sheng Cao, Yuntao Ren, Yongyue Wu, Xiaosong Zhang

+ [ThreMoLIA: Threat Modeling of Large Language Model-Integrated Applications](https://arxiv.org//abs/2504.18369)

	Felix Viktor Jedrzejewski, Davide Fucci, Oleksandr Adamov

+ [Proof-of-TBI -- Fine-Tuned Vision Language Model Consortium and OpenAI-o3 Reasoning LLM-Based Medical Diagnosis Support System for Mild Traumatic Brain Injury (TBI) Prediction](https://arxiv.org//abs/2504.18671)

	Ross Gore, Eranga Bandara, Sachin Shetty, Alberto E. Musto, Pratip Rana, Ambrosio Valencia-Romero, Christopher Rhea, Lobat Tayebi, Heather Richter, Atmaram Yarlagadda, Donna Edmonds, Steven Wallace, Donna Broshek

+ [Evolution of AI in Education: Agentic Workflows](https://arxiv.org//abs/2504.20082)

	Firuz Kamalov, David Santandreu Calonge, Linda Smail, Dilshod Azizov, Dimple R. Thadani, Theresa Kwong, Amara Atif

+ [Spark: A System for Scientifically Creative Idea Generation](https://arxiv.org//abs/2504.20090)

	Aishik Sanyal, Samuel Schapiro, Sumuk Shashidhar, Royce Moon, Lav R. Varshney, Dilek Hakkani-Tur

+ [A model and package for German ColBERT](https://arxiv.org//abs/2504.20083)

	Thuong Dang, Qiqi Chen

+ [CORG: Generating Answers from Complex, Interrelated Contexts](https://arxiv.org//abs/2505.00023)

	Hyunji Lee, Franck Dernoncourt, Trung Bui, Seunghyun Yoon

+ [Nemotron-Research-Tool-N1: Tool-Using Language Models with Reinforced Reasoning](https://arxiv.org//abs/2505.00024)

	Shaokun Zhang, Yi Dong, Jieyu Zhang, Jan Kautz, Bryan Catanzaro, Andrew Tao, Qingyun Wu, Zhiding Yu, Guilin Liu

+ [A Method for the Architecture of a Medical Vertical Large Language Model Based on Deepseek R1](https://arxiv.org//abs/2505.00025)

	Mingda Zhang, Jianglong Qin

+ [Anti-adversarial Learning: Desensitizing Prompts for Large Language Models](https://arxiv.org//abs/2505.01273)

	Xuan Li, Zhe Yin, Xiaodong Gu, Beijun Shen

# 2025-04-24
+ [Assessing the Capability of Large Language Models for Domain-Specific Ontology Generation](https://arxiv.org//abs/2504.17402)

	Anna Sofia Lippolis, Mohammad Javad Saeedizade, Robin Keskisarkka, Aldo Gangemi, Eva Blomqvist, Andrea Giovanni Nuzzolese

+ [Towards Machine-Generated Code for the Resolution of User Intentions](https://arxiv.org//abs/2504.17531)

	Justus Flerlage, Ilja Behnke, Odej Kao

+ [Auditing the Ethical Logic of Generative AI Models](https://arxiv.org//abs/2504.17544)

	W. Russell Neuman, Chad Coleman, Ali Dasdan, Safinah Ali, Manan Shah

+ [Automatically Generating Rules of Malicious Software Packages via Large Language Model](https://arxiv.org//abs/2504.17198)

	XiangRui Zhang, HaoYu Chen, Yongzhong He, Wenjia Niu, Qiang Li

+ [FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation](https://arxiv.org//abs/2504.17311)

	Yulia Otmakhova, Hung Thinh Truong, Rahmad Mahendra, Zenan Zhai, Rongxin Zhu, Daniel Beck, Jey Han Lau

+ [LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams](https://arxiv.org//abs/2504.17366)

	Yongxuan Wu, Runyu Chen, Peiyu Liu, Hongjin Qian

+ [Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks](https://arxiv.org//abs/2504.17421)

	Yang Liu, Bingjie Yan, Tianyuan Zou, Jianqing Zhang, Zixuan Gu, Jianbing Ding, Xidong Wang, Jingyi Li, Xiaozhou Ye, Ye Ouyang, Qiang Yang, Ya-Qin Zhang

+ [Towards Leveraging Large Language Model Summaries for Topic Modeling in Source Code](https://arxiv.org//abs/2504.17426)

	Michele Carissimi, Martina Saletta, Claudio Ferretti

+ [HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models](https://arxiv.org//abs/2504.17449)

	Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, Qin Xie, Guiming Xie, Xuejian Gong

+ [HalluLens: LLM Hallucination Benchmark](https://arxiv.org//abs/2504.17550)

	Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung

+ [Towards a HIPAA Compliant Agentic AI System in Healthcare](https://arxiv.org//abs/2504.17669)

	Subash Neupane, Shaswata Mitra, Sudip Mittal, Shahram Rahimi

+ [INSIGHT: Bridging the Student-Teacher Gap in Times of Large Language Models](https://arxiv.org//abs/2504.17677)

	Jarne Thys, Sebe Vanbrabant, Davy Vanacken, Gustavo Rovelo Ruiz

+ [Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks](https://arxiv.org//abs/2504.17685)

	Haru-Tada Sato, Fuka Matsuzaki, Jun-ichiro Takahashi

+ [Multilingual Performance Biases of Large Language Models in Education](https://arxiv.org//abs/2504.17720)

	Vansh Gupta, Sankalan Pal Chowdhury, Vilém Zouhar, Donya Rooein, Mrinmaya Sachan

+ [Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning](https://arxiv.org//abs/2504.17192)

	Minju Seo, Jinheon Baek, Seongyun Lee, Sung Ju Hwang

+ [A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation](https://arxiv.org//abs/2504.17200)

	Yangxinyu Xie, Bowen Jiang, Tanwi Mallick, Joshua David Bergerson, John K. Hutchison, Duane R. Verner, Jordan Branham, M. Ross Alexander, Robert B. Ross, Yan Feng, Leslie-Anne Levy, Weijie Su, Camillo J. Taylor

+ [Does Knowledge Distillation Matter for Large Language Model based Bundle Generation?](https://arxiv.org//abs/2504.17220)

	Kaidong Feng, Zhu Sun, Jie Yang, Hui Fang, Xinghua Qu, Wenyuan Liu

+ [Crisp: Cognitive Restructuring of Negative Thoughts through Multi-turn Supportive Dialogues](https://arxiv.org//abs/2504.17238)

	Jinfeng Zhou, Yuxuan Chen, Jianing Yin, Yongkang Huang, Yihan Shi, Xikun Zhang, Libiao Peng, Rongsheng Zhang, Tangjie Lv, Zhipeng Hu, Hongning Wang, Minlie Huang

+ [CoheMark: A Novel Sentence-Level Watermark for Enhanced Text Quality](https://arxiv.org//abs/2504.17309)

	Junyan Zhang, Shuliang Liu, Aiwei Liu, Yubo Gao, Jungang Li, Xiaojie Gu, Xuming Hu

+ [FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation](https://arxiv.org//abs/2504.17311)

	Yulia Otmakhova, Hung Thinh Truong, Rahmad Mahendra, Zenan Zhai, Rongxin Zhu, Daniel Beck, Jey Han Lau

+ [LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams](https://arxiv.org//abs/2504.17366)

	Yongxuan Wu, Runyu Chen, Peiyu Liu, Hongjin Qian

+ [Unified Attacks to Large Language Model Watermarks: Spoofing and Scrubbing in Unauthorized Knowledge Distillation](https://arxiv.org//abs/2504.17480)

	Xin Yi, Shunfan Zhengc, Linlin Wanga, Xiaoling Wang, Liang He

+ [HalluLens: LLM Hallucination Benchmark](https://arxiv.org//abs/2504.17550)

	Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung

+ [When Does Metadata Conditioning (NOT) Work for Language Model Pre-Training? A Study with Context-Free Grammars](https://arxiv.org//abs/2504.17562)

	Rei Higuchi, Ryotaro Kawata, Naoki Nishikawa, Kazusato Oko, Shoichiro Yamaguchi, Sosuke Kobayashi, Seiya Tokui, Kohei Hayashi, Daisuke Okanohara, Taiji Suzuki

+ [DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training](https://arxiv.org//abs/2504.17565)

	Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li

+ [Evaluating Grounded Reasoning by Code-Assisted Large Language Models for Mathematics](https://arxiv.org//abs/2504.17665)

	Zena Al-Khalili, Nick Howell, Dietrich Klakow

+ [Energy Considerations of Large Language Model Inference and Efficiency Optimizations](https://arxiv.org//abs/2504.17674)

	Jared Fernandez, Clara Na, Vashisth Tiwari, Yonatan Bisk, Sasha Luccioni, Emma Strubell

+ [Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks](https://arxiv.org//abs/2504.17685)

	Haru-Tada Sato, Fuka Matsuzaki, Jun-ichiro Takahashi

+ [Safety in Large Reasoning Models: A Survey](https://arxiv.org//abs/2504.17704)

	Cheng Wang, Yue Liu, Baolong Li, Duzhen Zhang, Zhongzhi Li, Junfeng Fang

+ [Multilingual Performance Biases of Large Language Models in Education](https://arxiv.org//abs/2504.17720)

	Vansh Gupta, Sankalan Pal Chowdhury, Vilém Zouhar, Donya Rooein, Mrinmaya Sachan

+ [The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs](https://arxiv.org//abs/2504.17768)

	Piotr Nawrot, Robert Li, Renjie Huang, Sebastian Ruder, Kelly Marchisio, Edoardo M. Ponti

+ [HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models](https://arxiv.org//abs/2504.17449)

	Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, Qin Xie, Guiming Xie, Xuejian Gong

+ [Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs](https://arxiv.org//abs/2504.17432)

	Tiancheng Gu, Kaicheng Yang, Ziyong Feng, Xingjun Wang, Yanzhao Zhang, Dingkun Long, Yingda Chen, Weidong Cai, Jiankang Deng

+ [Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks](https://arxiv.org//abs/2504.17421)

	Yang Liu, Bingjie Yan, Tianyuan Zou, Jianqing Zhang, Zixuan Gu, Jianbing Ding, Xidong Wang, Jingyi Li, Xiaozhou Ye, Ye Ouyang, Qiang Yang, Ya-Qin Zhang

+ [Towards Robust LLMs: an Adversarial Robustness Measurement Framework](https://arxiv.org//abs/2504.17723)

	Natan Levy, Adiel Ashrov, Guy Katz

+ [Replay to Remember: Retaining Domain Knowledge in Streaming Language Models](https://arxiv.org//abs/2504.17780)

	Sneh Pillai (University of Massachusetts Dartmouth)

+ [High-Fidelity And Complex Test Data Generation For Real-World SQL Code Generation Services](https://arxiv.org//abs/2504.17203)

	Shivasankari Kannan, Yeounoh Chung, Amita Gondi, Tristan Swadell, Fatma Ozcan

+ [Comprehend, Divide, and Conquer: Feature Subspace Exploration via Multi-Agent Hierarchical Reinforcement Learning](https://arxiv.org//abs/2504.17356)

	Weiliang Zhang, Xiaohan Huang, Yi Du, Ziyue Qiao, Qingqing Long, Zhen Meng, Yuanchun Zhou, Meng Xiao

+ [On-Device Qwen2.5: Efficient LLM Inference with Model Compression and Hardware Acceleration](https://arxiv.org//abs/2504.17376)

	Maoyang Xiang, Ramesh Fernando, Bo Wang

+ [L3: DIMM-PIM Integrated Architecture and Coordination for Scalable Long-Context LLM Inference](https://arxiv.org//abs/2504.17584)

	Qingyuan Liu, Liyan Chen, Yanning Yang, Haocheng Wang, Dong Du, Zhigang Mao, Naifeng Jing, Yubin Xia, Haibo Chen

+ [Assessing the Capability of Large Language Models for Domain-Specific Ontology Generation](https://arxiv.org//abs/2504.17402)

	Anna Sofia Lippolis, Mohammad Javad Saeedizade, Robin Keskisarkka, Aldo Gangemi, Eva Blomqvist, Andrea Giovanni Nuzzolese

+ [Towards Machine-Generated Code for the Resolution of User Intentions](https://arxiv.org//abs/2504.17531)

	Justus Flerlage, Ilja Behnke, Odej Kao

+ [Auditing the Ethical Logic of Generative AI Models](https://arxiv.org//abs/2504.17544)

	W. Russell Neuman, Chad Coleman, Ali Dasdan, Safinah Ali, Manan Shah

+ [Automatically Generating Rules of Malicious Software Packages via Large Language Model](https://arxiv.org//abs/2504.17198)

	XiangRui Zhang, HaoYu Chen, Yongzhong He, Wenjia Niu, Qiang Li

+ [NeuralGrok: Accelerate Grokking by Neural Gradient Transformation](https://arxiv.org//abs/2504.17243)

	Xinyu Zhou, Simin Fan, Martin Jaggi, Jie Fu

+ [FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation](https://arxiv.org//abs/2504.17311)

	Yulia Otmakhova, Hung Thinh Truong, Rahmad Mahendra, Zenan Zhai, Rongxin Zhu, Daniel Beck, Jey Han Lau

+ [LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams](https://arxiv.org//abs/2504.17366)

	Yongxuan Wu, Runyu Chen, Peiyu Liu, Hongjin Qian

+ [Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks](https://arxiv.org//abs/2504.17421)

	Yang Liu, Bingjie Yan, Tianyuan Zou, Jianqing Zhang, Zixuan Gu, Jianbing Ding, Xidong Wang, Jingyi Li, Xiaozhou Ye, Ye Ouyang, Qiang Yang, Ya-Qin Zhang

+ [Towards Leveraging Large Language Model Summaries for Topic Modeling in Source Code](https://arxiv.org//abs/2504.17426)

	Michele Carissimi, Martina Saletta, Claudio Ferretti

+ [HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models](https://arxiv.org//abs/2504.17449)

	Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, Qin Xie, Guiming Xie, Xuejian Gong

+ [HalluLens: LLM Hallucination Benchmark](https://arxiv.org//abs/2504.17550)

	Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung

+ [Towards a HIPAA Compliant Agentic AI System in Healthcare](https://arxiv.org//abs/2504.17669)

	Subash Neupane, Shaswata Mitra, Sudip Mittal, Shahram Rahimi

+ [INSIGHT: Bridging the Student-Teacher Gap in Times of Large Language Models](https://arxiv.org//abs/2504.17677)

	Jarne Thys, Sebe Vanbrabant, Davy Vanacken, Gustavo Rovelo Ruiz

+ [Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks](https://arxiv.org//abs/2504.17685)

	Haru-Tada Sato, Fuka Matsuzaki, Jun-ichiro Takahashi

+ [Multilingual Performance Biases of Large Language Models in Education](https://arxiv.org//abs/2504.17720)

	Vansh Gupta, Sankalan Pal Chowdhury, Vilém Zouhar, Donya Rooein, Mrinmaya Sachan

+ [Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning](https://arxiv.org//abs/2504.17192)

	Minju Seo, Jinheon Baek, Seongyun Lee, Sung Ju Hwang

+ [A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation](https://arxiv.org//abs/2504.17200)

	Yangxinyu Xie, Bowen Jiang, Tanwi Mallick, Joshua David Bergerson, John K. Hutchison, Duane R. Verner, Jordan Branham, M. Ross Alexander, Robert B. Ross, Yan Feng, Leslie-Anne Levy, Weijie Su, Camillo J. Taylor

+ [Does Knowledge Distillation Matter for Large Language Model based Bundle Generation?](https://arxiv.org//abs/2504.17220)

	Kaidong Feng, Zhu Sun, Jie Yang, Hui Fang, Xinghua Qu, Wenyuan Liu

+ [Crisp: Cognitive Restructuring of Negative Thoughts through Multi-turn Supportive Dialogues](https://arxiv.org//abs/2504.17238)

	Jinfeng Zhou, Yuxuan Chen, Jianing Yin, Yongkang Huang, Yihan Shi, Xikun Zhang, Libiao Peng, Rongsheng Zhang, Tangjie Lv, Zhipeng Hu, Hongning Wang, Minlie Huang

+ [CoheMark: A Novel Sentence-Level Watermark for Enhanced Text Quality](https://arxiv.org//abs/2504.17309)

	Junyan Zhang, Shuliang Liu, Aiwei Liu, Yubo Gao, Jungang Li, Xiaojie Gu, Xuming Hu

+ [PatientDx: Merging Large Language Models for Protecting Data-Privacy in Healthcare](https://arxiv.org//abs/2504.17360)

	Jose G. Moreno (IRIT-IRIS), Jesus Lovon (IRIT-IRIS), M'Rick Robin-Charlet (UT3), Christine Damase-Michel, Lynda Tamine (IRIT-IRIS)

+ [Unified Attacks to Large Language Model Watermarks: Spoofing and Scrubbing in Unauthorized Knowledge Distillation](https://arxiv.org//abs/2504.17480)

	Xin Yi, Shunfan Zhengc, Linlin Wanga, Xiaoling Wang, Liang He

+ [When Does Metadata Conditioning (NOT) Work for Language Model Pre-Training? A Study with Context-Free Grammars](https://arxiv.org//abs/2504.17562)

	Rei Higuchi, Ryotaro Kawata, Naoki Nishikawa, Kazusato Oko, Shoichiro Yamaguchi, Sosuke Kobayashi, Seiya Tokui, Kohei Hayashi, Daisuke Okanohara, Taiji Suzuki

+ [DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training](https://arxiv.org//abs/2504.17565)

	Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li

+ [Evaluating Grounded Reasoning by Code-Assisted Large Language Models for Mathematics](https://arxiv.org//abs/2504.17665)

	Zena Al-Khalili, Nick Howell, Dietrich Klakow

+ [Energy Considerations of Large Language Model Inference and Efficiency Optimizations](https://arxiv.org//abs/2504.17674)

	Jared Fernandez, Clara Na, Vashisth Tiwari, Yonatan Bisk, Sasha Luccioni, Emma Strubell

+ [Safety in Large Reasoning Models: A Survey](https://arxiv.org//abs/2504.17704)

	Cheng Wang, Yue Liu, Baolong Li, Duzhen Zhang, Zhongzhi Li, Junfeng Fang

+ [Conversational Assistants to support Heart Failure Patients: comparing a Neurosymbolic Architecture with ChatGPT](https://arxiv.org//abs/2504.17753)

	Anuja Tayal, Devika Salunke, Barbara Di Eugenio, Paula Allen-Meares, Eulalia Puig Abril, Olga Garcia, Carolyn Dickens, Andrew Boyd

+ [The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs](https://arxiv.org//abs/2504.17768)

	Piotr Nawrot, Robert Li, Renjie Huang, Sebastian Ruder, Kelly Marchisio, Edoardo M. Ponti

+ [Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs](https://arxiv.org//abs/2504.17432)

	Tiancheng Gu, Kaicheng Yang, Ziyong Feng, Xingjun Wang, Yanzhao Zhang, Dingkun Long, Yingda Chen, Weidong Cai, Jiankang Deng

+ [Towards Robust LLMs: an Adversarial Robustness Measurement Framework](https://arxiv.org//abs/2504.17723)

	Natan Levy, Adiel Ashrov, Guy Katz

+ [Replay to Remember: Retaining Domain Knowledge in Streaming Language Models](https://arxiv.org//abs/2504.17780)

	Sneh Pillai (University of Massachusetts Dartmouth)

+ [High-Fidelity And Complex Test Data Generation For Real-World SQL Code Generation Services](https://arxiv.org//abs/2504.17203)

	Shivasankari Kannan, Yeounoh Chung, Amita Gondi, Tristan Swadell, Fatma Ozcan

+ [On-Device Qwen2.5: Efficient LLM Inference with Model Compression and Hardware Acceleration](https://arxiv.org//abs/2504.17376)

	Maoyang Xiang, Ramesh Fernando, Bo Wang

+ [L3: DIMM-PIM Integrated Architecture and Coordination for Scalable Long-Context LLM Inference](https://arxiv.org//abs/2504.17584)

	Qingyuan Liu, Liyan Chen, Yanning Yang, Haocheng Wang, Dong Du, Zhigang Mao, Naifeng Jing, Yubin Xia, Haibo Chen

+ [LLM Agent Swarm for Hypothesis-Driven Drug Discovery](https://arxiv.org//abs/2504.17967)

	Kevin Song, Andrew Trotter, Jake Y. Chen

+ [Data-Driven Calibration of Prediction Sets in Large Vision-Language Models Based on Inductive Conformal Prediction](https://arxiv.org//abs/2504.17671)

	Yuanchang Ye, Weiyan Wen

+ [Unsupervised Corpus Poisoning Attacks in Continuous Space for Dense Retrieval](https://arxiv.org//abs/2504.17884)

	Yongkang Li, Panagiotis Eustratiadis, Simon Lupart, Evangelos Kanoulas

+ [Toward a Human-Centered Evaluation Framework for Trustworthy LLM-Powered GUI Agents](https://arxiv.org//abs/2504.17934)

	Chaoran Chen, Zhiping Zhang, Ibrahim Khalilov, Bingcan Guo, Simret A Gebreegziabher, Yanfang Ye, Ziang Xiao, Yaxing Yao, Tianshi Li, Toby Jia-Jun Li

+ [Collaborating Action by Action: A Multi-agent LLM Framework for Embodied Reasoning](https://arxiv.org//abs/2504.17950)

	Isadora White, Kolby Nottingham, Ayush Maniar, Max Robinson, Hansen Lillemark, Mehul Maheshwari, Lianhui Qin, Prithviraj Ammanabrolu

+ [DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training](https://arxiv.org//abs/2504.17565)

	Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li

+ [Training Large Language Models to Reason via EM Policy Gradient](https://arxiv.org//abs/2504.18587)

	Tianbing Xu

+ [BadMoE: Backdooring Mixture-of-Experts LLMs via Optimizing Routing Triggers and Infecting Dormant Experts](https://arxiv.org//abs/2504.18598)

	Qingyue Wang, Qi Pang, Xixun Lin, Shuai Wang, Daoyuan Wu

+ [RAGEN: Understanding Self-Evolution in LLM Agents via Multi-Turn Reinforcement Learning](https://arxiv.org//abs/2504.20073)

	Zihan Wang, Kangrui Wang, Qineng Wang, Pingyue Zhang, Linjie Li, Zhengyuan Yang, Kefan Yu, Minh Nhat Nguyen, Licheng Liu, Eli Gottlieb, Monica Lam, Yiping Lu, Kyunghyun Cho, Jiajun Wu, Li Fei-Fei, Lijuan Wang, Yejin Choi, Manling Li

+ [Tempo: Application-aware LLM Serving with Mixed SLO Requirements](https://arxiv.org//abs/2504.20068)

	Wei Zhang, Zhiyu Wu, Yi Mu, Banruo Liu, Myungjin Lee, Fan Lai

+ [ReCellTy: Domain-specific knowledge graph retrieval-augmented LLMs workflow for single-cell annotation](https://arxiv.org//abs/2505.00017)

	Dezheng Han, Yibin Jia, Ruxiao Chen, Wenjie Han, Shuaishuai Guo, Jianbo Wang

+ [An Empirical Study on Prompt Compression for Large Language Models](https://arxiv.org//abs/2505.00019)

	Zheng Zhang, Jinyi Li, Yihuai Lan, Xiang Wang, Hao Wang

+ [Beyond Public Access in LLM Pre-Training Data](https://arxiv.org//abs/2505.00020)

	Sruly Rosenblat, Tim O'Reilly, Ilan Strauss

+ [Aleph-Alpha-GermanWeb: Improving German-language LLM pre-training with model-based data curation and synthetic data generation](https://arxiv.org//abs/2505.00022)

	Thomas F Burns, Letitia Parcalabescu, Stephan Wäldchen, Michael Barlow, Gregor Ziegltrum, Volker Stampa, Bastian Harren, Björn Deiseroth

+ [Towards a HIPAA Compliant Agentic AI System in Healthcare](https://arxiv.org//abs/2504.17669)

	Subash Neupane, Sudip Mittal, Shahram Rahimi

+ [Towards Machine-Generated Code for the Resolution of User Intentions](https://arxiv.org//abs/2504.17531)

	Justus Flerlage, Ilja Behnke, Odej Kao

# 2025-04-23
+ [Steering the CensorShip: Uncovering Representation Vectors for LLM "Thought" Control](https://arxiv.org//abs/2504.17130)

	Hannah Cyberey, David Evans

+ [Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification](https://arxiv.org//abs/2504.17017)

	Balaji Rao, William Eiers, Carlo Lipizzi

+ [Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments](https://arxiv.org//abs/2504.17087)

	Yuran Li, Jama Hussein Mohamud, Chongren Sun, Di Wu, Benoit Boulet

+ [Backslash: Rate Constrained Optimized Training of Large Language Models](https://arxiv.org//abs/2504.16968)

	Jun Wu, Jiangtao Wen, Yuxing Han

+ [(Im)possibility of Automated Hallucination Detection in Large Language Models](https://arxiv.org//abs/2504.17004)

	Amin Karbasi, Omar Montasser, John Sous, Grigoris Velegkas

+ [Robo-Troj: Attacking LLM-based Task Planners](https://arxiv.org//abs/2504.17070)

	Mohaiminul Al Nahian, Zainab Altaweel, David Reitano, Sabbir Ahmed, Saumitra Lohokare, Shiqi Zhang, Adnan Siraj Rakin

+ [MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation](https://arxiv.org//abs/2504.17137)

	Chanhee Park, Hyeonseok Moon, Chanjun Park, Heuiseok Lim

+ [Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark](https://arxiv.org//abs/2504.16427)

	Hanlei Zhang, Zhuohang Li, Yeshuang Zhu, Hua Xu, Peiwu Wang, Haige Zhu, Jie Zhou, Jinchao Zhang

+ [Optimizing LLMs for Italian: Reducing Token Fertility and Enhancing Efficiency Through Vocabulary Adaptation](https://arxiv.org//abs/2504.17025)

	Luca Moroni, Giovanni Puccetti, Pere-Lluis Huguet Cabot, Andrei Stefan Bejgu, Edoardo Barba, Alessio Miaschi, Felice Dell'Orletta, Andrea Esuli, Roberto Navigli

+ [Do Words Reflect Beliefs? Evaluating Belief Depth in Large Language Models](https://arxiv.org//abs/2504.17052)

	Shariar Kabir, Kevin Esterling, Yue Dong

+ [Agree to Disagree? A Meta-Evaluation of LLM Misgendering](https://arxiv.org//abs/2504.17075)

	Arjun Subramonian, Vagrant Gautam, Preethi Seshadri, Dietrich Klakow, Kai-Wei Chang, Yizhou Sun

+ [How Individual Traits and Language Styles Shape Preferences In Open-ended User-LLM Interaction: A Preliminary Study](https://arxiv.org//abs/2504.17083)

	Rendi Chevi, Kentaro Inui, Thamar Solorio, Alham Fikri Aji

+ [Co-CoT: A Prompt-Based Framework for Collaborative Chain-of-Thought Reasoning](https://arxiv.org//abs/2504.17091)

	Seunghyun Yoo

+ [Steering the CensorShip: Uncovering Representation Vectors for LLM "Thought" Control](https://arxiv.org//abs/2504.17130)

	Hannah Cyberey, David Evans

+ [MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation](https://arxiv.org//abs/2504.17137)

	Chanhee Park, Hyeonseok Moon, Chanjun Park, Heuiseok Lim

+ [(Im)possibility of Automated Hallucination Detection in Large Language Models](https://arxiv.org//abs/2504.17004)

	Amin Karbasi, Omar Montasser, John Sous, Grigoris Velegkas

+ [Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark](https://arxiv.org//abs/2504.16427)

	Hanlei Zhang, Zhuohang Li, Yeshuang Zhu, Hua Xu, Peiwu Wang, Haige Zhu, Jie Zhou, Jinchao Zhang

+ [Backslash: Rate Constrained Optimized Training of Large Language Models](https://arxiv.org//abs/2504.16968)

	Jun Wu, Jiangtao Wen, Yuxing Han

+ [Safety Pretraining: Toward the Next Generation of Safe AI](https://arxiv.org//abs/2504.16980)

	Pratyush Maini, Sachin Goyal, Dylan Sam, Alex Robey, Yash Savani, Yiding Jiang, Andy Zou, Zacharcy C. Lipton, J. Zico Kolter

+ [Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification](https://arxiv.org//abs/2504.17017)

	Balaji Rao, William Eiers, Carlo Lipizzi

+ [Exploring How LLMs Capture and Represent Domain-Specific Knowledge](https://arxiv.org//abs/2504.16871)

	Mirian Hipolito Garcia, Camille Couturier, Daniel Madrigal Diaz, Ankur Mallick, Anastasios Kyrillidis, Robert Sim, Victor Ruhle, Saravan Rajmohan


+ [Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments](https://arxiv.org//abs/2504.17087)

	Yuran Li, Jama Hussein Mohamud, Chongren Sun, Di Wu, Benoit Boulet

+ [Backslash: Rate Constrained Optimized Training of Large Language Models](https://arxiv.org//abs/2504.16968)

	Jun Wu, Jiangtao Wen, Yuxing Han

+ [(Im)possibility of Automated Hallucination Detection in Large Language Models](https://arxiv.org//abs/2504.17004)

	Amin Karbasi, Omar Montasser, John Sous, Grigoris Velegkas

+ [Robo-Troj: Attacking LLM-based Task Planners](https://arxiv.org//abs/2504.17070)

	Mohaiminul Al Nahian, Zainab Altaweel, David Reitano, Sabbir Ahmed, Saumitra Lohokare, Shiqi Zhang, Adnan Siraj Rakin

+ [MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation](https://arxiv.org//abs/2504.17137)

	Chanhee Park, Hyeonseok Moon, Chanjun Park, Heuiseok Lim

+ [Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark](https://arxiv.org//abs/2504.16427)

	Hanlei Zhang, Zhuohang Li, Yeshuang Zhu, Hua Xu, Peiwu Wang, Haige Zhu, Jie Zhou, Jinchao Zhang

+ [Optimizing LLMs for Italian: Reducing Token Fertility and Enhancing Efficiency Through Vocabulary Adaptation](https://arxiv.org//abs/2504.17025)

	Luca Moroni, Giovanni Puccetti, Pere-Lluis Huguet Cabot, Andrei Stefan Bejgu, Edoardo Barba, Alessio Miaschi, Felice Dell'Orletta, Andrea Esuli, Roberto Navigli

+ [Do Words Reflect Beliefs? Evaluating Belief Depth in Large Language Models](https://arxiv.org//abs/2504.17052)

	Shariar Kabir, Kevin Esterling, Yue Dong

+ [Agree to Disagree? A Meta-Evaluation of LLM Misgendering](https://arxiv.org//abs/2504.17075)

	Arjun Subramonian, Vagrant Gautam, Preethi Seshadri, Dietrich Klakow, Kai-Wei Chang, Yizhou Sun

+ [How Individual Traits and Language Styles Shape Preferences In Open-ended User-LLM Interaction: A Preliminary Study](https://arxiv.org//abs/2504.17083)

	Rendi Chevi, Kentaro Inui, Thamar Solorio, Alham Fikri Aji

+ [Co-CoT: A Prompt-Based Framework for Collaborative Chain-of-Thought Reasoning](https://arxiv.org//abs/2504.17091)

	Seunghyun Yoo

+ [Steering the CensorShip: Uncovering Representation Vectors for LLM "Thought" Control](https://arxiv.org//abs/2504.17130)

	Hannah Cyberey, David Evans

+ [Safety Pretraining: Toward the Next Generation of Safe AI](https://arxiv.org//abs/2504.16980)

	Pratyush Maini, Sachin Goyal, Dylan Sam, Alex Robey, Yash Savani, Yiding Jiang, Andy Zou, Zacharcy C. Lipton, J. Zico Kolter

+ [Exploring How LLMs Capture and Represent Domain-Specific Knowledge](https://arxiv.org//abs/2504.16871)

	Mirian Hipolito Garcia, Camille Couturier, Daniel Madrigal Diaz, Ankur Mallick, Anastasios Kyrillidis, Robert Sim, Victor Ruhle, Saravan Rajmohan

+ [EduBot -- Can LLMs Solve Personalized Learning and Programming Assignments?](https://arxiv.org//abs/2504.17824)

	Yibin Wang, Jiaxi Xie, Lakshminarayanan Subramanian

+ [BackSlash: Rate Constrained Optimized Training of Large Language Models](https://arxiv.org//abs/2504.16968)

	Jun Wu, Jiangtao Wen, Yuxing Han

+ [PARD: Accelerating LLM Inference with Low-Cost PARallel Draft Model Adaptation](https://arxiv.org//abs/2504.18583)

	Zihao An, Huajun Bai, Ziqiong Liu, Dong Li, Emad Barsoum

+ [Param$Δ$ for Direct Weight Mixing: Post-Train Large Language Model at Zero Cost](https://arxiv.org//abs/2504.21023)

	Sheng Cao, Mingrui Wu, Karthik Prasad, Yuandong Tian, Zechun Liu

+ [WebEvolver: Enhancing Web Agent Self-Improvement with Coevolving World Model](https://arxiv.org//abs/2504.21024)

	Tianqing Fang, Hongming Zhang, Zhisong Zhang, Kaixin Ma, Wenhao Yu, Haitao Mi, Dong Yu

+ [Sparks of Tabular Reasoning via Text2SQL Reinforcement Learning](https://arxiv.org//abs/2505.00016)

	Josefa Lia Stoisser, Marc Boubnovski Martell, Julien Fauqueur

+ [Building A Secure Agentic AI Application Leveraging A2A Protocol](https://arxiv.org//abs/2504.16902)

	Idan Habler, Ken Huang, Vineeth Sai Narajala, Prashant Kulkarni

+ [ConTextual: Improving Clinical Text Summarization in LLMs with Context-preserving Token Filtering and Knowledge Graphs](https://arxiv.org//abs/2504.16394)

	Fahmida Liza Piya, Rahmatollah Beheshti

+ [LLMSR@XLLM25: Less is More: Enhancing Structured Multi-Agent Reasoning via Quality-Guided Distillation](https://arxiv.org//abs/2504.16408)

	Jiahao Yuan, Xingzhe Sun, Xing Yu, Jingwen Wang, Dehui Du, Zhiqing Cui, Zixiang Di

+ [Harden and Catch for Just-in-Time Assured LLM-Based Software Testing: Open Research Challenges](https://arxiv.org//abs/2504.16472)

	Mark Harman, Peter O'Hearn, Shubho Sengupta

+ [Process Reward Models That Think](https://arxiv.org//abs/2504.16828)

	Muhammad Khalifa, Rishabh Agarwal, Lajanugen Logeswaran, Jaekyeom Kim, Hao Peng, Moontae Lee, Honglak Lee, Lu Wang

+ [OptimAI: Optimization from Natural Language Using LLM-Powered AI Agents](https://arxiv.org//abs/2504.16918)

	Raghav Thind, Youran Sun, Ling Liang, Haizhao Yang

+ [(Im)possibility of Automated Hallucination Detection in Large Language Models](https://arxiv.org//abs/2504.17004)

	Amin Karbasi, Omar Montasser, John Sous, Grigoris Velegkas

+ [Impact of Comments on LLM Comprehension of Legacy Code](https://arxiv.org//abs/2506.11007)

	Rock Sabetto, Emily Escamilla, Devesh Agarwal, Sujay Kandwal, Justin F. Brunelle, Scott Rosen, Nitin Naik, Samruddhi Thaker, Eric O. Scott, Jacob Zimmer, Amit Madan, Arun Sridharan, Doug Wendt, Michael Doyle, Christopher Glasz, Jasper Phillips, William Macke, Colin Diggs, Michael Bartholf, Zachary Robin, Paul Ursino

# 2025-04-22
+ [Impact of Noise on LLM-Models Performance in Abstraction and Reasoning Corpus (ARC) Tasks with Model Temperature Considerations](https://arxiv.org//abs/2504.15903)

	Nikhil Khandalkar, Pavan Yadav, Krishna Shinde, Lokesh B. Ramegowda, Rajarshi Das


+ [CAPO: Cost-Aware Prompt Optimization](https://arxiv.org//abs/2504.16005)

	Tom Zehle, Moritz Schlager, Timo Heiß, Matthias Feurer

+ [Pre-DPO: Improving Data Utilization in Direct Preference Optimization Using a Guiding Reference Model](https://arxiv.org//abs/2504.15843)

	Junshu Pan, Wei Shen, Shulin Huang, Qiji Zhou, Yue Zhang

+ [BELL: Benchmarking the Explainability of Large Language Models](https://arxiv.org//abs/2504.18572)

	Syed Quiser Ahmed, Bharathi Vokkaliga Ganesh, Jagadish Babu P, Karthick Selvaraj, ReddySiva Naga Parvathi Devi, Sravya Kappala

+ [Large Language Model Empowered Privacy-Protected Framework for PHI Annotation in Clinical Notes](https://arxiv.org//abs/2504.18569)

	Guanchen Wu, Linzhi Zheng, Han Xie, Zhen Xiang, Jiaying Lu, Darren Liu, Delgersuren Bold, Bo Li, Xiao Hu, Carl Yang

+ [Understanding the Skill Gap in Recurrent Language Models: The Role of the Gather-and-Aggregate Mechanism](https://arxiv.org//abs/2504.18574)

	Aviv Bick, Eric Xing, Albert Gu

+ [WASP: Benchmarking Web Agent Security Against Prompt Injection Attacks](https://arxiv.org//abs/2504.18575)

	Ivan Evtimov, Arman Zharmagambetov, Aaron Grattafiori, Chuan Guo, Kamalika Chaudhuri

+ [Kill two birds with one stone: generalized and robust AI-generated text detection via dynamic perturbations](https://arxiv.org//abs/2504.21019)

	Yinghan Zhou, Juan Wen, Wanli Peng, Yiming Xue, Ziwei Zhang, Zhengxian Wu

+ [Context-Enhanced Contrastive Search for Improved LLM Text Generation](https://arxiv.org//abs/2504.21020)

	Jaydip Sen, Rohit Pandey, Hetvi Waghela

+ [A Framework for Testing and Adapting REST APIs as LLM Tools](https://arxiv.org//abs/2504.15546)

	Jayachandu Bandlamudi, Ritwik Chaudhuri, Neelamadhav Gantayat, Kushal Mukherjee, Prerna Agarwal, Renuka Sindhgatta, Sameep Mehta

+ [Advancing Embodied Agent Security: From Safety Benchmarks to Input Moderation](https://arxiv.org//abs/2504.15699)

	Ning Wang, Zihan Yan, Weiyang Li, Chuan Ma, He Chen, Tao Xiang

+ [LLMs meet Federated Learning for Scalable and Secure IoT Management](https://arxiv.org//abs/2504.16032)

	Yazan Otoum, Arghavan Asad, Amiya Nayak

+ [A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment](https://arxiv.org//abs/2504.15585)

	Kun Wang, Guibin Zhang, Zhenhong Zhou, Jiahao Wu, Miao Yu, Shiqian Zhao, Chenlong Yin, Jinhu Fu, Yibo Yan, Hanjun Luo, Liang Lin, Zhihao Xu, Haolang Lu, Xinye Cao, Xinyun Zhou, Weifei Jin, Fanci Meng, Junyuan Mao, Yu Wang, Hao Wu, Minghe Wang, Fan Zhang, Junfeng Fang, Wenjie Qu, Yue Liu, Chengwei Liu, Yifan Zhang, Qiankun Li, Chongye Guo, Yalan Qin, Zhaoxin Fan, Yi Ding, Donghai Hong, Jiaming Ji, Yingxin Lai, Zitong Yu, Xinfeng Li, Yifan Jiang, Yanhui Li, Xinyu Deng, Junlin Wu, Dongxia Wang, Yihao Huang, Yufei Guo, Jen-tse Huang, Qiufeng Wang, Wenxuan Wang, Dongrui Liu, Yanwei Yue, Wenke Huang, Guancheng Wan, Heng Chang, Tianlin Li, Yi Yu, Chenghao Li, Jiawei Li, Lei Bai, Jie Zhang, Qing Guo, Jingyi Wang, Tianlong Chen, Joey Tianyi Zhou, Xiaojun Jia, Weisong Sun, Cong Wu, Jing Chen, Xuming Hu, Yiming Li, Xiao Wang, Ningyu Zhang, Luu Anh Tuan, Guowen Xu, Jiaheng Zhang, Tianwei Zhang, Xingjun Ma, Jindong Gu, Xiang Wang, Bo An, Jun Sun, Mohit Bansal, Shirui Pan, Lingjuan Lyu, Yuval Elovici, Bhavya Kailkhura, Yaodong Yang, Hongwei Li, Wenyuan Xu, Yizhou Sun, Wei Wang, Qing Li, Ke Tang, Yu-Gang Jiang, Felix Juefei-Xu, Hui Xiong, Xiaofeng Wang, Dacheng Tao, Philip S. Yu, Qingsong Wen, Yang Liu

+ [Dynamic Early Exit in Reasoning Models](https://arxiv.org//abs/2504.15895)

	Chenxu Yang, Qingyi Si, Yongjie Duan, Zheliang Zhu, Chenyu Zhu, Qiaowei Li, Zheng Lin, Li Cao, Weiping Wang

+ [PHYBench: Holistic Evaluation of Physical Perception and Reasoning in Large Language Models](https://arxiv.org//abs/2504.16074)

	Shi Qiu, Shaoyang Guo, Zhuo-Yang Song, Yunbo Sun, Zeyu Cai, Jiashen Wei, Tianyu Luo, Yixuan Yin, Haoxu Zhang, Yi Hu, Chenyang Wang, Chencheng Tang, Haoling Chang, Qi Liu, Ziheng Zhou, Tianyu Zhang, Jingtian Zhang, Zhangyi Liu, Minghao Li, Yuku Zhang, Boxuan Jing, Xianqi Yin, Yutong Ren, Zizhuo Fu, Jiaming Ji, Weike Wang, Xudong Tian, Anqi Lv, Laifu Man, Jianxiang Li, Feiyu Tao, Qihua Sun, Zhou Liang, Yushu Mu, Zhongxuan Li, Jing-Jun Zhang, Shutao Zhang, Xiaotian Li, Xingqi Xia, Jiawei Lin, Zheyu Shen, Jiahang Chen, Qiuhao Xiong, Binran Wang, Fengyuan Wang, Ziyang Ni, Bohan Zhang, Fan Cui, Changkun Shao, Qing-Hong Cao, Ming-xing Luo, Yaodong Yang, Muhan Zhang, Hua Xing Zhu

+ [Grounded in Context: Retrieval-Based Method for Hallucination Detection](https://arxiv.org//abs/2504.15771)

	Assaf Gerner, Netta Madvil, Nadav Barak, Alex Zaikman, Jonatan Liberman, Liron Hamra, Rotem Brazilay, Shay Tsadok, Yaron Friedman, Neal Harow, Noam Bresler, Shir Chorev, Philip Tannor

+ [Instruction-Tuning Data Synthesis from Scratch via Web Reconstruction](https://arxiv.org//abs/2504.15573)

	Yuxin Jiang, Yufei Wang, Chuhan Wu, Xinyi Dai, Yan Xu, Weinan Gan, Yasheng Wang, Xin Jiang, Lifeng Shang, Ruiming Tang, Wei Wang

+ [TTRL: Test-Time Reinforcement Learning](https://arxiv.org//abs/2504.16084)

	Yuxin Zuo, Kaiyan Zhang, Li Sheng, Shang Qu, Ganqu Cui, Xuekai Zhu, Haozhan Li, Yuchen Zhang, Xinwei Long, Ermo Hua, Biqing Qi, Youbang Sun, Zhiyuan Ma, Lifan Yuan, Ning Ding, Bowen Zhou

+ [MMInference: Accelerating Pre-filling for Long-Context VLMs via Modality-Aware Permutation Sparse Attention](https://arxiv.org//abs/2504.16083)

	Yucheng Li, Huiqiang Jiang, Chengruidong Zhang, Qianhui Wu, Xufang Luo, Surin Ahn, Amir H. Abdi, Dongsheng Li, Jianfeng Gao, Yuqing Yang, Lili Qiu

+ [What's the Difference? Supporting Users in Identifying the Effects of Prompt and Model Changes Through Token Patterns](https://arxiv.org//abs/2504.15815)

	Michael A. Hedderich, Anyi Wang, Raoyuan Zhao, Florian Eichin, Jonas Fischer, Barbara Plank

+ [CiteFix: Enhancing RAG Accuracy Through Post-Processing Citation Correction](https://arxiv.org//abs/2504.15629)

	Harsh Maheshwari, Srikanth Tenneti, Alwarappan Nakkiran

+ [Tina: Tiny Reasoning Models via LoRA](https://arxiv.org//abs/2504.15777)

	Shangshang Wang, Julian Asilis, Ömer Faruk Akgül, Enes Burak Bilgin, Ollie Liu, Willie Neiswanger

# 2025-04-21
+ [Intrinsic Barriers to Explaining Deep Foundation Models](https://arxiv.org//abs/2504.16948)

	Zhen Tan, Huan Liu

+ [KeyDiff: Key Similarity-Based KV Cache Eviction for Long-Context LLM Inference in Resource-Constrained Environments](https://arxiv.org//abs/2504.15364)

	Junyoung Park, Dalton Jones, Matt J Morse, Raghavv Goel, Mingu Lee, Chris Lott

+ [MARFT: Multi-Agent Reinforcement Fine-Tuning](https://arxiv.org//abs/2504.16129)

	Junwei Liao, Muning Wen, Jun Wang, Weinan Zhang

+ [Efficient Pretraining Length Scaling](https://arxiv.org//abs/2504.14992)

	Bohong Wu, Shen Yan, Sijun Zhang, Jianqiao Lu, Yutao Zeng, Ya Wang, Xun Zhou

+ [MARFT: Multi-Agent Reinforcement Fine-Tuning](https://arxiv.org//abs/2504.16129)

	Junwei Liao, Muning Wen, Jun Wang, Weinan Zhang


+ [DualBreach: Efficient Dual-Jailbreaking via Target-Driven Initialization and Multi-Target Optimization](https://arxiv.org//abs/2504.18564)

	Xinzhe Huang, Kedong Xiu, Tianhang Zheng, Churui Zeng, Wangze Ni, Zhan Qiin, Kui Ren, Chun Chen

+ [RepliBench: Evaluating the autonomous replication capabilities of language model agents](https://arxiv.org//abs/2504.18565)

	Sid Black, Asa Cooper Stickland, Jake Pencharz, Oliver Sourbut, Michael Schmatz, Jay Bailey, Ollie Matthews, Ben Millwood, Alex Remedios, Alan Cooney

+ [Jailbreak Detection in Clinical Training LLMs Using Feature-Based Predictive Models](https://arxiv.org//abs/2505.00010)

	Tri Nguyen, Lohith Srikanth Pentapalli, Magnus Sieverding, Laurah Turner, Seth Overla, Weibing Zheng, Chris Zhou, David Furniss, Danielle Weber, Michael Gharib, Matt Kelleher, Michael Shukis, Cameron Pawlik, Kelly Cohen

+ [Integrating Symbolic Execution into the Fine-Tuning of Code-Generating LLMs](https://arxiv.org//abs/2504.15210)

	Marina Sakharova, Abhinav Anand, Mira Mezini

+ [Splitwiser: Efficient LM inference with constrained resources](https://arxiv.org//abs/2505.03763)

	Asad Aali, Adney Cardoza, Melissa Capo

+ [AlignRAG: Leveraging Critique Learning for Evidence-Sensitive Retrieval-Augmented Reasoning](https://arxiv.org//abs/2504.14858)

	Jiaqi Wei, Hao Zhou, Xiang Zhang, Di Zhang, Zijie Qiu, Wei Wei, Jinzhe Li, Wanli Ouyang, Siqi Sun

+ [A Self-Improving Coding Agent](https://arxiv.org//abs/2504.15228)

	Maxime Robeyns, Martin Szummer, Laurence Aitchison

+ [MARFT: Multi-Agent Reinforcement Fine-Tuning](https://arxiv.org//abs/2504.16129)

	Junwei Liao, Muning Wen, Jun Wang, Weinan Zhang

+ [KeyDiff: Key Similarity-Based KV Cache Eviction for Long-Context LLM Inference in Resource-Constrained Environments](https://arxiv.org//abs/2504.15364)

	Junyoung Park, Dalton Jones, Matthew J Morse, Raghavv Goel, Mingu Lee, Chris Lott

+ [MrGuard: A Multilingual Reasoning Guardrail for Universal LLM Safety](https://arxiv.org//abs/2504.15241)

	Yahan Yang, Soham Dan, Shuo Li, Dan Roth, Insup Lee

+ [Evaluating Judges as Evaluators: The JETTS Benchmark of LLM-as-Judges as Test-Time Scaling Evaluators](https://arxiv.org//abs/2504.15253)

	Yilun Zhou, Austin Xu, Peifeng Wang, Caiming Xiong, Shafiq Joty

+ [Stop Summation: Min-Form Credit Assignment Is All Process Reward Model Needs for Reasoning](https://arxiv.org//abs/2504.15275)

	Jie Cheng, Ruixi Qiao, Lijun Li, Chao Guo, Junle Wang, Gang Xiong, Yisheng Lv, Fei-Yue Wang

+ [Text-to-Decision Agent: Offline Meta-Reinforcement Learning from Natural Language Supervision](https://arxiv.org//abs/2504.15046)

	Shilin Zhang, Zican Hu, Wenhao Wu, Xinyi Xie, Jianxiang Tang, Chunlin Chen, Daoyi Dong, Yu Cheng, Zhenhong Sun, Zhi Wang

+ [Acting Less is Reasoning More! Teaching Model to Act Efficiently](https://arxiv.org//abs/2504.14870)

	Hongru Wang, Cheng Qian, Wanjun Zhong, Xiusi Chen, Jiahao Qiu, Shijue Huang, Bowen Jin, Mengdi Wang, Kam-Fai Wong, Heng Ji

+ [Completing A Systematic Review in Hours instead of Months with Interactive AI Agents](https://arxiv.org//abs/2504.14822)

	Rui Qiu, Shijie Chen, Yu Su, Po-Yin Yen, Han-Wei Shen

# 2025-04-20
+ [UFO2: The Desktop AgentOS](https://arxiv.org//abs/2504.14603)

	Chaoyun Zhang, He Huang, Chiming Ni, Jian Mu, Si Qin, Shilin He, Lu Wang, Fangkai Yang, Pu Zhao, Chao Du, Liqun Li, Yu Kang, Zhao Jiang, Suzhen Zheng, Rujia Wang, Jiaxu Qian, Minghua Ma, Jian-Guang Lou, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang

+ [Towards Optimal Circuit Generation: Multi-Agent Collaboration Meets Collective Intelligence](https://arxiv.org//abs/2504.14625)

	Haiyan Qin, Jiahao Feng, Xiaotong Feng, Wei W. Xing, Wang Kang

+ [FinSage: A Multi-aspect RAG System for Financial Filings Question Answering](https://arxiv.org//abs/2504.14493)

	Xinyu Wang, Jijun Chi, Zhenghan Tai, Tung Sum Thomas Kwok, Muzhi Li, Zhuhong Li, Hailin He, Yuchen Hua, Peng Lu, Suyuchen Wang, Yihong Wu, Jerry Huang, Jingrui Tian, Ling Zhou

+ [Don't Retrieve, Generate: Prompting LLMs for Synthetic Training Data in Dense Retrieval](https://arxiv.org//abs/2504.21015)

	Aarush Sinha

+ [Trans-Zero: Self-Play Incentivizes Large Language Models for Multilingual Translation Without Parallel Data](https://arxiv.org//abs/2504.14669)

	Wei Zou, Sen Yang, Yu Bao, Shujian Huang, Jiajun Chen, Shanbo Cheng

# 2025-04-19
+ [TALES: Text Adventure Learning Environment Suite](https://arxiv.org//abs/2504.14128)

	Christopher Zhang Cui, Xingdi Yuan, Ziang Xiao, Prithviraj Ammanabrolu, Marc-Alexandre Côté



+ [Mind the Language Gap: Automated and Augmented Evaluation of Bias in LLMs for High- and Low-Resource Languages](https://arxiv.org//abs/2504.18560)

	Alessio Buscemi, Cédric Lothritz, Sergio Morales, Marcos Gomez-Vazquez, Robert Clarisó, Jordi Cabot, German Castignani

+ [Improving the Serving Performance of Multi-LoRA Large Language Models via Efficient LoRA and KV Cache Management](https://arxiv.org//abs/2505.03756)

	Hang Zhang, Jiuchen Shi, Yixiao Wang, Quan Chen, Yizhou Shan, Minyi Guo

+ [The Geometry of Self-Verification in a Task-Specific Reasoning Model](https://arxiv.org//abs/2504.14379)

	Andrew Lee, Lihao Sun, Chris Wendler, Fernanda Viégas, Martin Wattenberg

+ [Walk the Talk? Measuring the Faithfulness of Large Language Model Explanations](https://arxiv.org//abs/2504.14150)

	Katie Matton, Robert Osazuwa Ness, John Guttag, Emre Kıcıman

+ [An Empirical Study of LLM Reasoning Ability Under Strict Output Length Constraint](https://arxiv.org//abs/2504.14350)

	Yi Sun, Han Wang, Jiaqiang Li, Jiacheng Liu, Xiangyu Li, Hao Wen, Yizhen Yuan, Huiwen Zheng, Yan Liang, Yuanchun Li, Yunxin Liu

+ [Understanding the Repeat Curse in Large Language Models from a Feature Perspective](https://arxiv.org//abs/2504.14218)

	Junchi Yao, Shu Yang, Jianhua Xu, Lijie Hu, Mengdi Li, Di Wang

+ [Empirical Evaluation of Knowledge Distillation from Transformers to Subquadratic Language Models](https://arxiv.org//abs/2504.14366)

	Patrick Haller, Jonas Golde, Alan Akbik

+ [EmbedAgent: Benchmarking Large Language Models in Embedded System Development](https://arxiv.org//abs/2506.11003)

	Ruiyang Xu, Jialun Cao, Mingyuan Wu, Wenliang Zhong, Yaojie Lu, Ben He, Xianpei Han, Shing-Chi Cheung, Le Sun

# 2025-04-18
+ [SCRAG: Social Computing-Based Retrieval Augmented Generation for Community Response Forecasting in Social Media Environments](https://arxiv.org//abs/2504.16947)

	Dachun Sun, You Lyu, Jinning Li, Yizhuo Chen, Tianshi Wang, Tomoyoshi Kimura, Tarek Abdelzaher

+ [From Large to Super-Tiny: End-to-End Optimization for Cost-Efficient LLMs](https://arxiv.org//abs/2504.13471)

	Jiliang Ni, Jiachen Pu, Zhongyi Yang, Kun Zhou, Hui Wang, Xiaoliang Xiao, Dakui Wang, Xin Li, Jingfeng Luo, Conggang Hu


+ [From Large to Super-Tiny: End-to-End Optimization for Cost-Efficient LLMs](https://arxiv.org//abs/2504.13471)

	Jiliang Ni, Jiachen Pu, Zhongyi Yang, Kun Zhou, Hui Wang, Xiaoliang Xiao, Dakui Wang, Xin Li, Jingfeng Luo, Conggang Hu

+ [Gradual Binary Search and Dimension Expansion : A general method for activation quantization in LLMs](https://arxiv.org//abs/2504.13989)

	Lucas Maisonnave, Cyril Moineau, Olivier Bichler, Fabrice Rastello

+ [Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?](https://arxiv.org//abs/2504.13837)

	Yang Yue, Zhiqi Chen, Rui Lu, Andrew Zhao, Zhaokai Wang, Yang Yue, Shiji Song, Gao Huang

+ [Signatures of human-like processing in Transformer forward passes](https://arxiv.org//abs/2504.14107)

	Jennifer Hu, Michael A. Lepori, Michael Franke

+ [CoT-RAG: Integrating Chain of Thought and Retrieval-Augmented Generation to Enhance Reasoning in Large Language Models](https://arxiv.org//abs/2504.13534)

	Feiyang Li, Peng Fang, Zhan Shi, Arijit Khan, Fang Wang, Dan Feng, Weihao Wang, Xin Zhang, Yongjian Cui

+ [Not All Rollouts are Useful: Down-Sampling Rollouts in LLM Reinforcement Learning](https://arxiv.org//abs/2504.13818)

	Yixuan Even Xu, Yash Savani, Fei Fang, Zico Kolter

+ [Analyzing LLMs' Knowledge Boundary Cognition Across Languages Through the Lens of Internal Representations](https://arxiv.org//abs/2504.13816)

	Chenghao Xiao, Hou Pong Chan, Hao Zhang, Mahani Aljunied, Lidong Bing, Noura Al Moubayed, Yu Rong

+ [Long-context Non-factoid Question Answering in Indic Languages](https://arxiv.org//abs/2504.13615)

	Ritwik Mishra, Rajiv Ratn Shah, Ponnurangam Kumaraguru

# 2025-04-17
+ [GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning](https://arxiv.org//abs/2504.12597)

	Liangyu Xu, Yingxiu Zhao, Jingyun Wang, Yingyao Wang, Bu Pi, Chen Wang, Mingliang Zhang, Jihao Gu, Xiang Li, Xiaoyong Zhu, Jun Song, Bo Zheng



+ [MCP Guardian: A Security-First Layer for Safeguarding MCP-Based AI System](https://arxiv.org//abs/2504.12757)

	Sonu Kumar, Anubhav Girdhar, Ritesh Patil, Divyansh Tripathi

+ [GraphOmni: A Comprehensive and Extendable Benchmark Framework for Large Language Models on Graph-theoretic Tasks](https://arxiv.org//abs/2504.12764)

	Hao Xu, Xiangru Jian, Xinjian Zhao, Wei Pang, Chao Zhang, Suyuchen Wang, Qixin Zhang, Zhengyuan Dong, Joao Monteiro, Bang Liu, Qiuzhuang Sun, Tianshu Yu

+ [QLLM: Do We Really Need a Mixing Network for Credit Assignment in Multi-Agent Reinforcement Learning?](https://arxiv.org//abs/2504.12961)

	Zhouyang Jiang, Bin Zhang, Airong Wei, Zhiwei Xu

+ [Information Gain-Guided Causal Intervention for Autonomous Debiasing Large Language Models](https://arxiv.org//abs/2504.12898)

	Zhouhao Sun, Xiao Ding, Li Du, Yunpeng Xu, Yixuan Ma, Yang Zhao, Bing Qin, Ting Liu

+ [A Theoretical Framework for OOD Robustness in Transformers using Gevrey Classes](https://arxiv.org//abs/2504.12991)

	Yu Wang, Fu-Chieh Chang, Pei-Yuan Wu

+ [Persona-judge: Personalized Alignment of Large Language Models via Token-level Self-judgment](https://arxiv.org//abs/2504.12663)

	Xiaotian Zhang, Ruizhe Chen, Yang Feng, Zuozhu Liu

+ [FreshStack: Building Realistic Benchmarks for Evaluating Retrieval on Technical Documents](https://arxiv.org//abs/2504.13128)

	Nandan Thakur, Jimmy Lin, Sam Havens, Michael Carbin, Omar Khattab, Andrew Drozdov

# 2025-04-16
+ [Activated LoRA: Fine-tuned LLMs for Intrinsics](https://arxiv.org//abs/2504.12397)

	Kristjan Greenewald, Luis Lastras, Thomas Parnell, Vraj Shah, Lucian Popa, Giulio Zizzo, Chulaka Gunasekara, Ambrish Rawat, David Cox

+ [Waking Up an AI: A Quantitative Framework for Prompt-Induced Phase Transition in Large Language Models](https://arxiv.org//abs/2504.21012)

	Makoto Sato

+ [The Devil is in the Prompts: Retrieval-Augmented Prompt Optimization for Text-to-Video Generation](https://arxiv.org//abs/2504.11739)

	Bingjie Gao, Xinyu Gao, Xiaoxue Wu, Yujie Zhou, Yu Qiao, Li Niu, Xinyuan Chen, Yaohui Wang

+ [InjectLab: A Tactical Framework for Adversarial Threat Modeling Against Large Language Models](https://arxiv.org//abs/2505.18156)

	Austin Howard

+ [The Hitchhiker's Guide to Program Analysis, Part II: Deep Thoughts by LLMs](https://arxiv.org//abs/2504.11711)

	Haonan Li, Hang Zhang, Kexin Pei, Zhiyun Qian

# 2025-04-15
+ [Looking beyond the next token](https://arxiv.org//abs/2504.11336)

	Abitha Thankaraj, Yiding Jiang, J. Zico Kolter, Yonatan Bisk

+ [Teaching Large Language Models to Reason through Learning and Forgetting](https://arxiv.org//abs/2504.11364)

	Tianwei Ni, Allen Nie, Sapana Chaudhary, Yao Liu, Huzefa Rangwala, Rasool Fakoor

+ [Nemotron-CrossThink: Scaling Self-Learning beyond Math Reasoning](https://arxiv.org//abs/2504.13941)

	Syeda Nahida Akter, Shrimai Prabhumoye, Matvei Novikov, Seungju Han, Ying Lin, Evelina Bakhturina, Eric Nyberg, Yejin Choi, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro


+ [CLASH: Evaluating Language Models on Judging High-Stakes Dilemmas from Multiple Perspectives](https://arxiv.org//abs/2504.10823)

	Ayoung Lee, Ryan Sungmo Kwon, Peter Railton, Lu Wang

+ [ARise: Towards Knowledge-Augmented Reasoning via Risk-Adaptive Search](https://arxiv.org//abs/2504.10893)

	Yize Zhang, Tianshu Wang, Sirui Chen, Kun Wang, Xingyu Zeng, Hongyu Lin, Xianpei Han, Le Sun, Chaochao Lu

+ [TextArena](https://arxiv.org//abs/2504.11442)

	Leon Guertler, Bobby Cheng, Simon Yu, Bo Liu, Leshem Choshen, Cheston Tan

+ [When is Task Vector Provably Effective for Model Editing? A Generalization Analysis of Nonlinear Transformers](https://arxiv.org//abs/2504.10957)

	Hongkang Li, Yihua Zhang, Shuai Zhang, Meng Wang, Sijia Liu, Pin-Yu Chen

+ [From Misleading Queries to Accurate Answers: A Three-Stage Fine-Tuning Method for LLMs](https://arxiv.org//abs/2504.11277)

	Guocong Li, Weize Liu, Yihang Wu, Ping Wang, Shuaihan Huang, Hongxia Xu, Jian Wu

+ [A Minimalist Approach to LLM Reasoning: from Rejection Sampling to Reinforce](https://arxiv.org//abs/2504.11343)

	Wei Xiong, Jiarui Yao, Yuhui Xu, Bo Pang, Lei Wang, Doyen Sahoo, Junnan Li, Nan Jiang, Tong Zhang, Caiming Xiong, Hanze Dong

# 2025-04-14
+ [Transferable text data distillation by trajectory matching](https://arxiv.org//abs/2504.09818)

	Rong Yao, Hailin Hu, Yifei Fu, Hanting Chen, Wenyi Fang, Fanyi Du, Kai Han, Yunhe Wang

+ [Weight Ensembling Improves Reasoning in Language Models](https://arxiv.org//abs/2504.10478)

	Xingyu Dang, Christina Baek, Kaiyue Wen, Zico Kolter, Aditi Raghunathan

+ [Better Estimation of the KL Divergence Between Language Models](https://arxiv.org//abs/2504.10637)

	Afra Amini, Tim Vieira, Ryan Cotterell

+ [DioR: Adaptive Cognitive Detection and Contextual Retrieval Optimization for Dynamic Retrieval-Augmented Generation](https://arxiv.org//abs/2504.10198)

	Hanghui Guo, Jia Zhu, Shimin Di, Weijie Shi, Zhangze Chen, Jiajie Xu

+ [TAMP: Token-Adaptive Layerwise Pruning in Multimodal Large Language Models](https://arxiv.org//abs/2504.09897)

	Jaewoo Lee, Keyang Xuan, Chanakya Ekbote, Sandeep Polisetty, Yi R. Fung, Paul Pu Liang

+ [S1-Bench: A Simple Benchmark for Evaluating System 1 Thinking Capability of Large Reasoning Models](https://arxiv.org//abs/2504.10368)

	Wenyuan Zhang, Shuaiyi Nie, Xinghua Zhang, Zefeng Zhang, Tingwen Liu

+ [Hallucination Detection in LLMs with Topological Divergence on Attention Graphs](https://arxiv.org//abs/2504.10063)

	Alexandra Bazarova, Aleksandr Yugay, Andrey Shulga, Alina Ermilova, Andrei Volodichev, Konstantin Polev, Julia Belikova, Rauf Parchiev, Dmitry Simakov, Maxim Savchenko, Andrey Savchenko, Serguei Barannikov, Alexey Zaytsev

+ [Stop Anthropomorphizing Intermediate Tokens as Reasoning/Thinking Traces!](https://arxiv.org//abs/2504.09762)

	Subbarao Kambhampati, Kaya Stechly, Karthik Valmeekam, Lucas Saldyt, Siddhant Bhambri, Vardhan Palod, Atharva Gundawar, Soumya Rani Samineni, Durgesh Kalwar, Upasana Biswas

+ [Guiding Reasoning in Small Language Models with LLM Assistance](https://arxiv.org//abs/2504.09923)

	Yujin Kim, Euiin Yi, Minu Kim, Se-Young Yun, Taehyeon Kim

+ [Benchmarking Practices in LLM-driven Offensive Security: Testbeds, Metrics, and Experiment Design](https://arxiv.org//abs/2504.10112)

	Andreas Happe, Jürgen Cito

# 2025-04-13
+ [CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent](https://arxiv.org//abs/2504.13192)

	Liang-bo Ning, Shijie Wang, Wenqi Fan, Qing Li, Xin Xu, Hao Chen, Feiran Huang

+ [EmoAgent: Assessing and Safeguarding Human-AI Interaction for Mental Health Safety](https://arxiv.org//abs/2504.09689)

	Jiahao Qiu, Yinghui He, Xinzhe Juan, Yimin Wang, Yuhan Liu, Zixin Yao, Yue Wu, Xun Jiang, Ling Yang, Mengdi Wang

+ [Mitigating Many-Shot Jailbreaking](https://arxiv.org//abs/2504.09604)

	Christopher M. Ackerman, Nina Panickssery

+ [Quantization Error Propagation: Revisiting Layer-Wise Post-Training Quantization](https://arxiv.org//abs/2504.09629)

	Yamato Arai, Yuma Ichikawa

+ [Understanding LLM Behaviors via Compression: Data Generation, Knowledge Acquisition and Scaling Laws](https://arxiv.org//abs/2504.09597)

	Zhixuan Pan, Shaowen Wang, Jian Li

+ [MLRC-Bench: Can Language Agents Solve Machine Learning Research Challenges?](https://arxiv.org//abs/2504.09702)

	Yunxiang Zhang, Muhammad Khalifa, Shitanshu Bhushan, Grant D Murphy, Lajanugen Logeswaran, Jaekyeom Kim, Moontae Lee, Honglak Lee, Lu Wang

+ [Enhancing Mathematical Reasoning in Large Language Models with Self-Consistency-Based Hallucination Detection](https://arxiv.org//abs/2504.09440)

	MingShan Liu, Shi Bo, Jialing Fang

+ [The Quantum LLM: Modeling Semantic Spaces with Quantum Principles](https://arxiv.org//abs/2504.13202)

	Timo Aukusti Laine

+ [LLMs Can Achieve High-quality Simultaneous Machine Translation as Efficiently as Offline](https://arxiv.org//abs/2504.09570)

	Biao Fu, Minpeng Liao, Kai Fan, Chengxi Li, Liang Zhang, Yidong Chen, Xiaodong Shi

+ [The Structural Safety Generalization Problem](https://arxiv.org//abs/2504.09712)

	Julius Broomfield, Tom Gibbs, Ethan Kosak-Hine, George Ingebretsen, Tia Nasir, Jason Zhang, Reihaneh Iranmanesh, Sara Pieri, Reihaneh Rabbany, Kellin Pelrine

# 2025-04-11
+ [Enterprise-Grade Security for the Model Context Protocol (MCP): Frameworks and Mitigation Strategies](https://arxiv.org//abs/2504.08623)

	Vineeth Sai Narajala, Idan Habler

+ [Large Language Models Could Be Rote Learners](https://arxiv.org//abs/2504.08300)

	Yuyang Xu, Renjun Hu, Haochao Ying, Jian Wu, Xing Shi, Wei Lin

+ [Beyond Self-Reports: Multi-Observer Agents for Personality Assessment in Large Language Models](https://arxiv.org//abs/2504.08399)

	Yin Jou Huang, Rafik Hadfi

+ [Playpen: An Environment for Exploring Learning Through Conversational Interaction](https://arxiv.org//abs/2504.08590)

	Nicola Horst, Davide Mazzaccara, Antonia Schmidt, Michael Sullivan, Filippo Momentè, Luca Franceschetti, Philipp Sadler, Sherzod Hakimov, Alberto Testoni, Raffaella Bernardi, Raquel Fernández, Alexander Koller, Oliver Lemon, David Schlangen, Mario Giulianelli, Alessandro Suglia

+ [DocAgent: A Multi-Agent System for Automated Code Documentation Generation](https://arxiv.org//abs/2504.08725)

	Dayu Yang, Antoine Simoulin, Xin Qian, Xiaoyi Liu, Yuwei Cao, Zhaopu Teng, Grey Yang

# 2025-04-10
+ [Throughput-Optimal Scheduling Algorithms for LLM Inference and AI Agents](https://arxiv.org//abs/2504.07347)

	Yueying Li, Jim Dai, Tianyi Peng


+ [Can Reasoning LLMs Enhance Clinical Document Classification?](https://arxiv.org//abs/2504.08040)

	Akram Mustafa, Usman Naseem, Mostafa Rahimi Azghadi

+ [Seed1.5-Thinking: Advancing Superb Reasoning Models with Reinforcement Learning](https://arxiv.org//abs/2504.13914)

	ByteDance Seed: Jiaze Chen, Tiantian Fan, Xin Liu, Lingjun Liu, Zhiqi Lin, Mingxuan Wang, Chengyi Wang, Xiangpeng Wei, Wenyuan Xu, Yufeng Yuan, Yu Yue, Lin Yan, Qiying Yu, Xiaochen Zuo, Chi Zhang, Ruofei Zhu, Zhecheng An, Zhihao Bai, Yu Bao, Xingyan Bin, Jiangjie Chen, Feng Chen, Hongmin Chen, Riwei Chen, Liangqiang Chen, Zixin Chen, Jinsong Chen, Siyan Chen, Kaiyuan Chen, Zhi Chen, Jin Chen, Jiecao Chen, Jinxin Chi, Weinan Dai, Ning Dai, Jiahui Dai, Shihan Dou, Yantao Du, Zhengyin Du, Jianhui Duan, Chen Dun, Ting-Han Fan, Jiazhan Feng, Junda Feng, Ziyuan Feng, Yuwei Fu, Wenqi Fu, Hanjie Fu, Hao Ge, Hongyi Guo, Mingji Han, Li Han, Wenhao Hao, Xintong Hao, Qianyu He, Jerry He, Feng He, Wen Heng, Zehua Hong, Qi Hou, Liang Hu, Shengding Hu, Nan Hu, Kai Hua, Qi Huang, Ziyue Huang, Hongzhi Huang, Zihao Huang, Ting Huang, Wenhao Huang, Wei Jia, Bin Jia, Xiaoying Jia, Yuhua Jiang, Haobin Jiang, Ziheng Jiang, Kaihua Jiang, Chengquan Jiang, Jianpeng Jiao, Xiaoran Jin, Xing Jin, Xunhao Lai, Zheng Li, Xiang Li, Liyi Li, Hongkai Li, Zheng Li, Shengxian Wan, Ya Wang, Yunshui Li, Chenggang Li, Niuniu Li, Siyu Li, Xi Li, Xiao Li, Aoyan Li, Yuntao Li, Nianning Liang, Xinnian Liang

+ [Towards Combinatorial Interpretability of Neural Computation](https://arxiv.org//abs/2504.08842)

	Micah Adler, Dan Alistarh, Nir Shavit

+ [Understanding Learner-LLM Chatbot Interactions and the Impact of Prompting Guidelines](https://arxiv.org//abs/2504.07840)

	Cansu Koyuturk, Emily Theophilou, Sabrina Patania, Gregor Donabauer, Andrea Martinenghi, Chiara Antico, Alessia Telari, Alessia Testa, Sathya Bursic, Franca Garzotto, Davinia Hernandez-Leo, Udo Kruschwitz, Davide Taibi, Simona Amenta, Martin Ruskov, Dimitri Ognibene

+ [Model Utility Law: Evaluating LLMs beyond Performance through Mechanism Interpretable Metric](https://arxiv.org//abs/2504.07440)

	Yixin Cao, Jiahao Ying, Yaoning Wang, Xipeng Qiu, Xuanjing Huang, Yugang Jiang

+ [SpecReason: Fast and Accurate Inference-Time Compute via Speculative Reasoning](https://arxiv.org//abs/2504.07891)

	Rui Pan, Yinwei Dai, Zhihao Zhang, Gabriele Oliaro, Zhihao Jia, Ravi Netravali

+ [DeepSeek vs. o3-mini: How Well can Reasoning LLMs Evaluate MT and Summarization?](https://arxiv.org//abs/2504.08120)

	Daniil Larionov, Sotaro Takeshita, Ran Zhang, Yanran Chen, Christoph Leiter, Zhipin Wang, Christian Greisinger, Steffen Eger

+ [SD$^2$: Self-Distilled Sparse Drafters](https://arxiv.org//abs/2504.08838)

	Mike Lasby, Nish Sinnadurai, Valavan Manohararajah, Sean Lie, Yani Ioannou, Vithursan Thangarasa

+ [Supervised Optimism Correction: Be Confident When LLMs Are Sure](https://arxiv.org//abs/2504.07527)

	Junjie Zhang, Rushuai Yang, Shunyu Liu, Ting-En Lin, Fei Huang, Yi Chen, Yongbin Li, Dacheng Tao

# 2025-04-09
+ [Understanding Users' Security and Privacy Concerns and Attitudes Towards Conversational AI Platforms](https://arxiv.org//abs/2504.06552)

	Mutahar Ali, Arjun Arunasalam, Habiba Farrukh

+ [Thinking Out Loud: Do Reasoning Models Know When They're Right?](https://arxiv.org//abs/2504.06564)

	Qingcheng Zeng, Weihao Xuan, Leyang Cui, Rob Voigt

+ [FamilyTool: A Multi-hop Personalized Tool Use Benchmark](https://arxiv.org//abs/2504.06766)

	Yuxin Wang, Yiran Guo, Yining Zheng, Zhangyue Yin, Shuo Chen, Jie Yang, Jiajun Chen, Yuan Li, Xuanjing Huang, Xipeng Qiu

+ [Domain-Specific Pruning of Large Mixture-of-Experts Models with Few-shot Demonstrations](https://arxiv.org//abs/2504.06792)

	Zican Dong, Han Peng, Peiyu Liu, Wayne Xin Zhao, Dong Wu, Feng Xiao, Zhifeng Wang

+ [NeedleInATable: Exploring Long-Context Capability of Large Language Models towards Long-Structured Tables](https://arxiv.org//abs/2504.06560)

	Lanrui Wang, Mingyu Zheng, Hongyin Tang, Zheng Lin, Yanan Cao, Jingang Wang, Xunliang Cai, Weiping Wang

+ [RAISE: Reinforced Adaptive Instruction Selection For Large Language Models](https://arxiv.org//abs/2504.07282)

	Lv Qingsong, Yangning Li, Zihua Lan, Zishan Xu, Jiwei Tang, Yinghui Li, Wenhao Jiang, Hai-Tao Zheng, Philip S. Yu

+ [AssistanceZero: Scalably Solving Assistance Games](https://arxiv.org//abs/2504.07091)

	Cassidy Laidlaw, Eli Bronstein, Timothy Guo, Dylan Feng, Lukas Berglund, Justin Svegliato, Stuart Russell, Anca Dragan

# 2025-04-08
+ [V-MAGE: A Game Evaluation Framework for Assessing Vision-Centric Capabilities in Multimodal Large Language Models](https://arxiv.org//abs/2504.06148)

	Xiangxi Zheng, Linjie Li, Zhengyuan Yang, Ping Yu, Alex Jinpeng Wang, Rui Yan, Yuan Yao, Lijuan Wang

+ [Leveraging Robust Optimization for LLM Alignment under Distribution Shifts](https://arxiv.org//abs/2504.05831)

	Mingye Zhu, Yi Liu, Zheren Fu, Yongdong Zhang, Zhendong Mao

+ [Right Question is Already Half the Answer: Fully Unsupervised LLM Reasoning Incentivization](https://arxiv.org//abs/2504.05812)

	Qingyang Zhang, Haitao Wu, Changqing Zhang, Peilin Zhao, Yatao Bian

+ [StealthRank: LLM Ranking Manipulation via Stealthy Prompt Optimization](https://arxiv.org//abs/2504.05804)

	Yiming Tang, Yi Fan, Chenxiao Yu, Tiankai Yang, Yue Zhao, Xiyang Hu

+ [Hogwild! Inference: Parallel LLM Generation via Concurrent Attention](https://arxiv.org//abs/2504.06261)

	Gleb Rodionov, Roman Garipov, Alina Shutova, George Yakushev, Erik Schultheis, Vage Egiazarian, Anton Sinitsin, Denis Kuznedelev, Dan Alistarh

+ [Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking](https://arxiv.org//abs/2504.05652)

	Yu-Hang Wu, Yu-Jie Xiong, Hao Zhang, Jia-Chen Zhang, Zheng Zhou

+ [Single-Agent vs. Multi-Agent LLM Strategies for Automated Student Reflection Assessment](https://arxiv.org//abs/2504.05716)

	Gen Li, Li Chen, Cheng Tang, Valdemar Švábenský, Daisuke Deguchi, Takayoshi Yamashita, Atsushi Shimada

+ [Reasoning Towards Fairness: Mitigating Bias in Language Models through Reasoning-Guided Fine-Tuning](https://arxiv.org//abs/2504.05632)

	Sanchit Kabra, Akshita Jha, Chandan K. Reddy

# 2025-04-07


+ [A Desideratum for Conversational Agents: Capabilities, Challenges, and Future Directions](https://arxiv.org//abs/2504.16939)

	Emre Can Acikgoz, Cheng Qian, Hongru Wang, Vardhan Dongre, Xiusi Chen, Heng Ji, Dilek Hakkani-Tür, Gokhan Tur

+ [Not All Data Are Unlearned Equally](https://arxiv.org//abs/2504.05058)

	Aravind Krishnan, Siva Reddy, Marius Mosbach


+ [Lightweight and Direct Document Relevance Optimization for Generative Information Retrieval](https://arxiv.org//abs/2504.05181)

	Kidist Amde Mekonnen, Yubao Tang, Maarten de Rijke

+ [CCSK:Cognitive Convection of Self-Knowledge Based Retrieval Augmentation for Large Language Models](https://arxiv.org//abs/2504.10498)

	Jianling Lu, Mingqi Lv, Tieming Chen

+ [LLM-based Automated Grading with Human-in-the-Loop](https://arxiv.org//abs/2504.05239)

	Hang Li, Yucheng Chu, Kaiqi Yang, Yasemin Copur-Gencturk, Jiliang Tang

+ [SEAL: Steerable Reasoning Calibration of Large Language Models for Free](https://arxiv.org//abs/2504.07986)

	Runjin Chen, Zhenyu Zhang, Junyuan Hong, Souvik Kundu, Zhangyang Wang

+ [AccLLM: Accelerating Long-Context LLM Inference Via Algorithm-Hardware Co-Design](https://arxiv.org//abs/2505.03745)

	Yanbiao Liang, Huihong Shi, Haikuo Shao, Zhongfeng Wang

+ [Promoting Security and Trust on Social Networks: Explainable Cyberbullying Detection Using Large Language Models in a Stream-Based Machine Learning Framework](https://arxiv.org//abs/2505.03746)

	Silvia García-Méndez, Francisco De Arriba-Pérez

+ [Beyond Single-Turn: A Survey on Multi-Turn Interactions with Large Language Models](https://arxiv.org//abs/2504.04717)

	Yubo Li, Xiaobin Shen, Xinyu Yao, Xueying Ding, Yidi Miao, Ramayya Krishnan, Rema Padman

+ [Concise Reasoning via Reinforcement Learning](https://arxiv.org//abs/2504.05185)

	Mehdi Fatemi, Banafsheh Rafiee, Mingjie Tang, Kartik Talamadupula

+ [Debate Only When Necessary: Adaptive Multiagent Collaboration for Efficient LLM Reasoning](https://arxiv.org//abs/2504.05047)

	Sugyeong Eo, Hyeonseok Moon, Evelyn Hayoon Zi, Chanjun Park, Heuiseok Lim

+ [Achieving binary weight and activation for LLMs using Post-Training Quantization](https://arxiv.org//abs/2504.05352)

	Siqing Song, Chuang Wang, Ruiqi Wang, Yi Yang, Xuyao Zhang

+ [AI for Climate Finance: Agentic Retrieval and Multi-Step Reasoning for Early Warning System Investments](https://arxiv.org//abs/2504.05104)

	Saeid Ario Vaghefi, Aymane Hachcham, Veronica Grasso, Jiska Manicus, Nakiete Msemo, Chiara Colesanti Senni, Markus Leippold

+ [Learning to Reason Over Time: Timeline Self-Reflection for Improved Temporal Reasoning in Language Models](https://arxiv.org//abs/2504.05258)

	Adrián Bazaga, Rexhina Blloshmi, Bill Byrne, Adrià de Gispert

+ [Post-Training Language Models for Continual Relation Extraction](https://arxiv.org//abs/2504.05214)

	Sefika Efeoglu, Adrian Paschke, Sonja Schimmler

+ [Can LLMs Interpret and Leverage Structured Linguistic Representations? A Case Study with AMRs](https://arxiv.org//abs/2504.04745)

	Ankush Raut, Xiaofeng Zhu, Maria Leonor Pacheco

+ [Don't Lag, RAG: Training-Free Adversarial Detection Using RAG](https://arxiv.org//abs/2504.04858)

	Roie Kazoom, Raz Lapid, Moshe Sipper, Ofer Hadar

# 2025-04-06
+ ["Trust me on this" Explaining Agent Behavior to a Human Terminator](https://arxiv.org//abs/2504.04592)

	Uri Menkes, Assaf Hallak, Ofra Amir

+ [Exploring Generative AI Techniques in Government: A Case Study](https://arxiv.org//abs/2504.10497)

	Sunyi Liu, Mengzhe Geng, Rebecca Hart

# 2025-04-05
+ [Among Us: A Sandbox for Measuring and Detecting Agentic Deception](https://arxiv.org//abs/2504.04072)

	Satvik Golechha, Adrià Garriga-Alonso

+ [FISH-Tuning: Enhancing PEFT Methods with Fisher Information](https://arxiv.org//abs/2504.04050)

	Kang Xue, Ming Dong, Xinhui Tu, Tingting He

+ [Cognitive Debiasing Large Language Models for Decision-Making](https://arxiv.org//abs/2504.04141)

	Yougang Lyu, Shijie Ren, Yue Feng, Zihan Wang, Zhumin Chen, Zhaochun Ren, Maarten de Rijke

+ [An Explicit Syllogistic Legal Reasoning Framework for Large Language Models](https://arxiv.org//abs/2504.04042)

	Kepu Zhang, Weijie Yu, Zhongxiang Sun, Jun Xu

# 2025-04-04
+ [Noise Augmented Fine Tuning for Mitigating Hallucinations in Large Language Models](https://arxiv.org//abs/2504.03302)

	Afshin Khadangi, Amir Sartipi, Igor Tchappi, Ramin Bahmani

+ [APIGen-MT: Agentic Pipeline for Multi-Turn Data Generation via Simulated Agent-Human Interplay](https://arxiv.org//abs/2504.03601)

	Akshara Prabhakar, Zuxin Liu, Ming Zhu, Jianguo Zhang, Tulika Awalgaonkar, Shiyu Wang, Zhiwei Liu, Haolin Chen, Thai Hoang, Juan Carlos Niebles, Shelby Heinecke, Weiran Yao, Huan Wang, Silvio Savarese, Caiming Xiong

+ [How Social is It? A Benchmark for LLMs' Capabilities in Multi-user Multi-turn Social Agent Tasks](https://arxiv.org//abs/2505.04628)

	Yusen Wu, Junwu Xiong, Xiaotie Deng

+ [Think When You Need: Self-Adaptive Chain-of-Thought Learning](https://arxiv.org//abs/2504.03234)

	Junjie Yang, Ke Lin, Xing Yu

+ [SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge Refinement](https://arxiv.org//abs/2504.03561)

	Runnan Fang, Xiaobin Wang, Yuan Liang, Shuofei Qiao, Jialong Wu, Zekun Xi, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen

+ [Agentic Knowledgeable Self-awareness](https://arxiv.org//abs/2504.03553)

	Shuofei Qiao, Zhisong Qiu, Baochang Ren, Xiaobin Wang, Xiangyuan Ru, Ningyu Zhang, Xiang Chen, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen

+ [BabyLM's First Words: Word Segmentation as a Phonological Probing Task](https://arxiv.org//abs/2504.03338)

	Zébulon Goriely, Paula Buttery

# 2025-04-03
+ [Cognitive Memory in Large Language Models](https://arxiv.org//abs/2504.02441)

	Lianlei Shan, Shixian Luo, Zezhou Zhu, Yu Yuan, Yong Wu


+ [Multifaceted Evaluation of Audio-Visual Capability for MLLMs: Effectiveness, Efficiency, Generalizability and Robustness](https://arxiv.org//abs/2504.16936)

	Yusheng Zhao, Junyu Luo, Xiao Luo, Weizhi Zhang, Zhiping Xiao, Wei Ju, Philip S. Yu, Ming Zhang



+ [Generative Evaluation of Complex Reasoning in Large Language Models](https://arxiv.org//abs/2504.02810)

	Haowei Lin, Xiangyu Wang, Ruilin Yan, Baizhou Huang, Haotian Ye, Jianhua Zhu, Zihao Wang, James Zou, Jianzhu Ma, Yitao Liang

+ [GPG: A Simple and Strong Reinforcement Learning Baseline for Model Reasoning](https://arxiv.org//abs/2504.02546)

	Xiangxiang Chu, Hailang Huang, Xiao Zhang, Fei Wei, Yong Wang

+ [GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image Generation](https://arxiv.org//abs/2504.02782)

	Zhiyuan Yan, Junyan Ye, Weijia Li, Zilong Huang, Shenghai Yuan, Xiangyang He, Kaiqing Lin, Jun He, Conghui He, Li Yuan

+ [Why do LLMs attend to the first token?](https://arxiv.org//abs/2504.02732)

	Federico Barbero, Álvaro Arroyo, Xiangming Gu, Christos Perivolaropoulos, Michael Bronstein, Petar Veličković, Razvan Pascanu

+ [GPTAQ: Efficient Finetuning-Free Quantization for Asymmetric Calibration](https://arxiv.org//abs/2504.02692)

	Yuhang Li, Ruokai Yin, Donghyun Lee, Shiting Xiao, Priyadarshini Panda

+ [Pel, A Programming Language for Orchestrating AI Agents](https://arxiv.org//abs/2505.13453)

	Behnam Mohammadi

+ [Layers at Similar Depths Generate Similar Activations Across LLM Architectures](https://arxiv.org//abs/2504.08775)

	Christopher Wolfram, Aaron Schein

+ [Overcoming Sparsity Artifacts in Crosscoders to Interpret Chat-Tuning](https://arxiv.org//abs/2504.02922)

	Julian Minder, Clément Dumas, Caden Juang, Bilal Chugtai, Neel Nanda

+ [LLM Social Simulations Are a Promising Research Method](https://arxiv.org//abs/2504.02234)

	Jacy Reese Anthis, Ryan Liu, Sean M. Richardson, Austin C. Kozlowski, Bernard Koch, James Evans, Erik Brynjolfsson, Michael Bernstein

+ [Datrics Text2SQL: A Framework for Natural Language to SQL Query Generation](https://arxiv.org//abs/2506.12234)

	Tetiana Gladkykh, Kyrylo Kirykov

+ [Affordable AI Assistants with Knowledge Graph of Thoughts](https://arxiv.org//abs/2504.02670)

	Maciej Besta, Lorenzo Paleari, Jia Hao Andrea Jiang, Robert Gerstenberger, You Wu, Jón Gunnar Hannesson, Patrick Iff, Ales Kubicek, Piotr Nyczyk, Diana Khimey, Nils Blach, Haiqiang Zhang, Tao Zhang, Peiran Ma, Grzegorz Kwaśniewski, Marcin Copik, Hubert Niewiadomski, Torsten Hoefler

# 2025-04-02
+ [LRAGE: Legal Retrieval Augmented Generation Evaluation Tool](https://arxiv.org//abs/2504.01840)

	Minhu Park, Hongseok Oh, Eunkyung Choi, Wonseok Hwang

+ [TiC-LM: A Web-Scale Benchmark for Time-Continual LLM Pretraining](https://arxiv.org//abs/2504.02107)

	Jeffrey Li, Mohammadreza Armandpour, Iman Mirzadeh, Sachin Mehta, Vaishaal Shankar, Raviteja Vemulapalli, Samy Bengio, Oncel Tuzel, Mehrdad Farajtabar, Hadi Pouransari, Fartash Faghri

+ [An Illusion of Progress? Assessing the Current State of Web Agents](https://arxiv.org//abs/2504.01382)

	Tianci Xue, Weijian Qi, Tianneng Shi, Chan Hee Song, Boyu Gou, Dawn Song, Huan Sun, Yu Su

+ [DeepSeek-R1 Thoughtology: Let's think about LLM Reasoning](https://arxiv.org//abs/2504.07128)

	Sara Vera Marjanović, Arkil Patel, Vaibhav Adlakha, Milad Aghajohari, Parishad BehnamGhader, Mehar Bhatia, Aditi Khandelwal, Austin Kraft, Benno Krojer, Xing Han Lù, Nicholas Meade, Dongchan Shin, Amirhossein Kazemnejad, Gaurav Kamath, Marius Mosbach, Karolina Stańczak, Siva Reddy

+ [Do Theory of Mind Benchmarks Need Explicit Human-like Reasoning in Language Models?](https://arxiv.org//abs/2504.01698)

	Yi-Long Lu, Chunhui Zhang, Jiajun Song, Lifeng Fan, Wei Wang

+ [Scaling Test-Time Inference with Policy-Optimized, Dynamic Retrieval-Augmented Generation via KV Caching and Decoding](https://arxiv.org//abs/2504.01281)

	Sakhinana Sagar Srinivas, Akash Das, Shivam Gupta, Venkataramana Runkana

+ [GTR: Graph-Table-RAG for Cross-Table Question Answering](https://arxiv.org//abs/2504.01346)

	Jiaru Zou, Dongqi Fu, Sirui Chen, Xinrui He, Zihao Li, Yada Zhu, Jiawei Han, Jingrui He

+ [Style over Substance: Distilled Language Models Reason Via Stylistic Replication](https://arxiv.org//abs/2504.01738)

	Philip Lippmann, Jie Yang

# 2025-04-01
+ [GraphMaster: Automated Graph Synthesis via LLM Agents in Data-Limited Environments](https://arxiv.org//abs/2504.00711)

	Enjun Du, Xunkai Li, Tian Jin, Zhihan Zhang, Rong-Hua Li, Guoren Wang

+ [Catch Me if You Search: When Contextual Web Search Results Affect the Detection of Hallucinations](https://arxiv.org//abs/2504.01153)

	Mahjabin Nahar, Eun-Ju Lee, Jin Won Park, Dongwon Lee

+ [Do We Truly Need So Many Samples? Multi-LLM Repeated Sampling Efficiently Scales Test-Time Compute](https://arxiv.org//abs/2504.00762)

	Jianhao Chen, Zishuo Xun, Bocheng Zhou, Han Qi, Hangfan Zhang, Qiaosheng Zhang, Yang Chen, Wei Hu, Yuzhong Qu, Wanli Ouyang, Shuyue Hu

+ [AI Hiring with LLMs: A Context-Aware and Explainable Multi-Agent Framework for Resume Screening](https://arxiv.org//abs/2504.02870)

	Frank P.-W. Lo, Jianing Qiu, Zeyu Wang, Haibao Yu, Yeming Chen, Gao Zhang, Benny Lo

+ [Token embeddings violate the manifold hypothesis](https://arxiv.org//abs/2504.01002)

	Michael Robinson, Sourya Dey, Tony Chiang

+ [AgentNet: Decentralized Evolutionary Coordination for LLM-based Multi-Agent Systems](https://arxiv.org//abs/2504.00587)

	Yingxuan Yang, Huacan Chai, Shuai Shao, Yuanyi Song, Siyuan Qi, Renting Rui, Weinan Zhang

# 2025-03-31
+ [Dynamic Parametric Retrieval Augmented Generation for Test-time Knowledge Enhancement](https://arxiv.org//abs/2503.23895)

	Yuqiao Tan, Shizhu He, Huanxuan Liao, Jun Zhao, Kang Liu

+ [A Survey on Test-Time Scaling in Large Language Models: What, How, Where, and How Well?](https://arxiv.org//abs/2503.24235)

	Qiyuan Zhang, Fuyuan Lyu, Zexu Sun, Lei Wang, Weixu Zhang, Wenyue Hua, Haolun Wu, Zhihan Guo, Yufei Wang, Niklas Muennighoff, Irwin King, Xue Liu, Chen Ma

+ [Rec-R1: Bridging Generative Large Language Models and User-Centric Recommendation Systems via Reinforcement Learning](https://arxiv.org//abs/2503.24289)

	Jiacheng Lin, Tian Wang, Kun Qian

+ [Is analogy enough to draw novel adjective-noun inferences?](https://arxiv.org//abs/2503.24293)

	Hayley Ross, Kathryn Davidson, Najoung Kim

+ [Effectively Controlling Reasoning Models through Thinking Intervention](https://arxiv.org//abs/2503.24370)

	Tong Wu, Chong Xiang, Jiachen T. Wang, G. Edward Suh, Prateek Mittal

+ [Enhancing Large Language Models (LLMs) for Telecommunications using Knowledge Graphs and Retrieval-Augmented Generation](https://arxiv.org//abs/2503.24245)

	Dun Yuan, Hao Zhou, Di Wu, Xue Liu, Hao Chen, Yan Xin, Jianzhong (Charlie)Zhang

+ [STI-Bench: Are MLLMs Ready for Precise Spatial-Temporal World Understanding?](https://arxiv.org//abs/2503.23765)

	Yun Li, Yiming Zhang, Tao Lin, XiangRui Liu, Wenxiao Cai, Zheng Liu, Bo Zhao

+ [DebFlow: Automating Agent Creation via Agent Debate](https://arxiv.org//abs/2503.23781)

	Jinwei Su, Yinghui Xia, Ronghua Shi, Jianhui Wang, Jianuo Huang, Yijin Wang, Tianyu Shi, Yang Jingsong, Lewei He

# 2025-03-30
+ [A Survey of WebAgents: Towards Next-Generation AI Agents for Web Automation with Large Foundation Models](https://arxiv.org//abs/2503.23350)

	Liangbo Ning, Ziran Liang, Zhuohang Jiang, Haohao Qu, Yujuan Ding, Wenqi Fan, Xiao-yong Wei, Shanru Lin, Hui Liu, Philip S. Yu, Qing Li

+ [Mixture of Routers](https://arxiv.org//abs/2503.23362)

	Jia-Chen Zhang, Yu-Jie Xiong, Xi-He Qiu, Chun-Ming Xia, Fei Dai

+ [RARE: Retrieval-Augmented Reasoning Modeling](https://arxiv.org//abs/2503.23513)

	Zhengren Wang, Jiayang Yu, Dongsheng Ma, Zhe Chen, Yu Wang, Zhiyu Li, Feiyu Xiong, Yanfeng Wang, Weinan E, Linpeng Tang, Wentao Zhang

+ [MiZero: The Shadowy Defender Against Text Style Infringements](https://arxiv.org//abs/2504.00035)

	Ziwei Zhang, Juan Wen, Wanli Peng, Zhengxian Wu, Yinghan Zhou, Yiming Xue

+ [Large Language and Reasoning Models are Shallow Disjunctive Reasoners](https://arxiv.org//abs/2503.23487)

	Irtaza Khalid, Amir Masoud Nourollah, Steven Schockaert

+ [SCORE: Story Coherence and Retrieval Enhancement for AI Narratives](https://arxiv.org//abs/2503.23512)

	Qiang Yi, Yangfan He, Jianhui Wang, Xinyuan Song, Shiyao Qian, Xinhang Yuan, Li Sun, Yi Xin, Jingqun Tang, Keqin Li, Kuan Lu, Menghao Huo, Jiaqi Chen, Tianyu Shi

# 2025-03-29
+ [LangVAE and LangSpace: Building and Probing for Language Model VAEs](https://arxiv.org//abs/2505.00004)

	Danilo S. Carvalho, Yingji Zhang, Harriet Unsworth, André Freitas

+ [MoLAE: Mixture of Latent Experts for Parameter-Efficient Language Models](https://arxiv.org//abs/2503.23100)

	Zehua Liu, Han Wu, Ruifeng She, Xiaojin Fu, Xiongwei Han, Tao Zhong, Mingxuan Yuan

+ [MHTS: Multi-Hop Tree Structure Framework for Generating Difficulty-Controllable QA Datasets for RAG Evaluation](https://arxiv.org//abs/2504.08756)

	Jeongsoo Lee, Daeyong Kwon, Kyohoon Jin, Junnyeong Jeong, Minwoo Sim, Minwoo Kim

+ [Evaluating how LLM annotations represent diverse views on contentious topics](https://arxiv.org//abs/2503.23243)

	Megan A. Brown, Shubham Atreja, Libby Hemphill, Patrick Y. Wu

+ [Efficient Inference for Large Reasoning Models: A Survey](https://arxiv.org//abs/2503.23077)

	Yue Liu, Jiaying Wu, Yufei He, Hongcheng Gao, Hongyu Chen, Baolong Bi, Ruihan Gong, Jiaheng Zhang, Zhiqi Huang, Bryan Hooi

# 2025-03-28
+ [Probabilistic Uncertain Reward Model: A Natural Generalization of Bradley-Terry Reward Model](https://arxiv.org//abs/2503.22480)

	Wangtao Sun, Xiang Cheng, Xing Yu, Haotian Xu, Zhao Yang, Shizhu He, Jun Zhao, Kang Liu

+ [The Mind in the Machine: A Survey of Incorporating Psychological Theories in LLMs](https://arxiv.org//abs/2505.00003)

	Zizhou Liu, Ziwei Gong, Lin Ai, Zheng Hui, Run Chen, Colin Wayne Leach, Michelle R. Greene, Julia Hirschberg

+ [Why Stop at One Error? Benchmarking LLMs as Data Science Code Debuggers for Multi-Hop and Multi-Bug Errors](https://arxiv.org//abs/2503.22388)

	Zhiyu Yang, Shuo Wang, Yukun Yan, Yang Deng

+ [Agent-Centric Personalized Multiple Clustering with Multi-Modal LLMs](https://arxiv.org//abs/2503.22241)

	Ziye Chen, Yiqun Duan, Riheng Zhu, Zhenbang Sun, Mingming Gong

+ [Firm or Fickle? Evaluating Large Language Models Consistency in Sequential Interactions](https://arxiv.org//abs/2503.22353)

	Yubo Li, Yidi Miao, Xueying Ding, Ramayya Krishnan, Rema Padman

+ [Understanding Inequality of LLM Fact-Checking over Geographic Regions with Agent and Retrieval models](https://arxiv.org//abs/2503.22877)

	Bruno Coelho, Shujaat Mirza, Yuyuan Cui, Christina Pöpper, Damon McCoy

+ [Landscape of Thoughts: Visualizing the Reasoning Process of Large Language Models](https://arxiv.org//abs/2503.22165)

	Zhanke Zhou, Zhaocheng Zhu, Xuan Li, Mikhail Galkin, Xiao Feng, Sanmi Koyejo, Jian Tang, Bo Han

# 2025-03-27
+ [Shared Global and Local Geometry of Language Model Embeddings](https://arxiv.org//abs/2503.21073)

	Andrew Lee, Melanie Weber, Fernanda Viégas, Martin Wattenberg

+ [A Computational Theory for Efficient Mini Agent Evaluation with Causal Guarantees](https://arxiv.org//abs/2503.21138)

	Hedong Yan

+ [Alleviating LLM-based Generative Retrieval Hallucination in Alipay Search](https://arxiv.org//abs/2503.21098)

	Yedan Shen, Kaixin Wu, Yuechen Ding, Jingyuan Wen, Hong Liu, Mingjie Zhong, Zhouhan Lin, Jia Xu, Linjian Mo

+ [UI-R1: Enhancing Efficient Action Prediction of GUI Agents by Reinforcement Learning](https://arxiv.org//abs/2503.21620)

	Zhengxi Lu, Yuxiang Chai, Yaxuan Guo, Xi Yin, Liang Liu, Hao Wang, Han Xiao, Shuai Ren, Guanjing Xiong, Hongsheng Li

+ [Video-R1: Reinforcing Video Reasoning in MLLMs](https://arxiv.org//abs/2503.21776)

	Kaituo Feng, Kaixiong Gong, Bohao Li, Zonghao Guo, Yibing Wang, Tianshuo Peng, Junfei Wu, Xiaoying Zhang, Benyou Wang, Xiangyu Yue

+ [ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large Reasoning Models with Iterative Retrieval Augmented Generation](https://arxiv.org//abs/2503.21729)

	Zhicheng Lee, Shulin Cao, Jinxin Liu, Jiajie Zhang, Weichuan Liu, Xiaoyin Che, Lei Hou, Juanzi Li

+ [MoQa: Rethinking MoE Quantization with Multi-stage Data-model Distribution Awareness](https://arxiv.org//abs/2503.21135)

	Zihao Zheng, Xiuping Cui, Size Zheng, Maoliang Li, Jiayu Chen, Yun Liang, Xiang Chen

+ [HyperGraphRAG: Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation](https://arxiv.org//abs/2503.21322)

	Haoran Luo, Haihong E, Guanting Chen, Yandan Zheng, Xiaobao Wu, Yikai Guo, Qika Lin, Yu Feng, Zemin Kuang, Meina Song, Yifan Zhu, Luu Anh Tuan

+ [LLaVA-CMoE: Towards Continual Mixture of Experts for Large Vision-Language Models](https://arxiv.org//abs/2503.21227)

	Hengyuan Zhao, Ziqin Wang, Qixin Sun, Kaiyou Song, Yilin Li, Xiaolin Hu, Qingpei Guo, Si Liu

# 2025-03-26
+ [Dynamic Pyramid Network for Efficient Multimodal Large Language Model](https://arxiv.org//abs/2503.20322)

	Hao Ai, Kunyi Wang, Zezhou Wang, Hao Lu, Jin Tian, Yaxin Luo, Peng Xing, Jen-Yuan Huang, Huaxia Li, Gen luo


+ [Clean & Clear: Feasibility of Safe LLM Clinical Guidance](https://arxiv.org//abs/2503.20953)

	Julia Ive, Felix Jozsa, Nick Jackson, Paulina Bondaronek, Ciaran Scott Hill, Richard Dobson

+ [A Multilingual, Culture-First Approach to Addressing Misgendering in LLM Applications](https://arxiv.org//abs/2503.20302)

	Sunayana Sitaram, Adrian de Wynter, Isobel McCrum, Qilong Gu, Si-Qing Chen

+ [Optimizing Case-Based Reasoning System for Functional Test Script Generation with Large Language Models](https://arxiv.org//abs/2503.20576)

	Siyuan Guo, Huiwu Liu, Xiaolong Chen, Yuming Xie, Liang Zhang, Tao Han, Hechang Chen, Yi Chang, Jun Wang

+ [Unlocking Efficient Long-to-Short LLM Reasoning with Model Merging](https://arxiv.org//abs/2503.20641)

	Han Wu, Yuxuan Yao, Shuqi Liu, Zehua Liu, Xiaojin Fu, Xiongwei Han, Xing Li, Hui-Ling Zhen, Tao Zhong, Mingxuan Yuan

+ [Prompting is Not All You Need! Evaluating LLM Agent Simulation Methodologies with Real-World Online Customer Behavior Data](https://arxiv.org//abs/2503.20749)

	Yuxuan Lu, Jing Huang, Yan Han, Bingsheng Yao, Sisong Bei, Jiri Gesi, Yaochen Xie, Zheshen (Jessie)Wang, Qi He, Dakuo Wang

+ [ADS-Edit: A Multimodal Knowledge Editing Dataset for Autonomous Driving Systems](https://arxiv.org//abs/2503.20756)

	Chenxi Wang, Jizhan Fang, Xiang Chen, Bozhong Tian, Ziwen Xu, Huajun Chen, Ningyu Zhang

+ [3MDBench: Medical Multimodal Multi-agent Dialogue Benchmark](https://arxiv.org//abs/2504.13861)

	Ivan Sviridov, Amina Miftakhova, Artemiy Tereshchenko, Galina Zubkova, Pavel Blinov, Andrey Savchenko

# 2025-03-25
+ [CausalRAG: Integrating Causal Graphs into Retrieval-Augmented Generation](https://arxiv.org//abs/2503.19878)

	Nengbo Wang, Xiaotian Han, Jagdip Singh, Jing Ma, Vipin Chaudhary

+ [Rosetta-PL: Propositional Logic as a Benchmark for Large Language Model Reasoning](https://arxiv.org//abs/2505.00001)

	Shaun Baek, Shaun Esua-Mensah, Cyrus Tsui, Sejan Vigneswaralingam, Abdullah Alali, Michael Lu, Vasu Sharma, Kevin Zhu

+ [OAEI-LLM-T: A TBox Benchmark Dataset for Understanding Large Language Model Hallucinations in Ontology Matching](https://arxiv.org//abs/2503.21813)

	Zhangcheng Qiang

+ [Universal Cross-Tokenizer Distillation via Approximate Likelihood Matching](https://arxiv.org//abs/2503.20083)

	Benjamin Minixhofer, Ivan Vulić, Edoardo Maria Ponti

+ [Beyond Verifiable Rewards: Scaling Reinforcement Learning for Language Models to Unverifiable Data](https://arxiv.org//abs/2503.19618)

	Yunhao Tang, Sid Wang, Lovish Madaan, Rémi Munos

+ [LEGO-Puzzles: How Good Are MLLMs at Multi-Step Spatial Reasoning?](https://arxiv.org//abs/2503.19990)

	Kexian Tang, Junyao Gao, Yanhong Zeng, Haodong Duan, Yanan Sun, Zhening Xing, Wenran Liu, Kaifeng Lyu, Kai Chen

# 2025-03-24
+ [SimpleRL-Zoo: Investigating and Taming Zero Reinforcement Learning for Open Base Models in the Wild](https://arxiv.org//abs/2503.18892)

	Weihao Zeng, Yuzhen Huang, Qian Liu, Wei Liu, Keqing He, Zejun Ma, Junxian He

+ [Oaken: Fast and Efficient LLM Serving with Online-Offline Hybrid KV Cache Quantization](https://arxiv.org//abs/2503.18599)

	Minsu Kim, Seongmin Hong, RyeoWook Ko, Soongyu Choi, Hunjong Lee, Junsoo Kim, Joo-Young Kim, Jongse Park

+ [REALM: A Dataset of Real-World LLM Use Cases](https://arxiv.org//abs/2503.18792)

	Jingwen Cheng, Kshitish Ghate, Wenyue Hua, William Yang Wang, Hong Shen, Fei Fang

# 2025-03-23
+ [HAIR: Hardness-Aware Inverse Reinforcement Learning with Introspective Reasoning for LLM Alignment](https://arxiv.org//abs/2503.18991)

	Ruoxi Cheng, Haoxuan Ma, Weixin Wang

+ [Adaptive Rank Allocation: Speeding Up Modern Transformers with RaNA Adapters](https://arxiv.org//abs/2503.18216)

	Roberto Garcia, Jerry Liu, Daniel Sorvisto, Sabri Eyuboglu

+ [DeLoRA: Decoupling Angles and Strength in Low-rank Adaptation](https://arxiv.org//abs/2503.18225)

	Massimo Bini, Leander Girrbach, Zeynep Akata

+ [MathAgent: Leveraging a Mixture-of-Math-Agent Framework for Real-World Multimodal Mathematical Error Detection](https://arxiv.org//abs/2503.18132)

	Yibo Yan, Shen Wang, Jiahao Huo, Philip S. Yu, Xuming Hu, Qingsong Wen

+ [MedPlan:A Two-Stage RAG-Based System for Personalized Medical Plan Generation](https://arxiv.org//abs/2503.17900)

	Hsin-Ling Hsu, Cong-Tinh Dao, Luning Wang, Zitao Shuai, Thao Nguyen Minh Phan, Jun-En Ding, Chun-Chieh Liao, Pengfei Hu, Xiaoxue Han, Chih-Ho Hsu, Dongsheng Luo, Wen-Chih Peng, Feng Liu, Fang-Ming Hung, Chenwei Wu

+ [Experience Retrieval-Augmentation with Electronic Health Records Enables Accurate Discharge QA](https://arxiv.org//abs/2503.17933)

	Justice Ou, Tinglin Huang, Yilun Zhao, Ziyang Yu, Peiqing Lu, Rex Ying

+ [ShED-HD: A Shannon Entropy Distribution Framework for Lightweight Hallucination Detection on Edge Devices](https://arxiv.org//abs/2503.18242)

	Aneesh Vathul, Daniel Lee, Sheryl Chen, Arthi Tasmia

# 2025-03-22
+ [Evaluating Clinical Competencies of Large Language Models with a General Practice Benchmark](https://arxiv.org//abs/2503.17599)

	Zheqing Li, Yiying Yang, Jiping Lang, Wenhao Jiang, Yuhang Zhao, Shuang Li, Dingqian Wang, Zhu Lin, Xuanna Li, Yuze Tang, Jiexian Qiu, Xiaolin Lu, Hongji Yu, Shuang Chen, Yuhua Bi, Xiaofei Zeng, Yixian Chen, Junrong Chen, Lin Yao

+ [Safe RLHF-V: Safe Reinforcement Learning from Multi-modal Human Feedback](https://arxiv.org//abs/2503.17682)

	Jiaming Ji, Xinyu Chen, Rui Pan, Conghui Zhang, Han Zhu, Jiahao Li, Donghai Hong, Boyuan Chen, Jiayi Zhou, Kaile Wang, Juntao Dai, Chi-Min Chan, Yida Tang, Sirui Han, Yike Guo, Yaodong Yang

# 2025-03-21
+ [A Survey on Personalized Alignment -- The Missing Piece for Large Language Models in Real-World Applications](https://arxiv.org//abs/2503.17003)

	Jian Guan, Junfei Wu, Jia-Nan Li, Chuanqi Cheng, Wei Wu

+ [ConvoGen: Enhancing Conversational AI with Synthetic Data: A Multi-Agent Approach](https://arxiv.org//abs/2503.17460)

	Reem Gody, Mahmoud Goudy, Ahmed Y. Tawfik

+ [MedAgent-Pro: Towards Evidence-based Multi-modal Medical Diagnosis via Reasoning Agentic Workflow](https://arxiv.org//abs/2503.18968)

	Ziyue Wang, Junde Wu, Linghan Cai, Chang Han Low, Xihong Yang, Qiaxuan Li, Yueming Jin

+ [Understanding Bias Reinforcement in LLM Agents Debate](https://arxiv.org//abs/2503.16814)

	Jihwan Oh, Minchan Jeong, Jongwoo Ko, Se-Young Yun

+ [FactSelfCheck: Fact-Level Black-Box Hallucination Detection for LLMs](https://arxiv.org//abs/2503.17229)

	Albert Sawczyn, Jakub Binkowski, Denis Janiak, Bogdan Gabrys, Tomasz Kajdanowicz

+ [LEMMA: Learning from Errors for MatheMatical Advancement in LLMs](https://arxiv.org//abs/2503.17439)

	Zhuoshi Pan, Yu Li, Honglin Lin, Qizhi Pei, Zinan Tang, Wei Wu, Chenlin Ming, H. Vicky Zhao, Conghui He, Lijun Wu

# 2025-03-20
+ [Detecting LLM-Generated Peer Reviews](https://arxiv.org//abs/2503.15772)

	Vishisht Rao, Aounon Kumar, Himabindu Lakkaraju, Nihar B. Shah

+ [Adaptive Group Policy Optimization: Towards Stable Training and Token-Efficient Reasoning](https://arxiv.org//abs/2503.15952)

	Chen Li, Nazhou Liu, Kai Yang

+ [Through the LLM Looking Glass: A Socratic Probing of Donkeys, Elephants, and Markets](https://arxiv.org//abs/2503.16674)

	Molly Kennedy, Ayyoob Imani, Timo Spinde, Hinrich Schütze

+ [Mixture of Lookup Experts](https://arxiv.org//abs/2503.15798)

	Shibo Jie, Yehui Tang, Kai Han, Yitong Li, Duyu Tang, Zhi-Hong Deng, Yunhe Wang

+ [FutureGen: LLM-RAG Approach to Generate the Future Work of Scientific Article](https://arxiv.org//abs/2503.16561)

	Ibrahim Al Azher, Miftahul Jannat Mokarrama, Zhishuai Guo, Sagnik Ray Choudhury, Hamed Alhoori

+ [CodeReviewQA: The Code Review Comprehension Assessment for Large Language Models](https://arxiv.org//abs/2503.16167)

	Hong Yi Lin, Chunhua Liu, Haoyu Gao, Patanamon Thongtanunam, Christoph Treude

+ [Big Help or Big Brother? Auditing Tracking, Profiling, and Personalization in Generative AI Assistants](https://arxiv.org//abs/2503.16586)

	Yash Vekaria (1), Aurelio Loris Canino (2), Jonathan Levitsky (1), Alex Ciechonski (3), Patricia Callejo (4), Anna Maria Mandalari (3), Zubair Shafiq (1) ((1) UC Davis, (2) Mediterranea University of Reggio Calabria, (3) University College London, (4) Universidad Carlos III de Madrid)

+ [MathFusion: Enhancing Mathematical Problem-solving of LLM through Instruction Fusion](https://arxiv.org//abs/2503.16212)

	Qizhi Pei, Lijun Wu, Zhuoshi Pan, Yu Li, Honglin Lin, Chenlin Ming, Xin Gao, Conghui He, Rui Yan

# 2025-03-19
+ [Benchmarking Open-Source Large Language Models on Healthcare Text Classification Tasks](https://arxiv.org//abs/2503.15169)

	Yuting Guo, Abeed Sarker

+ [Task-Specific Data Selection for Instruction Tuning via Monosemantic Neuronal Activations](https://arxiv.org//abs/2503.15573)

	Da Ma, Gonghu Shang, Zhi Chen, Libo Qin, Yijie Luo, Lei Pan, Shuai Fan, Lu Chen, Kai Yu

+ [From 1,000,000 Users to Every User: Scaling Up Personalized Preference for User-level Alignment](https://arxiv.org//abs/2503.15463)

	Jia-Nan Li, Jian Guan, Songhao Wu, Wei Wu, Rui Yan

+ [TROVE: A Challenge for Fine-Grained Text Provenance via Source Sentence Tracing and Relationship Classification](https://arxiv.org//abs/2503.15289)

	Junnan Zhu, Min Xiao, Yining Wang, Feifei Zhai, Yu Zhou, Chengqing Zong

+ [Prompt engineering and framework: implementation to increase code reliability based guideline for LLMs](https://arxiv.org//abs/2506.10989)

	Rogelio Cruz, Jonatan Contreras, Francisco Guerrero, Ezequiel Rodriguez, Carlos Valdez, Citlali Carrillo

# 2025-03-18
+ [JuDGE: Benchmarking Judgment Document Generation for Chinese Legal System](https://arxiv.org//abs/2503.14258)

	Weihang Su, Baoqing Yue, Qingyao Ai, Yiran Hu, Jiaqi Li, Changyue Wang, Kaiyuan Zhang, Yueyue Wu, Yiqun Liu

+ [Predicting Human Choice Between Textually Described Lotteries](https://arxiv.org//abs/2503.14004)

	Eyal Marantz, Ori Plonsky

+ [Safety Evaluation and Enhancement of DeepSeek Models in Chinese Contexts](https://arxiv.org//abs/2503.16529)

	Wenjing Zhang, Xuejiao Lei, Zhaoxiang Liu, Limin Han, Jiaojiao Zhao, Junting Guo, Zhenhong Long, Shu Yang, Meijuan An, Beibei Huang, Rongjia Du, Ning Wang, Kai Wang, Shiguo Lian

+ [Beyond Single Pass, Looping Through Time: KG-IRAG with Iterative Knowledge Retrieval](https://arxiv.org//abs/2503.14234)

	Ruiyi Yang, Hao Xue, Imran Razzak, Hakim Hacid, Flora D. Salim

+ [LED: LLM Enhanced Open-Vocabulary Object Detection without Human Curated Data Generation](https://arxiv.org//abs/2503.13794)

	Yang Zhou, Shiyu Zhao, Yuxiao Chen, Zhenting Wang, Can Jin, Dimitris N. Metaxas

+ [DAPO: An Open-Source LLM Reinforcement Learning System at Scale](https://arxiv.org//abs/2503.14476)

	Qiying Yu, Zheng Zhang, Ruofei Zhu, Yufeng Yuan, Xiaochen Zuo, Yu Yue, Weinan Dai, Tiantian Fan, Gaohong Liu, Lingjun Liu, Xin Liu, Haibin Lin, Zhiqi Lin, Bole Ma, Guangming Sheng, Yuxuan Tong, Chi Zhang, Mofan Zhang, Wang Zhang, Hang Zhu, Jinhua Zhu, Jiaze Chen, Jiangjie Chen, Chengyi Wang, Hongli Yu, Yuxuan Song, Xiangpeng Wei, Hao Zhou, Jingjing Liu, Wei-Ying Ma, Ya-Qin Zhang, Lin Yan, Mu Qiao, Yonghui Wu, Mingxuan Wang

+ [Uncertainty Distillation: Teaching Language Models to Express Semantic Confidence](https://arxiv.org//abs/2503.14749)

	Sophia Hager, David Mueller, Kevin Duh, Nicholas Andrews

+ [Inferring Events from Time Series using Language Models](https://arxiv.org//abs/2503.14190)

	Mingtian Tan, Mike A. Merrill, Zack Gottesman, Tim Althoff, David Evans, Tom Hartvigsen

+ [Robust Weight Imprinting: Insights from Neural Collapse and Proxy-Based Aggregation](https://arxiv.org//abs/2503.14572)

	Justus Westerhoff, Golzar Atefi, Mario Koddenbrock, Alexei Figueroa, Alexander Löser, Erik Rodner, Felix A. Gers

+ [Learning on LLM Output Signatures for gray-box Behavior Analysis](https://arxiv.org//abs/2503.14043)

	Guy Bar-Shalom, Fabrizio Frasca, Derek Lim, Yoav Gelberg, Yftah Ziser, Ran El-Yaniv, Gal Chechik, Haggai Maron

+ [Navigating Rifts in Human-LLM Grounding: Study and Benchmark](https://arxiv.org//abs/2503.13975)

	Omar Shaikh, Hussein Mozannar, Gagan Bansal, Adam Fourney, Eric Horvitz

+ [PLAY2PROMPT: Zero-shot Tool Instruction Optimization for LLM Agents via Tool Play](https://arxiv.org//abs/2503.14432)

	Wei Fang, Yang Zhang, Kaizhi Qian, James Glass, Yada Zhu

+ [Zero-Shot Scene Understanding with Multimodal Large Language Models for Automated Vehicles](https://arxiv.org//abs/2506.12232)

	Mohammed Elhenawy, Shadi Jaradat, Taqwa I. Alhadidi, Huthaifa I. Ashqar, Ahmed Jaber, Andry Rakotonirainy, Mohammad Abu Tami

# 2025-03-17
+ [Atyaephyra at SemEval-2025 Task 4: Low-Rank Negative Preference Optimization](https://arxiv.org//abs/2503.13690)

	Jan Bronec (1), Jindřich Helcl (1) ((1) Charles University, Faculty of Mathematics and Physics, Institute of Formal and Applied Linguistics)

+ [KVShare: An LLM Service System with Efficient and Effective Multi-Tenant KV Cache Reuse](https://arxiv.org//abs/2503.16525)

	Huan Yang, Renji Zhang, Mingzhe Huang, Weijun Wang, Yin Tang, Yuanchun Li, Yunxin Liu, Deyu Zhang

+ [HICD: Hallucination-Inducing via Attention Dispersion for Contrastive Decoding to Mitigate Hallucinations in Large Language Models](https://arxiv.org//abs/2503.12908)

	Xinyan Jiang, Hang Ye, Yongxin Zhu, Xiaoying Zheng, Zikang Chen, Jun Gong

+ [RAG-RL: Advancing Retrieval-Augmented Generation via RL and Curriculum Learning](https://arxiv.org//abs/2503.12759)

	Jerry Huang, Siddarth Madala, Risham Sidhu, Cheng Niu, Hao Peng, Julia Hockenmaier, Tong Zhang

+ [ClearSight: Visual Signal Enhancement for Object Hallucination Mitigation in Multimodal Large language Models](https://arxiv.org//abs/2503.13107)

	Hao Yin, Guangzong Si, Zilei Wang

+ [In-Context Linear Regression Demystified: Training Dynamics and Mechanistic Interpretability of Multi-Head Softmax Attention](https://arxiv.org//abs/2503.12734)

	Jianliang He, Xintian Pan, Siyu Chen, Zhuoran Yang

+ [HiDe-LLaVA: Hierarchical Decoupling for Continual Instruction Tuning of Multimodal Large Language Model](https://arxiv.org//abs/2503.12941)

	Haiyang Guo, Fanhu Zeng, Ziwei Xiang, Fei Zhu, Da-Han Wang, Xu-Yao Zhang, Cheng-Lin Liu

+ [ClusComp: A Simple Paradigm for Model Compression and Efficient Finetuning](https://arxiv.org//abs/2503.13089)

	Baohao Liao, Christian Herold, Seyyed Hadi Hashemi, Stefan Vasilev, Shahram Khadivi, Christof Monz

+ [TinySQL: A Progressive Text-to-SQL Dataset for Mechanistic Interpretability Research](https://arxiv.org//abs/2503.12730)

	Abir Harrasse, Philip Quirke, Clement Neo, Dhruv Nathawani, Amir Abdullah

+ [Computation Mechanism Behind LLM Position Generalization](https://arxiv.org//abs/2503.13305)

	Chi Han, Heng Ji

+ [VeriContaminated: Assessing LLM-Driven Verilog Coding for Data Contamination](https://arxiv.org//abs/2503.13572)

	Zeng Wang, Minghao Shao, Jitendra Bhandari, Likhitha Mankali, Ramesh Karri, Ozgur Sinanoglu, Muhammad Shafique, Johann Knechtel

+ [VeriLeaky: Navigating IP Protection vs Utility in Fine-Tuning for LLM-Driven Verilog Coding](https://arxiv.org//abs/2503.13116)

	Zeng Wang, Minghao Shao, Mohammed Nabeel, Prithwish Basu Roy, Likhitha Mankali, Jitendra Bhandari, Ramesh Karri, Ozgur Sinanoglu, Muhammad Shafique, Johann Knechtel

+ [The Amazon Nova Family of Models: Technical Report and Model Card](https://arxiv.org//abs/2506.12103)

	Amazon AGI, Aaron Langford, Aayush Shah, Abhanshu Gupta, Abhimanyu Bhatter, Abhinav Goyal, Abhinav Mathur, Abhinav Mohanty, Abhishek Kumar, Abhishek Sethi, Abi Komma, Abner Pena, Achin Jain, Adam Kunysz, Adam Opyrchal, Adarsh Singh, Aditya Rawal, Adok Achar Budihal Prasad, Adrià de Gispert, Agnika Kumar, Aishwarya Aryamane, Ajay Nair, Akilan M, Akshaya Iyengar, Akshaya Vishnu Kudlu Shanbhogue, Alan He, Alessandra Cervone, Alex Loeb, Alex Zhang, Alexander Fu, Alexander Lisnichenko, Alexander Zhipa, Alexandros Potamianos, Ali Kebarighotbi, Aliakbar Daronkolaei, Alok Parmesh, Amanjot Kaur Samra, Ameen Khan, Amer Rez, Amir Saffari, Amit Agarwalla, Amit Jhindal, Amith Mamidala, Ammar Asmro, Amulya Ballakur, Anand Mishra, Anand Sridharan, Anastasiia Dubinina, Andre Lenz, Andreas Doerr, Andrew Keating, Andrew Leaver, Andrew Smith, Andrew Wirth, Andy Davey, Andy Rosenbaum, Andy Sohn, Angela Chan, Aniket Chakrabarti, Anil Ramakrishna, Anirban Roy, Anita Iyer, Anjali Narayan-Chen, Ankith Yennu, Anna Dabrowska, Anna Gawlowska, Anna Rumshisky, Anna Turek, Anoop Deoras, Anton Bezruchkin, Anup Prasad, Anupam Dewan, Anwith Kiran, Apoorv Gupta, Aram Galstyan, Aravind Manoharan, Arijit Biswas, Arindam Mandal, Arpit Gupta, Arsamkhan Pathan, Arun Nagarajan, Arushan Rajasekaram, Arvind Sundararajan, Ashwin Ganesan, Ashwin Swaminathan, Athanasios Mouchtaris, Audrey Champeau, Avik Ray, Ayush Jaiswal, Ayush Sharma, Bailey Keefer, Balamurugan Muthiah, Beatriz Leon-Millan, Ben Koopman, Ben Li, Benjamin Biggs, Benjamin Ott, Bhanu Vinzamuri, Bharath Venkatesh, Bhavana Ganesh

+ [REPA: Russian Error Types Annotation for Evaluating Text Generation and Judgment Capabilities](https://arxiv.org//abs/2503.13102)

	Alexander Pugachev, Alena Fenogenova, Vladislav Mikhailov, Ekaterina Artemova

# 2025-03-16
+ [Towards Hierarchical Multi-Step Reward Models for Enhanced Reasoning in Large Language Models](https://arxiv.org//abs/2503.13551)

	Teng Wang, Zhangyi Jiang, Zhenqi He, Shenyang Tong, Wenhan Yang, Yanan Zheng, Zeyu Li, Zifan He, Hailei Gong

+ [Being-0: A Humanoid Robotic Agent with Vision-Language Models and Modular Skills](https://arxiv.org//abs/2503.12533)

	Haoqi Yuan, Yu Bai, Yuhui Fu, Bohan Zhou, Yicheng Feng, Xinrun Xu, Yi Zhan, Börje F. Karlsson, Zongqing Lu

+ [Empirical Privacy Variance](https://arxiv.org//abs/2503.12314)

	Yuzheng Hu, Fan Wu, Ruicheng Xian, Yuhang Liu, Lydia Zakynthinou, Pritish Kamath, Chiyuan Zhang, David Forsyth

+ [GraphEval: A Lightweight Graph-Based LLM Framework for Idea Evaluation](https://arxiv.org//abs/2503.12600)

	Tao Feng, Yihang Sun, Jiaxuan You

# 2025-03-15
+ [No LLM is Free From Bias: A Comprehensive Study of Bias Evaluation in Large Language Models](https://arxiv.org//abs/2503.11985)

	Charaka Vinayak Kumar, Ashok Urlana, Gopichand Kanumolu, Bala Mallikarjunarao Garlapati, Pruthwik Mishra

+ [PIPO: Pipelined Offloading for Efficient Inference on Consumer Devices](https://arxiv.org//abs/2504.03664)

	Yangyijian Liu, Jun Li, Wu-Jun Li

# 2025-03-14
+ [CURIE: Evaluating LLMs On Multitask Scientific Long Context Understanding and Reasoning](https://arxiv.org//abs/2503.13517)

	Hao Cui, Zahra Shamsi, Gowoon Cheon, Xuejian Ma, Shutong Li, Maria Tikhanovskaya, Peter Norgaard, Nayantara Mudur, Martyna Plomecka, Paul Raccuglia, Yasaman Bahri, Victor V. Albert, Pranesh Srinivasan, Haining Pan, Philippe Faist, Brian Rohr, Ekin Dogus Cubuk, Muratahan Aykol, Amil Merchant, Michael J. Statt, Dan Morris, Drew Purves, Elise Kleeman, Ruth Alcantara, Matthew Abraham, Muqthar Mohammad, Ean Phing VanLee, Chenfei Jiang, Elizabeth Dorfman, Eun-Ah Kim, Michael P Brenner, Viren Jain, Sameera Ponda, Subhashini Venugopalan

+ [Implicit Bias-Like Patterns in Reasoning Models](https://arxiv.org//abs/2503.11572)

	Messi H.J. Lee, Calvin K. Lai

+ [D3: Diversity, Difficulty, and Dependability-Aware Data Selection for Sample-Efficient LLM Instruction Tuning](https://arxiv.org//abs/2503.11441)

	Jia Zhang, Chen-Xi Zhang, Yao Liu, Yi-Xuan Jin, Xiao-Wen Yang, Bo Zheng, Yi Liu, Lan-Zhe Guo

+ [MUSS: Multilevel Subset Selection for Relevance and Diversity](https://arxiv.org//abs/2503.11126)

	Vu Nguyen, Andrey Kan

+ [ASMA-Tune: Unlocking LLMs' Assembly Code Comprehension via Structural-Semantic Instruction Tuning](https://arxiv.org//abs/2503.11617)

	Xinyi Wang, Jiashui Wang, Jinbo Su, Ke Wang, Peng Chen, Yanming Liu, Long Liu, Xiang Li, Yangdong Wang, Qiyuan Chen, Rongze Chen, Chunfu Jia

+ [BriLLM: Brain-inspired Large Language Model](https://arxiv.org//abs/2503.11299)

	Hai Zhao, Hongqiu Wu, Dongjie Yang, Anni Zou, Jiale Hong

+ [Exploring the Necessity of Reasoning in LLM-based Agent Scenarios](https://arxiv.org//abs/2503.11074)

	Xueyang Zhou, Guiyao Tie, Guowen Zhang, Weidong Wang, Zhigang Zuo, Di Wu, Duanfeng Chu, Pan Zhou, Neil Zhenqiang Gong, Lichao Sun

+ [MMS-LLaMA: Efficient LLM-based Audio-Visual Speech Recognition with Minimal Multimodal Speech Tokens](https://arxiv.org//abs/2503.11315)

	Jeong Hun Yeo, Hyeongseop Rha, Se Jin Park, Yong Man Ro

+ [Taming Knowledge Conflicts in Language Models](https://arxiv.org//abs/2503.10996)

	Gaotang Li, Yuzhong Chen, Hanghang Tong

+ [Unlocking General Long Chain-of-Thought Reasoning Capabilities of Large Language Models via Representation Engineering](https://arxiv.org//abs/2503.11314)

	Xinyu Tang, Xiaolei Wang, Zhihao Lv, Yingqian Min, Wayne Xin Zhao, Binbin Hu, Ziqi Liu, Zhiqiang Zhang

# 2025-03-13
+ [HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks](https://arxiv.org//abs/2503.10894)

	Jiuding Sun, Jing Huang, Sidharth Baskaran, Karel D'Oosterlinck, Christopher Potts, Michael Sklar, Atticus Geiger


+ [HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks](https://arxiv.org//abs/2503.10894)

	Jiuding Sun, Jing Huang, Sidharth Baskaran, Karel D'Oosterlinck, Christopher Potts, Michael Sklar, Atticus Geiger

+ [How Do Multimodal Large Language Models Handle Complex Multimodal Reasoning? Placing Them in An Extensible Escape Game](https://arxiv.org//abs/2503.10042)

	Ziyue Wang, Yurui Dong, Fuwen Luo, Minyuan Ruan, Zhili Cheng, Chi Chen, Peng Li, Yang Liu

+ [Collaborative Speculative Inference for Efficient LLM Inference Serving](https://arxiv.org//abs/2503.10325)

	Luyao Gao, Jianchun Liu, Hongli Xu, Xichong Zhang, Yunming Liao, Liusheng Huang

+ [Evaluating Mathematical Reasoning Across Large Language Models: A Fine-Grained Approach](https://arxiv.org//abs/2503.10573)

	Afrar Jahin, Arif Hassan Zidan, Wei Zhang, Yu Bao, Tianming Liu

+ [Language Models, Graph Searching, and Supervision Adulteration: When More Supervision is Less and How to Make More More](https://arxiv.org//abs/2503.10542)

	Arvid Frydenlund

+ [Scalable Evaluation of Online Facilitation Strategies via Synthetic Simulation of Discussions](https://arxiv.org//abs/2503.16505)

	Dimitris Tsirmpas, Ion Androutsopoulos, John Pavlopoulos

+ [DynaCode: A Dynamic Complexity-Aware Code Benchmark for Evaluating Large Language Models in Code Generation](https://arxiv.org//abs/2503.10452)

	Wenhao Hu, Jinhao Duan, Chunchen Wei, Li Zhang, Yue Zhang, Kaidi Xu

+ [Why Prompt Design Matters and Works: A Complexity Analysis of Prompt Search Space in LLMs](https://arxiv.org//abs/2503.10084)

	Xiang Zhang, Juntai Cao, Jiaqi Wei, Chenyu You, Dujian Ding

+ [Compute Optimal Scaling of Skills: Knowledge vs Reasoning](https://arxiv.org//abs/2503.10061)

	Nicholas Roberts, Niladri Chatterji, Sharan Narang, Mike Lewis, Dieuwke Hupkes

+ [Efficient Safety Alignment of Large Language Models via Preference Re-ranking and Representation-based Reward Modeling](https://arxiv.org//abs/2503.10093)

	Qiyuan Deng, Xuefeng Bai, Kehai Chen, Yaowei Wang, Liqiang Nie, Min Zhang

# 2025-03-12
+ [LocAgent: Graph-Guided LLM Agents for Code Localization](https://arxiv.org//abs/2503.09089)

	Zhaoling Chen, Xiangru Tang, Gangda Deng, Fang Wu, Jialong Wu, Zhiwei Jiang, Viktor Prasanna, Arman Cohan, Xingyao Wang

+ [Privacy-Preserved Automated Scoring using Federated Learning for Educational Research](https://arxiv.org//abs/2503.11711)

	Ehsan Latif, Xiaoming Zhai

+ [I Predict Therefore I Am: Is Next Token Prediction Enough to Learn Human-Interpretable Concepts from Data?](https://arxiv.org//abs/2503.08980)

	Yuhang Liu, Dong Gong, Yichao Cai, Erdun Gao, Zhen Zhang, Biwei Huang, Mingming Gong, Anton van den Hengel, Javen Qinfeng Shi

+ [PolyPythias: Stability and Outliers across Fifty Language Model Pre-Training Runs](https://arxiv.org//abs/2503.09543)

	Oskar van der Wal, Pietro Lesci, Max Muller-Eberstein, Naomi Saphra, Hailey Schoelkopf, Willem Zuidema, Stella Biderman

+ [Probabilistic Reasoning with LLMs for k-anonymity Estimation](https://arxiv.org//abs/2503.09674)

	Jonathan Zheng, Sauvik Das, Alan Ritter, Wei Xu

+ [Cost-Optimal Grouped-Query Attention for Long-Context Modeling](https://arxiv.org//abs/2503.09579)

	Yingfa Chen, Yutong Wu, Chenyang Song, Zhen Leng Thai, Xingyu Shen, Xu Han, Zhiyuan Liu, Maosong Sun

+ [MindGYM: What Matters in Question Synthesis for Thinking-Centric Fine-Tuning?](https://arxiv.org//abs/2503.09499)

	Zhe Xu, Daoyuan Chen, Zhenqing Ling, Yaliang Li, Ying Shen

+ [MoC: Mixtures of Text Chunking Learners for Retrieval-Augmented Generation System](https://arxiv.org//abs/2503.09600)

	Jihao Zhao, Zhiyuan Ji, Zhaoxin Fan, Hanyu Wang, Simin Niu, Bo Tang, Feiyu Xiong, Zhiyu Li

+ [ReMA: Learning to Meta-think for LLMs with Multi-Agent Reinforcement Learning](https://arxiv.org//abs/2503.09501)

	Ziyu Wan, Yunxiang Li, Xiaoyu Wen, Yan Song, Hanjing Wang, Linyi Yang, Mark Schmidt, Jun Wang, Weinan Zhang, Shuyue Hu, Ying Wen

+ [How to Protect Yourself from 5G Radiation? Investigating LLM Responses to Implicit Misinformation](https://arxiv.org//abs/2503.09598)

	Ruohao Guo, Wei Xu, Alan Ritter

+ [Explicit Learning and the LLM in Machine Translation](https://arxiv.org//abs/2503.09454)

	Malik Marmonier, Rachel Bawden, Benoît Sagot

+ [SciHorizon: Benchmarking AI-for-Science Readiness from Scientific Data to Large Language Models](https://arxiv.org//abs/2503.13503)

	Chuan Qin, Xin Chen, Chengrui Wang, Pengmin Wu, Xi Chen, Yihang Cheng, Jingyi Zhao, Meng Xiao, Xiangchao Dong, Qingqing Long, Boya Pan, Han Wu, Chengzan Li, Yuanchun Zhou, Hui Xiong, Hengshu Zhu

+ [GRU: Mitigating the Trade-off between Unlearning and Retention for LLMs](https://arxiv.org//abs/2503.09117)

	Yue Wang, Qizhou Wang, Feng Liu, Wei Huang, Yali Du, Xiaojiang Du, Bo Han

+ [Safer or Luckier? LLMs as Safety Evaluators Are Not Robust to Artifacts](https://arxiv.org//abs/2503.09347)

	Hongyu Chen, Seraphina Goldfarb-Tarrant

# 2025-03-11
+ [Training Plug-n-Play Knowledge Modules with Deep Context Distillation](https://arxiv.org//abs/2503.08727)

	Lucas Caccia, Alan Ansell, Edoardo Ponti, Ivan Vulić, Alessandro Sordoni

+ [SQLCritic: Correcting Text-to-SQL Generation via Clause-wise Critic](https://arxiv.org//abs/2503.07996)

	Jikai Chen, Leilei Gan, Ziyu Zhao, Zechuan Wang, Dong Wang, Chenyi Zhuang

+ [ReviewAgents: Bridging the Gap Between Human and AI-Generated Paper Reviews](https://arxiv.org//abs/2503.08506)

	Xian Gao, Jiacheng Ruan, Jingsheng Gao, Ting Liu, Yuzhuo Fu

+ [Route Sparse Autoencoder to Interpret Large Language Models](https://arxiv.org//abs/2503.08200)

	Wei Shi, Sihang Li, Tao Liang, Mingyang Wan, Guojun Ma, Xiang Wang, Xiangnan He

+ [Odysseus Navigates the Sirens' Song: Dynamic Focus Decoding for Factual and Diverse Open-Ended Text Generation](https://arxiv.org//abs/2503.08057)

	Wen Luo, Feifan Song, Wei Li, Guangyue Peng, Shaohang Wei, Houfeng Wang

+ [Context-aware Biases for Length Extrapolation](https://arxiv.org//abs/2503.08067)

	Ali Veisi, Hamidreza Amirzadeh, Amir Mansourian

+ [Large Language Models for Outpatient Referral: Problem Definition, Benchmarking and Challenges](https://arxiv.org//abs/2503.08292)

	Xiaoxiao Liu, Qingying Xiao, Junying Chen, Xiangyi Feng, Xiangbo Wu, Bairui Zhang, Xiang Wan, Jian Chang, Guangjun Yu, Yan Hu, Benyou Wang

# 2025-03-10
+ [Are We Truly Forgetting? A Critical Re-examination of Machine Unlearning Evaluation Protocols](https://arxiv.org//abs/2503.06991)

	Yongwoo Kim, Sungmin Cha, Donghyun Kim

+ [UC-MOA: Utility-Conditioned Multi-Objective Alignment for Distributional Pareto-Optimality](https://arxiv.org//abs/2503.10669)

	Zelei Cheng, Xin-Qiang Cai, Yuting Tang, Pushi Zhang, Boming Yang, Masashi Sugiyama, Xinyu Xing

+ [When Trust Collides: Decoding Human-LLM Cooperation Dynamics through the Prisoner's Dilemma](https://arxiv.org//abs/2503.07320)

	Guanxuan Jiang, Shirao Yang, Yuyang Wang, Pan Hui

+ [ReAgent: Reversible Multi-Agent Reasoning for Knowledge-Enhanced Multi-Hop QA](https://arxiv.org//abs/2503.06951)

	Xinjie Zhao, Fan Gao, Xingyu Song, Yingjian Chen, Rui Yang, Yanran Fu, Yuyang Wang, Yusuke Iwasawa, Yutaka Matsuo, Irene Li

+ [Enhancing Retrieval for ESGLLM via ESG-CID -- A Disclosure Content Index Finetuning Dataset for Mapping GRI and ESRS](https://arxiv.org//abs/2503.10674)

	Shafiuddin Rehan Ahmed, Ankit Parag Shah, Quan Hung Tran, Vivek Khetan, Sukryool Kang, Ankit Mehta, Yujia Bao, Wei Wei

+ [DistiLLM-2: A Contrastive Approach Boosts the Distillation of LLMs](https://arxiv.org//abs/2503.07067)

	Jongwoo Ko, Tianyi Chen, Sungnyun Kim, Tianyu Ding, Luming Liang, Ilya Zharkov, Se-Young Yun

+ [Implicit Reasoning in Transformers is Reasoning through Shortcuts](https://arxiv.org//abs/2503.07604)

	Tianhe Lin, Jian Xie, Siyu Yuan, Deqing Yang

+ [ProjectEval: A Benchmark for Programming Agents Automated Evaluation on Project-Level Code Generation](https://arxiv.org//abs/2503.07010)

	Kaiyuan Liu, Youcheng Pan, Yang Xiang, Daojing He, Jing Li, Yexing Du, Tianrun Gao

+ [Navigating Motion Agents in Dynamic and Cluttered Environments through LLM Reasoning](https://arxiv.org//abs/2503.07323)

	Yubo Zhao, Qi Wu, Yifan Wang, Yu-Wing Tai, Chi-Keung Tang

+ [PoisonedParrot: Subtle Data Poisoning Attacks to Elicit Copyright-Infringing Content from Large Language Models](https://arxiv.org//abs/2503.07697)

	Michael-Andrei Panaitescu-Liess, Pankayaraj Pathmanathan, Yigitcan Kaya, Zora Che, Bang An, Sicheng Zhu, Aakriti Agrawal, Furong Huang

# 2025-03-09
+ [HCT-QA: A Benchmark for Question Answering on Human-Centric Tables](https://arxiv.org//abs/2504.20047)

	Mohammad S. Ahmad, Zan A. Naeem, Michaël Aupetit, Ahmed Elmagarmid, Mohamed Eltabakh, Xiasong Ma, Mourad Ouzzani, Chaoyi Ruan

+ [InftyThink: Breaking the Length Limits of Long-Context Reasoning in Large Language Models](https://arxiv.org//abs/2503.06692)

	Yuchen Yan, Yongliang Shen, Yang Liu, Jin Jiang, Mengdi Zhang, Jian Shao, Yueting Zhuang

+ [Beyond Decoder-only: Large Language Models Can be Good Encoders for Machine Translation](https://arxiv.org//abs/2503.06594)

	Yingfeng Luo, Tong Zheng, Yongyu Mu, Bei Li, Qinghong Zhang, Yongqi Gao, Ziqiang Xu, Peinan Feng, Xiaoqian Liu, Tong Xiao, Jingbo Zhu

# 2025-03-08
+ [SCoRE: Benchmarking Long-Chain Reasoning in Commonsense Scenarios](https://arxiv.org//abs/2503.06218)

	Weidong Zhan, Yue Wang, Nan Hu, Liming Xiao, Jingyuan Ma, Yuhang Qin, Zheng Li, Yixin Yang, Sirui Deng, Jinkun Ding, Wenhan Ma, Rui Li, Weilin Luo, Qun Liu, Zhifang Sui

+ [RouterEval: A Comprehensive Benchmark for Routing LLMs to Explore Model-level Scaling Up in LLMs](https://arxiv.org//abs/2503.10657)

	Zhongzhan Huang, Guoming Ling, Yupei Lin, Yandong Chen, Shanshan Zhong, Hefeng Wu, Liang Lin

+ [Large Language Models Post-training: Surveying Techniques from Alignment to Reasoning](https://arxiv.org//abs/2503.06072)

	Guiyao Tie, Zeli Zhao, Dingjie Song, Fuyang Wei, Rong Zhou, Yurou Dai, Wen Yin, Zhejian Yang, Jiangyue Yan, Yao Su, Zhenhan Dai, Yifeng Xie, Yihan Cao, Lichao Sun, Pan Zhou, Lifang He, Hechang Chen, Yu Zhang, Qingsong Wen, Tianming Liu, Neil Zhenqiang Gong, Jiliang Tang, Caiming Xiong, Heng Ji, Philip S. Yu, Jianfeng Gao

# 2025-03-07
+ [Correctness Coverage Evaluation for Medical Multiple-Choice Question Answering Based on the Enhanced Conformal Prediction Framework](https://arxiv.org//abs/2503.05505)

	Yusong Ke, Hongru Lin, Yuting Ruan, Junya Tang, Li Li

+ [AVA: Attentive VLM Agent for Mastering StarCraft II](https://arxiv.org//abs/2503.05383)

	Weiyu Ma, Yuqian Fu, Zecheng Zhang, Bernard Ghanem, Guohao Li

+ [Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching](https://arxiv.org//abs/2503.05179)

	Simon A. Aytes, Jinheon Baek, Sung Ju Hwang

+ [Capacity-Aware Inference: Mitigating the Straggler Effect in Mixture of Experts](https://arxiv.org//abs/2503.05066)

	Shwai He, Weilin Cai, Jiayi Huang, Ang Li

+ [To See a World in a Spark of Neuron: Disentangling Multi-task Interference for Training-free Model Merging](https://arxiv.org//abs/2503.05320)

	Zitao Fang, Guodong DU, Shuyang Yu, Yifei Guo, Yiwei Zhang, Yiyao Cao, Jing Li, Ho-Kin Tang, Sim Kuan Goh

+ [Path Pooling: Training-Free Structure Enhancement for Efficient Knowledge Graph Retrieval-Augmented Generation](https://arxiv.org//abs/2503.05203)

	Hairu Wang, Yuan Feng, Xike Xie, S Kevin Zhou

+ [A Survey on Sparse Autoencoders: Interpreting the Internal Mechanisms of Large Language Models](https://arxiv.org//abs/2503.05613)

	Dong Shu, Xuansheng Wu, Haiyan Zhao, Daking Rai, Ziyu Yao, Ninghao Liu, Mengnan Du

# 2025-03-06
+ [Wanda++: Pruning Large Language Models via Regional Gradients](https://arxiv.org//abs/2503.04992)

	Yifan Yang, Kai Zhen, Bhavana Ganesh, Aram Galstyan, Goeric Huybrechts, Markus Müller, Jonas M. Kübler, Rupak Vignesh Swaminathan, Athanasios Mouchtaris, Sravan Babu Bodapati, Nathan Susanj, Zheng Zhang, Jack FitzGerald, Abhishek Kumar

+ [SOLAR: Scalable Optimization of Large-scale Architecture for Reasoning](https://arxiv.org//abs/2503.04530)

	Chen Li, Yinyi Luo, Anudeep Bolimera, Uzair Ahmed, Shri Kiran Srinivasan, Hrishikesh Gokhale, Marios Savvides

+ [Predictable Scale: Part I -- Optimal Hyperparameter Scaling Law in Large Language Model Pretraining](https://arxiv.org//abs/2503.04715)

	Houyi Li, Wenzhen Zheng, Qiufeng Wang, Hanshan Zhang, Zili Wang, Shijie Xuyang, Yuantao Fan, Shuigeng Zhou, Xiangyu Zhang, Daxin Jiang

+ [DB-Explore: Automated Database Exploration and Instruction Synthesis for Text-to-SQL](https://arxiv.org//abs/2503.04959)

	Haoyuan Ma, Yongliang Shen, Hengwei Liu, Wenqi Zhang, Haolei Xu, Qiuying Peng, Jun Wang, Weiming Lu

+ [Compositional Causal Reasoning Evaluation in Language Models](https://arxiv.org//abs/2503.04556)

	Jacqueline R. M. A. Maasch, Alihan Hüyük, Xinnuo Xu, Aditya V. Nori, Javier Gonzalez

+ [DiffPO: Diffusion-styled Preference Optimization for Efficient Inference-Time Alignment of Large Language Models](https://arxiv.org//abs/2503.04240)

	Ruizhe Chen, Wenhao Chai, Zhifei Yang, Xiaotian Zhang, Joey Tianyi Zhou, Tony Quek, Soujanya Poria, Zuozhu Liu

+ [TS-RAG: Retrieval-Augmented Generation based Time Series Foundation Models are Stronger Zero-Shot Forecaster](https://arxiv.org//abs/2503.07649)

	Kanghui Ning, Zijie Pan, Yu Liu, Yushan Jiang, James Y. Zhang, Kashif Rasul, Anderson Schneider, Lintao Ma, Yuriy Nevmyvaka, Dongjin Song

+ [Shaping Shared Languages: Human and Large Language Models' Inductive Biases in Emergent Communication](https://arxiv.org//abs/2503.04395)

	Tom Kouwenhoven, Max Peeperkorn, Roy de Kleijn, Tessa Verhoef

+ [HelpSteer3: Human-Annotated Feedback and Edit Data to Empower Inference-Time Scaling in Open-Ended General-Domain Tasks](https://arxiv.org//abs/2503.04378)

	Zhilin Wang, Jiaqi Zeng, Olivier Delalleau, Daniel Egert, Ellie Evans, Hoo-Chang Shin, Felipe Soares, Yi Dong, Oleksii Kuchaiev

+ [Implicit Cross-Lingual Rewarding for Efficient Multilingual Preference Alignment](https://arxiv.org//abs/2503.04647)

	Wen Yang, Junhong Wu, Chen Wang, Chengqing Zong, Jiajun Zhang

+ [TRACT: Regression-Aware Fine-tuning Meets Chain-of-Thought Reasoning for LLM-as-a-Judge](https://arxiv.org//abs/2503.04381)

	Cheng-Han Chiang, Hung-yi Lee, Michal Lukasik

+ [Towards Autonomous Reinforcement Learning for Real-World Robotic Manipulation with Large Language Models](https://arxiv.org//abs/2503.04280)

	Niccolò Turcato, Matteo Iovino, Aris Synodinos, Alberto Dalla Libera, Ruggero Carli, Pietro Falco

+ [Wider or Deeper? Scaling LLM Inference-Time Compute with Adaptive Branching Tree Search](https://arxiv.org//abs/2503.04412)

	Yuichi Inoue, Kou Misaki, Yuki Imajuku, So Kuroki, Taishi Nakamura, Takuya Akiba

# 2025-03-05
+ [CodeIF-Bench: Evaluating Instruction-Following Capabilities of Large Language Models in Interactive Code Generation](https://arxiv.org//abs/2503.22688)

	Peiding Wang, Li Zhang, Fang Liu, Lin Shi, Minxiao Li, Bo Shen, An Fu

+ [The Devil Is in the Details: Tackling Unimodal Spurious Correlations for Generalizable Multimodal Reward Models](https://arxiv.org//abs/2503.03122)

	Zichao Li, Xueru Wen, Jie Lou, Yuqiu Ji, Yaojie Lu, Xianpei Han, Debing Zhang, Le Sun

+ [Cite Before You Speak: Enhancing Context-Response Grounding in E-commerce Conversational LLM-Agents](https://arxiv.org//abs/2503.04830)

	Jingying Zeng, Hui Liu, Zhenwei Dai, Xianfeng Tang, Chen Luo, Samarth Varshney, Zhen Li, Qi He

+ [Can Frontier LLMs Replace Annotators in Biomedical Text Mining? Analyzing Challenges and Exploring Solutions](https://arxiv.org//abs/2503.03261)

	Yichong Zhao, Susumu Goto

+ [Not-Just-Scaling Laws: Towards a Better Understanding of the Downstream Impact of Language Model Design Decisions](https://arxiv.org//abs/2503.03862)

	Emmy Liu, Amanda Bertsch, Lintang Sutawika, Lindia Tjuatja, Patrick Fernandes, Lara Marinov, Michael Chen, Shreya Singhal, Carolin Lawrence, Aditi Raghunathan, Kiril Gashteovski, Graham Neubig

+ [MA-LoT: Model-Collaboration Lean-based Long Chain-of-Thought Reasoning enhances Formal Theorem Proving](https://arxiv.org//abs/2503.03205)

	Ruida Wang, Rui Pan, Yuxin Li, Jipeng Zhang, Yizhen Jia, Shizhe Diao, Renjie Pi, Junjie Hu, Tong Zhang

+ [EnigmaToM: Improve LLMs' Theory-of-Mind Reasoning Capabilities with Neural Knowledge Base of Entity States](https://arxiv.org//abs/2503.03340)

	Hainiu Xu, Siya Qi, Jiazheng Li, Yuxiang Zhou, Jinhua Du, Caroline Catmur, Yulan He

# 2025-03-04
+ [LiteWebAgent: The Open-Source Suite for VLM-Based Web-Agent Applications](https://arxiv.org//abs/2503.02950)

	Danqing Zhang, Balaji Rama, Jingyi Ni, Shiying He, Fu Zhao, Kunyu Chen, Arnold Chen, Junyu Cao

+ [Call for Rigor in Reporting Quality of Instruction Tuning Data](https://arxiv.org//abs/2503.04807)

	Hyeonseok Moon, Jaehyung Seo, Heuiseok Lim

+ [MoSE: Hierarchical Self-Distillation Enhances Early Layer Embeddings](https://arxiv.org//abs/2503.03008)

	Andrea Gurioli, Federico Pennino, João Monteiro, Maurizio Gabbrielli

+ [MCiteBench: A Multimodal Benchmark for Generating Text with Citations](https://arxiv.org//abs/2503.02589)

	Caiyu Hu, Yikai Zhang, Tinghui Zhu, Yiwei Ye, Yanghua Xiao

+ [Scaling Laws for Many-Shot In-Context Learning with Self-Generated Annotations](https://arxiv.org//abs/2503.03062)

	Zhengyao Gu, Henry Peng Zou, Yankai Chen, Aiwei Liu, Weizhi Zhang, Philip S. Yu

+ [Teaching Metric Distance to Autoregressive Multimodal Foundational Models](https://arxiv.org//abs/2503.02379)

	Jiwan Chung, Saejin Kim, Yongrae Jo, Jaewoo Park, Dongjun Min, Youngjae Yu

+ [Rewarding Doubt: A Reinforcement Learning Approach to Calibrated Confidence Expression of Large Language Models](https://arxiv.org//abs/2503.02623)

	Paul Stangel, David Bani-Harouni, Chantal Pellegrini, Ege Özsoy, Kamilia Zaripova, Matthias Keicher, Nassir Navab

+ [PersonaX: A Recommendation Agent Oriented User Modeling Framework for Long Behavior Sequence](https://arxiv.org//abs/2503.02398)

	Yunxiao Shi, Wujiang Xu, Zeqi Zhang, Xing Zi, Qiang Wu, Min Xu

+ [LINGOLY-TOO: Disentangling Memorisation from Knowledge with Linguistic Templatisation and Orthographic Obfuscation](https://arxiv.org//abs/2503.02972)

	Jude Khouja, Karolina Korgul, Simi Hellsten, Lingyi Yang, Vlad Neacsu, Harry Mayne, Ryan Kearns, Andrew Bean, Adam Mahdi

+ [SteerConf: Steering LLMs for Confidence Elicitation](https://arxiv.org//abs/2503.02863)

	Ziang Zhou, Tianyuan Jin, Jieming Shi, Qing Li

+ [Measuring What Makes You Unique: Difference-Aware User Modeling for Enhancing LLM Personalization](https://arxiv.org//abs/2503.02450)

	Yilun Qiu, Xiaoyan Zhao, Yang Zhang, Yimeng Bai, Wenjie Wang, Hong Cheng, Fuli Feng, Tat-Seng Chua

+ [ATLaS: Agent Tuning via Learning Critical Steps](https://arxiv.org//abs/2503.02197)

	Zhixun Chen, Ming Li, Yuxuan Huang, Yali Du, Meng Fang, Tianyi Zhou

+ [Adversarial Tokenization](https://arxiv.org//abs/2503.02174)

	Renato Lui Geh, Zilei Shao, Guy Van den Broeck

+ [Large Language Models for Multilingual Previously Fact-Checked Claim Detection](https://arxiv.org//abs/2503.02737)

	Ivan Vykopal, Matúš Pikuliak, Simon Ostermann, Tatiana Anikina, Michal Gregor, Marián Šimko

# 2025-03-03
+ [SAGE: A Framework of Precise Retrieval for RAG](https://arxiv.org//abs/2503.01713)

	Jintao Zhang, Guoliang Li, Jinyang Su

+ [Liger: Linearizing Large Language Models to Gated Recurrent Structures](https://arxiv.org//abs/2503.01496)

	Disen Lan, Weigao Sun, Jiaxi Hu, Jusen Du, Yu Cheng

+ [Adaptively profiling models with task elicitation](https://arxiv.org//abs/2503.01986)

	Davis Brown, Prithvi Balehannina, Helen Jin, Shreya Havaldar, Hamed Hassani, Eric Wong

+ [Retrieval-Augmented Perception: High-Resolution Image Perception Meets Visual RAG](https://arxiv.org//abs/2503.01222)

	Wenbin Wang, Yongcheng Jing, Liang Ding, Yingjie Wang, Li Shen, Yong Luo, Bo Du, Dacheng Tao

+ [HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs](https://arxiv.org//abs/2503.02003)

	Tin Nguyen, Logan Bolton, Mohammad Reza Taesiri, Anh Totti Nguyen

+ [Retrieval Models Aren't Tool-Savvy: Benchmarking Tool Retrieval for Large Language Models](https://arxiv.org//abs/2503.01763)

	Zhengliang Shi, Yuhan Wang, Lingyong Yan, Pengjie Ren, Shuaiqiang Wang, Dawei Yin, Zhaochun Ren

+ [Position: Don't Use the CLT in LLM Evals With Fewer Than a Few Hundred Datapoints](https://arxiv.org//abs/2503.01747)

	Sam Bowyer, Laurence Aitchison, Desi R. Ivanova

+ [Beyond Prompting: An Efficient Embedding Framework for Open-Domain Question Answering](https://arxiv.org//abs/2503.01606)

	Zhanghao Hu, Hanqi Yan, Qinglin Zhu, Zhenyi Shen, Yulan He, Lin Gui

+ [Marco-o1 v2: Towards Widening The Distillation Bottleneck for Reasoning Models](https://arxiv.org//abs/2503.01461)

	Huifeng Yin, Yu Zhao, Minghao Wu, Xuanfan Ni, Bo Zeng, Hao Wang, Tianqi Shi, Liangying Shao, Chenyang Lyu, Longyue Wang, Weihua Luo, Kaifu Zhang

+ [HoH: A Dynamic Benchmark for Evaluating the Impact of Outdated Information on Retrieval-Augmented Generation](https://arxiv.org//abs/2503.04800)

	Jie Ouyang, Tingyue Pan, Mingyue Cheng, Ruiran Yan, Yucong Luo, Jiaying Lin, Qi Liu

+ [On the Power of Context-Enhanced Learning in LLMs](https://arxiv.org//abs/2503.01821)

	Xingyu Zhu, Abhishek Panigrahi, Sanjeev Arora

+ [AskToAct: Enhancing LLMs Tool Use via Self-Correcting Clarification](https://arxiv.org//abs/2503.01940)

	Xuan Zhang, Yongliang Shen, Zhe Zheng, Linjuan Wu, Wenqi Zhang, Yuchen Yan, Qiuying Peng, Jun Wang, Weiming Lu

# 2025-03-02
+ [NCL-UoR at SemEval-2025 Task 3: Detecting Multilingual Hallucination and Related Observable Overgeneration Text Spans with Modified RefChecker and Modified SeflCheckGPT](https://arxiv.org//abs/2503.01921)

	Jiaying Hong, Thanet Markchom, Jianfei Xu, Tong Wu, Huizhi Liang

+ [ALinFiK: Learning to Approximate Linearized Future Influence Kernel for Scalable Third-Party LLM Data Valuation](https://arxiv.org//abs/2503.01052)

	Yanzhou Pan, Huawei Lin, Yide Ran, Jiamin Chen, Xiaodong Yu, Weijie Zhao, Denghui Zhang, Zhaozhuo Xu

+ [Explainable Multi-modal Time Series Prediction with LLM-in-the-Loop](https://arxiv.org//abs/2503.01013)

	Yushan Jiang, Wenchao Yu, Geon Lee, Dongjin Song, Kijung Shin, Wei Cheng, Yanchi Liu, Haifeng Chen

+ [Optimizing Multi-Hop Document Retrieval Through Intermediate Representations](https://arxiv.org//abs/2503.04796)

	Jiaen Lin, Jingyu Liu, Yingbo Liu

# 2025-03-01
+ [Steer LLM Latents for Hallucination Detection](https://arxiv.org//abs/2503.01917)

	Seongheon Park, Xuefeng Du, Min-Hsuan Yeh, Haobo Wang, Yixuan Li

+ [Semantic Integrity Constraints: Declarative Guardrails for AI-Augmented Data Processing Systems](https://arxiv.org//abs/2503.00600)

	Alexander W. Lee, Justin Chan, Michael Fu, Nicolas Kim, Akshay Mehta, Deepti Raghavan, Ugur Cetintemel

+ [Safety Tax: Safety Alignment Makes Your Large Reasoning Models Less Reasonable](https://arxiv.org//abs/2503.00555)

	Tiansheng Huang, Sihao Hu, Fatih Ilhan, Selim Furkan Tekin, Zachary Yahn, Yichang Xu, Ling Liu

+ [Instructor-Worker Large Language Model System for Policy Recommendation: a Case Study on Air Quality Analysis of the January 2025 Los Angeles Wildfires](https://arxiv.org//abs/2503.00566)

	Kyle Gao, Dening Lu, Liangzhi Li, Nan Chen, Hongjie He, Linlin Xu, Jonathan Li

+ [Sentence-level Reward Model can Generalize Better for Aligning LLM from Human Preference](https://arxiv.org//abs/2503.04793)

	Wenjie Qiu, Yi-Chen Li, Xuqin Zhang, Tianyi Zhang, Yihang Zhang, Zongzhang Zhang, Yang Yu

# 2025-02-28
+ [SPD: Sync-Point Drop for efficient tensor parallelism of Large Language Models](https://arxiv.org//abs/2502.20727)

	Han-Byul Kim, Duc Hoang, Arnav Kundu, Mohammad Samragh, Minsik Cho

+ [Semantic Volume: Quantifying and Detecting both External and Internal Uncertainty in LLMs](https://arxiv.org//abs/2502.21239)

	Xiaomin Li, Zhou Yu, Ziji Zhang, Yingying Zhuang, Swair Shah, Narayanan Sadagopan, Anurag Beniwal

+ [A Pilot Empirical Study on When and How to Use Knowledge Graphs as Retrieval Augmented Generation](https://arxiv.org//abs/2502.20854)

	Xujie Yuan, Yongxu Liu, Shimin Di, Shiwen Wu, Libin Zheng, Rui Meng, Lei Chen, Xiaofang Zhou, Jian Yin

+ [FANformer: Improving Large Language Models Through Effective Periodicity Modeling](https://arxiv.org//abs/2502.21309)

	Yihong Dong, Ge Li, Xue Jiang, Yongding Tao, Kechi Zhang, Hao Zhu, Huanyu Liu, Jiazheng Ding, Jia Li, Jinliang Deng, Hong Mei

+ [CODI: Compressing Chain-of-Thought into Continuous Space via Self-Distillation](https://arxiv.org//abs/2502.21074)

	Zhenyi Shen, Hanqi Yan, Linhai Zhang, Zhanghao Hu, Yali Du, Yulan He

+ [EdgeAIGuard: Agentic LLMs for Minor Protection in Digital Spaces](https://arxiv.org//abs/2503.00092)

	Ghulam Mujtaba, Sunder Ali Khowaja, Kapal Dev

+ [PersuasiveToM: A Benchmark for Evaluating Machine Theory of Mind in Persuasive Dialogues](https://arxiv.org//abs/2502.21017)

	Fangxu Yu, Lai Jiang, Shenyi Huang, Zhen Wu, Xinyu Dai

+ [WiseMind: Recontextualizing AI with a Knowledge-Guided, Theory-Informed Multi-Agent Framework for Instrumental and Humanistic Benefits](https://arxiv.org//abs/2502.20689)

	Yuqi Wu, Guangya Wan, Jingjing Li, Shengming Zhao, Lingfeng Ma, Tianyi Ye, Ion Pop, Yanbo Zhang, Jie Chen

+ [Personalized Causal Graph Reasoning for LLMs: A Case Study on Dietary Recommendations](https://arxiv.org//abs/2503.00134)

	Zhongqi Yang, Amir Rahmani

+ [A Survey of Uncertainty Estimation Methods on Large Language Models](https://arxiv.org//abs/2503.00172)

	Zhiqiu Xia, Jinxuan Xu, Yuqian Zhang, Hang Liu

+ [SafeAuto: Knowledge-Enhanced Safe Autonomous Driving with Multimodal Foundation Models](https://arxiv.org//abs/2503.00211)

	Jiawei Zhang, Xuan Yang, Taiqi Wang, Yu Yao, Aleksandr Petiushko, Bo Li

+ [UDora: A Unified Red Teaming Framework against LLM Agents by Dynamically Hijacking Their Own Reasoning](https://arxiv.org//abs/2503.01908)

	Jiawei Zhang, Shuang Yang, Bo Li

# 2025-02-27
+ [LLM-driven Effective Knowledge Tracing by Integrating Dual-channel Difficulty](https://arxiv.org//abs/2502.19915)

	Jiahui Cen, Jianghao Lin, Weixuan Zhong, Dong Zhou, Jin Chen, Aimin Yang, Yongmei Zhou

+ [Mapping Trustworthiness in Large Language Models: A Bibliometric Analysis Bridging Theory to Practice](https://arxiv.org//abs/2503.04785)

	José Siqueira de Cerqueira, Kai-Kristian Kemell, Muhammad Waseem, Rebekah Rousi, Nannan Xi, Juho Hamari, Pekka Abrahamsson

+ [Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization](https://arxiv.org//abs/2502.20364)

	Ryan C. Barron, Maksim E. Eren, Olga M. Serafimova, Cynthia Matuszek, Boian S. Alexandrov

+ [Erasing Without Remembering: Implicit Knowledge Forgetting in Large Language Models](https://arxiv.org//abs/2502.19982)

	Huazheng Wang, Yongcheng Jing, Haifeng Sun, Yingjie Wang, Jingyu Wang, Jianxin Liao, Dacheng Tao

+ [Multi2: Multi-Agent Test-Time Scalable Framework for Multi-Document Processing](https://arxiv.org//abs/2502.20592)

	Juntai Cao, Xiang Zhang, Raymond Li, Chuyuan Li, Chenyu You, Shafiq Joty, Giuseppe Carenini

+ [Sensing and Steering Stereotypes: Extracting and Applying Gender Representation Vectors in LLMs](https://arxiv.org//abs/2502.19721)

	Hannah Cyberey, Yangfeng Ji, David Evans

+ [Investigating and Enhancing Vision-Audio Capability in Omnimodal Large Language Models](https://arxiv.org//abs/2503.00059)

	Rui Hu, Delai Qiu, Shuyu Wei, Jiaming Zhang, Yining Wang, Shengping Liu, Jitao Sang

+ [Meta-Reasoner: Dynamic Guidance for Optimized Inference-time Reasoning in Large Language Models](https://arxiv.org//abs/2502.19918)

	Yuan Sui, Yufei He, Tri Cao, Simeng Han, Yulin Chen, Bryan Hooi

+ [Collab-Overcooked: Benchmarking and Evaluating Large Language Models as Collaborative Agents](https://arxiv.org//abs/2502.20073)

	Haochen Sun, Shuwen Zhang, Lujie Niu, Lei Ren, Hao Xu, Hao Fu, Fangkun Zhao, Caixia Yuan, Xiaojie Wang

+ [Similarity-Distance-Magnitude Universal Verification](https://arxiv.org//abs/2502.20167)

	Allen Schmaltz

+ [Do Retrieval-Augmented Language Models Adapt to Varying User Needs?](https://arxiv.org//abs/2502.19779)

	Peilin Wu, Xinlu Zhang, Wenhao Yu, Xingyu Liu, Xinya Du, Zhiyu Zoey Chen

+ [GeoEdit: Geometric Knowledge Editing for Large Language Models](https://arxiv.org//abs/2502.19953)

	Yujie Feng, Liming Zhan, Zexin Lu, Yongxin Xu, Xu Chu, Yasha Wang, Jiannong Cao, Philip S. Yu, Xiao-Ming Wu

+ [FINEREASON: Evaluating and Improving LLMs' Deliberate Reasoning through Reflective Puzzle Solving](https://arxiv.org//abs/2502.20238)

	Guizhen Chen, Weiwen Xu, Hao Zhang, Hou Pong Chan, Chaoqun Liu, Lidong Bing, Deli Zhao, Anh Tuan Luu, Yu Rong

+ [Tokens for Learning, Tokens for Unlearning: Mitigating Membership Inference Attacks in Large Language Models via Dual-Purpose Training](https://arxiv.org//abs/2502.19726)

	Toan Tran, Ruixuan Liu, Li Xiong

+ [OmniRouter: Budget and Performance Controllable Multi-LLM Routing](https://arxiv.org//abs/2502.20576)

	Kai Mei, Wujiang Xu, Shuhang Lin, Yongfeng Zhang

+ [Emergent Symbolic Mechanisms Support Abstract Reasoning in Large Language Models](https://arxiv.org//abs/2502.20332)

	Yukang Yang, Declan Campbell, Kaixuan Huang, Mengdi Wang, Jonathan Cohen, Taylor Webb

+ [Self-Training Elicits Concise Reasoning in Large Language Models](https://arxiv.org//abs/2502.20122)

	Tergel Munkhbat, Namgyu Ho, Seo Hyun Kim, Yongjin Yang, Yujin Kim, Se-Young Yun

+ [Revisiting Self-Consistency from Dynamic Distributional Alignment Perspective on Answer Aggregation](https://arxiv.org//abs/2502.19830)

	Yiwei Li, Ji Zhang, Shaoxiong Feng, Peiwen Yuan, Xinglin Wang, Jiayi Shi, Yueqi Zhang, Chuyi Tan, Boyuan Pan, Yao Hu, Kan Li

+ [Why Are Web AI Agents More Vulnerable Than Standalone LLMs? A Security Analysis](https://arxiv.org//abs/2502.20383)

	Jeffrey Yang Fan Chiang, Seungjae Lee, Jia-Bin Huang, Furong Huang, Yizheng Chen

# 2025-02-26
+ [BIG-Bench Extra Hard](https://arxiv.org//abs/2502.19187)

	Mehran Kazemi, Bahare Fatemi, Hritik Bansal, John Palowitch, Chrysovalantis Anastasiou, Sanket Vaibhav Mehta, Lalit K. Jain, Virginia Aglietti, Disha Jindal, Peter Chen, Nishanth Dikkala, Gladys Tyen, Xin Liu, Uri Shalit, Silvia Chiappa, Kate Olszewska, Yi Tay, Vinh Q. Tran, Quoc V. Le, Orhan Firat

+ [A Sliding Layer Merging Method for Efficient Depth-Wise Pruning in LLMs](https://arxiv.org//abs/2502.19159)

	Xuan Ding, Rui Sun, Yunjian Zhang, Xiu Yan, Yueqi Zhou, Kaihao Huang, Suzhong Fu, Chuanlong Xie, Yao Zhu

+ [Can RLHF be More Efficient with Imperfect Reward Models? A Policy Coverage Perspective](https://arxiv.org//abs/2502.19255)

	Jiawei Huang, Bingcong Li, Christoph Dann, Niao He

+ [ZEBRA: Leveraging Model-Behavioral Knowledge for Zero-Annotation Preference Dataset Construction](https://arxiv.org//abs/2502.18744)

	Jeesu Jung, Chanjun Park, Sangkeun Jung

+ [Stay Focused: Problem Drift in Multi-Agent Debate](https://arxiv.org//abs/2502.19559)

	Jonas Becker, Lars Benedikt Kaesberg, Andreas Stephan, Jan Philip Wahle, Terry Ruas, Bela Gipp

+ [Is Your Paper Being Reviewed by an LLM? Benchmarking AI Text Detection in Peer Review](https://arxiv.org//abs/2502.19614)

	Sungduk Yu, Man Luo, Avinash Madusu, Vasudev Lal, Phillip Howard

+ [TheoremExplainAgent: Towards Video-based Multimodal Explanations for LLM Theorem Understanding](https://arxiv.org//abs/2502.19400)

	Max Ku, Thomas Chong, Jonathan Leung, Krish Shah, Alvin Yu, Wenhu Chen

+ [Can LLMs Help Uncover Insights about LLMs? A Large-Scale, Evolving Literature Analysis of Frontier LLMs](https://arxiv.org//abs/2502.18791)

	Jungsoo Park, Junmo Kang, Gabriel Stanovsky, Alan Ritter

+ [Exploring the Generalizability of Factual Hallucination Mitigation via Enhancing Precise Knowledge Utilization](https://arxiv.org//abs/2502.19127)

	Siyuan Zhang, Yichi Zhang, Yinpeng Dong, Hang Su

+ [Amulet: ReAlignment During Test Time for Personalized Preference Adaptation of LLMs](https://arxiv.org//abs/2502.19148)

	Zhaowei Zhang, Fengshuo Bai, Qizhi Chen, Chengdong Ma, Mingzhi Wang, Haoran Sun, Zilong Zheng, Yaodong Yang

+ [Learning to Align Multi-Faceted Evaluation: A Unified and Robust Framework](https://arxiv.org//abs/2502.18874)

	Kaishuai Xu, Tiezheng Yu, Wenjun Hou, Yi Cheng, Liangyou Li, Xin Jiang, Lifeng Shang, Qun Liu, Wenjie Li

+ [Voting or Consensus? Decision-Making in Multi-Agent Debate](https://arxiv.org//abs/2502.19130)

	Lars Benedikt Kaesberg, Jonas Becker, Jan Philip Wahle, Terry Ruas, Bela Gipp

+ [Between Circuits and Chomsky: Pre-pretraining on Formal Languages Imparts Linguistic Biases](https://arxiv.org//abs/2502.19249)

	Michael Y. Hu, Jackson Petty, Chuan Shi, William Merrill, Tal Linzen

+ [Beyond Surface-Level Patterns: An Essence-Driven Defense Framework Against Jailbreak Attacks in LLMs](https://arxiv.org//abs/2502.19041)

	Shiyu Xiang, Ansen Zhang, Yanfei Cao, Yang Fan, Ronghao Chen

+ [TestNUC: Enhancing Test-Time Computing Approaches and Scaling through Neighboring Unlabeled Data Consistency](https://arxiv.org//abs/2502.19163)

	Henry Peng Zou, Zhengyao Gu, Yue Zhou, Yankai Chen, Weizhi Zhang, Liancheng Fang, Yibo Wang, Yangning Li, Kay Liu, Philip S. Yu

+ [General Intelligence Requires Reward-based Pretraining](https://arxiv.org//abs/2502.19402)

	Seungwook Han, Jyothish Pari, Samuel J. Gershman, Pulkit Agrawal

+ [ImageChain: Advancing Sequential Image-to-Text Reasoning in Multimodal Large Language Models](https://arxiv.org//abs/2502.19409)

	Danae Sánchez Villegas, Ingo Ziegler, Desmond Elliott

+ [The Sharpness Disparity Principle in Transformers for Accelerating Language Model Pre-Training](https://arxiv.org//abs/2502.19002)

	Jinbo Wang, Mingze Wang, Zhanpeng Zhou, Junchi Yan, Weinan E, Lei Wu

+ [MEDDxAgent: A Unified Modular Agent Framework for Explainable Automatic Differential Diagnosis](https://arxiv.org//abs/2502.19175)

	Daniel Rose, Chia-Chien Hung, Marco Lepri, Israa Alqassem, Kiril Gashteovski, Carolin Lawrence

+ [Conformal Linguistic Calibration: Trading-off between Factuality and Specificity](https://arxiv.org//abs/2502.19110)

	Zhengping Jiang, Anqi Liu, Benjamin Van Durme

+ [Reference-Aligned Retrieval-Augmented Question Answering over Heterogeneous Proprietary Documents](https://arxiv.org//abs/2502.19596)

	Nayoung Choi, Grace Byun, Andrew Chung, Ellie S. Paek, Shinsun Lee, Jinho D. Choi

+ [OS-Kairos: Adaptive Interaction for MLLM-Powered GUI Agents](https://arxiv.org//abs/2503.16465)

	Pengzhou Cheng, Zheng Wu, Zongru Wu, Aston Zhang, Zhuosheng Zhang, Gongshen Liu

+ [Gatekeeper: Improving Model Cascades Through Confidence Tuning](https://arxiv.org//abs/2502.19335)

	Stephan Rabanser, Nathalie Rauschmayr, Achin Kulshrestha, Petra Poklukar, Wittawat Jitkrittum, Sean Augenstein, Congchao Wang, Federico Tombari

# 2025-02-25
+ [Faster, Cheaper, Better: Multi-Objective Hyperparameter Optimization for LLM and RAG Systems](https://arxiv.org//abs/2502.18635)

	Matthew Barker, Andrew Bell, Evan Thomas, James Carr, Thomas Andrews, Umang Bhatt

+ [Discriminative Finetuning of Generative Large Language Models without Reward Models and Human Preference Data](https://arxiv.org//abs/2502.18679)

	Siqi Guo, Ilgee Hong, Vicente Balmaseda, Changlong Yu, Liang Qiu, Xin Liu, Haoming Jiang, Tuo Zhao, Tianbao Yang

+ [Harnessing Multiple Large Language Models: A Survey on LLM Ensemble](https://arxiv.org//abs/2502.18036)

	Zhijun Chen, Jingzheng Li, Pengpeng Chen, Zhuoran Li, Kai Sun, Yuankai Luo, Qianren Mao, Dingqi Yang, Hailong Sun, Philip S. Yu

+ [Uncertainty Quantification for LLM-Based Survey Simulations](https://arxiv.org//abs/2502.17773)

	Chengpiao Huang, Yuhang Wu, Kaizheng Wang

+ [FoREST: Frame of Reference Evaluation in Spatial Reasoning Tasks](https://arxiv.org//abs/2502.17775)

	Tanawan Premsri, Parisa Kordjamshidi

+ [Towards Better Understanding of Program-of-Thought Reasoning in Cross-Lingual and Multilingual Environments](https://arxiv.org//abs/2502.17956)

	Patomporn Payoungkhamdee, Pume Tuchinda, Jinheon Baek, Samuel Cahyawijaya, Can Udomcharoenchaikit, Potsawee Manakul, Peerat Limkonchotiwat, Ekapol Chuangsuwanich, Sarana Nutanong

+ [Unveiling the Key Factors for Distilling Chain-of-Thought Reasoning](https://arxiv.org//abs/2502.18001)

	Xinghao Chen, Zhijing Sun, Wenjin Guo, Miaoran Zhang, Yanjun Chen, Yirong Sun, Hui Su, Yijie Pan, Dietrich Klakow, Wenjie Li, Xiaoyu Shen

+ [SpargeAttention: Accurate and Training-free Sparse Attention Accelerating Any Model Inference](https://arxiv.org//abs/2502.18137)

	Jintao Zhang, Chendong Xiang, Haofeng Huang, Jia Wei, Haocheng Xi, Jun Zhu, Jianfei Chen

+ [IMPROVE: Iterative Model Pipeline Refinement and Optimization Leveraging LLM Experts](https://arxiv.org//abs/2502.18530)

	Eric Xue, Ke Chen, Zeyi Huang, Yuyang Ji, Yong Jae Lee, Haohan Wang

+ [Jacobian Sparse Autoencoders: Sparsify Computations, Not Just Activations](https://arxiv.org//abs/2502.18147)

	Lucy Farnik, Tim Lawson, Conor Houghton, Laurence Aitchison

+ [Breaking Distortion-free Watermarks in Large Language Models](https://arxiv.org//abs/2502.18608)

	Shayleen Reynolds, Hengzhi He, Dung Daniel T. Ngo, Saheed Obitayo, Niccolò Dalmasso, Guang Cheng, Vamsi K. Potluru, Manuela Veloso

# 2025-02-24
+ [Automatically Evaluating the Paper Reviewing Capability of Large Language Models](https://arxiv.org//abs/2502.17086)

	Hyungyu Shin, Jingyu Tang, Yoonjoo Lee, Nayoung Kim, Hyunseung Lim, Ji Yong Cho, Hwajung Hong, Moontae Lee, Juho Kim

+ [From System 1 to System 2: A Survey of Reasoning Large Language Models](https://arxiv.org//abs/2502.17419)

	Zhong-Zhi Li, Duzhen Zhang, Ming-Liang Zhang, Jiaxin Zhang, Zengyan Liu, Yuxuan Yao, Haotian Xu, Junhao Zheng, Pei-Jie Wang, Xiuyi Chen, Yingying Zhang, Fei Yin, Jiahua Dong, Zhiwei Li, Bao-Long Bi, Ling-Rui Mei, Junfeng Fang, Zhijiang Guo, Le Song, Cheng-Lin Liu

+ [MEMERAG: A Multilingual End-to-End Meta-Evaluation Benchmark for Retrieval Augmented Generation](https://arxiv.org//abs/2502.17163)

	María Andrea Cruz Blandón, Jayasimha Talur, Bruno Charron, Dong Liu, Saab Mansour, Marcello Federico

+ [Make LoRA Great Again: Boosting LoRA with Adaptive Singular Values and Mixture-of-Experts Optimization Alignment](https://arxiv.org//abs/2502.16894)

	Chenghao Fan, Zhenyi Lu, Sichen Liu, Chengfeng Gu, Xiaoye Qu, Wei Wei, Yu Cheng

+ [Intermediate Languages Matter: Formal Choice Drives Neurosymbolic LLM Reasoning](https://arxiv.org//abs/2502.17216)

	Alexander Beiser, David Penz, Nysret Musliu

+ [Large Language Models are Powerful Electronic Health Record Encoders](https://arxiv.org//abs/2502.17403)

	Stefan Hegselmann, Georg von Arnim, Tillmann Rheude, Noel Kronenberg, David Sontag, Gerhard Hindricks, Roland Eils, Benjamin Wild

+ [Spontaneous Giving and Calculated Greed in Language Models](https://arxiv.org//abs/2502.17720)

	Yuxuan Li, Hirokazu Shirado

+ [Finding the Sweet Spot: Preference Data Construction for Scaling Preference Optimization](https://arxiv.org//abs/2502.16825)

	Yao Xiao, Hai Ye, Linyao Chen, Hwee Tou Ng, Lidong Bing, Xiaoli Li, Roy Ka-wei Lee

+ [Unveiling Downstream Performance Scaling of LLMs: A Clustering-Based Perspective](https://arxiv.org//abs/2502.17262)

	Chengyin Xu, Kaiyuan Chen, Xiao Li, Ke Shen, Chenggang Li

+ [PrivaCI-Bench: Evaluating Privacy with Contextual Integrity and Legal Compliance](https://arxiv.org//abs/2502.17041)

	Haoran Li, Wenbin Hu, Huihao Jing, Yulin Chen, Qi Hu, Sirui Han, Tianshu Chu, Peizhao Hu, Yangqiu Song

+ [CORAL: Learning Consistent Representations across Multi-step Training with Lighter Speculative Drafter](https://arxiv.org//abs/2502.16880)

	Yepeng Weng, Dianwen Mei, Huishi Qiu, Xujie Chen, Li Liu, Jiang Tian, Zhongchao Shi

+ [Cheems: A Practical Guidance for Building and Evaluating Chinese Reward Models from Scratch](https://arxiv.org//abs/2502.17173)

	Xueru Wen, Jie Lou, Zichao Li, Yaojie Lu, Xing Yu, Yuqiu Ji, Guohai Xu, Hongyu Lin, Ben He, Xianpei Han, Le Sun, Debing Zhang

+ [ExpandR: Teaching Dense Retrievers Beyond Queries with LLM Guidance](https://arxiv.org//abs/2502.17057)

	Sijia Yao, Pengcheng Huang, Zhenghao Liu, Yu Gu, Yukun Yan, Shi Yu, Ge Yu

+ [From Perceptions to Decisions: Wildfire Evacuation Decision Prediction with Behavioral Theory-informed LLMs](https://arxiv.org//abs/2502.17701)

	Ruxiao Chen, Chenguang Wang, Yuran Sun, Xilei Zhao, Susu Xu

+ [DIS-CO: Discovering Copyrighted Content in VLMs Training Data](https://arxiv.org//abs/2502.17358)

	André V. Duarte, Xuandong Zhao, Arlindo L. Oliveira, Lei Li

+ [Measuring Data Diversity for Instruction Tuning: A Systematic Analysis and A Reliable Metric](https://arxiv.org//abs/2502.17184)

	Yuming Yang, Yang Nan, Junjie Ye, Shihan Dou, Xiao Wang, Shuo Li, Huijie Lv, Mingqi Wu, Tao Gui, Qi Zhang, Xuanjing Huang

# 2025-02-23
+ [Retrieval-Augmented Fine-Tuning With Preference Optimization For Visual Program Generation](https://arxiv.org//abs/2502.16529)

	Deokhyung Kang, Jeonghun Cho, Yejin Jeon, Sunbin Jang, Minsub Lee, Jawoon Cho, Gary Geunbae Lee

+ [GraphCheck: Breaking Long-Term Text Barriers with Extracted Knowledge Graph-Powered Fact-Checking](https://arxiv.org//abs/2502.16514)

	Yingjian Chen, Haoran Liu, Yinhong Liu, Jinxiang Xie, Rui Yang, Han Yuan, Yanran Fu, Peng Yuan Zhou, Qingyu Chen, James Caverlee, Irene Li

# 2025-02-22
+ [Worse than Zero-shot? A Fact-Checking Dataset for Evaluating the Robustness of RAG Against Misleading Retrievals](https://arxiv.org//abs/2502.16101)

	Linda Zeng, Rithwik Gupta, Divij Motwani, Diji Yang, Yi Zhang

+ [Patterns Over Principles: The Fragility of Inductive Reasoning in LLMs under Noisy Observations](https://arxiv.org//abs/2502.16169)

	Chunyang Li, Weiqi Wang, Tianshi Zheng, Yangqiu Song

+ [Robustness and Cybersecurity in the EU Artificial Intelligence Act](https://arxiv.org//abs/2502.16184)

	Henrik Nolte, Miriam Rateike, Michèle Finck

+ [Can LLMs Reason About Program Semantics? A Comprehensive Evaluation of LLMs on Formal Specification Inference](https://arxiv.org//abs/2503.04779)

	Thanh Le-Cong, Bach Le, Toby Murray

+ [Instruction-Tuning LLMs for Event Extraction with Annotation Guidelines](https://arxiv.org//abs/2502.16377)

	Saurabh Srivastava, Sweta Pati, Ziyu Yao

+ [Recurrent Knowledge Identification and Fusion for Language Model Continual Learning](https://arxiv.org//abs/2502.17510)

	Yujie Feng, Xujia Wang, Zexin Lu, Shenghong Fu, Guangyuan Shi, Yongxin Xu, Yasha Wang, Philip S. Yu, Xu Chu, Xiao-Ming Wu

+ [A Comprehensive Survey of Machine Unlearning Techniques for Large Language Models](https://arxiv.org//abs/2503.01854)

	Jiahui Geng, Qing Li, Herbert Woisetschlaeger, Zongxiong Chen, Fengyu Cai, Yuxia Wang, Preslav Nakov, Hans-Arno Jacobsen, Fakhri Karray

+ [Mapping 1,000+ Language Models via the Log-Likelihood Vector](https://arxiv.org//abs/2502.16173)

	Momose Oyama, Hiroaki Yamagiwa, Yusuke Takase, Hidetoshi Shimodaira

+ [C2-DPO: Constrained Controlled Direct Preference Optimization](https://arxiv.org//abs/2502.17507)

	Kavosh Asadi, Julien Han, Idan Pipano, Xingzi Xu, Dominique Perrault-Joncas, Shoham Sabach, Karim Bouyarmane, Mohammad Ghavamzadeh

# 2025-02-21
+ [Machine-generated text detection prevents language model collapse](https://arxiv.org//abs/2502.15654)

	George Drayson, Emine Yilmaz, Vasileios Lampos

+ [Activation Steering in Neural Theorem Provers](https://arxiv.org//abs/2502.15507)

	Shashank Kirtania

+ [Unveiling Attractor Cycles in Large Language Models: A Dynamical Systems View of Successive Paraphrasing](https://arxiv.org//abs/2502.15208)

	Zhilin Wang, Yafu Li, Jianhao Yan, Yu Cheng, Yue Zhang

+ [ARS: Automatic Routing Solver with Large Language Models](https://arxiv.org//abs/2502.15359)

	Kai Li, Fei Liu, Zhenkun Wang, Xialiang Tong, Xiongwei Han, Mingxuan Yuan, Qingfu Zhang

+ [Sparsity May Be All You Need: Sparse Random Parameter Adaptation](https://arxiv.org//abs/2502.15975)

	Jesus Rios, Pierre Dognin, Ronny Luss, Karthikeyan N. Ramamurthy

+ [Problem-Solving Logic Guided Curriculum In-Context Learning for LLMs Complex Reasoning](https://arxiv.org//abs/2502.15401)

	Xuetao Ma, Wenbin Jiang, Hua Huang

+ [CoT-ICL Lab: A Synthetic Framework for Studying Chain-of-Thought Learning from In-Context Demonstrations](https://arxiv.org//abs/2502.15132)

	Vignesh Kothapalli, Hamed Firooz, Maziar Sanjabi

+ [KVLink: Accelerating Large Language Models via Efficient KV Cache Reuse](https://arxiv.org//abs/2502.16002)

	Jingbo Yang, Bairu Hou, Wei Wei, Yujia Bao, Shiyu Chang

+ [SafeInt: Shielding Large Language Models from Jailbreak Attacks via Safety-Aware Representation Intervention](https://arxiv.org//abs/2502.15594)

	Jiaqi Wu, Chen Chen, Chunyan Hou, Xiaojie Yuan

+ [Does Reasoning Introduce Bias? A Study of Social Bias Evaluation and Mitigation in LLM Reasoning](https://arxiv.org//abs/2502.15361)

	Xuyang Wu, Jinming Nian, Ting-Ruen Wei, Zhiqiang Tao, Hsin-Tai Wu, Yi Fang

+ [Self-Taught Agentic Long Context Understanding](https://arxiv.org//abs/2502.15920)

	Yufan Zhuang, Xiaodong Yu, Jialian Wu, Ximeng Sun, Ze Wang, Jiang Liu, Yusheng Su, Jingbo Shang, Zicheng Liu, Emad Barsoum

+ [ParamMute: Suppressing Knowledge-Critical FFNs for Faithful Retrieval-Augmented Generation](https://arxiv.org//abs/2502.15543)

	Pengcheng Huang, Zhenghao Liu, Yukun Yan, Haiyan Zhao, Xiaoyuan Yi, Hao Chen, Zhiyuan Liu, Maosong Sun, Tong Xiao, Ge Yu, Chenyan Xiong

+ [SOTOPIA-$Ω$: Dynamic Strategy Injection Learning and Social Instruction Following Evaluation for Social Agents](https://arxiv.org//abs/2502.15538)

	Wenyuan Zhang, Tianyun Liu, Mengxiao Song, Xiaodong Li, Tingwen Liu

+ [DReSD: Dense Retrieval for Speculative Decoding](https://arxiv.org//abs/2502.15572)

	Milan Gritta, Huiyin Xue, Gerasimos Lampouras

+ [TETRIS: Optimal Draft Token Selection for Batch Speculative Decoding](https://arxiv.org//abs/2502.15197)

	Zhaoxuan Wu, Zijian Zhou, Arun Verma, Alok Prakash, Daniela Rus, Bryan Kian Hsiang Low

+ [Mixup Model Merge: Enhancing Model Merging Performance through Randomized Linear Interpolation](https://arxiv.org//abs/2502.15434)

	Yue Zhou, Yi Chang, Yuan Wu

+ [R-LoRA: Randomized Multi-Head LoRA for Efficient Multi-Task Learning](https://arxiv.org//abs/2502.15455)

	Jinda Liu, Yi Chang, Yuan Wu

+ [Standard Benchmarks Fail - Auditing LLM Agents in Finance Must Prioritize Risk](https://arxiv.org//abs/2502.15865)

	Zichen Chen, Jiaao Chen, Jianda Chen, Misha Sra

+ [Empowering LLMs with Logical Reasoning: A Comprehensive Survey](https://arxiv.org//abs/2502.15652)

	Fengxiang Cheng, Haoxuan Li, Fenrong Liu, Robert van Rooij, Kun Zhang, Zhouchen Lin

+ [On Synthesizing Data for Context Attribution in Question Answering](https://arxiv.org//abs/2504.05317)

	Gorjan Radevski, Kiril Gashteovski, Shahbaz Syed, Christopher Malon, Sebastien Nicolas, Chia-Chien Hung, Timo Sztyler, Verena Heußer, Wiem Ben Rim, Masafumi Enomoto, Kunihiro Takeoka, Masafumi Oyamada, Goran Glavaš, Carolin Lawrence

# 2025-02-20
+ [Drift: Decoding-time Personalized Alignments with Implicit User Preferences](https://arxiv.org//abs/2502.14289)

	Minbeom Kim, Kang-il Lee, Seongho Joo, Hwaran Lee, Thibaut Thonet, Kyomin Jung

+ [A Statistical Case Against Empirical Human-AI Alignment](https://arxiv.org//abs/2502.14581)

	Julian Rodemann, Esteban Garces Arias, Christoph Luther, Christoph Jansen, Thomas Augustin

+ [InductionBench: LLMs Fail in the Simplest Complexity Class](https://arxiv.org//abs/2502.15823)

	Wenyue Hua, Tyler Wong, Sun Fei, Liangming Pan, Adam Jardine, William Yang Wang

+ [iAgent: LLM Agent as a Shield between User and Recommender Systems](https://arxiv.org//abs/2502.14662)

	Wujiang Xu, Yunxiao Shi, Zujie Liang, Xuying Ning, Kai Mei, Kun Wang, Xi Zhu, Min Xu, Yongfeng Zhang

+ [Enhancing Conversational Agents with Theory of Mind: Aligning Beliefs, Desires, and Intentions for Human-Like Interaction](https://arxiv.org//abs/2502.14171)

	Mehdi Jafari, Devin Yuncheng Hua, Hao Xue, Flora Salim

+ [Rapid Word Learning Through Meta In-Context Learning](https://arxiv.org//abs/2502.14791)

	Wentao Wang, Guangyuan Jiang, Tal Linzen, Brenden M. Lake

+ [Edit Once, Update Everywhere: A Simple Framework for Cross-Lingual Knowledge Synchronization in LLMs](https://arxiv.org//abs/2502.14645)

	Yuchen Wu, Liang Ding, Li Shen, Dacheng Tao

+ [Triangulating LLM Progress through Benchmarks, Games, and Cognitive Tests](https://arxiv.org//abs/2502.14359)

	Filippo Momentè, Alessandro Suglia, Mario Giulianelli, Ambra Ferrari, Alexander Koller, Oliver Lemon, David Schlangen, Raquel Fernández, Raffaella Bernardi

+ [ICA-RAG: Information Completeness Guided Adaptive Retrieval-Augmented Generation for Disease Diagnosis](https://arxiv.org//abs/2502.14614)

	Mingyi Jia, Zhihao Jia, Junwen Duan, Yan Song, Jianxin Wang

+ [Quantize What Counts: Bit Allocation Insights Informed by Spectral Gaps in Keys and Values](https://arxiv.org//abs/2502.15075)

	Mohsen Hariri, Alan Luo, Mohammadreza Nemati, Lam Nguyen, Shaochen Zhong, Qifan Wang, Xia Hu, Xiaotian Han, Vipin Chaudhary

+ [HPS: Hard Preference Sampling for Human Preference Alignment](https://arxiv.org//abs/2502.14400)

	Xiandong Zou, Wanyu Lin, Yuchen Li, Pan Zhou

+ [CER: Confidence Enhanced Reasoning in LLMs](https://arxiv.org//abs/2502.14634)

	Ali Razghandi, Seyed Mohammad Hadi Hosseini, Mahdieh Soleymani Baghshah

+ [Mitigating Lost-in-Retrieval Problems in Retrieval Augmented Multi-Hop Question Answering](https://arxiv.org//abs/2502.14245)

	Rongzhi Zhu, Xiangyu Liu, Zequn Sun, Yiwei Wang, Wei Hu

+ [STeCa: Step-level Trajectory Calibration for LLM Agent Learning](https://arxiv.org//abs/2502.14276)

	Hanlin Wang, Jian Wang, Chak Tou Leong, Wenjie Li

+ [Length-Controlled Margin-Based Preference Optimization without Reference Model](https://arxiv.org//abs/2502.14643)

	Gengxu Li, Tingyu Xia, Yi Chang, Yuan Wu

+ [Middle-Layer Representation Alignment for Cross-Lingual Transfer in Fine-Tuned LLMs](https://arxiv.org//abs/2502.14830)

	Danni Liu, Jan Niehues

+ [StructFlowBench: A Structured Flow Benchmark for Multi-turn Instruction Following](https://arxiv.org//abs/2502.14494)

	Jinnan Li, Jinzhe Li, Yue Wang, Yi Chang, Yuan Wu

+ [Does Time Have Its Place? Temporal Heads: Where Language Models Recall Time-specific Information](https://arxiv.org//abs/2502.14258)

	Yein Park, Chanwoong Yoon, Jungwoo Park, Minbyul Jeong, Jaewoo Kang

+ [A Survey on Data Contamination for Large Language Models](https://arxiv.org//abs/2502.14425)

	Yuxing Cheng, Yi Chang, Yuan Wu

+ [Obliviate: Efficient Unmemorization for Protecting Intellectual Property in Large Language Models](https://arxiv.org//abs/2502.15010)

	Mark Russinovich, Ahmed Salem

+ [Measuring Chain of Thought Faithfulness by Unlearning Reasoning Steps](https://arxiv.org//abs/2502.14829)

	Martin Tutek, Fateme Hashemi Chaleshtori, Ana Marasović, Yonatan Belinkov

+ [Less is More: Improving LLM Alignment via Preference Data Selection](https://arxiv.org//abs/2502.14560)

	Xun Deng, Han Zhong, Rui Ai, Fuli Feng, Zheng Wang, Xiangnan He

# 2025-02-19
+ [FairKV: Balancing Per-Head KV Cache for Fast Multi-GPU Inference](https://arxiv.org//abs/2502.15804)

	Bingzhe Zhao, Ke Cheng, Aomufei Yuan, Yuxuan Tian, Ruiguang Zhong, Chengchen Hu, Tong Yang, Lian Yu

+ [Is This Collection Worth My LLM's Time? Automatically Measuring Information Potential in Text Corpora](https://arxiv.org//abs/2502.13691)

	Tristan Karch, Luca Engel, Philippe Schwaller, Frédéric Kaplan

+ [TreeCut: A Synthetic Unanswerable Math Word Problem Dataset for LLM Hallucination Evaluation](https://arxiv.org//abs/2502.13442)

	Jialin Ouyang

+ [FineEdit: Unlock Instruction-Based Text Editing for LLMs](https://arxiv.org//abs/2502.13358)

	Yiming Zeng, Wanhao Yu, Zexin Li, Tao Ren, Yu Ma, Jinghan Cao, Xiyan Chen, Tingting Yu

+ [Reducing Hallucinations in Language Model-based SPARQL Query Generation Using Post-Generation Memory Retrieval](https://arxiv.org//abs/2502.13369)

	Aditya Sharma, Luis Lara, Christopher J. Pal, Amal Zouaq

+ [UniKnow: A Unified Framework for Reliable Language Model Behavior across Parametric and External Knowledge](https://arxiv.org//abs/2502.13648)

	Youna Kim, Hyuhng Joon Kim, Minjoon Choi, Sungmin Cho, Hyunsoo Cho, Sang-goo Lee, Taeuk Kim

+ [Agentic AI Software Engineers: Programming with Trust](https://arxiv.org//abs/2502.13767)

	Abhik Roychoudhury, Corina Pasareanu, Michael Pradel, Baishakhi Ray

+ [A Tale of Two Structures: Do LLMs Capture the Fractal Complexity of Language?](https://arxiv.org//abs/2502.14924)

	Ibrahim Alabdulmohsin, Andreas Steiner

+ [ThinkGuard: Deliberative Slow Thinking Leads to Cautious Guardrails](https://arxiv.org//abs/2502.13458)

	Xiaofei Wen, Wenxuan Zhou, Wenjie Jacky Mo, Muhao Chen

+ [How Do LLMs Perform Two-Hop Reasoning in Context?](https://arxiv.org//abs/2502.13913)

	Tianyu Guo, Hanlin Zhu, Ruiqi Zhang, Jiantao Jiao, Song Mei, Michael I. Jordan, Stuart Russell

+ [Repo2Run: Automated Building Executable Environment for Code Repository at Scale](https://arxiv.org//abs/2502.13681)

	Ruida Hu, Chao Peng, Xinchen Wang, Junjielong Xu, Cuiyun Gao

+ [AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence](https://arxiv.org//abs/2502.13943)

	Yuliang Liu, Junjie Lu, Zhaoling Chen, Chaofeng Qu, Jason Klein Liu, Chonghan Liu, Zefan Cai, Yunhui Xia, Li Zhao, Jiang Bian, Chuheng Zhang, Wei Shen, Zhouhan Lin

+ [VITAL: A New Dataset for Benchmarking Pluralistic Alignment in Healthcare](https://arxiv.org//abs/2502.13775)

	Anudeex Shetty, Amin Beheshti, Mark Dras, Usman Naseem

+ [RAG-Gym: Systematic Optimization of Language Agents for Retrieval-Augmented Generation](https://arxiv.org//abs/2502.13957)

	Guangzhi Xiong, Qiao Jin, Xiao Wang, Yin Fang, Haolin Liu, Yifan Yang, Fangyuan Chen, Zhixing Song, Dengyu Wang, Minjia Zhang, Zhiyong Lu, Aidong Zhang

+ [Which of These Best Describes Multiple Choice Evaluation with LLMs? A) Forced B) Flawed C) Fixable D) All of the Above](https://arxiv.org//abs/2502.14127)

	Nishant Balepur, Rachel Rudinger, Jordan Lee Boyd-Graber

+ [Investigating Non-Transitivity in LLM-as-a-Judge](https://arxiv.org//abs/2502.14074)

	Yi Xu, Laura Ruis, Tim Rocktäschel, Robert Kirk

+ [The Canary's Echo: Auditing Privacy Risks of LLM-Generated Synthetic Text](https://arxiv.org//abs/2502.14921)

	Matthieu Meeus, Lukas Wutschitz, Santiago Zanella-Béguelin, Shruti Tople, Reza Shokri

+ [Lost in Sequence: Do Large Language Models Understand Sequential Recommendation?](https://arxiv.org//abs/2502.13909)

	Sein Kim, Hongseok Kang, Kibum Kim, Jiwan Kim, Donghyun Kim, Minchul Yang, Kwangjin Oh, Julian McAuley, Chanyoung Park

+ [BeamLoRA: Beam-Constraint Low-Rank Adaptation](https://arxiv.org//abs/2502.13604)

	Naibin Gu, Zhenyu Zhang, Xiyu Liu, Peng Fu, Zheng Lin, Shuohuan Wang, Yu Sun, Hua Wu, Weiping Wang, Haifeng Wang

+ [ETS: Efficient Tree Search for Inference-Time Scaling](https://arxiv.org//abs/2502.13575)

	Coleman Hooper, Sehoon Kim, Suhong Moon, Kerem Dilmen, Monishwaran Maheswaran, Nicholas Lee, Michael W. Mahoney, Sophia Shao, Kurt Keutzer, Amir Gholami

+ [Quantifying Memorization and Parametric Response Rates in Retrieval-Augmented Vision-Language Models](https://arxiv.org//abs/2502.13836)

	Peter Carragher, Abhinand Jha, R Raghav, Kathleen M. Carley

+ [Self-Regularization with Sparse Autoencoders for Controllable LLM-based Classification](https://arxiv.org//abs/2502.14133)

	Xuansheng Wu, Wenhao Yu, Xiaoming Zhai, Ninghao Liu

# 2025-02-18
+ [EPO: Explicit Policy Optimization for Strategic Reasoning in LLMs via Reinforcement Learning](https://arxiv.org//abs/2502.12486)

	Xiaoqian Liu, Ke Wang, Yongbin Li, Yuchuan Wu, Wentao Ma, Aobo Kong, Fei Huang, Jianbin Jiao, Junge Zhang

+ [An LLM-Powered Agent for Physiological Data Analysis: A Case Study on PPG-based Heart Rate Estimation](https://arxiv.org//abs/2502.12836)

	Mohammad Feli, Iman Azimi, Pasi Liljeberg, Amir M.Rahmani

+ [None of the Others: a General Technique to Distinguish Reasoning from Memorization in Multiple-Choice LLM Evaluation Benchmarks](https://arxiv.org//abs/2502.12896)

	Eva Sánchez Salido, Julio Gonzalo, Guillermo Marco

+ [Demonstrating specification gaming in reasoning models](https://arxiv.org//abs/2502.13295)

	Alexander Bondarenko, Denis Volk, Dmitrii Volkov, Jeffrey Ladish

+ [KL Penalty Control via Perturbation for Direct Preference Optimization](https://arxiv.org//abs/2502.13177)

	Sangkyu Lee, Janghoon Han, Hosung Song, Stanley Jungkyu Choi, Honglak Lee, Youngjae Yu

+ [SafeRoute: Adaptive Model Selection for Efficient and Accurate Safety Guardrails in Large Language Models](https://arxiv.org//abs/2502.12464)

	Seanie Lee, Dong Bok Lee, Dominik Wagner, Minki Kang, Haebin Seong, Tobias Bocklet, Juho Lee, Sung Ju Hwang

+ [EquiBench: Benchmarking Large Language Models' Understanding of Program Semantics via Equivalence Checking](https://arxiv.org//abs/2502.12466)

	Anjiang Wei, Jiannan Cao, Ran Li, Hongyu Chen, Yuhui Zhang, Ziheng Wang, Yuan Liu, Thiago S. F. X. Teixeira, Diyi Yang, Ke Wang, Alex Aiken

+ [R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on Knowledge Graphs](https://arxiv.org//abs/2502.12767)

	Sumin Jo, Junseong Choi, Jiho Kim, Edward Choi

+ [Robust Adaptation of Large Multimodal Models for Retrieval Augmented Hateful Meme Detection](https://arxiv.org//abs/2502.13061)

	Jingbiao Mei, Jinghong Chen, Guangyu Yang, Weizhe Lin, Bill Byrne

+ [Re-Align: Aligning Vision Language Models via Retrieval-Augmented Direct Preference Optimization](https://arxiv.org//abs/2502.13146)

	Shuo Xing, Yuping Wang, Peiran Li, Ruizheng Bai, Yueqi Wang, Chan-wei Hu, Chengxuan Qian, Huaxiu Yao, Zhengzhong Tu

+ [Benchmarking Post-Training Quantization in LLMs: Comprehensive Taxonomy, Unified Evaluation, and Comparative Analysis](https://arxiv.org//abs/2502.13178)

	Jiaqi Zhao, Ming Wang, Miao Zhang, Yuzhang Shang, Xuebo Liu, Yaowei Wang, Min Zhang, Liqiang Nie

+ [SEA: Low-Resource Safety Alignment for Multimodal Large Language Models via Synthetic Embeddings](https://arxiv.org//abs/2502.12562)

	Weikai Lu, Hao Peng, Huiping Zhuang, Cen Chen, Ziqian Zeng

+ [CityEQA: A Hierarchical LLM Agent on Embodied Question Answering Benchmark in City Space](https://arxiv.org//abs/2502.12532)

	Yong Zhao, Kai Xu, Zhengqiu Zhu, Yue Hu, Zhiheng Zheng, Yingfeng Chen, Yatai Ji, Chen Gao, Yong Li, Jincai Huang

+ [PASER: Post-Training Data Selection for Efficient Pruned Large Language Model Recovery](https://arxiv.org//abs/2502.12594)

	Bowei He, Lihao Yin, Hui-Ling Zhen, Xiaokun Zhang, Mingxuan Yuan, Chen Ma

+ [A Cognitive Writing Perspective for Constrained Long-Form Text Generation](https://arxiv.org//abs/2502.12568)

	Kaiyang Wan, Honglin Mu, Rui Hao, Haoran Luo, Tianle Gu, Xiuying Chen

+ [Multi-Step Alignment as Markov Games: An Optimistic Online Gradient Descent Approach with Convergence Guarantees](https://arxiv.org//abs/2502.12678)

	Yongtao Wu, Luca Viano, Yihang Chen, Zhenyu Zhu, Kimon Antonakopoulos, Quanquan Gu, Volkan Cevher

+ [Training Turn-by-Turn Verifiers for Dialogue Tutoring Agents: The Curious Case of LLMs as Your Coding Tutors](https://arxiv.org//abs/2502.13311)

	Jian Wang, Yinpei Dai, Yichi Zhang, Ziqiao Ma, Wenjie Li, Joyce Chai

+ [Fraud-R1 : A Multi-Round Benchmark for Assessing the Robustness of LLM Against Augmented Fraud and Phishing Inducements](https://arxiv.org//abs/2502.12904)

	Shu Yang, Shenzhe Zhu, Zeyu Wu, Keyu Wang, Junchi Yao, Junchao Wu, Lijie Hu, Mengdi Li, Derek F. Wong, Di Wang

+ [HopRAG: Multi-Hop Reasoning for Logic-Aware Retrieval-Augmented Generation](https://arxiv.org//abs/2502.12442)

	Hao Liu, Zhengren Wang, Xi Chen, Zhiyu Li, Feiyu Xiong, Qinhan Yu, Wentao Zhang

+ [K-Paths: Reasoning over Graph Paths for Drug Repurposing and Drug Interaction Prediction](https://arxiv.org//abs/2502.13344)

	Tassallah Abdullahi, Ioanna Gemou, Nihal V. Nayak, Ghulam Murtaza, Stephen H. Bach, Carsten Eickhoff, Ritambhara Singh

+ [Task-Informed Anti-Curriculum by Masking Improves Downstream Performance on Text](https://arxiv.org//abs/2502.12953)

	Andrei Jarca, Florinel Alin Croitoru, Radu Tudor Ionescu

+ [GSQ-Tuning: Group-Shared Exponents Integer in Fully Quantized Training for LLMs On-Device Fine-tuning](https://arxiv.org//abs/2502.12913)

	Sifan Zhou, Shuo Wang, Zhihang Yuan, Mingjia Shi, Yuzhang Shang, Dawei Yang

+ [LongFaith: Enhancing Long-Context Reasoning in LLMs with Faithful Synthetic Data](https://arxiv.org//abs/2502.12583)

	Cehao Yang, Xueyuan Lin, Chengjin Xu, Xuhui Jiang, Shengjie Ma, Aofan Liu, Hui Xiong, Jian Guo

+ [Flow-of-Options: Diversified and Improved LLM Reasoning by Thinking Through Options](https://arxiv.org//abs/2502.12929)

	Lakshmi Nair, Ian Trase, Mark Kim

+ [CoCo-CoLa: Evaluating and Improving Language Adherence in Multilingual LLMs](https://arxiv.org//abs/2502.12476)

	Elnaz Rahmati, Alireza S. Ziabari, Morteza Dehghani

+ [HumT DumT: Measuring and controlling human-like language in LLMs](https://arxiv.org//abs/2502.13259)

	Myra Cheng, Sunny Yu, Dan Jurafsky

+ [Pitfalls of Scale: Investigating the Inverse Task of Redefinition in Large Language Models](https://arxiv.org//abs/2502.12821)

	Elena Stringli, Maria Lymperaiou, Giorgos Filandrianos, Athanasios Voulodimos, Giorgos Stamou

+ [HPSS: Heuristic Prompting Strategy Search for LLM Evaluators](https://arxiv.org//abs/2502.13031)

	Bosi Wen, Pei Ke, Yufei Sun, Cunxiang Wang, Xiaotao Gu, Jinfeng Zhou, Jie Tang, Hongning Wang, Minlie Huang

+ [Retrieval-augmented systems can be dangerous medical communicators](https://arxiv.org//abs/2502.14898)

	Lionel Wong, Ayman Ali, Raymond Xiong, Shannon Zeijang Shen, Yoon Kim, Monica Agrawal

# 2025-02-17
+ [Towards Reasoning Ability of Small Language Models](https://arxiv.org//abs/2502.11569)

	Gaurav Srivastava, Shuxiang Cao, Xuan Wang


+ [Fate: Fast Edge Inference of Mixture-of-Experts Models via Cross-Layer Gate](https://arxiv.org//abs/2502.12224)

	Zhiyuan Fang, Zicong Hong, Yuegui Huang, Yufeng Lyu, Wuhui Chen, Yue Yu, Fan Yu, Zibin Zheng

+ [Integrating Expert Knowledge into Logical Programs via LLMs](https://arxiv.org//abs/2502.12275)

	Franciszek Górski, Oskar Wysocki, Marco Valentino, Andre Freitas

+ [Can Your Uncertainty Scores Detect Hallucinated Entity?](https://arxiv.org//abs/2502.11948)

	Min-Hsuan Yeh, Max Kamachee, Seongheon Park, Yixuan Li

+ [Table-Critic: A Multi-Agent Framework for Collaborative Criticism and Refinement in Table Reasoning](https://arxiv.org//abs/2502.11799)

	Peiying Yu, Guoxin Chen, Jingjing Wang

+ [From the New World of Word Embeddings: A Comparative Study of Small-World Lexico-Semantic Networks in LLMs](https://arxiv.org//abs/2502.11380)

	Zhu Liu, Ying Liu, KangYang Luo, Cunliang Kong, Maosong Sun

+ [Beyond Single-Task: Robust Multi-Task Length Generalization for LLMs](https://arxiv.org//abs/2502.11525)

	Yi Hu, Shijia Kang, Haotong Yang, Haotian Xu, Muhan Zhang

+ [Plant in Cupboard, Orange on Rably, Inat Aphone. Benchmarking Incremental Learning of Situation and Language Model using a Text-Simulated Situated Environment](https://arxiv.org//abs/2502.11733)

	Jonathan Jordan, Sherzod Hakimov, David Schlangen

+ [FineFilter: A Fine-grained Noise Filtering Mechanism for Retrieval-Augmented Large Language Models](https://arxiv.org//abs/2502.11811)

	Qianchi Zhang, Hainan Zhang, Liang Pang, Ziwei Wang, Hongwei Zheng, Yongxin Tong, Zhiming Zheng

+ [SQL-o1: A Self-Reward Heuristic Dynamic Search Method for Text-to-SQL](https://arxiv.org//abs/2502.11741)

	Shuai Lyu, Haoran Luo, Ripeng Li, Zhonghong Ou, Jiangfeng Sun, Yang Qin, Xiaoran Shang, Meina Song, Yifan Zhu

+ [Which Retain Set Matters for LLM Unlearning? A Case Study on Entity Unlearning](https://arxiv.org//abs/2502.11441)

	Hwan Chang, Hwanhee Lee

+ [GLTW: Joint Improved Graph Transformer and LLM via Three-Word Language for Knowledge Graph Completion](https://arxiv.org//abs/2502.11471)

	Kangyang Luo, Yuzhuo Bai, Cheng Gao, Shuzheng Si, Yingli Shen, Zhu Liu, Zhitong Wang, Cunliang Kong, Wenhao Li, Yufei Huang, Ye Tian, Xuantang Xiong, Lei Han, Maosong Sun

+ [SAFE-SQL: Self-Augmented In-Context Learning with Fine-grained Example Selection for Text-to-SQL](https://arxiv.org//abs/2502.11438)

	Jimin Lee, Ingeol Baek, Byeongjeong Kim, Hyunkyung Bae, Hwanhee Lee

+ [System Message Generation for User Preferences using Open-Source Models](https://arxiv.org//abs/2502.11330)

	Minbyul Jeong, Jungho Cho, Minsoo Khang, Dawoon Jung, Teakgyu Hong

+ [Personality Editing for Language Models through Relevant Knowledge Editing](https://arxiv.org//abs/2502.11789)

	Seojin Hwang, Yumin Kim, Byeongjeong Kim, Donghoon Shin, Hwanhee Lee

+ [SMART: Self-Aware Agent for Tool Overuse Mitigation](https://arxiv.org//abs/2502.11435)

	Cheng Qian, Emre Can Acikgoz, Hongru Wang, Xiusi Chen, Avirup Sil, Dilek Hakkani-Tür, Gokhan Tur, Heng Ji

+ [KnowPath: Knowledge-enhanced Reasoning via LLM-generated Inference Paths over Knowledge Graphs](https://arxiv.org//abs/2502.12029)

	Qi Zhao, Hongyu Yang, Qi Song, Xinwei Yao, Xiangyang Li

+ [ReviewEval: An Evaluation Framework for AI-Generated Reviews](https://arxiv.org//abs/2502.11736)

	Madhav Krishan Garg, Tejash Prasad, Tanmay Singhal, Chhavi Kirtani, Murari Mandal, Dhruv Kumar

+ [Balancing Truthfulness and Informativeness with Uncertainty-Aware Instruction Fine-Tuning](https://arxiv.org//abs/2502.11962)

	Tianyi Wu, Jingwei Ni, Bryan Hooi, Jiaheng Zhang, Elliott Ash, See-Kiong Ng, Mrinmaya Sachan, Markus Leippold

+ [TokenSkip: Controllable Chain-of-Thought Compression in LLMs](https://arxiv.org//abs/2502.12067)

	Heming Xia, Chak Tou Leong, Wenjie Wang, Yongqi Li, Wenjie Li

+ [HellaSwag-Pro: A Large-Scale Bilingual Benchmark for Evaluating the Robustness of LLMs in Commonsense Reasoning](https://arxiv.org//abs/2502.11393)

	Xiaoyuan Li, Moxin Li, Rui Men, Yichang Zhang, Keqin Bao, Wenjie Wang, Fuli Feng, Dayiheng Liu, Junyang Lin

+ [Investigating Inference-time Scaling for Chain of Multi-modal Thought: A Preliminary Study](https://arxiv.org//abs/2502.11514)

	Yujie Lin, Ante Wang, Moye Chen, Jingyao Liu, Hao Liu, Jinsong Su, Xinyan Xiao

+ [Can LLM Watermarks Robustly Prevent Unauthorized Knowledge Distillation?](https://arxiv.org//abs/2502.11598)

	Leyi Pan, Aiwei Liu, Shiyu Huang, Yijian Lu, Xuming Hu, Lijie Wen, Irwin King, Philip S. Yu

+ [Evaluating Step-by-step Reasoning Traces: A Survey](https://arxiv.org//abs/2502.12289)

	Jinu Lee, Julia Hockenmaier

+ [APB: Accelerating Distributed Long-Context Inference by Passing Compressed Context Blocks across GPUs](https://arxiv.org//abs/2502.12085)

	Yuxiang Huang, Mingye Li, Xu Han, Chaojun Xiao, Weilin Zhao, Sun Ao, Hao Zhou, Jie Zhou, Zhiyuan Liu, Maosong Sun

+ [DiSCo: Device-Server Collaborative LLM-Based Text Streaming Services](https://arxiv.org//abs/2502.11417)

	Ting Sun, Penghan Wang, Fan Lai

+ [Explorer: Scaling Exploration-driven Web Trajectory Synthesis for Multimodal Web Agents](https://arxiv.org//abs/2502.11357)

	Vardaan Pahuja, Yadong Lu, Corby Rosset, Boyu Gou, Arindam Mitra, Spencer Whitehead, Yu Su, Ahmed Awadallah

+ [Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration](https://arxiv.org//abs/2502.11882)

	Shao Zhang, Xihuai Wang, Wenhao Zhang, Chaoran Li, Junru Song, Tingyu Li, Lin Qiu, Xuezhi Cao, Xunliang Cai, Wen Yao, Weinan Zhang, Xinbing Wang, Ying Wen

+ [DELMAN: Dynamic Defense Against Large Language Model Jailbreaking with Model Editing](https://arxiv.org//abs/2502.11647)

	Yi Wang, Fenghua Weng, Sibei Yang, Zhan Qin, Minlie Huang, Wenjie Wang

+ [Token Pruning in Multimodal Large Language Models: Are We Solving the Right Problem?](https://arxiv.org//abs/2502.11501)

	Zichen Wen, Yifeng Gao, Weijia Li, Conghui He, Linfeng Zhang

+ [MuSC: Improving Complex Instruction Following with Multi-granularity Self-Contrastive Training](https://arxiv.org//abs/2502.11541)

	Hui Huang, Jiaheng Liu, Yancheng He, Shilong Li, Bing Xu, Conghui Zhu, Muyun Yang, Tiejun Zhao

+ [LLM Agents Making Agent Tools](https://arxiv.org//abs/2502.11705)

	Georg Wölflein, Dyke Ferber, Daniel Truhn, Ognjen Arandjelović, Jakob Nikolas Kather

+ [BaxBench: Can LLMs Generate Correct and Secure Backends?](https://arxiv.org//abs/2502.11844)

	Mark Vero, Niels Mündler, Victor Chibotaru, Veselin Raychev, Maximilian Baader, Nikola Jovanović, Jingxuan He, Martin Vechev

+ [ToolCoder: A Systematic Code-Empowered Tool Learning Framework for Large Language Models](https://arxiv.org//abs/2502.11404)

	Hanxing Ding, Shuchang Tao, Liang Pang, Zihao Wei, Jinyang Gao, Bolin Ding, Huawei Shen, Xueqi Cheng

+ [Diversity-oriented Data Augmentation with Large Language Models](https://arxiv.org//abs/2502.11671)

	Zaitian Wang, Jinghan Zhang, Xinhao Zhang, Kunpeng Liu, Pengfei Wang, Yuanchun Zhou

+ [MT-RAIG: Novel Benchmark and Evaluation Framework for Retrieval-Augmented Insight Generation over Multiple Tables](https://arxiv.org//abs/2502.11735)

	Kwangwook Seo, Donguk Kwon, Dongha Lee

+ [From Selection to Generation: A Survey of LLM-based Active Learning](https://arxiv.org//abs/2502.11767)

	Yu Xia, Subhojyoti Mukherjee, Zhouhang Xie, Junda Wu, Xintong Li, Ryan Aponte, Hanjia Lyu, Joe Barrow, Hongjie Chen, Franck Dernoncourt, Branislav Kveton, Tong Yu, Ruiyi Zhang, Jiuxiang Gu, Nesreen K. Ahmed, Yu Wang, Xiang Chen, Hanieh Deilamsalehy, Sungchul Kim, Zhengmian Hu, Yue Zhao, Nedim Lipka, Seunghyun Yoon, Ting-Hao Kenneth Huang, Zichao Wang, Puneet Mathur, Soumyabrata Pal, Koyel Mukherjee, Zhehao Zhang, Namyong Park, Thien Huu Nguyen, Jiebo Luo, Ryan A. Rossi, Julian McAuley

+ [LLMs on the Line: Data Determines Loss-to-Loss Scaling Laws](https://arxiv.org//abs/2502.12120)

	Prasanna Mayilvahanan, Thaddäus Wiedemer, Sayak Mallick, Matthias Bethge, Wieland Brendel

+ [On the Query Complexity of Verifier-Assisted Language Generation](https://arxiv.org//abs/2502.12123)

	Edoardo Botta, Yuchen Li, Aashay Mehta, Jordan T. Ash, Cyril Zhang, Andrej Risteski

+ [Towards Understanding Fine-Tuning Mechanisms of LLMs via Circuit Analysis](https://arxiv.org//abs/2502.11812)

	Xu Wang, Yan Hu, Wenyu Du, Reynold Cheng, Benyou Wang, Difan Zou

+ [HARBOR: Exploring Persona Dynamics in Multi-Agent Competition](https://arxiv.org//abs/2502.12149)

	Kenan Jiang, Li Xiong, Fei Liu

+ [Idiosyncrasies in Large Language Models](https://arxiv.org//abs/2502.12150)

	Mingjie Sun, Yida Yin, Zhiqiu Xu, J. Zico Kolter, Zhuang Liu

# 2025-02-16
+ [Leveraging Conditional Mutual Information to Improve Large Language Model Fine-Tuning For Classification](https://arxiv.org//abs/2502.11258)

	Thanushon Sivakaran, En-Hui Yang

+ [Safety Evaluation of DeepSeek Models in Chinese Contexts](https://arxiv.org//abs/2502.11137)

	Wenjing Zhang, Xuejiao Lei, Zhaoxiang Liu, Ning Wang, Zhenhong Long, Peijun Yang, Jiaojiao Zhao, Minjie Hua, Chaoyang Ma, Kai Wang, Shiguo Lian

+ [Investigating Language Preference of Multilingual RAG Systems](https://arxiv.org//abs/2502.11175)

	Jeonghyun Park, Hwanhee Lee

+ [RAS: Retrieval-And-Structuring for Knowledge-Intensive LLM Generation](https://arxiv.org//abs/2502.10996)

	Pengcheng Jiang, Lang Cao, Ruike Zhu, Minhao Jiang, Yunyi Zhang, Jimeng Sun, Jiawei Han

+ [The Mirage of Model Editing: Revisiting Evaluation in the Wild](https://arxiv.org//abs/2502.11177)

	Wanli Yang, Fei Sun, Jiajun Tan, Xinyu Ma, Qi Cao, Dawei Yin, Huawei Shen, Xueqi Cheng

+ [CoLA: Compute-Efficient Pre-Training of LLMs via Low-Rank Activation](https://arxiv.org//abs/2502.10940)

	Ziyue Liu, Ruijie Zhang, Zhengyang Wang, Zi Yang, Paul Hovland, Bogdan Nicolae, Franck Cappello, Zheng Zhang

+ [MMUnlearner: Reformulating Multimodal Machine Unlearning in the Era of Multimodal Large Language Models](https://arxiv.org//abs/2502.11051)

	Jiahao Huo, Yibo Yan, Xu Zheng, Yuanhuiyi Lyu, Xin Zou, Zhihua Wei, Xuming Hu

+ [Attention Mechanism for LLM-based Agents Dynamic Diffusion under Information Asymmetry](https://arxiv.org//abs/2502.13160)

	Yiwen Zhang, Yifu Wu, Wenyue Hua, Xiang Lu, Xuming Hu

+ [CARMA: Enhanced Compositionality in LLMs via Advanced Regularisation and Mutual Information Alignment](https://arxiv.org//abs/2502.11066)

	Nura Aljaafari, Danilo S. Carvalho, André Freitas

+ [VLMs as GeoGuessr Masters: Exceptional Performance, Hidden Biases, and Privacy Risks](https://arxiv.org//abs/2502.11163)

	Jingyuan Huang, Jen-tse Huang, Ziyi Liu, Xiaoyuan Liu, Wenxuan Wang, Jieyu Zhao

+ [GRIFFIN: Effective Token Alignment for Faster Speculative Decoding](https://arxiv.org//abs/2502.11018)

	Shijing Hu, Jingyang Li, Xingyu Xie, Zhihui Lu, Kim-Chuan Toh, Pan Zhou

+ [Vendi-RAG: Adaptively Trading-Off Diversity And Quality Significantly Improves Retrieval Augmented Generation With LLMs](https://arxiv.org//abs/2502.11228)

	Mohammad Reza Rezaei, Adji Bousso Dieng

+ [A Survey of LLM-based Agents in Medicine: How far are we from Baymax?](https://arxiv.org//abs/2502.11211)

	Wenxuan Wang, Zizhan Ma, Zheng Wang, Chenghan Wu, Jiaming Ji, Wenting Chen, Xiang Li, Yixuan Yuan

+ [ReLearn: Unlearning via Learning for Large Language Models](https://arxiv.org//abs/2502.11190)

	Haoming Xu, Ningyuan Zhao, Liming Yang, Sendong Zhao, Shumin Deng, Mengru Wang, Bryan Hooi, Nay Oo, Huajun Chen, Ningyu Zhang

+ [Learning to Reason from Feedback at Test-Time](https://arxiv.org//abs/2502.15771)

	Yanyang Li, Michael Lyu, Liwei Wang

+ [Are Generative Models Underconfident? Better Quality Estimation with Boosted Model Probability](https://arxiv.org//abs/2502.11115)

	Tu Anh Dinh, Jan Niehues

+ [RaaS: Reasoning-Aware Attention Sparsity for Efficient LLM Reasoning](https://arxiv.org//abs/2502.11147)

	Junhao Hu, Wenrui Huang, Weidong Wang, Zhenwen Li, Tiancheng Hu, Zhixia Liu, Xusheng Chen, Tao Xie, Yizhou Shan

+ [Rewrite to Jailbreak: Discover Learnable and Transferable Implicit Harmfulness Instruction](https://arxiv.org//abs/2502.11084)

	Yuting Huang, Chengyuan Liu, Yifeng Feng, Yiquan Wu, Chao Wu, Fei Wu, Kun Kuang

+ [Primus: A Pioneering Collection of Open-Source Datasets for Cybersecurity LLM Training](https://arxiv.org//abs/2502.11191)

	Yao-Ching Yu, Tsun-Han Chiang, Cheng-Wei Tsai, Chien-Ming Huang, Wen-Kwang Tsao

+ [How Do LLMs Acquire New Knowledge? A Knowledge Circuits Perspective on Continual Pre-Training](https://arxiv.org//abs/2502.11196)

	Yixin Ou, Yunzhi Yao, Ningyu Zhang, Hui Jin, Jiacheng Sun, Shumin Deng, Zhenguo Li, Huajun Chen

+ [Mind the Confidence Gap: Overconfidence, Calibration, and Distractor Effects in Large Language Models](https://arxiv.org//abs/2502.11028)

	Prateek Chhikara

+ [CMCTS: A Constrained Monte Carlo Tree Search Framework for Mathematical Reasoning in Large Language Model](https://arxiv.org//abs/2502.11169)

	Qingwen Lin, Boyan Xu, Guimin Hu, Zijian Li, Zhifeng Hao, Keli Zhang, Ruichu Cai

+ [Diversified Sampling Improves Scaling LLM inference](https://arxiv.org//abs/2502.11027)

	Tianchun Wang, Zichuan Liu, Yuanzhou Chen, Jonathan Light, Haifeng Chen, Xiang Zhang, Wei Cheng

# 2025-02-15
+ [D-CIPHER: Dynamic Collaborative Intelligent Multi-Agent System with Planner and Heterogeneous Executors for Offensive Security](https://arxiv.org//abs/2502.10931)

	Meet Udeshi, Minghao Shao, Haoran Xi, Nanda Rani, Kimberly Milner, Venkata Sai Charan Putrevu, Brendan Dolan-Gavitt, Sandeep Kumar Shukla, Prashanth Krishnamurthy, Farshad Khorrami, Ramesh Karri, Muhammad Shafique

+ [Probing Semantic Routing in Large Mixture-of-Expert Models](https://arxiv.org//abs/2502.10928)

	Matthew Lyle Olson, Neale Ratzlaff, Musashi Hinck, Man Luo, Sungduk Yu, Chendi Xue, Vasudev Lal

+ [LoRE-Merging: Exploring Low-Rank Estimation For Large Language Model Merging](https://arxiv.org//abs/2502.10749)

	Zehua Liu, Han Wu, Yuxuan Yao, Ruifeng She, Xiongwei Han, Tao Zhong, Mingxuan Yuan

+ [Beyond One-Size-Fits-All Pruning via Evolutionary Metric Search for Large Language Models](https://arxiv.org//abs/2502.10735)

	Shuqi Liu, Bowei He, Han Wu, Linqi Song

+ [1bit-Merging: Dynamic Quantized Merging for Large Language Models](https://arxiv.org//abs/2502.10743)

	Shuqi Liu, Yuxuan Yao, Bowei He, Zehua Liu, Xiongwei Han, Mingxuan Yuan, Han Wu, Linqi Song

+ [Bone Soups: A Seek-and-Soup Model Merging Approach for Controllable Multi-Objective Generation](https://arxiv.org//abs/2502.10762)

	Guofu Xie, Xiao Zhang, Ting Yao, Yunsheng Shi

+ [Lost in the Passage: Passage-level In-context Learning Does Not Necessarily Need a "Passage"](https://arxiv.org//abs/2502.10634)

	Hao Sun, Chenming Tang, Gengyang Li, Yunfang Wu

+ [Towards Effective Extraction and Evaluation of Factual Claims](https://arxiv.org//abs/2502.10855)

	Dasha Metropolitansky, Jonathan Larson

# 2025-02-14
+ [Cooperative Multi-Agent Planning with Adaptive Skill Synthesis](https://arxiv.org//abs/2502.10148)

	Zhiyuan Li, Wenshuai Zhao, Joni Pajarinen

+ [MIR-Bench: Can Your LLM Recognize Complicated Patterns via Many-Shot In-Context Reasoning?](https://arxiv.org//abs/2502.09933)

	Kai Yan, Zhan Ling, Kang Liu, Yifan Yang, Ting-Han Fan, Lingfeng Shen, Zhengyin Du, Jiecao Chen

+ [Prediction hubs are context-informed frequent tokens in LLMs](https://arxiv.org//abs/2502.10201)

	Beatrix M. G. Nielsen, Iuri Macocco, Marco Baroni

+ [Do Large Language Models Reason Causally Like Us? Even Better?](https://arxiv.org//abs/2502.10215)

	Hanna M. Dettki, Brenden M. Lake, Charley M. Wu, Bob Rehder

# 2025-02-13
+ [CRANE: Reasoning with constrained LLM generation](https://arxiv.org//abs/2502.09061)

	Debangshu Banerjee, Tarun Suresh, Shubham Ugare, Sasa Misailovic, Gagandeep Singh

+ [SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models](https://arxiv.org//abs/2502.09604)

	Yung-Sung Chuang, Benjamin Cohen-Wang, Shannon Zejiang Shen, Zhaofeng Wu, Hu Xu, Xi Victoria Lin, James Glass, Shang-Wen Li, Wen-tau Yih

+ [The Hidden Dimensions of LLM Alignment: A Multi-Dimensional Analysis of Orthogonal Safety Directions](https://arxiv.org//abs/2502.09674)

	Wenbo Pan, Zhichao Liu, Qiguang Chen, Xiangyang Zhou, Haining Yu, Xiaohua Jia

+ [CopySpec: Accelerating LLMs with Speculative Copy-and-Paste Without Compromising Quality](https://arxiv.org//abs/2502.08923)

	Razvan-Gabriel Dumitru, Minglai Yang, Vikas Yadav, Mihai Surdeanu

+ [CoSER: Coordinating LLM-Based Persona Simulation of Established Roles](https://arxiv.org//abs/2502.09082)

	Xintao Wang, Heng Wang, Yifei Zhang, Xinfeng Yuan, Rui Xu, Jen-tse Huang, Siyu Yuan, Haoran Guo, Jiangjie Chen, Shuchang Zhou, Wei Wang, Yanghua Xiao

+ [You Do Not Fully Utilize Transformer's Representation Capacity](https://arxiv.org//abs/2502.09245)

	Gleb Gerasimov, Yaroslav Aksenov, Nikita Balagansky, Viacheslav Sinii, Daniil Gavrilov

+ [Can Uniform Meaning Representation Help GPT-4 Translate from Indigenous Languages?](https://arxiv.org//abs/2502.08900)

	Shira Wein

+ [EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents](https://arxiv.org//abs/2502.09560)

	Rui Yang, Hanyang Chen, Junyu Zhang, Mark Zhao, Cheng Qian, Kangrui Wang, Qineng Wang, Teja Venkat Koripella, Marziyeh Movahedi, Manling Li, Heng Ji, Huan Zhang, Tong Zhang

+ [GoRA: Gradient-driven Adaptive Low Rank Adaptation](https://arxiv.org//abs/2502.12171)

	Haonan He, Peng Ye, Yuchen Ren, Yuan Yuan, Luyang Zhou, Shucun Ju, Lei Chen

+ [RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models](https://arxiv.org//abs/2502.09003)

	Quan Wei, Chung-Yiu Yau, Hoi-To Wai, Yang Katie Zhao, Dongyeop Kang, Youngsuk Park, Mingyi Hong

+ [NestQuant: Nested Lattice Quantization for Matrix Products and LLMs](https://arxiv.org//abs/2502.09720)

	Semyon Savkin, Eitan Porat, Or Ordentlich, Yury Polyanskiy

+ [Application Modernization with LLMs: Addressing Core Challenges in Reliability, Security, and Quality](https://arxiv.org//abs/2506.10984)

	Ahilan Ayyachamy Nadar Ponnusamy

+ [Truth Knows No Language: Evaluating Truthfulness Beyond English](https://arxiv.org//abs/2502.09387)

	Blanca Calvo Figueras, Eneko Sagarzazu, Julen Etxaniz, Jeremy Barnes, Pablo Gamallo, Iria De Dios Flores, Rodrigo Agerri

# 2025-02-12
+ [k-LLMmeans: Scalable, Stable, and Interpretable Text Clustering via LLM-based Centroids](https://arxiv.org//abs/2502.09667)

	Jairo Diaz-Rodriguez

+ [No Need for Explanations: LLMs can implicitly learn from mistakes in-context](https://arxiv.org//abs/2502.08550)

	Lisa Alazraki, Maximilian Mozes, Jon Ander Campos, Tan Yi-Chern, Marek Rei, Max Bartolo

+ [SelfElicit: Your Language Model Secretly Knows Where is the Relevant Evidence](https://arxiv.org//abs/2502.08767)

	Zhining Liu, Rana Ali Amjad, Ravinarayana Adkathimar, Tianxin Wei, Hanghang Tong

+ [Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation](https://arxiv.org//abs/2502.08826)

	Mohammad Mahdi Abootorabi, Amirhosein Zobeiri, Mahdi Dehghani, Mohammadali Mohammadkhani, Bardia Mohammadi, Omid Ghahroodi, Mahdieh Soleymani Baghshah, Ehsaneddin Asgari

+ [Fino1: On the Transferability of Reasoning-Enhanced LLMs and Reinforcement Learning to Finance](https://arxiv.org//abs/2502.08127)

	Lingfei Qian, Weipeng Zhou, Yan Wang, Xueqing Peng, Han Yi, Yilun Zhao, Jimin Huang, Qianqian Xie, Jian-yun Nie

# 2025-02-11
+ [Time2Lang: Bridging Time-Series Foundation Models and Large Language Models for Health Sensing Beyond Prompting](https://arxiv.org//abs/2502.07608)

	Arvind Pillai, Dimitris Spathis, Subigya Nepal, Amanda C Collins, Daniel M Mackin, Michael V Heinz, Tess Z Griffin, Nicholas C Jacobson, Andrew Campbell

+ [Caught in the Web of Words: Do LLMs Fall for Spin in Medical Literature?](https://arxiv.org//abs/2502.07963)

	Hye Sun Yun, Karen Y.C. Zhang, Ramez Kouzy, Iain J. Marshall, Junyi Jessy Li, Byron C. Wallace

+ [Recursive Inference Scaling: A Winning Path to Scalable Inference in Language and Multimodal Systems](https://arxiv.org//abs/2502.07503)

	Ibrahim Alabdulmohsin, Xiaohua Zhai

+ [Principled Data Selection for Alignment: The Hidden Risks of Difficult Examples](https://arxiv.org//abs/2502.09650)

	Chengqian Gao, Haonan Li, Liu Liu, Zeke Xie, Peilin Zhao, Zhiqiang Xu

+ [Hallucination, Monofacts, and Miscalibration: An Empirical Investigation](https://arxiv.org//abs/2502.08666)

	Miranda Muqing Miao, Michael Kearns

+ [Mask-Enhanced Autoregressive Prediction: Pay Less Attention to Learn More](https://arxiv.org//abs/2502.07490)

	Xialie Zhuang, Zhikai Jia, Jianjin Li, Zhenyu Zhang, Li Shen, Zheng Cao, Shiwei Liu

+ [Memory Is Not the Bottleneck: Cost-Efficient Continual Learning via Weight Space Consolidation](https://arxiv.org//abs/2502.07274)

	Dongkyu Cho, Taesup Moon, Rumi Chunara, Kyunghyun Cho, Sungmin Cha

+ [CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction](https://arxiv.org//abs/2502.07316)

	Junlong Li, Daya Guo, Dejian Yang, Runxin Xu, Yu Wu, Junxian He

+ [Streaming Attention Approximation via Discrepancy Theory](https://arxiv.org//abs/2502.07861)

	Insu Han, Michael Kapralov, Ekaterina Kochetkova, Kshiteej Sheth, Amir Zandieh

+ [When More is Less: Understanding Chain-of-Thought Length in LLMs](https://arxiv.org//abs/2502.07266)

	Yuyang Wu, Yifei Wang, Tianqi Du, Stefanie Jegelka, Yisen Wang

+ [Aligning Large Language Models to Follow Instructions and Hallucinate Less via Effective Data Filtering](https://arxiv.org//abs/2502.07340)

	Shuzheng Si, Haozhe Zhao, Gang Chen, Cheng Gao, Yuzhuo Bai, Zhitong Wang, Kaikai An, Kangyang Luo, Chen Qian, Fanchao Qi, Baobao Chang, Maosong Sun

+ [HRP: High-Rank Preheating for Superior LoRA Initialization](https://arxiv.org//abs/2502.07739)

	Yuzhu Chen, Yingjie Wang, Shi Fu, Li Shen, Yongcheng Jing, Xinmei Tian, Dacheng Tao

+ [LongReD: Mitigating Short-Text Degradation of Long-Context Large Language Models via Restoration Distillation](https://arxiv.org//abs/2502.07365)

	Zican Dong, Junyi Li, Jinhao Jiang, Mingyu Xu, Wayne Xin Zhao, Bingning Wang, Weipeng Chen

+ [DPO-Shift: Shifting the Distribution of Direct Preference Optimization](https://arxiv.org//abs/2502.07599)

	Xiliang Yang, Feng Jiang, Qianen Zhang, Lei Zhao, Xiao Li

+ [TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation](https://arxiv.org//abs/2502.07306)

	Navid Rajabi, Jana Kosecka

# 2025-02-10
+ [Generating Privacy-Preserving Personalized Advice with Zero-Knowledge Proofs and LLMs](https://arxiv.org//abs/2502.06425)

	Hiroki Watanabe, Motonobu Uchikoshi


+ [Unbiased Evaluation of Large Language Models from a Causal Perspective](https://arxiv.org//abs/2502.06655)

	Meilin Chen, Jian Tian, Liang Ma, Di Xie, Weijie Chen, Jiang Zhu

+ [Is LLM an Overconfident Judge? Unveiling the Capabilities of LLMs in Detecting Offensive Language with Annotation Disagreement](https://arxiv.org//abs/2502.06207)

	Junyu Lu, Kai Ma, Kaichun Wang, Kelaiti Xiao, Roy Ka-Wei Lee, Bo Xu, Liang Yang, Hongfei Lin

+ [Who Taught You That? Tracing Teachers in Model Distillation](https://arxiv.org//abs/2502.06659)

	Somin Wadhwa, Chantal Shaib, Silvio Amir, Byron C. Wallace

+ [Online Scheduling for LLM Inference with KV Cache Constraints](https://arxiv.org//abs/2502.07115)

	Patrick Jaillet, Jiashuo Jiang, Konstantina Mellou, Marco Molinaro, Chara Podimata, Zijie Zhou

+ [C-3PO: Compact Plug-and-Play Proxy Optimization to Achieve Human-like Retrieval-Augmented Generation](https://arxiv.org//abs/2502.06205)

	Guoxin Chen, Minpeng Liao, Peiying Yu, Dingmin Wang, Zile Qiao, Chao Yang, Xin Zhao, Kai Fan

+ [InSTA: Towards Internet-Scale Training For Agents](https://arxiv.org//abs/2502.06776)

	Brandon Trabucco, Gunnar Sigurdsson, Robinson Piramuthu, Ruslan Salakhutdinov

+ [Is a Peeled Apple Still Red? Evaluating LLMs' Ability for Conceptual Combination with Property Type](https://arxiv.org//abs/2502.06086)

	Seokwon Song, Taehyun Lee, Jaewoo Ahn, Jae Hyuk Sung, Gunhee Kim

+ [LCIRC: A Recurrent Compression Approach for Efficient Long-form Context and Query Dependent Modeling in LLMs](https://arxiv.org//abs/2502.06139)

	Sumin An, Junyoung Sung, Wonpyo Park, Chanjun Park, Paul Hongsuck Seo

+ [Towards Copyright Protection for Knowledge Bases of Retrieval-augmented Language Models via Reasoning](https://arxiv.org//abs/2502.10440)

	Junfeng Guo, Yiming Li, Ruibo Chen, Yihan Wu, Chenxi Liu, Yanshuo Chen, Heng Huang

+ [Generating Samples to Question Trained Models](https://arxiv.org//abs/2502.06658)

	Eren Mehmet Kıral, Nurşen Aydın, Ş. İlker Birbil

+ [RoToR: Towards More Reliable Responses for Order-Invariant Inputs](https://arxiv.org//abs/2502.08662)

	Soyoung Yoon, Dongha Ahn, Youngwon Lee, Minkyu Jung, HyungJoo Jang, Seung-won Hwang

+ [Non-literal Understanding of Number Words by Language Models](https://arxiv.org//abs/2502.06204)

	Polina Tsvilodub, Kanishk Gandhi, Haoran Zhao, Jan-Philipp Fränken, Michael Franke, Noah D. Goodman

+ [Position: It's Time to Act on the Risk of Efficient Personalized Text Generation](https://arxiv.org//abs/2502.06560)

	Eugenia Iofinova, Andrej Jovanovic, Dan Alistarh

+ [Emergent Response Planning in LLMs](https://arxiv.org//abs/2502.06258)

	Zhichen Dong, Zhanhui Zhou, Zhixuan Liu, Chao Yang, Chaochao Lu

# 2025-02-09
+ [HSI: Head-Specific Intervention Can Induce Misaligned AI Coordination in Large Language Models](https://arxiv.org//abs/2502.05945)

	Paul Darm, Annalisa Riccardi

+ [Provably Overwhelming Transformer Models with Designed Inputs](https://arxiv.org//abs/2502.06038)

	Lev Stambler, Seyed Sajjad Nezhadi, Matthew Coudron

+ [$μ$nit Scaling: Simple and Scalable FP8 LLM Training](https://arxiv.org//abs/2502.05967)

	Saaketh Narayan, Abhay Gupta, Mansheej Paul, Davis Blalock

# 2025-02-08
+ [Agentic AI Systems Applied to tasks in Financial Services: Modeling and model risk management crews](https://arxiv.org//abs/2502.05439)

	Izunna Okpala, Ashkan Golgoon, Arjun Ravi Kannan

+ [The Odyssey of the Fittest: Can Agents Survive and Still Be Good?](https://arxiv.org//abs/2502.05442)

	Dylan Waldner, Risto Miikkulainen

+ [Mix Data or Merge Models? Balancing the Helpfulness, Honesty, and Harmlessness of Large Language Model via Model Merging](https://arxiv.org//abs/2502.06876)

	Jinluan Yang, Dingnan Jin, Anke Tang, Li Shen, Didi Zhu, Zhengyu Chen, Ziyu Zhao, Daixin Wang, Qing Cui, Zhiqiang Zhang, Jun Zhou, Fei Wu, Kun Kuang

+ [Evolving LLMs' Self-Refinement Capability via Iterative Preference Optimization](https://arxiv.org//abs/2502.05605)

	Yongcheng Zeng, Xinyu Cui, Xuanfa Jin, Guoqing Liu, Zexu Sun, Dong Li, Ning Yang, Jianye Hao, Haifeng Zhang, Jun Wang

+ [Flowing Through Layers: A Continuous Dynamical Systems Perspective on Transformers](https://arxiv.org//abs/2502.05656)

	Jacob Fein-Ashley

+ [Iterative Deepening Sampling as Efficient Test-Time Scaling](https://arxiv.org//abs/2502.05449)

	Weizhe Chen, Sven Koenig, Bistra Dilkina

+ [FRAME: Boosting LLMs with A Four-Quadrant Multi-Stage Pretraining Strategy](https://arxiv.org//abs/2502.05551)

	Xuemiao Zhang, Feiyu Duan, Liangyu Xu, Yongwei Zhou, Sirui Wang, Rongxiang Weng, Jingang Wang, Xunliang Cai

+ [The Complexity of Learning Sparse Superposed Features with Feedback](https://arxiv.org//abs/2502.05407)

	Akash Kumar

# 2025-02-07
+ [Probabilistic Subspace Manifolds for Contextual Inference in Large Language Models](https://arxiv.org//abs/2502.05346)

	Christopher Nightingale, Dominic Lavington, Jonathan Thistlethwaite, Sebastian Penhaligon, Thomas Belinski, David Boldo

+ [MELON: Provable Indirect Prompt Injection Defense via Masked Re-execution and Tool Comparison](https://arxiv.org//abs/2502.05174)

	Kaijie Zhu, Xianjun Yang, Jindong Wang, Wenbo Guo, William Yang Wang

+ [Unveiling the Mechanisms of Explicit CoT Training: How CoT Enhances Reasoning Generalization](https://arxiv.org//abs/2502.04667)

	Xinhao Yao, Ruifeng Ren, Yun Liao, Yong Liu

+ [Generating Symbolic World Models via Test-time Scaling of Large Language Models](https://arxiv.org//abs/2502.04728)

	Zhouliang Yu, Yuhuan Yuan, Tim Z. Xiao, Fuxiang Frank Xia, Jie Fu, Ge Zhang, Ge Lin, Weiyang Liu

+ [ARR: Question Answering with Large Language Models via Analyzing, Retrieving, and Reasoning](https://arxiv.org//abs/2502.04689)

	Yuwei Yin, Giuseppe Carenini

+ [Uncertainty Quantification for LLMs through Minimum Bayes Risk: Bridging Confidence and Consistency](https://arxiv.org//abs/2502.04964)

	Roman Vashurin, Maiya Goloburda, Albina Ilina, Alexander Rubashevskii, Preslav Nakov, Artem Shelmanov, Maxim Panov

+ [Beyond External Monitors: Enhancing Transparency of Large Language Models for Easier Monitoring](https://arxiv.org//abs/2502.05242)

	Guanxu Chen, Dongrui Liu, Tao Luo, Lijie Hu, Jing Shao

+ [Scalable Oversight for Superhuman AI via Recursive Self-Critiquing](https://arxiv.org//abs/2502.04675)

	Xueru Wen, Jie Lou, Xinyu Lu, Junjie Yang, Yanjiang Liu, Yaojie Lu, Debing Zhang, Xing Yu

+ [Developmentally-plausible Working Memory Shapes a Critical Period for Language Acquisition](https://arxiv.org//abs/2502.04795)

	Masato Mita, Ryo Yoshida, Yohei Oseki

+ [QuEST: Stable Training of LLMs with 1-Bit Weights and Activations](https://arxiv.org//abs/2502.05003)

	Andrei Panferov, Jiale Chen, Soroush Tabesh, Roberto L. Castro, Mahdi Nikdan, Dan Alistarh

+ [Unsafe LLM-Based Search: Quantitative Analysis and Mitigation of Safety Risks in AI Web Search](https://arxiv.org//abs/2502.04951)

	Zeren Luo, Zifan Peng, Yule Liu, Zhen Sun, Mingchen Li, Jingyi Zheng, Xinlei He

+ [Optimizing Temperature for Language Models with Multi-Sample Inference](https://arxiv.org//abs/2502.05234)

	Weihua Du, Yiming Yang, Sean Welleck

# 2025-02-06
+ [The Order Effect: Investigating Prompt Sensitivity to Input Order in LLMs](https://arxiv.org//abs/2502.04134)

	Bryan Guan, Tanya Roosta, Peyman Passban, Mehdi Rezagholizadeh

+ [SMI: An Information-Theoretic Metric for Predicting Model Knowledge Solely from Pre-Training Signals](https://arxiv.org//abs/2502.04066)

	Changhao Jiang, Ming Zhang, Junjie Ye, Xiaoran Fan, Yifei Cao, Jiajun Sun, Zhiheng Xi, Shihan Dou, Yi Dong, Yujiong Shen, Jingqi Tong, Zhen Wang, Tao Liang, Zhihui Fei, Mingyang Wan, Guojun Ma, Qi Zhang, Tao Gui, Xuanjing Huang

+ [FAS: Fast ANN-SNN Conversion for Spiking Large Language Models](https://arxiv.org//abs/2502.04405)

	Long Chen, Xiaotian Song, Andy Song, BaDong Chen, Jiancheng Lv, Yanan Sun

+ [Reformulation for Pretraining Data Augmentation](https://arxiv.org//abs/2502.04235)

	Xintong Hao, Ruijie Zhu, Ge Zhang, Ke Shen, Chenggang Li

+ [Training Language Models to Reason Efficiently](https://arxiv.org//abs/2502.04463)

	Daman Arora, Andrea Zanette

+ [Beyond Prompt Content: Enhancing LLM Performance via Content-Format Integrated Prompt Optimization](https://arxiv.org//abs/2502.04295)

	Yuanye Liu, Jiahang Xu, Li Lyna Zhang, Qi Chen, Xuan Feng, Yang Chen, Zhongxin Guo, Yuqing Yang, Peng Cheng

+ [CMoE: Converting Mixture-of-Experts from Dense to Accelerate LLM Inference](https://arxiv.org//abs/2502.04416)

	Zehua Pei, Lancheng Zou, Hui-Ling Zhen, Xianzhi Yu, Wulong Liu, Sinno Jialin Pan, Mingxuan Yuan, Bei Yu

+ [Group-Adaptive Threshold Optimization for Robust AI-Generated Text Detection](https://arxiv.org//abs/2502.04528)

	Minseok Jung, Cynthia Fuertes Panizo, Liam Dugan, Yi R. (May)Fung, Pin-Yu Chen, Paul Pu Liang

+ [Toward universal steering and monitoring of AI models](https://arxiv.org//abs/2502.03708)

	Daniel Beaglehole, Adityanarayanan Radhakrishnan, Enric Boix-Adserà, Mikhail Belkin

+ [Safety Reasoning with Guidelines](https://arxiv.org//abs/2502.04040)

	Haoyu Wang, Zeyu Qin, Li Shen, Xueqian Wang, Dacheng Tao, Minhao Cheng

+ [Exploring Imbalanced Annotations for Effective In-Context Learning](https://arxiv.org//abs/2502.04037)

	Hongfu Gao, Feipeng Zhang, Hao Zeng, Deyu Meng, Bingyi Jing, Hongxin Wei

+ [KVTuner: Sensitivity-Aware Layer-Wise Mixed-Precision KV Cache Quantization for Efficient and Nearly Lossless LLM Inference](https://arxiv.org//abs/2502.04420)

	Xing Li, Zeyu Xing, Yiming Li, Linping Qu, Hui-Ling Zhen, Wulong Liu, Yiwu Yao, Sinno Jialin Pan, Mingxuan Yuan

+ [LLM Alignment as Retriever Optimization: An Information Retrieval Perspective](https://arxiv.org//abs/2502.03699)

	Bowen Jin, Jinsung Yoon, Zhen Qin, Ziqi Wang, Wei Xiong, Yu Meng, Jiawei Han, Sercan O. Arik

+ [Great Models Think Alike and this Undermines AI Oversight](https://arxiv.org//abs/2502.04313)

	Shashwat Goel, Joschka Struber, Ilze Amanda Auzina, Karuna K Chandra, Ponnurangam Kumaraguru, Douwe Kiela, Ameya Prabhu, Matthias Bethge, Jonas Geiping

+ [Speeding up Speculative Decoding via Sequential Approximate Verification](https://arxiv.org//abs/2502.04557)

	Meiyu Zhong, Noel Teku, Ravi Tandon

# 2025-02-05
+ [Leveraging the true depth of LLMs](https://arxiv.org//abs/2502.02790)

	Ramón Calvo González, Daniele Paliotta, Matteo Pagliardini, Martin Jaggi, François Fleuret

+ [Large Language Model as Universal Retriever in Industrial-Scale Recommender System](https://arxiv.org//abs/2502.03041)

	Junguang Jiang, Yanwen Huang, Bin Liu, Xiaoyu Kong, Xinhang Li, Ziru Xu, Han Zhu, Jian Xu, Bo Zheng

+ [Speculative Prefill: Turbocharging TTFT with Lightweight and Training-Free Token Importance Estimation](https://arxiv.org//abs/2502.02789)

	Jingyu Liu, Beidi Chen, Ce Zhang

+ [CARROT: A Cost Aware Rate Optimal Router](https://arxiv.org//abs/2502.03261)

	Seamus Somerstep, Felipe Maia Polo, Allysson Flavio Melo de Oliveira, Prattyush Mangal, Mírian Silva, Onkar Bhardwaj, Mikhail Yurochkin, Subha Maity

+ [An Analysis for Reasoning Bias of Language Models with Small Initialization](https://arxiv.org//abs/2502.04375)

	Junjie Yao, Zhongwang Zhang, Zhi-Qin John Xu

+ [Diversity as a Reward: Fine-Tuning LLMs on a Mixture of Domain-Undetermined Data](https://arxiv.org//abs/2502.04380)

	Zhenqing Ling, Daoyuan Chen, Liuyi Yao, Qianli Shen, Yaliang Li, Ying Shen

+ [Advancing Reasoning in Large Language Models: Promising Methods and Approaches](https://arxiv.org//abs/2502.03671)

	Avinash Patil, Aryan Jadon

+ [SPRI: Aligning Large Language Models with Context-Situated Principles](https://arxiv.org//abs/2502.03397)

	Hongli Zhan, Muneeza Azmat, Raya Horesh, Junyi Jessy Li, Mikhail Yurochkin

+ [Analyzing limits for in-context learning](https://arxiv.org//abs/2502.03503)

	Omar Naim, Nicholas Asher

+ [Reflection-Window Decoding: Text Generation with Selective Refinement](https://arxiv.org//abs/2502.03678)

	Zeyu Tang, Zhenhao Chen, Xiangchen Song, Loka Li, Yunlong Deng, Yifan Shen, Guangyi Chen, Peter Spirtes, Kun Zhang

+ [In Praise of Stubbornness: An Empirical Case for Cognitive-Dissonance Aware Continual Update of Knowledge in LLMs](https://arxiv.org//abs/2502.04390)

	Simone Clemente, Zied Ben Houidi, Alexis Huet, Dario Rossi, Giulio Franzese, Pietro Michiardi

+ [Upweighting Easy Samples in Fine-Tuning Mitigates Forgetting](https://arxiv.org//abs/2502.02797)

	Sunny Sanyal, Hayden Prairie, Rudrajit Das, Ali Kavis, Sujay Sanghavi

+ [Adapt-Pruner: Adaptive Structural Pruning for Efficient Small Language Model Training](https://arxiv.org//abs/2502.03460)

	Rui Pan, Boyao Wang, Shizhe Diao, Xingyuan Pan, Jipeng Zhang, Renjie Pi, Tong Zhang

+ [Scaling Laws for Upcycling Mixture-of-Experts Language Models](https://arxiv.org//abs/2502.03009)

	Seng Pei Liew, Takuya Kato, Sho Takase

# 2025-02-04
+ [CITER: Collaborative Inference for Efficient Large Language Model Decoding with Token-Level Routing](https://arxiv.org//abs/2502.01976)

	Wenhao Zheng, Yixiao Chen, Weitong Zhang, Souvik Kundu, Yun Li, Zhengzhong Liu, Eric P. Xing, Hongyi Wang, Huaxiu Yao

+ [Shuttle Between the Instructions and the Parameters of Large Language Models](https://arxiv.org//abs/2502.02315)

	Wangtao Sun, Haotian Xu, Huanxuan Liao, Xuanqing Yu, Zhongtao Jiang, Shizhu He, Jun Zhao, Kang Liu

+ [Generative Psycho-Lexical Approach for Constructing Value Systems in Large Language Models](https://arxiv.org//abs/2502.02444)

	Haoran Ye, Tianze Zhang, Yuhang Xie, Liyuan Zhang, Yuanyi Ren, Xin Zhang, Guojie Song

+ [From Words to Collisions: LLM-Guided Evaluation and Adversarial Generation of Safety-Critical Driving Scenarios](https://arxiv.org//abs/2502.02145)

	Yuan Gao, Mattia Piccinini, Korbinian Moller, Johannes Betz

+ [LongDPO: Unlock Better Long-form Generation Abilities for LLMs via Critique-augmented Stepwise Information](https://arxiv.org//abs/2502.02095)

	Bowen Ping, Jiali Zeng, Fandong Meng, Shuo Wang, Jie Zhou, Shanghang Zhang

+ [Premise-Augmented Reasoning Chains Improve Error Identification in Math reasoning with LLMs](https://arxiv.org//abs/2502.02362)

	Sagnik Mukherjee, Abhinav Chinta, Takyoung Kim, Tarun Anoop Sharma, Dilek Hakkani-Tür

+ [Can LLMs Maintain Fundamental Abilities under KV Cache Compression?](https://arxiv.org//abs/2502.01941)

	Xiang Liu, Zhenheng Tang, Hong Chen, Peijie Dong, Zeyu Li, Xiuze Zhou, Bo Li, Xuming Hu, Xiaowen Chu

+ [Neurons Speak in Ranges: Breaking Free from Discrete Neuronal Attribution](https://arxiv.org//abs/2502.06809)

	Muhammad Umair Haider, Hammad Rizwan, Hassan Sajjad, Peizhong Ju, A.B. Siddique

+ [Fairness through Difference Awareness: Measuring Desired Group Discrimination in LLMs](https://arxiv.org//abs/2502.01926)

	Angelina Wang, Michelle Phan, Daniel E. Ho, Sanmi Koyejo

+ [JingFang: An Expert-Level Large Language Model for Traditional Chinese Medicine Clinical Consultation and Syndrome Differentiation-Based Treatment](https://arxiv.org//abs/2502.04345)

	Yehan Yang, Tianhao Ma, Ruotai Li, Xinhan Zheng, Guodong Shan, Chisheng Li

+ [Robust LLM Alignment via Distributionally Robust Direct Preference Optimization](https://arxiv.org//abs/2502.01930)

	Zaiyan Xu, Sushil Vemuri, Kishan Panaganti, Dileep Kalathil, Rahul Jain, Deepak Ramachandran

+ [LV-XAttn: Distributed Cross-Attention for Long Visual Inputs in Multimodal Large Language Models](https://arxiv.org//abs/2502.02406)

	Tzu-Tao Chang, Shivaram Venkataraman

+ [MedRAX: Medical Reasoning Agent for Chest X-ray](https://arxiv.org//abs/2502.02673)

	Adibvafa Fallahpour, Jun Ma, Alif Munim, Hongwei Lyu, Bo Wang

+ [CodeSteer: Symbolic-Augmented Language Models via Code/Text Guidance](https://arxiv.org//abs/2502.04350)

	Yongchao Chen, Yilun Hao, Yueying Liu, Yang Zhang, Chuchu Fan

+ [Position: Scaling LLM Agents Requires Asymptotic Analysis with LLM Primitives](https://arxiv.org//abs/2502.04358)

	Elliot Meyerson, Xin Qiu

+ [A Training-Free Length Extrapolation Approach for LLMs: Greedy Attention Logit Interpolation (GALI)](https://arxiv.org//abs/2502.02659)

	Yan Li, Tianyi Zhang, Zechuan Li, Soyeon Caren Han

+ [Boosting Multimodal Reasoning with Automated Structured Thinking](https://arxiv.org//abs/2502.02339)

	Jinyang Wu, Mingkuan Feng, Shuai Zhang, Fangrui Lv, Ruihan Jin, Feihu Che, Zengqi Wen, Jianhua Tao

+ [Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search](https://arxiv.org//abs/2502.02508)

	Maohao Shen, Guangtao Zeng, Zhenting Qi, Zhang-Wei Hong, Zhenfang Chen, Wei Lu, Gregory Wornell, Subhro Das, David Cox, Chuang Gan

+ [On the Emergence of Position Bias in Transformers](https://arxiv.org//abs/2502.01951)

	Xinyi Wu, Yifei Wang, Stefanie Jegelka, Ali Jadbabaie

+ [Spatial-RAG: Spatial Retrieval Augmented Generation for Real-World Spatial Reasoning Questions](https://arxiv.org//abs/2502.18470)

	Dazhou Yu, Riyang Bao, Ruiyu Ning, Jinghong Peng, Gengchen Mai, Liang Zhao

+ [PatchPilot: A Cost-Efficient Software Engineering Agent with Early Attempts on Formal Verification](https://arxiv.org//abs/2502.02747)

	Hongwei Li, Yuheng Tang, Shiqi Wang, Wenbo Guo

+ [Prompt-based Depth Pruning of Large Language Models](https://arxiv.org//abs/2502.04348)

	Juyun Wee, Minjae Park, Jaeho Lee

+ [Layer by Layer: Uncovering Hidden Representations in Language Models](https://arxiv.org//abs/2502.02013)

	Oscar Skean, Md Rifat Arefin, Dan Zhao, Niket Patel, Jalal Naghiyev, Yann LeCun, Ravid Shwartz-Ziv

+ [Activation-Informed Merging of Large Language Models](https://arxiv.org//abs/2502.02421)

	Amin Heyrani Nobari, Kaveh Alimohammadi, Ali ArjomandBigdeli, Akash Srivastava, Faez Ahmed, Navid Azizan

# 2025-02-03
+ [Efficient Model Editing with Task Vector Bases: A Theoretical Framework and Scalable Approach](https://arxiv.org//abs/2502.01015)

	Siqi Zeng, Yifei He, Weiqiu You, Yifan Hao, Yao-Hung Hubert Tsai, Makoto Yamada, Han Zhao


+ [Factual Knowledge in Language Models: Robustness and Anomalies under Simple Temporal Context Variations](https://arxiv.org//abs/2502.01220)

	Hichem Ammar Khodja, Frédéric Béchet, Quentin Brabant, Alexis Nasr, Gwénolé Lecorvé

+ [Efficient Model Editing with Task Vector Bases: A Theoretical Framework and Scalable Approach](https://arxiv.org//abs/2502.01015)

	Siqi Zeng, Yifei He, Weiqiu You, Yifan Hao, Yao-Hung Hubert Tsai, Makoto Yamada, Han Zhao

+ [Massive Values in Self-Attention Modules are the Key to Contextual Knowledge Understanding](https://arxiv.org//abs/2502.01563)

	Mingyu Jin, Kai Mei, Wujiang Xu, Mingjie Sun, Ruixiang Tang, Mengnan Du, Zirui Liu, Yongfeng Zhang

+ [SE Arena: An Interactive Platform for Evaluating Foundation Models in Software Engineering](https://arxiv.org//abs/2502.01860)

	Zhimin Zhao

+ [Firewalls to Secure Dynamic LLM Agentic Networks](https://arxiv.org//abs/2502.01822)

	Sahar Abdelnabi, Amr Gomaa, Per Ola Kristensson, Reza Shokri

+ [Joint Localization and Activation Editing for Low-Resource Fine-Tuning](https://arxiv.org//abs/2502.01179)

	Wen Lai, Alexander Fraser, Ivan Titov

+ [Scaling Embedding Layers in Language Models](https://arxiv.org//abs/2502.01637)

	Da Yu, Edith Cohen, Badih Ghazi, Yangsibo Huang, Pritish Kamath, Ravi Kumar, Daogao Liu, Chiyuan Zhang

+ [Explaining Context Length Scaling and Bounds for Language Models](https://arxiv.org//abs/2502.01481)

	Jingzhe Shi, Qinwei Ma, Hongyi Liu, Hang Zhao, Jeng-Neng Hwang, Lei Li

+ [The Differences Between Direct Alignment Algorithms are a Blur](https://arxiv.org//abs/2502.01237)

	Alexey Gorbatovski, Boris Shaposhnikov, Viacheslav Sinii, Alexey Malakhov, Daniil Gavrilov

+ [The Jumping Reasoning Curve? Tracking the Evolution of Reasoning Performance in GPT-[n] and o-[n] Models on Multimodal Puzzles](https://arxiv.org//abs/2502.01081)

	Vernon Y.H. Toh, Yew Ken Chia, Deepanway Ghosal, Soujanya Poria

+ [Lifelong Knowledge Editing requires Better Regularization](https://arxiv.org//abs/2502.01636)

	Akshat Gupta, Phudish Prateepamornkul, Maochuan Lu, Ahmed Alaa, Thomas Hartvigsen, Gopala Anumanchipalli

+ [BARE: Leveraging Base Language Models for Few-Shot Synthetic Data Generation](https://arxiv.org//abs/2502.01697)

	Alan Zhu, Parth Asawa, Jared Quincy Davis, Lingjiao Chen, Boris Hanin, Ion Stoica, Joseph E. Gonzalez, Matei Zaharia

+ [FastKV: KV Cache Compression for Fast Long-Context Processing with Token-Selective Propagation](https://arxiv.org//abs/2502.01068)

	Dongwon Jo, Jiwon Song, Yulhwa Kim, Jae-Joon Kim

+ [GRADIEND: Monosemantic Feature Learning within Neural Networks Applied to Gender Debiasing of Transformer Models](https://arxiv.org//abs/2502.01406)

	Jonathan Drechsel, Steffen Herbold

+ [Preference Leakage: A Contamination Problem in LLM-as-a-judge](https://arxiv.org//abs/2502.01534)

	Dawei Li, Renliang Sun, Yue Huang, Ming Zhong, Bohan Jiang, Jiawei Han, Xiangliang Zhang, Wei Wang, Huan Liu

+ [ACECODER: Acing Coder RL via Automated Test-Case Synthesis](https://arxiv.org//abs/2502.01718)

	Huaye Zeng, Dongfu Jiang, Haozhe Wang, Ping Nie, Xiaotong Chen, Wenhu Chen

+ [LoRA-One: One-Step Full Gradient Could Suffice for Fine-Tuning Large Language Models, Provably and Efficiently](https://arxiv.org//abs/2502.01235)

	Yuanhe Zhang, Fanghui Liu, Yudong Chen

+ [Memento No More: Coaching AI Agents to Master Multiple Tasks via Hints Internalization](https://arxiv.org//abs/2502.01562)

	Minttu Alakuijala, Ya Gao, Georgy Ananov, Samuel Kaski, Pekka Marttinen, Alexander Ilin, Harri Valpola

+ [Bias Beware: The Impact of Cognitive Biases on LLM-Driven Product Recommendations](https://arxiv.org//abs/2502.01349)

	Giorgos Filandrianos, Angeliki Dimitriou, Maria Lymperaiou, Konstantinos Thomas, Giorgos Stamou

+ [Rollout Roulette: A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods](https://arxiv.org//abs/2502.01618)

	Isha Puri, Shivchander Sudalairaj, Guangxuan Xu, Kai Xu, Akash Srivastava

# 2025-02-02
+ [Vision-centric Token Compression in Large Language Model](https://arxiv.org//abs/2502.00791)

	Ling Xing, Alex Jinpeng Wang, Rui Yan, Xiangbo Shu, Jinhui Tang

+ [Disentangling Length Bias In Preference Learning Via Response-Conditioned Modeling](https://arxiv.org//abs/2502.00814)

	Jianfeng Cai, Jinhua Zhu, Ruopei Sun, Yue Wang, Li Li, Wengang Zhou, Houqiang Li

+ [When Do LLMs Help With Node Classification? A Comprehensive Analysis](https://arxiv.org//abs/2502.00829)

	Xixi Wu, Yifei Shen, Fangzhou Ge, Caihua Shan, Yizhu Jiao, Xiangguo Sun, Hong Cheng

+ [How Contaminated Is Your Benchmark? Quantifying Dataset Leakage in Large Language Models with Kernel Divergence](https://arxiv.org//abs/2502.00678)

	Hyeong Kyu Choi, Maxim Khanov, Hongxin Wei, Yixuan Li

+ [To Code or not to Code? Adaptive Tool Integration for Math Language Models via Expectation-Maximization](https://arxiv.org//abs/2502.00691)

	Haozhe Wang, Long Li, Chao Qu, Fengming Zhu, Weidi Xu, Wei Chu, Fangzhen Lin

+ [ReFoRCE: A Text-to-SQL Agent with Self-Refinement, Consensus Enforcement, and Column Exploration](https://arxiv.org//abs/2502.00675)

	Minghang Deng, Ashwin Ramachandran, Canwen Xu, Lanxiang Hu, Zhewei Yao, Anupam Datta, Hao Zhang

+ [FIRE: Flexible Integration of Data Quality Ratings for Effective Pre-Training](https://arxiv.org//abs/2502.00761)

	Liangyu Xu, Xuemiao Zhang, Feiyu Duan, Sirui Wang, Rongxiang Weng, Jingang Wang, Xunliang Cai

+ [Mitigating Heterogeneous Token Overfitting in LLM Knowledge Editing](https://arxiv.org//abs/2502.00602)

	Tianci Liu, Ruirui Li, Zihan Dong, Hui Liu, Xianfeng Tang, Qingyu Yin, Linjun Zhang, Haoyu Wang, Jing Gao

+ [LLM Safety Alignment is Divergence Estimation in Disguise](https://arxiv.org//abs/2502.00657)

	Rajdeep Haldar, Ziyi Wang, Qifan Song, Guang Lin, Yue Xing

+ [Explainability in Practice: A Survey of Explainable NLP Across Various Domains](https://arxiv.org//abs/2502.00837)

	Hadi Mohammadi, Ayoub Bagheri, Anastasia Giachanou, Daniel L. Oberski

+ [Blink of an eye: a simple theory for feature localization in generative models](https://arxiv.org//abs/2502.00921)

	Marvin Li, Aayush Karan, Sitan Chen

+ [Activation Approximations Can Incur Safety Vulnerabilities Even in Aligned LLMs: Comprehensive Analysis and Defense](https://arxiv.org//abs/2502.00840)

	Jiawen Zhang, Kejia Chen, Lipeng He, Jian Lou, Dan Li, Zunlei Feng, Mingli Song, Jian Liu, Kui Ren, Xiaohu Yang

+ [CollabLLM: From Passive Responders to Active Collaborators](https://arxiv.org//abs/2502.00640)

	Shirley Wu, Michel Galley, Baolin Peng, Hao Cheng, Gavin Li, Yao Dou, Weixin Cai, James Zou, Jure Leskovec, Jianfeng Gao

# 2025-02-01
+ [Explorations of the Softmax Space: Knowing When the Neural Network Doesn't Know](https://arxiv.org//abs/2502.00456)

	Daniel Sikar, Artur d'Avila Garcez, Tillman Weyde

+ [Estimating LLM Uncertainty with Logits](https://arxiv.org//abs/2502.00290)

	Huan Ma, Jingdong Chen, Joey Tianyi Zhou, Guangyu Wang, Changqing Zhang

+ [DUET: Optimizing Training Data Mixtures via Feedback from Unseen Evaluation Tasks](https://arxiv.org//abs/2502.00270)

	Zhiliang Chen, Gregory Kang Ruey Lau, Chuan-Sheng Foo, Bryan Kian Hsiang Low

+ [ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference](https://arxiv.org//abs/2502.00299)

	Xiang Liu, Zhenheng Tang, Peijie Dong, Zeyu Li, Yue Liu, Bo Li, Xuming Hu, Xiaowen Chu

+ [Understanding Multimodal LLMs Under Distribution Shifts: An Information-Theoretic Approach](https://arxiv.org//abs/2502.00577)

	Changdae Oh, Zhen Fang, Shawn Im, Xuefeng Du, Yixuan Li

+ [A statistically consistent measure of semantic uncertainty using Language Models](https://arxiv.org//abs/2502.00507)

	Yi Liu

+ [Fast Large Language Model Collaborative Decoding via Speculation](https://arxiv.org//abs/2502.01662)

	Jiale Fu, Yuchu Jiang, Junkai Chen, Jiaming Fan, Xin Geng, Xu Yang

+ [M+: Extending MemoryLLM with Scalable Long-Term Memory](https://arxiv.org//abs/2502.00592)

	Yu Wang, Dmitry Krotov, Yuanzhe Hu, Yifan Gao, Wangchunshu Zhou, Julian McAuley, Dan Gutfreund, Rogerio Feris, Zexue He

# 2025-01-31
+ [Deep Learning Model Inversion Attacks and Defenses: A Comprehensive Survey](https://arxiv.org//abs/2501.18934)

	Wencheng Yang, Song Wang, Di Wu, Taotao Cai, Yanming Zhu, Shicheng Wei, Yiying Zhang, Xu Yang, Zhaohui Tang, Yan Li

+ [Towards the Worst-case Robustness of Large Language Models](https://arxiv.org//abs/2501.19040)

	Huanran Chen, Yinpeng Dong, Zeming Wei, Hang Su, Jun Zhu

+ [Federated Sketching LoRA: On-Device Collaborative Fine-Tuning of Large Language Models](https://arxiv.org//abs/2501.19389)

	Wenzhi Fang, Dong-Jun Han, Liangqi Yuan, Seyyedali Hosseinalipour, Christopher G. Brinton

+ [Improving LLM Unlearning Robustness via Random Perturbations](https://arxiv.org//abs/2501.19202)

	Dang Huu-Tien, Hoang Thanh-Tung, Anh Bui, Le-Minh Nguyen, Naoya Inoue

+ [Fairshare Data Pricing via Data Valuation for Large Language Models](https://arxiv.org//abs/2502.00198)

	Luyang Zhang, Cathy Jiao, Beibei Li, Chenyan Xiong

+ [SETS: Leveraging Self-Verification and Self-Correction for Improved Test-Time Scaling](https://arxiv.org//abs/2501.19306)

	Jiefeng Chen, Jie Ren, Xinyun Chen, Chengrun Yang, Ruoxi Sun, Jinsung Yoon, Sercan Ö Arık

+ [A Checks-and-Balances Framework for Context-Aware Ethical AI Alignment](https://arxiv.org//abs/2502.00136)

	Edward Y. Chang

+ [Improving Rule-based Reasoning in LLMs via Neurosymbolic Representations](https://arxiv.org//abs/2502.01657)

	Varun Dhanraj, Chris Eliasmith

+ [Token Sampling Uncertainty Does Not Explain Homogeneity Bias in Large Language Models](https://arxiv.org//abs/2501.19337)

	Messi H.J. Lee, Soyeon Jeon

+ [Norm-Bounded Low-Rank Adaptation](https://arxiv.org//abs/2501.19050)

	Ruigang Wang, Krishnamurthy Dvijotham, Ian R. Manchester

+ [KBQA-o1: Agentic Knowledge Base Question Answering with Monte Carlo Tree Search](https://arxiv.org//abs/2501.18922)

	Haoran Luo, Haihong E, Yikai Guo, Qika Lin, Xiaobao Wu, Xinyu Mu, Wenhao Liu, Meina Song, Yifan Zhu, Luu Anh Tuan

+ [MINDSTORES: Memory-Informed Neural Decision Synthesis for Task-Oriented Reinforcement in Embodied Systems](https://arxiv.org//abs/2501.19318)

	Anirudh Chari, Suraj Reddy, Aditya Tiwari, Richard Lian, Brian Zhou

+ [Towards Unified Attribution in Explainable AI, Data-Centric AI, and Mechanistic Interpretability](https://arxiv.org//abs/2501.18887)

	Shichang Zhang, Tessa Han, Usha Bhalla, Himabindu Lakkaraju

+ [RedundancyLens: Revealing and Exploiting Visual Token Processing Redundancy for Efficient Decoder-Only MLLMs](https://arxiv.org//abs/2501.19036)

	Hongliang Li, Jiaxin Zhang, Wenhui Liao, Dezhi Peng, Kai Ding, Lianwen Jin

+ [Accelerating LLM Inference with Lossless Speculative Decoding Algorithms for Heterogeneous Vocabularies](https://arxiv.org//abs/2502.05202)

	Nadav Timor, Jonathan Mamou, Daniel Korat, Moshe Berchansky, Gaurav Jain, Oren Pereg, Moshe Wasserblat, David Harel

+ [Pivoting Factorization: A Compact Meta Low-Rank Representation of Sparsity for Efficient Inference in Large Language Models](https://arxiv.org//abs/2501.19090)

	Jialin Zhao, Yingtao Zhang, Carlo Vittorio Cannistraci

# 2025-01-30
+ [Efficiency and Effectiveness of LLM-Based Summarization of Evidence in Crowdsourced Fact-Checking](https://arxiv.org//abs/2501.18265)

	Kevin Roitero, Dustin Wright, Michael Soprano, Isabelle Augenstein, Stefano Mizzaro

+ [On the Role of Transformer Feed-Forward Layers in Nonlinear In-Context Learning](https://arxiv.org//abs/2501.18187)

	Haoyuan Sun, Ali Jadbabaie, Navid Azizan

+ [Diverse Preference Optimization](https://arxiv.org//abs/2501.18101)

	Jack Lanchantin, Angelica Chen, Shehzaad Dhuliawala, Ping Yu, Jason Weston, Sainbayar Sukhbaatar, Ilia Kulikov

+ [WILDCHAT-50M: A Deep Dive Into the Role of Synthetic Data in Post-Training](https://arxiv.org//abs/2501.18511)

	Benjamin Feuer, Chinmay Hegde

# 2025-01-29
+ [Large Language Models Think Too Fast To Explore Effectively](https://arxiv.org//abs/2501.18009)

	Lan Pan, Hanbo Xie, Robert C. Wilson

+ [LEKA:LLM-Enhanced Knowledge Augmentation](https://arxiv.org//abs/2501.17802)

	Xinhao Zhang, Jinghan Zhang, Fengran Mo, Dongjie Wang, Yanjie Fu, Kunpeng Liu

# 2025-01-28
+ [Instantiation-based Formalization of Logical Reasoning Tasks using Language Models and Logical Solvers](https://arxiv.org//abs/2501.16961)

	Mohammad Raza, Natasa Milic-Frayling

+ [RadioLLM: Introducing Large Language Model into Cognitive Radio via Hybrid Prompt and Token Reprogrammings](https://arxiv.org//abs/2501.17888)

	Shuai Chen, Yong Zu, Zhixi Feng, Shuyuan Yang, Mengchang Li

+ [Over-Tokenized Transformer: Vocabulary is Generally Worth Scaling](https://arxiv.org//abs/2501.16975)

	Hongzhi Huang, Defa Zhu, Banggu Wu, Yutao Zeng, Ya Wang, Qiyang Min, Xun Zhou

+ [SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training](https://arxiv.org//abs/2501.17161)

	Tianzhe Chu, Yuexiang Zhai, Jihan Yang, Shengbang Tong, Saining Xie, Dale Schuurmans, Quoc V. Le, Sergey Levine, Yi Ma

+ [Graph of Attacks with Pruning: Optimizing Stealthy Jailbreak Prompt Generation for Enhanced LLM Content Moderation](https://arxiv.org//abs/2501.18638)

	Daniel Schwartz, Dmitriy Bespalov, Zhe Wang, Ninad Kulkarni, Yanjun Qi

# 2025-01-27
+ [Are Transformers Able to Reason by Connecting Separated Knowledge in Training Data?](https://arxiv.org//abs/2501.15857)

	Yutong Yin, Zhaoran Wang


+ [Are Transformers Able to Reason by Connecting Separated Knowledge in Training Data?](https://arxiv.org//abs/2501.15857)

	Yutong Yin, Zhaoran Wang

+ [AdaCoT: Rethinking Cross-Lingual Factual Reasoning through Adaptive Chain-of-Thought](https://arxiv.org//abs/2501.16154)

	Xin Huang, Tarun Kumar Vangani, Zhengyuan Liu, Bowei Zou, Ai Ti Aw

+ [On the Feasibility of Using LLMs to Autonomously Execute Multi-host Network Attacks](https://arxiv.org//abs/2501.16466)

	Brian Singer, Keane Lucas, Lakshmi Adiga, Meghna Jain, Lujo Bauer, Vyas Sekar

+ [Training Dynamics of In-Context Learning in Linear Attention](https://arxiv.org//abs/2501.16265)

	Yedi Zhang, Aaditya K. Singh, Peter E. Latham, Andrew Saxe

+ [FDLLM: A Dedicated Detector for Black-Box LLMs Fingerprinting](https://arxiv.org//abs/2501.16029)

	Zhiyuan Fu, Junfan Chen, Lan Zhang, Ting Yang, Jun Niu, Hongyu Sun, Ruidong Li, Peng Liu, Yuqing Zhang

# 2025-01-26
+ [TensorLLM: Tensorising Multi-Head Attention for Enhanced Reasoning and Compression in LLMs](https://arxiv.org//abs/2501.15674)

	Yuxuan Gu, Wuyang Zhou, Giorgos Iacovides, Danilo Mandic

+ [FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint](https://arxiv.org//abs/2501.15509)

	Shuo Shao, Haozhe Zhu, Hongwei Yao, Yiming Li, Tianwei Zhang, Zhan Qin, Kui Ren

# 2025-01-25
+ [Option-ID Based Elimination For Multiple Choice Questions](https://arxiv.org//abs/2501.15175)

	Zhenhao Zhu, Bulou Liu, Qingyao Ai, Yiqun Liu

+ [FBQuant: FeedBack Quantization for Large Language Models](https://arxiv.org//abs/2501.16385)

	Yijiang Liu, Hengyu Fang, Liulu He, Rongyu Zhang, Yichuan Bai, Yuan Du, Li Du

+ [Can Large Language Models Be Trusted as Evolutionary Optimizers for Network-Structured Combinatorial Problems?](https://arxiv.org//abs/2501.15081)

	Jie Zhao, Tao Wen, Kang Hao Cheong

+ [Feedback-Aware Monte Carlo Tree Search for Efficient Information Seeking in Goal-Oriented Conversations](https://arxiv.org//abs/2501.15056)

	Harshita Chopra, Chirag Shah

+ [PIP: Perturbation-based Iterative Pruning for Large Language Models](https://arxiv.org//abs/2501.15278)

	Yi Cao, Wei-Jie Xu, Yucheng Shen, Weijie Shi, Chi-Min Chan, Jianfeng Qu, Jiajie Xu

# 2025-01-24
+ [Context-Aware Neural Gradient Mapping for Fine-Grained Instruction Processing](https://arxiv.org//abs/2501.14936)

	David Boldo, Lily Pemberton, Gabriel Thistledown, Jacob Fairchild, Felix Kowalski


+ [Prompt-Based Cost-Effective Evaluation and Operation of ChatGPT as a Computer Programming Teaching Assistant](https://arxiv.org//abs/2501.17176)

	Marc Ballestero-Ribó, Daniel Ortiz-Martínez

+ [Self-reflecting Large Language Models: A Hegelian Dialectical Approach](https://arxiv.org//abs/2501.14917)

	Sara Abdali, Can Goksen, Saeed Amizadeh, Julie E. Maybee, Kazuhito Koishida

+ [JustLogic: A Comprehensive Benchmark for Evaluating Deductive Reasoning in Large Language Models](https://arxiv.org//abs/2501.14851)

	Michael K. Chen, Xikun Zhang, Dacheng Tao

+ [SwiftPrune: Hessian-Free Weight Pruning for Large Language Models](https://arxiv.org//abs/2501.16376)

	Yuhan Kang, Yang Shi, Mei We, Jun He, Jianchao Yang, Zeyu Xue, Jing Feng, Xinwang Liu

+ [Mitigating Forgetting in LLM Fine-Tuning via Low-Perplexity Token Learning](https://arxiv.org//abs/2501.14315)

	Chao-Chung Wu, Zhi Rui Tam, Chieh-Yen Lin, Yun-Nung Chen, Shao-Hua Sun, Hung-yi Lee

+ [Tuning LLM Judge Design Decisions for 1/1000 of the Cost](https://arxiv.org//abs/2501.17178)

	David Salinas, Omar Swelam, Frank Hutter

+ [Domaino1s: Guiding LLM Reasoning for Explainable Answers in High-Stakes Domains](https://arxiv.org//abs/2501.14431)

	Xu Chu, Zhijie Tan, Hanlin Xue, Guanyu Wang, Tong Mo, Weiping Li

+ [Rethinking Table Instruction Tuning](https://arxiv.org//abs/2501.14693)

	Naihao Deng, Rada Mihalcea

# 2025-01-23
+ [GraphRAG under Fire](https://arxiv.org//abs/2501.14050)

	Jiacheng Liang, Yuhui Wang, Changjiang Li, Rongyi Zhu, Tanqiu Jiang, Neil Gong, Ting Wang


+ [A Cognitive Paradigm Approach to Probe the Perception-Reasoning Interface in VLMs](https://arxiv.org//abs/2501.13620)

	Mohit Vaishnav, Tanel Tammet

+ [Communicating Activations Between Language Model Agents](https://arxiv.org//abs/2501.14082)

	Vignav Ramesh, Kenneth Li

+ [Softplus Attention with Re-weighting Boosts Length Extrapolation in Large Language Models](https://arxiv.org//abs/2501.13428)

	Bo Gao, Michael W. Spratling

+ [Re-ranking Using Large Language Models for Mitigating Exposure to Harmful Content on Social Media Platforms](https://arxiv.org//abs/2501.13977)

	Rajvardhan Oak, Muhammad Haroon, Claire Jo, Magdalena Wojcieszak, Anshuman Chhabra

+ [Jailbreak-AudioBench: In-Depth Evaluation and Analysis of Jailbreak Threats for Large Audio Language Models](https://arxiv.org//abs/2501.13772)

	Hao Cheng, Erjia Xiao, Jing Shao, Yichi Wang, Le Yang, Chao Sheng, Philip Torr, Jindong Gu, Renjing Xu

+ [K-COMP: Retrieval-Augmented Medical Domain Question Answering With Knowledge-Injected Compressor](https://arxiv.org//abs/2501.13567)

	Jeonghun Cho, Gary Geunbae Lee

+ [Chain of Grounded Objectives: Bridging Process and Goal-oriented Prompting for Code Generation](https://arxiv.org//abs/2501.13978)

	Sangyeop Yeo, Seung-won Hwang, Yu-Seung Ma

# 2025-01-22
+ [NExtLong: Toward Effective Long-Context Training without Long Documents](https://arxiv.org//abs/2501.12766)

	Chaochen Gao, Xing Wu, Zijia Lin, Debing Zhang, Songlin Hu

+ [Kimi k1.5: Scaling Reinforcement Learning with LLMs](https://arxiv.org//abs/2501.12599)

	Kimi Team, Angang Du, Bofei Gao, Bowei Xing, Changjiu Jiang, Cheng Chen, Cheng Li, Chenjun Xiao, Chenzhuang Du, Chonghua Liao, Chuning Tang, Congcong Wang, Dehao Zhang, Enming Yuan, Enzhe Lu, Fengxiang Tang, Flood Sung, Guangda Wei, Guokun Lai, Haiqing Guo, Han Zhu, Hao Ding, Hao Hu, Hao Yang, Hao Zhang, Haotian Yao, Haotian Zhao, Haoyu Lu, Haoze Li, Haozhen Yu, Hongcheng Gao, Huabin Zheng, Huan Yuan, Jia Chen, Jianhang Guo, Jianlin Su, Jianzhou Wang, Jie Zhao, Jin Zhang, Jingyuan Liu, Junjie Yan, Junyan Wu, Lidong Shi, Ling Ye, Longhui Yu, Mengnan Dong, Neo Zhang, Ningchen Ma, Qiwei Pan, Qucheng Gong, Shaowei Liu, Shengling Ma, Shupeng Wei, Sihan Cao, Siying Huang, Tao Jiang, Weihao Gao, Weimin Xiong, Weiran He, Weixiao Huang, Wenhao Wu, Wenyang He, Xianghui Wei, Xianqing Jia, Xingzhe Wu, Xinran Xu, Xinxing Zu, Xinyu Zhou, Xuehai Pan, Y. Charles, Yang Li, Yangyang Hu, Yangyang Liu, Yanru Chen, Yejie Wang, Yibo Liu, Yidao Qin, Yifeng Liu, Ying Yang, Yiping Bao, Yulun Du, Yuxin Wu, Yuzhi Wang, Zaida Zhou, Zhaoji Wang, Zhaowei Li, Zhen Zhu, Zheng Zhang, Zhexu Wang, Zhilin Yang, Zhiqi Huang, Zihao Huang, Ziyao Xu, Zonghan Yang, Zongyu Lin

+ [Autonomy-of-Experts Models](https://arxiv.org//abs/2501.13074)

	Ang Lv, Ruobing Xie, Yining Qian, Songhao Wu, Xingwu Sun, Zhanhui Kang, Di Wang, Rui Yan

# 2025-01-21
+ [Test-time regression: a unifying framework for designing sequence models with associative memory](https://arxiv.org//abs/2501.12352)

	Ke Alexander Wang, Jiaxin Shi, Emily B. Fox

+ [Med-R$^2$: Crafting Trustworthy LLM Physicians via Retrieval and Reasoning of Evidence-Based Medicine](https://arxiv.org//abs/2501.11885)

	Keer Lu, Zheng Liang, Zhuoran Zhang, Da Pan, Shusen Zhang, Xin Wu, Zenan Zhou, Guosheng Dong, Bin Cui, Tengjiao Wang, Wentao Zhang

+ [AdaServe: Accelerating Multi-SLO LLM Serving with SLO-Customized Speculative Decoding](https://arxiv.org//abs/2501.12162)

	Zikun Li, Zhuofu Chen, Remi Delacourt, Gabriele Oliaro, Zeyu Wang, Qinghan Chen, Shuhuai Lin, April Yang, Zhihao Zhang, Zhuoming Chen, Sean Lai, Xinhao Cheng, Xupeng Miao, Zhihao Jia

+ [InternLM-XComposer2.5-Reward: A Simple Yet Effective Multi-Modal Reward Model](https://arxiv.org//abs/2501.12368)

	Yuhang Zang, Xiaoyi Dong, Pan Zhang, Yuhang Cao, Ziyu Liu, Shengyuan Ding, Shenxi Wu, Yubo Ma, Haodong Duan, Wenwei Zhang, Kai Chen, Dahua Lin, Jiaqi Wang

+ [Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation](https://arxiv.org//abs/2501.12432)

	Dongsheng Zhu, Weixian Shi, Zhengliang Shi, Zhaochun Ren, Shuaiqiang Wang, Lingyong Yan, Dawei Yin

# 2025-01-20
+ [Each Graph is a New Language: Graph Learning with LLMs](https://arxiv.org//abs/2501.11478)

	Huachi Zhou, Jiahe Du, Chuang Zhou, Chang Yang, Yilin Xiao, Yuxuan Xie, Xiao Huang

+ [Whose Boat Does it Float? Improving Personalization in Preference Tuning via Inferred User Personas](https://arxiv.org//abs/2501.11549)

	Nishant Balepur, Vishakh Padmakumar, Fumeng Yang, Shi Feng, Rachel Rudinger, Jordan Lee Boyd-Graber

+ [Reasoning Language Models: A Blueprint](https://arxiv.org//abs/2501.11223)

	Maciej Besta, Julia Barth, Eric Schreiber, Ales Kubicek, Afonso Catarino, Robert Gerstenberger, Piotr Nyczyk, Patrick Iff, Yueling Li, Sam Houliston, Tomasz Sternal, Marcin Copik, Grzegorz Kwaśniewski, Jürgen Müller, Łukasz Flis, Hannes Eberhard, Zixuan Chen, Hubert Niewiadomski, Torsten Hoefler

+ [T1: Advancing Language Model Reasoning through Reinforcement Learning and Inference Scaling](https://arxiv.org//abs/2501.11651)

	Zhenyu Hou, Xin Lv, Rui Lu, Jiajie Zhang, Yujiang Li, Zijun Yao, Juanzi Li, Jie Tang, Yuxiao Dong

# 2025-01-19
+ [A Comprehensive Survey on Integrating Large Language Models with Knowledge-Based Methods](https://arxiv.org//abs/2501.13947)

	Wenli Yang, Lilian Some, Michael Bain, Byeong Kang

+ [Chain-of-Reasoning: Towards Unified Mathematical Reasoning in Large Language Models via a Multi-Paradigm Perspective](https://arxiv.org//abs/2501.11110)

	Yiyao Yu, Yuxiang Zhang, Dongdong Zhang, Xiao Liang, Hengyuan Zhang, Xingxing Zhang, Mahmoud Khademi, Hany Awadalla, Junjie Wang, Yujiu Yang, Furu Wei

# 2025-01-17
+ [Know Your Mistakes: Towards Preventing Overreliance on Task-Oriented Conversational AI Through Accountability Modeling](https://arxiv.org//abs/2501.10316)

	Suvodip Dey, Yi-Jyun Sun, Gokhan Tur, Dilek Hakkani-Tur

# 2025-01-16
+ [Domain Adaptation of Foundation LLMs for e-Commerce](https://arxiv.org//abs/2501.09706)

	Christian Herold, Michael Kozielski, Tala Bazazo, Pavel Petrushkov, Patrycja Cieplicka, Dominika Basaj, Yannick Versley, Seyyed Hadi Hashemi, Shahram Khadivi

+ [Beyond Reward Hacking: Causal Rewards for Large Language Model Alignment](https://arxiv.org//abs/2501.09620)

	Chaoqi Wang, Zhuokai Zhao, Yibo Jiang, Zhaorun Chen, Chen Zhu, Yuxin Chen, Jiayi Liu, Lizhu Zhang, Xiangjun Fan, Hao Ma, Sinong Wang

# 2025-01-15
+ [iTool: Reinforced Fine-Tuning with Dynamic Deficiency Calibration for Advanced Tool Use](https://arxiv.org//abs/2501.09766)

	Yirong Zeng, Xiao Ding, Yuxian Wang, Weiwen Liu, Wu Ning, Yutai Hou, Xu Huang, Bing Qin, Ting Liu

+ [RLHS: Mitigating Misalignment in RLHF with Hindsight Simulation](https://arxiv.org//abs/2501.08617)

	Kaiqu Liang, Haimin Hu, Ryan Liu, Thomas L. Griffiths, Jaime Fernández Fisac

# 2025-01-14
+ [PRESERVE: Prefetching Model Weights and KV-Cache in Distributed LLM Serving](https://arxiv.org//abs/2501.08192)

	Ahmet Caner Yüzügüler, Jiawei Zhuang, Lukas Cavigelli

+ [The Invisible Hand: Unveiling Provider Bias in Large Language Models for Code Generation](https://arxiv.org//abs/2501.07849)

	Xiaoyu Zhang, Juan Zhai, Shiqing Ma, Qingshuang Bao, Weipeng Jiang, Qian Wang, Chao Shen, Yang Liu

+ [Enhancing Automated Interpretability with Output-Centric Feature Descriptions](https://arxiv.org//abs/2501.08319)

	Yoav Gur-Arieh, Roy Mayan, Chen Agassy, Atticus Geiger, Mor Geva

# 2025-01-13
+ [TiEBe: Tracking Language Model Recall of Notable Worldwide Events Through Time](https://arxiv.org//abs/2501.07482)

	Thales Sales Almeida, Giovana Kerche Bonás, João Guilherme Alves Santos, Hugo Abonizio, Rodrigo Nogueira

+ [Value Compass Leaderboard: A Platform for Fundamental and Validated Evaluation of LLMs Values](https://arxiv.org//abs/2501.07071)

	Jing Yao, Xiaoyuan Yi, Shitong Duan, Jindong Wang, Yuzhuo Bai, Muhua Huang, Peng Zhang, Tun Lu, Zhicheng Dou, Maosong Sun, Xing Xie

+ [The Lessons of Developing Process Reward Models in Mathematical Reasoning](https://arxiv.org//abs/2501.07301)

	Zhenru Zhang, Chujie Zheng, Yangzhen Wu, Beichen Zhang, Runji Lin, Bowen Yu, Dayiheng Liu, Jingren Zhou, Junyang Lin

# 2025-01-11
+ [Tensor Product Attention Is All You Need](https://arxiv.org//abs/2501.06425)

	Yifan Zhang, Yifeng Liu, Huizhuo Yuan, Zhen Qin, Yang Yuan, Quanquan Gu, Andrew C Yao

# 2025-01-10
+ [Dynamics of Spontaneous Topic Changes in Next Token Prediction with Self-Attention](https://arxiv.org//abs/2501.06382)

	Mumin Jia, Jairo Diaz-Rodriguez

+ [How to Enable Effective Cooperation Between Humans and NLP Models: A Survey of Principles, Formalizations, and Beyond](https://arxiv.org//abs/2501.05714)

	Chen Huang, Yang Deng, Wenqiang Lei, Jiancheng Lv, Tat-Seng Chua, Jimmy Xiangji Huang

+ [Large Language Models Share Representations of Latent Grammatical Concepts Across Typologically Diverse Languages](https://arxiv.org//abs/2501.06346)

	Jannik Brinkmann, Chris Wendler, Christian Bartelt, Aaron Mueller

+ [LLMs Reproduce Stereotypes of Sexual and Gender Minorities](https://arxiv.org//abs/2501.05926)

	Ruby Ostrow, Adam Lopez

+ [VideoRAG: Retrieval-Augmented Generation over Video Corpus](https://arxiv.org//abs/2501.05874)

	Soyeong Jeong, Kangsan Kim, Jinheon Baek, Sung Ju Hwang

+ [Supervision policies can shape long-term risk management in general-purpose AI models](https://arxiv.org//abs/2501.06137)

	Manuel Cebrian, Emilia Gomez, David Fernandez Llorca

# 2025-01-09
+ [CallNavi, A Challenge and Empirical Study on LLM Function Calling and Routing](https://arxiv.org//abs/2501.05255)

	Yewei Song, Xunzhu Tang, Cedric Lothritz, Saad Ezzini, Jacques Klein, Tegawendé F. Bissyandé, Andrey Boytsov, Ulrick Ble, Anne Goujon


+ [SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution](https://arxiv.org//abs/2501.05040)

	Chengxing Xie, Bowen Li, Chang Gao, He Du, Wai Lam, Difan Zou, Kai Chen

+ [TreeKV: Smooth Key-Value Cache Compression with Tree Structures](https://arxiv.org//abs/2501.04987)

	Ziwei He, Jian Yuan, Haoli Bai, Jingwen Leng, Bo Jiang

+ [Step-by-Step Mastery: Enhancing Soft Constraint Following Ability of Large Language Models](https://arxiv.org//abs/2501.04945)

	Qingyu Ren, Jie Zeng, Qianyu He, Jiaqing Liang, Yanghua Xiao, Weikang Zhou, Zeye Sun, Fei Yu

# 2025-01-08
+ [URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics](https://arxiv.org//abs/2501.04686)

	Ruilin Luo, Zhuofan Zheng, Yifan Wang, Xinzhe Ni, Zicheng Lin, Songtao Jiang, Yiyao Yu, Chufan Shi, Ruihang Chu, Jin Zeng, Yujiu Yang

# 2025-01-07
+ [More is not always better? Enhancing Many-Shot In-Context Learning with Differentiated and Reweighting Objectives](https://arxiv.org//abs/2501.04070)

	Xiaoqing Zhang, Ang Lv, Yuhan Liu, Flood Sung, Wei Liu, Jian Luan, Shuo Shang, Xiuying Chen, Rui Yan

+ [AlphaPO: Reward Shape Matters for LLM Alignment](https://arxiv.org//abs/2501.03884)

	Aman Gupta, Shao Tang, Qingquan Song, Sirou Zhu, Jiwoo Hong, Ankan Saha, Viral Gupta, Noah Lee, Eunki Kim, Siyu Zhu, Parag Agrawal, Natesh Pillai, S. Sathiya Keerthi

+ [Beyond Factual Accuracy: Evaluating Coverage of Diverse Factual Information in Long-form Text Generation](https://arxiv.org//abs/2501.03545)

	Chris Samarinas, Alexander Krubner, Alireza Salemi, Youngwoo Kim, Hamed Zamani

# 2025-01-06
+ [GeAR: Generation Augmented Retrieval](https://arxiv.org//abs/2501.02772)

	Haoyu Liu, Shaohan Huang, Jianfeng Liu, Yuefeng Zhan, Hao Sun, Weiwei Deng, Feng Sun, Furu Wei, Qi Zhang

# 2025-01-05
+ [Towards the Anonymization of the Language Modeling](https://arxiv.org//abs/2501.02407)

	Antoine Boutet, Lucas Magnana, Juliette Sénéchal, Helain Zimmermann

+ [Scaling Laws for Floating Point Quantization Training](https://arxiv.org//abs/2501.02423)

	Xingwu Sun, Shuaipeng Li, Ruobing Xie, Weidong Han, Kan Wu, Zhen Yang, Yixing Li, An Wang, Shuai Li, Jinbao Xue, Yu Cheng, Yangyu Tao, Zhanhui Kang, Chengzhong Xu, Di Wang, Jie Jiang

+ [ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use](https://arxiv.org//abs/2501.02506)

	Junjie Ye, Zhengyin Du, Xuesong Yao, Weijian Lin, Yufei Xu, Zehui Chen, Zaiyuan Wang, Sining Zhu, Zhiheng Xi, Siyu Yuan, Tao Gui, Qi Zhang, Xuanjing Huang, Jiecao Chen

+ [Towards Omni-RAG: Comprehensive Retrieval-Augmented Generation for Large Language Models in Medical Applications](https://arxiv.org//abs/2501.02460)

	Zhe Chen, Yusheng Liao, Shuyang Jiang, Pingjie Wang, Yiqiu Guo, Yanfeng Wang, Yu Wang

# 2025-01-04
+ [Zero-Shot Statistical Tests for LLM-Generated Text Detection using Finite Sample Concentration Inequalities](https://arxiv.org//abs/2501.02406)

	Tara Radvand, Mojtaba Abdolmaleki, Mohamed Mostagir, Ambuj Tewari

+ [LLM Content Moderation and User Satisfaction: Evidence from Response Refusals in Chatbot Arena](https://arxiv.org//abs/2501.03266)

	Stefan Pasch

+ [Personalized Graph-Based Retrieval for Large Language Models](https://arxiv.org//abs/2501.02157)

	Steven Au, Cameron J. Dimacali, Ojasmitha Pedirappagari, Namyong Park, Franck Dernoncourt, Yu Wang, Nikos Kanakaris, Hanieh Deilamsalehy, Ryan A. Rossi, Nesreen K. Ahmed

+ [Explicit vs. Implicit: Investigating Social Bias in Large Language Models through Self-Reflection](https://arxiv.org//abs/2501.02295)

	Yachao Zhao, Bo Wang, Yan Wang

# 2025-01-03
+ [MIRAGE: Exploring How Large Language Models Perform in Complex Social Interactive Environments](https://arxiv.org//abs/2501.01652)

	Yin Cai, Zhouhong Gu, Zhaohan Du, Zheyu Ye, Shaosheng Cao, Yiqian Xu, Hongwei Feng, Ping Chen

+ [Automating Legal Interpretation with LLMs: Retrieval, Generation, and Evaluation](https://arxiv.org//abs/2501.01743)

	Kangcheng Luo, Quzhe Huang, Cong Jiang, Yansong Feng

+ [An Investigation into Value Misalignment in LLM-Generated Texts for Cultural Heritage](https://arxiv.org//abs/2501.02039)

	Fan Bu, Zheng Wang, Siyi Wang, Ziyao Liu

+ [CoT-based Synthesizer: Enhancing LLM Performance through Answer Synthesis](https://arxiv.org//abs/2501.01668)

	Bohan Zhang, Xiaokang Zhang, Jing Zhang, Jifan Yu, Sijia Luo, Jie Tang

# 2025-01-02
+ [ValuesRAG: Enhancing Cultural Alignment Through Retrieval-Augmented Contextual Learning](https://arxiv.org//abs/2501.01031)

	Wonduk Seo, Zonghao Yuan, Yi Bu

+ [Cross-model Transferability among Large Language Models on the Platonic Representations of Concepts](https://arxiv.org//abs/2501.02009)

	Youcheng Huang, Chen Huang, Duanyu Feng, Wenqiang Lei, Jiancheng Lv

+ [ProgCo: Program Helps Self-Correction of Large Language Models](https://arxiv.org//abs/2501.01264)

	Xiaoshuai Song, Yanan Wu, Weixun Wang, Jiaheng Liu, Wenbo Su, Bo Zheng

+ [Are LLMs effective psychological assessors? Leveraging adaptive RAG for interpretable mental health screening through psychometric practice](https://arxiv.org//abs/2501.00982)

	Federico Ravenda, Seyed Ali Bahrainian, Andrea Raballo, Antonietta Mira, Noriko Kando

+ [Improving Medical Large Vision-Language Models with Abnormal-Aware Feedback](https://arxiv.org//abs/2501.01377)

	Yucheng Zhou, Lingran Song, Jianbing Shen

+ [Retrieval-Augmented Dynamic Prompt Tuning for Incomplete Multimodal Learning](https://arxiv.org//abs/2501.01120)

	Jian Lang, Zhangtao Cheng, Ting Zhong, Fan Zhou

# 2025-01-01
+ [LUSIFER: Language Universal Space Integration for Enhanced Multilingual Embeddings with Large Language Models](https://arxiv.org//abs/2501.00874)

	Hieu Man, Nghia Trung Ngo, Viet Dac Lai, Ryan A. Rossi, Franck Dernoncourt, Thien Huu Nguyen

+ [FitCF: A Framework for Automatic Feature Importance-guided Counterfactual Example Generation](https://arxiv.org//abs/2501.00777)

	Qianli Wang, Nils Feldhus, Simon Ostermann, Luis Felipe Villa-Arenas, Sebastian Möller, Vera Schmitt

+ [Unraveling Indirect In-Context Learning Using Influence Functions](https://arxiv.org//abs/2501.01473)

	Hadi Askari, Shivanshu Gupta, Terry Tong, Fei Wang, Anshuman Chhabra, Muhao Chen

+ [Efficient Unsupervised Shortcut Learning Detection and Mitigation in Transformers](https://arxiv.org//abs/2501.00942)

	Lukas Kuhn, Sari Sadiya, Jorg Schlotterer, Florian Buettner, Christin Seifert, Gemma Roig

# 2024-12-31
+ [GRASP: Replace Redundant Layers with Adaptive Singular Parameters for Efficient Model Compression](https://arxiv.org//abs/2501.00339)

	Kainan Liu, Yong Zhang, Ning Cheng, Zhitao Li, Shaojun Wang, Jing Xiao

# 2024-12-30
+ [ExpShield: Safeguarding Web Text from Unauthorized Crawling and Language Modeling Exploitation](https://arxiv.org//abs/2412.21123)

	Ruixuan Liu, Toan Tran, Tianhao Wang, Hongsheng Hu, Shuo Wang, Li Xiong

+ [Thinking Before Running! Efficient Code Generation with Thorough Exploration and Optimal Refinement](https://arxiv.org//abs/2502.17442)

	Xiaoqing Zhang, Yuhan Liu, Flood Sung, Xiuying Chen, Shuo Shang, Rui Yan

+ [Training Software Engineering Agents and Verifiers with SWE-Gym](https://arxiv.org//abs/2412.21139)

	Jiayi Pan, Xingyao Wang, Graham Neubig, Navdeep Jaitly, Heng Ji, Alane Suhr, Yizhe Zhang

# 2024-12-29
+ [ICLR: In-Context Learning of Representations](https://arxiv.org//abs/2501.00070)

	Core Francisco Park, Andrew Lee, Ekdeep Singh Lubana, Yongyi Yang, Maya Okawa, Kento Nishi, Martin Wattenberg, Hidenori Tanaka

+ [Understanding the Impact of Confidence in Retrieval Augmented Generation: A Case Study in the Medical Domain](https://arxiv.org//abs/2412.20309)

	Shintaro Ozaki, Yuta Kato, Siyuan Feng, Masayo Tomita, Kazuki Hayashi, Wataru Hashimoto, Ryoma Obara, Masafumi Oyamada, Katsuhiko Hayashi, Hidetaka Kamigaito, Taro Watanabe

+ [Enhancing Code LLMs with Reinforcement Learning in Code Generation: A Survey](https://arxiv.org//abs/2412.20367)

	Junqiao Wang, Zeng Zhang, Yangfan He, Zihao Zhang, Yuyang Song, Tianyu Shi, Yuchen Li, Hengyuan Xu, Kunyu Wu, Xin Yi, Zhongwei Wan, Xinhang Yuan, Kuan Lu, Menghao Huo, Tang Jingqun, Guangwu Qian, Keqin Li, Qiuwu Chen, Lewei He

# 2024-12-28
+ [No Preference Left Behind: Group Distributional Preference Optimization](https://arxiv.org//abs/2412.20299)

	Binwei Yao, Zefan Cai, Yun-Shiuan Chuang, Shanglin Yang, Ming Jiang, Diyi Yang, Junjie Hu

+ [ComparisonQA: Evaluating Factuality Robustness of LLMs Through Knowledge Frequency Control and Uncertainty](https://arxiv.org//abs/2412.20251)

	Qing Zong, Zhaowei Wang, Tianshi Zheng, Xiyu Ren, Yangqiu Song

# 2024-12-27
+ [Position: Theory of Mind Benchmarks are Broken for Large Language Models](https://arxiv.org//abs/2412.19726)

	Matthew Riemer, Zahra Ashktorab, Djallel Bouneffouf, Payel Das, Miao Liu, Justin D. Weisz, Murray Campbell

# 2024-12-24
+ [LSAQ: Layer-Specific Adaptive Quantization for Large Language Model Deployment](https://arxiv.org//abs/2412.18135)

	Binrui Zeng, Bin Ji, Xiaodong Liu, Jie Yu, Shasha Li, Jun Ma, Xiaopeng Li, Shangwen Wang, Xinran Hong, Yongtao Tang

+ [KunServe: Parameter-centric Memory Management for Efficient Memory Throttling Handling in LLM Serving](https://arxiv.org//abs/2412.18169)

	Rongxin Cheng, Yuxin Lai, Xingda Wei, Rong Chen, Haibo Chen

+ [A Statistical Framework for Ranking LLM-Based Chatbots](https://arxiv.org//abs/2412.18407)

	Siavash Ameli, Siyuan Zhuang, Ion Stoica, Michael W. Mahoney

+ [Neuron Empirical Gradient: Discovering and Quantifying Neurons Global Linear Controllability](https://arxiv.org//abs/2412.18053)

	Xin Zhao, Zehui Jiang, Naoki Yoshinaga

+ [Do Language Models Understand the Cognitive Tasks Given to Them? Investigations with the N-Back Paradigm](https://arxiv.org//abs/2412.18120)

	Xiaoyang Hu, Richard L. Lewis

+ [Token-Budget-Aware LLM Reasoning](https://arxiv.org//abs/2412.18547)

	Tingxu Han, Zhenting Wang, Chunrong Fang, Shiyu Zhao, Shiqing Ma, Zhenyu Chen

+ [Improving Factuality with Explicit Working Memory](https://arxiv.org//abs/2412.18069)

	Mingda Chen, Yang Li, Karthik Padthe, Rulin Shao, Alicia Sun, Luke Zettlemoyer, Gargi Ghosh, Wen-tau Yih

# 2024-12-23
+ [Fourier Position Embedding: Enhancing Attention's Periodic Extension for Length Generalization](https://arxiv.org//abs/2412.17739)

	Ermo Hua, Che Jiang, Xingtai Lv, Kaiyan Zhang, Ning Ding, Youbang Sun, Biqing Qi, Yuchen Fan, Xuekai Zhu, Bowen Zhou

# 2024-12-22
+ [Multi-Agent Sampling: Scaling Inference Compute for Data Synthesis with Tree Search-Based Agentic Collaboration](https://arxiv.org//abs/2412.17061)

	Hai Ye, Mingbao Lin, Hwee Tou Ng, Shuicheng Yan

+ [Better Think with Tables: Tabular Structures Enhance LLM Comprehension for Data-Analytics Requests](https://arxiv.org//abs/2412.17189)

	Jio Oh, Geon Heo, Seungjun Oh, Hyunjin Kim, JinYeong Bak, Jindong Wang, Xing Xie, Steven Euijong Whang

+ [Revisiting In-Context Learning with Long Context Language Models](https://arxiv.org//abs/2412.16926)

	Jinheon Baek, Sun Jae Lee, Prakhar Gupta, Geunseob Oh, Siddharth Dalmia, Prateek Kolhar

+ [A Reality Check on Context Utilisation for Retrieval-Augmented Generation](https://arxiv.org//abs/2412.17031)

	Lovisa Hagström, Sara Vera Marjanović, Haeun Yu, Arnav Arora, Christina Lioma, Maria Maistro, Pepa Atanasova, Isabelle Augenstein

# 2024-12-21
+ [Beyond Partisan Leaning: A Comparative Analysis of Political Bias in Large Language Models](https://arxiv.org//abs/2412.16746)

	Tai-Quan Peng, Kaiqi Yang, Sanguk Lee, Hang Li, Yucheng Chu, Yuping Lin, Hui Liu

+ [SubData: Bridging Heterogeneous Datasets to Enable Theory-Driven Evaluation of Political and Demographic Perspectives in LLMs](https://arxiv.org//abs/2412.16783)

	Leon Fröhling, Pietro Bernardelle, Gianluca Demartini

+ [Assessing Social Alignment: Do Personality-Prompted Large Language Models Behave Like Humans?](https://arxiv.org//abs/2412.16772)

	Ivan Zakazov, Mikolaj Boronski, Lorenzo Drudi, Robert West

# 2024-12-20
+ [Less is More: Towards Green Code Large Language Models via Unified Structural Pruning](https://arxiv.org//abs/2412.15921)

	Guang Yang, Yu Zhou, Xiangyu Zhang, Wei Cheng, Ke Liu, Xiang Chen, Terry Yue Zhuo, Taolue Chen


+ [XRAG: eXamining the Core -- Benchmarking Foundational Components in Advanced Retrieval-Augmented Generation](https://arxiv.org//abs/2412.15529)

	Qianren Mao, Yangyifei Luo, Qili Zhang, Yashuo Luo, Zhilong Cao, Jinlong Zhang, HanWen Hao, Zhijun Chen, Weifeng Jiang, Junnan Liu, Xiaolong Wang, Zhenting Huang, Zhixing Tan, Sun Jie, Bo Li, Xudong Liu, Richong Zhang, Jianxin Li

+ [MRAG: A Modular Retrieval Framework for Time-Sensitive Question Answering](https://arxiv.org//abs/2412.15540)

	Zhang Siyue, Xue Yuxiang, Zhang Yiming, Wu Xiaobao, Luu Anh Tuan, Zhao Chen

+ [MORTAR: Multi-turn Metamorphic Testing for LLM-based Dialogue Systems](https://arxiv.org//abs/2412.15557)

	Guoxiang Guo, Aldeida Aleti, Neelofar Neelofar, Chakkrit Tantithamthavorn, Yuanyuan Qi, Tsong Yueh Chen

# 2024-12-19
+ [A Retrieval-Augmented Generation Framework for Academic Literature Navigation in Data Science](https://arxiv.org//abs/2412.15404)

	Ahmet Yasin Aytar, Kemal Kilic, Kamer Kaya

+ [Agent-SafetyBench: Evaluating the Safety of LLM Agents](https://arxiv.org//abs/2412.14470)

	Zhexin Zhang, Shiyao Cui, Yida Lu, Jingzhuo Zhou, Junxiao Yang, Hongning Wang, Minlie Huang

+ [How to Synthesize Text Data without Model Collapse?](https://arxiv.org//abs/2412.14689)

	Xuekai Zhu, Daixuan Cheng, Hengli Li, Kaiyan Zhang, Ermo Hua, Xingtai Lv, Ning Ding, Zhouhan Lin, Zilong Zheng, Bowen Zhou

+ [DynamicKV: Task-Aware Adaptive KV Cache Compression for Long Context LLMs](https://arxiv.org//abs/2412.14838)

	Xiabin Zhou, Wenbin Wang, Minyan Zeng, Jiaxian Guo, Xuebo Liu, Li Shen, Min Zhang, Liang Ding

+ [Bel Esprit: Multi-Agent Framework for Building AI Model Pipelines](https://arxiv.org//abs/2412.14684)

	Yunsu Kim, AhmedElmogtaba Abdelaziz, Thiago Castro Ferreira, Mohamed Al-Badrashiny, Hassan Sawaf

# 2024-12-18
+ [TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks](https://arxiv.org//abs/2412.14161)

	Frank F. Xu, Yufan Song, Boxuan Li, Yuxuan Tang, Kritanjali Jain, Mengxue Bao, Zora Z. Wang, Xuhui Zhou, Zhitong Guo, Murong Cao, Mingyang Yang, Hao Yang Lu, Amaad Martin, Zhe Su, Leander Maben, Raj Mehta, Wayne Chi, Lawrence Jang, Yiqing Xie, Shuyan Zhou, Graham Neubig

+ [EscapeBench: Towards Advancing Creative Intelligence of Language Model Agents](https://arxiv.org//abs/2412.13549)

	Cheng Qian, Peixuan Han, Qinyu Luo, Bingxiang He, Xiusi Chen, Yuji Zhang, Hongyi Du, Jiarui Yao, Xiaocheng Yang, Denghui Zhang, Yunzhu Li, Heng Ji

+ [GMoE: Empowering LLMs Fine-Tuning via MoE Graph Collaboration](https://arxiv.org//abs/2412.16216)

	Ting Bai, Yue Yu, Le Huang, Zenan Xu, Zhe Zhao, Chuan Shi

+ [AntiLeakBench: Preventing Data Contamination by Automatically Constructing Benchmarks with Updated Real-World Knowledge](https://arxiv.org//abs/2412.13670)

	Xiaobao Wu, Liangming Pan, Yuxi Xie, Ruiwen Zhou, Shuai Zhao, Yubo Ma, Mingzhe Du, Rui Mao, Anh Tuan Luu, William Yang Wang

+ [ChinaTravel: An Open-Ended Benchmark for Language Agents in Chinese Travel Planning](https://arxiv.org//abs/2412.13682)

	Jie-Jing Shao, Bo-Wen Zhang, Xiao-Wen Yang, Baizhi Chen, Si-Yu Han, Wen-Da Wei, Guohao Cai, Zhenhua Dong, Lan-Zhe Guo, Yu-feng Li

+ [A Rose by Any Other Name: LLM-Generated Explanations Are Good Proxies for Human Explanations to Collect Label Distributions on NLI](https://arxiv.org//abs/2412.13942)

	Beiduo Chen, Siyao Peng, Anna Korhonen, Barbara Plank

+ [Mind Your Theory: Theory of Mind Goes Deeper Than Reasoning](https://arxiv.org//abs/2412.13631)

	Eitan Wagner, Nitay Alon, Joseph M. Barnby, Omri Abend

+ [Exploring Multi-Modal Data with Tool-Augmented LLM Agents for Precise Causal Discovery](https://arxiv.org//abs/2412.13667)

	ChengAo Shen, Zhengzhang Chen, Dongsheng Luo, Dongkuan Xu, Haifeng Chen, Jingchao Ni

+ [GAMEBoT: Transparent Assessment of LLM Reasoning in Games](https://arxiv.org//abs/2412.13602)

	Wenye Lin, Jonathan Roberts, Yunhan Yang, Samuel Albanie, Zongqing Lu, Kai Han

+ [SCOPE: Optimizing Key-Value Cache Compression in Long-context Generation](https://arxiv.org//abs/2412.13649)

	Jialong Wu, Zhenglin Wang, Linhai Zhang, Yilong Lai, Yulan He, Deyu Zhou

+ [Cross-Lingual Transfer of Debiasing and Detoxification in Multilingual LLMs: An Extensive Investigation](https://arxiv.org//abs/2412.14050)

	Vera Neplenbroek, Arianna Bisazza, Raquel Fernández

+ [Cracking the Code of Hallucination in LVLMs with Vision-aware Head Divergence](https://arxiv.org//abs/2412.13949)

	Jinghan He, Kuan Zhu, Haiyun Guo, Junfeng Fang, Zhenglin Hua, Yuheng Jia, Ming Tang, Tat-Seng Chua, Jinqiao Wang

# 2024-12-17
+ [What External Knowledge is Preferred by LLMs? Characterizing and Exploring Chain of Evidence in Imperfect Context](https://arxiv.org//abs/2412.12632)

	Zhiyuan Chang, Mingyang Li, Xiaojun Jia, Junjie Wang, Yuekai Huang, Qing Wang, Yihao Huang, Yang Liu

+ [When to Speak, When to Abstain: Contrastive Decoding with Abstention](https://arxiv.org//abs/2412.12527)

	Hyuhng Joon Kim, Youna Kim, Sang-goo Lee, Taeuk Kim

+ [DateLogicQA: Benchmarking Temporal Biases in Large Language Models](https://arxiv.org//abs/2412.13377)

	Gagan Bhatia, MingZe Tang, Cristina Mahanta, Madiha Kazi

+ [Boosting LLM-based Relevance Modeling with Distribution-Aware Robust Learning](https://arxiv.org//abs/2412.12504)

	Hong Liu, Saisai Gong, Yixin Ji, Kaixin Wu, Jia Xu, Jinjie Gu

+ [Exploring Cross-lingual Latent Transplantation: Mutual Opportunities and Open Challenges](https://arxiv.org//abs/2412.12686)

	Yangfan Ye, Xiaocheng Feng, Xiachong Feng, Libo Qin, Yichong Huang, Lei Huang, Weitao Ma, Qichen Hong, Zhirui Zhang, Yunfei Lu, Xiaohui Yan, Duyu Tang, Dandan Tu, Bing Qin

+ [LITA: An Efficient LLM-assisted Iterative Topic Augmentation Framework](https://arxiv.org//abs/2412.12459)

	Chia-Hsuan Chang, Jui-Tse Tsai, Yi-Hang Tsai, San-Yih Hwang

+ [Boosting Long-Context Management via Query-Guided Activation Refilling](https://arxiv.org//abs/2412.12486)

	Hongjin Qian, Zheng Liu, Peitian Zhang, Zhicheng Dou, Defu Lian

+ [Core Context Aware Transformers for Long Context Language Modeling](https://arxiv.org//abs/2412.12465)

	Yaofo Chen, Zeng You, Shuhai Zhang, Haokun Li, Yirui Li, Yaowei Wang, Mingkui Tan

+ [EXIT: Context-Aware Extractive Compression for Enhancing Retrieval-Augmented Generation](https://arxiv.org//abs/2412.12559)

	Taeho Hwang, Sukmin Cho, Soyeong Jeong, Hoyun Song, SeungYoon Han, Jong C. Park

+ [SimGRAG: Leveraging Similar Subgraphs for Knowledge Graphs Driven Retrieval-Augmented Generation](https://arxiv.org//abs/2412.15272)

	Yuzheng Cai, Zhenyue Guo, Yiwen Pei, Wanrui Bian, Weiguo Zheng

+ [FCMR: Robust Evaluation of Financial Cross-Modal Multi-Hop Reasoning](https://arxiv.org//abs/2412.12567)

	Seunghee Kim, Changhyeon Kim, Taeuk Kim

+ [Enhancing LLM-based Hatred and Toxicity Detection with Meta-Toxic Knowledge Graph](https://arxiv.org//abs/2412.15268)

	Yibo Zhao, Jiapeng Zhu, Can Xu, Yao Liu, Xiang Li

+ [Are Your LLMs Capable of Stable Reasoning?](https://arxiv.org//abs/2412.13147)

	Junnan Liu, Hongwei Liu, Linchen Xiao, Ziyi Wang, Kuikun Liu, Songyang Gao, Wenwei Zhang, Songyang Zhang, Kai Chen

+ [SummExecEdit: A Factual Consistency Benchmark in Summarization with Executable Edits](https://arxiv.org//abs/2412.13378)

	Onkar Thorat, Philippe Laban, Chien-Sheng Wu

# 2024-12-16
+ [ElChat: Adapting Chat Language Models Using Only Target Unlabeled Language Data](https://arxiv.org//abs/2412.11704)

	Atsuki Yamaguchi, Terufumi Morishita, Aline Villavicencio, Nikolaos Aletras

+ [A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method & Challenges](https://arxiv.org//abs/2412.11936)

	Yibo Yan, Jiamin Su, Jianxiang He, Fangteng Fu, Xu Zheng, Yuanhuiyi Lyu, Kun Wang, Shen Wang, Qingsong Wen, Xuming Hu

+ [UAlign: Leveraging Uncertainty Estimations for Factuality Alignment on Large Language Models](https://arxiv.org//abs/2412.11803)

	Boyang Xue, Fei Mi, Qi Zhu, Hongru Wang, Rui Wang, Sheng Wang, Erxin Yu, Xuming Hu, Kam-Fai Wong

+ [ConKE: Conceptualization-Augmented Knowledge Editing in Large Language Models for Commonsense Reasoning](https://arxiv.org//abs/2412.11418)

	Liyu Zhang, Weiqi Wang, Tianqing Fang, Yangqiu Song

+ [Emergence and Effectiveness of Task Vectors in In-Context Learning: An Encoder Decoder Perspective](https://arxiv.org//abs/2412.12276)

	Seungwook Han, Jinyeop Song, Jeff Gore, Pulkit Agrawal

+ [INTERACT: Enabling Interactive, Question-Driven Learning in Large Language Models](https://arxiv.org//abs/2412.11388)

	Aum Kendapadi, Kerem Zaman, Rakesh R. Menon, Shashank Srivastava

+ [Inferring Functionality of Attention Heads from their Parameters](https://arxiv.org//abs/2412.11965)

	Amit Elhelo, Mor Geva

# 2024-12-15
+ [AD-LLM: Benchmarking Large Language Models for Anomaly Detection](https://arxiv.org//abs/2412.11142)

	Tiankai Yang, Yi Nian, Shawn Li, Ruiyao Xu, Yuangang Li, Jiaqi Li, Zhuo Xiao, Xiyang Hu, Ryan Rossi, Kaize Ding, Xia Hu, Yue Zhao

+ [SceneLLM: Implicit Language Reasoning in LLM for Dynamic Scene Graph Generation](https://arxiv.org//abs/2412.11026)

	Hang Zhang, Zhuoling Li, Jun Liu

+ [Separate the Wheat from the Chaff: A Post-Hoc Approach to Safety Re-Alignment for Fine-Tuned Language Models](https://arxiv.org//abs/2412.11041)

	Di Wu, Xin Lu, Yanyan Zhao, Bing Qin

+ [Leveraging Large Language Models for Active Merchant Non-player Characters](https://arxiv.org//abs/2412.11189)

	Byungjun Kim, Minju Kim, Dayeon Seo, Bugeun Kim

+ [CoopetitiveV: Leveraging LLM-powered Coopetitive Multi-Agent Prompting for High-quality Verilog Generation](https://arxiv.org//abs/2412.11014)

	Zhendong Mi, Renming Zheng, Haowen Zhong, Yue Sun, Seth Kneeland, Sayan Moitra, Ken Kutzer, Zhaozhuo Xu Shaoyi Huang

# 2024-12-14
+ [Superhuman performance of a large language model on the reasoning tasks of a physician](https://arxiv.org//abs/2412.10849)

	Peter G. Brodeur, Thomas A. Buckley, Zahir Kanjee, Ethan Goh, Evelyn Bin Ling, Priyank Jain, Stephanie Cabral, Raja-Elie Abdulnour, Adrian D. Haimovich, Jason A. Freed, Andrew Olson, Daniel J. Morgan, Jason Hom, Robert Gallo, Liam G. McCoy, Haadi Mombini, Christopher Lucas, Misha Fotoohi, Matthew Gwiazdon, Daniele Restifo, Daniel Restrepo, Eric Horvitz, Jonathan Chen, Arjun K. Manrai, Adam Rodman

+ [Rethinking Chain-of-Thought from the Perspective of Self-Training](https://arxiv.org//abs/2412.10827)

	Zongqian Wu, Baoduo Xu, Ruochen Cui, Mengmeng Zhan, Xiaofeng Zhu, Lei Feng

# 2024-12-13
+ [You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary Projects](https://arxiv.org//abs/2412.10133)

	Islem Bouzenia, Michael Pradel

+ [ROUTE: Robust Multitask Tuning and Collaboration for Text-to-SQL](https://arxiv.org//abs/2412.10138)

	Yang Qin, Chao Chen, Zhihang Fu, Ze Chen, Dezhong Peng, Peng Hu, Jieping Ye

+ [On the Limit of Language Models as Planning Formalizers](https://arxiv.org//abs/2412.09879)

	Cassie Huang, Li Zhang

+ [MALAMUTE: A Multilingual, Highly-granular, Template-free, Education-based Probing Dataset](https://arxiv.org//abs/2412.10105)

	Sagi Shaier, George Arthur Baker, Chiranthan Sridhar, Lawrence E Hunter, Katharina von der Wense

+ [HashEvict: A Pre-Attention KV Cache Eviction Strategy using Locality-Sensitive Hashing](https://arxiv.org//abs/2412.16187)

	Minghui Liu, Tahseen Rabbani, Tony O'Halloran, Ananth Sankaralingam, Mary-Anne Hartley, Furong Huang, Cornelia Fermüller, Yiannis Aloimonos

# 2024-12-12
+ [Dial-In LLM: Human-Aligned LLM-in-the-loop Intent Clustering for Customer Service Dialogues](https://arxiv.org//abs/2412.09049)

	Mengze Hong, Wailing Ng, Chen Jason Zhang, Yuanfeng Song, Di Jiang

+ [RuleArena: A Benchmark for Rule-Guided Reasoning with LLMs in Real-World Scenarios](https://arxiv.org//abs/2412.08972)

	Ruiwen Zhou, Wenyue Hua, Liangming Pan, Sitao Cheng, Xiaobao Wu, En Yu, William Yang Wang

+ [KnowShiftQA: How Robust are RAG Systems when Textbook Knowledge Shifts in K-12 Education?](https://arxiv.org//abs/2412.08985)

	Tianshi Zheng, Weihan Li, Jiaxin Bai, Weiqi Wang, Yangqiu Song

+ [From Intention To Implementation: Automating Biomedical Research via LLMs](https://arxiv.org//abs/2412.09429)

	Yi Luo, Linghang Shi, Yihao Li, Aobo Zhuang, Yeyun Gong, Ling Liu, Chen Lin

+ [JuStRank: Benchmarking LLM Judges for System Ranking](https://arxiv.org//abs/2412.09569)

	Ariel Gera, Odellia Boni, Yotam Perlitz, Roy Bar-Haim, Lilach Eden, Asaf Yehudai

# 2024-12-11
+ [Generative Agents for Multi-Agent Autoformalization of Interaction Scenarios](https://arxiv.org//abs/2412.08805)

	Agnieszka Mensfelt, Kostas Stathis, Vince Trencsenyi

+ [Bridging Relevance and Reasoning: Rationale Distillation in Retrieval-Augmented Generation](https://arxiv.org//abs/2412.08519)

	Pengyue Jia, Derong Xu, Xiaopeng Li, Zhaocheng Du, Xiangyang Li, Yichao Wang, Yuhao Wang, Qidong Liu, Maolin Wang, Huifeng Guo, Ruiming Tang, Xiangyu Zhao

# 2024-12-10
+ [A Causal World Model Underlying Next Token Prediction: Exploring GPT in a Controlled Environment](https://arxiv.org//abs/2412.07446)

	Raanan Y. Rohekar, Yaniv Gurwicz, Sungduk Yu, Estelle Aflalo, Vasudev Lal

+ [AutoPrep: Natural Language Question-Aware Data Preparation with a Multi-Agent Framework](https://arxiv.org//abs/2412.10422)

	Meihao Fan, Ju Fan, Nan Tang, Lei Cao, Guoliang Li, Xiaoyong Du

+ [MoE-CAP: Benchmarking Cost, Accuracy and Performance of Sparse Mixture-of-Experts Systems](https://arxiv.org//abs/2412.07067)

	Yinsicheng Jiang, Yao Fu, Yeqi Huang, Ping Nie, Zhan Lu, Leyang Xue, Congjie He, Man-Kit Sit, Jilong Xue, Li Dong, Ziming Miao, Dayou Du, Tairan Xu, Kai Zou, Edoardo Ponti, Luo Mai

+ [HARP: Hesitation-Aware Reframing in Transformer Inference Pass](https://arxiv.org//abs/2412.07282)

	Romain Storaï, Seung-won Hwang

+ [LLM-as-an-Interviewer: Beyond Static Testing Through Dynamic LLM Evaluation](https://arxiv.org//abs/2412.10424)

	Eunsu Kim, Juyoung Suk, Seungone Kim, Niklas Muennighoff, Dongkwan Kim, Alice Oh

# 2024-12-09
+ [MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization](https://arxiv.org//abs/2412.06141)

	Kangyu Zhu, Peng Xia, Yun Li, Hongtu Zhu, Sheng Wang, Huaxiu Yao

+ [ProcessBench: Identifying Process Errors in Mathematical Reasoning](https://arxiv.org//abs/2412.06559)

	Chujie Zheng, Zhenru Zhang, Beichen Zhang, Runji Lin, Keming Lu, Bowen Yu, Dayiheng Liu, Jingren Zhou, Junyang Lin

+ [A Comparative Study of Learning Paradigms in Large Language Models via Intrinsic Dimension](https://arxiv.org//abs/2412.06245)

	Saahith Janapati, Yangfeng Ji

+ [Evaluating LLM-based Approaches to Legal Citation Prediction: Domain-specific Pre-training, Fine-tuning, or RAG? A Benchmark and an Australian Law Case Study](https://arxiv.org//abs/2412.06272)

	Jiuzhou Han, Paul Burgess, Ehsan Shareghi

+ [The Synergy of LLMs & RL Unlocks Offline Learning of Generalizable Language-Conditioned Policies with Low-fidelity Data](https://arxiv.org//abs/2412.06877)

	Thomas Pouplin, Katarzyna Kobalczyk, Hao Sun, Mihaela van der Schaar

# 2024-12-08
+ [7B Fully Open Source Moxin-LLM/VLM -- From Pretraining to GRPO-based Reinforcement Learning Enhancement](https://arxiv.org//abs/2412.06845)

	Pu Zhao, Xuan Shen, Zhenglun Kong, Yixin Shen, Sung-En Chang, Timothy Rupprecht, Lei Lu, Enfu Nan, Changdi Yang, Yumei He, Weiyan Shi, Xingchen Xu, Yu Huang, Wei Jiang, Wei Wang, Yue Chen, Yong He, Yanzhi Wang

# 2024-12-07
+ [SLA Management in Reconfigurable Multi-Agent RAG: A Systems Approach to Question Answering](https://arxiv.org//abs/2412.06832)

	Michael Iannelli, Sneha Kuchipudi, Vera Dvorak

+ [KG-Retriever: Efficient Knowledge Indexing for Retrieval-Augmented Large Language Models](https://arxiv.org//abs/2412.05547)

	Weijie Chen, Ting Bai, Jinbo Su, Jian Luan, Wei Liu, Chuan Shi

+ [Training-Free Bayesianization for Low-Rank Adapters of Large Language Models](https://arxiv.org//abs/2412.05723)

	Haizhou Shi, Yibin Wang, Ligong Han, Huan Zhang, Hao Wang

+ [PromptRefine: Enhancing Few-Shot Performance on Low-Resource Indic Languages with Example Selection from Related Example Banks](https://arxiv.org//abs/2412.05710)

	Soumya Suvra Ghosal, Soumyabrata Pal, Koyel Mukherjee, Dinesh Manocha

# 2024-12-06
+ [Multi-Party Supervised Fine-tuning of Language Models for Multi-Party Dialogue Generation](https://arxiv.org//abs/2412.05342)

	Xiaoyu Wang, Ningyuan Xi, Teng Chen, Qingqing Gu, Yue Zhao, Xiaokai Chen, Zhonglin Jiang, Yong Chen, Luo Ji

+ [ChatNVD: Advancing Cybersecurity Vulnerability Assessment with Large Language Models](https://arxiv.org//abs/2412.04756)

	Shivansh Chopra, Hussain Ahmad, Diksha Goel, Claudia Szabo

+ [C$^2$LEVA: Toward Comprehensive and Contamination-Free Language Model Evaluation](https://arxiv.org//abs/2412.04947)

	Yanyang Li, Tin Long Wong, Cheung To Hung, Jianqiao Zhao, Duo Zheng, Ka Wai Liu, Michael R. Lyu, Liwei Wang

+ [DEMO: Reframing Dialogue Interaction with Fine-grained Element Modeling](https://arxiv.org//abs/2412.04905)

	Minzheng Wang, Xinghua Zhang, Kun Chen, Nan Xu, Haiyang Yu, Fei Huang, Wenji Mao, Yongbin Li

+ [Knowledge Graphs are all you need: Leveraging KGs in Physics Question Answering](https://arxiv.org//abs/2412.05453)

	Krishnasai Addala, Kabir Dev Paul Baghel, Dhruv Jain, Navya Gupta, Rishitej Reddy Vyalla, Chhavi Kirtani, Avinash Anand, Rajiv Ratn Shah

# 2024-12-05
+ [Extractive Structures Learned in Pretraining Enable Generalization on Finetuned Facts](https://arxiv.org//abs/2412.04614)

	Jiahai Feng, Stuart Russell, Jacob Steinhardt

+ [Demonstration Selection for In-Context Learning via Reinforcement Learning](https://arxiv.org//abs/2412.03966)

	Xubin Wang, Jianfei Wu, Yichen Yuan, Deyu Cai, Mingzhe Li, Weijia Jia

+ [Reducing Tool Hallucination via Reliability Alignment](https://arxiv.org//abs/2412.04141)

	Hongshen Xu, Zichen Zhu, Lei Pan, Zihan Wang, Su Zhu, Da Ma, Ruisheng Cao, Lu Chen, Kai Yu

+ [The broader spectrum of in-context learning](https://arxiv.org//abs/2412.03782)

	Andrew Kyle Lampinen, Stephanie C. Y. Chan, Aaditya K. Singh, Murray Shanahan

+ [GRAF: Graph Retrieval Augmented by Facts for Romanian Legal Multi-Choice Question Answering](https://arxiv.org//abs/2412.04119)

	Cristian-George Crăciun, Răzvan-Alexandru Smădu, Dumitru-Clementin Cercel, Mihaela-Claudia Cercel

+ [Monet: Mixture of Monosemantic Experts for Transformers](https://arxiv.org//abs/2412.04139)

	Jungwoo Park, Young Jin Ahn, Kee-Eung Kim, Jaewoo Kang

# 2024-12-04
+ [ClusterKV: Manipulating LLM KV Cache in Semantic Space for Recallable Compression](https://arxiv.org//abs/2412.03213)

	Guangda Liu, Chengwei Li, Jieru Zhao, Chenqi Zhang, Minyi Guo

# 2024-12-03
+ [Enhancing LLMs with Smart Preprocessing for EHR Analysis](https://arxiv.org//abs/2412.02868)

	Yixiang Qu, Yifan Dai, Shilin Yu, Pradham Tanikella, Travis Schrank, Trevor Hackman, Didong Li, Di Wu


+ [DP-2Stage: Adapting Language Models as Differentially Private Tabular Data Generators](https://arxiv.org//abs/2412.02467)

	Tejumade Afonja, Hui-Po Wang, Raouf Kerkouche, Mario Fritz

+ [RARE: Retrieval-Augmented Reasoning Enhancement for Large Language Models](https://arxiv.org//abs/2412.02830)

	Hieu Tran, Zonghai Yao, Junda Wang, Yifan Zhang, Zhichao Yang, Hong Yu

# 2024-12-02
+ [Mastering Board Games by External and Internal Planning with Language Models](https://arxiv.org//abs/2412.12119)

	John Schultz, Jakub Adamek, Matej Jusup, Marc Lanctot, Michael Kaisers, Sarah Perrin, Daniel Hennes, Jeremy Shar, Cannada Lewis, Anian Ruoss, Tom Zahavy, Petar Veličković, Laurel Prince, Satinder Singh, Eric Malmi, Nenad Tomašev

+ [FastRM: An efficient and automatic explainability framework for multimodal generative models](https://arxiv.org//abs/2412.01487)

	Gabriela Ben-Melech Stan, Estelle Aflalo, Man Luo, Shachar Rosenman, Tiep Le, Sayak Paul, Shao-Yen Tseng, Vasudev Lal

+ [Beyond Text-Visual Attention: Exploiting Visual Cues for Effective Token Pruning in VLMs](https://arxiv.org//abs/2412.01818)

	Qizhe Zhang, Aosong Cheng, Ming Lu, Renrui Zhang, Zhiyong Zhuo, Jiajun Cao, Shaobo Guo, Qi She, Shanghang Zhang

# 2024-12-01
+ [Competition Dynamics Shape Algorithmic Phases of In-Context Learning](https://arxiv.org//abs/2412.01003)

	Core Francisco Park, Ekdeep Singh Lubana, Itamar Pres, Hidenori Tanaka

# 2024-11-29
+ [Simple and Provable Scaling Laws for the Test-Time Compute of Large Language Models](https://arxiv.org//abs/2411.19477)

	Yanxi Chen, Xuchen Pan, Yaliang Li, Bolin Ding, Jingren Zhou

+ [VLSBench: Unveiling Visual Leakage in Multimodal Safety](https://arxiv.org//abs/2411.19939)

	Xuhao Hu, Dongrui Liu, Hao Li, Xuanjing Huang, Jing Shao

+ [Initialization using Update Approximation is a Silver Bullet for Extremely Efficient Low-Rank Fine-Tuning](https://arxiv.org//abs/2411.19557)

	Kaustubh Ponkshe, Raghav Singhal, Eduard Gorbunov, Alexey Tumanov, Samuel Horvath, Praneeth Vepakomma

# 2024-11-28
+ [Personalized Federated Fine-Tuning for LLMs via Data-Driven Heterogeneous Model Architectures](https://arxiv.org//abs/2411.19128)

	Yicheng Zhang, Zhen Qin, Zhaomin Wu, Jian Hou, Shuiguang Deng

# 2024-11-27
+ [Can LLMs assist with Ambiguity? A Quantitative Evaluation of various Large Language Models on Word Sense Disambiguation](https://arxiv.org//abs/2411.18337)

	T.G.D.K. Sumanathilaka, Nicholas Micallef, Julian Hough

+ [Beyond Examples: High-level Automated Reasoning Paradigm in In-Context Learning via MCTS](https://arxiv.org//abs/2411.18478)

	Jinyang Wu, Mingkuan Feng, Shuai Zhang, Feihu Che, Zengqi Wen, Chonghua Liao, Jianhua Tao

+ [Retrofitting Large Language Models with Dynamic Tokenization](https://arxiv.org//abs/2411.18553)

	Darius Feher, Ivan Vulić, Benjamin Minixhofer

+ [Autonomous Imagination: Closed-Loop Decomposition of Visual-to-Textual Conversion in Visual Reasoning for Multimodal Large Language Models](https://arxiv.org//abs/2411.18142)

	Jingming Liu, Yumeng Li, Boyuan Xiao, Yichang Jian, Ziang Qin, Tianjia Shao, Yao-Xiang Ding, Kun Zhou

# 2024-11-26
+ [ThreatModeling-LLM: Automating Threat Modeling using Large Language Models for Banking System](https://arxiv.org//abs/2411.17058)

	Tingmin Wu, Shuiqiao Yang, Shigang Liu, David Nguyen, Seung Jang, Alsharif Abuadbba

+ [Not All Adapters Matter: Selective Adapter Freezing for Memory-Efficient Fine-Tuning of Language Models](https://arxiv.org//abs/2412.03587)

	Hyegang Son, Yonglak Son, Changhoon Kim, Young Geun Kim

+ [Can LLMs be Good Graph Judge for Knowledge Graph Construction?](https://arxiv.org//abs/2411.17388)

	Haoyu Huang, Chong Chen, Zeang Sheng, Yang Li, Wentao Zhang

+ [Enhancing Character-Level Understanding in LLMs through Token Internal Structure Learning](https://arxiv.org//abs/2411.17679)

	Zhu Xu, Zhiqiang Zhao, Zihan Zhang, Yuchi Liu, Quanwei Shen, Fei Liu, Yu Kuang, Jian He, Conglin Liu

+ [Star Attention: Efficient LLM Inference over Long Sequences](https://arxiv.org//abs/2411.17116)

	Shantanu Acharya, Fei Jia, Boris Ginsburg

+ [VL-RewardBench: A Challenging Benchmark for Vision-Language Generative Reward Models](https://arxiv.org//abs/2411.17451)

	Lei Li, Yuancheng Wei, Zhihui Xie, Xuqing Yang, Yifan Song, Peiyi Wang, Chenxin An, Tianyu Liu, Sujian Li, Bill Yuchen Lin, Lingpeng Kong, Qi Liu

+ [Meaningless is better: hashing bias-inducing words in LLM prompts improves performance in logical reasoning and statistical learning](https://arxiv.org//abs/2411.17304)

	Milena Chadimová, Eduard Jurášek, Tomáš Kliegr

# 2024-11-25
+ [Multi-modal Retrieval Augmented Multi-modal Generation: Datasets, Evaluation Metrics and Strong Baselines](https://arxiv.org//abs/2411.16365)

	Zi-Ao Ma, Tian Lan, Rong-Cheng Tu, Yong Hu, Yu-Shi Zhu, Tong Zhang, Heyan Huang, Zhijing Wu, Xian-Ling Mao

+ [Do Large Language Models Perform Latent Multi-Hop Reasoning without Exploiting Shortcuts?](https://arxiv.org//abs/2411.16679)

	Sohee Yang, Nora Kassner, Elena Gribovskaya, Sebastian Riedel, Mor Geva

+ [Fundamental Limits of Prompt Tuning Transformers: Universality, Capacity and Efficiency](https://arxiv.org//abs/2411.16525)

	Jerry Yao-Chieh Hu, Wei-Po Wang, Ammar Gilani, Chenyang Li, Zhao Song, Han Liu

# 2024-11-22
+ [XGrammar: Flexible and Efficient Structured Generation Engine for Large Language Models](https://arxiv.org//abs/2411.15100)

	Yixin Dong, Charlie F. Ruan, Yaxing Cai, Ruihang Lai, Ziyi Xu, Yilong Zhao, Tianqi Chen

+ [KBAlign: Efficient Self Adaptation on Specific Knowledge Bases](https://arxiv.org//abs/2411.14790)

	Zheni Zeng, Yuxuan Chen, Shi Yu, Ruobing Wang, Yukun Yan, Zhenghao Liu, Shuo Wang, Xu Han, Zhiyuan Liu, Maosong Sun

+ [RE-Bench: Evaluating frontier AI R&D capabilities of language model agents against human experts](https://arxiv.org//abs/2411.15114)

	Hjalmar Wijk, Tao Lin, Joel Becker, Sami Jawhar, Neev Parikh, Thomas Broadley, Lawrence Chan, Michael Chen, Josh Clymer, Jai Dhyani, Elena Ericheva, Katharyn Garcia, Brian Goodrich, Nikola Jurkovic, Holden Karnofsky, Megan Kinniment, Aron Lajko, Seraphina Nix, Lucas Sato, William Saunders, Maksym Taran, Ben West, Elizabeth Barnes

# 2024-11-21
+ [Insight-V: Exploring Long-Chain Visual Reasoning with Multimodal Large Language Models](https://arxiv.org//abs/2411.14432)

	Yuhao Dong, Zuyan Liu, Hai-Long Sun, Jingkang Yang, Winston Hu, Yongming Rao, Ziwei Liu

+ [Enhancing LLMs for Power System Simulations: A Feedback-driven Multi-agent Framework](https://arxiv.org//abs/2411.16707)

	Mengshuo Jia, Zeyu Cui, Gabriela Hug

+ [Velocitune: A Velocity-based Dynamic Domain Reweighting Method for Continual Pre-training](https://arxiv.org//abs/2411.14318)

	Zheheng Luo, Xin Zhang, Xiao Liu, Haoling Li, Yeyun Gong, Chen Qi, Peng Cheng

+ [Planning-Driven Programming: A Large Language Model Programming Workflow](https://arxiv.org//abs/2411.14503)

	Chao Lei, Yanchuan Chang, Nir Lipovetzky, Krista A. Ehinger

+ [FuseGPT: Learnable Layers Fusion of Generative Pre-trained Transformers](https://arxiv.org//abs/2411.14507)

	Zehua Pei, Hui-Ling Zhen, Xianzhi Yu, Sinno Jialin Pan, Mingxuan Yuan, Bei Yu

+ [Natural Language Reinforcement Learning](https://arxiv.org//abs/2411.14251)

	Xidong Feng, Bo Liu, Yan Song, Haotian Fu, Ziyu Wan, Girish A. Koushik, Zhiyuan Hu, Mengyue Yang, Ying Wen, Jun Wang

+ [FastRAG: Retrieval Augmented Generation for Semi-structured Data](https://arxiv.org//abs/2411.13773)

	Amar Abane, Anis Bekri, Abdella Battou, Saddek Bensalem

# 2024-11-20
+ [Disentangling Memory and Reasoning Ability in Large Language Models](https://arxiv.org//abs/2411.13504)

	Mingyu Jin, Weidi Luo, Sitao Cheng, Xinyi Wang, Wenyue Hua, Ruixiang Tang, William Yang Wang, Yongfeng Zhang

+ [MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong Cultural Learning](https://arxiv.org//abs/2411.12977)

	Mircea Lică, Ojas Shirekar, Baptiste Colle, Chirag Raman

# 2024-11-19
+ [The Moral Mind(s) of Large Language Models](https://arxiv.org//abs/2412.04476)

	Avner Seror

+ [ProSec: Fortifying Code LLMs with Proactive Security Alignment](https://arxiv.org//abs/2411.12882)

	Xiangzhe Xu, Zian Su, Jinyao Guo, Kaiyuan Zhang, Zhenting Wang, Xiangyu Zhang

# 2024-11-18
+ [PEEK: Phishing Evolution Framework for Phishing Generation and Evolving Pattern Analysis using Large Language Models](https://arxiv.org//abs/2411.11389)

	Fengchao Chen, Tingmin Wu, Van Nguyen, Shuo Wang, Alsharif Abuadbba, Carsten Rudolph

+ [PSPO*: An Effective Process-supervised Policy Optimization for Reasoning Alignment](https://arxiv.org//abs/2411.11681)

	Jiawei Li, Xinyue Liang, Junlong Zhang, Yizhe Yang, Chong Feng, Yang Gao

+ [VersaTune: An Efficient Data Composition Framework for Training Multi-Capability LLMs](https://arxiv.org//abs/2411.11266)

	Keer Lu, Keshi Zhao, Zhuoran Zhang, Zheng Liang, Da Pan, Shusen Zhang, Xin Wu, Guosheng Dong, Bin Cui, Tengjiao Wang, Wentao Zhang

+ [Steering Language Model Refusal with Sparse Autoencoders](https://arxiv.org//abs/2411.11296)

	Kyle O'Brien, David Majercak, Xavier Fernandes, Richard Edgar, Blake Bullwinkel, Jingya Chen, Harsha Nori, Dean Carignan, Eric Horvitz, Forough Poursabzi-Sangde

+ [Preempting Text Sanitization Utility in Resource-Constrained Privacy-Preserving LLM Interactions](https://arxiv.org//abs/2411.11521)

	Robin Carpentier, Benjamin Zi Hao Zhao, Hassan Jameel Asghar, Dali Kaafar

# 2024-11-17
+ [JailbreakLens: Interpreting Jailbreak Mechanism in the Lens of Representation and Circuit](https://arxiv.org//abs/2411.11114)

	Zeqing He, Zhibo Wang, Zhixuan Chu, Huiyu Xu, Wenhui Zhang, Qinglong Wang, Rui Zheng


+ [SRA-MCTS: Self-driven Reasoning Augmentation with Monte Carlo Tree Search for Code Generation](https://arxiv.org//abs/2411.11053)

	Bin Xu, Yiguan Lin, Yinghao Li, Yang Gao

+ [FastDraft: How to Train Your Draft](https://arxiv.org//abs/2411.11055)

	Ofir Zafrir, Igor Margulis, Dorin Shteyman, Shira Guskin, Guy Boudoukh

+ [INVARLLM: LLM-assisted Physical Invariant Extraction for Cyber-Physical Systems Anomaly Detection](https://arxiv.org//abs/2411.10918)

	Danial Abshari, Peiran Shi, Chenglong Fu, Meera Sridhar, Xiaojiang Du

+ [Debiasing Watermarks for Large Language Models via Maximal Coupling](https://arxiv.org//abs/2411.11203)

	Yangxinyu Xie, Xiang Li, Tanwi Mallick, Weijie J. Su, Ruixun Zhang

# 2024-11-15
+ [P$^2$ Law: Scaling Law for Post-Training After Model Pruning](https://arxiv.org//abs/2411.10272)

	Xiaodong Chen, Yuxuan Hu, Xiaokang Zhang, Yanling Wang, Cuiping Li, Hong Chen, Jing Zhang

+ [AMXFP4: Taming Activation Outliers with Asymmetric Microscaling Floating-Point for 4-bit LLM Inference](https://arxiv.org//abs/2411.09909)

	Janghwan Lee, Jiwoong Park, Jinseok Kim, Yongjik Kim, Jungju Oh, Jinwook Oh, Jungwook Choi

# 2024-11-14
+ [Rethinking Weight-Averaged Model-merging](https://arxiv.org//abs/2411.09263)

	Hu Wang, Congbo Ma, Ibrahim Almakky, Ian Reid, Gustavo Carneiro, Mohammad Yaqub

+ [Probing LLM Hallucination from Within: Perturbation-Driven Approach via Internal Knowledge](https://arxiv.org//abs/2411.09689)

	Seongmin Lee, Hsiang Hsu, Chun-Fu Chen, Duen Horng (Polo)Chau

+ [Real-time Adapting Routing (RAR): Improving Efficiency Through Continuous Learning in Software Powered by Layered Foundation Models](https://arxiv.org//abs/2411.09837)

	Kirill Vasilevski, Dayi Lin, Ahmed E. Hassan

+ [Squeezed Attention: Accelerating Long Context Length LLM Inference](https://arxiv.org//abs/2411.09688)

	Coleman Hooper, Sehoon Kim, Hiva Mohammadzadeh, Monishwaran Maheswaran, Sebastian Zhao, June Paik, Michael W. Mahoney, Kurt Keutzer, Amir Gholami

# 2024-11-12
+ [Knowledge-Augmented Multimodal Clinical Rationale Generation for Disease Diagnosis with Small Language Models](https://arxiv.org//abs/2411.07611)

	Shuai Niu, Jing Ma, Hongzhan Lin, Liang Bai, Zhihua Wang, Yida Xu, Yunya Song, Xian Yang

+ [Beyond the Safety Bundle: Auditing the Helpful and Harmless Dataset](https://arxiv.org//abs/2411.08243)

	Khaoula Chehbouni, Jonathan Colaço Carr, Yash More, Jackie CK Cheung, Golnoosh Farnadi

+ [Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for Knowledge Graph Completion](https://arxiv.org//abs/2411.08165)

	Muzhi Li, Cehao Yang, Chengjin Xu, Xuhui Jiang, Yiyan Qi, Jian Guo, Ho-fung Leung, Irwin King

+ [ImageRAG: Enhancing Ultra High Resolution Remote Sensing Imagery Analysis with ImageRAG](https://arxiv.org//abs/2411.07688)

	Zilun Zhang, Haozhan Shen, Tiancheng Zhao, Zian Guan, Bin Chen, Yuhao Wang, Xu Jia, Yuxiang Cai, Yongheng Shang, Jianwei Yin

+ [Entropy Controllable Direct Preference Optimization](https://arxiv.org//abs/2411.07595)

	Motoki Omura, Yasuhiro Fujita, Toshiki Kataoka

# 2024-11-11
+ [ChemToolAgent: The Impact of Tools on Language Agents for Chemistry Problem Solving](https://arxiv.org//abs/2411.07228)

	Botao Yu, Frazier N. Baker, Ziru Chen, Garrett Herb, Boyu Gou, Daniel Adu-Ampratwum, Xia Ning, Huan Sun

+ [Contextualized Evaluations: Judging Language Model Responses to Underspecified Queries](https://arxiv.org//abs/2411.07237)

	Chaitanya Malaviya, Joseph Chee Chang, Dan Roth, Mohit Iyyer, Mark Yatskar, Kyle Lo

+ [Controllable Context Sensitivity and the Knob Behind It](https://arxiv.org//abs/2411.07404)

	Julian Minder, Kevin Du, Niklas Stoehr, Giovanni Monea, Chris Wendler, Robert West, Ryan Cotterell

+ [Combining Domain and Alignment Vectors to Achieve Better Knowledge-Safety Trade-offs in LLMs](https://arxiv.org//abs/2411.06824)

	Megh Thakkar, Quentin Fournier, Matthew Riemer, Pin-Yu Chen, Amal Zouaq, Payel Das, Sarath Chandar

+ [On Many-Shot In-Context Learning for Long-Context Evaluation](https://arxiv.org//abs/2411.07130)

	Kaijian Zou, Muhammad Khalifa, Lu Wang

# 2024-11-10
+ [An Efficient Matrix Multiplication Algorithm for Accelerating Inference in Binary and Ternary Neural Networks](https://arxiv.org//abs/2411.06360)

	Mohsen Dehghankar, Mahdi Erfanian, Abolfazl Asudeh

# 2024-11-09
+ [A Picture is Worth A Thousand Numbers: Enabling LLMs Reason about Time Series via Visualization](https://arxiv.org//abs/2411.06018)

	Haoxin Liu, Chenghao Liu, B. Aditya Prakash

# 2024-11-08
+ [LLM-PySC2: Starcraft II learning environment for Large Language Models](https://arxiv.org//abs/2411.05348)

	Zongyuan Li, Yanan Ni, Runnan Qi, Lumin Jiang, Chang Lu, Xiaojie Xu, Xiangbei Liu, Pengfei Li, Yunzheng Guo, Zhe Ma, Huanyu Li, Hui Wu, Xian Guo, Kuihua Huang, Xuebo Zhang

+ [FactLens: Benchmarking Fine-Grained Fact Verification](https://arxiv.org//abs/2411.05980)

	Kushan Mitra, Dan Zhang, Sajjadur Rahman, Estevam Hruschka

# 2024-11-07
+ [Prompt-Guided Internal States for Hallucination Detection of Large Language Models](https://arxiv.org//abs/2411.04847)

	Fujie Zhang, Peiqi Yu, Biao Yi, Baolei Zhang, Tong Li, Zheli Liu

# 2024-11-06
+ [LSHBloom: Memory-efficient, Extreme-scale Document Deduplication](https://arxiv.org//abs/2411.04257)

	Arham Khan, Robert Underwood, Carlo Siebenschuh, Yadu Babuji, Aswathy Ajith, Kyle Hippe, Ozan Gokdemir, Alexander Brace, Kyle Chard, Ian Foster

# 2024-11-05
+ [Benchmarking Multimodal Retrieval Augmented Generation with Dynamic VQA Dataset and Self-adaptive Planning Agent](https://arxiv.org//abs/2411.02937)

	Yangning Li, Yinghui Li, Xinyu Wang, Yong Jiang, Zhen Zhang, Xinran Zheng, Hui Wang, Hai-Tao Zheng, Philip S. Yu, Fei Huang, Jingren Zhou

# 2024-11-04
+ [Sparsing Law: Towards Large Language Models with Greater Activation Sparsity](https://arxiv.org//abs/2411.02335)

	Yuqi Luo, Chenyang Song, Xu Han, Yingfa Chen, Chaojun Xiao, Zhiyuan Liu, Maosong Sun

+ ["Give Me BF16 or Give Me Death"? Accuracy-Performance Trade-Offs in LLM Quantization](https://arxiv.org//abs/2411.02355)

	Eldar Kurtic, Alexandre Marques, Shubhra Pandit, Mark Kurtz, Dan Alistarh

+ [Foundations and Recent Trends in Multimodal Mobile Agents: A Survey](https://arxiv.org//abs/2411.02006)

	Biao Wu, Yanda Li, Yunchao Wei, Meng Fang, Ling Chen

+ [Code-Switching Curriculum Learning for Multilingual Transfer in LLMs](https://arxiv.org//abs/2411.02460)

	Haneul Yoo, Cheonbok Park, Sangdoo Yun, Alice Oh, Hwaran Lee

# 2024-11-03
+ [Enhancing LLM Evaluations: The Garbling Trick](https://arxiv.org//abs/2411.01533)

	William F. Bradley

+ [Rate, Explain and Cite (REC): Enhanced Explanation and Attribution in Automatic Evaluation by Large Language Models](https://arxiv.org//abs/2411.02448)

	Aliyah R. Hsu, James Zhu, Zhichao Wang, Bin Bi, Shubham Mehrotra, Shiva K. Pentyala, Katherine Tan, Xiang-Bo Mao, Roshanak Omrani, Sougata Chaudhuri, Regunathan Radhakrishnan, Sitaram Asur, Claire Na Cheng, Bin Yu

+ [Graph-based Confidence Calibration for Large Language Models](https://arxiv.org//abs/2411.02454)

	Yukun Li, Sijia Wang, Lifu Huang, Li-Ping Liu

+ [Autoformulation of Mathematical Optimization Models Using LLMs](https://arxiv.org//abs/2411.01679)

	Nicolás Astorga, Tennison Liu, Yuanzhang Xiao, Mihaela van der Schaar

# 2024-11-01
+ [E2E-AFG: An End-to-End Model with Adaptive Filtering for Retrieval-Augmented Generation](https://arxiv.org//abs/2411.00437)

	Yun Jiang, Zilong Xie, Wei Zhang, Yun Fang, Shuai Pan

+ [Phase Diagram of Vision Large Language Models Inference: A Perspective from Interaction across Image and Instruction](https://arxiv.org//abs/2411.00646)

	Houjing Wei, Yuting Shi, Naoya Inoue

+ [STEM-POM: Evaluating Language Models Math-Symbol Reasoning in Document Parsing](https://arxiv.org//abs/2411.00387)

	Jiaru Zou, Qing Wang, Pratyush Thakur, Nickvash Kani

# 2024-10-31
+ [AlphaTrans: A Neuro-Symbolic Compositional Approach for Repository-Level Code Translation and Validation](https://arxiv.org//abs/2410.24117)

	Ali Reza Ibrahimzada, Kaiyao Ke, Mrigank Pawagi, Muhammad Salman Abid, Rangeet Pan, Saurabh Sinha, Reyhaneh Jabbarvand

+ [Constraint Back-translation Improves Complex Instruction Following of Large Language Models](https://arxiv.org//abs/2410.24175)

	Yunjia Qi, Hao Peng, Xiaozhi Wang, Bin Xu, Lei Hou, Juanzi Li

+ [RESTOR: Knowledge Recovery in Machine Unlearning](https://arxiv.org//abs/2411.00204)

	Keivan Rezaei, Khyathi Chandu, Soheil Feizi, Yejin Choi, Faeze Brahman, Abhilasha Ravichander

+ [Length-Induced Embedding Collapse in PLM-based Models](https://arxiv.org//abs/2410.24200)

	Yuqi Zhou, Sunhao Dai, Zhanshuo Cao, Xiao Zhang, Jun Xu

# 2024-10-30
+ [MDCure: A Scalable Pipeline for Multi-Document Instruction-Following](https://arxiv.org//abs/2410.23463)

	Gabrielle Kaili-May Liu, Bowen Shi, Avi Caciularu, Idan Szpektor, Arman Cohan

+ [GWQ: Gradient-Aware Weight Quantization for Large Language Models](https://arxiv.org//abs/2411.00850)

	Yihua Shao, Yan Gu, Siyu Chen, Haiyang Liu, Zixian Zhu, Zijian Ling, Minxi Yan, Ziyang Yan, Chenyu Zhang, Michele Magno, Haotong Qin, Yan Wang, Jingcai Guo, Ling Shao, Hao Tang

+ [Focus On This, Not That! Steering LLMs with Adaptive Feature Specification](https://arxiv.org//abs/2410.22944)

	Tom A. Lamb, Adam Davies, Alasdair Paren, Philip H.S. Torr, Francesco Pinto

# 2024-10-29
+ [Personalization of Large Language Models: A Survey](https://arxiv.org//abs/2411.00027)

	Zhehao Zhang, Ryan A. Rossi, Branislav Kveton, Yijia Shao, Diyi Yang, Hamed Zamani, Franck Dernoncourt, Joe Barrow, Tong Yu, Sungchul Kim, Ruiyi Zhang, Jiuxiang Gu, Tyler Derr, Hongjie Chen, Junda Wu, Xiang Chen, Zichao Wang, Subrata Mitra, Nedim Lipka, Nesreen Ahmed, Yu Wang

+ [Unlearning as multi-task optimization: A normalized gradient difference approach with an adaptive learning rate](https://arxiv.org//abs/2410.22086)

	Zhiqi Bu, Xiaomeng Jin, Bhanukiran Vinzamuri, Anil Ramakrishna, Kai-Wei Chang, Volkan Cevher, Mingyi Hong

+ [Vision-Language Models Create Cross-Modal Task Representations](https://arxiv.org//abs/2410.22330)

	Grace Luo, Trevor Darrell, Amir Bar

+ [SceneGenAgent: Precise Industrial Scene Generation with Coding Agent](https://arxiv.org//abs/2410.21909)

	Xiao Xia, Dan Zhang, Zibo Liao, Zhenyu Hou, Tianrui Sun, Jing Li, Ling Fu, Yuxiao Dong

+ [Let's Be Self-generated via Step by Step: A Curriculum Learning Approach to Automated Reasoning with Large Language Models](https://arxiv.org//abs/2410.21728)

	Kangyang Luo, Zichen Ding, Zhenmin Weng, Lingfeng Qiao, Meng Zhao, Xiang Li, Di Yin, Jinlong Shu

+ [Understanding Synthetic Context Extension via Retrieval Heads](https://arxiv.org//abs/2410.22316)

	Xinyu Zhao, Fangcong Yin, Greg Durrett

+ [AAAR-1.0: Assessing AI's Potential to Assist Research](https://arxiv.org//abs/2410.22394)

	Renze Lou, Hanzi Xu, Sijia Wang, Jiangshu Du, Ryo Kamoi, Xiaoxin Lu, Jian Xie, Yuxuan Sun, Yusen Zhang, Jihyun Janice Ahn, Hongchao Fang, Zhuoyang Zou, Wenchao Ma, Xi Li, Kai Zhang, Congying Xia, Lifu Huang, Wenpeng Yin

+ [The Impact of Inference Acceleration on Bias of LLMs](https://arxiv.org//abs/2410.22118)

	Elisabeth Kirsten, Ivan Habernal, Vedant Nanda, Muhammad Bilal Zafar

# 2024-10-28
+ [Are LLM-Judges Robust to Expressions of Uncertainty? Investigating the effect of Epistemic Markers on LLM-based Evaluation](https://arxiv.org//abs/2410.20774)

	Dongryeol Lee, Yerin Hwang, Yongil Kim, Joonsuk Park, Kyomin Jung

+ [Arithmetic Without Algorithms: Language Models Solve Math With a Bag of Heuristics](https://arxiv.org//abs/2410.21272)

	Yaniv Nikankin, Anja Reusch, Aaron Mueller, Yonatan Belinkov

+ [Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning](https://arxiv.org//abs/2410.20926)

	Aosong Feng, Rex Ying, Leandros Tassiulas

# 2024-10-27
+ [TrajAgent: An LLM-based Agent Framework for Automated Trajectory Modeling via Collaboration of Large and Small Models](https://arxiv.org//abs/2410.20445)

	Yuwei Du, Jie Feng, Jie Zhao, Yong Li

# 2024-10-26
+ [Agentic Feedback Loop Modeling Improves Recommendation and User Simulation](https://arxiv.org//abs/2410.20027)

	Shihao Cai, Jizhi Zhang, Keqin Bao, Chongming Gao, Qifan Wang, Fuli Feng, Xiangnan He

+ [AutoMIR: Effective Zero-Shot Medical Information Retrieval without Relevance Labels](https://arxiv.org//abs/2410.20050)

	Lei Li, Xiangxu Zhang, Xiao Zhou, Zheng Liu

# 2024-10-25
+ [Can We Trust AI Agents? A Case Study of an LLM-Based Multi-Agent System for Ethical AI](https://arxiv.org//abs/2411.08881)

	José Antonio Siqueira de Cerqueira, Mamia Agbese, Rebekah Rousi, Nannan Xi, Juho Hamari, Pekka Abrahamsson

+ [ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Contrastive Framework](https://arxiv.org//abs/2410.19453)

	Hengyuan Zhang, Chenming Shang, Sizhe Wang, Dongdong Zhang, Feng Yao, Renliang Sun, Yiyao Yu, Yujiu Yang, Furu Wei

+ [FairMT-Bench: Benchmarking Fairness for Multi-turn Dialogue in Conversational LLMs](https://arxiv.org//abs/2410.19317)

	Zhiting Fan, Ruizhe Chen, Tianxiang Hu, Zuozhu Liu

+ [An Auditing Test To Detect Behavioral Shift in Language Models](https://arxiv.org//abs/2410.19406)

	Leo Richter, Xuanli He, Pasquale Minervini, Matt J. Kusner

# 2024-10-24
+ [Parameter-Efficient Fine-Tuning in Large Models: A Survey of Methodologies](https://arxiv.org//abs/2410.19878)

	Luping Wang, Sheng Chen, Linnan Jiang, Shu Pan, Runze Cai, Sen Yang, Fei Yang

+ [Hybrid Preferences: Learning to Route Instances for Human vs. AI Feedback](https://arxiv.org//abs/2410.19133)

	Lester James V. Miranda, Yizhong Wang, Yanai Elazar, Sachin Kumar, Valentina Pyatkin, Faeze Brahman, Noah A. Smith, Hannaneh Hajishirzi, Pradeep Dasigi

+ [Unleashing LLM Reasoning Capability via Scalable Question Synthesis from Scratch](https://arxiv.org//abs/2410.18693)

	Yuyang Ding, Xinyu Shi, Xiaobo Liang, Juntao Li, Zhaopeng Tu, Qiaoming Zhu, Min Zhang

+ [The Stepwise Deception: Simulating the Evolution from True News to Fake News with LLM Agents](https://arxiv.org//abs/2410.19064)

	Yuhan Liu, Zirui Song, Juntian Zhang, Xiaoqing Zhang, Xiuying Chen, Rui Yan

+ [Can Code-Switched Texts Activate a Knowledge Switch in LLMs? A Case Study on English-Korean Code-Switching](https://arxiv.org//abs/2410.18436)

	Seoyeon Kim, Huiseo Kim, Chanjun Park, Jinyoung Yeo, Dongha Lee

+ [Improving Model Factuality with Fine-grained Critique-based Evaluator](https://arxiv.org//abs/2410.18359)

	Yiqing Xie, Wenxuan Zhou, Pradyot Prakash, Di Jin, Yuning Mao, Quintin Fettes, Arya Talebzadeh, Sinong Wang, Han Fang, Carolyn Rose, Daniel Fried, Hejia Zhang

# 2024-10-23
+ [CogSteer: Cognition-Inspired Selective Layer Intervention for Efficiently Steering Large Language Models](https://arxiv.org//abs/2410.17714)

	Xintong Wang, Jingheng Pan, Liang Ding, Longyue Wang, Longqin Jiang, Xingshan Li, Chris Biemann

+ [CLEAR: Character Unlearning in Textual and Visual Modalities](https://arxiv.org//abs/2410.18057)

	Alexey Dontsov, Dmitrii Korzh, Alexey Zhavoronkin, Boris Mikheev, Denis Bobkov, Aibek Alanov, Oleg Y. Rogov, Ivan Oseledets, Elena Tutubalina

+ [ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents](https://arxiv.org//abs/2410.17657)

	Yusheng Liao, Shuyang Jiang, Yanfeng Wang, Yu Wang

# 2024-10-22
+ [Do Robot Snakes Dream like Electric Sheep? Investigating the Effects of Architectural Inductive Biases on Hallucination](https://arxiv.org//abs/2410.17477)

	Jerry Huang, Prasanna Parthasarathi, Mehdi Rezagholizadeh, Boxing Chen, Sarath Chandar

+ [SaVe-TAG: Semantic-aware Vicinal Risk Minimization for Long-Tailed Text-Attributed Graphs](https://arxiv.org//abs/2410.16882)

	Leyao Wang, Yu Wang, Bo Ni, Yuying Zhao, Hanyu Wang, Yao Ma, Tyler Derr

+ [SafetyAnalyst: Interpretable, Transparent, and Steerable Safety Moderation for AI Behavior](https://arxiv.org//abs/2410.16665)

	Jing-Jing Li, Valentina Pyatkin, Max Kleiman-Weiner, Liwei Jiang, Nouha Dziri, Anne G. E. Collins, Jana Schaich Borg, Maarten Sap, Yejin Choi, Sydney Levine

+ [Math Neurosurgery: Isolating Language Models' Math Reasoning Abilities Using Only Forward Passes](https://arxiv.org//abs/2410.16930)

	Bryan R. Christ, Zack Gottesman, Jonathan Kropko, Thomas Hartvigsen

+ [Self-Steering Optimization: Autonomous Preference Optimization for Large Language Models](https://arxiv.org//abs/2410.17131)

	Hao Xiang, Bowen Yu, Hongyu Lin, Keming Lu, Yaojie Lu, Xianpei Han, Ben He, Le Sun, Jingren Zhou, Junyang Lin

# 2024-10-21
+ [Long Term Memory: The Foundation of AI Self-Evolution](https://arxiv.org//abs/2410.15665)

	Xun Jiang, Feng Li, Han Zhao, Jiahao Qiu, Jiaying Wang, Jun Shao, Shihao Xu, Shu Zhang, Weiling Chen, Xavier Tang, Yize Chen, Mengyue Wu, Weizhi Ma, Mengdi Wang, Tianqiao Chen

+ [Training of Scaffolded Language Models with Language Supervision: A Survey](https://arxiv.org//abs/2410.16392)

	Matthieu Lin, Jenny Sheng, Andrew Zhao, Shenzhi Wang, Yang Yue, Victor Shea Jay Huang, Huan Liu, Jun Liu, Gao Huang, Yong-Jin Liu

+ [Security of Language Models for Code: A Systematic Literature Review](https://arxiv.org//abs/2410.15631)

	Yuchen Chen, Weisong Sun, Chunrong Fang, Zhenpeng Chen, Yifei Ge, Tingxu Han, Quanjun Zhang, Yang Liu, Zhenyu Chen, Baowen Xu

+ [Exploring Pretraining via Active Forgetting for Improving Cross Lingual Transfer for Decoder Language Models](https://arxiv.org//abs/2410.16168)

	Divyanshu Aggarwal, Ashutosh Sathe, Sunayana Sitaram

+ [When LLMs Learn to be Students: The SOEI Framework for Modeling and Evaluating Virtual Student Agents in Educational Interaction](https://arxiv.org//abs/2410.15701)

	Yiping Ma, Shiyu Hu, Xuchen Li, Yipei Wang, Yuqing Chen, Shiqing Liu, Kang Hao Cheong

+ [On The Global Convergence Of Online RLHF With Neural Parametrization](https://arxiv.org//abs/2410.15610)

	Mudit Gaur, Amrit Singh Bedi, Raghu Pasupathy, Vaneet Aggarwal

+ [RULEBREAKERS: Challenging LLMs at the Crossroads between Formal Logic and Human-like Reasoning](https://arxiv.org//abs/2410.16502)

	Jason Chan, Robert Gaizauskas, Zhixue Zhao

+ [Reflection-Bench: Evaluating Epistemic Agency in Large Language Models](https://arxiv.org//abs/2410.16270)

	Lingyu Li, Yixu Wang, Haiquan Zhao, Shuqi Kong, Yan Teng, Chunbo Li, Yingchun Wang

# 2024-10-19
+ [TrendFact: A Benchmark for Explainable Hotspot Perception in Fact-Checking with Natural Language Explanation](https://arxiv.org//abs/2410.15135)

	Xiaocheng Zhang, Xi Wang, Yifei Lu, Jianing Wang, Zhuangzhuang Ye, Mengjiao Bao, Peng Yan, Xiaohong Su

# 2024-10-18
+ [ELOQ: Resources for Enhancing LLM Detection of Out-of-Scope Questions](https://arxiv.org//abs/2410.14567)

	Zhiyuan Peng, Jinming Nian, Alexandre Evfimievski, Yi Fang

+ [Electrocardiogram-Language Model for Few-Shot Question Answering with Meta Learning](https://arxiv.org//abs/2410.14464)

	Jialu Tang, Tong Xia, Yuan Lu, Cecilia Mascolo, Aaqib Saeed

+ [DiSCo: LLM Knowledge Distillation for Efficient Sparse Retrieval in Conversational Search](https://arxiv.org//abs/2410.14609)

	Simon Lupart, Mohammad Aliannejadi, Evangelos Kanoulas

+ [Distance between Relevant Information Pieces Causes Bias in Long-Context LLMs](https://arxiv.org//abs/2410.14641)

	Runchu Tian, Yanghao Li, Yuepeng Fu, Siyang Deng, Qinyu Luo, Cheng Qian, Shuo Wang, Xin Cong, Zhong Zhang, Yesai Wu, Yankai Lin, Huadong Wang, Xiaojiang Liu

+ [LoGU: Long-form Generation with Uncertainty Expressions](https://arxiv.org//abs/2410.14309)

	Ruihan Yang, Caiqi Zhang, Zhisong Zhang, Xinting Huang, Sen Yang, Nigel Collier, Dong Yu, Deqing Yang

+ [How Do Multilingual Language Models Remember Facts?](https://arxiv.org//abs/2410.14387)

	Constanza Fierro, Negar Foroutan, Desmond Elliott, Anders Søgaard

# 2024-10-17
+ [MobA: Multifaceted Memory-Enhanced Adaptive Planning for Efficient Mobile Task Automation](https://arxiv.org//abs/2410.13757)

	Zichen Zhu, Hao Tang, Yansi Li, Dingye Liu, Hongshen Xu, Kunyao Lan, Danyang Zhang, Yixuan Jiang, Hao Zhou, Chenrun Wang, Situo Zhang, Liangtai Sun, Yixiao Wang, Yuheng Sun, Lu Chen, Kai Yu

+ [How Does Knowledge Selection Help Retrieval Augmented Generation?](https://arxiv.org//abs/2410.13258)

	Xiangci Li, Jessica Ouyang

+ [The Mystery of the Pathological Path-star Task for Language Models](https://arxiv.org//abs/2410.13779)

	Arvid Frydenlund

+ [Retrospective Learning from Interactions](https://arxiv.org//abs/2410.13852)

	Zizhao Chen, Mustafa Omer Gul, Yiwei Chen, Gloria Geng, Anne Wu, Yoav Artzi

+ [MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling](https://arxiv.org//abs/2410.13610)

	Yakun Zhu, Shaohang Wei, Xu Wang, Kui Xue, Xiaofan Zhang, Shaoting Zhang

+ [AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents](https://arxiv.org//abs/2410.13825)

	Ke Yang, Yao Liu, Sapana Chaudhary, Rasool Fakoor, Pratik Chaudhari, George Karypis, Huzefa Rangwala

+ [SynapticRAG: Enhancing Temporal Memory Retrieval in Large Language Models through Synaptic Mechanisms](https://arxiv.org//abs/2410.13553)

	Yuki Hou, Haruki Tamoto, Qinghua Zhao, Homei Miyashita

+ [Aggregation Artifacts in Subjective Tasks Collapse Large Language Models' Posteriors](https://arxiv.org//abs/2410.13776)

	Georgios Chochlakis, Alexandros Potamianos, Kristina Lerman, Shrikanth Narayanan

+ [Router-Tuning: A Simple and Effective Approach for Enabling Dynamic-Depth in Transformers](https://arxiv.org//abs/2410.13184)

	Shwai He, Tao Ge, Guoheng Sun, Bowei Tian, Xiaoyang Wang, Dong Yu

+ [An Online Learning Approach to Prompt-based Selection of Generative Models and LLMs](https://arxiv.org//abs/2410.13287)

	Xiaoyan Hu, Ho-fung Leung, Farzan Farnia

+ [Sparse Mixture-of-Experts for Compositional Generalization: Empirical Evidence and Theoretical Foundations of Optimal Sparsity](https://arxiv.org//abs/2410.13964)

	Jinze Zhao, Peihao Wang, Junjie Yang, Ruisi Cai, Gaowen Liu, Jayanth Srinivasa, Ramana Rao Kompella, Yingbin Liang, Zhangyang Wang

# 2024-10-16
+ [TradExpert: Revolutionizing Trading with Mixture of Expert LLMs](https://arxiv.org//abs/2411.00782)

	Qianggang Ding, Haochen Shi, Jiadong Guo, Bang Liu

+ [MatryoshkaKV: Adaptive KV Compression via Trainable Orthogonal Projection](https://arxiv.org//abs/2410.14731)

	Bokai Lin, Zihao Zeng, Zipeng Xiao, Siqi Kou, Tianqi Hou, Xiaofeng Gao, Hao Zhang, Zhijie Deng

+ [Interpreting token compositionality in LLMs: A robustness analysis](https://arxiv.org//abs/2410.12924)

	Nura Aljaafari, Danilo S. Carvalho, André Freitas

+ [Meta-Chunking: Learning Text Segmentation and Semantic Completion via Logical Perception](https://arxiv.org//abs/2410.12788)

	Jihao Zhao, Zhiyuan Ji, Yuchen Feng, Pengnian Qi, Simin Niu, Bo Tang, Feiyu Xiong, Zhiyu Li

+ [KCIF: Knowledge-Conditioned Instruction Following](https://arxiv.org//abs/2410.12972)

	Rudra Murthy, Praveen Venkateswaran, Prince Kumar, Danish Contractor

+ [Reversal of Thought: Enhancing Large Language Models with Preference-Guided Reverse Reasoning Warm-up](https://arxiv.org//abs/2410.12323)

	Jiahao Yuan, Dehui Du, Hao Zhang, Zixiang Di, Usman Naseem

+ [Conformity in Large Language Models](https://arxiv.org//abs/2410.12428)

	Xiaochen Zhu, Caiqi Zhang, Tom Stafford, Nigel Collier, Andreas Vlachos

+ [Graph-constrained Reasoning: Faithful Reasoning on Knowledge Graphs with Large Language Models](https://arxiv.org//abs/2410.13080)

	Linhao Luo, Zicheng Zhao, Gholamreza Haffari, Yuan-Fang Li, Chen Gong, Shirui Pan

+ [Personality-Guided Code Generation Using Large Language Models](https://arxiv.org//abs/2411.00006)

	Yaoqi Guo, Zhenpeng Chen, Jie M. Zhang, Yang Liu, Yun Ma

+ [BenchmarkCards: Large Language Model and Risk Reporting](https://arxiv.org//abs/2410.12974)

	Anna Sokol, Elizabeth Daly, Michael Hind, David Piorkowski, Xiangliang Zhang, Nuno Moniz, Nitesh Chawla

+ [Exploring Model Kinship for Merging Large Language Models](https://arxiv.org//abs/2410.12613)

	Yedi Hu, Yunzhi Yao, Shumin Deng, Huajun Chen, Ningyu Zhang

+ [Communication-Efficient and Tensorized Federated Fine-Tuning of Large Language Models](https://arxiv.org//abs/2410.13097)

	Sajjad Ghiasvand, Yifan Yang, Zhiyu Xue, Mahnoosh Alizadeh, Zheng Zhang, Ramtin Pedarsani

+ [POROver: Improving Safety and Reducing Overrefusal in Large Language Models with Overgeneration and Preference Optimization](https://arxiv.org//abs/2410.12999)

	Batuhan K. Karaman, Ishmam Zabir, Alon Benhaim, Vishrav Chaudhary, Mert R. Sabuncu, Xia Song

# 2024-10-15
+ [MIND: Math Informed syNthetic Dialogues for Pretraining LLMs](https://arxiv.org//abs/2410.12881)

	Syeda Nahida Akter, Shrimai Prabhumoye, John Kamalu, Sanjeev Satheesh, Eric Nyberg, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro

+ [TopoLM: brain-like spatio-functional organization in a topographic language model](https://arxiv.org//abs/2410.11516)

	Neil Rathi, Johannes Mehrer, Badr AlKhamissi, Taha Binhuraib, Nicholas M. Blauch, Martin Schrimpf

+ [TestAgent: A Framework for Domain-Adaptive Evaluation of LLMs via Dynamic Benchmark Construction and Exploratory Interaction](https://arxiv.org//abs/2410.11507)

	Wanying Wang, Zeyu Ma, Pengfei Liu, Mingang Chen

+ [RATE: Causal Explainability of Reward Models with Imperfect Counterfactuals](https://arxiv.org//abs/2410.11348)

	David Reber, Sean Richardson, Todd Nief, Cristina Garbacea, Victor Veitch

+ [MoH: Multi-Head Attention as Mixture-of-Head Attention](https://arxiv.org//abs/2410.11842)

	Peng Jin, Bo Zhu, Li Yuan, Shuicheng Yan

# 2024-10-14
+ [A Unified Approach to Routing and Cascading for LLMs](https://arxiv.org//abs/2410.10347)

	Jasper Dekoninck, Maximilian Baader, Martin Vechev

+ [TMGBench: A Systematic Game Benchmark for Evaluating Strategic Reasoning Abilities of LLMs](https://arxiv.org//abs/2410.10479)

	Haochuan Wang, Xiachong Feng, Lei Li, Yu Guo, Zhanyue Qin, Dianbo Sui, Lingpeng Kong

+ [Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs](https://arxiv.org//abs/2410.11001)

	Haozhen Zhang, Tao Feng, Jiaxuan You

+ [RoCoFT: Efficient Finetuning of Large Language Models with Row-Column Updates](https://arxiv.org//abs/2410.10075)

	Md Kowsher, Tara Esmaeilbeig, Chun-Nam Yu, Chen Chen, Mojtaba Soltanalian, Niloofar Yousefi

+ [Not All Options Are Created Equal: Textual Option Weighting for Token-Efficient LLM-Based Knowledge Tracing](https://arxiv.org//abs/2410.12872)

	JongWoo Kim, SeongYeub Chu, Bryan Wong, Mun Yi

+ [Persistent Topological Features in Large Language Models](https://arxiv.org//abs/2410.11042)

	Yuri Gardinazzi, Karthik Viswanathan, Giada Panerai, Alessio Ansuini, Alberto Cazzaniga, Matteo Biagetti

# 2024-10-13
+ [Self-Data Distillation for Recovering Quality in Pruned Large Language Models](https://arxiv.org//abs/2410.09982)

	Vithursan Thangarasa, Ganesh Venkatesh, Mike Lasby, Nish Sinnadurai, Sean Lie

# 2024-10-12
+ [Inference and Verbalization Functions During In-Context Learning](https://arxiv.org//abs/2410.09349)

	Junyi Tao, Xiaoyin Chen, Nelson F. Liu

+ [Keys to Robust Edits: from Theoretical Insights to Practical Advances](https://arxiv.org//abs/2410.09338)

	Jianhao Yan, Futing Wang, Yun Luo, Yafu Li, Yue Zhang

+ [Many Heads Are Better Than One: Improved Scientific Idea Generation by A LLM-Based Multi-Agent System](https://arxiv.org//abs/2410.09403)

	Haoyang Su, Renqi Chen, Shixiang Tang, Zhenfei Yin, Xinzhe Zheng, Jinzhe Li, Biqing Qi, Qi Wu, Hui Li, Wanli Ouyang, Philip Torr, Bowen Zhou, Nanqing Dong

# 2024-10-11
+ [Emergent social conventions and collective bias in LLM populations](https://arxiv.org//abs/2410.08948)

	Ariel Flint Ashery, Luca Maria Aiello, Andrea Baronchelli

+ [DAWN: Designing Distributed Agents in a Worldwide Network](https://arxiv.org//abs/2410.22339)

	Zahra Aminiranjbar, Jianan Tang, Qiudan Wang, Shubha Pant, Mahesh Viswanathan

# 2024-10-10
+ [Extracting and Transferring Abilities For Building Multi-lingual Ability-enhanced Large Language Models](https://arxiv.org//abs/2410.07825)

	Zhipeng Chen, Kun Zhou, Liang Song, Wayne Xin Zhao, Bingning Wang, Weipeng Chen, Ji-Rong Wen

+ [A Closer Look at Machine Unlearning for Large Language Models](https://arxiv.org//abs/2410.08109)

	Xiaojian Yuan, Tianyu Pang, Chao Du, Kejiang Chen, Weiming Zhang, Min Lin

+ [Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study Over Open-ended Question Answering](https://arxiv.org//abs/2410.08085)

	Yuan Sui, Yufei He, Zifeng Ding, Bryan Hooi

+ [Insight Over Sight: Exploring the Vision-Knowledge Conflicts in Multimodal LLMs](https://arxiv.org//abs/2410.08145)

	Xiaoyuan Liu, Wenxuan Wang, Youliang Yuan, Jen-tse Huang, Qiuzhi Liu, Pinjia He, Zhaopeng Tu

+ [Upcycling Large Language Models into Mixture of Experts](https://arxiv.org//abs/2410.07524)

	Ethan He, Abhinav Khattar, Ryan Prenger, Vijay Korthikanti, Zijie Yan, Tong Liu, Shiqing Fan, Ashwath Aithal, Mohammad Shoeybi, Bryan Catanzaro

+ [Accurate and Regret-aware Numerical Problem Solver for Tabular Question Answering](https://arxiv.org//abs/2410.12846)

	Yuxiang Wang, Jianzhong Qi, Junhao Gan

+ [Mind the Gap: a Spectral Analysis of Rank Collapse and Signal Propagation in Attention Layers](https://arxiv.org//abs/2410.07799)

	Thiziri Nait Saada, Alireza Naderi, Jared Tanner

# 2024-10-09
+ [Let's Ask GNN: Empowering Large Language Model for Graph In-Context Learning](https://arxiv.org//abs/2410.07074)

	Zhengyu Hu, Yichuan Li, Zhengyu Chen, Jingang Wang, Han Liu, Kyumin Lee, Kaize Ding

+ [Steering Large Language Models using Conceptors: Improving Addition-Based Activation Engineering](https://arxiv.org//abs/2410.16314)

	Joris Postmus, Steven Abreu

+ [CursorCore: Assist Programming through Aligning Anything](https://arxiv.org//abs/2410.07002)

	Hao Jiang, Qi Liu, Rui Li, Shengyu Ye, Shijin Wang

+ [ST-WebAgentBench: A Benchmark for Evaluating Safety and Trustworthiness in Web Agents](https://arxiv.org//abs/2410.06703)

	Ido Levy, Ben Wiesel, Sami Marreed, Alon Oved, Avi Yaeli, Segev Shlomov

+ [Functional-level Uncertainty Quantification for Calibrated Fine-tuning on LLMs](https://arxiv.org//abs/2410.06431)

	Ruijia Niu, Dongxia Wu, Rose Yu, Yi-An Ma

+ [Context-Augmented Code Generation Using Programming Knowledge Graphs](https://arxiv.org//abs/2410.18251)

	Iman Saberi, Fatemeh Fard

+ [Scaling Laws For Mixed Qquantization](https://arxiv.org//abs/2410.06722)

	Zeyu Cao, Boyang Gu, Cheng Zhang, Pedro Gimenes, Jianqiao Lu, Jianyi Cheng, Xitong Gao, Yiren Zhao

# 2024-10-08
+ [Large Continual Instruction Assistant](https://arxiv.org//abs/2410.10868)

	Jingyang Qiao, Zhizhong Zhang, Xin Tan, Yanyun Qu, Shouhong Ding, Yuan Xie

+ [Structural Reasoning Improves Molecular Understanding of LLM](https://arxiv.org//abs/2410.05610)

	Yunhui Jang, Jaehyung Kim, Sungsoo Ahn

+ [A Bayesian Model Selection Criterion for Selecting Pretraining Checkpoints](https://arxiv.org//abs/2410.05612)

	Michael Munn, Susan Wei

+ [MEXA: Multilingual Evaluation of English-Centric LLMs via Cross-Lingual Alignment](https://arxiv.org//abs/2410.05873)

	Amir Hossein Kargaran, Ali Modarressi, Nafiseh Nikeghbal, Jana Diesner, François Yvon, Hinrich Schütze

+ [Stereotype or Personalization? User Identity Biases Chatbot Recommendations](https://arxiv.org//abs/2410.05613)

	Anjali Kantharuban, Jeremiah Milbauer, Maarten Sap, Emma Strubell, Graham Neubig

+ [Biased AI can Influence Political Decision-Making](https://arxiv.org//abs/2410.06415)

	Jillian Fisher, Shangbin Feng, Robert Aron, Thomas Richardson, Yejin Choi, Daniel W. Fisher, Jennifer Pan, Yulia Tsvetkov, Katharina Reinecke

# 2024-10-07
+ [GLEE: A Unified Framework and Benchmark for Language-based Economic Environments](https://arxiv.org//abs/2410.05254)

	Eilam Shapira, Omer Madmon, Itamar Reinman, Samuel Joseph Amouyal, Roi Reichart, Moshe Tennenholtz

# 2024-10-06
+ [Regressing the Relative Future: Efficient Policy Optimization for Multi-turn RLHF](https://arxiv.org//abs/2410.04612)

	Zhaolin Gao, Wenhao Zhan, Jonathan D. Chang, Gokul Swamy, Kianté Brantley, Jason D. Lee, Wen Sun


+ [Evaluating the Correctness of Inference Patterns Used by LLMs for Judgment](https://arxiv.org//abs/2410.09083)

	Lu Chen, Yuxuan Huang, Yixing Li, Dongrui Liu, Qihan Ren, Shuai Zhao, Kun Kuang, Zilong Zheng, Quanshi Zhang

+ [Gödel Agent: A Self-Referential Agent Framework for Recursive Self-Improvement](https://arxiv.org//abs/2410.04444)

	Xunjian Yin, Xinyi Wang, Liangming Pan, Li Lin, Xiaojun Wan, William Yang Wang

# 2024-10-05
+ [Domain-Oriented Time Series Inference Agents for Reasoning and Automated Analysis](https://arxiv.org//abs/2410.04047)

	Wen Ye, Wei Yang, Defu Cao, Yizhou Zhang, Lumingyuan Tang, Jie Cai, Yan Liu

# 2024-10-04
+ [Understanding Large Language Models in Your Pockets: Performance Study on COTS Mobile Devices](https://arxiv.org//abs/2410.03613)

	Jie Xiao, Qianyi Huang, Xu Chen, Chen Tian

+ [Look Twice Before You Answer: Memory-Space Visual Retracing for Hallucination Mitigation in Multimodal Large Language Models](https://arxiv.org//abs/2410.03577)

	Xin Zou, Yizhou Wang, Yibo Yan, Yuanhuiyi Lyu, Kening Zheng, Sirui Huang, Junkai Chen, Peijie Jiang, Jia Liu, Chang Tang, Xuming Hu

+ [Decoding Game: On Minimax Optimality of Heuristic Text Generation Strategies](https://arxiv.org//abs/2410.03968)

	Sijin Chen, Omar Hagrass, Jason M. Klusowski

+ [Learning from Committee: Reasoning Distillation from a Mixture of Teachers with Peer-Review](https://arxiv.org//abs/2410.03663)

	Zhuochun Li, Yuelyu Ji, Rui Meng, Daqing He

+ [Permissive Information-Flow Analysis for Large Language Models](https://arxiv.org//abs/2410.03055)

	Shoaib Ahmed Siddiqui, Radhika Gaonkar, Boris Köpf, David Krueger, Andrew Paverd, Ahmed Salem, Shruti Tople, Lukas Wutschitz, Menglin Xia, Santiago Zanella-Béguelin

+ [MLLM as Retriever: Interactively Learning Multimodal Retrieval for Embodied Agents](https://arxiv.org//abs/2410.03450)

	Junpeng Yue, Xinrun Xu, Börje F. Karlsson, Zongqing Lu

+ [In-context Demonstration Matters: On Prompt Optimization for Pseudo-Supervision Refinement](https://arxiv.org//abs/2410.03124)

	Zhen-Yu Zhang, Jiandong Zhang, Huaxiu Yao, Gang Niu, Masashi Sugiyama

+ [SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation](https://arxiv.org//abs/2410.03960)

	Aurick Qiao, Zhewei Yao, Samyam Rajbhandari, Yuxiong He

+ [Efficiently Identifying Watermarked Segments in Mixed-Source Texts](https://arxiv.org//abs/2410.03600)

	Xuandong Zhao, Chenwen Liao, Yu-Xiang Wang, Lei Li

# 2024-10-03
+ [Selective Attention Improves Transformer](https://arxiv.org//abs/2410.02703)

	Yaniv Leviathan, Matan Kalman, Yossi Matias


+ [A Formal Framework for Understanding Length Generalization in Transformers](https://arxiv.org//abs/2410.02140)

	Xinting Huang, Andy Yang, Satwik Bhattamishra, Yash Sarrof, Andreas Krebs, Hattie Zhou, Preetum Nakkiran, Michael Hahn

+ [Theoretical Insights into Fine-Tuning Attention Mechanism: Generalization and Optimization](https://arxiv.org//abs/2410.02247)

	Xinhao Yao, Hongjin Qian, Xiaolin Hu, Gengze Xu, Wei Liu, Jian Luan, Bin Wang, Yong Liu

+ [IoT-LLM: Enhancing Real-World IoT Task Reasoning with Large Language Models](https://arxiv.org//abs/2410.02429)

	Tuo An, Yunjiao Zhou, Han Zou, Jianfei Yang

+ [Optimizing Adaptive Attacks against Watermarks for Language Models](https://arxiv.org//abs/2410.02440)

	Abdulrahman Diaa, Toluwani Aremu, Nils Lukas

+ [Discovering Spoofing Attempts on Language Model Watermarks](https://arxiv.org//abs/2410.02693)

	Thibaud Gloaguen, Nikola Jovanović, Robin Staab, Martin Vechev

+ [Training Nonlinear Transformers for Chain-of-Thought Inference: A Theoretical Generalization Analysis](https://arxiv.org//abs/2410.02167)

	Hongkang Li, Songtao Lu, Pin-Yu Chen, Xiaodong Cui, Meng Wang

+ [CodePMP: Scalable Preference Model Pretraining for Large Language Model Reasoning](https://arxiv.org//abs/2410.02229)

	Huimu Yu, Xing Wu, Haotian Xu, Debing Zhang, Songlin Hu

+ [Estimating Privacy Leakage of Augmented Contextual Knowledge in Language Models](https://arxiv.org//abs/2410.03026)

	James Flemings, Bo Jiang, Wanrong Zhang, Zafar Takhirov, Murali Annavaram

+ [AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML](https://arxiv.org//abs/2410.02958)

	Patara Trirat, Wonyong Jeong, Sung Ju Hwang

+ [Beyond Bradley-Terry Models: A General Preference Model for Language Model Alignment](https://arxiv.org//abs/2410.02197)

	Yifan Zhang, Ge Zhang, Yue Wu, Kangping Xu, Quanquan Gu

# 2024-10-02
+ [TypedThinker: Diversify Large Language Model Reasoning with Typed Thinking](https://arxiv.org//abs/2410.01952)

	Danqing Wang, Jianxin Ma, Fei Fang, Lei Li


+ [Racing Thoughts: Explaining Contextualization Errors in Large Language Models](https://arxiv.org//abs/2410.02102)

	Michael A. Lepori, Michael C. Mozer, Asma Ghandeharioun

+ [Moral Alignment for LLM Agents](https://arxiv.org//abs/2410.01639)

	Elizaveta Tennant, Stephen Hailes, Mirco Musolesi

+ [Efficient Length-Generalizable Attention via Causal Retrieval for Long-Context Language Modeling](https://arxiv.org//abs/2410.01651)

	Xiang Hu, Zhihao Teng, Jun Zhao, Wei Wu, Kewei Tu

+ [EMMA: Efficient Visual Alignment in Multi-Modal LLMs](https://arxiv.org//abs/2410.02080)

	Sara Ghazanfari, Alexandre Araujo, Prashanth Krishnamurthy, Siddharth Garg, Farshad Khorrami

# 2024-10-01
+ [RATIONALYST: Mining Implicit Rationales for Process Supervision of Reasoning](https://arxiv.org//abs/2410.01044)

	Dongwei Jiang, Guoxuan Wang, Yining Lu, Andrew Wang, Jingyu Zhang, Chuyu Liu, Benjamin Van Durme, Daniel Khashabi

# 2024-09-30
+ [Beyond Single Concept Vector: Modeling Concept Subspace in LLMs with Gaussian Distribution](https://arxiv.org//abs/2410.00153)

	Haiyan Zhao, Heng Zhao, Bo Shen, Ali Payani, Fan Yang, Mengnan Du

+ [Characterizing and Efficiently Accelerating Multimodal Generation Model Inference](https://arxiv.org//abs/2410.00215)

	Yejin Lee, Anna Sun, Basil Hosmer, Bilge Acun, Can Balioglu, Changhan Wang, Charles David Hernandez, Christian Puhrsch, Daniel Haziza, Driss Guessous, Francisco Massa, Jacob Kahn, Jeffrey Wan, Jeremy Reizenstein, Jiaqi Zhai, Joe Isaacson, Joel Schlosser, Juan Pino, Kaushik Ram Sadagopan, Leonid Shamis, Linjian Ma, Min-Jae Hwang, Mingda Chen, Mostafa Elhoushi, Pedro Rodriguez, Ram Pasunuru, Scott Yih, Sravya Popuri, Xing Liu, Carole-Jean Wu

+ [SSR: Alignment-Aware Modality Connector for Speech Language Models](https://arxiv.org//abs/2410.00168)

	Weiting Tan, Hirofumi Inaguma, Ning Dong, Paden Tomasello, Xutai Ma

+ [QAEncoder: Towards Aligned Representation Learning in Question Answering System](https://arxiv.org//abs/2409.20434)

	Zhengren Wang, Qinhan Yu, Shida Wei, Zhiyu Li, Feiyu Xiong, Xiaoxing Wang, Simin Niu, Hao Liang, Wentao Zhang

# 2024-09-29
+ [Identifying Knowledge Editing Types in Large Language Models](https://arxiv.org//abs/2409.19663)

	Xiaopeng Li, Shasha Li, Shangwen Wang, Shezheng Song, Bin Ji, Huijun Liu, Jun Ma, Jie Yu

+ [Overcoming the Machine Penalty with Imperfectly Fair AI Agents](https://arxiv.org//abs/2410.03724)

	Zhen Wang, Ruiqi Song, Chen Shen, Shiya Yin, Zhao Song, Balaraju Battu, Lei Shi, Danyang Jia, Talal Rahwan, Shuyue Hu

# 2024-09-28
+ [Scalable Fine-tuning from Multiple Data Sources: A First-Order Approximation Approach](https://arxiv.org//abs/2409.19458)

	Dongyue Li, Ziniu Zhang, Lu Wang, Hongyang R. Zhang

# 2024-09-27
+ [Can LLMs Really Learn to Translate a Low-Resource Language from One Grammar Book?](https://arxiv.org//abs/2409.19151)

	Seth Aycock, David Stap, Di Wu, Christof Monz, Khalil Sima'an

+ [Mitigating Selection Bias with Node Pruning and Auxiliary Options](https://arxiv.org//abs/2409.18857)

	Hyeong Kyu Choi, Weijie Xu, Chi Xue, Stephanie Eckman, Chandan K. Reddy

+ ["Oh LLM, I'm Asking Thee, Please Give Me a Decision Tree": Zero-Shot Decision Tree Induction and Embedding with Large Language Models](https://arxiv.org//abs/2409.18594)

	Ricardo Knauer, Mario Koddenbrock, Raphael Wallsberger, Nicholas M. Brisson, Georg N. Duda, Deborah Falla, David W. Evans, Erik Rodner

+ [Predicting memorization within Large Language Models fine-tuned for classification](https://arxiv.org//abs/2409.18858)

	Jérémie Dentan, Davide Buscaldi, Aymen Shabou, Sonia Vanier

+ [Code Vulnerability Repair with Large Language Model using Context-Aware Prompt Tuning](https://arxiv.org//abs/2409.18395)

	Arshiya Khan, Guannan Liu, Xing Gao

# 2024-09-26
+ [Benign Overfitting in Token Selection of Attention Mechanism](https://arxiv.org//abs/2409.17625)

	Keitaro Sakamoto, Issei Sato

+ [Control Industrial Automation System with Large Language Model Agents](https://arxiv.org//abs/2409.18009)

	Yuchen Xia, Nasser Jazdi, Jize Zhang, Chaitanya Shah, Michael Weyrich

# 2024-09-25
+ [AXIS: Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents](https://arxiv.org//abs/2409.17140)

	Junting Lu, Zhiyang Zhang, Fangkai Yang, Jue Zhang, Lu Wang, Chao Du, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang

+ [Judgment-of-Thought Prompting: A Courtroom-Inspired Framework for Binary Logical Reasoning with Large Language Models](https://arxiv.org//abs/2409.16635)

	Sungjune Park, Heehwan Kim, Haehyun Cho, Daeseon Choi

+ [Tell Me What You Don't Know: Enhancing Refusal Capabilities of Role-Playing Agents via Representation Space Analysis and Editing](https://arxiv.org//abs/2409.16913)

	Wenhao Liu, Siyu An, Junru Lu, Muling Wu, Tianlong Li, Xiaohua Wang, Changze lv, Xiaoqing Zheng, Di Yin, Xing Sun, Xuanjing Huang

# 2024-09-24
+ [EnIGMA: Interactive Tools Substantially Assist LM Agents in Finding Security Vulnerabilities](https://arxiv.org//abs/2409.16165)

	Talor Abramovich, Meet Udeshi, Minghao Shao, Kilian Lieret, Haoran Xi, Kimberly Milner, Sofija Jancheska, John Yang, Carlos E. Jimenez, Farshad Khorrami, Prashanth Krishnamurthy, Brendan Dolan-Gavitt, Muhammad Shafique, Karthik Narasimhan, Ramesh Karri, Ofir Press

# 2024-09-23
+ [Scideator: Human-LLM Scientific Idea Generation Grounded in Research-Paper Facet Recombination](https://arxiv.org//abs/2409.14634)

	Marissa Radensky, Simra Shahid, Raymond Fok, Pao Siangliulue, Tom Hope, Daniel S. Weld

+ [Revise, Reason, and Recognize: LLM-Based Emotion Recognition via Emotion-Specific Prompts and ASR Error Correction](https://arxiv.org//abs/2409.15551)

	Yuanchao Li, Yuan Gong, Chao-Han Huck Yang, Peter Bell, Catherine Lai

+ [MediConfusion: Can you trust your AI radiologist? Probing the reliability of multimodal medical foundation models](https://arxiv.org//abs/2409.15477)

	Mohammad Shahab Sepehri, Zalan Fabian, Maryam Soltanolkotabi, Mahdi Soltanolkotabi

# 2024-09-22
+ [Position IDs Matter: An Enhanced Position Layout for Efficient Context Compression in Large Language Models](https://arxiv.org//abs/2409.14364)

	Runsong Zhao, Xin Liu, Xinyu Liu, Pengcheng Huang, Chunyang Xiao, Tong Xiao, Jingbo Zhu

+ [Large Model Based Agents: State-of-the-Art, Cooperation Paradigms, Security and Privacy, and Future Trends](https://arxiv.org//abs/2409.14457)

	Yuntao Wang, Yanghe Pan, Zhou Su, Yi Deng, Quan Zhao, Linkang Du, Tom H. Luan, Jiawen Kang, Dusit Niyato

# 2024-09-21
+ [Co-occurrence is not Factual Association in Language Models](https://arxiv.org//abs/2409.14057)

	Xiao Zhang, Miao Li, Ji Wu

# 2024-09-20
+ [Time Awareness in Large Language Models: Benchmarking Fact Recall Across Time](https://arxiv.org//abs/2409.13338)

	David Herel, Vojtech Bartek, Jiri Jirak, Tomas Mikolov

+ [On-Device Collaborative Language Modeling via a Mixture of Generalists and Specialists](https://arxiv.org//abs/2409.13931)

	Dongyang Fan, Bettina Messmer, Nikita Doikov, Martin Jaggi

# 2024-09-19
+ [Prompts Are Programs Too! Understanding How Developers Build Software Containing Prompts](https://arxiv.org//abs/2409.12447)

	Jenny T. Liang, Melissa Lin, Nikitha Rao, Brad A. Myers

+ [Strategic Collusion of LLM Agents: Market Division in Multi-Commodity Competitions](https://arxiv.org//abs/2410.00031)

	Ryan Y. Lin, Siddhartha Ojha, Kevin Cai, Maxwell F. Chen

# 2024-09-18
+ [To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning](https://arxiv.org//abs/2409.12183)

	Zayne Sprague, Fangcong Yin, Juan Diego Rodriguez, Dongwei Jiang, Manya Wadhwa, Prasann Singhal, Xinyu Zhao, Xi Ye, Kyle Mahowald, Greg Durrett

+ [Revealing and Mitigating the Challenge of Detecting Character Knowledge Errors in LLM Role-Playing](https://arxiv.org//abs/2409.11726)

	Wenyuan Zhang, Shuaiyi Nie, Jiawei Sheng, Zefeng Zhang, Xinghua Zhang, Yongquan He, Tingwen Liu

+ [From Lists to Emojis: How Format Bias Affects Model Alignment](https://arxiv.org//abs/2409.11704)

	Xuanchang Zhang, Wei Xiong, Lichang Chen, Tianyi Zhou, Heng Huang, Tong Zhang

+ [BanStereoSet: A Dataset to Measure Stereotypical Social Biases in LLMs for Bangla](https://arxiv.org//abs/2409.11638)

	Mahammed Kamruzzaman, Abdullah Al Monsur, Shrabon Das, Enamul Hassan, Gene Louis Kim

# 2024-09-17
+ [Measuring and Enhancing Trustworthiness of LLMs in RAG through Grounded Attributions and Learning to Refuse](https://arxiv.org//abs/2409.11242)

	Maojia Song, Shang Hong Sim, Rishabh Bhardwaj, Hai Leong Chieu, Navonil Majumder, Soujanya Poria

+ [Exploring the Trade-Offs: Quantization Methods, Task Difficulty, and Model Size in Large Language Models From Edge to Giant](https://arxiv.org//abs/2409.11055)

	Jemin Lee, Sihyeong Park, Jinse Kwon, Jihun Oh, Yongin Kwon

+ [Task Arithmetic for Language Expansion in Speech Translation](https://arxiv.org//abs/2409.11274)

	Yao-Fei Cheng, Hayato Futami, Yosuke Kashiwagi, Emiru Tsunoo, Wen Shen Teo, Siddhant Arora, Shinji Watanabe

# 2024-09-16
+ [Lab-AI: Using Retrieval Augmentation to Enhance Language Models for Personalized Lab Test Interpretation in Clinical Medicine](https://arxiv.org//abs/2409.18986)

	Xiaoyu Wang, Haoyong Ouyang, Balu Bhasuran, Xiao Luo, Karim Hanna, Mia Liza A. Lustria, Carl Yang, Zhe He


# 2024-09-14
+ [Hacking, The Lazy Way: LLM Augmented Pentesting](https://arxiv.org//abs/2409.09493)

	Dhruva Goyal, Sitaraman Subramanian, Aditya Peela, Nisha P. Shetty

# 2024-09-13
+ [Your Weak LLM is Secretly a Strong Teacher for Alignment](https://arxiv.org//abs/2409.08813)

	Leitian Tao, Yixuan Li

# 2024-09-12
+ [Fine-tuning Large Language Models for Entity Matching](https://arxiv.org//abs/2409.08185)

	Aaron Steiner, Ralph Peeters, Christian Bizer

+ [On the Vulnerability of Applying Retrieval-Augmented Generation within Knowledge-Intensive Application Domains](https://arxiv.org//abs/2409.17275)

	Xun Xian, Ganghua Wang, Xuan Bi, Jayanth Srinivasa, Ashish Kundu, Charles Fleming, Mingyi Hong, Jie Ding

# 2024-09-11
+ [Traceable LLM-based validation of statements in knowledge graphs](https://arxiv.org//abs/2409.07507)

	Daniel Adam, Tomáš Kliegr

+ [MOSAIC: Multiple Observers Spotting AI Content](https://arxiv.org//abs/2409.07615)

	Matthieu Dubois, François Yvon, Pablo Piantanida

# 2024-09-10
+ [LaMsS: When Large Language Models Meet Self-Skepticism](https://arxiv.org//abs/2409.06601)

	Yetao Wu, Yihong Wang, Teng Chen, Ningyuan Xi, Qingqing Gu, Hongyang Lei, Luo Ji

# 2024-09-09
+ [CKnowEdit: A New Chinese Knowledge Editing Dataset for Linguistics, Facts, and Logic Error Correction in LLMs](https://arxiv.org//abs/2409.05806)

	Jizhan Fang, Tianhe Lu, Yunzhi Yao, Ziyan Jiang, Xin Xu, Huajun Chen, Ningyu Zhang

+ [STRICTA: Structured Reasoning in Critical Text Assessment for Peer Review and Beyond](https://arxiv.org//abs/2409.05367)

	Nils Dycke, Matej Zečević, Ilia Kuznetsov, Beatrix Suess, Kristian Kersting, Iryna Gurevych

# 2024-09-07
+ [Reward Guidance for Reinforcement Learning Tasks Based on Large Language Models: The LMGT Framework](https://arxiv.org//abs/2409.04744)

	Yongxin Deng, Xihe Qiu, Jue Chen, Xiaoyu Tan

# 2024-09-06
+ [From Calculation to Adjudication: Examining LLM judges on Mathematical Reasoning Tasks](https://arxiv.org//abs/2409.04168)

	Andreas Stephan, Dawei Zhu, Matthias Aßenmacher, Xiaoyu Shen, Benjamin Roth

+ [GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding](https://arxiv.org//abs/2409.04183)

	Ziyin Zhang, Hang Yu, Shijie Li, Peng Di, Jianguo Li, Rui Wang

+ [An overview of domain-specific foundation model: key technologies, applications and challenges](https://arxiv.org//abs/2409.04267)

	Haolong Chen, Hanzhi Chen, Zijian Zhao, Kaifeng Han, Guangxu Zhu, Yichen Zhao, Ying Du, Wei Xu, Qingjiang Shi

# 2024-09-05
+ [Content Moderation by LLM: From Accuracy to Legitimacy](https://arxiv.org//abs/2409.03219)

	Tao Huang

# 2024-09-04
+ [NESTFUL: A Benchmark for Evaluating LLMs on Nested Sequences of API Calls](https://arxiv.org//abs/2409.03797)

	Kinjal Basu, Ibrahim Abdelaziz, Kiran Kate, Mayank Agarwal, Maxwell Crouse, Yara Rizk, Kelsey Bradford, Asim Munawar, Sadhana Kumaravel, Saurabh Goyal, Xin Wang, Luis A. Lastras, Pavan Kapanipathi

# 2024-09-03
+ [Efficient LLM Context Distillation](https://arxiv.org//abs/2409.01930)

	Rajesh Upadhayayaya, Manish Raj Osti, Zachary Smith, Chritopher Kottmyer

+ [What are the Essential Factors in Crafting Effective Long Context Multi-Hop Instruction Datasets? Insights and Best Practices](https://arxiv.org//abs/2409.01893)

	Zhi Chen, Qiguang Chen, Libo Qin, Qipeng Guo, Haijun Lv, Yicheng Zou, Wanxiang Che, Hang Yan, Kai Chen, Dahua Lin

# 2024-09-02
+ [Language Models Benefit from Preparation with Elicited Knowledge](https://arxiv.org//abs/2409.01345)

	Jiacan Yu, Hannah An, Lenhart K. Schubert

# 2024-09-01
+ [Automatic Pseudo-Harmful Prompt Generation for Evaluating False Refusals in Large Language Models](https://arxiv.org//abs/2409.00598)

	Bang An, Sicheng Zhu, Ruiyi Zhang, Michael-Andrei Panaitescu-Liess, Yuancheng Xu, Furong Huang

# 2024-08-30
+ [Training Ultra Long Context Language Model with Fully Pipelined Distributed Transformer](https://arxiv.org//abs/2408.16978)

	Jinghan Yao, Sam Ade Jacobs, Masahiro Tanaka, Olatunji Ruwase, Hari Subramoni, Dhabaleswar K. Panda

# 2024-08-28
+ [Towards Logically Sound Natural Language Reasoning with Logic-Enhanced Language Model Agents](https://arxiv.org//abs/2408.16081)

	Agnieszka Mensfelt, Kostas Stathis, Vince Trencsenyi

# 2024-08-27
+ [Wait, that's not an option: LLMs Robustness with Incorrect Multiple-Choice Options](https://arxiv.org//abs/2409.00113)

	Gracjan Góral, Emilia Wiśnios, Piotr Sankowski, Paweł Budzianowski

+ [How transformers learn structured data: insights from hierarchical filtering](https://arxiv.org//abs/2408.15138)

	Jerome Garnier-Brun, Marc Mézard, Emanuele Moscato, Luca Saglietti

# 2024-08-26
+ [CHARTOM: A Visual Theory-of-Mind Benchmark for Multimodal Large Language Models](https://arxiv.org//abs/2408.14419)

	Shubham Bharti, Shiyun Cheng, Jihyun Rho, Jianrui Zhang, Mu Cai, Yong Jae Lee, Martina Rau, Xiaojin Zhu

+ [LogProber: Disentangling confidence from contamination in LLM responses](https://arxiv.org//abs/2408.14352)

	Nicolas Yax, Pierre-Yves Oudeyer, Stefano Palminteri

+ [Improving Clinical Note Generation from Complex Doctor-Patient Conversation](https://arxiv.org//abs/2408.14568)

	Yizhan Li, Sifan Wu, Christopher Smith, Thomas Lo, Bang Liu

# 2024-08-24
+ [LlamaDuo: LLMOps Pipeline for Seamless Migration from Service LLMs to Small-Scale Local LLMs](https://arxiv.org//abs/2408.13467)

	Chansung Park, Juyong Jiang, Fan Wang, Sayak Paul, Jing Tang

# 2024-08-22
+ [LLMs are not Zero-Shot Reasoners for Biomedical Information Extraction](https://arxiv.org//abs/2408.12249)

	Aishik Nagar, Viktor Schlegel, Thanh-Tung Nguyen, Hao Li, Yuping Wu, Kuluhan Binici, Stefan Winkler

# 2024-08-21
+ [Automating Thought of Search: A Journey Towards Soundness and Completeness](https://arxiv.org//abs/2408.11326)

	Daniel Cao, Michael Katz, Harsha Kokel, Kavitha Srinivas, Shirin Sohrabi

# 2024-08-20
+ [Enhancing Robustness in Large Language Models: Prompting for Mitigating the Impact of Irrelevant Information](https://arxiv.org//abs/2408.10615)

	Ming Jiang, Tingting Huang, Biao Guo, Yao Lu, Feng Zhang

# 2024-08-19
+ [Kubrick: Multimodal Agent Collaborations for Synthetic Video Generation](https://arxiv.org//abs/2408.10453)

	Liu He, Yizhi Song, Hejun Huang, Pinxin Liu, Yunlong Tang, Daniel Aliaga, Xin Zhou

+ [Bridging the Language Gap: Enhancing Multilingual Prompt-Based Code Generation in LLMs via Zero-Shot Cross-Lingual Transfer](https://arxiv.org//abs/2408.09701)

	Mingda Li, Abhijit Mishra, Utkarsh Mujumdar

+ [Fine-Grained and Thematic Evaluation of LLMs in Social Deduction Game](https://arxiv.org//abs/2408.09946)

	Byungjun Kim, Dayeon Seo, Bugeun Kim

+ [X-TURING: Towards an Enhanced and Efficient Turing Test for Long-Term Dialogue Agents](https://arxiv.org//abs/2408.09853)

	Weiqi Wu, Hongqiu Wu, Hai Zhao

+ [Resolving Lexical Bias in Model Editing](https://arxiv.org//abs/2408.10411)

	Hammad Rizwan, Domenic Rosati, Ga Wu, Hassan Sajjad

+ [Paired Completion: Flexible Quantification of Issue-framing at Scale with LLMs](https://arxiv.org//abs/2408.09742)

	Simon D Angus, Lachlan O'Neill

# 2024-08-18
+ [Reefknot: A Comprehensive Benchmark for Relation Hallucination Evaluation, Analysis and Mitigation in Multimodal Large Language Models](https://arxiv.org//abs/2408.09429)

	Kening Zheng, Junkai Chen, Yibo Yan, Xin Zou, Xuming Hu

# 2024-08-16
+ [Turning Trash into Treasure: Accelerating Inference of Large Language Models with Token Recycling](https://arxiv.org//abs/2408.08696)

	Xianzhen Luo, Yixuan Wang, Qingfu Zhu, Zhiming Zhang, Xuanyu Zhang, Qing Yang, Dongliang Xu

+ [Where is the signal in tokenization space?](https://arxiv.org//abs/2408.08541)

	Renato Lui Geh, Honghua Zhang, Kareem Ahmed, Benjie Wang, Guy Van den Broeck

+ [The Fellowship of the LLMs: Multi-Agent Workflows for Synthetic Preference Optimization Dataset Generation](https://arxiv.org//abs/2408.08688)

	Samee Arif, Sualeha Farid, Abdul Hameed Azeemi, Awais Athar, Agha Ali Raza

+ [SelectLLM: Query-Aware Efficient Selection Algorithm for Large Language Models](https://arxiv.org//abs/2408.08545)

	Kaushal Kumar Maurya, KV Aditya Srivatsa, Ekaterina Kochmar

+ [EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics](https://arxiv.org//abs/2408.08782)

	Chenwei Wan, Matthieu Labeau, Chloé Clavel

# 2024-08-15
+ [Multimodal Causal Reasoning Benchmark: Challenging Vision Large Language Models to Discern Causal Links Across Modalities](https://arxiv.org//abs/2408.08105)

	Zhiyuan Li, Heng Wang, Dongnan Liu, Chaoyi Zhang, Ao Ma, Jieting Long, Weidong Cai

+ [Can Large Language Models Understand Symbolic Graphics Programs?](https://arxiv.org//abs/2408.08313)

	Zeju Qiu, Weiyang Liu, Haiwen Feng, Zhen Liu, Tim Z. Xiao, Katherine M. Collins, Joshua B. Tenenbaum, Adrian Weller, Michael J. Black, Bernhard Schölkopf

+ [AgentCourt: Simulating Court with Adversarial Evolvable Lawyer Agents](https://arxiv.org//abs/2408.08089)

	Guhong Chen, Liyang Fan, Zihan Gong, Nan Xie, Zixuan Li, Ziqiang Liu, Chengming Li, Qiang Qu, Hamid Alinejad-Rokny, Shiwen Ni, Min Yang

# 2024-08-13
+ [Bridging LLMs and KGs without Fine-Tuning: Intermediate Probing Meets Subgraph-Aware Entity Descriptions](https://arxiv.org//abs/2408.06787)

	Bo Xue, Yi Xu, Yunchong Song, Yiming Pang, Yuyang Ren, Jiaxin Ding, Luoyi Fu, Xinbing Wang

# 2024-08-12
+ [Does Liking Yellow Imply Driving a School Bus? Semantic Leakage in Language Models](https://arxiv.org//abs/2408.06518)

	Hila Gonen, Terra Blevins, Alisa Liu, Luke Zettlemoyer, Noah A. Smith

# 2024-08-10
+ [SWIFT:A Scalable lightWeight Infrastructure for Fine-Tuning](https://arxiv.org//abs/2408.05517)

	Yuze Zhao, Jintao Huang, Jinghan Hu, Xingjun Wang, Yunlin Mao, Daoze Zhang, Hong Zhang, Zeyinzi Jiang, Zhikai Wu, Baole Ai, Ang Wang, Wenmeng Zhou, Yingda Chen

# 2024-08-09
+ [Order Matters in Hallucination: Reasoning Order as Benchmark and Reflexive Prompting for Large-Language-Models](https://arxiv.org//abs/2408.05093)

	Zikai Xie

+ [VITA: Towards Open-Source Interactive Omni Multimodal LLM](https://arxiv.org//abs/2408.05211)

	Chaoyou Fu, Haojia Lin, Zuwei Long, Yunhang Shen, Yuhang Dai, Meng Zhao, Yi-Fan Zhang, Shaoqi Dong, Yangze Li, Xiong Wang, Haoyu Cao, Di Yin, Long Ma, Xiawu Zheng, Rongrong Ji, Yunsheng Wu, Ran He, Caifeng Shan, Xing Sun

+ [Can a Bayesian Oracle Prevent Harm from an Agent?](https://arxiv.org//abs/2408.05284)

	Yoshua Bengio, Michael K. Cohen, Nikolay Malkin, Matt MacDermott, Damiano Fornasiere, Pietro Greiner, Younesse Kaddar

+ [A Survey of Text-to-SQL in the Era of LLMs: Where are we, and where are we going?](https://arxiv.org//abs/2408.05109)

	Xinyu Liu, Shuyu Shen, Boyan Li, Peixian Ma, Runzhi Jiang, Yuxin Zhang, Ju Fan, Guoliang Li, Nan Tang, Yuyu Luo

+ [Retrieval-augmented code completion for local projects using large language models](https://arxiv.org//abs/2408.05026)

	Marko Hostnik, Marko Robnik-Šikonja

# 2024-08-08
+ [The Struggles of LLMs in Cross-lingual Code Clone Detection](https://arxiv.org//abs/2408.04430)

	Micheline Bénédicte Moumoula, Abdoul Kader Kabore, Jacques Klein, Tegawendé Bissyande

# 2024-08-07
+ [A Logical Fallacy-Informed Framework for Argument Generation](https://arxiv.org//abs/2408.03618)

	Luca Mouchel, Debjit Paul, Shaobo Cui, Robert West, Antoine Bosselut, Boi Faltings

+ [Optimus: Accelerating Large-Scale Multi-Modal LLM Training by Bubble Exploitation](https://arxiv.org//abs/2408.03505)

	Weiqi Feng, Yangrui Chen, Shaoyu Wang, Yanghua Peng, Haibin Lin, Minlan Yu

+ [AcTracer: Active Testing of Large Language Model via Multi-Stage Sampling](https://arxiv.org//abs/2408.03573)

	Yuheng Huang, Jiayang Song, Qiang Hu, Felix Juefei-Xu, Lei Ma

# 2024-08-05
+ [Black-Box Adversarial Attacks on LLM-Based Code Completion](https://arxiv.org//abs/2408.02509)

	Slobodan Jenko, Niels Mündler, Jingxuan He, Mark Vero, Martin Vechev

# 2024-08-02
+ [CFBench: A Comprehensive Constraints-Following Benchmark for LLMs](https://arxiv.org//abs/2408.01122)

	Tao Zhang, Chenglin Zhu, Yanjun Shen, Wenjing Luo, Yan Zhang, Hao Liang, Tao Zhang, Fan Yang, Mingan Lin, Yujing Qiao, Weipeng Chen, Bin Cui, Wentao Zhang, Zenan Zhou

+ [On the Resilience of LLM-Based Multi-Agent Collaboration with Faulty Agents](https://arxiv.org//abs/2408.00989)

	Jen-tse Huang, Jiaxu Zhou, Tailin Jin, Xuhui Zhou, Zixi Chen, Wenxuan Wang, Youliang Yuan, Michael R. Lyu, Maarten Sap

# 2024-07-31
+ [Correcting Negative Bias in Large Language Models through Negative Attention Score Alignment](https://arxiv.org//abs/2408.00137)

	Sangwon Yu, Jongyoon Song, Bongkyu Hwang, Hoyoung Kang, Sooah Cho, Junhwa Choi, Seongho Joe, Taehee Lee, Youngjune L. Gwon, Sungroh Yoon

+ [SAKR: Enhancing Retrieval-Augmented Generation via Streaming Algorithm and K-Means Clustering](https://arxiv.org//abs/2407.21300)

	Haoyu Kang (1), Yuzhou Zhu (2), Yukun Zhong (3), Ke Wang (4) ((1) Central South University, (2) Dalian University of Technology, (3) Nanjing University, (4) Xidian University)

# 2024-07-29
+ [Genetic Instruct: Scaling up Synthetic Generation of Coding Instructions for Large Language Models](https://arxiv.org//abs/2407.21077)

	Somshubra Majumdar, Vahid Noroozi, Mehrzad Samadi, Sean Narenthiran, Aleksander Ficek, Wasi Uddin Ahmad, Jocelyn Huang, Jagadeesh Balam, Boris Ginsburg

# 2024-07-27
+ [The Impact of LoRA Adapters for LLMs on Clinical NLP Classification Under Data Limitations](https://arxiv.org//abs/2407.19299)

	Thanh-Dung Le, Ti Ti Nguyen, Vu Nguyen Ha, Symeon Chatzinotas, Philippe Jouvet, Rita Noumeir

# 2024-07-26
+ [Patched MOA: optimizing inference for diverse software development tasks](https://arxiv.org//abs/2407.18521)

	Asankhaya Sharma

+ [ClinicRealm: Re-evaluating Large Language Models with Conventional Machine Learning for Non-Generative Clinical Prediction Tasks](https://arxiv.org//abs/2407.18525)

	Yinghao Zhu, Junyi Gao, Zixiang Wang, Weibin Liao, Xiaochen Zheng, Lifang Liang, Miguel O. Bernabeu, Yasha Wang, Lequan Yu, Chengwei Pan, Ewen M. Harrison, Liantao Ma

+ [Right Now, Wrong Then: Non-Stationary Direct Preference Optimization under Preference Drift](https://arxiv.org//abs/2407.18676)

	Seongho Son, William Bankes, Sayak Ray Chowdhury, Brooks Paige, Ilija Bogunovic

# 2024-07-25
+ [PersonaGym: Evaluating Persona Agents and LLMs](https://arxiv.org//abs/2407.18416)

	Vinay Samuel, Henry Peng Zou, Yue Zhou, Shreyas Chaudhari, Ashwin Kalyan, Tanmay Rajpurohit, Ameet Deshpande, Karthik Narasimhan, Vishvak Murahari

+ [Principled Understanding of Generalization for Generative Transformer Models in Arithmetic Reasoning Tasks](https://arxiv.org//abs/2407.17963)

	Xingcheng Xu, Zibo Zhao, Haipeng Zhang, Yanqing Yang

+ [Multi-group Uncertainty Quantification for Long-form Text Generation](https://arxiv.org//abs/2407.21057)

	Terrance Liu, Zhiwei Steven Wu

# 2024-07-24
+ [LAMBDA: A Large Model Based Data Agent](https://arxiv.org//abs/2407.17535)

	Maojun Sun, Ruijian Han, Binyan Jiang, Houduo Qi, Defeng Sun, Yancheng Yuan, Jian Huang

# 2024-07-23
+ [Patched RTC: evaluating LLMs for diverse software development tasks](https://arxiv.org//abs/2407.16557)

	Asankhaya Sharma

# 2024-07-22
+ [Compensate Quantization Errors+: Quantized Models Are Inquisitive Learners](https://arxiv.org//abs/2407.15508)

	Yifei Gao, Jie Ou, Lei Wang, Jun Cheng, Mengchu Zhou

+ [Odyssey: Empowering Minecraft Agents with Open-World Skills](https://arxiv.org//abs/2407.15325)

	Shunyu Liu, Yaoru Li, Kongcheng Zhang, Zhenyu Cui, Wenkai Fang, Yuxuan Zheng, Tongya Zheng, Mingli Song

# 2024-07-21
+ [A Practical Analysis of Human Alignment with *PO](https://arxiv.org//abs/2407.15229)

	Kian Ahrabian, Xihui Lin, Barun Patra, Vishrav Chaudhary, Alon Benhaim, Jay Pujara, Xia Song

# 2024-07-17
+ [PersLLM: A Personified Training Approach for Large Language Models](https://arxiv.org//abs/2407.12393)

	Zheni Zeng, Jiayi Chen, Huimin Chen, Yukun Yan, Yuxuan Chen, Zhenghao Liu, Zhiyuan Liu, Maosong Sun

+ [Conversational Query Reformulation with the Guidance of Retrieved Documents](https://arxiv.org//abs/2407.12363)

	Jeonghyun Park, Hwanhee Lee

# 2024-07-16
+ [NeedleBench: Can LLMs Do Retrieval and Reasoning in Information-Dense Context?](https://arxiv.org//abs/2407.11963)

	Mo Li, Songyang Zhang, Taolin Zhang, Haodong Duan, Yunxin Liu, Kai Chen

+ [A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting](https://arxiv.org//abs/2407.11638)

	He Chang, Chenchen Ye, Zhulin Tao, Jie Wu, Zhengmao Yang, Yunshan Ma, Xianglin Huang, Tat-Seng Chua

# 2024-07-15
+ [Hey, That's My Model! Introducing Chain & Hash, An LLM Fingerprinting Technique](https://arxiv.org//abs/2407.10887)

	Mark Russinovich, Ahmed Salem

# 2024-07-13
+ [NativQA: Multilingual Culturally-Aligned Natural Query for LLMs](https://arxiv.org//abs/2407.09823)

	Md. Arid Hasan, Maram Hasanain, Fatema Ahmad, Sahinur Rahman Laskar, Sunaya Upadhyay, Vrunda N Sukhadia, Mucahid Kutlu, Shammur Absar Chowdhury, Firoj Alam

# 2024-07-12
+ [ASTPrompter: Preference-Aligned Automated Language Model Red-Teaming to Generate Low-Perplexity Unsafe Prompts](https://arxiv.org//abs/2407.09447)

	Amelia F. Hardy, Houjun Liu, Bernard Lange, Duncan Eddy, Mykel J. Kochenderfer

# 2024-07-11
+ [How Well Can a Long Sequence Model Model Long Sequences? Comparing Architechtural Inductive Biases on Long-Context Abilities](https://arxiv.org//abs/2407.08112)

	Jerry Huang

+ [ProxyGPT: Enabling User Anonymity in LLM Chatbots via (Un)Trustworthy Volunteer Proxies](https://arxiv.org//abs/2407.08792)

	Dzung Pham, Jade Sheffey, Chau Minh Pham, Amir Houmansadr

# 2024-07-10
+ [EfficientQAT: Efficient Quantization-Aware Training for Large Language Models](https://arxiv.org//abs/2407.11062)

	Mengzhao Chen, Wenqi Shao, Peng Xu, Jiahao Wang, Peng Gao, Kaipeng Zhang, Ping Luo

+ [Benchmarking LLMs for Environmental Review and Permitting](https://arxiv.org//abs/2407.07321)

	Rounak Meyur, Hung Phan, Koby Hayashi, Ian Stewart, Shivam Sharma, Sarthak Chaturvedi, Mike Parker, Dan Nally, Sadie Montgomery, Karl Pazdernik, Ali Jannesari, Mahantesh Halappanavar, Sai Munikoti, Sameera Horawalavithana, Anurag Acharya

# 2024-07-06
+ [Algorithmic Language Models with Neurally Compiled Libraries](https://arxiv.org//abs/2407.04899)

	Lucas Saldyt, Subbarao Kambhampati

# 2024-07-05
+ [AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents](https://arxiv.org//abs/2407.04363)

	Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Andrey Kravchenko, Mikhail Burtsev, Evgeny Burnaev

+ [When LLMs Play the Telephone Game: Cultural Attractors as Conceptual Tools to Evaluate LLMs in Multi-turn Settings](https://arxiv.org//abs/2407.04503)

	Jérémy Perez, Grgur Kovač, Corentin Léger, Cédric Colas, Gaia Molinaro, Maxime Derex, Pierre-Yves Oudeyer, Clément Moulin-Frier

# 2024-07-02
+ [A Bounding Box is Worth One Token: Interleaving Layout and Text in a Large Language Model for Document Understanding](https://arxiv.org//abs/2407.01976)

	Jinghui Lu, Haiyang Yu, Yanjie Wang, Yongjie Ye, Jingqun Tang, Ziwei Yang, Binghong Wu, Qi Liu, Hao Feng, Han Wang, Hao Liu, Can Huang

+ [Helpful assistant or fruitful facilitator? Investigating how personas affect language model behavior](https://arxiv.org//abs/2407.02099)

	Pedro Henrique Luz de Araujo, Benjamin Roth

# 2024-07-01
+ [Large Language Models Are Involuntary Truth-Tellers: Exploiting Fallacy Failure for Jailbreak Attacks](https://arxiv.org//abs/2407.00869)

	Yue Zhou, Henry Peng Zou, Barbara Di Eugenio, Yang Zhang

+ [Ground Every Sentence: Improving Retrieval-Augmented LLMs with Interleaved Reference-Claim Generation](https://arxiv.org//abs/2407.01796)

	Sirui Xia, Xintao Wang, Jiaqing Liang, Yifei Zhang, Weikang Zhou, Jiaji Deng, Fei Yu, Yanghua Xiao

+ [Human-like object concept representations emerge naturally in multimodal large language models](https://arxiv.org//abs/2407.01067)

	Changde Du, Kaicheng Fu, Bincheng Wen, Yi Sun, Jie Peng, Wei Wei, Ying Gao, Shengpei Wang, Chuncheng Zhang, Jinpeng Li, Shuang Qiu, Le Chang, Huiguang He

# 2024-06-28
+ [Scaling Synthetic Data Creation with 1,000,000,000 Personas](https://arxiv.org//abs/2406.20094)

	Tao Ge, Xin Chan, Xiaoyang Wang, Dian Yu, Haitao Mi, Dong Yu

+ [LLMEasyQuant: Scalable Quantization for Parallel and Distributed LLM Inference](https://arxiv.org//abs/2406.19657)

	Dong Liu, Yanxuan Yu

+ [ScaleBiO: Scalable Bilevel Optimization for LLM Data Reweighting](https://arxiv.org//abs/2406.19976)

	Rui Pan, Dylan Zhang, Hanning Zhang, Xingyuan Pan, Minrui Xu, Jipeng Zhang, Renjie Pi, Xiaoyu Wang, Tong Zhang

+ [SK-VQA: Synthetic Knowledge Generation at Scale for Training Context-Augmented Multimodal LLMs](https://arxiv.org//abs/2406.19593)

	Xin Su, Man Luo, Kris W Pan, Tien Pei Chou, Vasudev Lal, Phillip Howard

# 2024-06-27
+ [Curriculum Learning with Quality-Driven Data Selection](https://arxiv.org//abs/2407.00102)

	Biao Wu, Ling Chen

+ [DataGen: Unified Synthetic Dataset Generation via Large Language Models](https://arxiv.org//abs/2406.18966)

	Yue Huang, Siyuan Wu, Chujie Gao, Dongping Chen, Qihui Zhang, Yao Wan, Tianyi Zhou, Xiangliang Zhang, Jianfeng Gao, Chaowei Xiao, Lichao Sun

# 2024-06-26
+ [Is In-Context Learning a Type of Error-Driven Learning? Evidence from the Inverse Frequency Effect in Structural Priming](https://arxiv.org//abs/2406.18501)

	Zhenghao Zhou, Robert Frank, R. Thomas McCoy

# 2024-06-25
+ [OPT-Tree: Speculative Decoding with Adaptive Draft Tree Structure](https://arxiv.org//abs/2406.17276)

	Jikai Wang, Yi Su, Juntao Li, Qingrong Xia, Zi Ye, Xinyu Duan, Zhefeng Wang, Min Zhang


+ [Recite, Reconstruct, Recollect: Memorization in LMs as a Multifaceted Phenomenon](https://arxiv.org//abs/2406.17746)

	USVSN Sai Prashanth, Alvin Deng, Kyle O'Brien, Jyothir S V, Mohammad Aflah Khan, Jaydeep Borkar, Christopher A. Choquette-Choo, Jacob Ray Fuehne, Stella Biderman, Tracy Ke, Katherine Lee, Naomi Saphra

+ [From Distributional to Overton Pluralism: Investigating Large Language Model Alignment](https://arxiv.org//abs/2406.17692)

	Thom Lake, Eunsol Choi, Greg Durrett

+ [Brittle Minds, Fixable Activations: Understanding Belief Representations in Language Models](https://arxiv.org//abs/2406.17513)

	Matteo Bortoletto, Constantin Ruhdorfer, Lei Shi, Andreas Bulling

+ [BMIKE-53: Investigating Cross-Lingual Knowledge Editing with In-Context Learning](https://arxiv.org//abs/2406.17764)

	Ercong Nie, Bo Shao, Zifeng Ding, Mingyang Wang, Helmut Schmid, Hinrich Schütze

# 2024-06-24
+ [Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging](https://arxiv.org//abs/2406.16330)

	Deyuan Liu, Zhanyue Qin, Hairu Wang, Zhao Yang, Zecheng Wang, Fangying Rong, Qingbin Liu, Yanchao Hao, Xi Chen, Cunhang Fan, Zhao Lv, Zhiying Tu, Dianhui Chu, Bo Li, Dianbo Sui

# 2024-06-20
+ [ReaL: Efficient RLHF Training of Large Language Models with Parameter Reallocation](https://arxiv.org//abs/2406.14088)

	Zhiyu Mei, Wei Fu, Kaiwei Li, Guangju Wang, Huanchen Zhang, Yi Wu

+ [APEER: Automatic Prompt Engineering Enhances Large Language Model Reranking](https://arxiv.org//abs/2406.14449)

	Can Jin, Hongwu Peng, Shiyu Zhao, Zhenting Wang, Wujiang Xu, Ligong Han, Jiahui Zhao, Kai Zhong, Sanguthevar Rajasekaran, Dimitris N. Metaxas

+ [Tracing Representation Progression: Analyzing and Enhancing Layer-Wise Similarity](https://arxiv.org//abs/2406.14479)

	Jiachen Jiang, Jinxin Zhou, Zhihui Zhu

+ [Raising the Bar: Investigating the Values of Large Language Models via Generative Evolving Testing](https://arxiv.org//abs/2406.14230)

	Han Jiang, Xiaoyuan Yi, Zhihua Wei, Ziang Xiao, Shu Wang, Xing Xie

+ [CityBench: Evaluating the Capabilities of Large Language Models for Urban Tasks](https://arxiv.org//abs/2406.13945)

	Jie Feng, Jun Zhang, Tianhui Liu, Xin Zhang, Tianjian Ouyang, Junbo Yan, Yuwei Du, Siqi Guo, Yong Li

+ [CityGPT: Empowering Urban Spatial Cognition of Large Language Models](https://arxiv.org//abs/2406.13948)

	Jie Feng, Tianhui Liu, Yuwei Du, Siqi Guo, Yuming Lin, Yong Li

+ [PKU-SafeRLHF: Towards Multi-Level Safety Alignment for LLMs with Human Preference](https://arxiv.org//abs/2406.15513)

	Jiaming Ji, Donghai Hong, Borong Zhang, Boyuan Chen, Juntao Dai, Boren Zheng, Tianyi Qiu, Jiayi Zhou, Kaile Wang, Boxuan Li, Sirui Han, Yike Guo, Yaodong Yang

# 2024-06-19
+ [Neuro-symbolic Training for Reasoning over Spatial Language](https://arxiv.org//abs/2406.13828)

	Tanawan Premsri, Parisa Kordjamshidi

+ [BoA: Attention-aware Post-training Quantization without Backpropagation](https://arxiv.org//abs/2406.13474)

	Junhan Kim, Ho-young Kim, Eulrang Cho, Chungman Lee, Joonyoung Kim, Yongkweon Jeon

# 2024-06-18
+ [Exploring the Robustness of Language Models for Tabular Question Answering via Attention Analysis](https://arxiv.org//abs/2406.12719)

	Kushal Raj Bhandari, Sixue Xing, Soham Dan, Jianxi Gao

+ [Opt-Out: Investigating Entity-Level Unlearning for Large Language Models via Optimal Transport](https://arxiv.org//abs/2406.12329)

	Minseok Choi, Daniel Rim, Dohyun Lee, Jaegul Choo

+ [P-React: Synthesizing Topic-Adaptive Reactions of Personality Traits via Mixture of Specialized LoRA Experts](https://arxiv.org//abs/2406.12548)

	Yuhao Dan, Jie Zhou, Qin Chen, Junfeng Tian, Liang He

# 2024-06-17
+ [SPA-VL: A Comprehensive Safety Preference Alignment Dataset for Vision Language Model](https://arxiv.org//abs/2406.12030)

	Yongting Zhang, Lu Chen, Guodong Zheng, Yifeng Gao, Rui Zheng, Jinlan Fu, Zhenfei Yin, Senjie Jin, Yu Qiao, Xuanjing Huang, Feng Zhao, Tao Gui, Jing Shao

+ [GUICourse: From General Vision Language Models to Versatile GUI Agents](https://arxiv.org//abs/2406.11317)

	Wentong Chen, Junbo Cui, Jinyi Hu, Yujia Qin, Junjie Fang, Yue Zhao, Chongyi Wang, Jun Liu, Guirong Chen, Yupeng Huo, Yuan Yao, Yankai Lin, Zhiyuan Liu, Maosong Sun

+ [Compress then Serve: Serving Thousands of LoRA Adapters with Little Overhead](https://arxiv.org//abs/2407.00066)

	Rickard Brüel-Gabrielsson, Jiacheng Zhu, Onkar Bhardwaj, Leshem Choshen, Kristjan Greenewald, Mikhail Yurochkin, Justin Solomon

+ [A Semantic-Aware Layer-Freezing Approach to Computation-Efficient Fine-Tuning of Language Models](https://arxiv.org//abs/2406.11753)

	Jian Gu, Aldeida Aleti, Chunyang Chen, Hongyu Zhang

+ [Code-Switching Red-Teaming: LLM Evaluation for Safety and Multilingual Understanding](https://arxiv.org//abs/2406.15481)

	Haneul Yoo, Yongjin Yang, Hwaran Lee

+ [Incentivizing Quality Text Generation via Statistical Contracts](https://arxiv.org//abs/2406.11118)

	Eden Saig, Ohad Einav, Inbal Talgam-Cohen

+ [Efficient Sequential Decision Making with Large Language Models](https://arxiv.org//abs/2406.12125)

	Dingyang Chen, Qi Zhang, Yinglun Zhu

# 2024-06-16
+ [ShareLoRA: Parameter Efficient and Robust Large Language Model Fine-tuning via Shared Low-Rank Adaptation](https://arxiv.org//abs/2406.10785)

	Yurun Song, Junchen Zhao, Ian G. Harris, Sangeetha Abdu Jyothi

+ [RAEmoLLM: Retrieval Augmented LLMs for Cross-Domain Misinformation Detection Using In-Context Learning Based on Emotional Information](https://arxiv.org//abs/2406.11093)

	Zhiwei Liu, Kailai Yang, Qianqian Xie, Christine de Kock, Sophia Ananiadou, Eduard Hovy

# 2024-06-15
+ [Unlocking Large Language Model's Planning Capabilities with Maximum Diversity Fine-tuning](https://arxiv.org//abs/2406.10479)

	Wenjun Li, Changyu Chen, Pradeep Varakantham

+ [Task Facet Learning: A Structured Approach to Prompt Optimization](https://arxiv.org//abs/2406.10504)

	Gurusha Juneja, Gautam Jajoo, Nagarajan Natarajan, Hua Li, Jian Jiao, Amit Sharma

+ [BlockPruner: Fine-grained Pruning for Large Language Models](https://arxiv.org//abs/2406.10594)

	Longguang Zhong, Fanqi Wan, Ruijun Chen, Xiaojun Quan, Liangzhi Li

# 2024-06-14
+ [Recent Advances in Federated Learning Driven Large Language Models: A Survey on Architecture, Performance, and Security](https://arxiv.org//abs/2406.09831)

	Youyang Qu, Ming Liu, Tianqing Zhu, Longxiang Gao, Shui Yu, Wanlei Zhou

# 2024-06-13
+ [Talking Heads: Understanding Inter-layer Communication in Transformer Language Models](https://arxiv.org//abs/2406.09519)

	Jack Merullo, Carsten Eickhoff, Ellie Pavlick

+ [Online Bandit Learning with Offline Preference Data for Improved RLHF](https://arxiv.org//abs/2406.09574)

	Akhil Agnihotri, Rahul Jain, Deepak Ramachandran, Zheng Wen

+ [GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning](https://arxiv.org//abs/2406.09187)

	Zhen Xiang, Linzhi Zheng, Yanjie Li, Junyuan Hong, Qinbin Li, Han Xie, Jiawei Zhang, Zidi Xiong, Chulin Xie, Carl Yang, Dawn Song, Bo Li

+ [Multi-Agent Collaboration via Cross-Team Orchestration](https://arxiv.org//abs/2406.08979)

	Zhuoyun Du, Chen Qian, Wei Liu, Zihao Xie, YiFei Wang, Rennai Qiu, Yufan Dang, Weize Chen, Cheng Yang, Ye Tian, Xuantang Xiong, Lei Han

# 2024-06-12
+ [Enhancing Differential Testing With LLMs For Testing Deep Learning Libraries](https://arxiv.org//abs/2406.07944)

	Meiziniu Li, Dongze Li, Jianmeng Liu, Jialun Cao, Yongqiang Tian, Shing-Chi Cheung

+ [Watermarking Language Models with Error Correcting Codes](https://arxiv.org//abs/2406.10281)

	Patrick Chao, Yan Sun, Edgar Dobriban, Hamed Hassani

+ [Ad Auctions for LLMs via Retrieval Augmented Generation](https://arxiv.org//abs/2406.09459)

	MohammadTaghi Hajiaghayi, Sébastien Lahaie, Keivan Rezaei, Suho Shin

# 2024-06-11
+ [RS-Agent: Automating Remote Sensing Tasks through Intelligent Agent](https://arxiv.org//abs/2406.07089)

	Wenjia Xu, Zijian Yu, Boyang Mu, Zhiwei Wei, Yuanben Zhang, Guangzuo Li, Mugen Peng

+ [DCA-Bench: A Benchmark for Dataset Curation Agents](https://arxiv.org//abs/2406.07275)

	Benhao Huang, Yingzhuo Yu, Jin Huang, Xingjian Zhang, Jiaqi Ma

# 2024-06-10
+ [Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching](https://arxiv.org//abs/2406.06326)

	Xiaoying Zhang, Baolin Peng, Ye Tian, Jingyan Zhou, Yipeng Zhang, Haitao Mi, Helen Meng

+ [Multi-Prompting Decoder Helps Better Language Understanding](https://arxiv.org//abs/2406.06279)

	Zifeng Cheng, Zhaoling Chen, Zhiwei Jiang, Yafeng Yin, Cong Wang, Shiping Ge, Qing Gu

+ [Language Models Resist Alignment: Evidence From Data Compression](https://arxiv.org//abs/2406.06144)

	Jiaming Ji, Kaile Wang, Tianyi Qiu, Boyuan Chen, Jiayi Zhou, Changye Li, Hantao Lou, Juntao Dai, Yunhuai Liu, Yaodong Yang

# 2024-06-07
+ [Multi-Head RAG: Solving Multi-Aspect Problems with LLMs](https://arxiv.org//abs/2406.05085)

	Maciej Besta, Ales Kubicek, Robert Gerstenberger, Marcin Chrapek, Roman Niggli, Patrik Okanovic, Yi Zhu, Patrick Iff, Michal Podstawski, Lucas Weitzendorf, Mingyuan Chi, Joanna Gajda, Piotr Nyczyk, Jürgen Müller, Hubert Niewiadomski, Torsten Hoefler

+ [LlavaGuard: An Open VLM-based Framework for Safeguarding Vision Datasets and Models](https://arxiv.org//abs/2406.05113)

	Lukas Helff, Felix Friedrich, Manuel Brack, Kristian Kersting, Patrick Schramowski

# 2024-06-06
+ [Quantifying Misalignment Between Agents: Towards a Sociotechnical Understanding of Alignment](https://arxiv.org//abs/2406.04231)

	Aidan Kierans, Avijit Ghosh, Hananel Hazan, Shiri Dori-Hacohen

# 2024-06-05
+ [Item-Language Model for Conversational Recommendation](https://arxiv.org//abs/2406.02844)

	Li Yang, Anushya Subbiah, Hardik Patel, Judith Yue Li, Yanwei Song, Reza Mirghaderi, Vikram Aggarwal, Qifan Wang

# 2024-06-04
+ [PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling](https://arxiv.org//abs/2406.02069)

	Zefan Cai, Yichi Zhang, Bofei Gao, Yuliang Liu, Yucheng Li, Tianyu Liu, Keming Lu, Wayne Xiong, Yue Dong, Junjie Hu, Wen Xiao

+ [MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset](https://arxiv.org//abs/2406.02106)

	Weiqi Wang, Yangqiu Song

+ [Mitigate Position Bias in Large Language Models via Scaling a Single Dimension](https://arxiv.org//abs/2406.02536)

	Yijiong Yu, Huiqiang Jiang, Xufang Luo, Qianhui Wu, Chin-Yew Lin, Dongsheng Li, Yuqing Yang, Yongfeng Huang, Lili Qiu

+ [CheckEmbed: Effective Verification of LLM Solutions to Open-Ended Tasks](https://arxiv.org//abs/2406.02524)

	Maciej Besta, Lorenzo Paleari, Marcin Copik, Robert Gerstenberger, Ales Kubicek, Piotr Nyczyk, Patrick Iff, Eric Schreiber, Tanja Srindran, Tomasz Lehmann, Hubert Niewiadomski, Torsten Hoefler

+ [Dynamic and Adaptive Feature Generation with LLM](https://arxiv.org//abs/2406.03505)

	Xinhao Zhang, Jinghan Zhang, Banafsheh Rekabdar, Yuanchun Zhou, Pengfei Wang, Kunpeng Liu

+ [JBBQ: Japanese Bias Benchmark for Analyzing Social Biases in Large Language Models](https://arxiv.org//abs/2406.02050)

	Hitomi Yanaka, Namgi Han, Ryoma Kumon, Jie Lu, Masashi Takeshita, Ryo Sekizawa, Taisei Kato, Hiromi Arai

# 2024-06-03
+ [Re-ReST: Reflection-Reinforced Self-Training for Language Agents](https://arxiv.org//abs/2406.01495)

	Zi-Yi Dou, Cheng-Fu Yang, Xueqing Wu, Kai-Wei Chang, Nanyun Peng

+ [REvolve: Reward Evolution with Large Language Models using Human Feedback](https://arxiv.org//abs/2406.01309)

	Rishi Hazra, Alkis Sygkounas, Andreas Persson, Amy Loutfi, Pedro Zuidberg Dos Martires

+ [AI as Decision-Maker: Ethics and Risk Preferences of LLMs](https://arxiv.org//abs/2406.01168)

	Shumiao Ouyang, Hayong Yun, Xingjian Zheng

# 2024-06-01
+ [Efficient Open Set Single Image Test Time Adaptation of Vision Language Models](https://arxiv.org//abs/2406.00481)

	Manogna Sreenivas, Soma Biswas

# 2024-05-31
+ [OR-Bench: An Over-Refusal Benchmark for Large Language Models](https://arxiv.org//abs/2405.20947)

	Justin Cui, Wei-Lin Chiang, Ion Stoica, Cho-Jui Hsieh

# 2024-05-30
+ [Uncovering Bias in Large Vision-Language Models at Scale with Counterfactuals](https://arxiv.org//abs/2405.20152)

	Phillip Howard, Kathleen C. Fraser, Anahita Bhiwandiwalla, Svetlana Kiritchenko

# 2024-05-29
+ [Nearest Neighbor Speculative Decoding for LLM Generation and Attribution](https://arxiv.org//abs/2405.19325)

	Minghan Li, Xilun Chen, Ari Holtzman, Beidi Chen, Jimmy Lin, Wen-tau Yih, Xi Victoria Lin

+ [Towards Better Chain-of-Thought: A Reflection on Effectiveness and Faithfulness](https://arxiv.org//abs/2405.18915)

	Jiachun Li, Pengfei Cao, Yubo Chen, Jiexin Xu, Huaijun Li, Xiaojian Jiang, Kang Liu, Jun Zhao

+ [Learning from Litigation: Graphs and LLMs for Retrieval and Reasoning in eDiscovery](https://arxiv.org//abs/2405.19164)

	Sounak Lahiri, Sumit Pai, Tim Weninger, Sanmitra Bhattacharya

+ [Does learning the right latent variables necessarily improve in-context learning?](https://arxiv.org//abs/2405.19162)

	Sarthak Mittal, Eric Elmoznino, Leo Gagnon, Sangnie Bhardwaj, Tom Marty, Dhanya Sridhar, Guillaume Lajoie

# 2024-05-28
+ [Unified Preference Optimization: Language Model Alignment Beyond the Preference Frontier](https://arxiv.org//abs/2405.17956)

	Anirudhan Badrinath, Prabhat Agarwal, Jiajing Xu

+ [Don't Miss the Forest for the Trees: Attentional Vision Calibration for Large Vision Language Models](https://arxiv.org//abs/2405.17820)

	Sangmin Woo, Donguk Kim, Jaehyuk Jang, Yubin Choi, Changick Kim

+ [The Impossibility of Fair LLMs](https://arxiv.org//abs/2406.03198)

	Jacy Anthis, Kristian Lum, Michael Ekstrand, Avi Feller, Chenhao Tan

# 2024-05-27
+ [UniICL: An Efficient Unified Framework Unifying Compression, Selection, and Generation](https://arxiv.org//abs/2405.17062)

	Jun Gao, Qi Lv, Zili Wang, Tianxiang Wu, Ziqiang Cao, Wenjie Li

# 2024-05-24
+ [Emergence of a High-Dimensional Abstraction Phase in Language Transformers](https://arxiv.org//abs/2405.15471)

	Emily Cheng, Diego Doimo, Corentin Kervadec, Iuri Macocco, Jade Yu, Alessandro Laio, Marco Baroni

+ [Sparse Matrix in Large Language Model Fine-tuning](https://arxiv.org//abs/2405.15525)

	Haoze He, Juncheng Billy Li, Xuan Jiang, Heather Miller

# 2024-05-23
+ [OAC: Output-adaptive Calibration for Accurate Post-training Quantization](https://arxiv.org//abs/2405.15025)

	Ali Edalati, Alireza Ghaffari, Mahsa Ghazvini Nejad, Lu Hou, Boxing Chen, Masoud Asgharian, Vahid Partovi Nia

+ [LoRA-Ensemble: Efficient Uncertainty Modelling for Self-Attention Networks](https://arxiv.org//abs/2405.14438)

	Dominik J. Mühlematter, Michelle Halbheer, Alexander Becker, Dominik Narnhofer, Helge Aasen, Konrad Schindler, Mehmet Ozgur Turkoglu

+ [SliM-LLM: Salience-Driven Mixed-Precision Quantization for Large Language Models](https://arxiv.org//abs/2405.14917)

	Wei Huang, Haotong Qin, Yangdong Liu, Yawei Li, Qinshuo Liu, Xianglong Liu, Luca Benini, Michele Magno, Shiming Zhang, Xiaojuan Qi

+ [Let's Fuse Step by Step: A Generative Fusion Decoding Algorithm with LLMs for Robust and Instruction-Aware ASR and OCR](https://arxiv.org//abs/2405.14259)

	Chan-Jan Hsu, Yi-Chang Chen, Feng-Ting Liao, Pei-Chen Ho, Yu-Hsiang Wang, Po-Chun Hsu, Da-shan Shiu

# 2024-05-22
+ [FiDeLiS: Faithful Reasoning in Large Language Model for Knowledge Graph Question Answering](https://arxiv.org//abs/2405.13873)

	Yuan Sui, Yufei He, Nian Liu, Xiaoxin He, Kun Wang, Bryan Hooi

+ [Mosaic-IT: Cost-Free Compositional Data Synthesis for Instruction Tuning](https://arxiv.org//abs/2405.13326)

	Ming Li, Pei Chen, Chenguang Wang, Hongyu Zhao, Yijun Liang, Yupeng Hou, Fuxiao Liu, Tianyi Zhou

# 2024-05-20
+ [(Perhaps) Beyond Human Translation: Harnessing Multi-Agent Collaboration for Translating Ultra-Long Literary Texts](https://arxiv.org//abs/2405.11804)

	Minghao Wu, Jiahao Xu, Yulin Yuan, Gholamreza Haffari, Longyue Wang, Weihua Luo, Kaifu Zhang

# 2024-05-17
+ [ActiveLLM: Large Language Model-based Active Learning for Textual Few-Shot Scenarios](https://arxiv.org//abs/2405.10808)

	Markus Bayer, Justin Lutz, Christian Reuter

# 2024-05-13
+ [AgentClinic: a multimodal agent benchmark to evaluate AI in simulated clinical environments](https://arxiv.org//abs/2405.07960)

	Samuel Schmidgall, Rojin Ziaei, Carl Harris, Eduardo Reis, Jeffrey Jopling, Michael Moor

# 2024-05-09
+ [Smurfs: Multi-Agent System using Context-Efficient DFSDT for Tool Planning](https://arxiv.org//abs/2405.05955)

	Junzhi Chen, Juhao Liang, Benyou Wang

# 2024-05-08
+ [Large Language Models for Cyber Security: A Systematic Literature Review](https://arxiv.org//abs/2405.04760)

	Hanxiang Xu, Shenao Wang, Ningke Li, Kailong Wang, Yanjie Zhao, Kai Chen, Ting Yu, Yang Liu, Haoyu Wang

# 2024-05-07
+ [QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving](https://arxiv.org//abs/2405.04532)

	Yujun Lin, Haotian Tang, Shang Yang, Zhekai Zhang, Guangxuan Xiao, Chuang Gan, Song Han

+ [Folded Context Condensation in Path Integral Formalism for Infinite Context Transformers](https://arxiv.org//abs/2405.04620)

	Won-Gi Paeng, Daesuk Kwon, Kyungwon Jeong, Honggyo Suh

+ [Fleet of Agents: Coordinated Problem Solving with Large Language Models](https://arxiv.org//abs/2405.06691)

	Lars Klein, Nearchos Potamitis, Roland Aydin, Robert West, Caglar Gulcehre, Akhil Arora

+ [FlashBack:Efficient Retrieval-Augmented Language Modeling for Long Context Inference](https://arxiv.org//abs/2405.04065)

	Runheng Liu, Xingchen Xiao, Heyan Huang, Zewen Chi, Zhijing Wu

# 2024-05-06
+ [Outlier Gradient Analysis: Efficiently Identifying Detrimental Training Samples for Deep Learning Models](https://arxiv.org//abs/2405.03869)

	Anshuman Chhabra, Bo Li, Jian Chen, Prasant Mohapatra, Hongfu Liu

+ [Anchored Answers: Unravelling Positional Bias in GPT-2's Multiple-Choice Questions](https://arxiv.org//abs/2405.03205)

	Ruizhe Li, Yanjun Gao

# 2024-05-03
+ [CodeGRAG: Bridging the Gap between Natural Language and Programming Language via Graphical Retrieval Augmented Generation](https://arxiv.org//abs/2405.02355)

	Kounianhua Du, Jizheng Chen, Renting Rui, Huacan Chai, Lingyue Fu, Wei Xia, Yasheng Wang, Ruiming Tang, Yong Yu, Weinan Zhang

# 2024-05-01
+ [Mixture of insighTful Experts (MoTE): The Synergy of Thought Chains and Expert Mixtures in Self-Alignment](https://arxiv.org//abs/2405.00557)

	Zhili Liu, Yunhao Gou, Kai Chen, Lanqing Hong, Jiahui Gao, Fei Mi, Yu Zhang, Zhenguo Li, Xin Jiang, Qun Liu, James T. Kwok

# 2024-04-30
+ [Calibration of Large Language Models on Code Summarization](https://arxiv.org//abs/2404.19318)

	Yuvraj Virk, Premkumar Devanbu, Toufique Ahmed

# 2024-04-29
+ [DPO Meets PPO: Reinforced Token Optimization for RLHF](https://arxiv.org//abs/2404.18922)

	Han Zhong, Zikang Shan, Guhao Feng, Wei Xiong, Xinle Cheng, Li Zhao, Di He, Jiang Bian, Liwei Wang

+ [A Framework for Real-time Safeguarding the Text Generation of Large Language Model](https://arxiv.org//abs/2404.19048)

	Ximing Dong, Dayi Lin, Shaowei Wang, Ahmed E. Hassan

# 2024-04-27
+ [Temporal Scaling Law for Large Language Models](https://arxiv.org//abs/2404.17785)

	Yizhe Xiong, Xiansheng Chen, Xin Ye, Hui Chen, Zijia Lin, Haoran Lian, Zhenpeng Su, Wei Huang, Jianwei Niu, Jungong Han, Guiguang Ding

# 2024-04-26
+ [Large Language Model Agent as a Mechanical Designer](https://arxiv.org//abs/2404.17525)

	Yayati Jadhav, Amir Barati Farimani

+ [PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction in Murder Mystery Games](https://arxiv.org//abs/2404.17662)

	Qinglin Zhu, Runcong Zhao, Bin Liang, Jinhua Du, Lin Gui, Yulan He

# 2024-04-25
+ [Towards Adapting Open-Source Large Language Models for Expert-Level Clinical Note Generation](https://arxiv.org//abs/2405.00715)

	Hanyin Wang, Chufan Gao, Bolun Liu, Qiping Xu, Guleid Hussein, Mohamad El Labban, Kingsley Iheasirim, Hariprasad Korsapati, Chuck Outcalt, Jimeng Sun

+ [Model Extrapolation Expedites Alignment](https://arxiv.org//abs/2404.16792)

	Chujie Zheng, Ziqi Wang, Heng Ji, Minlie Huang, Nanyun Peng

# 2024-04-20
+ [Personalized Wireless Federated Learning for Large Language Models](https://arxiv.org//abs/2404.13238)

	Feibo Jiang, Li Dong, Siwei Tu, Yubo Peng, Kezhi Wang, Kun Yang, Cunhua Pan, Dusit Niyato

# 2024-04-19
+ [Relevant or Random: Can LLMs Truly Perform Analogical Reasoning?](https://arxiv.org//abs/2404.12728)

	Chengwei Qin, Wenhan Xia, Tan Wang, Fangkai Jiao, Yuchen Hu, Bosheng Ding, Ruirui Chen, Shafiq Joty

# 2024-04-18
+ [Lean Copilot: Large Language Models as Copilots for Theorem Proving in Lean](https://arxiv.org//abs/2404.12534)

	Peiyang Song, Kaiyu Yang, Anima Anandkumar

# 2024-04-17
+ [Offset Unlearning for Large Language Models](https://arxiv.org//abs/2404.11045)

	James Y. Huang, Wenxuan Zhou, Fei Wang, Fred Morstatter, Sheng Zhang, Hoifung Poon, Muhao Chen

# 2024-04-13
+ [T-REX: Mixture-of-Rank-One-Experts with Semantic-aware Intuition for Multi-task Large Language Model Finetuning](https://arxiv.org//abs/2404.08985)

	Rongyu Zhang, Yijiang Liu, Huanrui Yang, Shenli Zheng, Dan Wang, Yuan Du, Li Du, Shanghang Zhang

# 2024-04-10
+ [Sample-Efficient Human Evaluation of Large Language Models via Maximum Discrepancy Competition](https://arxiv.org//abs/2404.08008)

	Kehua Feng, Keyan Ding, Hongzhi Tan, Kede Ma, Zhihua Wang, Shuangquan Guo, Yuzhou Cheng, Ge Sun, Guozhou Zheng, Qiang Zhang, Huajun Chen

# 2024-04-06
+ [Multilingual Brain Surgeon: Large Language Models Can be Compressed Leaving No Language Behind](https://arxiv.org//abs/2404.04748)

	Hongchuan Zeng, Hongshen Xu, Lu Chen, Kai Yu

# 2024-04-04
+ [PRobELM: Plausibility Ranking Evaluation for Language Models](https://arxiv.org//abs/2404.03818)

	Zhangdie Yuan, Eric Chamoun, Rami Aly, Chenxi Whitehouse, Andreas Vlachos

# 2024-04-02
+ [Poro 34B and the Blessing of Multilinguality](https://arxiv.org//abs/2404.01856)

	Risto Luukkonen, Jonathan Burdge, Elaine Zosa, Aarne Talman, Ville Komulainen, Väinö Hatanpää, Peter Sarlin, Sampo Pyysalo

# 2024-04-01
+ [Query Performance Prediction using Relevance Judgments Generated by Large Language Models](https://arxiv.org//abs/2404.01012)

	Chuan Meng, Negar Arabzadeh, Arian Askari, Mohammad Aliannejadi, Maarten de Rijke

+ [Emphasising Structured Information: Integrating Abstract Meaning Representation into LLMs for Enhanced Open-Domain Dialogue Evaluation](https://arxiv.org//abs/2404.01129)

	Bohao Yang, Kun Zhao, Dong Liu, Liang Zhan, Chenghua Lin

# 2024-03-31
+ [ParaICL: Towards Parallel In-Context Learning](https://arxiv.org//abs/2404.00570)

	Xingxuan Li, Xuan-Phi Nguyen, Shafiq Joty, Lidong Bing

+ [Algorithmic Collusion by Large Language Models](https://arxiv.org//abs/2404.00806)

	Sara Fish, Yannai A. Gonczarowski, Ran I. Shorrer

# 2024-03-28
+ [Large Language Models Are Struggle to Cope with Unreasonability in Math Problems](https://arxiv.org//abs/2403.19346)

	Jingyuan Ma, Damai Dai, Zihang Yuan, Rui li, Weilin Luo, Bin Wang, Qun Liu, Lei Sha, Zhifang Sui

# 2024-03-27
+ [Leveraging Large Language Models for Relevance Judgments in Legal Case Retrieval](https://arxiv.org//abs/2403.18405)

	Shengjie Ma, Qi Chu, Jiaxin Mao, Xuhui Jiang, Haozhe Duan, Chong Chen

# 2024-03-25
+ [AIOS: LLM Agent Operating System](https://arxiv.org//abs/2403.16971)

	Kai Mei, Xi Zhu, Wujiang Xu, Wenyue Hua, Mingyu Jin, Zelong Li, Shuyuan Xu, Ruosong Ye, Yingqiang Ge, Yongfeng Zhang

# 2024-03-21
+ [Agentic AI: The Era of Semantic Decoding](https://arxiv.org//abs/2403.14562)

	Maxime Peyrard, Martin Josifoski, Robert West

# 2024-03-19
+ [To Help or Not to Help: LLM-based Attentive Support for Human-Robot Group Interactions](https://arxiv.org//abs/2403.12533)

	Daniel Tanneberg, Felix Ocker, Stephan Hasler, Joerg Deigmoeller, Anna Belardinelli, Chao Wang, Heiko Wersing, Bernhard Sendhoff, Michael Gienger

+ [Using Shapley interactions to understand how models use structure](https://arxiv.org//abs/2403.13106)

	Divyansh Singhvi, Diganta Misra, Andrej Erkelens, Raghav Jain, Isabel Papadimitriou, Naomi Saphra

+ [Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices](https://arxiv.org//abs/2403.12503)

	Sara Abdali, Richard Anarfi, CJ Barberan, Jia He, Erfan Shayegani

# 2024-03-15
+ [Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning](https://arxiv.org//abs/2403.10056)

	Yongquan He, Wenyuan Zhang, Xuancheng Huang, Peng Zhang

# 2024-03-13
+ [Usable XAI: 10 Strategies Towards Exploiting Explainability in the LLM Era](https://arxiv.org//abs/2403.08946)

	Xuansheng Wu, Haiyan Zhao, Yaochen Zhu, Yucheng Shi, Fan Yang, Lijie Hu, Tianming Liu, Xiaoming Zhai, Wenlin Yao, Jundong Li, Mengnan Du, Ninghao Liu

+ [CleanAgent: Automating Data Standardization with LLM-based Agents](https://arxiv.org//abs/2403.08291)

	Danrui Qi, Zhengjie Miao, Jiannan Wang

# 2024-03-08
+ [Bias-Augmented Consistency Training Reduces Biased Reasoning in Chain-of-Thought](https://arxiv.org//abs/2403.05518)

	James Chua, Edward Rees, Hunar Batra, Samuel R. Bowman, Julian Michael, Ethan Perez, Miles Turpin

# 2024-03-04
+ [DECIDER: A Dual-System Rule-Controllable Decoding Framework for Language Generation](https://arxiv.org//abs/2403.01954)

	Chen Xu, Tian Lan, Yu Ji, Changlong Yu, Wei Wang, Jun Gao, Qunxi Dong, Kun Qian, Piji Li, Wei Bi, Bin Hu

# 2024-02-29
+ [LoRATK: LoRA Once, Backdoor Everywhere in the Share-and-Play Ecosystem](https://arxiv.org//abs/2403.00108)

	Hongyi Liu, Shaochen Zhong, Xintong Sun, Minghao Tian, Mohsen Hariri, Zirui Liu, Ruixiang Tang, Zhimeng Jiang, Jiayi Yuan, Yu-Neng Chuang, Li Li, Soo-Hyun Choi, Rui Chen, Vipin Chaudhary, Xia Hu

+ [FlexLLM: A System for Co-Serving Large Language Model Inference and Parameter-Efficient Finetuning](https://arxiv.org//abs/2402.18789)

	Gabriele Oliaro, Xupeng Miao, Xinhao Cheng, Vineeth Kada, Ruohan Gao, Yingyi Huang, Remi Delacourt, April Yang, Yingcheng Wang, Mengdi Wu, Colin Unger, Zhihao Jia

+ [PRSA: Prompt Stealing Attacks against Real-World Prompt Services](https://arxiv.org//abs/2402.19200)

	Yong Yang, Changjiang Li, Qingming Li, Oubo Ma, Haoyu Wang, Zonghui Wang, Yandong Gao, Wenzhi Chen, Shouling Ji

# 2024-02-26
+ [Do Large Language Models Latently Perform Multi-Hop Reasoning?](https://arxiv.org//abs/2402.16837)

	Sohee Yang, Elena Gribovskaya, Nora Kassner, Mor Geva, Sebastian Riedel

# 2024-02-23
+ [Bias and Volatility: A Statistical Framework for Evaluating Large Language Model's Stereotypes and the Associated Generation Inconsistency](https://arxiv.org//abs/2402.15481)

	Yiran Liu, Ke Yang, Zehan Qi, Xiao Liu, Yang Yu, ChengXiang Zhai

# 2024-02-22
+ [COBIAS: Assessing the Contextual Reliability of Bias Benchmarks for Language Models](https://arxiv.org//abs/2402.14889)

	Priyanshul Govil, Hemang Jain, Vamshi Krishna Bonagiri, Aman Chadha, Ponnurangam Kumaraguru, Manas Gaur, Sanorita Dey

# 2024-02-21
+ [Round Trip Translation Defence against Large Language Model Jailbreaking Attacks](https://arxiv.org//abs/2402.13517)

	Canaan Yung, Hadi Mohaghegh Dolatabadi, Sarah Erfani, Christopher Leckie

+ [MlingConf: A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models](https://arxiv.org//abs/2402.13606)

	Boyang Xue, Hongru Wang, Rui Wang, Sheng Wang, Zezhong Wang, Yiming Du, Bin Liang, Wenxuan Zhang, Kam-Fai Wong

# 2024-02-20
+ [FormulaReasoning: A Dataset for Formula-Based Numerical Reasoning](https://arxiv.org//abs/2402.12692)

	Xiao Li, Bolin Zhu, Kaiwen Shi, Sichen Liu, Yin Zhu, Yiwei Liu, Gong Cheng

+ [Bias in Language Models: Beyond Trick Tests and Toward RUTEd Evaluation](https://arxiv.org//abs/2402.12649)

	Kristian Lum, Jacy Reese Anthis, Kevin Robinson, Chirag Nagpal, Alexander D'Amour

# 2024-02-19
+ [Uncertainty quantification in fine-tuned LLMs using LoRA ensembles](https://arxiv.org//abs/2402.12264)

	Oleksandr Balabanov, Hampus Linander

+ [Structure Guided Large Language Model for SQL Generation](https://arxiv.org//abs/2402.13284)

	Qinggang Zhang, Hao Chen, Junnan Dong, Shengyuan Chen, Feiran Huang, Xiao Huang

+ [Ask Optimal Questions: Aligning Large Language Models with Retriever's Preference in Conversation](https://arxiv.org//abs/2402.11827)

	Chanwoong Yoon, Gangwoo Kim, Byeongguk Jeon, Sungdong Kim, Yohan Jo, Jaewoo Kang

# 2024-02-16
+ [Can We Verify Step by Step for Incorrect Answer Detection?](https://arxiv.org//abs/2402.10528)

	Xin Xu, Shizhe Diao, Can Yang, Yang Wang

# 2024-02-15
+ [CodeMind: Evaluating Large Language Models for Code Reasoning](https://arxiv.org//abs/2402.09664)

	Changshu Liu, Yang Chen, Reyhaneh Jabbarvand

# 2024-02-14
+ [How Secure Are Large Language Models (LLMs) for Navigation in Urban Environments?](https://arxiv.org//abs/2402.09546)

	Congcong Wen, Jiazhao Liang, Shuaihang Yuan, Hao Huang, Geeta Chandra Raju Bethala, Yu-Shen Liu, Mengyu Wang, Anthony Tzes, Yi Fang

# 2024-02-13
+ ["Reasoning" with Rhetoric: On the Style-Evidence Tradeoff in LLM-Generated Counter-Arguments](https://arxiv.org//abs/2402.08498)

	Preetika Verma, Kokil Jaidka, Svetlana Churina

# 2024-02-10
+ [Fiddler: CPU-GPU Orchestration for Fast Inference of Mixture-of-Experts Models](https://arxiv.org//abs/2402.07033)

	Keisuke Kamahori, Tian Tang, Yile Gu, Kan Zhu, Baris Kasikci

# 2024-02-09
+ [EntGPT: Entity Linking with Generative Large Language Models](https://arxiv.org//abs/2402.06738)

	Yifan Ding, Amrit Poudel, Qingkai Zeng, Tim Weninger, Balaji Veeramani, Sanmitra Bhattacharya

# 2024-02-05
+ [LLM Multi-Agent Systems: Challenges and Open Problems](https://arxiv.org//abs/2402.03578)

	Shanshan Han, Qifan Zhang, Yuhang Yao, Weizhao Jin, Zhaozhuo Xu

# 2024-02-02
+ [Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach](https://arxiv.org//abs/2402.01454)

	Masayuki Takayama, Tadahisa Okuda, Thong Pham, Tatsuyoshi Ikenoue, Shingo Fukuma, Shohei Shimizu, Akiyoshi Sannai

# 2024-02-01
+ [On the Challenges of Fuzzing Techniques via Large Language Models](https://arxiv.org//abs/2402.00350)

	Linghan Huang, Peizhou Zhao, Huaming Chen, Lei Ma

# 2024-01-30
+ [Incoherent Probability Judgments in Large Language Models](https://arxiv.org//abs/2401.16646)

	Jian-Qiao Zhu, Thomas L. Griffiths

+ [Weak-to-Strong Jailbreaking on Large Language Models](https://arxiv.org//abs/2401.17256)

	Xuandong Zhao, Xianjun Yang, Tianyu Pang, Chao Du, Lei Li, Yu-Xiang Wang, William Yang Wang

# 2024-01-29
+ [An Insight into Security Code Review with LLMs: Capabilities, Obstacles, and Influential Factors](https://arxiv.org//abs/2401.16310)

	Jiaxin Yu, Peng Liang, Yujia Fu, Amjed Tahir, Mojtaba Shahin, Chong Wang, Yangxiao Cai

# 2024-01-26
+ [Unearthing Large Scale Domain-Specific Knowledge from Public Corpora](https://arxiv.org//abs/2401.14624)

	Zhaoye Fei, Yunfan Shao, Linyang Li, Zhiyuan Zeng, Conghui He, Qipeng Guo, Hang Yan, Dahua Lin, Xipeng Qiu

# 2024-01-16
+ [Contrastive Perplexity for Controlled Generation: An Application in Detoxifying Large Language Models](https://arxiv.org//abs/2401.08491)

	Tassilo Klein, Moin Nabi

# 2024-01-03
+ [Theoretical guarantees on the best-of-n alignment policy](https://arxiv.org//abs/2401.01879)

	Ahmad Beirami, Alekh Agarwal, Jonathan Berant, Alexander D'Amour, Jacob Eisenstein, Chirag Nagpal, Ananda Theertha Suresh

# 2023-12-28
+ [Beyond Output Matching: Bidirectional Alignment for Enhanced In-Context Learning](https://arxiv.org//abs/2312.17055)

	Chengwei Qin, Wenhan Xia, Fangkai Jiao, Chen Chen, Yuchen Hu, Bosheng Ding, Ruirui Chen, Shafiq Joty

+ [Enhancing Open-Domain Task-Solving Capability of LLMs via Autonomous Tool Integration from GitHub](https://arxiv.org//abs/2312.17294)

	Bohan Lyu, Xin Cong, Heyang Yu, Pan Yang, Yujia Qin, Yining Ye, Yaxi Lu, Zhong Zhang, Yukun Yan, Yankai Lin, Zhiyuan Liu, Maosong Sun

# 2023-12-21
+ [Large Language Models are Miscalibrated In-Context Learners](https://arxiv.org//abs/2312.13772)

	Chengzu Li, Han Zhou, Goran Glavaš, Anna Korhonen, Ivan Vulić

# 2023-12-11
+ [On Meta-Prompting](https://arxiv.org//abs/2312.06562)

	Adrian de Wynter, Xun Wang, Qilong Gu, Si-Qing Chen

# 2023-12-04
+ [LLM A*: Human in the Loop Large Language Models Enabled A* Search for Robotics](https://arxiv.org//abs/2312.01797)

	Hengjia Xiao, Peng Wang, Mingzhe Yu, Mattia Robbiani

# 2023-11-30
+ [RaDialog: A Large Vision-Language Model for Radiology Report Generation and Conversational Assistance](https://arxiv.org//abs/2311.18681)

	Chantal Pellegrini, Ege Özsoy, Benjamin Busam, Nassir Navab, Matthias Keicher

# 2023-11-16
+ [Automating the Generation of Prompts for LLM-based Action Choice in PDDL Planning](https://arxiv.org//abs/2311.09830)

	Katharina Stein, Daniel Fišer, Jörg Hoffmann, Alexander Koller

# 2023-11-07
+ [Watermarks in the Sand: Impossibility of Strong Watermarking for Generative Models](https://arxiv.org//abs/2311.04378)

	Hanlin Zhang, Benjamin L. Edelman, Danilo Francati, Daniele Venturi, Giuseppe Ateniese, Boaz Barak

# 2023-11-06
+ [GLEN: Generative Retrieval via Lexical Index Learning](https://arxiv.org//abs/2311.03057)

	Sunkyung Lee, Minjin Choi, Jongwuk Lee

# 2023-10-29
+ [Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game](https://arxiv.org//abs/2310.18940)

	Zelai Xu, Chao Yu, Fei Fang, Yu Wang, Yi Wu

# 2023-10-20
+ [Towards Understanding Sycophancy in Language Models](https://arxiv.org//abs/2310.13548)

	Mrinank Sharma, Meg Tong, Tomasz Korbak, David Duvenaud, Amanda Askell, Samuel R. Bowman, Newton Cheng, Esin Durmus, Zac Hatfield-Dodds, Scott R. Johnston, Shauna Kravec, Timothy Maxwell, Sam McCandlish, Kamal Ndousse, Oliver Rausch, Nicholas Schiefer, Da Yan, Miranda Zhang, Ethan Perez

# 2023-10-16
+ [Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models](https://arxiv.org//abs/2310.10378)

	Jirui Qi, Raquel Fernández, Arianna Bisazza

# 2023-10-12
+ [Language Models are Universal Embedders](https://arxiv.org//abs/2310.08232)

	Xin Zhang, Zehan Li, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang, Min Zhang

# 2023-10-11
+ [CoPAL: Corrective Planning of Robot Actions with Large Language Models](https://arxiv.org//abs/2310.07263)

	Frank Joublin, Antonello Ceravola, Pavel Smirnov, Felix Ocker, Joerg Deigmoeller, Anna Belardinelli, Chao Wang, Stephan Hasler, Daniel Tanneberg, Michael Gienger


+ [QFT: Quantized Full-parameter Tuning of LLMs with Affordable Resources](https://arxiv.org//abs/2310.07147)

	Zhikai Li, Xiaoxuan Liu, Banghua Zhu, Zhen Dong, Qingyi Gu, Kurt Keutzer

# 2023-10-07
+ [Uncovering Model Processing Strategies with Non-Negative Per-Example Fisher Factorization](https://arxiv.org//abs/2310.04649)

	Michael Matena, Colin Raffel

# 2023-10-05
+ [LLM-Coordination: Evaluating and Analyzing Multi-agent Coordination Abilities in Large Language Models](https://arxiv.org//abs/2310.03903)

	Saaket Agashe, Yue Fan, Anthony Reyna, Xin Eric Wang

# 2023-09-21
+ [Automating construction contract review using knowledge graph-enhanced large language models](https://arxiv.org//abs/2309.12132)

	Chunmo Zheng, Saika Wong, Xing Su, Yinqiu Tang, Ahsan Nawaz, Mohamad Kassem

# 2023-09-15
+ [EvoPrompt: Connecting LLMs with Evolutionary Algorithms Yields Powerful Prompt Optimizers](https://arxiv.org//abs/2309.08532)

	Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song, Xu Tan, Guoqing Liu, Jiang Bian, Yujiu Yang

# 2023-08-29
+ [Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models](https://arxiv.org//abs/2308.15022)

	Qingyue Wang, Yanhe Fu, Yanan Cao, Shuai Wang, Zhiliang Tian, Liang Ding

# 2023-08-17
+ [Semantic Consistency for Assuring Reliability of Large Language Models](https://arxiv.org//abs/2308.09138)

	Harsh Raj, Vipul Gupta, Domenic Rosati, Subhabrata Majumdar

# 2023-07-07
+ [GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest](https://arxiv.org//abs/2307.03601)

	Shilong Zhang, Peize Sun, Shoufa Chen, Min Xiao, Wenqi Shao, Wenwei Zhang, Yu Liu, Kai Chen, Ping Luo

# 2023-06-14
+ [WizardCoder: Empowering Code Large Language Models with Evol-Instruct](https://arxiv.org//abs/2306.08568)

	Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, Daxin Jiang

# 2023-05-26
+ [Playing repeated games with Large Language Models](https://arxiv.org//abs/2305.16867)

	Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, Eric Schulz

# 2023-05-23
+ [Physics of Language Models: Part 1, Learning Hierarchical Language Structures](https://arxiv.org//abs/2305.13673)

	Zeyuan Allen-Zhu, Yuanzhi Li

# 2023-05-01
+ [Large Linguistic Models: Investigating LLMs' metalinguistic abilities](https://arxiv.org//abs/2305.00948)

	Gašper Beguš, Maksymilian Dąbkowski, Ryan Rhodes

# 2023-04-24
+ [WizardLM: Empowering large pre-trained language models to follow complex instructions](https://arxiv.org//abs/2304.12244)

	Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, Qingwei Lin, Daxin Jiang

# 2023-04-04
+ [The Vector Grounding Problem](https://arxiv.org//abs/2304.01481)

	Dimitri Coelho Mollo, Raphaël Millière

# 2023-03-03
+ [Prophet: Prompting Large Language Models with Complementary Answer Heuristics for Knowledge-based Visual Question Answering](https://arxiv.org//abs/2303.01903)

	Zhou Yu, Xuecheng Ouyang, Zhenwei Shao, Meng Wang, Jun Yu

# 2023-01-11
+ [Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability](https://arxiv.org//abs/2301.04709)

	Atticus Geiger, Duligur Ibeling, Amir Zur, Maheep Chaudhary, Sonakshi Chauhan, Jing Huang, Aryaman Arora, Zhengxuan Wu, Noah Goodman, Christopher Potts, Thomas Icard

# 2022-11-10
+ [ADEPT: A DEbiasing PrompT Framework](https://arxiv.org//abs/2211.05414)

	Ke Yang, Charles Yu, Yi Fung, Manling Li, Heng Ji

