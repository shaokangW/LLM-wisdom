# LLM-wisdom
The papers related to the LLM wisdom, including test-time scaling, knowledge editing, model recognition, capacity enhancement, RAG, Agent, internal mechanism of LLM and etc. 

# 2025-05-23
+ [Misaligning Reasoning with Answers -- A Framework for Assessing LLM CoT Robustness](https://arxiv.org//abs/2505.17406)

	Enyi Jiang, Changming Xu, Nischay Singh, Gagandeep Singh

+ [From Reasoning to Generalization: Knowledge-Augmented LLMs for ARC Benchmark](https://arxiv.org//abs/2505.17482)

	Chao Lei, Nir Lipovetzky, Krista A. Ehinger, Yanchuan Chang

+ [Probe by Gaming: A Game-based Benchmark for Assessing Conceptual Knowledge in LLMs](https://arxiv.org//abs/2505.17512)

	Shuhang Xu, Weijian Deng, Yixuan Zhou, Fangwei Zhong

+ [Optimizing Retrieval-Augmented Generation for Electrical Engineering: A Case Study on ABB Circuit Breakers](https://arxiv.org//abs/2505.17520)

	Salahuddin Alawadhi, Noorhan Abbas

+ [USTBench: Benchmarking and Dissecting Spatiotemporal Reasoning of LLMs as Urban Agents](https://arxiv.org//abs/2505.17572)

	Siqi Lai, Yansong Ning, Zirui Yuan, Zhixi Chen, Hao Liu

+ [Controlled Agentic Planning & Reasoning for Mechanism Synthesis](https://arxiv.org//abs/2505.17607)

	João Pedro Gandarela, Thiago Rios, Stefan Menzel, André Freitas

+ [Does Chain-of-Thought Reasoning Really Reduce Harmfulness from Jailbreaking?](https://arxiv.org//abs/2505.17650)

	Chengda Lu, Xiaoyu Fan, Yu Huang, Rongwu Xu, Jijie Li, Wei Xu

+ [GeoGramBench: Benchmarking the Geometric Program Reasoning in Modern LLMs](https://arxiv.org//abs/2505.17653)

	Shixian Luo, Zezhou Zhu, Yu Yuan, Yuncheng Yang, Lianlei Shan, Yong Wu

+ [Rethinking Agent Design: From Top-Down Workflows to Bottom-Up Skill Evolution](https://arxiv.org//abs/2505.17673)

	Jiawei Du, Jinlong Wu, Yuzheng Chen, Yucheng Hu, Bing Li, Joey Tianyi Zhou

+ [CIKT: A Collaborative and Iterative Knowledge Tracing Framework with Large Language Models](https://arxiv.org//abs/2505.17705)

	Runze Li, Siyu Wu, Jun Wang, Wei Zhang

+ [Automating Safety Enhancement for LLM-based Agents with Synthetic Risk Scenarios](https://arxiv.org//abs/2505.17735)

	Xueyang Zhou, Weidong Wang, Lin Lu, Jiawen Shi, Guiyao Tie, Yongtian Xu, Lixing Chen, Pan Zhou, Neil Zhenqiang Gong, Lichao Sun

+ [Integrating Counterfactual Simulations with Language Models for Explaining Multi-Agent Behaviour](https://arxiv.org//abs/2505.17801)

	Bálint Gyevnár, Christopher G. Lucas, Stefano V. Albrecht, Shay B. Cohen

+ [Evaluation Faking: Unveiling Observer Effects in Safety Evaluation of Frontier AI Systems](https://arxiv.org//abs/2505.17815)

	Yihe Fan, Wenqi Zhang, Xudong Pan, Min Yang

+ [Structured Thinking Matters: Improving LLMs Generalization in Causal Inference Tasks](https://arxiv.org//abs/2505.18034)

	Wentao Sun, Joao Paulo Nogueira, Alonso Silva

+ [ProgRM: Build Better GUI Agents with Progress Rewards](https://arxiv.org//abs/2505.18121)

	Danyang Zhang, Situo Zhang, Ziyue Yang, Zichen Zhu, Zihan Zhao, Ruisheng Cao, Lu Chen, Kai Yu

+ [Gaming Tool Preferences in Agentic LLMs](https://arxiv.org//abs/2505.18135)

	Kazem Faghih, Wenxiao Wang, Yize Cheng, Siddhant Bharti, Gaurang Sriramanan, Sriram Balasubramanian, Parsa Hosseini, Soheil Feizi

+ [Value-Guided Search for Efficient Chain-of-Thought Reasoning](https://arxiv.org//abs/2505.17373)

	Kaiwen Wang, Jin Peng Zhou, Jonathan Chang, Zhaolin Gao, Nathan Kallus, Kianté Brantley, Wen Sun

+ [Discovering Forbidden Topics in Language Models](https://arxiv.org//abs/2505.17441)

	Can Rager, Chris Wendler, Rohit Gandikota, David Bau

+ [SLearnLLM: A Self-Learning Framework for Efficient Domain-Specific Adaptation of Large Language Models](https://arxiv.org//abs/2505.17470)

	Xiang Liu, Zhaoxiang Liu, Peng Wang, Kohou Wang, Huan Hu, Kai Wang, Shiguo Lian

+ [keepitsimple at SemEval-2025 Task 3: LLM-Uncertainty based Approach for Multilingual Hallucination Span Detection](https://arxiv.org//abs/2505.17485)

	Saketh Reddy Vemula, Parameswari Krishnamurthy

+ [ProxySPEX: Inference-Efficient Interpretability via Sparse Feature Interactions in LLMs](https://arxiv.org//abs/2505.17495)

	Landon Butler, Abhineet Agarwal, Justin Singh Kang, Yigit Efe Erginbas, Bin Yu, Kannan Ramchandran

+ [Analyzing Mitigation Strategies for Catastrophic Forgetting in End-to-End Training of Spoken Language Models](https://arxiv.org//abs/2505.17496)

	Chi-Yuan Hsiao, Ke-Han Lu, Kai-Wei Chang, Chih-Kai Yang, Wei-Chih Chen, Hung-yi Lee

+ [On the Design of KL-Regularized Policy Gradient Algorithms for LLM Reasoning](https://arxiv.org//abs/2505.17508)

	Yifan Zhang, Yifeng Liu, Huizhuo Yuan, Yang Yuan, Quanquan Gu, Andrew C Yao

+ [Multi-agent Systems for Misinformation Lifecycle : Detection, Correction And Source Identification](https://arxiv.org//abs/2505.17511)

	Aditya Gautam

+ [Do You Keep an Eye on What I Ask? Mitigating Multimodal Hallucination via Attention-Guided Ensemble Decoding](https://arxiv.org//abs/2505.17529)

	Yeongjae Cho, Keonwoo Kim, Taebaek Hwang, Sungzoon Cho

+ [Teaching with Lies: Curriculum DPO on Synthetic Negatives for Hallucination Detection](https://arxiv.org//abs/2505.17558)

	Shrey Pandit, Ashwin Vinod, Liu Leqi, Ying Ding

+ [JALMBench: Benchmarking Jailbreak Vulnerabilities in Audio Language Models](https://arxiv.org//abs/2505.17568)

	Zifan Peng, Yule Liu, Zhen Sun, Mingchen Li, Zeren Luo, Jingyi Zheng, Wenhan Dong, Xinlei He, Xuechao Wang, Yingjie Xue, Shengmin Xu, Xinyi Huang

+ [Distilling LLM Agent into Small Models with Retrieval and Code Tools](https://arxiv.org//abs/2505.17612)

	Minki Kang, Jongwon Jeong, Seanie Lee, Jaewoong Cho, Sung Ju Hwang

+ [Runaway is Ashamed, But Helpful: On the Early-Exit Behavior of Large Language Model-based Agents in Embodied Environments](https://arxiv.org//abs/2505.17616)

	Qingyu Lu, Liang Ding, Siyi Cao, Xuebo Liu, Kanjian Zhang, Jinxia Zhang, Dacheng Tao

+ [Surfacing Semantic Orthogonality Across Model Safety Benchmarks: A Multi-Dimensional Analysis](https://arxiv.org//abs/2505.17636)

	Jonathan Bennion, Shaona Ghosh, Mantek Singh, Nouha Dziri

+ [Rethinking the Sampling Criteria in Reinforcement Learning for LLM Reasoning: A Competence-Difficulty Alignment Perspective](https://arxiv.org//abs/2505.17652)

	Deyang Kong, Qi Guo, Xiangyu Xi, Wei Wang, Jingang Wang, Xunliang Cai, Shikun Zhang, Wei Ye

+ [EVADE: Multimodal Benchmark for Evasive Content Detection in E-Commerce Applications](https://arxiv.org//abs/2505.17654)

	Ancheng Xu, Zhihao Yang, Jingpeng Li, Guanghu Yuan, Longze Chen, Liang Yan, Jiehui Zhou, Zhen Qin, Hengyun Chang, Hamid Alinejad-Rokny, Bo Zheng, Min Yang

+ [Towards General Continuous Memory for Vision-Language Models](https://arxiv.org//abs/2505.17670)

	Wenyi Wu, Zixuan Song, Kun Zhou, Yifei Shao, Zhiting Hu, Biwei Huang

+ [Tuning Language Models for Robust Prediction of Diverse User Behaviors](https://arxiv.org//abs/2505.17682)

	Fanjin Meng, Jingtao Ding, Jiahui Gong, Chen Yang, Hong Chen, Zuojian Wang, Haisheng Lu, Yong Li

+ [COUNTDOWN: Contextually Sparse Activation Filtering Out Unnecessary Weights in Down Projection](https://arxiv.org//abs/2505.17701)

	Jaewon Cheon, Pilsung Kang

+ [Slot-MLLM: Object-Centric Visual Tokenization for Multimodal LLM](https://arxiv.org//abs/2505.17726)

	Donghwan Chi, Hyomin Kim, Yoonjin Oh, Yongjin Kim, Donghoon Lee, Daejin Jo, Jongmin Kim, Junyeob Baek, Sungjin Ahn, Sungwoong Kim

+ [But what is your honest answer? Aiding LLM-judges with honest alternatives using steering vectors](https://arxiv.org//abs/2505.17760)

	Leon Eshuijs, Archie Chaudhury, Alan McBeth, Ethan Nguyen

+ [DialogXpert: Driving Intelligent and Emotion-Aware Conversations through Online Value-Based Reinforcement Learning with LLM Priors](https://arxiv.org//abs/2505.17795)

	Tazeek Bin Abdur Rakib, Ambuj Mehrish, Lay-Ki Soon, Wern Han Lim, Soujanya Poria

+ [Don't Overthink it. Preferring Shorter Thinking Chains for Improved LLM Reasoning](https://arxiv.org//abs/2505.17813)

	Michael Hassid, Gabriel Synnaeve, Yossi Adi, Roy Schwartz

+ [Scalable Valuation of Human Feedback through Provably Robust Model Alignment](https://arxiv.org//abs/2505.17859)

	Masahiro Fujisawa, Masaki Adachi, Michael A. Osborne

+ [Beyond Distillation: Pushing the Limits of Medical LLM Reasoning with Minimalist Rule-Based RL](https://arxiv.org//abs/2505.17952)

	Che Liu, Haozhe Wang, Jiazhen Pan, Zhongwei Wan, Yong Dai, Fangzhen Lin, Wenjia Bai, Daniel Rueckert, Rossella Arcucci

+ [SVD-Free Low-Rank Adaptive Gradient Optimization for Large Language Models](https://arxiv.org//abs/2505.17967)

	Ionut-Vlad Modoranu, Mher Safaryan, Erik Schultheis, Dan Alistarh

+ [Are Large Language Models Reliable AI Scientists? Assessing Reverse-Engineering of Black-Box Systems](https://arxiv.org//abs/2505.17968)

	Jiayi Geng, Howard Chen, Dilip Arumugam, Thomas L. Griffiths

+ [Generalized Fisher-Weighted SVD: Scalable Kronecker-Factored Fisher Approximation for Compressing Large Language Models](https://arxiv.org//abs/2505.17974)

	Viktoriia Chekalina, Daniil Moskovskiy, Daria Cherniuk, Maxim Kurkin, Andrey Kuznetsov, Evgeny Frolov

+ [Towards Revealing the Effectiveness of Small-Scale Fine-tuning in R1-style Reinforcement Learning](https://arxiv.org//abs/2505.17988)

	Yutong Chen, Jiandong Gao, Ji Wu

+ [An Example Safety Case for Safeguards Against Misuse](https://arxiv.org//abs/2505.18003)

	Joshua Clymer, Jonah Weinbaum, Robert Kirk, Kimberly Mai, Selena Zhang, Xander Davies

+ [Deep Video Discovery: Agentic Search with Tool Use for Long-form Video Understanding](https://arxiv.org//abs/2505.18079)

	Xiaoyi Zhang, Zhaoyang Jia, Zongyu Guo, Jiahao Li, Bin Li, Houqiang Li, Yan Lu

+ [Data Mixing Can Induce Phase Transitions in Knowledge Acquisition](https://arxiv.org//abs/2505.18091)

	Xinran Gu, Kaifeng Lyu, Jiazheng Li, Jingzhao Zhang

+ [Planning without Search: Refining Frontier LLMs with Offline Goal-Conditioned RL](https://arxiv.org//abs/2505.18098)

	Joey Hong, Anca Dragan, Sergey Levine

+ [How Can I Publish My LLM Benchmark Without Giving the True Answers Away?](https://arxiv.org//abs/2505.18102)

	Takashi Ishida, Thanawat Lodkaew, Ikko Yamane

+ [Reward Model Overoptimisation in Iterated RLHF](https://arxiv.org//abs/2505.18126)

	Lorenz Wolf, Robert Kirk, Mirco Musolesi

+ [Lost in the Haystack: Smaller Needles are More Difficult for LLMs to Find](https://arxiv.org//abs/2505.18148)

	Owen Bianchi, Mathew J. Koretsky, Maya Willey, Chelsea X. Alvarado, Tanay Nayak, Adi Asija, Nicole Kuznetsov, Mike A. Nalls, Faraz Faghri, Daniel Khashabi

+ [AI-Augmented LLMs Achieve Therapist-Level Responses in Motivational Interviewing](https://arxiv.org//abs/2505.17380)

	Yinghui Huang, Yuxuan Jiang, Hui Liu, Yixin Cai, Weiqing Li, Xiangen Hu

+ [WiNGPT-3.0 Technical Report](https://arxiv.org//abs/2505.17387)

	Boqin Zhuang, Chenxiao Song, Huitong Lu, Jiacheng Qiao, Mingqian Liu, Mingxing Yu, Ping Hong, Rui Li, Xiaoxia Song, Xiangjun Xu, Xu Chen, Yaoyao Ma, Yujie Gao

+ [Measuring diversity of synthetic prompts and data generated with fine-grained persona prompting](https://arxiv.org//abs/2505.17390)

	Gauri Kambhatla, Chantal Shaib, Venkata Govindarajan

+ [Curriculum Guided Reinforcement Learning for Efficient Multi Hop Retrieval Augmented Generation](https://arxiv.org//abs/2505.17391)

	Yuelyu Ji, Rui Meng, Zhuochun Li, Daqing He

+ [Language Matters: How Do Multilingual Input and Reasoning Paths Affect Large Reasoning Models?](https://arxiv.org//abs/2505.17407)

	Zhi Rui Tam, Cheng-Kuang Wu, Yu Ying Chiu, Chieh-Yen Lin, Yun-Nung Chen, Hung-yi Lee

+ [Conversations: Love Them, Hate Them, Steer Them](https://arxiv.org//abs/2505.17413)

	Niranjan Chebrolu, Gerard Christopher Yeo, Kokil Jaidka

+ [DASH: Input-Aware Dynamic Layer Skipping for Efficient LLM Inference with Markov Decision Policies](https://arxiv.org//abs/2505.17420)

	Ning Yang, Fangxin Liu, Junjie Wang, Tao Yang, Kan Liu, Haibing Guan, Li Jiang

+ [T$^2$: An Adaptive Test-Time Scaling Strategy for Contextual Question Answering](https://arxiv.org//abs/2505.17427)

	Zhengyi Zhao, Shubo Zhang, Zezhong Wang, Huimin Wang, Yutian Zhao, Bin Liang, Yefeng Zheng, Binyang Li, Kam-Fai Wong, Xian Wu

+ [LeTS: Learning to Think-and-Search via Process-and-Outcome Reward Hybridization](https://arxiv.org//abs/2505.17447)

	Qi Zhang, Shouqing Yang, Lirong Gao, Hao Chen, Xiaomeng Hu, Jinglei Chen, Jiexiang Wang, Sheng Guo, Bo Zheng, Haobo Wang, Junbo Zhao

+ [Hydra: Structured Cross-Source Enhanced Large Language Model Reasoning](https://arxiv.org//abs/2505.17464)

	Xingyu Tan, Xiaoyang Wang, Qing Liu, Xiwei Xu, Xin Yuan, Liming Zhu, Wenjie Zhang

+ [FinRAGBench-V: A Benchmark for Multimodal RAG with Visual Citation in the Financial Domain](https://arxiv.org//abs/2505.17471)

	Suifeng Zhao, Zhuoran Jin, Sujian Li, Jun Gao

+ [MARCO: Meta-Reflection with Cross-Referencing for Code Reasoning](https://arxiv.org//abs/2505.17481)

	Yusheng Zhao, Xiao Luo, Weizhi Zhang, Wei Ju, Zhiping Xiao, Philip S. Yu, Ming Zhang

+ [CReSt: A Comprehensive Benchmark for Retrieval-Augmented Generation with Complex Reasoning over Structured Documents](https://arxiv.org//abs/2505.17503)

	Minsoo Khang, Sangjun Park, Teakgyu Hong, Dawoon Jung

+ [L-MTP: Leap Multi-Token Prediction Beyond Adjacent Context for Large Language Models](https://arxiv.org//abs/2505.17505)

	Xiaohao Liu, Xiaobo Xia, Weixiang Zhao, Manyi Zhang, Xianzhi Yu, Xiu Su, Shuo Yang, See-Kiong Ng, Tat-Seng Chua

+ [Large Language Models Do Multi-Label Classification Differently](https://arxiv.org//abs/2505.17510)

	Marcus Ma, Georgios Chochlakis, Niyantha Maruthu Pandiyan, Jesse Thomason, Shrikanth Narayanan

+ [How Knowledge Popularity Influences and Enhances LLM Knowledge Boundary Perception](https://arxiv.org//abs/2505.17537)

	Shiyu Ni, Keping Bi, Jiafeng Guo, Xueqi Cheng

+ [Reasoning Meets Personalization: Unleashing the Potential of Large Reasoning Model for Personalized Generation](https://arxiv.org//abs/2505.17571)

	Sichun Luo, Guanzhi Deng, Jian Xu, Xiaojie Zhang, Hanxu Hou, Linqi Song

+ [Wolf Hidden in Sheep's Conversations: Toward Harmless Data-Based Backdoor Attacks for Jailbreaking Large Language Models](https://arxiv.org//abs/2505.17601)

	Jiawei Kong, Hao Fang, Xiaochen Yang, Kuofeng Gao, Bin Chen, Shu-Tao Xia, Yaowei Wang, Min Zhang

+ [Enhancing Large Vision-Language Models with Layout Modality for Table Question Answering on Japanese Annual Securities Reports](https://arxiv.org//abs/2505.17625)

	Hayato Aida, Kosuke Takahashi, Takahiro Omi

+ [GIM: Improved Interpretability for Large Language Models](https://arxiv.org//abs/2505.17630)

	Joakim Edin, Róbert Csordás, Tuukka Ruotsalo, Zhengxuan Wu, Maria Maistro, Jing Huang, Lars Maaløe

+ [Too Consistent to Detect: A Study of Self-Consistent Errors in LLMs](https://arxiv.org//abs/2505.17656)

	Hexiang Tan, Fei Sun, Sha Liu, Du Su, Qi Cao, Xin Chen, Jingang Wang, Xunliang Cai, Yuanzhuo Wang, Huawei Shen, Xueqi Cheng

+ [Towards Dynamic Theory of Mind: Evaluating LLM Adaptation to Temporal Evolution of Human States](https://arxiv.org//abs/2505.17663)

	Yang Xiao, Jiashuo Wang, Qiancheng Xu, Changhe Song, Chunpu Xu, Yi Cheng, Wenjie Li, Pengfei Liu

+ [QwenLong-L1: Towards Long-Context Large Reasoning Models with Reinforcement Learning](https://arxiv.org//abs/2505.17667)

	Fanqi Wan, Weizhou Shen, Shengyi Liao, Yingcheng Shi, Chenliang Li, Ziyi Yang, Ji Zhang, Fei Huang, Jingren Zhou, Ming Yan

+ [MIDB: Multilingual Instruction Data Booster for Enhancing Multilingual Instruction Synthesis](https://arxiv.org//abs/2505.17671)

	Yilun Liu, Chunguang Zhao, Xinhua Yang, Hongyong Zeng, Shimin Tao, Weibin Meng, Minggui He, Chang Su, Yan Yu, Hongxia Ma, Li Zhang, Daimeng Wei, Hao Yang

+ [ELSPR: Evaluator LLM Training Data Self-Purification on Non-Transitive Preferences via Tournament Graph Reconstruction](https://arxiv.org//abs/2505.17691)

	Yan Yu, Yilun Liu, Minggui He, Shimin Tao, Weibin Meng, Xinhua Yang, Li Zhang, Hongxia Ma, Chang Su, Hao Yang, Fuliang Li

+ [Activation Control for Efficiently Eliciting Long Chain-of-thought Ability of Language Models](https://arxiv.org//abs/2505.17697)

	Zekai Zhao, Qi Liu, Kun Zhou, Zihan Liu, Yifei Shao, Zhiting Hu, Biwei Huang

+ [Understanding How Value Neurons Shape the Generation of Specified Values in LLMs](https://arxiv.org//abs/2505.17712)

	Yi Su, Jiayi Zhang, Shu Yang, Xinhai Wang, Lijie Hu, Di Wang

+ [Fast Quiet-STaR: Thinking Without Thought Tokens](https://arxiv.org//abs/2505.17746)

	Wei Huang, Yizhe Xiong, Xin Ye, Zhijie Deng, Hui Chen, Zijia Lin, Guiguang Ding

+ [Discriminating Form and Meaning in Multilingual Models with Minimal-Pair ABX Tasks](https://arxiv.org//abs/2505.17747)

	Maureen de Seyssel, Jie Chi, Skyler Seto, Maartje ter Hoeve, Masha Fedzechkina, Natalie Schluter

+ [Resolving Conflicting Evidence in Automated Fact-Checking: A Study on Retrieval-Augmented LLMs](https://arxiv.org//abs/2505.17762)

	Ziyu Ge, Yuhao Wu, Daniel Wai Kit Chin, Roy Ka-Wei Lee, Rui Cao

+ [The Real Barrier to LLM Agent Usability is Agentic ROI](https://arxiv.org//abs/2505.17767)

	Weiwen Liu, Jiarui Qin, Xu Huang, Xingshan Zeng, Yunjia Xi, Jianghao Lin, Chuhan Wu, Yasheng Wang, Lifeng Shang, Ruiming Tang, Defu Lian, Yong Yu, Weinan Zhang

+ [EXECUTE: A Multilingual Benchmark for LLM Token Understanding](https://arxiv.org//abs/2505.17784)

	Lukas Edman, Helmut Schmid, Alexander Fraser

+ [Compression Hacking: A Supplementary Perspective on Informatics Metric of Language Models from Geometric Distortion](https://arxiv.org//abs/2505.17793)

	Jianxiang Zang, Meiling Ning, Yongda Wei, Shihan Dou, Jiazheng Zhang, Nijia Mo, Binhong Li, Tao Gui, Qi Zhang, Xuanjing Huang

+ [Not All Tokens Are What You Need In Thinking](https://arxiv.org//abs/2505.17827)

	Hang Yuan, Bin Yu, Haotian Li, Shijun Yang, Christina Dan Wang, Zhou Yu, Xueyin Xu, Weizhen Qi, Kai Chen

+ [Stepwise Reasoning Checkpoint Analysis: A Test Time Scaling Method to Enhance LLMs' Reasoning](https://arxiv.org//abs/2505.17829)

	Zezhong Wang, Xingshan Zeng, Weiwen Liu, Yufei Wang, Liangyou Li, Yasheng Wang, Lifeng Shang, Xin Jiang, Qun Liu, Kam-Fai Wong

+ [Explaining Sources of Uncertainty in Automated Fact-Checking](https://arxiv.org//abs/2505.17855)

	Jingyi Sun, Greta Warren, Irina Shklovski, Isabelle Augenstein

+ [Just as Humans Need Vaccines, So Do Models: Model Immunization to Combat Falsehoods](https://arxiv.org//abs/2505.17870)

	Shaina Raza, Rizwan Qureshi, Marcelo Lotif, Aman Chadha, Deval Pandya, Christos Emmanouilidis

+ [Language models can learn implicit multi-hop reasoning, but only if they have lots of training data](https://arxiv.org//abs/2505.17923)

	Yuekun Yao, Yupei Du, Dawei Zhu, Michael Hahn, Alexander Koller

+ [TRACE for Tracking the Emergence of Semantic Representations in Transformers](https://arxiv.org//abs/2505.17998)

	Nura Aljaafari, Danilo S. Carvalho, André Freitas

+ [Contrastive Distillation of Emotion Knowledge from LLMs for Zero-Shot Emotion Recognition](https://arxiv.org//abs/2505.18040)

	Minxue Niu, Emily Mower Provost

+ [MathEDU: Towards Adaptive Feedback for Student Mathematical Problem-Solving](https://arxiv.org//abs/2505.18056)

	Wei-Ling Hsu, Yu-Chien Tang, An-Zi Yen

+ [QwenLong-CPRS: Towards $\infty$-LLMs with Dynamic Context Optimization](https://arxiv.org//abs/2505.18092)

	Weizhou Shen, Chenliang Li, Fanqi Wan, Shengyi Liao, Shaopeng Lai, Bo Zhang, Yingcheng Shi, Yuning Wu, Gang Fu, Zhansheng Li, Bin Yang, Ji Zhang, Fei Huang, Jingren Zhou, Ming Yan

+ [ManuSearch: Democratizing Deep Search in Large Language Models with a Transparent and Open Multi-Agent Framework](https://arxiv.org//abs/2505.18105)

	Lisheng Huang, Yichen Liu, Jinhao Jiang, Rongxiang Zhang, Jiahao Yan, Junyi Li, Wayne Xin Zhao

+ [First Finish Search: Efficient Test-Time Scaling in Large Language Models](https://arxiv.org//abs/2505.18149)

	Aradhye Agarwal, Ayan Sengupta, Tanmoy Chakraborty

+ [The Staircase of Ethics: Probing LLM Value Priorities through Multi-Step Induction to Complex Moral Dilemmas](https://arxiv.org//abs/2505.18154)

	Ya Wu, Qiang Sheng, Danding Wang, Guang Yang, Yifan Sun, Zhengjia Wang, Yuyan Bu, Juan Cao

+ [LLM-based Generative Error Correction for Rare Words with Synthetic Data and Phonetic Context](https://arxiv.org//abs/2505.17410)

	Natsuo Yamashita, Masaaki Yamamoto, Hiroaki Kokubo, Yohei Kawaguchi

+ [Self-Training Large Language Models with Confident Reasoning](https://arxiv.org//abs/2505.17454)

	Hyosoon Jang, Yunhui Jang, Sungjae Lee, Jungseul Ok, Sungsoo Ahn

+ [Chain-of-Lure: A Synthetic Narrative-Driven Approach to Compromise Large Language Models](https://arxiv.org//abs/2505.17519)

	Wenhan Chang, Tianqing Zhu, Yu Zhao, Shuangyong Song, Ping Xiong, Wanlei Zhou, Yongxiang Li

+ [Co-Reinforcement Learning for Unified Multimodal Understanding and Generation](https://arxiv.org//abs/2505.17534)

	Jingjing Jiang, Chongjie Si, Jun Luo, Hanwang Zhang, Chao Ma

+ [CoMoE: Contrastive Representation for Mixture-of-Experts in Parameter-Efficient Fine-tuning](https://arxiv.org//abs/2505.17553)

	Jinyuan Feng, Chaopeng Wei, Tenghai Qiu, Tianyi Hu, Zhiqiang Pu

+ [One Model Transfer to All: On Robust Jailbreak Prompts Generation against LLMs](https://arxiv.org//abs/2505.17598)

	Linbao Li, Yannan Liu, Daojing He, Yu Li

+ [Trinity-RFT: A General-Purpose and Unified Framework for Reinforcement Fine-Tuning of Large Language Models](https://arxiv.org//abs/2505.17826)

	Xuchen Pan, Yanxi Chen, Yushuo Chen, Yuchang Sun, Daoyuan Chen, Wenhao Zhang, Yuexiang Xie, Yilun Huang, Yilei Zhang, Dawei Gao, Yaliang Li, Bolin Ding, Jingren Zhou

+ [Understanding Gated Neurons in Transformers from Their Input-Output Functionality](https://arxiv.org//abs/2505.17936)

	Sebastian Gerstner, Hinrich Schütze

+ [Towards Analyzing and Understanding the Limitations of VAPO: A Theoretical Perspective](https://arxiv.org//abs/2505.17997)

	Jintian Shao, Yiming Cheng, Hongyi Huang, Beiwen Zhang, Zhiyu Wu, You Shan, Mingkai Zheng

+ [Bridging Supervised Learning and Reinforcement Learning in Math Reasoning](https://arxiv.org//abs/2505.18116)

	Huayu Chen, Kaiwen Zheng, Qinsheng Zhang, Ganqu Cui, Yin Cui, Haotian Ye, Tsung-Yi Lin, Ming-Yu Liu, Jun Zhu, Haoxiang Wang

+ [VEAttack: Downstream-agnostic Vision Encoder Attack against Large Vision Language Models](https://arxiv.org//abs/2505.17440)

	Hefei Mei, Zirui Wang, Shen You, Minjing Dong, Chang Xu

+ [The Coherence Trap: When MLLM-Crafted Narratives Exploit Manipulated Visual Contexts](https://arxiv.org//abs/2505.17476)

	Yuchen Zhang, Yaxiong Wang, Yujiao Wu, Lianwei Wu, Li Zhu

+ [Enhancing Adversarial Robustness of Vision Language Models via Adversarial Mixture Prompt Tuning](https://arxiv.org//abs/2505.17509)

	Shiji Zhao, Qihui Zhu, Shukun Xiong, Shouwei Ruan, Yize Fan, Ranjie Duan, Qing Guo, Xingxing Wei

+ [Navigate the Unknown: Enhancing LLM Reasoning with Intrinsic Motivation Guided Exploration](https://arxiv.org//abs/2505.17621)

	Jingtong Gao, Ling Pan, Yejing Wang, Rui Zhong, Chi Lu, Qingpeng Cai, Peng Jiang, Xiangyu Zhao

+ [PreMoe: Lightening MoEs on Constrained Memory by Expert Pruning and Retrieval](https://arxiv.org//abs/2505.17639)

	Zehua Pei, Ying Zhang, Hui-Ling Zhen, Xianzhi Yu, Wulong Liu, Sinno Jialin Pan, Mingxuan Yuan, Bei Yu

+ [Understanding Pre-training and Fine-tuning from Loss Landscape Perspectives](https://arxiv.org//abs/2505.17646)

	Huanran Chen, Yinpeng Dong, Zeming Wei, Yao Huang, Yichi Zhang, Hang Su, Jun Zhu

+ [FlashForge: Ultra-Efficient Prefix-Aware Attention for LLM Decoding](https://arxiv.org//abs/2505.17694)

	Zhibin Wang, Rui Ning, Chao Fang, Zhonghui Zhang, Xi Lin, Shaobo Ma, Mo Zhou, Xue Li, Zhongfeng Wang, Chengying Huan, Rong Gu, Kun Yang, Guihai Chen, Sheng Zhong, Chen Tian

+ [Get Experience from Practice: LLM Agents with Record & Replay](https://arxiv.org//abs/2505.17716)

	Erhu Feng, Wenbo Zhou, Zibin Liu, Le Chen, Yunpeng Dong, Cheng Zhang, Yisheng Zhao, Dong Du, Zhichao Hua, Yubin Xia, Haibo Chen

+ [Inference-Time Decomposition of Activations (ITDA): A Scalable Approach to Interpreting Large Language Models](https://arxiv.org//abs/2505.17769)

	Patrick Leask, Neel Nanda, Noura Al Moubayed

+ [C-LoRA: Contextual Low-Rank Adaptation for Uncertainty Estimation in Large Language Models](https://arxiv.org//abs/2505.17773)

	Amir Hossein Rahmati, Sanket Jantre, Weifeng Zhang, Yucheng Wang, Byung-Jun Yoon, Nathan M. Urban, Xiaoning Qian

+ [RECIPE-TKG: From Sparse History to Structured Reasoning for LLM-based Temporal Knowledge Graph Completion](https://arxiv.org//abs/2505.17794)

	Ömer Faruk Akgül, Feiyu Zhu, Yuxin Yang, Rajgopal Kannan, Viktor Prasanna

+ [VIBE: Vector Index Benchmark for Embeddings](https://arxiv.org//abs/2505.17810)

	Elias Jääsaari, Ville Hyvönen, Matteo Ceccarello, Teemu Roos, Martin Aumüller

+ [The emergence of sparse attention: impact of data distribution and benefits of repetition](https://arxiv.org//abs/2505.17863)

	Nicolas Zucchet, Francesco d'Angelo, Andrew K. Lampinen, Stephanie C.Y. Chan

+ [VeriThinker: Learning to Verify Makes Reasoning Model Efficient](https://arxiv.org//abs/2505.17941)

	Zigeng Chen, Xinyin Ma, Gongfan Fang, Ruonan Yu, Xinchao Wang

+ [Reward Model Generalization for Compute-Aware Test-Time Reasoning](https://arxiv.org//abs/2505.18065)

	Zeen Song, Wenwen Qiang, Siyu Zhao, Changwen Zheng, Gang Hua

+ [LLM-BSCVM: An LLM-Based Blockchain Smart Contract Vulnerability Management Framework](https://arxiv.org//abs/2505.17416)

	Yanli Jin, Chunpei Li, Peng Fan, Peng Liu, Xianxian Li, Chen Liu, Wangjie Qiu

+ [Large Language Models in the IoT Ecosystem -- A Survey on Security Challenges and Applications](https://arxiv.org//abs/2505.17586)

	Kushal Khatiwada, Jayden Hopper, Joseph Cheatham, Ayan Joshi, Sabur Baidya

# 2025-05-22
+ [Optimizing LLM-Based Multi-Agent System with Textual Feedback: A Case Study on Software Development](https://arxiv.org//abs/2505.16086)

	Ming Shen, Raphael Shu, Anurag Pratik, James Gung, Yubin Ge, Monica Sunkara, Yi Zhang

+ [Can AI Read Between The Lines? Benchmarking LLMs On Financial Nuance](https://arxiv.org//abs/2505.16090)

	Dominick Kubica, Dylan T. Gordon, Nanami Emura, Derleen Saini, Charlie Goldenberg

+ [Logic-of-Thought: Empowering Large Language Models with Logic Programs for Solving Puzzles in Natural Language](https://arxiv.org//abs/2505.16114)

	Naiqi Li, Peiyuan Liu, Zheng Liu, Tao Dai, Yong Jiang, Shu-Tao Xia

+ [LLM-Powered AI Agent Systems and Their Applications in Industry](https://arxiv.org//abs/2505.16120)

	Guannan Liang, Qianqian Tong

+ [Losing is for Cherishing: Data Valuation Based on Machine Unlearning and Shapley Value](https://arxiv.org//abs/2505.16147)

	Le Ma, Shirao Yang, Zihao Wang, Yinggui Wang, Lei Wang, Tao Wei, Kejun Zhang

+ [SafeKey: Amplifying Aha-Moment Insights for Safety Reasoning](https://arxiv.org//abs/2505.16186)

	Kaiwen Zhou, Xuandong Zhao, Gaowen Liu, Jayanth Srinivasa, Aosong Feng, Dawn Song, Xin Eric Wang

+ [LightRouter: Towards Efficient LLM Collaboration with Minimal Overhead](https://arxiv.org//abs/2505.16221)

	Yifan Zhang, Xinkui Zhao, Zuxin Wang, Guanjie Cheng, Yueshen Xu, Shuiguang Deng, Jianwei Yin

+ [MAPLE: Many-Shot Adaptive Pseudo-Labeling for In-Context Learning](https://arxiv.org//abs/2505.16225)

	Zihan Chen, Song Wang, Zhen Tan, Jundong Li, Cong Shen

+ [How do Scaling Laws Apply to Knowledge Graph Engineering Tasks? The Impact of Model Size on Large Language Model Performance](https://arxiv.org//abs/2505.16276)

	Desiree Heim, Lars-Peter Meyer, Markus Schröder, Johannes Frey, Andreas Dengel

+ [No Black Boxes: Interpretable and Interactable Predictive Healthcare with Knowledge-Enhanced Agentic Causal Discovery](https://arxiv.org//abs/2505.16288)

	Xiaoxue Han, Pengfei Hu, Jun-En Ding, Chang Lu, Feng Liu, Yue Ning

+ [EquivPruner: Boosting Efficiency and Quality in LLM-Based Search via Action Pruning](https://arxiv.org//abs/2505.16312)

	Jiawei Liu, Qisi Chen, Jianshu Zhang, Quan Liu, Defu Lian

+ [Incentivizing Dual Process Thinking for Efficient Large Language Model Reasoning](https://arxiv.org//abs/2505.16315)

	Xiaoxue Cheng, Junyi Li, Zhenduo Zhang, Xinyu Tang, Wayne Xin Zhao, Xinyu Kong, Zhiqiang Zhang

+ [FREESON: Retriever-Free Retrieval-Augmented Reasoning via Corpus-Traversing MCTS](https://arxiv.org//abs/2505.16409)

	Chaeeun Kim, Seungone Kim

+ [Internal Bias in Reasoning Models leads to Overthinking](https://arxiv.org//abs/2505.16448)

	Renfei Dang, Shujian Huang, Jiajun Chen

+ [Psychology-driven LLM Agents for Explainable Panic Prediction on Social Media during Sudden Disaster Events](https://arxiv.org//abs/2505.16455)

	Mengzhu Liu, Zhengqiu Zhu, Chuan Ai, Chen Gao, Xinghong Li, Lingnan He, Kaisheng Lai, Yingfeng Chen, Xin Lu, Yong Li, Quanjun Yin

+ [ReflectEvo: Improving Meta Introspection of Small LLMs by Learning Self-Reflection](https://arxiv.org//abs/2505.16475)

	Jiaqi Li, Xinyi Dong, Yang Liu, Zhizhuo Yang, Quansen Wang, Xiaobo Wang, SongChun Zhu, Zixia Jia, Zilong Zheng

+ [Bridging the Dynamic Perception Gap: Training-Free Draft Chain-of-Thought for Dynamic Multimodal Spatial Reasoning](https://arxiv.org//abs/2505.16579)

	Siqu Ou, Hongcheng Liu, Pingjie Wang, Yusheng Liao, Chuan Xuan, Yanfeng Wang, Yu Wang

+ [SMART: Self-Generating and Self-Validating Multi-Dimensional Assessment for LLMs' Mathematical Problem Solving](https://arxiv.org//abs/2505.16646)

	Yujie Hou, Ting Zhang, Mei Wang, Xuetao Ma, Hu Huang

+ [ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming](https://arxiv.org//abs/2505.16667)

	Xinwei Yang, Zhaofeng Liu, Chen Huang, Jiashuai Zhang, Tong Zhang, Yifan Zhang, Wenqiang Lei

+ [MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models](https://arxiv.org//abs/2505.16700)

	Xuanqi Gao, Siyi Xie, Juan Zhai, Shqing Ma, Chao Shen

+ [KTAE: A Model-Free Algorithm to Key-Tokens Advantage Estimation in Mathematical Reasoning](https://arxiv.org//abs/2505.16826)

	Wei Sun, Wen Yang, Pu Jian, Qianlong Du, Fuwei Cui, Shuo Ren, Jiajun Zhang

+ [GUI-explorer: Autonomous Exploration and Mining of Transition-aware Knowledge for GUI Agent](https://arxiv.org//abs/2505.16827)

	Bin Xie, Rui Shao, Gongwei Chen, Kaiwen Zhou, Yinchuan Li, Jie Liu, Min Zhang, Liqiang Nie

+ [Identifying, Evaluating, and Mitigating Risks of AI Thought Partnerships](https://arxiv.org//abs/2505.16899)

	Kerem Oktar, Katherine M. Collins, Jose Hernandez-Orallo, Diane Coyle, Stephen Cave, Adrian Weller, Ilia Sucholutsky

+ [NovelSeek: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification](https://arxiv.org//abs/2505.16938)

	NovelSeek Team: Bo Zhang, Shiyang Feng, Xiangchao Yan, Jiakang Yuan, Zhiyin Yu, Xiaohan He, Songtao Huang, Shaowei Hou, Zheng Nie, Zhilong Wang, Jinyao Liu, Runmin Ma, Tianshuo Peng, Peng Ye, Dongzhan Zhou, Shufei Zhang, Xiaosong Wang, Yilan Zhang, Meng Li, Zhongying Tu, Xiangyu Yue, Wangli Ouyang, Bowen Zhou, Lei Bai

+ [AGENTIF: Benchmarking Instruction Following of Large Language Models in Agentic Scenarios](https://arxiv.org//abs/2505.16944)

	Yunjia Qi, Hao Peng, Xiaozhi Wang, Amy Xin, Youfeng Liu, Bin Xu, Lei Hou, Juanzi Li

+ [HyGenar: An LLM-Driven Hybrid Genetic Algorithm for Few-Shot Grammar Generation](https://arxiv.org//abs/2505.16978)

	Weizhi Tang, Yixuan Li, Chris Sypherd, Elizabeth Polgreen, Vaishak Belle

+ [Know the Ropes: A Heuristic Strategy for LLM-based Multi-Agent System Design](https://arxiv.org//abs/2505.16979)

	Zhenkun Li, Lingyao Li, Shuhang Lin, Yongfeng Zhang

+ [Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine](https://arxiv.org//abs/2505.16982)

	Adib Bazgir, Amir Habibdoust Lafmajani, Yuwen Zhang

+ [X-MAS: Towards Building Multi-Agent Systems with Heterogeneous LLMs](https://arxiv.org//abs/2505.16997)

	Rui Ye, Xiangrui Liu, Qimin Wu, Xianghe Pang, Zhenfei Yin, Lei Bai, Siheng Chen

+ [Date Fragments: A Hidden Bottleneck of Tokenization for Temporal Reasoning](https://arxiv.org//abs/2505.16088)

	Gagan Bhatia, Maxime Peyrard, Wei Zhao

+ [Steering LVLMs via Sparse Autoencoder for Hallucination Mitigation](https://arxiv.org//abs/2505.16146)

	Zhenglin Hua, Jinghan He, Zijun Yao, Tianxu Han, Haiyun Guo, Yuheng Jia, Junfeng Fang

+ [VLM-R$^3$: Region Recognition, Reasoning, and Refinement for Enhanced Multimodal Chain-of-Thought](https://arxiv.org//abs/2505.16192)

	Chaoya Jiang, Yongrui Heng, Wei Ye, Han Yang, Haiyang Xu, Ming Yan, Ji Zhang, Fei Huang, Shikun Zhang

+ [NQKV: A KV Cache Quantization Scheme Based on Normal Distribution Characteristics](https://arxiv.org//abs/2505.16210)

	Zhihang Cai, Xingjun Zhang, Zhendong Tan, Zheng Wei

+ [AudioTrust: Benchmarking the Multifaceted Trustworthiness of Audio Large Language Models](https://arxiv.org//abs/2505.16211)

	Kai Li, Can Shen, Yile Liu, Jirui Han, Kelong Zheng, Xuechao Zou, Zhe Wang, Xingjian Du, Shun Zhang, Hanjun Luo, Yingbin Jin, Xinxin Xing, Ziyang Ma, Yue Liu, Xiaojun Jia, Yifan Zhang, Junfeng Fang, Kun Wang, Yibo Yan, Haoyang Li, Yiming Li, Xiaobin Zhuang, Yang Liu, Haibo Hu, Zhuo Chen, Zhizheng Wu, Xiaolin Hu, Eng-Siong Chng, XiaoFeng Wang, Wenyuan Xu, Wei Dong, Xinfeng Li

+ [LIFEBench: Evaluating Length Instruction Following in Large Language Models](https://arxiv.org//abs/2505.16234)

	Wei Zhang, Zhenhong Zhou, Junfeng Fang, Rongwu Xu, Kun Wang, Yuanhe Zhang, Rui Wang, Ge Zhang, Xinfeng Li, Li Sun, Lingjuan Lyu, Yang Liu, Sen Su

+ [Transformer Copilot: Learning from The Mistake Log in LLM Fine-tuning](https://arxiv.org//abs/2505.16270)

	Jiaru Zou, Yikun Ban, Zihao Li, Yunzhe Qi, Ruizhong Qiu, Ling Yang, Jingrui He

+ [PMPO: Probabilistic Metric Prompt Optimization for Small and Large Language Models](https://arxiv.org//abs/2505.16307)

	Chenzhuo Zhao, Ziqian Liu, Xingda Wang, Junting Lu, Chaoyi Ruan

+ [AdaSTaR: Adaptive Data Sampling for Training Self-Taught Reasoners](https://arxiv.org//abs/2505.16322)

	Woosung Koh, Wonbeen Oh, Jaein Jang, MinHyung Lee, Hyeongjin Kim, Ah Yeon Kim, Joonkee Kim, Junghyun Lee, Taehyeon Kim, Se-Young Yun

+ [SATURN: SAT-based Reinforcement Learning to Unleash Language Model Reasoning](https://arxiv.org//abs/2505.16368)

	Huanyu Liu, Jia Li, Hao Zhu, Kechi Zhang, Yihong Dong, Ge Li

+ [Tool-Star: Empowering LLM-Brained Multi-Tool Reasoner via Reinforcement Learning](https://arxiv.org//abs/2505.16410)

	Guanting Dong, Yifei Chen, Xiaoxi Li, Jiajie Jin, Hongjin Qian, Yutao Zhu, Hangyu Mao, Guorui Zhou, Zhicheng Dou, Ji-Rong Wen

+ [Attributing Response to Context: A Jensen-Shannon Divergence Driven Mechanistic Study of Context Attribution in Retrieval-Augmented Generation](https://arxiv.org//abs/2505.16415)

	Ruizhe Li, Chen Chen, Yuchen Hu, Yanjun Gao, Xi Wang, Emine Yilmaz

+ [Teaching Large Language Models to Maintain Contextual Faithfulness via Synthetic Tasks and Reinforcement Learning](https://arxiv.org//abs/2505.16483)

	Shuzheng Si, Haozhe Zhao, Cheng Gao, Yuzhuo Bai, Zhitong Wang, Bofei Gao, Kangyang Luo, Wenhao Li, Yufei Huang, Gang Chen, Fanchao Qi, Minjia Zhang, Baobao Chang, Maosong Sun

+ [LLaMAs Have Feelings Too: Unveiling Sentiment and Emotion Representations in LLaMA Models Through Probing](https://arxiv.org//abs/2505.16491)

	Dario Di Palma, Alessandro De Bellis, Giovanni Servedio, Vito Walter Anelli, Fedelucio Narducci, Tommaso Di Noia

+ [Human-like Semantic Navigation for Autonomous Driving using Knowledge Representation and Large Language Models](https://arxiv.org//abs/2505.16498)

	Augusto Luis Ballardini, Miguel Ángel Sotelo

+ [Smaller, Smarter, Closer: The Edge of Collaborative Generative AI](https://arxiv.org//abs/2505.16499)

	Roberto Morabito, SiYoung Jang

+ [Sparse Activation Editing for Reliable Instruction Following in Narratives](https://arxiv.org//abs/2505.16505)

	Runcong Zhao, Chengyu Cao, Qinglin Zhu, Xiucheng Lv, Shun Shao, Lin Gui, Ruifeng Xu, Yulan He

+ [Edge-First Language Model Inference: Models, Metrics, and Tradeoffs](https://arxiv.org//abs/2505.16508)

	SiYoung Jang, Roberto Morabito

+ [CUB: Benchmarking Context Utilisation Techniques for Language Models](https://arxiv.org//abs/2505.16518)

	Lovisa Hagström, Youna Kim, Haeun Yu, Sang-goo Lee, Richard Johansson, Hyunsoo Cho, Isabelle Augenstein

+ [Are the Hidden States Hiding Something? Testing the Limits of Factuality-Encoding Capabilities in LLMs](https://arxiv.org//abs/2505.16520)

	Giovanni Servedio, Alessandro De Bellis, Dario Di Palma, Vito Walter Anelli, Tommaso Di Noia

+ [Benchmarking and Pushing the Multi-Bias Elimination Boundary of LLMs via Causal Effect Estimation-guided Debiasing](https://arxiv.org//abs/2505.16522)

	Zhouhao Sun, Zhiyuan Kan, Xiao Ding, Li Du, Yang Zhao, Bing Qin, Ting Liu

+ [DuFFin: A Dual-Level Fingerprinting Framework for LLMs IP Protection](https://arxiv.org//abs/2505.16530)

	Yuliang Yan, Haochun Tang, Shuo Yan, Enyan Dai

+ [Finetuning-Activated Backdoors in LLMs](https://arxiv.org//abs/2505.16567)

	Thibaud Gloaguen, Mark Vero, Robin Staab, Martin Vechev

+ [O$^2$-Searcher: A Searching-based Agent Model for Open-Domain Open-Ended Question Answering](https://arxiv.org//abs/2505.16582)

	Jianbiao Mei, Tao Hu, Daocheng Fu, Licheng Wen, Xuemeng Yang, Rong Wu, Pinlong Cai, Xing Gao, Yu Yang, Chengjun Xie, Botian Shi, Yong Liu, Yu Qiao

+ [Steering Large Language Models for Machine Translation Personalization](https://arxiv.org//abs/2505.16612)

	Daniel Scalena, Gabriele Sarti, Arianna Bisazza, Elisabetta Fersini, Malvina Nissim

+ [BadVLA: Towards Backdoor Attacks on Vision-Language-Action Models via Objective-Decoupled Optimization](https://arxiv.org//abs/2505.16640)

	Xueyang Zhou, Guiyao Tie, Guowen Zhang, Hechang Wang, Pan Zhou, Lichao Sun

+ [From Evaluation to Defense: Advancing Safety in Video Large Language Models](https://arxiv.org//abs/2505.16643)

	Yiwei Sun, Peiqi Jiang, Chuanbin Liu, Luohao Lin, Zhiying Lu, Hongtao Xie

+ [Collaboration among Multiple Large Language Models for Medical Question Answering](https://arxiv.org//abs/2505.16648)

	Kexin Shang, Chia-Hsuan Chang, Christopher C. Yang

+ [BitHydra: Towards Bit-flip Inference Cost Attack against Large Language Models](https://arxiv.org//abs/2505.16670)

	Xiaobei Yan, Yiming Li, Zhaoxin Fan, Han Qiu, Tianwei Zhang

+ [R1-ShareVL: Incentivizing Reasoning Capability of Multimodal Large Language Models via Share-GRPO](https://arxiv.org//abs/2505.16673)

	Huanjin Yao, Qixiang Yin, Jingyi Zhang, Min Yang, Yibo Wang, Wenhao Wu, Fei Su, Li Shen, Minghui Qiu, Dacheng Tao, Jiaxing Huang

+ [Your Pre-trained LLM is Secretly an Unsupervised Confidence Calibrator](https://arxiv.org//abs/2505.16690)

	Beier Luo, Shuoyuan Wang, Yixuan Li, Hongxin Wei

+ [Beyond Induction Heads: In-Context Meta Learning Induces Multi-Phase Circuit Emergence](https://arxiv.org//abs/2505.16694)

	Gouki Minegishi, Hiroki Furuta, Shohei Taniguchi, Yusuke Iwasawa, Yutaka Matsuo

+ [Training Long-Context LLMs Efficiently via Chunk-wise Optimization](https://arxiv.org//abs/2505.16710)

	Wenhao Li, Yuxin Zhang, Gen Luo, Daohai Yu, Rongrong Ji

+ [Breaking mBad! Supervised Fine-tuning for Cross-Lingual Detoxification](https://arxiv.org//abs/2505.16722)

	Himanshu Beniwal, Youngwoo Kim, Maarten Sap, Soham Dan, Thomas Hartvigsen

+ [Mitigating Fine-tuning Risks in LLMs via Safety-Aware Probing Optimization](https://arxiv.org//abs/2505.16737)

	Chengcan Wu, Zhixin Zhang, Zeming Wei, Yihao Zhang, Meng Sun

+ [TRIM: Achieving Extreme Sparsity with Targeted Row-wise Iterative Metric-driven Pruning](https://arxiv.org//abs/2505.16743)

	Florentin Beck, William Rudman, Carsten Eickhoff

+ [When Safety Detectors Aren't Enough: A Stealthy and Effective Jailbreak Attack on LLMs via Steganographic Techniques](https://arxiv.org//abs/2505.16765)

	Jianing Geng, Biao Yi, Zekun Fei, Tongxi Wu, Lihai Nie, Zheli Liu

+ [CoTSRF: Utilize Chain of Thought as Stealthy and Robust Fingerprint of Large Language Models](https://arxiv.org//abs/2505.16785)

	Zhenzhen Ren, GuoBiao Li, Sheng Li, Zhenxing Qian, Xinpeng Zhang

+ [Accidental Misalignment: Fine-Tuning Language Models Induces Unexpected Vulnerability](https://arxiv.org//abs/2505.16789)

	Punya Syon Pandey, Samuel Simko, Kellin Pelrine, Zhijing Jin

+ [Unlearning Isn't Deletion: Investigating Reversibility of Machine Unlearning in LLMs](https://arxiv.org//abs/2505.16831)

	Xiaoyu Xu, Xiang Yue, Yang Liu, Qingqing Ye, Haibo Hu, Minxin Du

+ [SimpleDeepSearcher: Deep Information Seeking via Web-Powered Reasoning Trajectory Synthesis](https://arxiv.org//abs/2505.16834)

	Shuang Sun, Huatong Song, Yuhao Wang, Ruiyang Ren, Jinhao Jiang, Junjie Zhang, Fei Bai, Jia Deng, Wayne Xin Zhao, Zheng Liu, Lei Fang, Zhongyuan Wang, Ji-Rong Wen

+ [CASTILLO: Characterizing Response Length Distributions of Large Language Models](https://arxiv.org//abs/2505.16881)

	Daniel F. Perez-Ramirez, Dejan Kostic, Magnus Boman

+ [Don't "Overthink" Passage Reranking: Is Reasoning Truly Necessary?](https://arxiv.org//abs/2505.16886)

	Nour Jedidi, Yung-Sung Chuang, James Glass, Jimmy Lin

+ [CAIN: Hijacking LLM-Humans Conversations via a Two-Stage Malicious System Prompt Generation and Refining Framework](https://arxiv.org//abs/2505.16888)

	Viet Pham, Thai Le

+ [Latent Principle Discovery for Language Model Self-Improvement](https://arxiv.org//abs/2505.16927)

	Keshav Ramji, Tahira Naseem, Ramón Fernandez Astudillo

+ [MixAT: Combining Continuous and Discrete Adversarial Training for LLMs](https://arxiv.org//abs/2505.16947)

	Csaba Dékány, Stefan Balauca, Robin Staab, Dimitar I. Dimitrov, Martin Vechev

+ [Bottlenecked Transformers: Periodic KV Cache Abstraction for Generalised Reasoning](https://arxiv.org//abs/2505.16950)

	Adnan Oomerjee, Zafeirios Fountas, Zhongwei Yu, Haitham Bou-Ammar, Jun Wang

+ [Invisible Prompts, Visible Threats: Malicious Font Injection in External Resources for Large Language Models](https://arxiv.org//abs/2505.16957)

	Junjie Xiong, Changjia Zhu, Shuhang Lin, Chong Zhang, Yongfeng Zhang, Yao Liu, Lingyao Li

+ [Fixing Data That Hurts Performance: Cascading LLMs to Relabel Hard Negatives for Robust Information Retrieval](https://arxiv.org//abs/2505.16967)

	Nandan Thakur, Crystina Zhang, Xueguang Ma, Jimmy Lin

+ [T1: A Tool-Oriented Conversational Dataset for Multi-Turn Agentic Planning](https://arxiv.org//abs/2505.16986)

	Amartya Chakraborty, Paresh Dashore, Nadia Bathaee, Anmol Jain, Anirban Das, Shi-Xiong Zhang, Sambit Sahu, Milind Naphade, Genta Indra Winata

+ [MASLab: A Unified and Comprehensive Codebase for LLM-based Multi-Agent Systems](https://arxiv.org//abs/2505.16988)

	Rui Ye, Keduan Huang, Qimin Wu, Yuzhu Cai, Tian Jin, Xianghe Pang, Xiangrui Liu, Jiaqi Su, Chen Qian, Bohan Tang, Kaiqu Liang, Jiaao Chen, Yue Hu, Zhenfei Yin, Rongye Shi, Bo An, Yang Gao, Wenjun Wu, Lei Bai, Siheng Chen

+ [Do Large Language Models Excel in Complex Logical Reasoning with Formal Language?](https://arxiv.org//abs/2505.16998)

	Jin Jiang, Jianing Wang, Yuchen Yan, Yang Liu, Jianhua Zhu, Mengdi Zhang, Xunliang Cai, Liangcai Gao

+ [R1-Searcher++: Incentivizing the Dynamic Knowledge Acquisition of LLMs via Reinforcement Learning](https://arxiv.org//abs/2505.17005)

	Huatong Song, Jinhao Jiang, Wenqing Tian, Zhipeng Chen, Yuhuan Wu, Jiahao Zhao, Yingqian Min, Wayne Xin Zhao, Lei Fang, Ji-Rong Wen

+ [Understanding Prompt Tuning and In-Context Learning via Meta-Learning](https://arxiv.org//abs/2505.17010)

	Tim Genewein, Kevin Wenliang Li, Jordi Grau-Moya, Anian Ruoss, Laurent Orseau, Marcus Hutter

+ [SpatialScore: Towards Unified Evaluation for Multimodal Spatial Understanding](https://arxiv.org//abs/2505.17012)

	Haoning Wu, Xiao Huang, Yaohui Chen, Ya Zhang, Yanfeng Wang, Weidi Xie

+ [Continually Self-Improving Language Models for Bariatric Surgery Question--Answering](https://arxiv.org//abs/2505.16102)

	Yash Kumar Atri, Thomas H Shin, Thomas Hartvigsen

+ [Hierarchical Safety Realignment: Lightweight Restoration of Safety in Pruned Large Vision-Language Models](https://arxiv.org//abs/2505.16104)

	Yue Li, Xin Yi, Dongsheng Shi, Gerard de Melo, Xiaoling Wang, Linlin Wang

+ [Veracity Bias and Beyond: Uncovering LLMs' Hidden Beliefs in Problem-Solving Reasoning](https://arxiv.org//abs/2505.16128)

	Yue Zhou, Barbara Di Eugenio

+ [Position of Uncertainty: A Cross-Linguistic Study of Positional Bias in Large Language Models](https://arxiv.org//abs/2505.16134)

	Menschikov Mikhail, Alexander Kharitonov, Maiia Kotyga, Vadim Porvatov, Anna Zhukovskaya, David Kagramanyan, Egor Shvetsov, Evgeny Burnaev

+ [Distilling the Implicit Multi-Branch Structure in LLMs' Reasoning via Reinforcement Learning](https://arxiv.org//abs/2505.16142)

	Shicheng Xu, Liang Pang, Yunchang Zhu, Jia Gu, Zihao Wei, Jingcheng Deng, Feiyang Pan, Huawei Shen, Xueqi Cheng

+ [KNN-SSD: Enabling Dynamic Self-Speculative Decoding via Nearest Neighbor Layer Set Optimization](https://arxiv.org//abs/2505.16162)

	Mingbo Song, Heming Xia, Jun Zhang, Chak Tou Leong, Qiancheng Xu, Wenjie Li, Sujian Li

+ [When Do LLMs Admit Their Mistakes? Understanding the Role of Model Belief in Retraction](https://arxiv.org//abs/2505.16170)

	Yuqing Yang, Robin Jia

+ [Understanding Fact Recall in Language Models: Why Two-Stage Training Encourages Memorization but Mixed Training Teaches Knowledge](https://arxiv.org//abs/2505.16178)

	Ying Zhang, Benjamin Heinzerling, Dongyuan Li, Ryoma Ishigaki, Yuta Hitomi, Kentaro Inui

+ [SAE-SSV: Supervised Steering in Sparse Representation Spaces for Reliable Control of Language Models](https://arxiv.org//abs/2505.16188)

	Zirui He, Mingyu Jin, Bo Shen, Ali Payani, Yongfeng Zhang, Mengnan Du

+ [An Empirical Study on Configuring In-Context Learning Demonstrations for Unleashing MLLMs' Sentimental Perception Capability](https://arxiv.org//abs/2505.16193)

	Daiqing Wu, Dongbao Yang, Sicheng Zhao, Can Ma, Yu Zhou

+ [Memorization or Reasoning? Exploring the Idiom Understanding of LLMs](https://arxiv.org//abs/2505.16216)

	Jisu Kim, Youngwoo Shin, Uiji Hwang, Jihun Choi, Richeng Xuan, Taeuk Kim

+ [Don't Judge Code by Its Cover: Exploring Biases in LLM Judges for Code Evaluation](https://arxiv.org//abs/2505.16222)

	Jiwon Moon, Yerin Hwang, Dongryeol Lee, Taegwan Kang, Yongil Kim, Kyomin Jung

+ [MuseRAG: Idea Originality Scoring At Scale](https://arxiv.org//abs/2505.16232)

	Ali Sarosh Bangash, Krish Veera, Ishfat Abrar Islam, Raiyan Abdul Baten

+ [Align-GRAG: Reasoning-Guided Dual Alignment for Graph Retrieval-Augmented Generation](https://arxiv.org//abs/2505.16237)

	Derong Xu, Pengyue Jia, Xiaopeng Li, Yingyi Zhang, Maolin Wang, Qidong Liu, Xiangyu Zhao, Yichao Wang, Huifeng Guo, Ruiming Tang, Enhong Chen, Tong Xu

+ [Three Minds, One Legend: Jailbreak Large Reasoning Model with Adaptive Stacked Ciphers](https://arxiv.org//abs/2505.16241)

	Viet-Anh Nguyen, Shiqian Zhao, Gia Dao, Runyi Hu, Yi Xie, Luu Anh Tuan

+ [Diverse, not Short: A Length-Controlled Self-Learning Framework for Improving Response Diversity of Language Models](https://arxiv.org//abs/2505.16245)

	Vijeta Deshpande, Debasmita Ghose, John D. Patterson, Roger Beaty, Anna Rumshisky

+ [Does Localization Inform Unlearning? A Rigorous Examination of Local Parameter Attribution for Knowledge Unlearning in Language Models](https://arxiv.org//abs/2505.16252)

	Hwiyeong Lee, Uiji Hwang, Hyelim Lim, Taeuk Kim

+ [HiMATE: A Hierarchical Multi-Agent Framework for Machine Translation Evaluation](https://arxiv.org//abs/2505.16281)

	Shijie Zhang, Renhao Li, Songsheng Wang, Philipp Koehn, Min Yang, Derek F. Wong

+ [Augmenting LLM Reasoning with Dynamic Notes Writing for Complex QA](https://arxiv.org//abs/2505.16293)

	Rishabh Maheshwary, Masoud Hashemi, Khyati Mahajan, Shiva Krishna Reddy Malay, Sai Rajeswar, Sathwik Tejaswi Madhusudhan, Spandana Gella, Vikas Yadav

+ [ToDi: Token-wise Distillation via Fine-Grained Divergence Control](https://arxiv.org//abs/2505.16297)

	Seongryong Jung, Suwan Yoon, DongGeon Kim, Hwanhee Lee

+ [INFERENCEDYNAMICS: Efficient Routing Across LLMs through Structured Capability and Knowledge Profiling](https://arxiv.org//abs/2505.16303)

	Haochen Shi, Tianshi Zheng, Weiqi Wang, Baixuan Xu, Chunyang Li, Chunkit Chan, Tao Fan, Yangqiu Song, Qiang Yang

+ [Embodied Agents Meet Personalization: Exploring Memory Utilization for Personalized Assistance](https://arxiv.org//abs/2505.16348)

	Taeyoon Kwon, Dongwook Choi, Sunghwan Kim, Hyojun Kim, Seungjun Moon, Beong-woo Kwak, Kuan-Hao Huang, Jinyoung Yeo

+ [Ask, Retrieve, Summarize: A Modular Pipeline for Scientific Literature Summarization](https://arxiv.org//abs/2505.16349)

	Pierre Achkar, Tim Gollub, Martin Potthast

+ [PaTH Attention: Position Encoding via Accumulating Householder Transformations](https://arxiv.org//abs/2505.16381)

	Songlin Yang, Yikang Shen, Kaiyue Wen, Shawn Tan, Mayank Mishra, Liliang Ren, Rameswar Panda, Yoon Kim

+ [Semantic Pivots Enable Cross-Lingual Transfer in Large Language Models](https://arxiv.org//abs/2505.16385)

	Kaiyu He, Tong Zhou, Yubo Chen, Delai Qiu, Shengping Liu, Kang Liu, Jun Zhao

+ [WebAgent-R1: Training Web Agents via End-to-End Multi-Turn Reinforcement Learning](https://arxiv.org//abs/2505.16421)

	Zhepei Wei, Wenlin Yao, Yao Liu, Weizhi Zhang, Qin Lu, Liang Qiu, Changlong Yu, Puyang Xu, Chao Zhang, Bing Yin, Hyokun Yun, Lihong Li

+ [Reading Between the Prompts: How Stereotypes Shape LLM's Implicit Personalization](https://arxiv.org//abs/2505.16467)

	Vera Neplenbroek, Arianna Bisazza, Raquel Fernández

+ [EnSToM: Enhancing Dialogue Systems with Entropy-Scaled Steering Vectors for Topic Maintenance](https://arxiv.org//abs/2505.16526)

	Heejae Suh, Yejin Jeon, Deokhyung Kang, Taehee Park, Yejin Min, Gary Geunbae Lee

+ [Mechanistic Understanding and Mitigation of Language Confusion in English-Centric Large Language Models](https://arxiv.org//abs/2505.16538)

	Ercong Nie, Helmut Schmid, Hinrich Schütze

+ [Think Silently, Think Fast: Dynamic Latent Compression of LLM Reasoning Chains](https://arxiv.org//abs/2505.16552)

	Wenhui Tan, Jiaze Li, Jianzhong Ju, Zhenbo Luo, Jian Luan, Ruihua Song

+ [URLs Help, Topics Guide: Understanding Metadata Utility in LLM Training](https://arxiv.org//abs/2505.16570)

	Dongyang Fan, Vinko Sabolčec, Martin Jaggi

+ [EMULATE: A Multi-Agent Framework for Determining the Veracity of Atomic Claims by Emulating Human Actions](https://arxiv.org//abs/2505.16576)

	Spencer Hong, Meng Luo, Xinyi Wan

+ [Evaluating Large Language Model with Knowledge Oriented Language Specific Simple Question Answering](https://arxiv.org//abs/2505.16591)

	Bowen Jiang, Runchuan Zhu, Jiang Wu, Zinco Jiang, Yifan He, Junyuan Gao, Jia Yu, Rui Min, Yinfan Wang, Haote Yang, Songyang Zhang, Dahua Lin, Lijun Wu, Conghui He

+ [From Generic Empathy to Personalized Emotional Support: A Self-Evolution Framework for User Preference Alignment](https://arxiv.org//abs/2505.16610)

	Jing Ye, Lu Xiang, Yaping Zhang, Chengqing Zong

+ [Locate-then-Merge: Neuron-Level Parameter Fusion for Mitigating Catastrophic Forgetting in Multimodal LLMs](https://arxiv.org//abs/2505.16703)

	Zeping Yu, Sophia Ananiadou

+ [Reasoning Beyond Language: A Comprehensive Survey on Latent Chain-of-Thought Reasoning](https://arxiv.org//abs/2505.16782)

	Xinghao Chen, Anhao Zhao, Heming Xia, Xuan Lu, Hanlin Wang, Yanjun Chen, Wei Zhang, Jian Wang, Wenjie Li, Xiaoyu Shen

+ [Two-way Evidence self-Alignment based Dual-Gated Reasoning Enhancement](https://arxiv.org//abs/2505.16806)

	Kexin Zhang, Junlan Chen, Daifeng Li, Yuxuan Zhang, Yangyang Feng, Bowen Deng, Weixu Chen

+ [R1-Compress: Long Chain-of-Thought Compression via Chunk Compression and Search](https://arxiv.org//abs/2505.16838)

	Yibo Wang, Li Shen, Huanjin Yao, Tiansheng Huang, Rui Liu, Naiqiang Tan, Jiaxing Huang, Kai Zhang, Dacheng Tao

+ [MPO: Multilingual Safety Alignment via Reward Gap Optimization](https://arxiv.org//abs/2505.16869)

	Weixiang Zhao, Yulin Hu, Yang Deng, Tongtong Wu, Wenxuan Zhang, Jiahe Guo, An Zhang, Yanyan Zhao, Bing Qin, Tat-Seng Chua, Ting Liu

+ [Shadows in the Attention: Contextual Perturbation and Representation Drift in the Dynamics of Hallucination in LLMs](https://arxiv.org//abs/2505.16894)

	Zeyu Wei, Shuo Wang, Xiaohui Rong, Xuemin Liu, He Li

+ [Power-Law Decay Loss for Large Language Model Finetuning: Focusing on Information Sparsity to Enhance Generation Quality](https://arxiv.org//abs/2505.16900)

	Jintian Shao, Hongyi Huang, Jiayi Wu, Beiwen Zhang, ZhiYu Wu, You Shan, MingKai Zheng

+ [UNCLE: Uncertainty Expressions in Long-Form Generation](https://arxiv.org//abs/2505.16922)

	Ruihan Yang, Caiqi Zhang, Zhisong Zhang, Xinting Huang, Dong Yu, Nigel Collier, Deqing Yang

+ [In-Context Watermarks for Large Language Models](https://arxiv.org//abs/2505.16934)

	Yepeng Liu, Xuandong Zhao, Christopher Kruegel, Dawn Song, Yuheng Bu

+ [On Multilingual Encoder Language Model Compression for Low-Resource Languages](https://arxiv.org//abs/2505.16956)

	Daniil Gurgurov, Michal Gregor, Josef van Genabith, Simon Ostermann

+ [VeriFastScore: Speeding up long-form factuality evaluation](https://arxiv.org//abs/2505.16973)

	Rishanth Rajendhran, Amir Zadeh, Matthew Sarte, Chuan Li, Mohit Iyyer

+ [LLM as Effective Streaming Processor: Bridging Streaming-Batch Mismatches with Group Position Encoding](https://arxiv.org//abs/2505.16983)

	Junlong Tong, Jinlan Fu, Zixuan Lin, Yingqi Fan, Anhao Zhao, Hui Su, Xiaoyu Shen

+ [Benchmarking Retrieval-Augmented Multimomal Generation for Document Question Answering](https://arxiv.org//abs/2505.16470)

	Kuicai Dong, Yujing Chang, Shijie Huang, Yasheng Wang, Ruiming Tang, Yong Liu

+ [CTRAP: Embedding Collapse Trap to Safeguard Large Language Models from Harmful Fine-Tuning](https://arxiv.org//abs/2505.16559)

	Biao Yi, Tiansheng Huang, Baolei Zhang, Tong Li, Lihai Nie, Zheli Liu, Li Shen

+ [UFT: Unifying Supervised and Reinforcement Fine-Tuning](https://arxiv.org//abs/2505.16984)

	Mingyang Liu, Gabriele Farina, Asuman Ozdaglar

+ [Multi-SpatialMLLM: Multi-Frame Spatial Understanding with Multi-Modal Large Language Models](https://arxiv.org//abs/2505.17015)

	Runsen Xu, Weiyao Wang, Hao Tang, Xingyu Chen, Xiaodong Wang, Fu-Jen Chu, Dahua Lin, Matt Feiszli, Kevin J. Liang

+ [Training-Free Reasoning and Reflection in MLLMs](https://arxiv.org//abs/2505.16151)

	Hongchen Wei, Zhenzhong Chen

+ [Erased or Dormant? Rethinking Concept Erasure Through Reversibility](https://arxiv.org//abs/2505.16174)

	Ping Liu, Chi Zhang

+ [CT-Agent: A Multimodal-LLM Agent for 3D CT Radiology Question Answering](https://arxiv.org//abs/2505.16229)

	Yuren Mao, Wenyi Xu, Yuyang Qin, Yunjun Gao

+ [ARPO:End-to-End Policy Optimization for GUI Agents with Experience Replay](https://arxiv.org//abs/2505.16282)

	Fanbin Lu, Zhisheng Zhong, Shu Liu, Chi-Wing Fu, Jiaya Jia

+ [Mitigating Hallucinations in Vision-Language Models through Image-Guided Head Suppression](https://arxiv.org//abs/2505.16411)

	Sreetama Sarkar, Yue Che, Alex Gavin, Peter A. Beerel, Souvik Kundu

+ [ALTo: Adaptive-Length Tokenizer for Autoregressive Mask Generation](https://arxiv.org//abs/2505.16495)

	Lingfeng Wang, Hualing Lin, Senda Chen, Tao Wang, Changxu Cheng, Yangyang Zhong, Dong Zheng, Wuyue Zhao

+ [Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding](https://arxiv.org//abs/2505.16652)

	Feilong Tang, Chengzhi Liu, Zhongxing Xu, Ming Hu, Zelin Peng, Zhiwei Yang, Jionglong Su, Minquan Lin, Yifan Peng, Xuelian Cheng, Imran Razzak, Zongyuan Ge

+ [Dimple: Discrete Diffusion Multimodal Large Language Model with Parallel Decoding](https://arxiv.org//abs/2505.16990)

	Runpeng Yu, Xinyin Ma, Xinchao Wang

+ [SophiaVL-R1: Reinforcing MLLMs Reasoning with Thinking Reward](https://arxiv.org//abs/2505.17018)

	Kaixuan Fan, Kaituo Feng, Haoming Lyu, Dongzhan Zhou, Xiangyu Yue

+ [Backdoor Cleaning without External Guidance in MLLM Fine-tuning](https://arxiv.org//abs/2505.16916)

	Xuankun Rong, Wenke Huang, Jian Liang, Jinhe Bi, Xun Xiao, Yiming Li, Bo Du, Mang Ye

+ [Tools in the Loop: Quantifying Uncertainty of LLM Question Answering Systems That Use Tools](https://arxiv.org//abs/2505.16113)

	Panagiotis Lymperopoulos, Vasanth Sarathy

+ [Plan and Budget: Effective and Efficient Test-Time Scaling on Large Language Model Reasoning](https://arxiv.org//abs/2505.16122)

	Junhong Lin, Xinyue Zeng, Jie Zhu, Song Wang, Julian Shun, Jun Wu, Dawei Zhou

+ [Small-to-Large Generalization: Data Influences Models Consistently Across Scale](https://arxiv.org//abs/2505.16260)

	Alaa Khaddaj, Logan Engstrom, Aleksander Madry

+ [Think-RM: Enabling Long-Horizon Reasoning in Generative Reward Models](https://arxiv.org//abs/2505.16265)

	Ilgee Hong, Changlong Yu, Liang Qiu, Weixiang Yan, Zhenghao Xu, Haoming Jiang, Qingru Zhang, Qin Lu, Xin Liu, Chao Zhang, Tuo Zhao

+ [Only Large Weights (And Not Skip Connections) Can Prevent the Perils of Rank Collapse](https://arxiv.org//abs/2505.16284)

	Josh Alman, Zhao Song

+ [Understanding Differential Transformer Unchains Pretrained Self-Attentions](https://arxiv.org//abs/2505.16333)

	Chaerin Kong, Jiho Jang, Nojun Kwak

+ [Improving Chemical Understanding of LLMs via SMILES Parsing](https://arxiv.org//abs/2505.16340)

	Yunhui Jang, Jaehyung Kim, Sungsoo Ahn

+ [Divide-Fuse-Conquer: Eliciting "Aha Moments" in Multi-Scenario Games](https://arxiv.org//abs/2505.16401)

	Xiaoqing Zhang, Huabin Zheng, Ang Lv, Yuhan Liu, Zirui Song, Flood Sung, Xiuying Chen, Rui Yan

+ [Implicit Jailbreak Attacks via Cross-Modal Information Concealment on Vision-Language Models](https://arxiv.org//abs/2505.16446)

	Zhaoxin Wang, Handing Wang, Cong Tian, Yaochu Jin

+ [HOFT: Householder Orthogonal Fine-tuning](https://arxiv.org//abs/2505.16531)

	Alejandro Moreno Arcas, Albert Sanchis, Jorge Civera, Alfons Juan

+ [Generator-Mediated Bandits: Thompson Sampling for GenAI-Powered Adaptive Interventions](https://arxiv.org//abs/2505.16311)

	Marc Brooks, Gabriel Durham, Kihyuk Hong, Ambuj Tewari

+ [Robust LLM Fingerprinting via Domain-Specific Watermarks](https://arxiv.org//abs/2505.16723)

	Thibaud Gloaguen, Robin Staab, Nikola Jovanović, Martin Vechev

+ [Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks](https://arxiv.org//abs/2505.16901)

	Hongyuan Tao, Ying Zhang, Zhenhao Tang, Hongen Peng, Xukun Zhu, Bingchang Liu, Yingguang Yang, Ziyin Zhang, Zhaogui Xu, Haipeng Zhang, Linchao Zhu, Rui Wang, Hang Yu, Jianguo Li, Peng Di

+ [ReCopilot: Reverse Engineering Copilot in Binary Analysis](https://arxiv.org//abs/2505.16366)

	Guoqiang Chen, Huiqi Sun, Daguang Liu, Zhiqi Wang, Qiang Wang, Bin Yin, Lu Liu, Lingyun Ying

+ [Effective Reinforcement Learning for Reasoning in Language Models](https://arxiv.org//abs/2505.17218)

	Lianghuan Huang, Shuo Li, Sagnik Anupam, Insup Lee, Osbert Bastani

+ [Reasoning Model is Stubborn: Diagnosing Instruction Overriding in Reasoning Models](https://arxiv.org//abs/2505.17225)

	Doohyuk Jang, Yoonjeon Kim, Chanjae Park, Hyun Ryu, Eunho Yang

+ [AdaReasoner: Adaptive Reasoning Enables More Flexible Thinking](https://arxiv.org//abs/2505.17312)

	Xiangqi Wang, Yue Huang, Yanbo Wang, Xiaonan Luo, Kehan Guo, Yujun Zhou, Xiangliang Zhang

+ [Longer Context, Deeper Thinking: Uncovering the Role of Long-Context Ability in Reasoning](https://arxiv.org//abs/2505.17315)

	Wang Yang, Zirui Liu, Hongye Jin, Qingyu Yin, Vipin Chaudhary, Xiaotian Han

+ [DEL-ToM: Inference-Time Scaling for Theory-of-Mind Reasoning via Dynamic Epistemic Logic](https://arxiv.org//abs/2505.17348)

	Yuheng Wu, Jianwen Xie, Denghui Zhang, Zhaozhuo Xu

+ [Relative Bias: A Comparative Framework for Quantifying Bias in LLMs](https://arxiv.org//abs/2505.17131)

	Alireza Arbabi, Florian Kerschbaum

+ [LongMagpie: A Self-synthesis Method for Generating Large-scale Long-context Instructions](https://arxiv.org//abs/2505.17134)

	Chaochen Gao, Xing Wu, Zijia Lin, Debing Zhang, Songlin Hu

+ [Foundation Models for Geospatial Reasoning: Assessing Capabilities of Large Language Models in Understanding Geometries and Topological Spatial Relations](https://arxiv.org//abs/2505.17136)

	Yuhan Ji, Song Gao, Ying Nie, Ivan Majić, Krzysztof Janowicz

+ [RAP: Runtime-Adaptive Pruning for LLM Inference](https://arxiv.org//abs/2505.17138)

	Huanrong Liu, Chunlin Tian, Xuyang Wei, Jiaheng Dai, Qin Liu, Tianqi Wei, Qingbiao Li, Li Li

+ [EarthSE: A Benchmark Evaluating Earth Scientific Exploration Capability for Large Language Models](https://arxiv.org//abs/2505.17139)

	Wanghan Xu, Xiangyu Zhao, Yuhao Zhou, Xiaoyu Yue, Ben Fei, Fenghua Ling, Wenlong Zhang, Lei Bai

+ [Data Doping or True Intelligence? Evaluating the Transferability of Injected Knowledge in LLMs](https://arxiv.org//abs/2505.17140)

	Essa Jan, Moiz Ali, Muhammad Saram Hassan, Fareed Zaffar, Yasir Zaki

+ [MDIT-Bench: Evaluating the Dual-Implicit Toxicity in Large Multimodal Models](https://arxiv.org//abs/2505.17144)

	Bohan Jin, Shuhan Qi, Kehai Chen, Xinyi Guo, Xuan Wang

+ [LLM Access Shield: Domain-Specific LLM Framework for Privacy Policy Compliance](https://arxiv.org//abs/2505.17145)

	Yu Wang, Cailing Cai, Zhihua Xiao, Peifung E. Lam

+ [MTSA: Multi-turn Safety Alignment for LLMs through Multi-round Red-teaming](https://arxiv.org//abs/2505.17147)

	Weiyang Guo, Jing Li, Wenya Wang, YU LI, Daojing He, Jun Yu, Min Zhang

+ [LLM-Powered Agents for Navigating Venice's Historical Cadastre](https://arxiv.org//abs/2505.17148)

	Tristan Karch, Jakhongir Saydaliev, Isabella Di Lenardo, Frédéric Kaplan

+ [Amplify Adjacent Token Differences: Enhancing Long Chain-of-Thought Reasoning with Shift-FFN](https://arxiv.org//abs/2505.17153)

	Yao Xu, Mingyu Xu, Fangyu Lei, Wangtao Sun, Xiangrong Zeng, Bingning Wang, Guang Liu, Shizhu He, Jun Zhao, Kang Liu

+ [Can Large Language Models Design Biological Weapons? Evaluating Moremi Bio](https://arxiv.org//abs/2505.17154)

	Gertrude Hattoh, Jeremiah Ayensu, Nyarko Prince Ofori, Solomon Eshun, Darlington Akogo

+ [TrimR: Verifier-based Training-Free Thinking Compression for Efficient Test-Time Scaling](https://arxiv.org//abs/2505.17155)

	Weizhe Lin, Xing Li, Zhiyuan Yang, Xiaojin Fu, Hui-Ling Zhen, Yaoyuan Wang, Xianzhi Yu, Wulong Liu, Xiaosong Li, Mingxuan Yuan

+ [Harry Potter is Still Here! Probing Knowledge Leakage in Targeted Unlearned Large Language Models via Automated Adversarial Prompting](https://arxiv.org//abs/2505.17160)

	Bang Trinh Tran To, Thai Le

+ [DailyQA: A Benchmark to Evaluate Web Retrieval Augmented LLMs Based on Capturing Real-World Changes](https://arxiv.org//abs/2505.17162)

	Jiehan Cheng, Zhicheng Dou

+ [OCR-Reasoning Benchmark: Unveiling the True Capabilities of MLLMs in Complex Text-Rich Image Reasoning](https://arxiv.org//abs/2505.17163)

	Mingxin Huang, Yongxin Shi, Dezhi Peng, Songxuan Lai, Zecheng Xie, Lianwen Jin

+ [Next Token Perception Score: Analytical Assessment of your LLM Perception Skills](https://arxiv.org//abs/2505.17169)

	Yu-Ang Cheng, Leyang Hu, Hai Huang, Randall Balestriero

+ [FB-RAG: Improving RAG with Forward and Backward Lookup](https://arxiv.org//abs/2505.17206)

	Kushal Chawla, Alfy Samuel, Anoop Kumar, Daben Liu

+ [Mitigating Gender Bias via Fostering Exploratory Thinking in LLMs](https://arxiv.org//abs/2505.17217)

	Kangda Wei, Hasnat Md Abdullah, Ruihong Huang

+ [ExeSQL: Self-Taught Text-to-SQL Models with Execution-Driven Bootstrapping for SQL Dialects](https://arxiv.org//abs/2505.17231)

	Jipeng Zhang, Haolin Yang, Kehao Miao, Ruiyuan Zhang, Renjie Pi, Jiahui Gao, Xiaofang Zhou

+ [Optimal Policy Minimum Bayesian Risk](https://arxiv.org//abs/2505.17242)

	Ramón Fernandez Astudillo, Md Arafat Sultan, Aashka Trivedi, Yousef El-Kurdi, Tahira Naseem, Radu Florian, Salim Roukos

+ [ReasoningShield: Content Safety Detection over Reasoning Traces of Large Reasoning Models](https://arxiv.org//abs/2505.17244)

	Changyi Li, Jiayi Wang, Xudong Pan, Geng Hong, Min Yang

+ [ConciseRL: Conciseness-Guided Reinforcement Learning for Efficient Reasoning Models](https://arxiv.org//abs/2505.17250)

	Razvan-Gabriel Dumitru, Darius Peteleaza, Vikas Yadav, Liangming Pan

+ [CaseReportBench: An LLM Benchmark Dataset for Dense Information Extraction in Clinical Case Reports](https://arxiv.org//abs/2505.17265)

	Xiao Yu Cindy Zhang (1), Carlos R. Ferreira (2), Francis Rossignol (2), Raymond T. Ng (1), Wyeth Wasserman (1), Jian Zhu (1) ((1) University of British Columbia, (2) National Institutes of Health)

+ [Select2Reason: Efficient Instruction-Tuning Data Selection for Long-CoT Reasoning](https://arxiv.org//abs/2505.17266)

	Cehao Yang, Xueyuan Lin, Chengjin Xu, Xuhui Jiang, Xiaojun Wu, Honghao Liu, Hui Xiong, Jian Guo

+ [Search Wisely: Mitigating Sub-optimal Agentic Searches By Reducing Uncertainty](https://arxiv.org//abs/2505.17281)

	Peilin Wu, Mian Zhang, Xinlu Zhang, Xinya Du, Zhiyu Zoey Chen

+ [Analyzing Fine-Grained Alignment and Enhancing Vision Understanding in Multimodal Language Models](https://arxiv.org//abs/2505.17316)

	Jiachen Jiang, Jinxin Zhou, Bo Peng, Xia Ning, Zhihui Zhu

+ [From Compression to Expansion: A Layerwise Analysis of In-Context Learning](https://arxiv.org//abs/2505.17322)

	Jiachen Jiang, Yuxin Dong, Jinxin Zhou, Zhihui Zhu

+ [SweEval: Do LLMs Really Swear? A Safety Benchmark for Testing Limits for Enterprise Use](https://arxiv.org//abs/2505.17332)

	Hitesh Laxmichand Patel, Amit Agarwal, Arion Das, Bhargava Kumar, Srikant Panda, Priyaranjan Pattnayak, Taki Hasan Rafi, Tejaswini Kumar, Dong-Kyu Chae

+ [When can isotropy help adapt LLMs' next word prediction to numerical domains?](https://arxiv.org//abs/2505.17135)

	Rashed Shelim, Shengzhe Xu, Walid Saad, Naren Ramakrishnan

+ [PersonaBOT: Bringing Customer Personas to Life with LLMs and RAG](https://arxiv.org//abs/2505.17156)

	Muhammed Rizwan, Lars Carlsson, Mohammad Loni

+ [Humans Hallucinate Too: Language Models Identify and Correct Subjective Annotation Errors With Label-in-a-Haystack Prompts](https://arxiv.org//abs/2505.17222)

	Georgios Chochlakis, Peter Wu, Arjun Bedi, Marcus Ma, Kristina Lerman, Shrikanth Narayanan

+ [Personalizing Student-Agent Interactions Using Log-Contextualized Retrieval Augmented Generation (RAG)](https://arxiv.org//abs/2505.17238)

	Clayton Cohn, Surya Rayala, Caitlin Snyder, Joyce Fonteles, Shruti Jain, Naveeduddin Mohammed, Umesh Timalsina, Sarah K. Burriss, Ashwin T S, Namrata Srivastava, Menton Deweese, Angela Eeds, Gautam Biswas

+ [The Rise of Parameter Specialization for Knowledge Storage in Large Language Models](https://arxiv.org//abs/2505.17260)

	Yihuai Hong, Yiran Zhao, Wei Tang, Yang Deng, Yu Rong, Wenxuan Zhang

+ [SELF: Self-Extend the Context Length With Logistic Growth Function](https://arxiv.org//abs/2505.17296)

	Phat Thanh Dang, Saahil Thoppay, Wang Yang, Qifan Wang, Vipin Chaudhary, Xiaotian Han

+ [Refusal Direction is Universal Across Safety-Aligned Languages](https://arxiv.org//abs/2505.17306)

	Xinpeng Wang, Mingyang Wang, Yihong Liu, Hinrich Schütze, Barbara Plank

+ [Language models should be subject to repeatable, open, domain-contextualized hallucination benchmarking](https://arxiv.org//abs/2505.17345)

	Justin D. Norman, Michael U. Rivera, D. Alex Hughes

+ [Robustifying Vision-Language Models via Dynamic Token Reweighting](https://arxiv.org//abs/2505.17132)

	Tanqiu Jiang, Jiacheng Liang, Rongyi Zhu, Jiawei Zhou, Fenglong Ma, Ting Wang

+ [Zebra-Llama: Towards Extremely Efficient Hybrid Models](https://arxiv.org//abs/2505.17272)

	Mingyu Yang, Mehdi Rezagholizadeh, Guihong Li, Vikram Appia, Emad Barsoum

+ [ECHO-LLaMA: Efficient Caching for High-Performance LLaMA Training](https://arxiv.org//abs/2505.17331)

	Maryam Dialameh, Rezaul Karim, Hossein Rajabzadeh, Omar Mohamed Awad, Hyock Ju Kwon, Boxing Chen, Walid Ahmed, Yang Liu

+ [Shape it Up! Restoring LLM Safety during Finetuning](https://arxiv.org//abs/2505.17196)

	ShengYun Peng, Pin-Yu Chen, Jianfeng Chi, Seongmin Lee, Duen Horng Chau

+ [Automated Capability Evaluation of Foundation Models](https://arxiv.org//abs/2505.17228)

	Arash Afkanpour, Omkar Dige, Fatemeh Tavakoli

# 2025-05-21
+ [ModelingAgent: Bridging LLMs and Mathematical Modeling for Real-World Challenges](https://arxiv.org//abs/2505.15068)

	Cheng Qian, Hongyi Du, Hongru Wang, Xiusi Chen, Yuji Zhang, Avirup Sil, Chengxiang Zhai, Kathleen McKeown, Heng Ji

+ [lmgame-Bench: How Good are LLMs at Playing Games?](https://arxiv.org//abs/2505.15146)

	Lanxiang Hu, Mingjia Huo, Yuxuan Zhang, Haoyang Yu, Eric P. Xing, Ion Stoica, Tajana Rosing, Haojian Jin, Hao Zhang

+ [Generalised Probabilistic Modelling and Improved Uncertainty Estimation in Comparative LLM-as-a-judge](https://arxiv.org//abs/2505.15240)

	Yassir Fathullah, Mark J. F. Gales

+ [When Can Large Reasoning Models Save Thinking? Mechanistic Analysis of Behavioral Divergence in Reasoning](https://arxiv.org//abs/2505.15276)

	Rongzhi Zhu, Yi Liu, Zequn Sun, Yiwei Wang, Wei Hu

+ [When to Continue Thinking: Adaptive Thinking Mode Switching for Efficient Reasoning](https://arxiv.org//abs/2505.15400)

	Xiaoyun Zhang, Jingqing Ruan, Xing Ma, Yawen Zhu, Haodong Zhao, Hao Li, Jiansong Chen, Ke Zeng, Xunliang Cai

+ [Meta-Design Matters: A Self-Design Multi-Agent System](https://arxiv.org//abs/2505.14996)

	Zixuan Ke, Austin Xu, Yifei Ming, Xuan-Phi Nguyen, Caiming Xiong, Shafiq Joty

+ [Learning to Rank Chain-of-Thought: An Energy-Based Approach with Outcome Supervision](https://arxiv.org//abs/2505.14999)

	Eric Hanchen Jiang, Haozheng Luo, Shengyuan Pang, Xiaomin Li, Zhenting Qi, Hengli Li, Cheng-Fu Yang, Zongyu Lin, Xinfeng Li, Hao Xu, Kai-Wei Chang, Ying Nian Wu

+ [RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning](https://arxiv.org//abs/2505.15034)

	Kaiwen Zha, Zhengqi Gao, Maohao Shen, Zhang-Wei Hong, Duane S. Boning, Dina Katabi

+ [Denoising Concept Vectors with Sparse Autoencoders for Improved Language Model Steering](https://arxiv.org//abs/2505.15038)

	Haiyan Zhao, Xuansheng Wu, Fan Yang, Bo Shen, Ninghao Liu, Mengnan Du

+ [Self-GIVE: Associative Thinking from Limited Structured Knowledge for Enhanced Large Language Model Reasoning](https://arxiv.org//abs/2505.15062)

	Jiashu He, Jinxuan Fan, Bowen Jiang, Ignacio Houine, Dan Roth, Alejandro Ribeiro

+ [Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs](https://arxiv.org//abs/2505.15075)

	Hao Wang, Pinzhi Huang, Jihan Yang, Saining Xie, Daisuke Kawahara

+ [SUS backprop: linear backpropagation algorithm for long inputs in transformers](https://arxiv.org//abs/2505.15080)

	Sergey Pankov, Georges Harik

+ [Leveraging Large Language Models for Command Injection Vulnerability Analysis in Python: An Empirical Study on Popular Open-Source Projects](https://arxiv.org//abs/2505.15088)

	Yuxuan Wang, Jingshu Chen, Qingyang Wang

+ [DeFTX: Denoised Sparse Fine-Tuning for Zero-Shot Cross-Lingual Transfer](https://arxiv.org//abs/2505.15090)

	Sona Elza Simon, Preethi Jyothi

+ [Mechanistic evaluation of Transformers and state space models](https://arxiv.org//abs/2505.15105)

	Aryaman Arora, Neil Rathi, Nikil Roashan Selvam, Róbert Csórdas, Dan Jurafsky, Christopher Potts

+ [StepSearch: Igniting LLMs Search Ability via Step-Wise Proximal Policy Optimization](https://arxiv.org//abs/2505.15107)

	Ziliang Wang, Xuhui Zheng, Kang An, Cijun Ouyang, Jialu Cai, Yuhang Wang, Yichao Wu

+ [A Risk Taxonomy for Evaluating AI-Powered Psychotherapy Agents](https://arxiv.org//abs/2505.15108)

	Ian Steenstra, Timothy W. Bickmore

+ [An Empirical Study on Reinforcement Learning for Reasoning-Search Interleaved LLM Agents](https://arxiv.org//abs/2505.15117)

	Bowen Jin, Jinsung Yoon, Priyanka Kargupta, Sercan O. Arik, Jiawei Han

+ [The Unreasonable Effectiveness of Entropy Minimization in LLM Reasoning](https://arxiv.org//abs/2505.15134)

	Shivam Agarwal, Zimin Zhang, Lifan Yuan, Jiawei Han, Hao Peng

+ [BanditSpec: Adaptive Speculative Decoding via Bandit Algorithms](https://arxiv.org//abs/2505.15141)

	Yunlong Hou, Fengzhuo Zhang, Cunxiao Du, Xuan Zhang, Jiachun Pan, Tianyu Pang, Chao Du, Vincent Y. F. Tan, Zhuoran Yang

+ [Prolonged Reasoning Is Not All You Need: Certainty-Based Adaptive Routing for Efficient LLM/MLLM Reasoning](https://arxiv.org//abs/2505.15154)

	Jinghui Lu, Haiyang Yu, Siliang Xu, Shiwei Ran, Guozhi Tang, Siqi Wang, Bin Shan, Teng Fu, Hao Feng, Jingqun Tang, Han Wang, Can Huang

+ [R&D-Agent-Quant: A Multi-Agent Framework for Data-Centric Factors and Model Joint Optimization](https://arxiv.org//abs/2505.15155)

	Yuante Li, Xu Yang, Xiao Yang, Minrui Xu, Xisen Wang, Weiqing Liu, Jiang Bian

+ [ReflAct: World-Grounded Decision Making in LLM Agents via Goal-State Reflection](https://arxiv.org//abs/2505.15182)

	Jeonghye Kim, Sojeong Rhee, Minbeom Kim, Dohyung Kim, Sangmook Lee, Youngchul Sung, Kyomin Jung

+ [BountyBench: Dollar Impact of AI Agent Attackers and Defenders on Real-World Cybersecurity Systems](https://arxiv.org//abs/2505.15216)

	Andy K. Zhang, Joey Ji, Celeste Menders, Riya Dulepet, Thomas Qin, Ron Y. Wang, Junrong Wu, Kyleen Liao, Jiliang Li, Jinghan Hu, Sara Hong, Nardos Demilew, Shivatmica Murgai, Jason Tran, Nishka Kacheria, Ethan Ho, Denis Liu, Lauren McLane, Olivia Bruvik, Dai-Rong Han, Seungwoo Kim, Akhil Vyas, Cuiyuanxiu Chen, Ryan Li, Weiran Xu, Jonathan Z. Ye, Prerit Choudhary, Siddharth M. Bhatia, Vikram Sivashankar, Yuxuan Bao, Dawn Song, Dan Boneh, Daniel E. Ho, Percy Liang

+ [Adaptive Plan-Execute Framework for Smart Contract Security Auditing](https://arxiv.org//abs/2505.15242)

	Zhiyuan Wei, Jing Sun, Zijian Zhang, Zhe Hou, Zixiao Zhao

+ [Towards Explainable Temporal Reasoning in Large Language Models: A Structure-Aware Generative Framework](https://arxiv.org//abs/2505.15245)

	Zihao Jiang, Ben Liu, Miao Peng, Wenjie Xu, Yao Xiao, Zhenyan Shan, Min Peng

+ [Blind Spot Navigation: Evolutionary Discovery of Sensitive Semantic Concepts for LVLMs](https://arxiv.org//abs/2505.15265)

	Zihao Pan, Yu Tong, Weibin Wu, Jingyi Wang, Lifeng Chen, Zhe Zhao, Jiajia Wei, Yitong Qiao, Zibin Zheng

+ [Multiple Weaks Win Single Strong: Large Language Models Ensemble Weak Reinforcement Learning Agents into a Supreme One](https://arxiv.org//abs/2505.15306)

	Yiwen Song, Qianyue Hao, Qingmin Liao, Jian Yuan, Yong Li

+ [Trajectory Bellman Residual Minimization: A Simple Value-Based Method for LLM Reasoning](https://arxiv.org//abs/2505.15311)

	Yurun Yuan, Fan Chen, Zeyu Jia, Alexander Rakhlin, Tengyang Xie

+ [Your Language Model Can Secretly Write Like Humans: Contrastive Paraphrase Attacks on LLM-Generated Text Detectors](https://arxiv.org//abs/2505.15337)

	Hao Fang, Jiawei Kong, Tianqu Zhuang, Yixiang Qiu, Kuofeng Gao, Bin Chen, Shu-Tao Xia, Yaowei Wang, Min Zhang

+ [RePPL: Recalibrating Perplexity by Uncertainty in Semantic Propagation and Language Generation for Explainable QA Hallucination Detection](https://arxiv.org//abs/2505.15386)

	Yiming Huang, Junyan Zhang, Zihao Wang, Biquan Bie, Xuming Hu, Yi R. (May)Fung, Xinlei He

+ [Audio Jailbreak: An Open Comprehensive Benchmark for Jailbreaking Large Audio-Language Models](https://arxiv.org//abs/2505.15406)

	Zirui Song, Qian Jiang, Mingxuan Cui, Mingzhe Li, Lang Gao, Zeyu Zhang, Zixiang Xu, Yanbo Wang, Chenxi Wang, Guangxian Ouyang, Zhenhao Chen, Xiuying Chen

+ [Silent Leaks: Implicit Knowledge Extraction Attack on RAG Systems through Benign Queries](https://arxiv.org//abs/2505.15420)

	Yuhao Wang, Wenjie Qu, Yanze Jiang, Zichen Liu, Yue Liu, Shengfang Zhai, Yinpeng Dong, Jiaheng Zhang

+ [Set-LLM: A Permutation-Invariant LLM](https://arxiv.org//abs/2505.15433)

	Beni Egressy, Jan Stühmer

+ [Single LLM, Multiple Roles: A Unified Retrieval-Augmented Generation Framework Using Role-Specific Token Optimization](https://arxiv.org//abs/2505.15444)

	Yutao Zhu, Jiajie Jin, Hongjin Qian, Zheng Liu, Zhicheng Dou, Ji-Rong Wen

+ [Joint Flashback Adaptation for Forgetting-Resistant Instruction Tuning](https://arxiv.org//abs/2505.15467)

	Yukun Zhao, Lingyong Yan, Zhenyang Li, Shuaiqiang Wang, Zhumin Chen, Zhaochun Ren, Dawei Yin

+ [LFTF: Locating First and Then Fine-Tuning for Mitigating Gender Bias in Large Language Models](https://arxiv.org//abs/2505.15475)

	Zhanyue Qin, Yue Ding, Deyuan Liu, Qingbin Liu, Junxian Cai, Xi Chen, Zhiying Tu, Dianhui Chu, Cuiyun Gao, Dianbo Sui

+ [Protoknowledge Shapes Behaviour of LLMs in Downstream Tasks: Memorization and Generalization with Knowledge Graphs](https://arxiv.org//abs/2505.15501)

	Federico Ranaldi, Andrea Zugarini, Leonardo Ranaldi, Fabio Massimo Zanzotto

+ [Evaluate Bias without Manual Test Sets: A Concept Representation Perspective for LLMs](https://arxiv.org//abs/2505.15524)

	Lang Gao, Kaiyang Wan, Wei Liu, Chenxi Wang, Zirui Song, Zixiang Xu, Yanbo Wang, Veselin Stoyanov, Xiuying Chen

+ [Beyond Classification: Evaluating Diffusion Denoised Smoothing for Security-Utility Trade off](https://arxiv.org//abs/2505.15594)

	Yury Belousov, Brian Pulfer, Vitaliy Kinakh, Slava Voloshynovskiy

+ [From Problem-Solving to Teaching Problem-Solving: Aligning LLMs with Pedagogy using Reinforcement Learning](https://arxiv.org//abs/2505.15607)

	David Dinucu-Jianu, Jakub Macina, Nico Daheim, Ido Hakimi, Iryna Gurevych, Mrinmaya Sachan

+ [Learn to Reason Efficiently with Adaptive Length-based Reward Shaping](https://arxiv.org//abs/2505.15612)

	Wei Liu, Ruochen Zhou, Yiyun Deng, Yuzhen Huang, Junteng Liu, Yuntian Deng, Yizhe Zhang, Junxian He

+ [Listen to the Context: Towards Faithful Large Language Models for Retrieval Augmented Generation on Climate Questions](https://arxiv.org//abs/2505.15633)

	David Thulke, Jakob Kemmler, Christian Dugast, Hermann Ney

+ [UniErase: Unlearning Token as a Universal Erasure Primitive for Language Models](https://arxiv.org//abs/2505.15674)

	Miao Yu, Liang Lin, Guibin Zhang, Xinfeng Li, Junfeng Fang, Ningyu Zhang, Kun Wang, Yang Wang

+ [A Federated Splitting Framework for LLMs: Security, Efficiency, and Adaptability](https://arxiv.org//abs/2505.15683)

	Zishuai Zhang, Hainan Zhang, Jiaying Zheng, Ziwei Wang, Yongxin Tong, Jin Dong, Zhiming Zheng

+ [A Unified Theoretical Analysis of Private and Robust Offline Alignment: from RLHF to DPO](https://arxiv.org//abs/2505.15694)

	Xingyu Zhou, Yulian Wu, Francesco Orabona

+ [Shared Path: Unraveling Memorization in Multilingual LLMs through Language Similarities](https://arxiv.org//abs/2505.15722)

	Xiaoyu Luo, Yiyi Chen, Johannes Bjerva, Qiongxiu Li

+ [DEBATE, TRAIN, EVOLVE: Self Evolution of Language Model Reasoning](https://arxiv.org//abs/2505.15734)

	Gaurav Srivastava, Zhenyu Bi, Meng Lu, Xuan Wang

+ [Alignment Under Pressure: The Case for Informed Adversaries When Evaluating LLM Defenses](https://arxiv.org//abs/2505.15738)

	Xiaoxue Yang, Bozhidar Stevanoski, Matthieu Meeus, Yves-Alexandre de Montjoye

+ [HybridProver: Augmenting Theorem Proving with LLM-Driven Proof Synthesis and Refinement](https://arxiv.org//abs/2505.15740)

	Jilin Hu, Jianyu Zhang, Yongwang Zhao, Talia Ringer

+ [Scalable Defense against In-the-wild Jailbreaking Attacks with Safety Context Retrieval](https://arxiv.org//abs/2505.15753)

	Taiye Chen, Zeming Wei, Ang Li, Yisen Wang

+ [Soft Thinking: Unlocking the Reasoning Potential of LLMs in Continuous Concept Space](https://arxiv.org//abs/2505.15778)

	Zhen Zhang, Xuehai He, Weixiang Yan, Ao Shen, Chenyang Zhao, Shuohang Wang, Yelong Shen, Xin Eric Wang

+ [Large Language Models as Computable Approximations to Solomonoff Induction](https://arxiv.org//abs/2505.15784)

	Jun Wan, Lingrui Mei

+ [Long-Form Information Alignment Evaluation Beyond Atomic Facts](https://arxiv.org//abs/2505.15792)

	Danna Zheng, Mirella Lapata, Jeff Z. Pan

+ [VerifyBench: Benchmarking Reference-based Reward Systems for Large Language Models](https://arxiv.org//abs/2505.15801)

	Yuchen Yan, Jin Jiang, Zhenbang Ren, Yijun Li, Xudong Cai, Yang Liu, Xin Xu, Mengdi Zhang, Jian Shao, Yongliang Shen, Jun Xiao, Yueting Zhuang

+ [Language Specific Knowledge: Do Models Know Better in X than in English?](https://arxiv.org//abs/2505.14990)

	Ishika Agarwal, Nimet Beyza Bozdag, Dilek Hakkani-Tür

+ [Effective and Efficient Schema-aware Information Extraction Using On-Device Large Language Models](https://arxiv.org//abs/2505.14992)

	Zhihao Wen, Sheng Liang, Yaxiong Wu, Yongyue Zhang, Yong Liu

+ [Diagnosing our datasets: How does my language model learn clinical information?](https://arxiv.org//abs/2505.15024)

	Furong Jia, David Sontag, Monica Agrawal

+ [Improving the fact-checking performance of language models by relying on their entailment ability](https://arxiv.org//abs/2505.15050)

	Gaurav Kumar, Debajyoti Mazumder, Ayush Garg, Jasabanta Patro

+ [Lost in Benchmarks? Rethinking Large Language Model Benchmarking with Item Response Theory](https://arxiv.org//abs/2505.15055)

	Hongli Zhou, Hui Huang, Ziqing Zhao, Lvyuan Han, Huicheng Wang, Kehai Chen, Muyun Yang, Wei Bao, Jian Dong, Bing Xu, Conghui Zhu, Hailong Cao, Tiejun Zhao

+ [UrduFactCheck: An Agentic Fact-Checking Framework for Urdu with Evidence Boosting and Benchmarking](https://arxiv.org//abs/2505.15063)

	Sarfraz Ahmad, Hasan Iqbal, Momina Ahsan, Numaan Naeem, Muhammad Ahsan Riaz Khan, Arham Riaz, Muhammad Arslan Manzoor, Yuxia Wang, Preslav Nakov

+ [Can Large Language Models Understand Internet Buzzwords Through User-Generated Content](https://arxiv.org//abs/2505.15071)

	Chen Huang, Junkai Luo, Xinzuo Wang, Wenqiang Lei, Jiancheng Lv

+ [SciCUEval: A Comprehensive Dataset for Evaluating Scientific Context Understanding in Large Language Models](https://arxiv.org//abs/2505.15094)

	Jing Yu, Yuqi Tang, Kehua Feng, Mingyang Rao, Lei Liang, Zhiqiang Zhang, Mengshu Sun, Wen Zhang, Qiang Zhang, Keyan Ding, Huajun Chen

+ [RoT: Enhancing Table Reasoning with Iterative Row-Wise Traversals](https://arxiv.org//abs/2505.15110)

	Xuanliang Zhang, Dingzirui Wang, Keyan Xu, Qingfu Zhu, Wanxiang Che

+ [DUSK: Do Not Unlearn Shared Knowledge](https://arxiv.org//abs/2505.15209)

	Wonje Jeung, Sangyeon Yoon, Hyesoo Hong, Soeun Kim, Seungju Han, Youngjae Yu, Albert No

+ [Deliberation on Priors: Trustworthy Reasoning of Large Language Models on Knowledge Graphs](https://arxiv.org//abs/2505.15210)

	Jie Ma, Ning Qu, Zhitao Gao, Rui Xing, Jun Liu, Hongbin Pei, Jiang Xie, Linyun Song, Pinghui Wang, Jing Tao, Zhou Su

+ [R-TOFU: Unlearning in Large Reasoning Models](https://arxiv.org//abs/2505.15214)

	Sangyeon Yoon, Wonje Jeung, Albert No

+ [Fooling the LVLM Judges: Visual Biases in LVLM-Based Evaluation](https://arxiv.org//abs/2505.15249)

	Yerin Hwang, Dongryeol Lee, Kyungmin Min, Taegwan Kang, Yong-il Kim, Kyomin Jung

+ [MentalMAC: Enhancing Large Language Models for Detecting Mental Manipulation via Multi-Task Anti-Curriculum Distillation](https://arxiv.org//abs/2505.15255)

	Yuansheng Gao, Han Bao, Tong Zhang, Bin Li, Zonghui Wang, Wenzhi Chen

+ [When Less Language is More: Language-Reasoning Disentanglement Makes LLMs Better Multilingual Reasoners](https://arxiv.org//abs/2505.15257)

	Weixiang Zhao, Jiahe Guo, Yang Deng, Tongtong Wu, Wenxuan Zhang, Yulin Hu, Xingyu Sui, Yanyan Zhao, Wanxiang Che, Bing Qin, Tat-Seng Chua, Ting Liu

+ [AGENT-X: Adaptive Guideline-based Expert Network for Threshold-free AI-generated teXt detection](https://arxiv.org//abs/2505.15261)

	Jiatao Li, Mao Ye, Cheng Peng, Xunjian Yin, Xiaojun Wan

+ [Web-Shepherd: Advancing PRMs for Reinforcing Web Agents](https://arxiv.org//abs/2505.15277)

	Hyungjoo Chae, Sunghwan Kim, Junhee Cho, Seungone Kim, Seungjun Moon, Gyeom Hwangbo, Dongha Lim, Minjin Kim, Yeonjun Hwang, Minju Gwak, Dongwook Choi, Minseok Kang, Gwanhoon Im, ByeongUng Cho, Hyojun Kim, Jun Hee Han, Taeyoon Kwon, Minju Kim, Beong-woo Kwak, Dongjin Kang, Jinyoung Yeo

+ [Hallucinate at the Last in Long Response Generation: A Case Study on Long Document Summarization](https://arxiv.org//abs/2505.15291)

	Joonho Yang, Seunghyun Yoon, Hwan Chang, Byeongjeong Kim, Hwanhee Lee

+ [Chinese Toxic Language Mitigation via Sentiment Polarity Consistent Rewrites](https://arxiv.org//abs/2505.15297)

	Xintong Wang, Yixiao Liu, Jingheng Pan, Liang Ding, Longyue Wang, Chris Biemann

+ [Improving LLM First-Token Predictions in Multiple-Choice Question Answering via Prefilling Attack](https://arxiv.org//abs/2505.15323)

	Silvia Cappelletti, Tobia Poppi, Samuele Poppi, Zheng-Xin Yong, Diego Garcia-Olano, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara

+ [FlowKV: Enhancing Multi-Turn Conversational Coherence in LLMs via Isolated Key-Value Cache Management](https://arxiv.org//abs/2505.15347)

	Xiang Liu, Hong Chen, Xuming Hu, Xiaowen Chu

+ [Revealing Language Model Trajectories via Kullback-Leibler Divergence](https://arxiv.org//abs/2505.15353)

	Ryo Kishino, Yusuke Takase, Momose Oyama, Hiroaki Yamagiwa, Hidetoshi Shimodaira

+ [NL-Debugging: Exploiting Natural Language as an Intermediate Representation for Code Debugging](https://arxiv.org//abs/2505.15356)

	Weiming Zhang, Qingyao Li, Xinyi Dai, Jizheng Chen, Kounianhua Du, Weinan Zhang, Weiwen Liu, Yasheng Wang, Ruiming Tang, Yong Yu

+ [X-WebAgentBench: A Multilingual Interactive Web Benchmark for Evaluating Global Agentic System](https://arxiv.org//abs/2505.15372)

	Peng Wang, Ruihan Tao, Qiguang Chen, Mengkang Hu, Libo Qin

+ [An Empirical Study of the Anchoring Effect in LLMs: Existence, Mechanism, and Potential Mitigations](https://arxiv.org//abs/2505.15392)

	Yiming Huang, Biquan Bie, Zuqiu Na, Weilin Ruan, Songxin Lei, Yutao Yue, Xinlei He

+ [How Should We Enhance the Safety of Large Reasoning Models: An Empirical Study](https://arxiv.org//abs/2505.15404)

	Zhexin Zhang, Xian Qi Loye, Victor Shea-Jay Huang, Junxiao Yang, Qi Zhu, Shiyao Cui, Fei Mi, Lifeng Shang, Yingkang Wang, Hongning Wang, Minlie Huang

+ [Gated Integration of Low-Rank Adaptation for Continual Learning of Language Models](https://arxiv.org//abs/2505.15424)

	Yan-Shuo Liang, Wu-Jun Li

+ [Likelihood Variance as Text Importance for Resampling Texts to Map Language Models](https://arxiv.org//abs/2505.15428)

	Momose Oyama, Ryo Kishino, Hiroaki Yamagiwa, Hidetoshi Shimodaira

+ [Hunyuan-TurboS: Advancing Large Language Models through Mamba-Transformer Synergy and Adaptive Chain-of-Thought](https://arxiv.org//abs/2505.15431)

	Ao Liu, Botong Zhou, Can Xu, Chayse Zhou, ChenChen Zhang, Chengcheng Xu, Chenhao Wang, Decheng Wu, Dengpeng Wu, Dian Jiao, Dong Du, Dong Wang, Feng Zhang, Fengzong Lian, Guanghui Xu, Guanwei Zhang, Hai Wang, Haipeng Luo, Han Hu, Huilin Xu, Jiajia Wu, Jianchen Zhu, Jianfeng Yan, Jiaqi Zhu, Jihong Zhang, Jinbao Xue, Jun Xia, Junqiang Zheng, Kai Liu, Kai Zhang, Kai Zheng, Kejiao Li, Keyao Wang, Lan Jiang, Lixin Liu, Lulu Wu, Mengyuan Huang, Peijie Yu, Peiqi Wang, Qian Wang, Qianbiao Xiang, Qibin Liu, Qingfeng Sun, Richard Guo, Ruobing Xie, Saiyong Yang, Shaohua Chen, Shihui Hu, Shuai Li, Shuaipeng Li, Shuang Chen, Suncong Zheng, Tao Yang, Tian Zhang, Tinghao Yu, Weidong Han, Weijie Liu, Weijin Zhou, Weikang Wang, Wesleye Chen, Xiao Feng, Xiaoqin Ren, Xingwu Sun, Xiong Kuang, Xuemeng Huang, Xun Cao, Yanfeng Chen, Yang Du, Yang Zhen, Yangyu Tao, Yaping Deng, Yi Shen, Yigeng Hong, Yiqi Chen, Yiqing Huang, Yuchi Deng, Yue Mao, Yulong Wang, Yuyuan Zeng, Zenan Xu, Zhanhui Kang, Zhe Zhao, ZhenXiang Yan, Zheng Fang, Zhichao Hu, Zhongzhi Chen, Zhuoyu Li, Zongwei Li, Alex Yan, Ande Liang, Baitong Liu, Beiping Pan, Bin Xing, Binghong Wu, Bingxin Qu, Bolin Ni, Boyu Wu, Chen Li, Cheng Jiang, Cheng Zhang

+ [On the Generalization vs Fidelity Paradox in Knowledge Distillation](https://arxiv.org//abs/2505.15442)

	Suhas Kamasetty Ramesh, Ayan Sengupta, Tanmoy Chakraborty

+ [AdUE: Improving uncertainty estimation head for LoRA adapters in LLMs](https://arxiv.org//abs/2505.15443)

	Artem Zabolotnyi, Roman Makarov, Mile Mitrovic, Polina Proskura, Oleg Travkin, Roman Alferov, Alexey Zaytsev

+ [Teaching Language Models to Evolve with Users: Dynamic Profile Modeling for Personalized Alignment](https://arxiv.org//abs/2505.15456)

	Weixiang Zhao, Xingyu Sui, Yulin Hu, Jiahe Guo, Haixiao Liu, Biye Li, Yanyan Zhao, Bing Qin, Ting Liu

+ [CoLA: Collaborative Low-Rank Adaptation](https://arxiv.org//abs/2505.15471)

	Yiyun Zhou, Chang Yao, Jingyuan Chen

+ [KaFT: Knowledge-aware Fine-tuning for Boosting LLMs' Domain-specific Question-Answering Performance](https://arxiv.org//abs/2505.15480)

	Qihuang Zhong, Liang Ding, Xiantao Cai, Juhua Liu, Bo Du, Dacheng Tao

+ [Multilingual Test-Time Scaling via Initial Thought Transfer](https://arxiv.org//abs/2505.15508)

	Prasoon Bajpai, Tanmoy Chakraborty

+ [Do RAG Systems Suffer From Positional Bias?](https://arxiv.org//abs/2505.15561)

	Florin Cuconasu, Simone Filice, Guy Horowitz, Yoelle Maarek, Fabrizio Silvestri

+ [Can LLMs $\textit{understand}$ Math? -- Exploring the Pitfalls in Mathematical Reasoning](https://arxiv.org//abs/2505.15623)

	Tiasa Singha Roy, Aditeya Baral, Ayush Rajesh Jhaveri, Yusuf Baig

+ [Feature Extraction and Steering for Enhanced Chain-of-Thought Reasoning in Language Models](https://arxiv.org//abs/2505.15634)

	Zihao Li, Xu Wang, Yuzhe Yang, Ziyu Yao, Haoyi Xiong, Mengnan Du

+ [Be Careful When Fine-tuning On Open-Source LLMs: Your Fine-tuning Data Could Be Secretly Stolen!](https://arxiv.org//abs/2505.15656)

	Zhexin Zhang, Yuhao Sun, Junxiao Yang, Shiyao Cui, Hongning Wang, Minlie Huang

+ [ThinkLess: A Training-Free Inference-Efficient Method for Reducing Reasoning Redundancy](https://arxiv.org//abs/2505.15684)

	Gengyang Li, Yifeng Gao, Yuming Li, Yunfang Wu

+ ["Alexa, can you forget me?" Machine Unlearning Benchmark in Spoken Language Understanding](https://arxiv.org//abs/2505.15700)

	Alkis Koudounas, Claudio Savelli, Flavio Giobergia, Elena Baralis

+ [LyapLock: Bounded Knowledge Preservation in Sequential Large Language Model Editing](https://arxiv.org//abs/2505.15702)

	Peng Wang, Biyu Zhou, Xuehai Tang, Jizhong Han, Songlin Hu

+ [Advancing LLM Safe Alignment with Safety Representation Ranking](https://arxiv.org//abs/2505.15710)

	Tianqi Du, Zeming Wei, Quan Chen, Chenheng Zhang, Yisen Wang

+ [TurnaboutLLM: A Deductive Reasoning Benchmark from Detective Games](https://arxiv.org//abs/2505.15712)

	Yuan Yuan, Muyu He, Muhammad Adil Shahid, Jiani Huang, Ziyang Li, Li Zhang

+ [Beyond Empathy: Integrating Diagnostic and Therapeutic Reasoning with Large Language Models for Mental Health Counseling](https://arxiv.org//abs/2505.15715)

	He Hu, Yucheng Zhou, Juzheng Si, Qianning Wang, Hengheng Zhang, Fuji Ren, Fei Ma, Laizhong Cui

+ [Beyond Hard and Soft: Hybrid Context Compression for Balancing Local and Global Information Retention](https://arxiv.org//abs/2505.15774)

	Huanxuan Liao, Wen Hu, Yao Xu, Shizhu He, Jun Zhao, Kang Liu

+ [dKV-Cache: The Cache for Diffusion Language Models](https://arxiv.org//abs/2505.15781)

	Xinyin Ma, Runpeng Yu, Gongfan Fang, Xinchao Wang

+ [Reverse Engineering Human Preferences with Reinforcement Learning](https://arxiv.org//abs/2505.15795)

	Lisa Alazraki, Tan Yi-Chern, Jon Ander Campos, Maximilian Mozes, Marek Rei, Max Bartolo

+ [Keep Security! Benchmarking Security Policy Preservation in Large Language Model Contexts Against Indirect Attacks in Question Answering](https://arxiv.org//abs/2505.15805)

	Hwan Chang, Yumin Kim, Yonghyun Jun, Hwanhee Lee

+ [The Atlas of In-Context Learning: How Attention Heads Shape In-Context Retrieval Augmentation](https://arxiv.org//abs/2505.15807)

	Patrick Kahardipraja, Reduan Achtibat, Thomas Wiegand, Wojciech Samek, Sebastian Lapuschkin

+ [Learning to Reason via Mixture-of-Thought for Logical Reasoning](https://arxiv.org//abs/2505.15817)

	Tong Zheng, Lichang Chen, Simeng Han, R. Thomas McCoy, Heng Huang

+ [ALN-P3: Unified Language Alignment for Perception, Prediction, and Planning in Autonomous Driving](https://arxiv.org//abs/2505.15158)

	Yunsheng Ma, Burhaneddin Yaman, Xin Ye, Mahmut Yurt, Jingru Luo, Abhirup Mallik, Ziran Wang, Liu Ren

+ [ReGUIDE: Data Efficient GUI Grounding via Spatial Reasoning and Search](https://arxiv.org//abs/2505.15259)

	Hyunseok Lee, Jeonghoon Kim, Beomjun Kim, Jihoon Tack, Chansong Jo, Jaehong Lee, Cheonbok Park, Sookyo In, Jinwoo Shin, Kang Min Yoo

+ [AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving](https://arxiv.org//abs/2505.15298)

	Kangan Qian, Sicong Jiang, Yang Zhong, Ziang Luo, Zilin Huang, Tianze Zhu, Kun Jiang, Mengmeng Yang, Zheng Fu, Jinyu Miao, Yining Shi, He Zhe Lim, Li Liu, Tianbao Zhou, Hongyi Wang, Huang Yu, Yifei Hu, Guang Li, Guang Chen, Hao Ye, Lijun Sun, Diange Yang

+ [AI vs. Human Judgment of Content Moderation: LLM-as-a-Judge and Ethics-Based Response Refusals](https://arxiv.org//abs/2505.15365)

	Stefan Pasch

+ [Visual Thoughts: A Unified Perspective of Understanding Multimodal Chain-of-Thought](https://arxiv.org//abs/2505.15510)

	Zihui Cheng, Qiguang Chen, Xiao Xu, Jiaqi Wang, Weiyun Wang, Hao Fei, Yidong Wang, Alex Jinpeng Wang, Zhi Chen, Wanxiang Che, Libo Qin

+ [Mechanistic Insights into Grokking from the Embedding Layer](https://arxiv.org//abs/2505.15624)

	H.V.AlquBoj, Hilal AlQuabeh, Velibor Bojkovic, Munachiso Nwadike, Kentaro Inui

+ [HDLxGraph: Bridging Large Language Models and HDL Repositories via HDL Graph Databases](https://arxiv.org//abs/2505.15701)

	Pingqing Zheng, Jiayin Qin, Fuqi Zhang, Shang Wu, Yu Cao, Caiwen Ding, Yang (Katie)Zhao

+ [Towards Zero-Shot Differential Morphing Attack Detection with Multimodal Large Language Models](https://arxiv.org//abs/2505.15332)

	Ria Shekhawat, Hailin Li, Raghavendra Ramachandra, Sushma Venkatesh

+ [LENS: Multi-level Evaluation of Multimodal Reasoning with Large Language Models](https://arxiv.org//abs/2505.15616)

	Ruilin Yao, Bo Zhang, Jirui Huang, Xinwei Long, Yifang Zhang, Tianyu Zou, Yufei Wu, Shichao Su, Yifan Xu, Wenxi Zeng, Zhaoyu Yang, Guoyou Li, Shilan Zhang, Zichan Li, Yaxiong Chen, Shengwu Xiong, Peng Xu, Jiajun Zhang, Bowen Zhou, David Clifton, Luc Van Gool

+ [STAR-R1: Spacial TrAnsformation Reasoning by Reinforcing Multimodal LLMs](https://arxiv.org//abs/2505.15804)

	Zongzhao Li, Zongyang Ma, Mingze Li, Songyou Li, Yu Rong, Tingyang Xu, Ziqi Zhang, Deli Zhao, Wenbing Huang

+ [Harnessing Large Language Models Locally: Empirical Results and Implications for AI PC](https://arxiv.org//abs/2505.15030)

	Qingyu Song, Peiyu Liao, Wenqian Zhao, Yiwen Wang, Shoubo Hu, Hui-Ling Zhen, Ning Jiang, Mingxuan Yuan

+ [Cost-aware LLM-based Online Dataset Annotation](https://arxiv.org//abs/2505.15101)

	Eray Can Elumar, Cem Tekin, Osman Yagan

+ [SSR: Speculative Parallel Scaling Reasoning in Test-time](https://arxiv.org//abs/2505.15340)

	Yuanlin Chu, Bo Wang, Xiang Liu, Hong Chen, Aiwei Liu, Xuming Hu

+ [Short-Range Dependency Effects on Transformer Instability and a Decomposed Attention Solution](https://arxiv.org//abs/2505.15548)

	Suvadeep Hajra

+ [An Efficient Private GPT Never Autoregressively Decodes](https://arxiv.org//abs/2505.15252)

	Zhengyi Li, Yue Guan, Kang Yang, Yu Feng, Ning Liu, Yu Yu, Jingwen Leng, Minyi Guo

+ [Causal LLM Routing: End-to-End Regret Minimization from Observational Data](https://arxiv.org//abs/2505.16037)

	Asterios Tsiourvas, Wei Sun, Georgia Perakis

+ [How Memory Management Impacts LLM Agents: An Empirical Study of Experience-Following Behavior](https://arxiv.org//abs/2505.16067)

	Zidi Xiong, Yuping Lin, Wenya Xie, Pengfei He, Jiliang Tang, Himabindu Lakkaraju, Zhen Xiang

+ [GRIT: Teaching MLLMs to Think with Images](https://arxiv.org//abs/2505.15879)

	Yue Fan, Xuehai He, Diji Yang, Kaizhi Zheng, Ching-Chen Kuo, Yuting Zheng, Sravana Jyothi Narayanaraju, Xinze Guan, Xin Eric Wang

+ [Extracting Probabilistic Knowledge from Large Language Models for Bayesian Network Parameterization](https://arxiv.org//abs/2505.15918)

	Aliakbar Nafar, Kristen Brent Venable, Zijun Cui, Parisa Kordjamshidi

+ [Pre-training Large Memory Language Models with Internal and External Knowledge](https://arxiv.org//abs/2505.15962)

	Linxi Zhao, Sofian Zalouk, Christian K. Belardi, Justin Lovelace, Jin Peng Zhou, Kilian Q. Weinberger, Yoav Artzi, Jennifer J. Sun

+ [Causal Interventions Reveal Shared Structure Across English Filler-Gap Constructions](https://arxiv.org//abs/2505.16002)

	Sasha Boguraev, Christopher Potts, Kyle Mahowald

+ [SLMEval: Entropy-Based Calibration for Human-Aligned Evaluation of Large Language Models](https://arxiv.org//abs/2505.16003)

	Roland Daynauth, Christopher Clarke, Krisztian Flautner, Lingjia Tang, Jason Mars

+ [Interpretability Illusions with Sparse Autoencoders: Evaluating Robustness of Concept Representations](https://arxiv.org//abs/2505.16004)

	Aaron J. Li, Suraj Srinivas, Usha Bhalla, Himabindu Lakkaraju

+ [LAGO: Few-shot Crosslingual Embedding Inversion Attacks via Language Similarity-Aware Graph Optimization](https://arxiv.org//abs/2505.16008)

	Wenrui Yu, Yiyi Chen, Johannes Bjerva, Sokol Kosta, Qiongxiu Li

+ [NOVER: Incentive Training for Language Models via Verifier-Free Reinforcement Learning](https://arxiv.org//abs/2505.16022)

	Wei Liu, Siya Qi, Xinyu Wang, Chen Qian, Yali Du, Yulan He

+ [Not All Models Suit Expert Offloading: On Local Routing Consistency of Mixture-of-Expert Models](https://arxiv.org//abs/2505.16056)

	Jingcong Liang, Siyuan Wang, Miren Tian, Yitong Li, Duyu Tang, Zhongyu Wei

+ [Merge to Mix: Mixing Datasets via Model Merging](https://arxiv.org//abs/2505.16066)

	Zhixu Silvia Tao, Kasper Vinken, Hao-Wei Yeh, Avi Cooper, Xavier Boix

+ [ThinkRec: Thinking-based recommendation via LLM](https://arxiv.org//abs/2505.15091)

	Qihang Yu, Kairui Fu, Shengyu Zhang, Zheqi Lv, Fan Wu, Fei Wu

+ [Aligning Dialogue Agents with Global Feedback via Large Language Model Reward Decomposition](https://arxiv.org//abs/2505.15922)

	Dong Won Lee, Hae Won Park, Cynthia Breazeal, Louis-Philippe Morency

+ [Training Step-Level Reasoning Verifiers with Formal Verification Tools](https://arxiv.org//abs/2505.15960)

	Ryo Kamoi, Yusen Zhang, Nan Zhang, Sarkar Snigdha Sarathi Das, Rui Zhang

+ [Ranking Free RAG: Replacing Re-ranking with Selection in RAG for Sensitive Domains](https://arxiv.org//abs/2505.16014)

	Yash Saxena, Anpur Padia, Mandar S Chaudhary, Kalpa Gunaratna, Srinivasan Parthasarathy, Manas Gaur

+ [Prototypical Human-AI Collaboration Behaviors from LLM-Assisted Writing in the Wild](https://arxiv.org//abs/2505.16023)

	Sheshera Mysore, Debarati Das, Hancheng Cao, Bahareh Sarrafzadeh

+ [InfoDeepSeek: Benchmarking Agentic Information Seeking for Retrieval-Augmented Generation](https://arxiv.org//abs/2505.15872)

	Yunjia Xi, Jianghao Lin, Menghui Zhu, Yongzhao Xiao, Zhuoying Ou, Jiaqi Liu, Tong Wan, Bo Chen, Weiwen Liu, Yasheng Wang, Ruiming Tang, Weinan Zhang, Yong Yu

+ [ViQAgent: Zero-Shot Video Question Answering via Agent with Open-Vocabulary Grounding Validation](https://arxiv.org//abs/2505.15928)

	Tony Montes, Fernando Lozano

+ [MAPS: A Multilingual Benchmark for Global Agent Performance and Security](https://arxiv.org//abs/2505.15935)

	Omer Hofman, Oren Rachmil, Shamik Bose, Vikas Pahuja, Jonathan Brokman, Toshiya Shimizu, Trisha Starostina, Kelly Marchisio, Seraphina Goldfarb-Tarrant, Roman Vainshtein

+ [Aug2Search: Enhancing Facebook Marketplace Search with LLM-Generated Synthetic Data Augmentation](https://arxiv.org//abs/2505.16065)

	Ruijie Xi, He Ba, Hao Yuan, Rishu Agrawal, Arul Prakash

+ [How Do Large Vision-Language Models See Text in Image? Unveiling the Distinctive Role of OCR Heads](https://arxiv.org//abs/2505.15865)

	Ingeol Baek, Hwan Chang, Sunghyun Ryu, Hwanhee Lee

+ [Decouple and Orthogonalize: A Data-Free Framework for LoRA Merging](https://arxiv.org//abs/2505.15875)

	Shenghe Zheng, Hongzhi Wang, Chenyu Huang, Xiaohui Wang, Tao Chen, Jiayuan Fan, Shuyue Hu, Peng Ye

+ [Is (Selective) Round-To-Nearest Quantization All You Need?](https://arxiv.org//abs/2505.15909)

	Alex Kogan

+ [CoT Information: Improved Sample Complexity under Chain-of-Thought Supervision](https://arxiv.org//abs/2505.15927)

	Awni Altabaa, Omar Montasser, John Lafferty

+ [CRAKEN: Cybersecurity LLM Agent with Knowledge-Based Execution](https://arxiv.org//abs/2505.17107)

	Minghao Shao, Haoran Xi, Nanda Rani, Meet Udeshi, Venkata Sai Charan Putrevu, Kimberly Milner, Brendan Dolan-Gavitt, Sandeep Kumar Shukla, Prashanth Krishnamurthy, Farshad Khorrami, Ramesh Karri, Muhammad Shafique

+ [Swarm Intelligence Enhanced Reasoning: A Density-Driven Framework for LLM-Based Multi-Agent Optimization](https://arxiv.org//abs/2505.17115)

	Ying Zhu, Heng Zhou, Rui Su, Peiqin Zhuang, Lei Bai

+ [From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning](https://arxiv.org//abs/2505.17117)

	Chen Shani, Dan Jurafsky, Yann LeCun, Ravid Shwartz-Ziv

+ [NEXT-EVAL: Next Evaluation of Traditional and LLM Web Data Record Extraction](https://arxiv.org//abs/2505.17125)

	Soyeon Kim, Namhee Kim, Yeonwoo Jeong

+ [Are LLMs reliable? An exploration of the reliability of large language models in clinical note generation](https://arxiv.org//abs/2505.17095)

	Kristine Ann M. Carandang, Jasper Meynard P. Araña, Ethan Robert A. Casin, Christopher P. Monterola, Daniel Stanley Y. Tan, Jesus Felix B. Valenzuela, Christian M. Alis

+ [TACO: Enhancing Multimodal In-context Learning via Task Mapping-Guided Sequence Configuration](https://arxiv.org//abs/2505.17098)

	Yanshu Li, Tian Yun, Jianjiang Yang, Pinyuan Feng, Jinfa Huang, Ruixiang Tang

+ [Any Large Language Model Can Be a Reliable Judge: Debiasing with a Reasoning-based Bias Detector](https://arxiv.org//abs/2505.17100)

	Haoyan Yang, Runxue Bao, Cao Xiao, Jun Ma, Parminder Bhatia, Shangqian Gao, Taha Kass-Hout

+ [An approach to identify the most semantically informative deep representations of text and images](https://arxiv.org//abs/2505.17101)

	Santiago Acevedo, Andrea Mascaretti, Riccardo Rende, Matéo Mahaut, Marco Baroni, Alessandro Laio

+ [RRTL: Red Teaming Reasoning Large Language Models in Tool Learning](https://arxiv.org//abs/2505.17106)

	Yifei Liu, Yu Cui, Haibin Zhang

+ [Multi-Modality Expansion and Retention for LLMs through Parameter Merging and Decoupling](https://arxiv.org//abs/2505.17110)

	Junlin Li, Guodong DU, Jing Li, Sim Kuan Goh, Wenya Wang, Yequan Wang, Fangming Liu, Ho-Kin Tang, Saleh Alharbi, Daojing He, Min Zhang

+ [Cultural Value Alignment in Large Language Models: A Prompt-based Analysis of Schwartz Values in Gemini, ChatGPT, and DeepSeek](https://arxiv.org//abs/2505.17112)

	Robin Segerer

+ [Comparative Evaluation of Prompting and Fine-Tuning for Applying Large Language Models to Grid-Structured Geospatial Data](https://arxiv.org//abs/2505.17116)

	Akash Dhruv, Yangxinyu Xie, Jordan Branham, Tanwi Mallick

+ [After Retrieval, Before Generation: Enhancing the Trustworthiness of Large Language Models in RAG](https://arxiv.org//abs/2505.17118)

	Xinbang Dai, Huikang Hu, Yuncheng Hua, Jiaqi Li, Yongrui Chen, Rihui Jin, Nan Hu, Guilin Qi

+ [Systematic Evaluation of Machine-Generated Reasoning and PHQ-9 Labeling for Depression Detection Using Large Language Models](https://arxiv.org//abs/2505.17119)

	Zongru Shao, Xin Wang, Zhanyang Liu, Chenhan Wang, K.P. Subbalakshmi

+ [Self-Interpretability: LLMs Can Describe Complex Internal Processes that Drive Their Decisions, and Improve with Training](https://arxiv.org//abs/2505.17120)

	Dillon Plunkett, Adam Morris, Keerthi Reddy, Jorge Morales

+ [Shallow Preference Signals: Large Language Model Aligns Even Better with Truncated Data?](https://arxiv.org//abs/2505.17122)

	Xuan Qi, Jiahao Qiu, Xinzhe Juan, Yue Wu, Mengdi Wang

+ [MTR-Bench: A Comprehensive Benchmark for Multi-Turn Reasoning Evaluation](https://arxiv.org//abs/2505.17123)

	Xiaoyuan Li, Keqin Bao, Yubo Ma, Moxin Li, Wenjie Wang, Rui Men, Yichang Zhang, Fuli Feng, Dayiheng Liu, Junyang Lin

+ [Conformal Language Model Reasoning with Coherent Factuality](https://arxiv.org//abs/2505.17126)

	Maxon Rubin-Toles, Maya Gambhir, Keshav Ramji, Aaron Roth, Surbhi Goel

+ [CAMA: Enhancing Multimodal In-Context Learning with Context-Aware Modulated Attention](https://arxiv.org//abs/2505.17097)

	Yanshu Li, JianJiang Yang, Bozheng Li, Ruixiang Tang

+ [Mitigating Cyber Risk in the Age of Open-Weight LLMs: Policy Gaps and Technical Realities](https://arxiv.org//abs/2505.17109)

	Alfonso de Gregorio

+ [Pixels Versus Priors: Controlling Knowledge Priors in Vision-Language Models through Visual Counterfacts](https://arxiv.org//abs/2505.17127)

	Michal Golovanevsky, William Rudman, Michael Lepori, Amir Bar, Ritambhara Singh, Carsten Eickhoff

# 2025-05-20
+ [Multimodal RAG-driven Anomaly Detection and Classification in Laser Powder Bed Fusion using Large Language Models](https://arxiv.org//abs/2505.13828)

	Kiarash Naghavi Khanghah, Zhiling Chen, Lela Romeo, Qian Yang, Rajiv Malhotra, Farhad Imani, Hongyi Xu

+ [Efficient Agent Training for Computer Use](https://arxiv.org//abs/2505.13909)

	Yanheng He, Jiahe Jin, Pengfei Liu

+ [DrugPilot: LLM-based Parameterized Reasoning Agent for Drug Discovery](https://arxiv.org//abs/2505.13940)

	Kun Li, Zhennan Wu, Shoupeng Wang, Wenbin Hu

+ [Visual Instruction Bottleneck Tuning](https://arxiv.org//abs/2505.13946)

	Changdae Oh, Jiatong Li, Shawn Im, Yixuan Li

+ [Divide by Question, Conquer by Agent: SPLIT-RAG with Question-Driven Graph Partitioning](https://arxiv.org//abs/2505.13994)

	Ruiyi Yang, Hao Xue, Imran Razzak, Hakim Hacid, Flora D. Salim

+ [RL of Thoughts: Navigating LLM Reasoning with Inference-time Reinforcement Learning](https://arxiv.org//abs/2505.14140)

	Qianyue Hao, Sibo Li, Jian Yuan, Yong Li

+ [s3: You Don't Need That Much Data to Train a Search Agent via RL](https://arxiv.org//abs/2505.14146)

	Pengcheng Jiang, Xueqiang Xu, Jiacheng Lin, Jinfeng Xiao, Zifeng Wang, Jimeng Sun, Jiawei Han

+ [SHARP: Synthesizing High-quality Aligned Reasoning Problems for Large Reasoning Models Reinforcement Learning](https://arxiv.org//abs/2505.14147)

	Xiong Jun Wu, Zhenduo Zhang, ZuJie Wen, Zhiqiang Zhang, Wang Ren, Lei Shi, Cai Chen, Deng Zhao, Dingnan Jin, Qing Cui, Jun Zhou

+ [MM-Agent: LLM as Agents for Real-world Mathematical Modeling Problem](https://arxiv.org//abs/2505.14148)

	Fan Liu, Zherui Yang, Cancheng Liu, Tianrui Song, Xiaofeng Gao, Hao Liu

+ [DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation](https://arxiv.org//abs/2505.14163)

	He Wang, Alexander Hanbo Li, Yiqun Hu, Sheng Zhang, Hideo Kobayashi, Jiani Zhang, Henry Zhu, Chung-Wei Hang, Patrick Ng

+ [Reinforcement Learning vs. Distillation: Understanding Accuracy and Capability in LLM Reasoning](https://arxiv.org//abs/2505.14216)

	Minwu Kim, Anubhav Shrestha, Safal Shrestha, Aadim Nepal, Keith Ross

+ [EVA: Red-Teaming GUI Agents via Evolving Indirect Prompt Injection](https://arxiv.org//abs/2505.14289)

	Yijie Lu, Tianjie Ju, Manman Zhao, Xinbei Ma, Yuan Guo, ZhuoSheng Zhang

+ [SafetyNet: Detecting Harmful Outputs in LLMs by Modeling and Monitoring Deceptive Behaviors](https://arxiv.org//abs/2505.14300)

	Maheep Chaudhary, Fazl Barez

+ [SCAN: Semantic Document Layout Analysis for Textual and Visual Retrieval-Augmented Generation](https://arxiv.org//abs/2505.14381)

	Yuyang Dong, Nobuhiro Ueda, Krisztián Boros, Daiki Ito, Takuya Sera, Masafumi Oyamada

+ [Beyond the First Error: Process Reward Models for Reflective Mathematical Reasoning](https://arxiv.org//abs/2505.14391)

	Zhaohui Yang, Chenghua He, Xiaowen Shi, Linjing Li, Qiyue Yin, Shihong Deng, Daxin Jiang

+ [Causal Cartographer: From Mapping to Reasoning Over Counterfactual Worlds](https://arxiv.org//abs/2505.14396)

	Gaël Gendron, Jože M. Rožanec, Michael Witbrock, Gillian Dobbie

+ [Unearthing Gems from Stones: Policy Optimization with Negative Sample Augmentation for LLM Reasoning](https://arxiv.org//abs/2505.14403)

	Zhaohui Yang, Shilei Jiang, Chen Hu, Linjing Li, Shihong Deng, Daxin Jiang

+ [PRL: Prompts from Reinforcement Learning](https://arxiv.org//abs/2505.14412)

	Paweł Batorski, Adrian Kosmala, Paul Swoboda

+ [Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach](https://arxiv.org//abs/2505.14479)

	Oren Sultan, Eitan Stern, Dafna Shahaf

+ [Reasoning Models Better Express Their Confidence](https://arxiv.org//abs/2505.14489)

	Dongkeun Yoon, Seungone Kim, Sohee Yang, Sunkyoung Kim, Soyeon Kim, Yongil Kim, Eunbi Choi, Yireun Kim, Minjoon Seo

+ [Guarded Query Routing for Large Language Models](https://arxiv.org//abs/2505.14524)

	Richard Šléher, William Brach, Tibor Sloboda, Kristián Košťál, Lukas Galke

+ [Agent Context Protocols Enhance Collective Inference](https://arxiv.org//abs/2505.14569)

	Devansh Bhardwaj, Arjun Beniwal, Shreyas Chaudhari, Ashwin Kalyan, Tanmay Rajpurohit, Karthik R. Narasimhan, Ameet Deshpande, Vishvak Murahari

+ [Let LLMs Break Free from Overthinking via Self-Braking Tuning](https://arxiv.org//abs/2505.14604)

	Haoran Zhao, Yuchen Yan, Yongliang Shen, Haolei Xu, Wenqi Zhang, Kaitao Song, Jian Shao, Weiming Lu, Jun Xiao, Yueting Zhuang

+ [SATBench: Benchmarking LLMs' Logical Reasoning via Automated Puzzle Generation from SAT Formulas](https://arxiv.org//abs/2505.14615)

	Anjiang Wei, Yuheng Wu, Yingjia Wan, Tarun Suresh, Huanmi Tan, Zhanke Zhou, Sanmi Koyejo, Ke Wang, Alex Aiken

+ [Debating for Better Reasoning: An Unsupervised Multimodal Approach](https://arxiv.org//abs/2505.14627)

	Ashutosh Adhikari, Mirella Lapata

+ [Cost-Augmented Monte Carlo Tree Search for LLM-Assisted Planning](https://arxiv.org//abs/2505.14656)

	Zihao Zhang, Fei Liu

+ [SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment](https://arxiv.org//abs/2505.14667)

	Wonje Jeung, Sangyeon Yoon, Minsuk Kahng, Albert No

+ [ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions](https://arxiv.org//abs/2505.14668)

	Bufang Yang, Lilin Xu, Liekang Zeng, Kaiwei Liu, Siyang Jiang, Wenrui Lu, Hongkai Chen, Xiaofan Jiang, Guoliang Xing, Zhenyu Yan

+ [Two Experts Are All You Need for Steering Thinking: Reinforcing Cognitive Effort in MoE Reasoning Models Without Additional Training](https://arxiv.org//abs/2505.14681)

	Mengru Wang, Xingyu Chen, Yue Wang, Zhiwei He, Jiahao Xu, Tian Liang, Qiuzhi Liu, Yunzhi Yao, Wenxuan Wang, Ruotian Ma, Haitao Mi, Ningyu Zhang, Zhaopeng Tu, Xiaolong Li, Dong Yu

+ [Preference Learning with Lie Detectors can Induce Honesty or Evasion](https://arxiv.org//abs/2505.13787)

	Chris Cundy, Adam Gleave

+ [Interpretable Traces, Unexpected Outcomes: Investigating the Disconnect in Trace-Based Knowledge Distillation](https://arxiv.org//abs/2505.13792)

	Siddhant Bhambri, Upasana Biswas, Subbarao Kambhampati

+ [Structured Agent Distillation for Large Language Model](https://arxiv.org//abs/2505.13820)

	Jun Liu, Zhenglun Kong, Peiyan Dong, Changdi Yang, Tianqi Li, Hao Tang, Geng Yuan, Wei Niu, Wenbin Zhang, Pu Zhao, Xue Lin, Dong Huang, Yanzhi Wang

+ [Do Language Models Use Their Depth Efficiently?](https://arxiv.org//abs/2505.13898)

	Róbert Csordás, Christopher D. Manning, Christopher Potts

+ [APEX: Empowering LLMs with Physics-Based Task Planning for Real-time Insight](https://arxiv.org//abs/2505.13921)

	Wanjing Huang, Weixiang Yan, Zhen Zhang, Ambuj Singh

+ [Memory-Centric Embodied Question Answer](https://arxiv.org//abs/2505.13948)

	Mingliang Zhai, Zhi Gao, Yuwei Wu, Yunde Jia

+ [FlashThink: An Early Exit Method For Efficient Reasoning](https://arxiv.org//abs/2505.13949)

	Guochao Jiang, Guofeng Quan, Zepeng Ding, Ziqin Luo, Dixuan Wang, Zheng Hu

+ [When LLMs meet open-world graph learning: a new perspective for unlabeled data uncertainty](https://arxiv.org//abs/2505.13989)

	Yanzhe Wen, Xunkai Li, Qi Zhang, Zhu Lei, Guang Zeng, Rong-Hua Li, Guoren Wang

+ [Social Sycophancy: A Broader Understanding of LLM Sycophancy](https://arxiv.org//abs/2505.13995)

	Myra Cheng, Sunny Yu, Cinoo Lee, Pranav Khadpe, Lujain Ibrahim, Dan Jurafsky

+ [From Unaligned to Aligned: Scaling Multilingual LLMs with Multi-Way Parallel Corpora](https://arxiv.org//abs/2505.14045)

	Yingli Shen, Wen Lai, Shuo Wang, Kangyang Luo, Alexander Fraser, Maosong Sun

+ [Field Matters: A lightweight LLM-enhanced Method for CTR Prediction](https://arxiv.org//abs/2505.14057)

	Yu Cui, Feng Liu, Jiawei Chen, Xingyu Lou, Changwang Zhang, Jun Wang, Yuegang Sun, Xiaohu Yang, Can Wang

+ [AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models](https://arxiv.org//abs/2505.14103)

	Guangke Chen, Fu Song, Zhe Zhao, Xiaojun Jia, Yang Liu, Yanchen Qiao, Weizhe Zhang

+ [A Personalized Conversational Benchmark: Towards Simulating Personalized Conversations](https://arxiv.org//abs/2505.14106)

	Li Li, Peilin Cai, Ryan A. Rossi, Franck Dernoncourt, Branislav Kveton, Junda Wu, Tong Yu, Linxin Song, Tiankai Yang, Yuehan Qin, Nesreen K. Ahmed, Samyadeep Basu, Subhojyoti Mukherjee, Ruiyi Zhang, Zhengmian Hu, Bo Ni, Yuxiao Zhou, Zichao Wang, Yue Huang, Yu Wang, Xiangliang Zhang, Philip S. Yu, Xiyang Hu, Yue Zhao

+ [DiagnosisArena: Benchmarking Diagnostic Reasoning for Large Language Models](https://arxiv.org//abs/2505.14107)

	Yakun Zhu, Zhongzhen Huang, Linjie Mu, Yutong Huang, Wei Nie, Shaoting Zhang, Pengfei Liu, Xiaofan Zhang

+ [Local Mixtures of Experts: Essentially Free Test-Time Training via Model Merging](https://arxiv.org//abs/2505.14136)

	Ryo Bertolissi, Jonas Hübotter, Ido Hakimi, Andreas Krause

+ [Unify Graph Learning with Text: Unleashing LLM Potentials for Session Search](https://arxiv.org//abs/2505.14156)

	Songhao Wu, Quan Tu, Hong Liu, Jia Xu, Zhongyi Liu, Guannan Zhang, Ran Wang, Xiuying Chen, Rui Yan

+ [Prior Prompt Engineering for Reinforcement Fine-Tuning](https://arxiv.org//abs/2505.14157)

	Pittawat Taveekitworachai, Potsawee Manakul, Sarana Nutanong, Kunat Pipatanakul

+ [Tokenization Constraints in LLMs: A Study of Symbolic and Arithmetic Reasoning Limits](https://arxiv.org//abs/2505.14178)

	Xiang Zhang, Juntai Cao, Jiaqi Wei, Yiwei Xu, Chenyu You

+ [Safety Subspaces are Not Distinct: A Fine-Tuning Case Study](https://arxiv.org//abs/2505.14185)

	Kaustubh Ponkshe, Shaan Shah, Raghav Singhal, Praneeth Vepakomma

+ [Automatic Dataset Generation for Knowledge Intensive Question Answering Tasks](https://arxiv.org//abs/2505.14212)

	Sizhe Yuen, Ting Su, Ziyang Wang, Yali Du, Adam J. Sobey

+ ["Haet Bhasha aur Diskrimineshun": Phonetic Perturbations in Code-Mixed Hinglish to Red-Team LLMs](https://arxiv.org//abs/2505.14226)

	Darpan Aswal, Siddharth D Jaiswal

+ [Mechanistic Fine-tuning for In-context Learning](https://arxiv.org//abs/2505.14233)

	Hakaze Cho, Peng Luo, Mariko Kato, Rin Kaenbyou, Naoya Inoue

+ [ABBA: Highly Expressive Hadamard Product Adaptation for Large Language Models](https://arxiv.org//abs/2505.14238)

	Raghav Singhal, Kaustubh Ponkshe, Rohit Vartak, Praneeth Vepakomma

+ [Visual Agentic Reinforcement Fine-Tuning](https://arxiv.org//abs/2505.14246)

	Ziyu Liu, Yuhang Zang, Yushan Zou, Zijian Liang, Xiaoyi Dong, Yuhang Cao, Haodong Duan, Dahua Lin, Jiaqi Wang

+ [Think-J: Learning to Think for Generative LLM-as-a-Judge](https://arxiv.org//abs/2505.14268)

	Hui Huang, Yancheng He, Hongli Zhou, Rui Zhang, Wei Liu, Weixun Wang, Wenbo Su, Bo Zheng, Jiaheng Liu

+ [YESciEval: Robust LLM-as-a-Judge for Scientific Question Answering](https://arxiv.org//abs/2505.14279)

	Jennifer D'Souza, Hamed Babaei Giglou, Quentin Münch

+ [Exploring Jailbreak Attacks on LLMs through Intent Concealment and Diversion](https://arxiv.org//abs/2505.14316)

	Tiehan Cui, Yanxu Mao, Peipei Liu, Congying Liu, Datao You

+ [MUG-Eval: A Proxy Evaluation Framework for Multilingual Generation Capabilities in Any Language](https://arxiv.org//abs/2505.14395)

	Seyoung Song, Seogyeong Jeong, Eunsu Kim, Jiho Jin, Dongkwan Kim, Jay Shin, Alice Oh

+ [Log-Augmented Generation: Scaling Test-Time Reasoning with Reusable Computation](https://arxiv.org//abs/2505.14398)

	Peter Baile Chen, Yi Zhang, Dan Roth, Samuel Madden, Jacob Andreas, Michael Cafarella

+ [Neural Incompatibility: The Unbridgeable Gap of Cross-Scale Parametric Knowledge Transfer in Large Language Models](https://arxiv.org//abs/2505.14436)

	Yuqiao Tan, Shizhu He, Kang Liu, Jun Zhao

+ [CtrlDiff: Boosting Large Diffusion Language Models with Dynamic Block Prediction and Controllable Generation](https://arxiv.org//abs/2505.14455)

	Chihan Huang, Hao Tang

+ [Attributional Safety Failures in Large Language Models under Code-Mixed Perturbations](https://arxiv.org//abs/2505.14469)

	Somnath Banerjee, Pratyush Chatterjee, Shanu Kumar, Sayan Layek, Parag Agrawal, Rima Hazra, Animesh Mukherjee

+ [Can Large Language Models Really Recognize Your Name?](https://arxiv.org//abs/2505.14549)

	Dzung Pham, Peter Kairouz, Niloofar Mireshghallah, Eugene Bagdasarian, Chau Minh Pham, Amir Houmansadr

+ [KORGym: A Dynamic Game Platform for LLM Reasoning Evaluation](https://arxiv.org//abs/2505.14552)

	Jiajun Shi, Jian Yang, Jiaheng Liu, Xingyuan Bu, Jiangjie Chen, Junting Zhou, Kaijing Ma, Zhoufutu Wen, Bingli Wang, Yancheng He, Liang Song, Hualei Zhu, Shilong Li, Xingjian Wang, Wei Zhang, Ruibin Yuan, Yifan Yao, Wenjun Yang, Yunli Wang, Siyuan Fang, Siyu Yuan, Qianyu He, Xiangru Tang, Yingshui Tan, Wangchunshu Zhou, Zhaoxiang Zhang, Zhoujun Li, Wenhao Huang, Ge Zhang

+ [Toward Reliable Biomedical Hypothesis Generation: Evaluating Truthfulness and Hallucination in Large Language Models](https://arxiv.org//abs/2505.14599)

	Guangzhi Xiong, Eric Xie, Corey Williams, Myles Kim, Amir Hassan Shariatmadari, Sikun Guo, Stefan Bekiranov, Aidong Zhang

+ [Language Models Optimized to Fool Detectors Still Have a Distinct Style (And How to Change It)](https://arxiv.org//abs/2505.14608)

	Rafael Rivera Soto, Barry Chen, Nicholas Andrews

+ [TinyV: Reducing False Negatives in Verification Improves RL for LLM Reasoning](https://arxiv.org//abs/2505.14625)

	Zhangchen Xu, Yuetai Li, Fengqing Jiang, Bhaskar Ramasubramanian, Luyao Niu, Bill Yuchen Lin, Radha Poovendran

+ [Will AI Tell Lies to Save Sick Children? Litmus-Testing AI Values Prioritization with AIRiskDilemmas](https://arxiv.org//abs/2505.14633)

	Yu Ying Chiu, Zhilin Wang, Sharan Maiya, Yejin Choi, Kyle Fish, Sydney Levine, Evan Hubinger

+ [Beyond Words: Multimodal LLM Knows When to Speak](https://arxiv.org//abs/2505.14654)

	Zikai Liao, Yi Ouyang, Yi-Lun Lee, Chen-Ping Yu, Yi-Hsuan Tsai, Zhaozheng Yin

+ [Mind the Gap: Bridging Thought Leap for Improved Chain-of-Thought Tuning](https://arxiv.org//abs/2505.14684)

	Haolei Xu, Yuchen Yan, Yongliang Shen, Wenqi Zhang, Guiyang Hou, Shengpei Jiang, Kaitao Song, Weiming Lu, Jun Xiao, Yueting Zhuang

+ [Improve Language Model and Brain Alignment via Associative Memory](https://arxiv.org//abs/2505.13844)

	Congchi Yin, Yongpeng Zhang, Xuyun Wen, Piji Li

+ [Reasoning Path Compression: Compressing Generation Trajectories for Efficient LLM Reasoning](https://arxiv.org//abs/2505.13866)

	Jiwon Song, Dongwon Jo, Yulhwa Kim, Jae-Joon Kim

+ [Mapping the Minds of LLMs: A Graph-Based Analysis of Reasoning LLM](https://arxiv.org//abs/2505.13890)

	Zhen Xiong, Yujun Cai, Zhecheng Li, Yiwei Wang

+ [InfiGFusion: Graph-on-Logits Distillation via Efficient Gromov-Wasserstein for Model Fusion](https://arxiv.org//abs/2505.13893)

	Yuanyi Wang, Zhaoyi Yan, Yiming Zhang, Qi Zhou, Yanggan Gu, Fei Wu, Hongxia Yang

+ [Let's Verify Math Questions Step by Step](https://arxiv.org//abs/2505.13903)

	Chengyu Shen, Zhen Hao Wong, Runming He, Hao Liang, Meiyi Qiang, Zimo Meng, Zhengyang Zhao, Bohan Zeng, Zhengzhou Zhu, Bin Cui, Wentao Zhang

+ [Through a Compressed Lens: Investigating the Impact of Quantization on LLM Explainability and Interpretability](https://arxiv.org//abs/2505.13963)

	Qianli Wang, Mingyang Wang, Nils Feldhus, Simon Ostermann, Yuan Cao, Hinrich Schütze, Sebastian Möller, Vera Schmitt

+ [Truth or Twist? Optimal Model Selection for Reliable Label Flipping Evaluation in LLM-based Counterfactuals](https://arxiv.org//abs/2505.13972)

	Qianli Wang, Van Bach Nguyen, Nils Feldhus, Luis Felipe Villa-Arenas, Christin Seifert, Sebastian Möller, Vera Schmitt

+ [DRP: Distilled Reasoning Pruning with Skill-aware Step Decomposition for Efficient Large Reasoning Models](https://arxiv.org//abs/2505.13975)

	Yuxuan Jiang, Dawei Li, Frank Ferraro

+ [The Hallucination Tax of Reinforcement Finetuning](https://arxiv.org//abs/2505.13988)

	Linxin Song, Taiwei Shi, Jieyu Zhao

+ [DecIF: Improving Instruction-Following through Meta-Decomposition](https://arxiv.org//abs/2505.13990)

	Tingfeng Hui, Pengyu Zhu, Bowen Ping, Ling Tang, Yaqi Zhang, Sen Su

+ [Activation-Guided Consensus Merging for Large Language Models](https://arxiv.org//abs/2505.14009)

	Yuxuan Yao, Shuqi Liu, Zehua Liu, Qintong Li, Mingyang Liu, Xiongwei Han, Zhijiang Guo, Han Wu, Linqi Song

+ [AUTOLAW: Enhancing Legal Compliance in Large Language Models via Case Law Generation and Jury-Inspired Deliberation](https://arxiv.org//abs/2505.14015)

	Tai D. Nguyen, Long H. Pham, Jun Sun

+ [Enhancing LLMs via High-Knowledge Data Selection](https://arxiv.org//abs/2505.14070)

	Feiyu Duan, Xuemiao Zhang, Sirui Wang, Haoran Que, Yuqi Liu, Wenge Rong, Xunliang Cai

+ [BAR: A Backward Reasoning based Agent for Complex Minecraft Tasks](https://arxiv.org//abs/2505.14079)

	Weihong Du, Wenrui Liao, Binyu Yan, Hongru Liang, Anthony G. Cohn, Wenqiang Lei

+ [Beyond Chains: Bridging Large Language Models and Knowledge Bases in Complex Question Answering](https://arxiv.org//abs/2505.14099)

	Yihua Zhu, Qianying Liu, Akiko Aizawa, Hidetoshi Shimodaira

+ [MultiHal: Multilingual Dataset for Knowledge-Graph Grounded Evaluation of LLM Hallucinations](https://arxiv.org//abs/2505.14101)

	Ernests Lavrinovics, Russa Biswas, Katja Hose, Johannes Bjerva

+ [Invisible Entropy: Towards Safe and Efficient Low-Entropy LLM Watermarking](https://arxiv.org//abs/2505.14112)

	Tianle Gu, Zongqi Wang, Kexin Huang, Yuanqi Yao, Xiangliang Zhang, Yujiu Yang, Xiuying Chen

+ [Self-Reasoning Language Models: Unfold Hidden Reasoning Chains with Few Reasoning Catalyst](https://arxiv.org//abs/2505.14116)

	Hongru Wang, Deng Cai, Wanjun Zhong, Shijue Huang, Jeff Z. Pan, Zeming Liu, Kam-Fai Wong

+ [Temporal Alignment of Time Sensitive Facts with Activation Engineering](https://arxiv.org//abs/2505.14158)

	Sanjay Govindan, Maurice Pagnucco, Yang Song

+ [The Strawberry Problem: Emergence of Character-level Understanding in Tokenized Language Models](https://arxiv.org//abs/2505.14172)

	Adrian Cosma, Stefan Ruseti, Emilian Radoi, Mihai Dascalu

+ [ThinkSwitcher: When to Think Hard, When to Think Fast](https://arxiv.org//abs/2505.14183)

	Guosheng Liang, Longguang Zhong, Ziyi Yang, Xiaojun Quan

+ [Unraveling Interwoven Roles of Large Language Models in Authorship Privacy: Obfuscation, Mimicking, and Verification](https://arxiv.org//abs/2505.14195)

	Tuc Nguyen, Yifan Hu, Thai Le

+ [Universal Acoustic Adversarial Attacks for Flexible Control of Speech-LLMs](https://arxiv.org//abs/2505.14286)

	Rao Ma, Mengjie Qian, Vyas Raina, Mark Gales, Kate Knill

+ [Studying the Role of Input-Neighbor Overlap in Retrieval-Augmented Language Models Training Efficiency](https://arxiv.org//abs/2505.14309)

	Ehsan Doostmohammadi, Marco Kuhlmann

+ [A MIND for Reasoning: Meta-learning for In-context Deduction](https://arxiv.org//abs/2505.14313)

	Leonardo Bertolazzi, Manuel Vargas Guzmán, Raffaella Bernardi, Maciej Malicki, Jakub Szymanik

+ [QA-prompting: Improving Summarization with Large Language Models using Question-Answering](https://arxiv.org//abs/2505.14347)

	Neelabh Sinha

+ [OSoRA: Output-Dimension and Singular-Value Initialized Low-Rank Adaptation](https://arxiv.org//abs/2505.14350)

	Jialong Han, Si Zhang, Ke Zhang

+ [Dual Decomposition of Weights and Singular Value Low Rank Adaptation](https://arxiv.org//abs/2505.14367)

	Jialong Han, Si Zhang, Ke Zhang

+ [Editing Across Languages: A Survey of Multilingual Knowledge Editing](https://arxiv.org//abs/2505.14393)

	Nadir Durrani, Basel Mousi, Fahim Dalvi

+ [Pierce the Mists, Greet the Sky: Decipher Knowledge Overshadowing via Knowledge Circuit Analysis](https://arxiv.org//abs/2505.14406)

	Haoming Huang, Yibo Yan, Jiahao Huo, Xin Zou, Xinfeng Li, Kun Wang, Xuming Hu

+ [Hidden Ghost Hand: Unveiling Backdoor Vulnerabilities in MLLM-Powered Mobile GUI Agents](https://arxiv.org//abs/2505.14418)

	Pengzhou Cheng, Haowen Hu, Zheng Wu, Zongru Wu, Tianjie Ju, Daizong Ding, Zhuosheng Zhang, Gongshen Liu

+ [Scaling Low-Resource MT via Synthetic Data Generation with LLMs](https://arxiv.org//abs/2505.14423)

	Ona de Gibert, Joseph Attieh, Teemu Vahtola, Mikko Aulamo, Zihao Li, Raúl Vázquez, Tiancheng Hu, Jörg Tiedemann

+ [From Templates to Natural Language: Generalization Challenges in Instruction-Tuned LLMs for Spatial Reasoning](https://arxiv.org//abs/2505.14425)

	Chalamalasetti Kranti, Sherzod Hakimov, David Schlangen

+ [Not All Correct Answers Are Equal: Why Your Distillation Source Matters](https://arxiv.org//abs/2505.14464)

	Xiaoyu Tian, Yunjie Ji, Haotian Wang, Shuaiting Chen, Sitong Zhao, Yiping Peng, Han Zhao, Xiangang Li

+ [Void in Language Models](https://arxiv.org//abs/2505.14467)

	Mani Shemiranifar

+ [MoMoE: Mixture of Moderation Experts Framework for AI-Assisted Online Governance](https://arxiv.org//abs/2505.14483)

	Agam Goyal, Xianyang Zhan, Yilun Chen, Koustuv Saha, Eshwar Chandrasekharan

+ [Internal Chain-of-Thought: Empirical Evidence for Layer-wise Subtask Scheduling in LLMs](https://arxiv.org//abs/2505.14530)

	Zhipeng Yang, Junzhuo Li, Siyu Xia, Xuming Hu

+ [Breaking Bad Tokens: Detoxification of LLMs Using Sparse Autoencoders](https://arxiv.org//abs/2505.14536)

	Agam Goyal, Vedant Rathi, William Yeh, Yian Wang, Yuen Chen, Hari Sundaram

+ [Can Pruning Improve Reasoning? Revisiting Long-CoT Compression with Capability in Mind for Better Reasoning](https://arxiv.org//abs/2505.14582)

	Shangziqi Zhao, Jiahao Yuan, Guisong Yang, Usman Naseem

+ [Context Reasoner: Incentivizing Reasoning Capability for Contextualized Privacy and Safety Compliance via Reinforcement Learning](https://arxiv.org//abs/2505.14585)

	Wenbin Hu, Haoran Li, Huihao Jing, Qi Hu, Ziqian Zeng, Sirui Han, Heli Xu, Tianshu Chu, Peizhao Hu, Yangqiu Song

+ [MCIP: Protecting MCP Safety via Model Contextual Integrity Protocol](https://arxiv.org//abs/2505.14590)

	Huihao Jing, Haoran Li, Wenbin Hu, Qi Hu, Heli Xu, Tianshu Chu, Peizhao Hu, Yangqiu Song

+ [Success is in the Details: Evaluate and Enhance Details Sensitivity of Code LLMs through Counterfactuals](https://arxiv.org//abs/2505.14597)

	Xianzhen Luo, Qingfu Zhu, Zhiming Zhang, Mingzheng Xu, Tianhao Cheng, Yixuan Wang, Zheng Chu, Shijie Xuyang, Zhiyuan Ma, YuanTao Fan, Wanxiang Che

+ [sudoLLM : On Multi-role Alignment of Language Models](https://arxiv.org//abs/2505.14607)

	Soumadeep Saha, Akshay Chaturvedi, Joy Mahapatra, Utpal Garain

+ [Linear Control of Test Awareness Reveals Differential Compliance in Reasoning Models](https://arxiv.org//abs/2505.14617)

	Sahar Abdelnabi, Ahmed Salem

+ [Think Only When You Need with Large Hybrid-Reasoning Models](https://arxiv.org//abs/2505.14631)

	Lingjie Jiang, Xun Wu, Shaohan Huang, Qingxiu Dong, Zewen Chi, Li Dong, Xingxing Zhang, Tengchao Lv, Lei Cui, Furu Wei

+ [General-Reasoner: Advancing LLM Reasoning Across All Domains](https://arxiv.org//abs/2505.14652)

	Xueguang Ma, Qian Liu, Dongfu Jiang, Ge Zhang, Zejun Ma, Wenhu Chen

+ [Reward Reasoning Model](https://arxiv.org//abs/2505.14674)

	Jiaxin Guo, Zewen Chi, Li Dong, Qingxiu Dong, Xun Wu, Shaohan Huang, Furu Wei

+ [UltraEdit: Training-, Subject-, and Memory-Free Lifelong Editing in Large Language Models](https://arxiv.org//abs/2505.14679)

	Xiaojie Gu, Guangxu Chen, Jungang Li, Jia-Chen Gu, Xuming Hu, Kai Zhang

+ [Language Models use Lookbacks to Track Beliefs](https://arxiv.org//abs/2505.14685)

	Nikhil Prakash, Natalie Shapira, Arnab Sen Sharma, Christoph Riedl, Yonatan Belinkov, Tamar Rott Shaham, David Bau, Atticus Geiger

+ [PandaGuard: Systematic Evaluation of LLM Safety in the Era of Jailbreaking Attacks](https://arxiv.org//abs/2505.13862)

	Guobin Shen, Dongcheng Zhao, Linghao Feng, Xiang He, Jihang Wang, Sicheng Shen, Haibo Tong, Yiting Dong, Jindong Li, Xiang Zheng, Yi Zeng

+ [InfiFPO: Implicit Model Fusion via Preference Optimization in Large Language Models](https://arxiv.org//abs/2505.13878)

	Yanggan Gu, Zhaoyi Yan, Yuanyi Wang, Yiming Zhang, Qi Zhou, Fei Wu, Hongxia Yang

+ [Beyond Text: Unveiling Privacy Vulnerabilities in Multi-modal Retrieval-Augmented Generation](https://arxiv.org//abs/2505.13957)

	Jiankun Zhang, Shenglai Zeng, Jie Ren, Tianqi Zheng, Hui Liu, Xianfeng Tang, Hui Liu, Yi Chang

+ [Textual Steering Vectors Can Improve Visual Understanding in Multimodal Large Language Models](https://arxiv.org//abs/2505.14071)

	Woody Haosheng Gan, Deqing Fu, Julian Asilis, Ollie Liu, Dani Yogatama, Vatsal Sharan, Robin Jia, Willie Neiswanger

+ [AAPO: Enhance the Reasoning Capabilities of LLMs with Advantage Momentum](https://arxiv.org//abs/2505.14264)

	Jian Xiong, Jingbo Zhou, Jingyong Ye, Dejing Dou

+ [Scaling Law for Quantization-Aware Training](https://arxiv.org//abs/2505.14302)

	Mengzhao Chen, Chaoyi Zhang, Jing Liu, Yutao Zeng, Zeyue Xue, Zhiheng Liu, Yunshui Li, Jin Ma, Jie Huang, Xun Zhou, Ping Luo

+ [RADAR: Enhancing Radiology Report Generation with Supplementary Knowledge Injection](https://arxiv.org//abs/2505.14318)

	Wenjun Hou, Yi Cheng, Kaishuai Xu, Heng Li, Yan Hu, Wenjie Li, Jiang Liu

+ [Is Your Prompt Safe? Investigating Prompt Injection Attacks Against Open-Source LLMs](https://arxiv.org//abs/2505.14368)

	Jiawen Wang, Pritha Gupta, Ivan Habernal, Eyke Hüllermeier

+ [Rank-K: Test-Time Reasoning for Listwise Reranking](https://arxiv.org//abs/2505.14432)

	Eugene Yang, Andrew Yates, Kathryn Ricci, Orion Weller, Vivek Chari, Benjamin Van Durme, Dawn Lawrie

+ [S2SBench: A Benchmark for Quantifying Intelligence Degradation in Speech-to-Speech Large Language Models](https://arxiv.org//abs/2505.14438)

	Yuanbo Fang, Haoze Sun, Jun Liu, Tao Zhang, Zenan Zhou, Weipeng Chen, Xiaofen Xing, Xiangmin Xu

+ [Enhancing Learned Knowledge in LoRA Adapters Through Efficient Contrastive Decoding on Ascend NPUs](https://arxiv.org//abs/2505.14620)

	Morgan Lindsay Heisler, Linzi Xing, Ge Shi, Hanieh Sadri, Gursimran Singh, Weiwei Zhang, Tao Ye, Ying Xiong, Yong Zhang, Zhenan Fan

+ [Aligning Attention Distribution to Information Flow for Hallucination Mitigation in Large Vision-Language Models](https://arxiv.org//abs/2505.14257)

	Jianfei Zhao, Feng Zhang, Xin Sun, Chong Feng

+ [UniGen: Enhanced Training & Test-Time Strategies for Unified Multimodal Understanding and Generation](https://arxiv.org//abs/2505.14682)

	Rui Tian, Mingfei Gao, Mingze Xu, Jiaming Hu, Jiasen Lu, Zuxuan Wu, Yinfei Yang, Afshin Dehghan

+ [Adversarially Pretrained Transformers may be Universally Robust In-Context Learners](https://arxiv.org//abs/2505.14042)

	Soichiro Kumano, Hiroshi Kera, Toshihiko Yamasaki

+ [Scaling and Enhancing LLM-based AVSR: A Sparse Mixture of Projectors Approach](https://arxiv.org//abs/2505.14336)

	Umberto Cappellazzo, Minsu Kim, Stavros Petridis, Daniele Falavigna, Alessio Brutti

+ [Context-Free Synthetic Data Mitigates Forgetting](https://arxiv.org//abs/2505.13811)

	Parikshit Bansal, Sujay Sanghavi

+ [Fragments to Facts: Partial-Information Fragment Inference from LLMs](https://arxiv.org//abs/2505.13819)

	Lucas Rosenblatt, Bin Han, Robert Wolfe, Bill Howe

+ [MAS-KCL: Knowledge component graph structure learning with large language model-based agentic workflow](https://arxiv.org//abs/2505.14126)

	Yuan-Hao Jiang, Kezong Tang, Zi-Wei Chen, Yuang Wei, Tian-Yi Liu, Jiayi Wu

+ [Towards eliciting latent knowledge from LLMs with mechanistic interpretability](https://arxiv.org//abs/2505.14352)

	Bartosz Cywiński, Emil Ryd, Senthooran Rajamanoharan, Neel Nanda

+ [ServerlessLoRA: Minimizing Latency and Cost in Serverless Inference for LoRA-Based LLMs](https://arxiv.org//abs/2505.14468)

	Yifan Sui, Hao Wang, Hanfei Yu, Yitao Hu, Jianxun Li, Hao Wang

+ [Quartet: Native FP4 Training Can Be Optimal for Large Language Models](https://arxiv.org//abs/2505.14669)

	Roberto L. Castro, Andrei Panferov, Soroush Tabesh, Oliver Sieberling, Jiale Chen, Mahdi Nikdan, Saleh Ashkboos, Dan Alistarh

+ [A Probabilistic Perspective on Model Collapse](https://arxiv.org//abs/2505.13947)

	Shirong Xu, Hengzhi He, Guang Cheng

+ [Vulnerability of Transfer-Learned Neural Networks to Data Reconstruction Attacks in Small-Data Regime](https://arxiv.org//abs/2505.14323)

	Tomasz Maciążek, Robert Allison

+ [Lessons from Defending Gemini Against Indirect Prompt Injections](https://arxiv.org//abs/2505.14534)

	Chongyang Shi, Sharon Lin, Shuang Song, Jamie Hayes, Ilia Shumailov, Itay Yona, Juliette Pluto, Aneesh Pappu, Christopher A. Choquette-Choo, Milad Nasr, Chawin Sitawarin, Gena Gibson, Andreas Terzis, John "Four" Flynn

+ [R&D-Agent: Automating Data-Driven AI Solution Building Through LLM-Powered Automated Research, Development, and Evolution](https://arxiv.org//abs/2505.14738)

	Xu Yang, Xiao Yang, Shikai Fang, Bowen Xian, Yuante Li, Jian Wang, Minrui Xu, Haoran Pan, Xinpeng Hong, Weiqing Liu, Yelong Shen, Weizhu Chen, Jiang Bian

+ [FOL-Pretrain: A complexity annotated corpus of first-order logic](https://arxiv.org//abs/2505.14932)

	Isabelle Lee, Sarah Liaw, Dani Yogatama

+ [Reinforcement Learning from User Feedback](https://arxiv.org//abs/2505.14946)

	Eric Han, Jun Chen, Karthik Abinav Sankararaman, Xiaoliang Peng, Tengyu Xu, Eryk Helenowski, Kaiyan Peng, Mrinal Kumar, Sinong Wang, Han Fang, Arya Talebzadeh

+ [Self-Evolving Curriculum for LLM Reasoning](https://arxiv.org//abs/2505.14970)

	Xiaoyin Chen, Jiarui Lu, Minsu Kim, Dinghuai Zhang, Jian Tang, Alexandre Piché, Nicolas Gontier, Yoshua Bengio, Ehsan Kamalloo

+ [The Energy Cost of Reasoning: Analyzing Energy Usage in LLMs with Test-time Compute](https://arxiv.org//abs/2505.14733)

	Yunho Jin, Gu-Yeon Wei, David Brooks

+ [Quaff: Quantized Parameter-Efficient Fine-Tuning under Outlier Spatial Stability Hypothesis](https://arxiv.org//abs/2505.14742)

	Hong Huang, Dapeng Wu

+ [$\texttt{LLINBO}$: Trustworthy LLM-in-the-Loop Bayesian Optimization](https://arxiv.org//abs/2505.14756)

	Chih-Yu Chang, Milad Azvar, Chinedum Okwudire, Raed Al Kontar

+ [Scaling Reasoning, Losing Control: Evaluating Instruction Following in Large Reasoning Models](https://arxiv.org//abs/2505.14810)

	Tingchen Fu, Jiawei Gu, Yafu Li, Xiaoye Qu, Yu Cheng

+ [WebNovelBench: Placing LLM Novelists on the Web Novel Distribution](https://arxiv.org//abs/2505.14818)

	Leon Lin, Jun Zheng, Haidong Wang

+ [Text Generation Beyond Discrete Token Sampling](https://arxiv.org//abs/2505.14827)

	Yufan Zhuang, Liyuan Liu, Chandan Singh, Jingbo Shang, Jianfeng Gao

+ [Balanced and Elastic End-to-end Training of Dynamic LLMs](https://arxiv.org//abs/2505.14864)

	Mohamed Wahib, Muhammed Abdullah Soyturk, Didem Unat

+ [Polar Sparsity: High Throughput Batched LLM Inferencing with Scalable Contextual Sparsity](https://arxiv.org//abs/2505.14884)

	Susav Shrestha, Brad Settlemyer, Nikoli Dryden, Narasimha Reddy

+ [Scaling Laws for State Dynamics in Large Language Models](https://arxiv.org//abs/2505.14892)

	Jacob X Li, Shreyas S Raman, Jessica Wan, Fahad Samman, Jazlyn Lin

+ [Too Long, Didn't Model: Decomposing LLM Long-Context Understanding With Novels](https://arxiv.org//abs/2505.14925)

	Sil Hamilton, Rebecca M. M. Hicke, Matthew Wilkens, David Mimno

+ [Soft Prompts for Evaluation: Measuring Conditional Distance of Capabilities](https://arxiv.org//abs/2505.14943)

	Ross Nordby

+ [JARVIS: A Multi-Agent Code Assistant for High-Quality EDA Script Generation](https://arxiv.org//abs/2505.14978)

	Ghasem Pasandi, Kishor Kunal, Varun Tej, Kunjal Shan, Hanfei Sun, Sumit Jain, Chunhui Li, Chenhui Deng, Teodor-Dumitru Ene, Haoxing Ren, Sreedhar Pratty

+ [Addressing the Challenges of Planning Language Generation](https://arxiv.org//abs/2505.14763)

	Prabhu Prakash Kagitha, Andrew Zhu, Li Zhang

+ [Language Mixing in Reasoning Language Models: Patterns, Impact, and Internal Causes](https://arxiv.org//abs/2505.14815)

	Mingyang Wang, Lukas Lange, Heike Adel, Yunpu Ma, Jannik Strötgen, Hinrich Schütze

+ [Tracing Multilingual Factual Knowledge Acquisition in Pretraining](https://arxiv.org//abs/2505.14824)

	Yihong Liu, Mingyang Wang, Amir Hossein Kargaran, Felicia Körner, Ercong Nie, Barbara Plank, François Yvon, Hinrich Schütze

+ [SEPS: A Separability Measure for Robust Unlearning in LLMs](https://arxiv.org//abs/2505.14832)

	Wonje Jeung, Sangyeon Yoon, Albert No

+ [MAATS: A Multi-Agent Automated Translation System Based on MQM Evaluation](https://arxiv.org//abs/2505.14848)

	Xi Wang, Jiaqian Hu, Safinah Ali

+ [Saten: Sparse Augmented Tensor Networks for Post-Training Compression of Large Language Models](https://arxiv.org//abs/2505.14871)

	Ryan Solgi, Kai Zhen, Rupak Vignesh Swaminathan, Nathan Susanj, Athanasios Mouchtaris, Siegfried Kunzmann, Zheng Zhang

+ [Incorporating Token Usage into Prompting Strategy Evaluation](https://arxiv.org//abs/2505.14880)

	Chris Sypherd, Sergei Petrov, Sonny George, Vaishak Belle

+ [Strategic Planning and Rationalizing on Trees Make LLMs Better Debaters](https://arxiv.org//abs/2505.14886)

	Danqing Wang, Zhuorui Ye, Xinran Zhao, Fei Fang, Lei Li

+ [Understanding 6G through Language Models: A Case Study on LLM-aided Structured Entity Extraction in Telecom Domain](https://arxiv.org//abs/2505.14906)

	Ye Yuan, Haolun Wu, Hao Zhou, Xue Liu, Hao Chen, Yan Xin, Jianzhong (Charlie)Zhang

+ [Reliable Decision Support with LLMs: A Framework for Evaluating Consistency in Binary Text Classification Applications](https://arxiv.org//abs/2505.14918)

	Fadel M. Megahed, Ying-Ju Chen, L. Allision Jones-Farmer, Younghwa Lee, Jiawei Brooke Wang, Inez M. Zwetsloot

+ [MedBrowseComp: Benchmarking Medical Deep Research and Computer Use](https://arxiv.org//abs/2505.14963)

	Shan Chen, Pedro Moreira, Yuxin Xiao, Sam Schmidgall, Jeremy Warner, Hugo Aerts, Thomas Hartvigsen, Jack Gallifant, Danielle S. Bitterman

+ [DECASTE: Unveiling Caste Stereotypes in Large Language Models through Multi-Dimensional Bias Analysis](https://arxiv.org//abs/2505.14971)

	Prashanth Vijayaraghavan, Soroush Vosoughi, Lamogha Chizor, Raya Horesh, Rogerio Abreu de Paula, Ehsan Degan, Vandana Mukherjee

+ [FisherSFT: Data-Efficient Supervised Fine-Tuning of Language Models Using Information Gain](https://arxiv.org//abs/2505.14826)

	Rohan Deb, Kiran Thekumparampil, Kousha Kalantari, Gaurush Hiranandani, Shoham Sabach, Branislav Kveton

+ [Think, Reflect, Create: Metacognitive Learning for Zero-Shot Robotic Planning with LLMs](https://arxiv.org//abs/2505.14899)

	Wenjie Lin, Jin Wei-Kocsis

+ [The Evolution of Alpha in Finance Harnessing Human Insight and LLM Agents](https://arxiv.org//abs/2505.14727)

	Mohammad Rubyet Islam

+ [Large Language Models for Data Synthesis](https://arxiv.org//abs/2505.14752)

	Yihong Tang, Menglin Kong, Lijun Sun

+ [Foundations of Unknown-aware Machine Learning](https://arxiv.org//abs/2505.14933)

	Xuefeng Du

+ [LEANCODE: Understanding Models Better for Code Simplification of Pre-trained Large Language Models](https://arxiv.org//abs/2505.14759)

	Yan Wang, Ling Ding, Tien N Nguyen, Shaohua Wang, Yanan Zheng

+ [Mechanistic Interpretability of GPT-like Models on Summarization Tasks](https://arxiv.org//abs/2505.17073)

	Anurag Mishra

+ [Semi-Clairvoyant Scheduling of Speculative Decoding Requests to Minimize LLM Inference Latency](https://arxiv.org//abs/2505.17074)

	Ruixiao Li, Fahao Chen, Peng Li

+ [GloSS over Toxicity: Understanding and Mitigating Toxicity in LLMs via Global Toxic Subspace](https://arxiv.org//abs/2505.17078)

	Zenghao Duan, Zhiyi Yin, Zhichao Shi, Liang Pang, Shaoling Jing, Jiayi Wu, Yu Yan, Huawei Shen, Xueqi Cheng

+ [From nuclear safety to LLM security: Applying non-probabilistic risk management strategies to build safe and secure LLM-powered systems](https://arxiv.org//abs/2505.17084)

	Alexander Gutfraind, Vicki Bier

+ [Large Language Models Implicitly Learn to See and Hear Just By Reading](https://arxiv.org//abs/2505.17091)

	Prateek Verma, Mert Pilanci

+ [Scale-invariant Attention](https://arxiv.org//abs/2505.17083)

	Ben Anson, Xi Wang, Laurence Aitchison

+ [Reinforcing Question Answering Agents with Minimalist Policy Gradient Optimization](https://arxiv.org//abs/2505.17086)

	Yihong Wu, Liheng Ma, Muzhi Li, Jiaming Zhou, Jianye Hao, Ho-fung Leung, Irwin King, Yingxue Zhang, Jian-Yun Nie

+ [Trust Me, I Can Handle It: Self-Generated Adversarial Scenario Extrapolation for Robust Language Models](https://arxiv.org//abs/2505.17089)

	Md Rafi Ur Rashid, Vishnu Asutosh Dasu, Ye Wang, Gang Tan, Shagufta Mehnaz

# 2025-05-19
+ [Bullying the Machine: How Personas Increase LLM Vulnerability](https://arxiv.org//abs/2505.12692)

	Ziwei Xu, Udit Sanghi, Mohan Kankanhalli

+ [Accelerating Adaptive Retrieval Augmented Generation via Instruction-Driven Representation Reduction of Retrieval Overlaps](https://arxiv.org//abs/2505.12731)

	Jie Ou, Jinyu Guo, Shuaihong Jiang, Zhaokun Wang, Libo Qin, Shunyu Yao, Wenhong Tian

+ [Dense Communication between Language Models](https://arxiv.org//abs/2505.12741)

	Shiguang Wu, Yaqing Wang, Quanming Yao

+ [IDEAL: Data Equilibrium Adaptation for Multi-Capability Language Model Alignment](https://arxiv.org//abs/2505.12762)

	Chenlin Ming, Chendi Qu, Mengzhang Cai, Qizhi Pei, Zhuoshi Pan, Yu Li, Xiaoming Duan, Lijun Wu, Conghui He

+ [Language Models That Walk the Talk: A Framework for Formal Fairness Certificates](https://arxiv.org//abs/2505.12767)

	Danqing Chen, Tobias Ladner, Ahmed Rayen Mhadhbi, Matthias Althoff

+ [FRAbench and GenEval: Scaling Fine-Grained Aspect Evaluation across Tasks, Modalities](https://arxiv.org//abs/2505.12795)

	Shibo Hong, Jiahao Ying, Haiyuan Liang, Mengdi Zhang, Jun Kuang, Jiazheng Zhang, Yixin Cao

+ [Emergent Specialization: Rare Token Neurons in Language Models](https://arxiv.org//abs/2505.12822)

	Jing Liu, Haozheng Wang, Yueheng Li

+ [Reasoning BO: Enhancing Bayesian Optimization with Long-Context Reasoning Power of LLMs](https://arxiv.org//abs/2505.12833)

	Zhuo Yang, Lingli Ge, Dong Han, Tianfan Fu, Yuqiang Li

+ [Multi-Level Aware Preference Learning: Enhancing RLHF for Complex Multi-Instruction Tasks](https://arxiv.org//abs/2505.12845)

	Ruopei Sun, Jianfeng Cai, Jinhua Zhu, Kangwen Zhao, Dongyun Xue, Wengang Zhou, Li Li, Houqiang Li

+ [Detection and Mitigation of Hallucination in Large Reasoning Models: A Mechanistic Perspective](https://arxiv.org//abs/2505.12886)

	Zhongxiang Sun, Qipeng Wang, Haoyu Wang, Xiao Zhang, Jun Xu

+ [TIME: A Multi-level Benchmark for Temporal Reasoning of LLMs in Real-World Scenarios](https://arxiv.org//abs/2505.12891)

	Shaohang Wei, Wei Li, Feifan Song, Wen Luo, Tianyi Zhuang, Haochen Tan, Zhijiang Guo, Houfeng Wang

+ [The Traitors: Deception and Trust in Multi-Agent Language Model Simulations](https://arxiv.org//abs/2505.12923)

	Pedro M. P. Curvo

+ [CAIM: Development and Evaluation of a Cognitive AI Memory Framework for Long-Term Interaction with Intelligent Agents](https://arxiv.org//abs/2505.13044)

	Rebecca Westhäußer, Frederik Berenz, Wolfgang Minker, Sebastian Zepf

+ [LLM-KG-Bench 3.0: A Compass for SemanticTechnology Capabilities in the Ocean of LLMs](https://arxiv.org//abs/2505.13098)

	Lars-Peter Meyer, Johannes Frey, Desiree Heim, Felix Brei, Claus Stadler, Kurt Junghanns, Michael Martin

+ [Zero-Shot Iterative Formalization and Planning in Partially Observable Environments](https://arxiv.org//abs/2505.13126)

	Liancheng Gong, Wang Zhu, Jesse Thomason, Li Zhang

+ [Adversarial Testing in LLMs: Insights into Decision-Making Vulnerabilities](https://arxiv.org//abs/2505.13195)

	Lili Zhang, Haomiaomiao Wang, Long Cheng, Libao Deng, Tomas Ward

+ [Agentic Publications: An LLM-Driven Framework for Interactive Scientific Publishing, Supplementing Traditional Papers with AI-Powered Knowledge Systems](https://arxiv.org//abs/2505.13246)

	Roberto Pugliese, George Kourousias, Francesco Venier, Grazia Garlatti Costa

+ [Multi-Armed Bandits Meet Large Language Models](https://arxiv.org//abs/2505.13355)

	Djallel Bouneffouf, Raphael Feraud

+ [CompeteSMoE -- Statistically Guaranteed Mixture of Experts Training via Competition](https://arxiv.org//abs/2505.13380)

	Nam V. Nguyen, Huy Nguyen, Quang Pham, Van Nguyen, Savitha Ramasamy, Nhat Ho

+ [AutoMathKG: The automated mathematical knowledge graph based on LLM and vector database](https://arxiv.org//abs/2505.13406)

	Rong Bian, Yu Geng, Zijian Yang, Bing Cheng

+ [CoT-Kinetics: A Theoretical Modeling Assessing LRM Reasoning Process](https://arxiv.org//abs/2505.13408)

	Jinhe Bi, Danqi Yan, Yifan Wang, Wenke Huang, Haokun Chen, Guancheng Wan, Mang Ye, Xun Xiao, Hinrich Schuetze, Volker Tresp, Yunpu Ma

+ [MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable Step-Level Supervision](https://arxiv.org//abs/2505.13427)

	Lingxiao Du, Fanqing Meng, Zongkai Liu, Zhixiang Zhou, Ping Luo, Qiaosheng Zhang, Wenqi Shao

+ [Trust, But Verify: A Self-Verification Approach to Reinforcement Learning with Verifiable Rewards](https://arxiv.org//abs/2505.13445)

	Xiaoyuan Liu, Tian Liang, Zhiwei He, Jiahao Xu, Wenxuan Wang, Pinjia He, Zhaopeng Tu, Haitao Mi, Dong Yu

+ [AD-AGENT: A Multi-agent Framework for End-to-end Anomaly Detection](https://arxiv.org//abs/2505.12594)

	Tiankai Yang, Junjun Liu, Wingchun Siu, Jiahang Wang, Zhuangzhuang Qian, Chanjuan Song, Cheng Cheng, Xiyang Hu, Yue Zhao

+ [Web IP at Risk: Prevent Unauthorized Real-Time Retrieval by Large Language Models](https://arxiv.org//abs/2505.12655)

	Yisheng Zhong, Yizhu Wen, Junfeng Guo, Mehran Kafai, Heng Huang, Hanqing Guo, Zhuangdi Zhu

+ [Know3-RAG: A Knowledge-aware RAG Framework with Adaptive Retrieval, Generation, and Filtering](https://arxiv.org//abs/2505.12662)

	Xukai Liu, Ye Liu, Shiwen Wu, Yanghai Zhang, Yihao Yuan, Kai Zhang, Qi Liu

+ [Shadow-FT: Tuning Instruct via Base](https://arxiv.org//abs/2505.12716)

	Taiqiang Wu, Runming Yang, Jiayi Li, Pengfei Hu, Ngai Wong, Yujiu Yang

+ [Rethinking Reward Model Evaluation Through the Lens of Reward Overoptimization](https://arxiv.org//abs/2505.12763)

	Sunghwan Kim, Dongjin Kang, Taeyoon Kwon, Hyungjoo Chae, Dongha Lee, Jinyoung Yeo

+ [A Token is Worth over 1,000 Tokens: Efficient Knowledge Distillation through Low-Rank Clone](https://arxiv.org//abs/2505.12781)

	Jitai Hao, Qiang Huang, Hao Liu, Xinyan Xiao, Zhaochun Ren, Jun Yu

+ [PsyMem: Fine-grained psychological alignment and Explicit Memory Control for Advanced Role-Playing LLMs](https://arxiv.org//abs/2505.12814)

	Xilong Cheng, Yunxiao Qin, Yuting Tan, Zhengnan Li, Ye Wang, Hongjiang Xiao, Yuan Zhang

+ [The Hidden Structure -- Improving Legal Document Understanding Through Explicit Text Formatting](https://arxiv.org//abs/2505.12837)

	Christian Braun, Alexander Lilienbeck, Daniel Mentjukov

+ [Bias Fitting to Mitigate Length Bias of Reward Model in RLHF](https://arxiv.org//abs/2505.12843)

	Kangwen Zhao, Jianfeng Cai, Jinhua Zhu, Ruopei Sun, Dongyun Xue, Wengang Zhou, Li Li, Houqiang Li

+ [LEXam: Benchmarking Legal Reasoning on 340 Law Exams](https://arxiv.org//abs/2505.12864)

	Yu Fan, Jingwei Ni, Jakob Merane, Etienne Salimbeni, Yang Tian, Yoan Hermstrüwer, Yinya Huang, Mubashara Akhtar, Florian Geering, Oliver Dreyer, Daniel Brunner, Markus Leippold, Mrinmaya Sachan, Alexander Stremitzer, Christoph Engel, Elliott Ash, Joel Niklaus

+ [Does Low Rank Adaptation Lead to Lower Robustness against Training-Time Attacks?](https://arxiv.org//abs/2505.12871)

	Zi Liang, Haibo Hu, Qingqing Ye, Yaxin Xiao, Ronghua Li

+ [Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs](https://arxiv.org//abs/2505.12929)

	Zhihe Yang, Xufang Luo, Zilong Wang, Dongqi Han, Zhiyuan He, Dongsheng Li, Yunjian Xu

+ [Leveraging LLM Inconsistency to Boost Pass@k Performance](https://arxiv.org//abs/2505.12938)

	Uri Dalal, Meirav Segal, Zvika Ben-Haim, Dan Lahav, Omer Nevo

+ [A3 : an Analytical Low-Rank Approximation Framework for Attention](https://arxiv.org//abs/2505.12942)

	Jeffrey T. H. Wong, Cheng Zhang, Xinye Cao, Pedro Gimenes, George A. Constantinides, Wayne Luk, Yiren Zhao

+ [DGRO: Enhancing LLM Reasoning via Exploration-Exploitation Control and Reward Variance Management](https://arxiv.org//abs/2505.12951)

	Xuerui Su, Liya Guo, Yue Wang, Yi Zhu, Zhiming Ma, Zun Wang, Yuting Liu

+ [From Assistants to Adversaries: Exploring the Security Risks of Mobile LLM Agents](https://arxiv.org//abs/2505.12981)

	Liangxuan Wu, Chao Wang, Tianming Liu, Yanjie Zhao, Haoyu Wang

+ [Fractured Chain-of-Thought Reasoning](https://arxiv.org//abs/2505.12992)

	Baohao Liao, Hanze Dong, Yuhui Xu, Doyen Sahoo, Christof Monz, Junnan Li, Caiming Xiong

+ [Step-wise Adaptive Integration of Supervised Fine-tuning and Reinforcement Learning for Task-Specific LLMs](https://arxiv.org//abs/2505.13026)

	Jack Chen, Fazhong Liu, Naruto Liu, Yuhan Luo, Erqu Qin, Harry Zheng, Tian Dong, Haojin Zhu, Yan Meng, Xiao Wang

+ [Evaluatiing the efficacy of LLM Safety Solutions : The Palit Benchmark Dataset](https://arxiv.org//abs/2505.13028)

	Sayon Palit, Daniel Woods

+ [KIT's Offline Speech Translation and Instruction Following Submission for IWSLT 2025](https://arxiv.org//abs/2505.13036)

	Sai Koneru, Maike Züfle, Thai-Binh Nguyen, Seymanur Akti, Jan Niehues, Alexander Waibel

+ [The Hidden Dangers of Browsing AI Agents](https://arxiv.org//abs/2505.13076)

	Mykyta Mudryi, Markiyan Chaklosh, Grzegorz Wójcik

+ [FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference](https://arxiv.org//abs/2505.13109)

	Guangda Liu, Chengwei Li, Zhenyu Ning, Jing Lin, Yiwu Yao, Danning Ke, Minyi Guo, Jieru Zhao

+ [Role-Playing Evaluation for Large Language Models](https://arxiv.org//abs/2505.13157)

	Yassine El Boudouri, Walter Nuninger, Julian Alvarez, Yvan Peter

+ [ToolSpectrum : Towards Personalized Tool Utilization for Large Language Models](https://arxiv.org//abs/2505.13176)

	Zihao Cheng, Hongru Wang, Zeming Liu, Yuhang Guo, Yuanfang Guo, Yunhong Wang, Haifeng Wang

+ [WikiPersonas: What Can We Learn From Personalized Alignment to Famous People?](https://arxiv.org//abs/2505.13257)

	Zilu Tang, Afra Feyza Akyürek, Ekin Akyürek, Derry Wijaya

+ [Cross-Cloud Data Privacy Protection: Optimizing Collaborative Mechanisms of AI Systems by Integrating Federated Learning and LLMs](https://arxiv.org//abs/2505.13292)

	Huaiying Luo, Cheng Ji

+ [RBF++: Quantifying and Optimizing Reasoning Boundaries across Measurable and Unmeasurable Capabilities for Chain-of-Thought Reasoning](https://arxiv.org//abs/2505.13307)

	Qiguang Chen, Libo Qin, Jinhao Liu, Yue Liao, Jiaqi Wang, Jingxuan Zhou, Wanxiang Che

+ [Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space](https://arxiv.org//abs/2505.13308)

	Hengli Li, Chenxi Li, Tong Wu, Xuekai Zhu, Yuxuan Wang, Zhaoxin Yu, Eric Hanchen Jiang, Song-Chun Zhu, Zixia Jia, Ying Nian Wu, Zilong Zheng

+ [Contextual Paralinguistic Data Creation for Multi-Modal Speech-LLM: Data Condensation and Spoken QA Generation](https://arxiv.org//abs/2505.13338)

	Qiongqiong Wang, Hardik B. Sailor, Tianchi Liu, Ai Ti Aw

+ [J4R: Learning to Judge with Equivalent Initial State Group Relative Preference Optimization](https://arxiv.org//abs/2505.13346)

	Austin Xu, Yilun Zhou, Xuan-Phi Nguyen, Caiming Xiong, Shafiq Joty

+ [Thinkless: LLM Learns When to Think](https://arxiv.org//abs/2505.13379)

	Gongfan Fang, Xinyin Ma, Xinchao Wang

+ [R3: Robust Rubric-Agnostic Reward Models](https://arxiv.org//abs/2505.13388)

	David Anugraha, Zilu Tang, Lester James V. Miranda, Hanyang Zhao, Mohammad Rifqi Farhansyah, Garry Kuwanto, Derry Wijaya, Genta Indra Winata

+ [AdaptThink: Reasoning Models Can Learn When to Think](https://arxiv.org//abs/2505.13417)

	Jiajie Zhang, Nianyi Lin, Lei Hou, Ling Feng, Juanzi Li

+ [Learnware of Language Models: Specialized Small Language Models Can Do Big](https://arxiv.org//abs/2505.13425)

	Zhi-Hao Tan, Zi-Chen Zhao, Hao-Yu Shi, Xin-Yu Zhang, Peng Tan, Yang Yu, Zhi-Hua Zhou

+ [Optimizing Anytime Reasoning via Budget Relative Policy Optimization](https://arxiv.org//abs/2505.13438)

	Penghui Qi, Zichen Liu, Tianyu Pang, Chao Du, Wee Sun Lee, Min Lin

+ [CIE: Controlling Language Model Text Generations Using Continuous Signals](https://arxiv.org//abs/2505.13448)

	Vinay Samuel, Harshita Diddee, Yiming Zhang, Daphne Ippolito

+ [Improving Multilingual Language Models by Aligning Representations through Steering](https://arxiv.org//abs/2505.12584)

	Omar Mahmoud, Buddhika Laknath Semage, Thommen George Karimpanal, Santu Rana

+ [PromptPrism: A Linguistically-Inspired Taxonomy for Prompts](https://arxiv.org//abs/2505.12592)

	Sullam Jeoung, Yueyan Chen, Yi Zhang, Shuai Wang, Haibo Ding, Lin Lee Cheong

+ [Think Before You Attribute: Improving the Performance of LLMs Attribution Systems](https://arxiv.org//abs/2505.12621)

	João Eduardo Batista, Emil Vatai, Mohamed Wahib

+ [R1dacted: Investigating Local Censorship in DeepSeek's R1 Language Model](https://arxiv.org//abs/2505.12625)

	Ali Naseh, Harsh Chaudhari, Jaechul Roh, Mingshi Wu, Alina Oprea, Amir Houmansadr

+ [Revealing the Deceptiveness of Knowledge Editing: A Mechanistic Analysis of Superficial Editing](https://arxiv.org//abs/2505.12636)

	Jiakuan Xie, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao

+ [ToTRL: Unlock LLM Tree-of-Thoughts Reasoning Potential through Puzzles Solving](https://arxiv.org//abs/2505.12717)

	Haoyuan Wu, Xueyi Chen, Rui Ming, Jilong Gao, Shoubo Hu, Zhuolun He, Bei Yu

+ [Automated Bias Assessment in AI-Generated Educational Content Using CEAT Framework](https://arxiv.org//abs/2505.12718)

	Jingyang Peng, Wenyuan Shen, Jiarui Rao, Jionghao Lin

+ [ReEx-SQL: Reasoning with Execution-Aware Reinforcement Learning for Text-to-SQL](https://arxiv.org//abs/2505.12768)

	Yaxun Dai (1), Wenxuan Xie (3), Xialie Zhuang (4), Tianyu Yang (5), Yiying Yang (2), Haiqin Yang (6), Yuhang Zhao (2), Pingfu Chao (1), Wenhao Jiang (2) ((1) Soochow University, (2) Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), (3) South China University of Technology, (4) University of Chinese Academy of Sciences, (5) Alibaba DAMO Academy, (6) International Digital Economy Academy (IDEA))

+ [EAVIT: Efficient and Accurate Human Value Identification from Text data via LLMs](https://arxiv.org//abs/2505.12792)

	Wenhao Zhu, Yuhang Xie, Guojie Song, Xin Zhang

+ [Decentralized Arena: Towards Democratic and Scalable Automatic Evaluation of Language Models](https://arxiv.org//abs/2505.12808)

	Yanbin Yin, Kun Zhou, Zhen Wang, Xiangdong Zhang, Yifei Shao, Shibo Hao, Yi Gu, Jieyuan Liu, Somanshu Singla, Tianyang Liu, Eric P. Xing, Zhengzhong Liu, Haojian Jin, Zhiting Hu

+ [Contrastive Prompting Enhances Sentence Embeddings in LLMs through Inference-Time Steering](https://arxiv.org//abs/2505.12831)

	Zifeng Cheng, Zhonghui Wang, Yuchen Fu, Zhiwei Jiang, Yafeng Yin, Cong Wang, Qing Gu

+ [Re-identification of De-identified Documents with Autoregressive Infilling](https://arxiv.org//abs/2505.12859)

	Lucas Georges Gabriel Charpentier, Pierre Lison

+ [On the Thinking-Language Modeling Gap in Large Language Models](https://arxiv.org//abs/2505.12896)

	Chenxi Liu, Yongqiang Chen, Tongliang Liu, James Cheng, Bo Han, Kun Zhang

+ [GuRE:Generative Query REwriter for Legal Passage Retrieval](https://arxiv.org//abs/2505.12950)

	Daehee Kim, Deokhyung Kang, Jonghwi Kim, Sangwon Ryu, Gary Geunbae Lee

+ [Evaluating the Performance of RAG Methods for Conversational AI in the Airport Domain](https://arxiv.org//abs/2505.13006)

	Yuyang Li, Philip J.M. Kerbusch, Raimon H.R. Pruim, Tobias Käfer

+ [Systematic Generalization in Language Models Scales with Information Entropy](https://arxiv.org//abs/2505.13089)

	Sondre Wold, Lucas Georges Gabriel Charpentier, Étienne Simon

+ [Understanding Cross-Lingual Inconsistency in Large Language Models](https://arxiv.org//abs/2505.13141)

	Zheng Wei Lim, Alham Fikri Aji, Trevor Cohn

+ [Positional Fragility in LLMs: How Offset Effects Reshape Our Understanding of Memorization Risks](https://arxiv.org//abs/2505.13171)

	Yixuan Xu, Antoine Bosselut, Imanol Schlag

+ [A Case Study of Cross-Lingual Zero-Shot Generalization for Classical Languages in LLMs](https://arxiv.org//abs/2505.13173)

	V.S.D.S.Mahesh Akavarapu, Hrishikesh Terdalkar, Pramit Bhattacharyya, Shubhangi Agarwal, Vishakha Deulgaonkar, Pralay Manna, Chaitali Dangarikar, Arnab Bhattacharya

+ [Alignment-Augmented Speculative Decoding with Alignment Sampling and Conditional Verification](https://arxiv.org//abs/2505.13204)

	Jikai Wang, Zhenxu Tian, Juntao Li, Qingrong Xia, Xinyu Duan, Zhefeng Wang, Baoxing Huai, Min Zhang

+ [Natural Language Planning via Coding and Inference Scaling](https://arxiv.org//abs/2505.13252)

	Rikhil Amonkar, Ronan Le Bras, Li Zhang

+ [HeteroSpec: Leveraging Contextual Heterogeneity for Efficient Speculative Decoding](https://arxiv.org//abs/2505.13254)

	Siran Liu, Yang Ye, Qianchao Zhu, Zheng Cao, Yongchao He

+ [Effective and Transparent RAG: Adaptive-Reward Reinforcement Learning for Decision Traceability](https://arxiv.org//abs/2505.13258)

	Jingyi Ren, Yekun Xu, Xiaolong Wang, Weitao Li, Weizhi Ma, Yang Liu

+ [CSC-SQL: Corrective Self-Consistency in Text-to-SQL via Reinforcement Learning](https://arxiv.org//abs/2505.13271)

	Lei Sheng, Shuai-Shuai Xu

+ [GUARD: Generation-time LLM Unlearning via Adaptive Restriction and Detection](https://arxiv.org//abs/2505.13312)

	Zhijie Deng, Chris Yuhao Liu, Zirui Pang, Xinlei He, Lei Feng, Qi Xuan, Zhaowei Zhu, Jiaheng Wei

+ [Rethinking Stateful Tool Use in Multi-Turn Dialogues: Benchmarks and Challenges](https://arxiv.org//abs/2505.13328)

	Hongru Wang, Wenyu Huang, Yufei Wang, Yuanhao Xi, Jianqiao Lu, Huan Zhang, Nan Hu, Zeming Liu, Jeff Z. Pan, Kam-Fai Wong

+ [Investigating the Vulnerability of LLM-as-a-Judge Architectures to Prompt-Injection Attacks](https://arxiv.org//abs/2505.13348)

	Narek Maloyan, Bislan Ashinov, Dmitry Namiot

+ [Sense and Sensitivity: Examining the Influence of Semantic Recall on Long Context Code Reasoning](https://arxiv.org//abs/2505.13353)

	Adam Štorek, Mukur Gupta, Samira Hajizadeh, Prashast Srivastava, Suman Jana

+ [What Prompts Don't Say: Understanding and Managing Underspecification in LLM Prompts](https://arxiv.org//abs/2505.13360)

	Chenyang Yang, Yike Shi, Qianou Ma, Michael Xieyang Liu, Christian Kästner, Tongshuang Wu

+ [MR. Judge: Multimodal Reasoner as a Judge](https://arxiv.org//abs/2505.13403)

	Renjie Pi, Felix Bai, Qibin Chen, Simon Wang, Jiulong Shan, Kieran Liu, Meng Cao

+ [Dementia Through Different Eyes: Explainable Modeling of Human and LLM Perceptions for Early Awareness](https://arxiv.org//abs/2505.13418)

	Lotem Peled-Cohen, Maya Zadok, Nitay Calderon, Hila Gonen, Roi Reichart

+ [SMOTExT: SMOTE meets Large Language Models](https://arxiv.org//abs/2505.13434)

	Mateusz Bystroński, Mikołaj Hołysz, Grzegorz Piotrowski, Nitesh V. Chawla, Tomasz Kajdanowicz

+ [Enhancing Latent Computation in Transformers with Latent Tokens](https://arxiv.org//abs/2505.12629)

	Yuchang Sun, Yanxi Chen, Yaliang Li, Bolin Ding

+ [GEM: Gaussian Embedding Modeling for Out-of-Distribution Detection in GUI Agents](https://arxiv.org//abs/2505.12842)

	Zheng Wu, Pengzhou Cheng, Zongru Wu, Lingzhong Dong, Zhuosheng Zhang

+ [BusterX: MLLM-Powered AI-Generated Video Forgery Detection and Explanation](https://arxiv.org//abs/2505.12620)

	Haiquan Wen, Yiwei He, Zhenglin Huang, Tianxiao Li, Zihan YU, Xingru Huang, Lu Qi, Baoyuan Wu, Xiangtai Li, Guangliang Cheng

+ [Mitigating Hallucination in VideoLLMs via Temporal-Aware Activation Engineering](https://arxiv.org//abs/2505.12826)

	Jianfeng Cai, Wengang Zhou, Zongmeng Zhang, Jiale Hong, Nianji Zhan, Houqiang Li

+ [Walking the Tightrope: Disentangling Beneficial and Detrimental Drifts in Non-Stationary Custom-Tuning](https://arxiv.org//abs/2505.13081)

	Xiaoyu Yang, Jie Lu, En Yu

+ [Rethinking Predictive Modeling for LLM Routing: When Simple kNN Beats Complex Learned Routers](https://arxiv.org//abs/2505.12601)

	Yang Li

+ [RoFL: Robust Fingerprinting of Language Models](https://arxiv.org//abs/2505.12682)

	Yun-Yun Tsai, Chuan Guo, Junfeng Yang, Laurens van der Maaten

+ [Koopman Autoencoders Learn Neural Representation Dynamics](https://arxiv.org//abs/2505.12809)

	Nishant Suresh Aswani, Saif Eddin Jabari

+ [Unpacking Positional Encoding in Transformers: A Spectral Analysis of Content-Position Coupling](https://arxiv.org//abs/2505.13027)

	Zihan Gu, Han Zhang, Ruoyu Chen, Yue Hu, Hua Zhang

+ [Why Knowledge Distillation Works in Generative Models: A Minimal Working Explanation](https://arxiv.org//abs/2505.13111)

	Sungmin Cha, Kyunghyun Cho

+ [RN-F: A Novel Approach for Mitigating Contaminated Data in Large Language Models](https://arxiv.org//abs/2505.13249)

	Le Vu Anh, Dinh Duc Nha Nguyen, Phi Long Nguyen

+ [Thinking Short and Right Over Thinking Long: Serving LLM Reasoning Efficiently and Accurately](https://arxiv.org//abs/2505.13326)

	Yuhang Wang, Youhe Jiang, Bin Cui, Fangcheng Fu

+ [Occult: Optimizing Collaborative Communication across Experts for Accelerated Parallel MoE Training and Inference](https://arxiv.org//abs/2505.13345)

	Shuqing Luo, Pingzhi Li, Jie Peng, Hanrui Wang, Yang (Katie)Zhao, Yu (Kevin)Cao, Yu Cheng, Tianlong Chen

+ [DynaNoise: Dynamic Probabilistic Noise Injection for Defending Against Membership Inference Attacks](https://arxiv.org//abs/2505.13362)

	Javad Forough, Hamed Haddadi

+ [Prompt Stability Matters: Evaluating and Optimizing Auto-Generated Prompt in General-Purpose Systems](https://arxiv.org//abs/2505.13546)

	Ke Chen, Yufei Zhou, Xitong Zhang, Haohan Wang

+ [A*-Decoding: Token-Efficient Inference Scaling](https://arxiv.org//abs/2505.13672)

	Giannis Chatziveroglou

+ [Warm Up Before You Train: Unlocking General Reasoning in Resource-Constrained Settings](https://arxiv.org//abs/2505.13718)

	Safal Shrestha, Minwu Kim, Aadim Nepal, Anubhav Shrestha, Keith Ross

+ [Causal Head Gating: A Framework for Interpreting Roles of Attention Heads in Transformers](https://arxiv.org//abs/2505.13737)

	Andrew Nam, Henry Conklin, Yukang Yang, Thomas Griffiths, Jonathan Cohen, Sarah-Jane Leslie

+ [Language Models Are Capable of Metacognitive Monitoring and Control of Their Internal Activations](https://arxiv.org//abs/2505.13763)

	Li Ji-An, Hua-Dong Xiong, Robert C. Wilson, Marcelo G. Mattar, Marcus K. Benna

+ [Measuring the Faithfulness of Thinking Drafts in Large Reasoning Models](https://arxiv.org//abs/2505.13774)

	Zidi Xiong, Chen Shan, Zhenting Qi, Himabindu Lakkaraju

+ [CoIn: Counting the Invisible Reasoning Tokens in Commercial Opaque LLM APIs](https://arxiv.org//abs/2505.13778)

	Guoheng Sun, Ziyao Wang, Bowei Tian, Meng Liu, Zheyu Shen, Shwai He, Yexiao He, Wanghao Ye, Yiting Wang, Ang Li

+ [Know Or Not: a library for evaluating out-of-knowledge base robustness](https://arxiv.org//abs/2505.13545)

	Jessica Foo, Pradyumna Shyama Prasad, Shaun Khoo

+ [Exploring Federated Pruning for Large Language Models](https://arxiv.org//abs/2505.13547)

	Pengxin Guo, Yinong Wang, Wei Li, Mengting Liu, Ming Li, Jinkai Zheng, Liangqiong Qu

+ [AMAQA: A Metadata-based QA Dataset for RAG Systems](https://arxiv.org//abs/2505.13557)

	Davide Bruni, Marco Avvenuti, Nicola Tonellotto, Maurizio Tesconi

+ [VocalAgent: Large Language Models for Vocal Health Diagnostics with Safety-Aware Evaluation](https://arxiv.org//abs/2505.13577)

	Yubin Kim, Taehan Kim, Wonjune Kang, Eugene Park, Joonsik Yoon, Dongjae Lee, Xin Liu, Daniel McDuff, Hyeonhoon Lee, Cynthia Breazeal, Hae Won Park

+ [RL in Name Only? Analyzing the Structural Assumptions in RL post-training for LLMs](https://arxiv.org//abs/2505.13697)

	Soumya Rani Samineni, Durgesh Kalwar, Karthik Valmeekam, Kaya Stechly, Subbarao Kambhampati

+ [Power Lines: Scaling Laws for Weight Decay and Batch Size in LLM Pre-training](https://arxiv.org//abs/2505.13738)

	Shane Bergsma, Nolan Dey, Gurpreet Gosal, Gavia Gray, Daria Soboleva, Joel Hestness

+ [Beyond Semantics: The Unreasonable Effectiveness of Reasonless Intermediate Tokens](https://arxiv.org//abs/2505.13775)

	Kaya Stechly, Karthik Valmeekam, Atharva Gundawar, Vardhan Palod, Subbarao Kambhampati

+ [SQLForge: Synthesizing Reliable and Diverse Data to Enhance Text-to-SQL Reasoning in LLMs](https://arxiv.org//abs/2505.13725)

	Yu Guo, Dong Jin, Shenghao Ye, Shuangwu Chen, Jian Yang, Xiaobin Tan

+ [Simulation Agent: A Framework for Integrating Simulation and Large Language Models for Enhanced Decision-Making](https://arxiv.org//abs/2505.13761)

	Jacob Kleiman, Kevin Frank, Sindy Campagna

+ [RAR: Setting Knowledge Tripwires for Retrieval Augmented Rejection](https://arxiv.org//abs/2505.13581)

	Tommaso Mario Buonocore, Enea Parimbelli

+ [Guided Search Strategies in Non-Serializable Environments with Applications to Software Engineering Agents](https://arxiv.org//abs/2505.13652)

	Karina Zainullina, Alexander Golubev, Maria Trofimova, Sergei Polezhaev, Ibragim Badertdinov, Daria Litvintseva, Simon Karasik, Filipp Fisin, Sergei Skvortsov, Maksim Nekrashevich, Anton Shevtsov, Boris Yangel

+ [LLM-Based Compact Reranking with Document Features for Scientific Retrieval](https://arxiv.org//abs/2505.13757)

	Runchu Tian, Xueqiang Xu, Bowen Jin, SeongKu Kang, Jiawei Han

+ [Incentivizing Truthful Language Models via Peer Elicitation Games](https://arxiv.org//abs/2505.13636)

	Baiting Chen, Tong Zhu, Jiale Han, Lexin Li, Gang Li, Xiaowu Dai

+ [Selective Code Generation for Functional Guarantees](https://arxiv.org//abs/2505.13553)

	Jaewoo Jeong, Taesoo Kim, Sangdon Park

+ [BeamClean: Language Aware Embedding Reconstruction](https://arxiv.org//abs/2505.13758)

	Kaan Kale, Kyle Mylonakis, Jay Roberts, Sidhartha Roy

+ [Safety Alignment Can Be Not Superficial With Explicit Safety Signals](https://arxiv.org//abs/2505.17072)

	Jianwei Li, Jung-Eng Kim

+ [What's in a prompt? Language models encode literary style in prompt embeddings](https://arxiv.org//abs/2505.17071)

	Raphaël Sarfati, Haley Moller, Toni J. B. Liu, Nicolas Boullé, Christopher Earls

# 2025-05-18
+ [Mitigating Content Effects on Reasoning in Language Models through Fine-Grained Activation Steering](https://arxiv.org//abs/2505.12189)

	Marco Valentino, Geonhee Kim, Dhairya Dalal, Zhixue Zhao, André Freitas

+ [Beyond Single-Point Judgment: Distribution Alignment for LLM-as-a-Judge](https://arxiv.org//abs/2505.12301)

	Luyu Chen, Zeyu Zhang, Haoran Tan, Quanyu Dai, Hao Yang, Zhenhua Dong, Xu Chen

+ [BeliefNest: A Joint Action Simulator for Embodied Agents with Theory of Mind](https://arxiv.org//abs/2505.12321)

	Rikunari Sagara, Koichiro Terao, Naoto Iwahashi

+ [Enhancing User-Oriented Proactivity in Open-Domain Dialogues with Critic Guidance](https://arxiv.org//abs/2505.12334)

	Yufeng Wang, Jinwu Hu, Ziteng Huang, Kunyang Lin, Zitian Zhang, Peihao Chen, Yu Hu, Qianyue Wang, Zhuliang Yu, Bin Sun, Xiaofen Xing, Qingfang Zheng, Mingkui Tan

+ [SEED-GRPO: Semantic Entropy Enhanced GRPO for Uncertainty-Aware Policy Optimization](https://arxiv.org//abs/2505.12346)

	Minghan Chen, Guikun Chen, Wenguan Wang, Yi Yang

+ [Reasoning-CV: Fine-tuning Powerful Reasoning LLMs for Knowledge-Assisted Claim Verification](https://arxiv.org//abs/2505.12348)

	Zhi Zheng, Wee Sun Lee

+ [MedAgentBoard: Benchmarking Multi-Agent Collaboration with Conventional Methods for Diverse Medical Tasks](https://arxiv.org//abs/2505.12371)

	Yinghao Zhu, Ziyi He, Haoran Hu, Xiaochen Zheng, Xichen Zhang, Zixiang Wang, Junyi Gao, Liantao Ma, Lequan Yu

+ [NeuroGen: Neural Network Parameter Generation via Large Language Models](https://arxiv.org//abs/2505.12470)

	Jiaqi Wang, Yusen Zhang, Xi Li

+ [UIShift: Enhancing VLM-based GUI Agents through Self-supervised Reinforcement Learning](https://arxiv.org//abs/2505.12493)

	Longxi Gao, Li Zhang, Mengwei Xu

+ [MARGE: Improving Math Reasoning for LLMs with Guided Exploration](https://arxiv.org//abs/2505.12500)

	Jingyue Gao, Runji Lin, Keming Lu, Bowen Yu, Junyang Lin, Jianyu Chen

+ [ALAS: A Stateful Multi-LLM Agent Framework for Disruption-Aware Planning](https://arxiv.org//abs/2505.12501)

	Edward Y. Chang, Longling Geng

+ [Decoding the Mind of Large Language Models: A Quantitative Evaluation of Ideology and Biases](https://arxiv.org//abs/2505.12183)

	Manari Hirose, Masato Uchida

+ [Self-Destructive Language Model](https://arxiv.org//abs/2505.12186)

	Yuhui Wang, Rongyi Zhu, Ting Wang

+ [LLM-DSE: Searching Accelerator Parameters with LLM Agents](https://arxiv.org//abs/2505.12188)

	Hanyu Wang, Xinrui Wu, Zijian Ding, Su Zheng, Chengyue Wang, Tony Nowatzki, Yizhou Sun, Jason Cong

+ [Reward Inside the Model: A Lightweight Hidden-State Reward Model for LLM's Best-of-N sampling](https://arxiv.org//abs/2505.12225)

	Jizhou Guo, Zhaomin Wu, Philip S. Yu

+ [PANORAMA: A synthetic PII-laced dataset for studying sensitive data memorization in LLMs](https://arxiv.org//abs/2505.12238)

	Sriram Selvam, Anneswa Ghosh

+ [ACU: Analytic Continual Unlearning for Efficient and Exact Forgetting with Privacy Preservation](https://arxiv.org//abs/2505.12239)

	Jianheng Tang, Huiping Zhuang, Di Fang, Jiaxu Li, Feijiang Han, Yajiang Huang, Kejia Fan, Leye Wang, Zhanxing Zhu, Shanghang Zhang, Houbing Herbert Song, Yunhuai Liu

+ [LAMeTA: Intent-Aware Agentic Network Optimization via a Large AI Model-Empowered Two-Stage Approach](https://arxiv.org//abs/2505.12247)

	Yinqiu Liu, Guangyuan Liu, Jiacheng Wang, Ruichen Zhang, Dusit Niyato, Geng Sun, Zehui Xiong, Zhu Han

+ [Not All Documents Are What You Need for Extracting Instruction Tuning Data](https://arxiv.org//abs/2505.12250)

	Chi Zhang, Huaping Zhong, Hongtao Li, Chengliang Chai, Jiawei Hong, Yuhao Deng, Jiacheng Wang, Tian Tan, Yizhou Yan, Jiantao Qiu, Ye Yuan, Guoren Wang, Conghui He, Lei Cao

+ [LightRetriever: A LLM-based Hybrid Retrieval Architecture with 1000x Faster Query Inference](https://arxiv.org//abs/2505.12260)

	Guangyuan Ma, Yongliang Ma, Xuanrui Gou, Zhenpeng Su, Ming Zhou, Songlin Hu

+ [The Tower of Babel Revisited: Multilingual Jailbreak Prompts on Closed-Source Large Language Models](https://arxiv.org//abs/2505.12287)

	Linghan Huang, Haolin Jin, Zhaoge Bi, Pengyue Yang, Peizhou Zhao, Taozhao Chen, Xiongfei Wu, Lei Ma, Huaming Chen

+ [Mitigating Hallucinations via Inter-Layer Consistency Aggregation in Large Vision-Language Models](https://arxiv.org//abs/2505.12343)

	Kai Tang, Jinhao You, Xiuqi Ge, Hanze Li, Yichen Guo, Xiande Huang

+ [Wisdom from Diversity: Bias Mitigation Through Hybrid Human-LLM Crowds](https://arxiv.org//abs/2505.12349)

	Axel Abels, Tom Lenaerts

+ [DisCO: Reinforcing Large Reasoning Models with Discriminative Constrained Optimization](https://arxiv.org//abs/2505.12366)

	Gang Li, Ming Lin, Tomer Galanti, Zhengzhong Tu, Tianbao Yang

+ [CAPTURE: Context-Aware Prompt Injection Testing and Robustness Enhancement](https://arxiv.org//abs/2505.12368)

	Gauri Kholkar, Ratinder Ahuja

+ [From n-gram to Attention: How Model Architectures Learn and Propagate Bias in Language Modeling](https://arxiv.org//abs/2505.12381)

	Mohsinul Kabir, Tasfia Tahsin, Sophia Ananiadou

+ [Traversal Verification for Speculative Tree Decoding](https://arxiv.org//abs/2505.12398)

	Yepeng Weng, Qiao Hu, Xujie Chen, Li Liu, Dianwen Mei, Huishi Qiu, Jiang Tian, Zhongchao Shi

+ [PSC: Extending Context Window of Large Language Models via Phase Shift Calibration](https://arxiv.org//abs/2505.12423)

	Wenqiao Zhu, Chao Xu, Lulu Wang, Jun Wu

+ [EvoGPT: Enhancing Test Suite Robustness via LLM-Based Generation and Genetic Optimization](https://arxiv.org//abs/2505.12424)

	Lior Broide, Roni Stern

+ [Observe-R1: Unlocking Reasoning Abilities of MLLMs with Dynamic Progressive Reinforcement Learning](https://arxiv.org//abs/2505.12432)

	Zirun Guo, Minjie Hong, Tao Jin

+ [SRLoRA: Subspace Recomposition in Low-Rank Adaptation via Importance-Based Fusion and Reinitialization](https://arxiv.org//abs/2505.12433)

	Haodong Yang, Lei Wang, Md Zakir Hossain

+ [SGDPO: Self-Guided Direct Preference Optimization for Language Model Alignment](https://arxiv.org//abs/2505.12435)

	Wenqiao Zhu, Ji Liu, Lulu Wang, Jun Wu, Yulun Zhang

+ [IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems](https://arxiv.org//abs/2505.12442)

	Liwen Wang, Wenxuan Wang, Shuai Wang, Zongjie Li, Zhenlan Ji, Zongyi Lyu, Daoyuan Wu, Shing-Chi Cheung

+ [Beyond Frameworks: Unpacking Collaboration Strategies in Multi-Agent Systems](https://arxiv.org//abs/2505.12467)

	Haochun Wang, Sendong Zhao, Jingbo Wang, Zewen Qiang, Bing Qin, Ting Liu

+ [Enhancing Large Language Models with Reward-guided Tree Search for Knowledge Graph Question and Answering](https://arxiv.org//abs/2505.12476)

	Xiao Long, Liansheng Zhuang, Chen Shen, Shaotian Yan, Yifei Li, Shafei Wang

+ [CPGD: Toward Stable Rule-based Reinforcement Learning for Language Models](https://arxiv.org//abs/2505.12504)

	Zongkai Liu, Fanqing Meng, Lingxiao Du, Zhixiang Zhou, Chao Yu, Wenqi Shao, Qiaosheng Zhang

+ [Towards Budget-Friendly Model-Agnostic Explanation Generation for Large Language Models](https://arxiv.org//abs/2505.12509)

	Junhao Liu, Haonan Yu, Xin Zhang

+ [A Survey of Attacks on Large Language Models](https://arxiv.org//abs/2505.12567)

	Wenrui Xu, Keshab K. Parhi

+ [Measuring Information Distortion in Hierarchical Ultra long Novel Generation:The Optimal Expansion Ratio](https://arxiv.org//abs/2505.12572)

	Hanwen Shen, Ting Ying

+ [Truth Neurons](https://arxiv.org//abs/2505.12182)

	Haohang Li, Yupeng Cao, Yangyang Yu, Jordan W. Suchow, Zining Zhu

+ [How Reliable is Multilingual LLM-as-a-Judge?](https://arxiv.org//abs/2505.12201)

	Xiyan Fu, Wei Liu

+ [Data Whisperer: Efficient Data Selection for Task-Specific LLM Fine-Tuning via Few-Shot In-Context Learning](https://arxiv.org//abs/2505.12212)

	Shaobo Wang, Ziming Wang, Xiangqi Jin, Jize Wang, Jiajun Zhang, Kaixin Li, Zichen Wen, Zhong Li, Conghui He, Xuming Hu, Linfeng Zhang

+ [GMSA: Enhancing Context Compression via Group Merging and Layer Semantic Alignment](https://arxiv.org//abs/2505.12215)

	Jiwei Tang, Zhicheng Zhang, Shunlong Wu, Jingheng Ye, Lichen Bai, Zitai Wang, Tingwei Lu, Jiaqi Chen, Lin Hai, Hai-Tao Zheng, Hong-Gee Kim

+ [One-for-All Pruning: A Universal Model for Customized Compression of Large Language Models](https://arxiv.org//abs/2505.12216)

	Rongguang Ye, Ming Tang

+ [Distribution Prompting: Understanding the Expressivity of Language Models Through the Next-Token Distributions They Can Produce](https://arxiv.org//abs/2505.12244)

	Haojin Wang, Zining Zhu, Freda Shi

+ [Teach2Eval: An Indirect Evaluation Method for LLM by Judging How It Teaches](https://arxiv.org//abs/2505.12259)

	Yuhang Zhou, Xutian Chen, Yixin Cao, Yuchen Ni, Yu He, Siyu Tian, Xiang Liu, Jian Zhang, Chuanjun Ji, Guangnan Ye, Xipeng Qiu

+ [Learning Auxiliary Tasks Improves Reference-Free Hallucination Detection in Open-Domain Long-Form Generation](https://arxiv.org//abs/2505.12265)

	Chengwei Qin, Wenxuan Zhou, Karthik Abinav Sankararaman, Nanshu Wang, Tengyu Xu, Alexander Radovic, Eryk Helenowski, Arya Talebzadeh, Aditya Tayade, Sinong Wang, Shafiq Joty, Han Fang, Hao Ma

+ [$K$-MSHC: Unmasking Minimally Sufficient Head Circuits in Large Language Models with Experiments on Syntactic Classification Tasks](https://arxiv.org//abs/2505.12268)

	Pratim Chowdhary

+ [LLM-Based Evaluation of Low-Resource Machine Translation: A Reference-less Dialect Guided Approach with a Refined Sylheti-English Benchmark](https://arxiv.org//abs/2505.12273)

	Md. Atiqur Rahman, Sabrina Islam, Mushfiqul Haque Omi

+ [HBO: Hierarchical Balancing Optimization for Fine-Tuning Large Language Models](https://arxiv.org//abs/2505.12300)

	Weixuan Wang, Minghao Wu, Barry Haddow, Alexandra Birch

+ [Bidirectional LMs are Better Knowledge Memorizers? A Benchmark for Real-world Knowledge Injection](https://arxiv.org//abs/2505.12306)

	Yuwei Zhang, Wenhao Yu, Shangbin Feng, Yifan Zhu, Letian Peng, Jayanth Srinivasa, Gaowen Liu, Jingbo Shang

+ [ExpertSteer: Intervening in LLMs through Expert Knowledge](https://arxiv.org//abs/2505.12313)

	Weixuan Wang, Minghao Wu, Barry Haddow, Alexandra Birch

+ [LLMSR@XLLM25: An Empirical Study of LLM for Structural Reasoning](https://arxiv.org//abs/2505.12328)

	Xinye Li, Mingqi Wan, Dianbo Sui

+ [UniEdit: A Unified Knowledge Editing Benchmark for Large Language Models](https://arxiv.org//abs/2505.12345)

	Qizhou Chen, Dakan Wang, Taolin Zhang, Zaoming Yan, Chengsong You, Chengyu Wang, Xiaofeng He

+ [SLOT: Sample-specific Language Model Optimization at Test-time](https://arxiv.org//abs/2505.12392)

	Yang Hu, Xingyu Zhang, Xueji Fang, Zhiyang Chen, Xiao Wang, Huatian Zhang, Guojun Qi

+ [Learning to Play Like Humans: A Framework for LLM Adaptation in Interactive Fiction Games](https://arxiv.org//abs/2505.12439)

	Jinming Zhang, Yunfei Long

+ [Introspective Growth: Automatically Advancing LLM Expertise in Technology Judgment](https://arxiv.org//abs/2505.12452)

	Siyang Wu, Honglin Bao, Nadav Kunievsky, James A. Evans

+ [What are they talking about? Benchmarking Large Language Models for Knowledge-Grounded Discussion Summarization](https://arxiv.org//abs/2505.12474)

	Weixiao Zhou, Junnan Zhu, Gengyao Li, Xianfu Cheng, Xinnian Liang, Feifei Zhai, Zhoujun Li

+ [KG-QAGen: A Knowledge-Graph-Based Framework for Systematic Question Generation and Long-Context LLM Evaluation](https://arxiv.org//abs/2505.12495)

	Nikita Tatarinov, Vidhyakshaya Kannan, Haricharana Srinivasa, Arnav Raj, Harpreet Singh Anand, Varun Singh, Aditya Luthra, Ravij Lade, Agam Shah, Sudheer Chava

+ [LM$^2$otifs : An Explainable Framework for Machine-Generated Texts Detection](https://arxiv.org//abs/2505.12507)

	Xu Zheng, Zhuomin Chen, Esteban Schafir, Sipeng Chen, Hojat Allah Salehi, Haifeng Chen, Farhad Shirani, Wei Cheng, Dongsheng Luo

+ [ESC-Judge: A Framework for Comparing Emotional Support Conversational Agents](https://arxiv.org//abs/2505.12531)

	Navid Madani, Rohini Srihari

+ [Disambiguation in Conversational Question Answering in the Era of LLM: A Survey](https://arxiv.org//abs/2505.12543)

	Md Mehrab Tanjim, Yeonjun In, Xiang Chen, Victor S. Bursztyn, Ryan A. Rossi, Sungchul Kim, Guang-Jie Ren, Vaishnavi Muppala, Shun Jiang, Yongsung Kim, Chanyoung Park

+ [Extracting memorized pieces of (copyrighted) books from open-weight language models](https://arxiv.org//abs/2505.12546)

	A. Feder Cooper, Aaron Gokaslan, Amy B. Cyphert, Christopher De Sa, Mark A. Lemley, Daniel E. Ho, Percy Liang

+ [EVALOOP: Assessing LLM Robustness in Programming from a Self-consistency Perspective](https://arxiv.org//abs/2505.12185)

	Sen Fang, Weiyuan Ding, Bowen Xu

+ [LogicOCR: Do Your Large Multimodal Models Excel at Logical Reasoning on Text-Rich Images?](https://arxiv.org//abs/2505.12307)

	Maoyuan Ye, Jing Zhang, Juhua Liu, Bo Du, Dacheng Tao

+ [UFO-RL: Uncertainty-Focused Optimization for Efficient Reinforcement Learning Data Selection](https://arxiv.org//abs/2505.12457)

	Yang Zhao, Kai Xiong, Xiao Ding, Li Du, YangouOuyang, Zhouhao Sun, Jiannan Guan, Wenbin Zhang, Bin Liu, Dong Hu, Bing Qin, Ting Liu

+ [From Shots to Stories: LLM-Assisted Video Editing with Unified Language Representations](https://arxiv.org//abs/2505.12237)

	Yuzhi Li, Haojun Xu, Fang Tian

+ [SchoenbAt: Rethinking Attention with Polynomial basis](https://arxiv.org//abs/2505.12252)

	Yuhan Guo, Lizhong Ding, Yuwan Yang, Xuewei Guo

+ [Graph-Reward-SQL: Execution-Free Reinforcement Learning for Text-to-SQL via Graph Matching and Stepwise Reward](https://arxiv.org//abs/2505.12380)

	Han Weng, Boyi Liu, Yuanfeng Song, Dun Zeng, Yingxiang Yang, Yi Zhan, Longjie Cui, Xiaoming Yin, Yang Sun

+ [AltLoRA: Towards Better Gradient Approximation in Low-Rank Adaptation with Alternating Projections](https://arxiv.org//abs/2505.12455)

	Xin Yu, Yujia Wang, Jinghui Chen, Lingzhou Xue

+ [Reasoning by Superposition: A Theoretical Perspective on Chain of Continuous Thought](https://arxiv.org//abs/2505.12514)

	Hanlin Zhu, Shibo Hao, Zhiting Hu, Jiantao Jiao, Stuart Russell, Yuandong Tian

+ [Harnessing the Universal Geometry of Embeddings](https://arxiv.org//abs/2505.12540)

	Rishi Jha, Collin Zhang, Vitaly Shmatikov, John X. Morris

+ [Adaptive parameter-efficient fine-tuning via Hessian-informed subset selection](https://arxiv.org//abs/2505.12579)

	Shiyun Xu, Zhiqi Bu

+ [OSS-Bench: Benchmark Generator for Coding LLMs](https://arxiv.org//abs/2505.12331)

	Yuancheng Jiang, Roland Yap, Zhenkai Liang

+ [Automated Profile Inference with Language Model Agents](https://arxiv.org//abs/2505.12402)

	Yuntao Du, Zitao Li, Bolin Ding, Yaliang Li, Hanshen Xiao, Jingren Zhou, Ninghui Li

+ [BARREL: Boundary-Aware Reasoning for Factual and Reliable LRMs](https://arxiv.org//abs/2505.13529)

	Junxiao Yang, Jinzhe Tu, Haoran Liu, Xiaoce Wang, Chujie Zheng, Zhexin Zhang, Shiyao Cui, Caishun Chen, Tiantian He, Hongning Wang, Yew-Soon Ong, Minlie Huang

+ [LLM Context Conditioning and PWP Prompting for Multimodal Validation of Chemical Formulas](https://arxiv.org//abs/2505.12257)

	Evgeny Markhasin

+ [Logic Jailbreak: Efficiently Unlocking LLM Safety Restrictions Through Formal Logical Expression](https://arxiv.org//abs/2505.13527)

	Jingyu Peng, Maolin Wang, Nan Wang, Xiangyu Zhao, Jiatong Li, Kai Zhang, Qi Liu

+ [LLM-Based User Simulation for Low-Knowledge Shilling Attacks on Recommender Systems](https://arxiv.org//abs/2505.13528)

	Shengkang Gu, Jiahao Liu, Dongsheng Li, Guangping Zhang, Mingzhe Han, Hansu Gu, Peng Zhang, Ning Gu, Li Shang, Tun Lu

+ [AdAEM: An Adaptively and Automated Extensible Measurement of LLMs' Value Difference](https://arxiv.org//abs/2505.13531)

	Shitong Duan, Xiaoyuan Yi, Peng Zhang, Dongkuan Xu, Jing Yao, Tun Lu, Ning Gu, Xing Xie

+ [RAGXplain: From Explainable Evaluation to Actionable Guidance of RAG Pipelines](https://arxiv.org//abs/2505.13538)

	Dvir Cohen, Lin Burg, Gilad Barkan

+ [SPIRIT: Patching Speech Language Models against Jailbreak Attacks](https://arxiv.org//abs/2505.13541)

	Amirbek Djanibekov, Nurdaulet Mukhituly, Kentaro Inui, Hanan Aldarmaki, Nils Lukas

+ [Improving LLM Outputs Against Jailbreak Attacks with Expert Model Integration](https://arxiv.org//abs/2505.17066)

	Tatia Tsmindashvili, Ana Kolkhidashvili, Dachi Kurtskhalia, Nino Maghlakelidze, Elene Mekvabishvili, Guram Dentoshvili, Orkhan Shamilov, Zaal Gachechiladze, Steven Saporta, David Dachi Choladze

# 2025-05-17
+ [Solver-Informed RL: Grounding Large Language Models for Authentic Optimization Modeling](https://arxiv.org//abs/2505.11792)

	Yitian Chen, Jingfan Xia, Siyu Shao, Dongdong Ge, Yinyu Ye

+ [ChatHTN: Interleaving Approximate (LLM) and Symbolic HTN Planning](https://arxiv.org//abs/2505.11814)

	Hector Munoz-Avila, David W. Aha, Paola Rizzo

+ [ToLeaP: Rethinking Development of Tool Learning with Large Language Models](https://arxiv.org//abs/2505.11833)

	Haotian Chen, Zijun Song, Boye Niu, Ke Zhang, Litu Ou, Yaxi Lu, Zhong Zhang, Xin Cong, Yankai Lin, Zhiyuan Liu, Maosong Sun

+ [On the Eligibility of LLMs for Counterfactual Reasoning: A Decompositional Study](https://arxiv.org//abs/2505.11839)

	Shuai Yang, Qi Yang, Luoxi Tang, Jeremy Blackburn, Zhaohan Xi

+ [Evaluating the Logical Reasoning Abilities of Large Reasoning Models](https://arxiv.org//abs/2505.11854)

	Hanmeng Liu, Yiran Ding, Zhizhang Fu, Chaoli Zhang, Xiaozhang Liu, Yue Zhang

+ [Fair-PP: A Synthetic Dataset for Aligning LLM with Personalized Preferences of Social Equity](https://arxiv.org//abs/2505.11861)

	Qi Zhou, Jie Zhang, Dongxia Wang, Qiang Liu, Tianlin Li, Jin Song Dong, Wenhai Wang, Qing Guo

+ [LifelongAgentBench: Evaluating LLM Agents as Lifelong Learners](https://arxiv.org//abs/2505.11942)

	Junhao Zheng, Xidi Cai, Qiuke Li, Duzhen Zhang, ZhongZhi Li, Yingying Zhang, Le Song, Qianli Ma

+ [Solve-Detect-Verify: Inference-Time Scaling with Flexible Generative Verifier](https://arxiv.org//abs/2505.11966)

	Jianyuan Zhong, Zeju Li, Zhijian Xu, Xiangyu Wen, Kezhi Li, Qiang Xu

+ [Interactional Fairness in LLM Multi-Agent Systems: An Evaluation Framework](https://arxiv.org//abs/2505.12001)

	Ruta Binkyte

+ [SOCIA: An End-to-End Agentic Framework for Automated Cyber-Physical-Social Simulator Generation](https://arxiv.org//abs/2505.12006)

	Yuncheng Hua, Ji Miao, Mehdi Jafari, Jianxiang Xie, Hao Xue, Flora D. Salim

+ [LLM-based Automated Theorem Proving Hinges on Scalable Synthetic Data Generation](https://arxiv.org//abs/2505.12031)

	Junyu Lai, Jiakun Zhang, Shuo Xu, Taolue Chen, Zihang Wang, Yao Yang, Jiarui Zhang, Chun Cao, Jingwei Xu

+ [Tiny QA Benchmark++: Ultra-Lightweight, Synthetic Multilingual Dataset Generation & Smoke-Tests for Continuous LLM Evaluation](https://arxiv.org//abs/2505.12058)

	Vincent Koc

+ [Demystifying and Enhancing the Efficiency of Large Language Model Based Search Agents](https://arxiv.org//abs/2505.12065)

	Tiannuo Yang, Zebin Yao, Bowen Jin, Lixiao Cui, Yusen Li, Gang Wang, Xiaoguang Liu

+ [LLM-BABYBENCH: Understanding and Evaluating Grounded Planning and Reasoning in LLMs](https://arxiv.org//abs/2505.12135)

	Omar Choukrani, Idriss Malek, Daniil Orel, Zhuohan Xie, Zangir Iklassov, Martin Takáč, Salem Lahlou

+ [OMAC: A Broad Optimization Framework for LLM-Based Multi-Agent Collaboration](https://arxiv.org//abs/2505.11765)

	Shijun Li, Hilaf Hasson, Joydeep Ghosh

+ [Internal Causal Mechanisms Robustly Predict Language Model Out-of-Distribution Behaviors](https://arxiv.org//abs/2505.11770)

	Jing Huang, Junyi Tao, Thomas Icard, Diyi Yang, Christopher Potts

+ [Retrospex: Language Agent Meets Offline Reinforcement Learning Critic](https://arxiv.org//abs/2505.11807)

	Yufei Xiang, Yiqun Shen, Yeqin Zhang, Cam-Tu Nguyen

+ [Search-Based Correction of Reasoning Chains for Language Models](https://arxiv.org//abs/2505.11824)

	Minsu Kim, Jean-Pierre Falet, Oliver E. Richardson, Xiaoyin Chen, Moksh Jain, Sungjin Ahn, Sungsoo Ahn, Yoshua Bengio

+ [Not All Thoughts are Generated Equal: Efficient LLM Reasoning via Multi-Turn Reinforcement Learning](https://arxiv.org//abs/2505.11827)

	Yansong Ning, Wei Li, Jun Fang, Naiqiang Tan, Hao Liu

+ [Multilingual Collaborative Defense for Large Language Models](https://arxiv.org//abs/2505.11835)

	Hongliang Li, Jinan Xu, Gengping Cui, Changhao Guan, Fengran Mo, Kaiyu Huang

+ [On Membership Inference Attacks in Knowledge Distillation](https://arxiv.org//abs/2505.11837)

	Ziyao Cui, Minxing Zhang, Jian Pei

+ [Mobile-Bench-v2: A More Realistic and Comprehensive Benchmark for VLM-based Mobile Agents](https://arxiv.org//abs/2505.11891)

	Weikai Xu, Zhizheng Jiang, Yuxuan Liu, Wei Liu, Jian Luan, Yuanchun Li, Yunxin Liu, Bin Wang, Bo An

+ [RLAP: A Reinforcement Learning Enhanced Adaptive Planning Framework for Multi-step NLP Task Solving](https://arxiv.org//abs/2505.11893)

	Zepeng Ding, Dixuan Wang, Ziqin Luo, Guochao Jiang, Deqing Yang, Jiaqing Liang

+ [AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via Reinforcement Learning](https://arxiv.org//abs/2505.11896)

	Chenwei Lou, Zewei Sun, Xinnian Liang, Meng Qu, Wei Shen, Wenqi Wang, Yuntao Li, Qingping Yang, Shuangzhi Wu

+ [An Explanation of Intrinsic Self-Correction via Linear Representations and Latent Concepts](https://arxiv.org//abs/2505.11924)

	Yu-Ting Lee, Hui-Ying Shih, Fu-Chieh Chang, Pei-Yuan Wu

+ [Exploring Criteria of Loss Reweighting to Enhance LLM Unlearning](https://arxiv.org//abs/2505.11953)

	Puning Yang, Qizhou Wang, Zhuo Huang, Tongliang Liu, Chengqi Zhang, Bo Han

+ [MARVEL: Multi-Agent RTL Vulnerability Extraction using Large Language Models](https://arxiv.org//abs/2505.11963)

	Luca Collini, Baleegh Ahmad, Joey Ah-kiow, Ramesh Karri

+ [Safe Delta: Consistently Preserving Safety when Fine-Tuning LLMs on Diverse Datasets](https://arxiv.org//abs/2505.12038)

	Ning Lu, Shengcai Liu, Jiahao Wu, Weiyu Chen, Zhirui Zhang, Yew-Soon Ong, Qi Wang, Ke Tang

+ [ABoN: Adaptive Best-of-N Alignment](https://arxiv.org//abs/2505.12050)

	Vinod Raman, Hilal Asi, Satyen Kale

+ [Improving Fairness in LLMs Through Testing-Time Adversaries](https://arxiv.org//abs/2505.12100)

	Isabela Pereira Gregio, Ian Pons, Anna Helena Reali Costa, Artur Jordão

+ [Reasoning Large Language Model Errors Arise from Hallucinating Critical Problem Features](https://arxiv.org//abs/2505.12151)

	Alex Heyman, Joel Zylberberg

+ [BELLE: A Bi-Level Multi-Agent Reasoning Framework for Multi-Hop Question Answering](https://arxiv.org//abs/2505.11811)

	Taolin Zhang, Dongyang Li, Qizhou Chen, Chengyu Wang, Xiaofeng He

+ [Chain-of-Model Learning for Language Model](https://arxiv.org//abs/2505.11820)

	Kaitao Song, Xiaohua Wang, Xu Tan, Huiqiang Jiang, Chengruidong Zhang, Yongliang Shen, Cen LU, Zihao Li, Zifan Song, Caihua Shan, Yansen Wang, Kan Ren, Xiaoqing Zheng, Tao Qin, Yuqing Yang, Dongsheng Li, Lili Qiu

+ [NAMET: Robust Massive Model Editing via Noise-Aware Memory Optimization](https://arxiv.org//abs/2505.11876)

	Yanbo Dai, Zhenlan Ji, Zongjie Li, Shuai Wang

+ [AutoMedEval: Harnessing Language Models for Automatic Medical Capability Evaluation](https://arxiv.org//abs/2505.11887)

	Xiechi Zhang, Zetian Ouyang, Linlin Wang, Gerard de Melo, Zhu Cao, Xiaoling Wang, Ya Zhang, Yanfeng Wang, Liang He

+ [ELITE: Embedding-Less retrieval with Iterative Text Exploration](https://arxiv.org//abs/2505.11908)

	Zhangyu Wang, Siyuan Gao, Rong Zhou, Hao Wang, Li Ning

+ [Enhancing Complex Instruction Following for Large Language Models with Mixture-of-Contexts Fine-tuning](https://arxiv.org//abs/2505.11922)

	Yuheng Lu, ZiMeng Bai, Caixia Yuan, Huixing Jiang, Xiaojie Wang

+ [Neuro-Symbolic Query Compiler](https://arxiv.org//abs/2505.11932)

	Yuyao Zhang, Zhicheng Dou, Xiaoxi Li, Jiajie Jin, Yongkang Wu, Zhonghua Li, Qi Ye, Ji-Rong Wen

+ [CCNU at SemEval-2025 Task 3: Leveraging Internal and External Knowledge of Large Language Models for Multilingual Hallucination Annotation](https://arxiv.org//abs/2505.11965)

	Xu Liu, Guanyi Chen

+ [Unveiling Knowledge Utilization Mechanisms in LLM-based Retrieval-Augmented Generation](https://arxiv.org//abs/2505.11995)

	Yuhao Wang, Ruiyang Ren, Yucheng Wang, Wayne Xin Zhao, Jing Liu, Hua Wu, Haifeng Wang

+ [MoL for LLMs: Dual-Loss Optimization to Enhance Domain Expertise While Preserving General Capabilities](https://arxiv.org//abs/2505.12043)

	Jingxue Chen, Qingkun Tang, Qianchun Lu, Siyuan Fang

+ [GenderBench: Evaluation Suite for Gender Biases in LLMs](https://arxiv.org//abs/2505.12054)

	Matúš Pikuliak

+ [Why Not Act on What You Know? Unleashing Safety Potential of LLMs via Self-Aware Guard Enhancement](https://arxiv.org//abs/2505.12060)

	Peng Ding, Jun Kuang, Zongyu Wang, Xuezhi Cao, Xunliang Cai, Jiajun Chen, Shujian Huang

+ [Do different prompting methods yield a common task representation in language models?](https://arxiv.org//abs/2505.12075)

	Guy Davidson, Todd M. Gureckis, Brenden M. Lake, Adina Williams

+ [Model Merging in Pre-training of Large Language Models](https://arxiv.org//abs/2505.12082)

	Yunshui Li, Yiyuan Ma, Shen Yan, Chaoyi Zhang, Jing Liu, Jianqiao Lu, Ziwen Xu, Mengzhao Chen, Minrui Wang, Shiyi Zhan, Jin Ma, Xunhao Lai, Yao Luo, Xingyan Bin, Hongbin Ren, Mingji Han, Wenhao Hao, Bairen Yi, LingJun Liu, Bole Ma, Xiaoying Jia, Zhou Xun, Liang Xiang, Yonghui Wu

+ [Video-SafetyBench: A Benchmark for Safety Evaluation of Video LVLMs](https://arxiv.org//abs/2505.11842)

	Xuannan Liu, Zekun Li, Zheqi He, Peipei Li, Shuhan Xia, Xing Cui, Huaibo Huang, Xi Yang, Ran He

+ [J1: Exploring Simple Test-Time Scaling for LLM-as-a-Judge](https://arxiv.org//abs/2505.11875)

	Chi-Min Chan, Chunpu Xu, Jiaming Ji, Zhen Ye, Pengcheng Wen, Chunyang Jiang, Yaodong Yang, Wei Xue, Sirui Han, Yike Guo

+ [Adversarial Robustness for Unified Multi-Modal Encoders via Efficient Calibration](https://arxiv.org//abs/2505.11895)

	Chih-Ting Liao, Bin Ren, Guofeng Mei, Xu Zheng

+ [Are Multimodal Large Language Models Ready for Omnidirectional Spatial Reasoning?](https://arxiv.org//abs/2505.11907)

	Zihao Dongfang, Xu Zheng, Ziqiao Weng, Yuanhuiyi Lyu, Danda Pani Paudel, Luc Van Gool, Kailun Yang, Xuming Hu

+ [MINGLE: Mixtures of Null-Space Gated Low-Rank Experts for Test-Time Continual Model Merging](https://arxiv.org//abs/2505.11883)

	Zihuan Qiu, Yi Xu, Chiyuan He, Fanman Meng, Linfeng Xu, Qingbo Wu, Hongliang Li

+ [LAMP: Extracting Locally Linear Decision Surfaces from LLM World Models](https://arxiv.org//abs/2505.11772)

	Ryan Chen, Youngmin Ko, Zeyu Zhang, Catherine Cho, Sunny Chung, Mauro Giuffré, Dennis L. Shung, Bradly C. Stadie

+ [JULI: Jailbreak Large Language Models by Self-Introspection](https://arxiv.org//abs/2505.11790)

	Jesson Wang, Zhanhao Hu, David Wagner

+ [Reinforcing Multi-Turn Reasoning in LLM Agents via Turn-Level Credit Assignment](https://arxiv.org//abs/2505.11821)

	Siliang Zeng, Quan Wei, William Brown, Oana Frunza, Yuriy Nevmyvaka, Mingyi Hong

+ [Spotlight Your Instructions: Instruction-following with Dynamic Attention Steering](https://arxiv.org//abs/2505.12025)

	Praveen Venkateswaran, Danish Contractor

+ [Transformer learns the cross-task prior and regularization for in-context learning](https://arxiv.org//abs/2505.12138)

	Fei Lu, Yue Yu

+ [Communication-Efficient Hybrid Language Model via Uncertainty-Aware Opportunistic and Compressed Transmission](https://arxiv.org//abs/2505.11788)

	Seungeun Oh, Jinhyuk Kim, Jihong Park, Seung-Woo Ko, Jinho Choi, Tony Q. S. Quek, Seong-Lyun Kim

+ [Benchmarking LLMs in an Embodied Environment for Blue Team Threat Hunting](https://arxiv.org//abs/2505.11901)

	Xiaoqun Liu, Feiyang Yu, Xi Li, Guanhua Yan, Ping Yang, Zhaohan Xi

+ [TechniqueRAG: Retrieval Augmented Generation for Adversarial Technique Annotation in Cyber Threat Intelligence Text](https://arxiv.org//abs/2505.11988)

	Ahmed Lekssays, Utsav Shukla, Husrev Taha Sencar, Md Rizwan Parvez

+ [Induction Head Toxicity Mechanistically Explains Repetition Curse in Large Language Models](https://arxiv.org//abs/2505.13514)

	Shuxun Wang, Qingyu Yin, Chak Tou Leong, Qiang Zhang, Linyi Yang

+ [LoRASuite: Efficient LoRA Adaptation Across Large Language Model Upgrades](https://arxiv.org//abs/2505.13515)

	Yanan Li, Fanxu Meng, Muhan Zhang, Shiai Zhu, Shangguang Wang, Mengwei Xu

+ [HALO: Hierarchical Autonomous Logic-Oriented Orchestration for Multi-Agent LLM Systems](https://arxiv.org//abs/2505.13516)

	Zhipeng Hou, Junyi Tang, Yipeng Wang

+ [Beyond Retrieval: Joint Supervision and Multimodal Document Ranking for Textbook Question Answering](https://arxiv.org//abs/2505.13520)

	Hessa Alawwad, Usman Naseem, Areej Alhothali, Ali Alkhathlan, Amani Jamal

+ [Are LLMs Ready for English Standardized Tests? A Benchmarking and Elicitation Perspective](https://arxiv.org//abs/2505.17056)

	Luoxi Tang, Tharunya Sundar, Shuai Yang, Ankita Patra, Manohar Chippada, Giqi Zhao, Yi Li, Riteng Zhang, Tunan Zhao, Ting Yang, Yuqiao Meng, Weicheng Ma, Zhaohan Xi

+ [DO-RAG: A Domain-Specific QA Framework Using Knowledge Graph-Enhanced Retrieval-Augmented Generation](https://arxiv.org//abs/2505.17058)

	David Osei Opoku, Ming Sheng, Yong Zhang

+ [Mixture of Decoding: An Attention-Inspired Adaptive Decoding Strategy to Mitigate Hallucinations in Large Vision-Language Models](https://arxiv.org//abs/2505.17061)

	Xinlong Chen, Yuanxing Zhang, Qiang Liu, Junfei Wu, Fuzheng Zhang, Tieniu Tan

# 2025-05-16
+ [PoE-World: Compositional World Modeling with Products of Programmatic Experts](https://arxiv.org//abs/2505.10819)

	Wasu Top Piriyakulkij, Yichao Liang, Hao Tang, Adrian Weller, Marta Kryven, Kevin Ellis

+ [Creativity or Brute Force? Using Brainteasers as a Window into the Problem-Solving Abilities of Large Language Models](https://arxiv.org//abs/2505.10844)

	Simeng Han, Stephen Xia, Grant Zhang, Howard Dai, Chen Liu, Lichang Chen, Hoang Huy Nguyen, Hongyuan Mei, Jiayuan Mao, R. Thomas McCoy

+ [Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A Perspective of Probability Theory](https://arxiv.org//abs/2505.10981)

	Yexiang Liu, Zekun Li, Zhi Fang, Nan Xu, Ran He, Tieniu Tan

+ [RAGSynth: Synthetic Data for Robust and Faithful RAG Component Optimization](https://arxiv.org//abs/2505.10989)

	Haiyang Shen, Hang Yan, Zhongshi Xing, Mugeng Liu, Yue Li, Zhiyang Chen, Yuxiang Wang, Jiuzheng Wang, Yun Ma

+ [GuardReasoner-VL: Safeguarding VLMs via Reinforced Reasoning](https://arxiv.org//abs/2505.11049)

	Yue Liu, Shengfang Zhai, Mingzhe Du, Yulin Chen, Tri Cao, Hongcheng Gao, Cheng Wang, Xinfeng Li, Kun Wang, Junfeng Fang, Jiaheng Zhang, Bryan Hooi

+ [Think Twice Before You Act: Enhancing Agent Behavioral Safety with Thought Correction](https://arxiv.org//abs/2505.11063)

	Changyue Jiang, Xudong Pan, Min Yang

+ [Group Think: Multiple Concurrent Reasoning Agents Collaborating at Token Level Granularity](https://arxiv.org//abs/2505.11107)

	Chan-Jan Hsu, Davide Buffelli, Jamie McGowan, Feng-Ting Liao, Yi-Chang Chen, Sattar Vakili, Da-shan Shiu

+ [Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining](https://arxiv.org//abs/2505.11122)

	Yu Shi, Yitong Duan, Jian Li

+ [Can Global XAI Methods Reveal Injected Bias in LLMs? SHAP vs Rule Extraction vs RuleSHAP](https://arxiv.org//abs/2505.11189)

	Francesco Sovrano

+ [Is PRM Necessary? Problem-Solving RL Implicitly Induces PRM Capability in LLMs](https://arxiv.org//abs/2505.11227)

	Zhangying Feng, Qianglong Chen, Ning Lu, Yongqian Li, Siqi Cheng, Shuangmu Peng, Duyu Tang, Shengcai Liu, Zhirui Zhang

+ [LD-Scene: LLM-Guided Diffusion for Controllable Generation of Adversarial Safety-Critical Driving Scenarios](https://arxiv.org//abs/2505.11247)

	Mingxing Peng, Yuting Xie, Xusen Guo, Ruoyu Yao, Hai Yang, Jun Ma

+ [SelfBudgeter: Adaptive Token Allocation for Efficient LLM Reasoning](https://arxiv.org//abs/2505.11274)

	Zheng Li, Qingxiu Dong, Jingyuan Ma, Di Zhang, Zhifang Sui

+ [A Systematic Analysis of Base Model Choice for Reward Modeling](https://arxiv.org//abs/2505.10775)

	Kian Ahrabian, Pegah Jandaghi, Negar Mokhberian, Sai Praneeth Karimireddy, Jay Pujara

+ [Enhancing Low-Resource Minority Language Translation with LLMs and Retrieval-Augmented Generation for Cultural Nuances](https://arxiv.org//abs/2505.10829)

	Chen-Chi Chang, Chong-Fu Li, Chu-Hsuan Lee, Hung-Shin Lee

+ [Learning When to Think: Shaping Adaptive Reasoning in R1-Style Models via Multi-Stage RL](https://arxiv.org//abs/2505.10832)

	Songjun Tu, Jiahao Lin, Qichao Zhang, Xiangyu Tian, Linjing Li, Xiangyuan Lan, Dongbin Zhao

+ [Ready2Unlearn: A Learning-Time Approach for Preparing Models with Future Unlearning Readiness](https://arxiv.org//abs/2505.10845)

	Hanyu Duan, Yi Yang, Ahmed Abbasi, Kar Yan Tam

+ [Improve Rule Retrieval and Reasoning with Self-Induction and Relevance ReEstimate](https://arxiv.org//abs/2505.10870)

	Ziyang Huang, Wangtao Sun, Jun Zhao, Kang Liu

+ [REI-Bench: Can Embodied Agents Understand Vague Human Instructions in Task Planning?](https://arxiv.org//abs/2505.10872)

	Chenxi Jiang, Chuhao Zhou, Jianfei Yang

+ [Explain What You Mean: Intent Augmented Knowledge Graph Recommender Built With LLM](https://arxiv.org//abs/2505.10900)

	Wenqing Zheng, Noah Fatsi, Daniel Barcklow, Dmitri Kalaev, Steven Yao, Owen Reinert, C. Bayan Bruss, Daniele Rosa

+ [Vaiage: A Multi-Agent Solution to Personalized Travel Planning](https://arxiv.org//abs/2505.10922)

	Binwen Liu, Jiexi Ge, Jiamin Wang

+ [A Survey on the Safety and Security Threats of Computer-Using Agents: JARVIS or Ultron?](https://arxiv.org//abs/2505.10924)

	Ada Chen, Yongjiang Wu, Junyuan Zhang, Shu Yang, Jen-tse Huang, Kun Wang, Wenxuan Wang, Shuai Wang

+ [Reasoning with OmniThought: A Large CoT Dataset with Verbosity and Cognitive Difficulty Annotations](https://arxiv.org//abs/2505.10937)

	Wenrui Cai, Chengyu Wang, Junbing Yan, Jun Huang, Xiangzhong Fang

+ [GenKnowSub: Improving Modularity and Reusability of LLMs through General Knowledge Subtraction](https://arxiv.org//abs/2505.10939)

	Mohammadtaha Bagherifard, Sahar Rajabi, Ali Edalat, Yadollah Yaghoobzadeh

+ [Let the Trial Begin: A Mock-Court Approach to Vulnerability Detection using LLM-Based Agents](https://arxiv.org//abs/2505.10961)

	Ratnadira Widyasari, Martin Weyssow, Ivana Clairine Irsan, Han Wei Ang, Frank Liauw, Eng Lieh Ouh, Lwin Khin Shar, Hong Jin Kang, David Lo

+ [Group-in-Group Policy Optimization for LLM Agent Training](https://arxiv.org//abs/2505.10978)

	Lang Feng, Zhenghai Xue, Tingcong Liu, Bo An

+ [Illusion or Algorithm? Investigating Memorization, Emergence, and Symbolic Processing in In-Context Learning](https://arxiv.org//abs/2505.11004)

	Jingcheng Niu, Subhabrata Dutta, Ahmed Elshabrawy, Harish Tayyar Madabushi, Iryna Gurevych

+ [Review-Instruct: A Review-Driven Multi-Turn Conversations Generation Method for Large Language Models](https://arxiv.org//abs/2505.11010)

	Jiangxu Wu, Cong Wang, TianHuang Su, Jun Yang, Haozhi Lin, Chao Zhang, Ming Peng, Kai Shi, SongPan Yang, BinQing Pan, ZiXian Li, Ni Yang, ZhenYu Yang

+ [Humans expect rationality and cooperation from LLM opponents in strategic games](https://arxiv.org//abs/2505.11011)

	Darija Barak, Miguel Costa-Gomes

+ [BLEUBERI: BLEU is a surprisingly effective reward for instruction following](https://arxiv.org//abs/2505.11080)

	Yapei Chang, Yekyung Kim, Michael Krumdick, Amir Zadeh, Chuan Li, Chris Tanner, Mohit Iyyer

+ [Scaling Reasoning can Improve Factuality in Large Language Models](https://arxiv.org//abs/2505.11140)

	Mike Zhang, Johannes Bjerva, Russa Biswas

+ [Human-Aligned Bench: Fine-Grained Assessment of Reasoning Ability in MLLMs vs. Humans](https://arxiv.org//abs/2505.11141)

	Yansheng Qiu, Li Xiao, Zhaopan Xu, Pengfei Zhou, Zheng Wang, Kaipeng Zhang

+ [SoLoPO: Unlocking Long-Context Capabilities in LLMs via Short-to-Long Preference Optimization](https://arxiv.org//abs/2505.11166)

	Huashan Sun, Shengyi Liao, Yansen Han, Yu Bai, Yang Gao, Cheng Fu, Weizhou Shen, Fanqi Wan, Ming Yan, Ji Zhang, Fei Huang

+ [Semantic Caching of Contextual Summaries for Efficient Question-Answering with Language Models](https://arxiv.org//abs/2505.11271)

	Camille Couturier, Spyros Mastorakis, Haiying Shen, Saravan Rajmohan, Victor Rühle

+ [Search and Refine During Think: Autonomous Retrieval-Augmented Reasoning of LLMs](https://arxiv.org//abs/2505.11277)

	Yaorui Shi, Shihan Li, Chang Wu, Zhiyuan Liu, Junfeng Fang, Hengxing Cai, An Zhang, Xiang Wang

+ [Phare: A Safety Probe for Large Language Models](https://arxiv.org//abs/2505.11365)

	Pierre Le Jeune, Benoît Malésieux, Weixuan Xiao, Matteo Dora

+ [EdgeWisePersona: A Dataset for On-Device User Profiling from Natural Language Interactions](https://arxiv.org//abs/2505.11417)

	Patryk Bartkowiak, Michal Podstawski

+ [LLMs unlock new paths to monetizing exploits](https://arxiv.org//abs/2505.11449)

	Nicholas Carlini, Milad Nasr, Edoardo Debenedetti, Barry Wang, Christopher A. Choquette-Choo, Daphne Ippolito, Florian Tramèr, Matthew Jagielski

+ [Disentangling Reasoning and Knowledge in Medical Large Language Models](https://arxiv.org//abs/2505.11462)

	Rahul Thapa, Qingyang Wu, Kevin Wu, Harrison Zhang, Angela Zhang, Eric Wu, Haotian Ye, Suhana Bedi, Nevin Aresh, Joseph Boen, Shriya Reddy, Ben Athiwaratkun, Shuaiwen Leon Song, James Zou

+ [HelpSteer3-Preference: Open Human-Annotated Preference Data across Diverse Tasks and Languages](https://arxiv.org//abs/2505.11475)

	Zhilin Wang, Jiaqi Zeng, Olivier Delalleau, Hoo-Chang Shin, Felipe Soares, Alexander Bukharin, Ellie Evans, Yi Dong, Oleksii Kuchaiev

+ [Ranked Voting based Self-Consistency of Large Language Models](https://arxiv.org//abs/2505.10772)

	Weiqin Wang, Yile Wang, Hui Huang

+ [Finetune-RAG: Fine-Tuning Language Models to Resist Hallucination in Retrieval-Augmented Generation](https://arxiv.org//abs/2505.10792)

	Zhan Peng Lee, Andre Lin, Calvin Tan

+ [Have Multimodal Large Language Models (MLLMs) Really Learned to Tell the Time on Analog Clocks?](https://arxiv.org//abs/2505.10862)

	Tairan Fu, Miguel González, Javier Conde, Elena Merino-Gómez, Pedro Reviriego

+ [Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents](https://arxiv.org//abs/2505.10936)

	Jiaxing Zhao, Hongbin Xie, Yuzhen Lei, Xuan Song, Zhuoran Shi, Lianxin Li, Shuangxue Liu, Haoran Zhang

+ [Accurate KV Cache Quantization with Outlier Tokens Tracing](https://arxiv.org//abs/2505.10938)

	Yi Su, Yuechi Zhou, Quantong Qiu, Juntao Li, Qingrong Xia, Ping Li, Xinyu Duan, Zhefeng Wang, Min Zhang

+ [The Way We Prompt: Conceptual Blending, Neural Dynamics, and Prompt-Induced Transitions in LLMs](https://arxiv.org//abs/2505.10948)

	Makoto Sato

+ [OntoURL: A Benchmark for Evaluating Large Language Models on Symbolic Ontological Understanding, Reasoning and Learning](https://arxiv.org//abs/2505.11031)

	Xiao Zhang, Huiyuan Lai, Qianru Meng, Johan Bos

+ [HAPO: Training Language Models to Reason Concisely via History-Aware Policy Optimization](https://arxiv.org//abs/2505.11225)

	Chengyu Huang, Zhengxin Zhang, Claire Cardie

+ [XtraGPT: LLMs for Human-AI Collaboration on Controllable Academic Paper Revision](https://arxiv.org//abs/2505.11336)

	Nuo Chen, Andre Lin HuiKai, Jiaying Wu, Junyi Hou, Zining Zhang, Qian Wang, Xidong Wang, Bingsheng He

+ [LegoSLM: Connecting LLM with Speech Encoder using CTC Posteriors](https://arxiv.org//abs/2505.11352)

	Rao Ma, Tongzhou Chen, Kartik Audhkhasi, Bhuvana Ramabhadran

+ [GuideBench: Benchmarking Domain-Oriented Guideline Following for LLM Agents](https://arxiv.org//abs/2505.11368)

	Lingxiao Diao, Xinyue Xu, Wanxuan Sun, Cheng Yang, Zhuosheng Zhang

+ [CARES: Comprehensive Evaluation of Safety and Adversarial Robustness in Medical LLMs](https://arxiv.org//abs/2505.11413)

	Sijia Chen, Xiaomin Li, Mengxue Zhang, Eric Hanchen Jiang, Qingcheng Zeng, Chen-Hsiang Yu

+ [When Thinking Fails: The Pitfalls of Reasoning for Instruction-Following in LLMs](https://arxiv.org//abs/2505.11423)

	Xiaomin Li, Zhou Yu, Zhiwei Zhang, Xupeng Chen, Ziji Zhang, Yingying Zhuang, Narayanan Sadagopan, Anurag Beniwal

+ [SoftCoT++: Test-Time Scaling with Soft Chain-of-Thought Reasoning](https://arxiv.org//abs/2505.11484)

	Yige Xu, Xu Guo, Zhiwei Zeng, Chunyan Miao

+ [LARGO: Latent Adversarial Reflection through Gradient Optimization for Jailbreaking LLMs](https://arxiv.org//abs/2505.10838)

	Ran Li, Hao Wang, Chengzhi Mao

+ [MPMA: Preference Manipulation Attack Against Model Context Protocol](https://arxiv.org//abs/2505.11154)

	Zihan Wang, Hongwei Li, Rui Zhang, Yu Liu, Wenbo Jiang, Wenshu Fan, Qingchuan Zhao, Guowen Xu

+ [On Next-Token Prediction in LLMs: How End Goals Determine the Consistency of Decoding Algorithms](https://arxiv.org//abs/2505.11183)

	Jacob Trauger, Ambuj Tewari

+ [EmotionHallucer: Evaluating Emotion Hallucinations in Multimodal Large Language Models](https://arxiv.org//abs/2505.11405)

	Bohao Xing, Xin Liu, Guoying Zhao, Chengyu Liu, Xiaolan Fu, Heikki Kälviäinen

+ [VISTA: Enhancing Vision-Text Alignment in MLLMs via Cross-Modal Mutual Information Maximization](https://arxiv.org//abs/2505.10917)

	Mingxiao Li, Na Su, Fang Qu, Zhizhou Zhong, Ziyang Chen, Zhaopeng Tu, Xiaolong Li

+ [Distilled Circuits: A Mechanistic Study of Internal Restructuring in Knowledge Distillation](https://arxiv.org//abs/2505.10822)

	Reilly Haskins, Benjamin Adams

+ [MergeBench: A Benchmark for Merging Domain-Specialized LLMs](https://arxiv.org//abs/2505.10833)

	Yifei He, Siqi Zeng, Yuzheng Hu, Rui Yang, Tong Zhang, Han Zhao

+ [AutoRAN: Weak-to-Strong Jailbreaking of Large Reasoning Models](https://arxiv.org//abs/2505.10846)

	Jiacheng Liang, Tanqiu Jiang, Yuhui Wang, Rongyi Zhu, Fenglong Ma, Ting Wang

+ [On DeepSeekMoE: Statistical Benefits of Shared Experts and Normalized Sigmoid Gating](https://arxiv.org//abs/2505.10860)

	Huy Nguyen, Thong T. Doan, Quang Pham, Nghi D. Q. Bui, Nhat Ho, Alessandro Rinaldo

+ [Improving the Data-efficiency of Reinforcement Learning by Warm-starting with LLM](https://arxiv.org//abs/2505.10861)

	Thang Duong, Minglai Yang, Chicheng Zhang

+ [Multi-Objective Preference Optimization: Improving Human Alignment of Generative Models](https://arxiv.org//abs/2505.10892)

	Akhil Agnihotri, Rahul Jain, Deepak Ramachandran, Zheng Wen

+ [SubGCache: Accelerating Graph-based RAG with Subgraph-level KV Cache](https://arxiv.org//abs/2505.10951)

	Qiuyu Zhu, Liang Zhang, Qianxiong Xu, Cheng Long, Jie Zhang

+ [ShiQ: Bringing back Bellman to LLMs](https://arxiv.org//abs/2505.11081)

	Pierre Clavier, Nathan Grinsztajn, Raphael Avalos, Yannis Flet-Berliac, Irem Ergun, Omar D. Domingues, Eugene Tarassov, Olivier Pietquin, Pierre H. Richemond, Florian Strub, Matthieu Geist

+ [Gaussian Weight Sampling for Scalable, Efficient and Stable Pseudo-Quantization Training](https://arxiv.org//abs/2505.11170)

	Myeonghwan Ahn, Sungjoo Yoo

+ [Memory-Efficient Orthogonal Fine-Tuning with Principal Subspace Adaptation](https://arxiv.org//abs/2505.11235)

	Fei Wu, Jia Hu, Geyong Min, Shiqiang Wang

+ [Delta Attention: Fast and Accurate Sparse Attention Inference by Delta Correction](https://arxiv.org//abs/2505.11254)

	Jeffrey Willette, Heejun Lee, Sung Ju Hwang

+ [Is Grokking a Computational Glass Relaxation?](https://arxiv.org//abs/2505.11411)

	Xiaotian Zhang, Yue Shang, Entao Yang, Ge Zhang

+ [MoE-CAP: Benchmarking Cost, Accuracy and Performance of Sparse Mixture-of-Experts Systems](https://arxiv.org//abs/2505.11415)

	Yinsicheng Jiang, Yao Fu, Yeqi Huang, Ping Nie, Zhan Lu, Leyang Xue, Congjie He, Man-Kit Sit, Jilong Xue, Li Dong, Ziming Miao, Dayou Du, Tairan Xu, Kai Zou, Edoardo Ponti, Luo Mai

+ [MegaScale-MoE: Large-Scale Communication-Efficient Training of Mixture-of-Experts Models in Production](https://arxiv.org//abs/2505.11432)

	Chao Jin, Ziheng Jiang, Zhihao Bai, Zheng Zhong, Juncai Liu, Xiang Li, Ningxin Zheng, Xi Wang, Cong Xie, Wen Heng, Yiyuan Ma, Wenlei Bao, Size Zheng, Yanghua Peng, Haibin Lin, Xuanzhe Liu, Xin Jin, Xin Liu

+ [TokenWeave: Efficient Compute-Communication Overlap for Distributed LLM Inference](https://arxiv.org//abs/2505.11329)

	Raja Gond, Nipun Kwatra, Ramachandran Ramjee

+ [ProxyPrompt: Securing System Prompts against Prompt Extraction Attacks](https://arxiv.org//abs/2505.11459)

	Zhixiong Zhuang, Maria-Irina Nicolae, Hui-Po Wang, Mario Fritz

+ [LLM Agents Are Hypersensitive to Nudges](https://arxiv.org//abs/2505.11584)

	Manuel Cherep, Pattie Maes, Nikhil Singh

+ [Probing the Vulnerability of Large Language Models to Polysemantic Interventions](https://arxiv.org//abs/2505.11611)

	Bofan Gong, Shiyang Lai, Dawn Song

+ [Using Reinforcement Learning to Train Large Language Models to Explain Human Decisions](https://arxiv.org//abs/2505.11614)

	Jian-Qiao Zhu, Hanbo Xie, Dilip Arumugam, Robert C. Wilson, Thomas L. Griffiths

+ [Benchmarking Spatiotemporal Reasoning in LLMs and Reasoning Models: Capabilities and Challenges](https://arxiv.org//abs/2505.11618)

	Pengrui Quan, Brian Wang, Kang Yang, Liying Han, Mani Srivastava

+ [DMN-Guided Prompting: A Low-Code Framework for Controlling LLM Behavior](https://arxiv.org//abs/2505.11701)

	Shaghayegh Abedi, Amin Jalali

+ [Rethinking Optimal Verification Granularity for Compute-Efficient Test-Time Scaling](https://arxiv.org//abs/2505.11730)

	Hao Mark Chen, Guanxi Lu, Yasuyuki Okoshi, Zhiwen Mo, Masato Motomura, Hongxiang Fan

+ [ACSE-Eval: Can LLMs threat model real-world cloud infrastructure?](https://arxiv.org//abs/2505.11565)

	Sarthak Munshi, Swapnil Pathak, Sonam Ghatode, Thenuga Priyadarshini, Dhivya Chandramouleeswaran, Ashutosh Rana

+ [InfiJanice: Joint Analysis and In-situ Correction Engine for Quantization-Induced Math Degradation in Large Language Models](https://arxiv.org//abs/2505.11574)

	Zhen Li, Yupeng Su, Songmiao Wang, Runming Yang, Congkai Xie, Aofan Liu, Ming Li, Jiannong Cao, Yuan Xie, Ngai Wong, Hongxia Yang

+ [Concept-Guided Interpretability via Neural Chunking](https://arxiv.org//abs/2505.11576)

	Shuchen Wu, Stephan Alaniz, Shyamgopal Karthik, Peter Dayan, Eric Schulz, Zeynep Akata

+ [The Ripple Effect: On Unforeseen Complications of Backdoor Attacks](https://arxiv.org//abs/2505.11586)

	Rui Zhang, Yun Shen, Hongwei Li, Wenbo Jiang, Hanxiao Chen, Yuan Zhang, Guowen Xu, Yang Zhang

+ [SageAttention3: Microscaling FP4 Attention for Inference and An Exploration of 8-Bit Training](https://arxiv.org//abs/2505.11594)

	Jintao Zhang, Jia Wei, Pengle Zhang, Xiaoming Xu, Haofeng Huang, Haoxu Wang, Kai Jiang, Jun Zhu, Jianfei Chen

+ [Spectral Policy Optimization: Coloring your Incorrect Reasoning in GRPO](https://arxiv.org//abs/2505.11595)

	Peter Chen, Xiaopeng Li, Ziniu Li, Xi Chen, Tianyi Lin

+ [Steering Risk Preferences in Large Language Models by Aligning Behavioral and Neural Representations](https://arxiv.org//abs/2505.11615)

	Jian-Qiao Zhu, Haijiang Yan, Thomas L. Griffiths

+ [Chatting with Papers: A Hybrid Approach Using LLMs and Knowledge Graphs](https://arxiv.org//abs/2505.11633)

	Vyacheslav Tykhonov, Han Yang, Philipp Mayr, Jetze Touber, Andrea Scharnhorst

+ [PeerGuard: Defending Multi-Agent Systems Against Backdoor Attacks Through Mutual Reasoning](https://arxiv.org//abs/2505.11642)

	Falong Fan, Xi Li

+ [EnvInjection: Environmental Prompt Injection Attack to Multi-modal Web Agents](https://arxiv.org//abs/2505.11717)

	Xilong Wang, John Bloch, Zedian Shao, Yuepeng Hu, Shuyan Zhou, Neil Zhenqiang Gong

+ [Efficient Uncertainty Estimation via Distillation of Bayesian Large Language Models](https://arxiv.org//abs/2505.11731)

	Harshil Vejendla, Haizhou Shi, Yibin Wang, Tunyu Zhang, Huan Zhang, Hao Wang

+ [Token-Level Uncertainty Estimation for Large Language Model Reasoning](https://arxiv.org//abs/2505.11737)

	Tunyu Zhang, Haizhou Shi, Yibin Wang, Hengyi Wang, Xiaoxiao He, Zhuowei Li, Haoxian Chen, Ligong Han, Kai Xu, Huan Zhang, Dimitris Metaxas, Hao Wang

+ [ZeroTuning: Unlocking the Initial Token's Power to Enhance Large Language Models Without Training](https://arxiv.org//abs/2505.11739)

	Feijiang Han, Xiaodong Yu, Jianheng Tang, Lyle Ungar

+ [Cloud-Based AI Systems: Leveraging Large Language Models for Intelligent Fault Detection and Autonomous Self-Healing](https://arxiv.org//abs/2505.11743)

	Cheng Ji, Huaiying Luo

+ [Talk to Your Slides: Efficient Slide Editing Agent with Large Language Models](https://arxiv.org//abs/2505.11604)

	Kyudan Jung, Hojun Cho, Jooyeol Yun, Jaehyeok Jang, Jagul Choo

+ [MedGUIDE: Benchmarking Clinical Decision-Making in Large Language Models](https://arxiv.org//abs/2505.11613)

	Xiaomin Li, Mingye Gao, Yuexing Hao, Taoran Li, Guangya Wan, Zihan Wang, Yijun Wang

+ [THELMA: Task Based Holistic Evaluation of Large Language Model Applications-RAG Question Answering](https://arxiv.org//abs/2505.11626)

	Udita Patel, Rutu Mulkar, Jay Roberts, Cibi Chakravarthy Senthilkumar, Sujay Gandhi, Xiaofei Zheng, Naumaan Nayyar, Rafael Castrillo

+ [Can an Easy-to-Hard Curriculum Make Reasoning Emerge in Small Language Models? Evidence from a Four-Stage Curriculum on GPT-2](https://arxiv.org//abs/2505.11643)

	Xiang Fu

+ [Ambiguity Resolution in Text-to-Structured Data Mapping](https://arxiv.org//abs/2505.11679)

	Zhibo Hu, Chen Wang, Yanfeng Shu, Hye-Young Paik, Liming Zhu

+ [MedCaseReasoning: Evaluating and learning diagnostic reasoning from clinical case reports](https://arxiv.org//abs/2505.11733)

	Kevin Wu, Eric Wu, Rahul Thapa, Kevin Wei, Angela Zhang, Arvind Suresh, Jacqueline J. Tao, Min Woo Sun, Alejandro Lozano, James Zou

+ [Masking in Multi-hop QA: An Analysis of How Language Models Perform with Context Permutation](https://arxiv.org//abs/2505.11754)

	Wenyu Huang, Pavlos Vougiouklis, Mirella Lapata, Jeff Z. Pan

+ [Reinforcement Learning Finetunes Small Subnetworks in Large Language Models](https://arxiv.org//abs/2505.11711)

	Sagnik Mukherjee, Lifan Yuan, Dilek Hakkani-Tur, Hao Peng

+ [Can AI Freelancers Compete? Benchmarking Earnings, Reliability, and Task Success at Scale](https://arxiv.org//abs/2505.13511)

	David Noever, Forrest McKee

+ [Noise Injection Systemically Degrades Large Language Model Safety Guardrails](https://arxiv.org//abs/2505.13500)

	Prithviraj Singh Shahani, Matthias Scheutz

+ [An agentic system with reinforcement-learned subsystem improvements for parsing form-like documents](https://arxiv.org//abs/2505.13504)

	Ayesha Amjad, Saurav Sthapit, Tahir Qasim Syed

+ [EcoSafeRAG: Efficient Security through Context Analysis in Retrieval-Augmented Generation](https://arxiv.org//abs/2505.13506)

	Ruobing Yao, Yifei Zhang, Shuang Song, Neng Gao, Chenyang Tu

+ [Time-R1: Towards Comprehensive Temporal Reasoning in LLMs](https://arxiv.org//abs/2505.13508)

	Zijia Liu, Peixuan Han, Haofei Yu, Haoru Li, Jiaxuan You

+ [Gender and Positional Biases in LLM-Based Hiring Decisions: Evidence from Comparative CV/Résumé Evaluations](https://arxiv.org//abs/2505.17049)

	David Rozado

+ [Embedding-to-Prefix: Parameter-Efficient Personalization for Pre-Trained Large Language Models](https://arxiv.org//abs/2505.17051)

	Bernd Huber, Ghazal Fazelnia, Andreas Damianou, Sebastian Peleato, Max Lefarov, Praveen Ravichandran, Marco De Nadai, Mounia Lalmas-Roellke, Paul N. Bennett

+ [SpecEdge: Scalable Edge-Assisted Serving Framework for Interactive LLMs](https://arxiv.org//abs/2505.17052)

	Jinwoo Park, Seunggeun Cho, Dongsu Han

# 2025-05-15
+ [Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents](https://arxiv.org//abs/2505.09970)

	Mrinal Rawat, Ambuje Gupta, Rushil Goomer, Alessandro Di Bari, Neha Gupta, Roberto Pieraccini

+ [Leveraging Graph Retrieval-Augmented Generation to Support Learners' Understanding of Knowledge Concepts in MOOCs](https://arxiv.org//abs/2505.10074)

	Mohamed Abdelmagied, Mohamed Amine Chatti, Shoeb Joarder, Qurat Ul Ain, Rawaa Alatrash

+ [AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenge](https://arxiv.org//abs/2505.10468)

	Ranjan Sapkota, Konstantinos I. Roumeliotis, Manoj Karkee

+ [Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models](https://arxiv.org//abs/2505.10543)

	Annie Wong, Thomas Bäck, Aske Plaat, Niki van Stein, Anna V. Kononova

+ [Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks](https://arxiv.org//abs/2505.09901)

	Ziyuan Zhang, Darcy Wang, Ningyuan Chen, Rodrigo Mansur, Vahid Sarhangian

+ [Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph](https://arxiv.org//abs/2505.09945)

	Deeksha Prahlad, Chanhee Lee, Dongha Kim, Hokeun Kim

+ [Analysing Safety Risks in LLMs Fine-Tuned with Pseudo-Malicious Cyber Security Data](https://arxiv.org//abs/2505.09974)

	Adel ElZemity, Budi Arief, Shujun Li

+ [Dark LLMs: The Growing Threat of Unaligned AI Models](https://arxiv.org//abs/2505.10066)

	Michael Fire, Yitzhak Elbazis, Adi Wasenstein, Lior Rokach

+ [The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think](https://arxiv.org//abs/2505.10185)

	Seongyun Lee, Seungone Kim, Minju Seo, Yongrae Jo, Dongyoung Go, Hyeonbin Hwang, Jinho Park, Xiang Yue, Sean Welleck, Graham Neubig, Moontae Lee, Minjoon Seo

+ [Do LLMs Memorize Recommendation Datasets? A Preliminary Study on MovieLens-1M](https://arxiv.org//abs/2505.10212)

	Dario Di Palma, Felice Antonio Merra, Maurizio Sfilio, Vito Walter Anelli, Fedelucio Narducci, Tommaso Di Noia

+ [Comparing LLM Text Annotation Skills: A Study on Human Rights Violations in Social Media Data](https://arxiv.org//abs/2505.10260)

	Poli Apollinaire Nemkova, Solomon Ubani, Mark V. Albert

+ [Private Transformer Inference in MLaaS: A Survey](https://arxiv.org//abs/2505.10315)

	Yang Li, Xinyu Zhou, Yitong Wang, Liangxin Qian, Jun Zhao

+ [J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning](https://arxiv.org//abs/2505.10320)

	Chenxi Whitehouse, Tianlu Wang, Ping Yu, Xian Li, Jason Weston, Ilia Kulikov, Swarnadeep Saha

+ [AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents](https://arxiv.org//abs/2505.10321)

	Julius Henke

+ [FactsR: A Safer Method for Producing High Quality Healthcare Documentation](https://arxiv.org//abs/2505.10360)

	Victor Petrén Bach Hansen, Lasse Krogsbøll, Jonas Lyngsø, Mathias Baltzersen, Andreas Motzfeldt, Kevin Pelgrims, Lars Maaløe

+ [Are Large Language Models Robust in Understanding Code Against Semantics-Preserving Mutations?](https://arxiv.org//abs/2505.10443)

	Pedro Orvalho, Marta Kwiatkowska

+ [Superposition Yields Robust Neural Scaling](https://arxiv.org//abs/2505.10465)

	Yizhou liu, Ziming Liu, Jeff Gore

+ [Multi-Token Prediction Needs Registers](https://arxiv.org//abs/2505.10518)

	Anastasios Gerontopoulos, Spyros Gidaris, Nikos Komodakis

+ [Real-Time Out-of-Distribution Failure Prevention via Multi-Modal Reasoning](https://arxiv.org//abs/2505.10547)

	Milan Ganai, Rohan Sinha, Christopher Agia, Daniel Morton, Marco Pavone

+ [From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models](https://arxiv.org//abs/2505.09924)

	Yidan Wang, Yubing Ren, Yanan Cao, Binxing Fang

+ [Rethinking Prompt Optimizers: From Prompt Merits to Optimization](https://arxiv.org//abs/2505.09930)

	Zixiao Zhu, Hanzhang Zhou, Zijian Feng, Tianjiao Li, Chua Jia Jim Deryl, Mak Lee Onn, Gee Wah Ng, Kezhi Mao

+ [DIF: A Framework for Benchmarking and Verifying Implicit Bias in LLMs](https://arxiv.org//abs/2505.10013)

	Lake Yin, Fan Huang

+ [CAFE: Retrieval Head-based Coarse-to-Fine Information Seeking to Enhance Multi-Document QA Capability](https://arxiv.org//abs/2505.10063)

	Han Peng, Jinhao Jiang, Zican Dong, Wayne Xin Zhao, Lei Fang

+ [Designing and Contextualising Probes for African Languages](https://arxiv.org//abs/2505.10081)

	Wisdom Aduah, Francois Meyer

+ [XRAG: Cross-lingual Retrieval-Augmented Generation](https://arxiv.org//abs/2505.10089)

	Wei Liu, Sony Trenous, Leonardo F. R. Ribeiro, Bill Byrne, Felix Hieber

+ [What Does Neuro Mean to Cardio? Investigating the Role of Clinical Specialty Data in Medical LLMs](https://arxiv.org//abs/2505.10113)

	Xinlan Yan, Di Wu, Yibin Lei, Christof Monz, Iacer Calixto

+ [GE-Chat: A Graph Enhanced RAG Framework for Evidential Response Generation of LLMs](https://arxiv.org//abs/2505.10143)

	Longchao Da, Parth Mitesh Shah, Kuan-Ru Liou, Jiaxing Zhang, Hua Wei

+ [Mining Hidden Thoughts from Texts: Evaluating Continual Pretraining with Synthetic Data for LLM Reasoning](https://arxiv.org//abs/2505.10182)

	Yoichi Ishibashi, Taro Yano, Masafumi Oyamada

+ [VQ-Logits: Compressing the Output Bottleneck of Large Language Models via Vector Quantized Logits](https://arxiv.org//abs/2505.10202)

	Jintian Shao, Hongyi Huang, Jiayi Wu, YiMing Cheng, ZhiYu Wu, You Shan, MingKai Zheng

+ [RAIDEN-R1: Improving Role-awareness of LLMs via GRPO with Verifiable Reward](https://arxiv.org//abs/2505.10218)

	Zongsheng Wang, Kaili Sun, Bowen Wu, Qun Yu, Ying Li, Baoxun Wang

+ [Hierarchical Document Refinement for Long-context Retrieval-augmented Generation](https://arxiv.org//abs/2505.10413)

	Jiajie Jin, Xiaoxi Li, Guanting Dong, Yuyao Zhang, Yutao Zhu, Yongkang Wu, Zhonghua Li, Qi Ye, Zhicheng Dou

+ [CL-RAG: Bridging the Gap in Retrieval-Augmented Generation with Curriculum Learning](https://arxiv.org//abs/2505.10493)

	Shaohan Wang, Licheng Zhang, Zheren Fu, Zhendong Mao

+ [Can You Really Trust Code Copilots? Evaluating Large Language Models from a Code Security Perspective](https://arxiv.org//abs/2505.10494)

	Yutao Mou, Xiao Deng, Yuxiao Luo, Shikun Zhang, Wei Ye

+ [WorldPM: Scaling Human Preference Modeling](https://arxiv.org//abs/2505.10527)

	Binghai Wang, Runji Lin, Keming Lu, Le Yu, Zhenru Zhang, Fei Huang, Chujie Zheng, Kai Dang, Yang Fan, Xingzhang Ren, An Yang, Binyuan Hui, Dayiheng Liu, Tao Gui, Qi Zhang, Xuanjing Huang, Yu-Gang Jiang, Bowen Yu, Jingren Zhou, Junyang Lin

+ [Beyond 'Aha!': Toward Systematic Meta-Abilities Alignment in Large Reasoning Models](https://arxiv.org//abs/2505.10554)

	Zhiyuan Hu, Yibo Wang, Hanze Dong, Yuhui Xu, Amrita Saha, Caiming Xiong, Bryan Hooi, Junnan Li

+ [PIG: Privacy Jailbreak Attack on LLMs via Gradient-based Iterative In-Context Optimization](https://arxiv.org//abs/2505.09921)

	Yidan Wang, Yanan Cao, Yubing Ren, Fang Fang, Zheng Lin, Binxing Fang

+ [Parallel Scaling Law for Language Models](https://arxiv.org//abs/2505.10475)

	Mouxiang Chen, Binyuan Hui, Zeyu Cui, Jiaxi Yang, Dayiheng Liu, Jianling Sun, Junyang Lin, Zhongxin Liu

+ [RouteNator: A Router-Based Multi-Modal Architecture for Generating Synthetic Training Data for Function Calling LLMs](https://arxiv.org//abs/2505.10495)

	Vibha Belavadi, Tushar Vatsa, Dewang Sultania, Suhas Suresha, Ishita Verma, Cheng Chen, Tracy Holloway King, Michael Friedrich

+ [Exploring Implicit Visual Misunderstandings in Multimodal Large Language Models through Attention Analysis](https://arxiv.org//abs/2505.10541)

	Pengfei Wang, Guohai Xu, Weinong Wang, Junjie Yang, Jie Lou, Yunhua Xue

+ [ImagineBench: Evaluating Reinforcement Learning with Large Language Model Rollouts](https://arxiv.org//abs/2505.10010)

	Jing-Cheng Pang, Kaiyuan Li, Yidi Wang, Si-Hang Yang, Shengyi Jiang, Yang Yu

+ [Rethinking Circuit Completeness in Language Models: AND, OR, and ADDER Gates](https://arxiv.org//abs/2505.10039)

	Hang Chen, Jiaying Zhu, Xinyu Yang, Wenya Wang

+ [Informed Forecasting: Leveraging Auxiliary Knowledge to Boost LLM Performance on Time Series Forecasting](https://arxiv.org//abs/2505.10213)

	Mohammadmahdi Ghasemloo, Alireza Moradi

+ [SpecOffload: Unlocking Latent GPU Capacity for LLM Inference on Resource-Constrained Devices](https://arxiv.org//abs/2505.10259)

	Xiangwen Zhuge, Xu Shen, Zeyu Wang, Fan Dang, Xuan Ding, Danyang Li, Yahui Han, Tianxiang Hao, Zheng Yang

+ [Learning to Think: Information-Theoretic Reinforcement Fine-Tuning for LLMs](https://arxiv.org//abs/2505.10425)

	Jingyao Wang, Wenwen Qiang, Zeen Song, Changwen Zheng, Hui Xiong

+ [Interpretable Risk Mitigation in LLM Agent Systems](https://arxiv.org//abs/2505.10670)

	Jan Chojnacki

+ [Evaluations at Work: Measuring the Capabilities of GenAI in Use](https://arxiv.org//abs/2505.10742)

	Brandon Lepine, Gawesha Weerantunga, Juho Kim, Pamela Mishkin, Matthew Beane

+ [Code-Driven Planning in Grid Worlds with Large Language Models](https://arxiv.org//abs/2505.10749)

	Ashwath Vaithinathan Aravindan, Zhisheng Tang, Mayank Kejriwal

+ [LLM-Explorer: Towards Efficient and Affordable LLM-based Exploration for Mobile Apps](https://arxiv.org//abs/2505.10593)

	Shanhui Zhao, Hao Wen, Wenjie Du, Cheng Liang, Yunxin Liu, Xiaozhou Ye, Ye Ouyang, Yuanchun Li

+ [CRPE: Expanding The Reasoning Capability of Large Language Model for Code Generation](https://arxiv.org//abs/2505.10594)

	Ningxin Gui, Qianghuai Jia, Feijun Jiang, Yuling Jiao, dechun wang, Jerry Zhijian Yang

+ [Two Minds Better Than One: Collaborative Reward Modeling for LLM Alignment](https://arxiv.org//abs/2505.10597)

	Jiazheng Zhang, Wenqing Jing, Zizhuo Zhang, Zhiheng Xi, Shihan Dou, Rongxiang Weng, Jiahuan Li, Jingang Wang, MingXu Cai, Shibo Hong, Tao Gui, Qi Zhang

+ [Toward a Public and Secure Generative AI: A Comparative Analysis of Open and Closed LLMs](https://arxiv.org//abs/2505.10603)

	Jorge Machado

+ [Continuity and Isolation Lead to Doubts or Dilemmas in Large Language Models](https://arxiv.org//abs/2505.10606)

	Hector Pasten, Felipe Urrutia, Hector Jimenez, Cristian B. Calderon, Cristóbal Rojas, Alexander Kozachinskiy

+ [Agent Name Service (ANS): A Universal Directory for Secure AI Agent Discovery and Interoperability](https://arxiv.org//abs/2505.10609)

	Ken Huang, Vineeth Sai Narajala, Idan Habler, Akram Sheriff

+ [The Hitchhikers Guide to Production-ready Trustworthy Foundation Model powered Software (FMware)](https://arxiv.org//abs/2505.10640)

	Kirill Vasilevski, Benjamin Rombaut, Gopi Krishnan Rajbahadur, Gustavo A. Oliva, Keheliya Gallaba, Filipe R. Cogo, Jiahuei (Justina)Lin, Dayi Lin, Haoxiang Zhang, Bouyan Chen, Kishanthan Thangarajah, Ahmed E. Hassan, Zhen Ming (Jack)Jiang

+ [A Modular Approach for Clinical SLMs Driven by Synthetic Data with Pre-Instruction Tuning, Model Merging, and Clinical-Tasks Alignment](https://arxiv.org//abs/2505.10717)

	Jean-Philippe Corbeil, Amin Dada, Jean-Michel Attendu, Asma Ben Abacha, Alessandro Sordoni, Lucas Caccia, François Beaulieu, Thomas Lin, Jens Kleesiek, Paul Vozila

+ [Automating Security Audit Using Large Language Model based Agent: An Exploration Experiment](https://arxiv.org//abs/2505.10732)

	Jia Hui Chin, Pu Zhang, Yu Xin Cheong, Jonathan Pan

+ [Tracr-Injection: Distilling Algorithms into Pre-trained Language Models](https://arxiv.org//abs/2505.10719)

	Tomás Vergara-Browne, Álvaro Soto

+ [Model Performance-Guided Evaluation Data Selection for Effective Prompt Optimization](https://arxiv.org//abs/2505.10736)

	Ximing Dong, Shaowei Wang, Dayi Lin, Ahmed E. Hassan

+ [Mitigate Language Priors in Large Vision-Language Models by Cross-Images Contrastive Decoding](https://arxiv.org//abs/2505.10634)

	Jianfei Zhao, Feng Zhang, Xin Sun, Chong Feng

+ [SafeTrans: LLM-assisted Transpilation from C to Rust](https://arxiv.org//abs/2505.10708)

	Muhammad Farrukh (1), Smeet Shah (1), Baris Coskun (2), Michalis Polychronakis (1) ((1) Stony Brook University, (2) Amazon Web Services)

+ [On Technique Identification and Threat-Actor Attribution using LLMs and Embedding Models](https://arxiv.org//abs/2505.11547)

	Kyla Guru, Robert J. Moss, Mykel J. Kochenderfer

+ [One Shot Dominance: Knowledge Poisoning Attack on Retrieval-Augmented Generation Systems](https://arxiv.org//abs/2505.11548)

	Zhiyuan Chang, Xiaojun Jia, Mingyang Li, Junjie Wang, Yuekai Huang, Qing Wang, Ziyou Jiang, Yang Liu

+ [AI-generated Text Detection: A Multifaceted Approach to Binary and Multiclass Classification](https://arxiv.org//abs/2505.11550)

	Harika Abburi, Sanmitra Bhattacharya, Edward Bowen, Nirmala Pudota

+ [Assessing Collective Reasoning in Multi-Agent LLMs via Hidden Profile Tasks](https://arxiv.org//abs/2505.11556)

	Yuxuan Li, Aoi Naito, Hirokazu Shirado

+ [AC-LoRA: (Almost) Training-Free Access Control-Aware Multi-Modal LLMs](https://arxiv.org//abs/2505.11557)

	Lara Magdalena Lazier, Aritra Dhar, Vasilije Stambolic, Lukas Cavigelli

+ [Reinforcing the Diffusion Chain of Lateral Thought with Diffusion Language Models](https://arxiv.org//abs/2505.10446)

	Zemin Huang, Zhiyang Chen, Zijun Wang, Tiancheng Li, Guo-Jun Qi

+ [Assessing GPT's Bias Towards Stigmatized Social Groups: An Intersectional Case Study on Nationality Prejudice and Psychophobia](https://arxiv.org//abs/2505.17045)

	Afifah Kashif, Heer Patel

# 2025-05-14
+ [Reproducibility Study of "Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents"](https://arxiv.org//abs/2505.09289)

	Pedro M. P. Curvo, Mara Dragomir, Salvador Torpes, Mohammadmahdi Rahimi

+ [The Influence of Human-inspired Agentic Sophistication in LLM-driven Strategic Reasoners](https://arxiv.org//abs/2505.09396)

	Vince Trencsenyi, Agnieszka Mensfelt, Kostas Stathis

+ [Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?](https://arxiv.org//abs/2505.09614)

	Anthony GX-Chen, Dongyan Lin, Mandana Samiei, Doina Precup, Blake A. Richards, Rob Fergus, Kenneth Marino

+ [SALM: A Multi-Agent Framework for Language Model-Driven Social Network Simulation](https://arxiv.org//abs/2505.09081)

	Gaurav Koley

+ [CEC-Zero: Chinese Error Correction Solution Based on LLM](https://arxiv.org//abs/2505.09082)

	Sophie Zhang, Zhiming Lin

+ [Human-like Cognitive Generalization for Large Models via Brain-in-the-loop Supervision](https://arxiv.org//abs/2505.09085)

	Jiaxuan Chen, Yu Qi, Yueming Wang, Gang Pan

+ [Air-Ground Collaboration for Language-Specified Missions in Unknown Environments](https://arxiv.org//abs/2505.09108)

	Fernando Cladera, Zachary Ravichandran, Jason Hughes, Varun Murali, Carlos Nieto-Granda, M. Ani Hsieh, George J. Pappas, Camillo J. Taylor, Vijay Kumar

+ [ELIS: Efficient LLM Iterative Scheduling System with Response Length Predictor](https://arxiv.org//abs/2505.09142)

	Seungbeom Choi, Jeonghoe Goo, Eunjoo Jeon, Mingyu Yang, Minsung Jang

+ [Focus, Merge, Rank: Improved Question Answering Based on Semi-structured Knowledge Bases](https://arxiv.org//abs/2505.09246)

	Derian Boer, Stephen Roth, Stefan Kramer

+ [CXMArena: Unified Dataset to benchmark performance in realistic CXM Scenarios](https://arxiv.org//abs/2505.09436)

	Raghav Garg, Kapil Sharma, Karan Gupta

+ [Deploying Foundation Model-Enabled Air and Ground Robots in the Field: Challenges and Opportunities](https://arxiv.org//abs/2505.09477)

	Zachary Ravichandran, Fernando Cladera, Jason Hughes, Varun Murali, M. Ani Hsieh, George J. Pappas, Camillo J. Taylor, Vijay Kumar

+ [WorldView-Bench: A Benchmark for Evaluating Global Cultural Perspectives in Large Language Models](https://arxiv.org//abs/2505.09595)

	Abdullah Mushtaq, Imran Taj, Rafay Naeem, Ibrahim Ghaznavi, Junaid Qadir

+ [Atomic Consistency Preference Optimization for Long-Form Question Answering](https://arxiv.org//abs/2505.09039)

	Jingfeng Chen, Raghuveer Thirukovalluru, Junlin Wang, Kaiwei Luo, Bhuwan Dhingra

+ [A Comprehensive Analysis of Large Language Model Outputs: Similarity, Diversity, and Bias](https://arxiv.org//abs/2505.09056)

	Brandon Smith, Mohamed Reda Bouadjenek, Tahsin Alamgir Kheya, Phillip Dawson, Sunil Aryal

+ [Scent of Knowledge: Optimizing Search-Enhanced Reasoning with Information Foraging](https://arxiv.org//abs/2505.09316)

	Hongjin Qian, Zheng Liu

+ [Llama See, Llama Do: A Mechanistic Perspective on Contextual Entrainment and Distraction in LLMs](https://arxiv.org//abs/2505.09338)

	Jingcheng Niu, Xingdi Yuan, Tong Wang, Hamidreza Saghir, Amir H. Abdi

+ [Qwen3 Technical Report](https://arxiv.org//abs/2505.09388)

	An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, Chujie Zheng, Dayiheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao Ge, Haoran Wei, Huan Lin, Jialong Tang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jing Zhou, Jingren Zhou, Junyang Lin, Kai Dang, Keqin Bao, Kexin Yang, Le Yu, Lianghao Deng, Mei Li, Mingfeng Xue, Mingze Li, Pei Zhang, Peng Wang, Qin Zhu, Rui Men, Ruize Gao, Shixuan Liu, Shuang Luo, Tianhao Li, Tianyi Tang, Wenbiao Yin, Xingzhang Ren, Xinyu Wang, Xinyu Zhang, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yinger Zhang, Yu Wan, Yuqiong Liu, Zekun Wang, Zeyu Cui, Zhenru Zhang, Zhipeng Zhou, Zihan Qiu

+ [PT-MoE: An Efficient Finetuning Framework for Integrating Mixture-of-Experts into Prompt Tuning](https://arxiv.org//abs/2505.09519)

	Zongqian Li, Yixuan Su, Nigel Collier

+ [Ornithologist: Towards Trustworthy "Reasoning" about Central Bank Communications](https://arxiv.org//abs/2505.09083)

	Dominic Zaun Eu Jones

+ [FaceShield: Explainable Face Anti-Spoofing with Multimodal Large Language Models](https://arxiv.org//abs/2505.09415)

	Hongyang Wang, Yichen Shi, Zhuofu Tao, Yuhao Gao, Liepiao Zhang, Xun Lin, Jun Feng, Xiaochen Yuan, Zitong Yu, Xiaochun Cao

+ [SafePath: Conformal Prediction for Safe LLM-Based Autonomous Navigation](https://arxiv.org//abs/2505.09427)

	Achref Doula, Max Mühläuser, Alejandro Sanchez Guinea

+ [Layered Unlearning for Adversarial Relearning](https://arxiv.org//abs/2505.09500)

	Timothy Qian, Vinith Suriyakumar, Ashia Wilson, Dylan Hadfield-Menell

+ [Adversarial Suffix Filtering: a Defense Pipeline for LLMs](https://arxiv.org//abs/2505.09602)

	David Khachaturov, Robert Mullins

+ [Instantiating Standards: Enabling Standard-Driven Text TTP Extraction with Evolvable Memory](https://arxiv.org//abs/2505.09261)

	Cheng Meng, ZhengWei Jiang, QiuYun Wang, XinYi Li, ChunYan Ma, FangMing Dong, FangLi Ren, BaoXu Liu

+ [A Multimodal Multi-Agent Framework for Radiology Report Generation](https://arxiv.org//abs/2505.09787)

	Ziruo Yi, Ting Xiao, Mark V. Albert

+ [System Prompt Optimization with Meta-Learning](https://arxiv.org//abs/2505.09666)

	Yumin Choi, Jinheon Baek, Sung Ju Hwang

+ [Achieving Tokenizer Flexibility in Language Models through Heuristic Adaptation and Supertoken Learning](https://arxiv.org//abs/2505.09738)

	Shaurya Sharthak, Vinayak Pahalwan, Adithya Kamath, Adarsh Shirawalmath

+ [Trustless Autonomy: Understanding Motivations, Benefits and Governance Dilemma in Self-Sovereign Decentralized AI Agents](https://arxiv.org//abs/2505.09757)

	Botao Amber Hu, Yuhan Liu, Helena Rong

+ [Exploring the generalization of LLM truth directions on conversational formats](https://arxiv.org//abs/2505.09807)

	Timour Ichmoukhamedov, David Martens

+ [Evaluating Large Language Models for the Generation of Unit Tests with Equivalence Partitions and Boundary Values](https://arxiv.org//abs/2505.09830)

	Martín Rodríguez, Gustavo Rossi, Alejandro Fernandez

+ [Do Large Language Models Know Conflict? Investigating Parametric vs. Non-Parametric Knowledge of LLMs for Conflict Forecasting](https://arxiv.org//abs/2505.09852)

	Apollinaire Poli Nemkova, Sarath Chandra Lingareddy, Sagnik Ray Choudhury, Mark V. Albert

+ [DRA-GRPO: Exploring Diversity-Aware Reward Adjustment for R1-Zero-Like Training of Large Language Models](https://arxiv.org//abs/2505.09655)

	Xiwen Chen, Wenhui Zhu, Peijie Qiu, Xuanzhao Dong, Hao Wang, Haiyu Wu, Huayu Li, Aristeidis Sotiras, Yalin Wang, Abolfazl Razi

+ [Large Language Models Are More Persuasive Than Incentivized Human Persuaders](https://arxiv.org//abs/2505.09662)

	Philipp Schoenegger, Francesco Salvi, Jiacheng Liu, Xiaoli Nan, Ramit Debnath, Barbara Fasolo, Evelina Leivada, Gabriel Recchia, Fritz Günther, Ali Zarifhonarvar, Joe Kwon, Zahoor Ul Islam, Marco Dehnert, Daryl Y. H. Lee, Madeline G. Reinecke, David G. Kamper, Mert Kobaş, Adam Sandford, Jonas Kgomo, Luke Hewitt, Shreya Kapoor, Kerem Oktar, Eyup Engin Kucuk, Bo Feng, Cameron R. Jones, Izzy Gainsburg, Sebastian Olschewski, Nora Heinzelmann, Francisco Cruz, Ben M. Tappin, Tao Ma, Peter S. Park, Rayan Onyonka, Arthur Hjorth, Peter Slattery, Qingcheng Zeng, Lennart Finke, Igor Grossmann, Alessandro Salatiello, Ezra Karger

+ [VeriFact: Enhancing Long-Form Factuality Evaluation with Refined Fact Extraction and Reference Facts](https://arxiv.org//abs/2505.09701)

	Xin Liu, Lechen Zhang, Sheza Munir, Yiyang Gu, Lu Wang

+ [LAS: Loss-less ANN-SNN Conversion for Fully Spike-Driven Large Language Models](https://arxiv.org//abs/2505.09659)

	Long Chen, Xiaotian Song, Yanan Sun

+ [Analog Foundation Models](https://arxiv.org//abs/2505.09663)

	Julian Büchel, Iason Chalas, Giovanni Acampa, An Chen, Omobayode Fagbohungbe, Sidney Tsai, Kaoutar El Maghraoui, Manuel Le Gallo, Abbas Rahimi, Abu Sebastian

+ [Adversarial Attack on Large Language Models using Exponentiated Gradient Descent](https://arxiv.org//abs/2505.09820)

	Sajib Biswas, Mao Nishino, Samuel Jacob Chacko, Xiuwen Liu

+ [Understanding Gen Alpha Digital Language: Evaluation of LLM Safety Systems for Content Moderation](https://arxiv.org//abs/2505.10588)

	Manisha Mehta, Fausto Giunchiglia

+ [Towards Automated Situation Awareness: A RAG-Based Framework for Peacebuilding Reports](https://arxiv.org//abs/2505.10586)

	Poli A. Nemkova, Suleyman O. Polat, Rafid I. Jahan, Sagnik Ray Choudhury, Sun-joo Lee, Shouryadipta Sarkar, Mark V. Albert

+ [TARGET: Benchmarking Table Retrieval for Generative Tasks](https://arxiv.org//abs/2505.11545)

	Xingyu Ji, Parker Glenn, Aditya G. Parameswaran, Madelon Hulsebos

+ [MorphMark: Flexible Adaptive Watermarking for Large Language Models](https://arxiv.org//abs/2505.11541)

	Zongqi Wang, Tianle Gu, Baoyuan Wu, Yujiu Yang

+ [Source framing triggers systematic evaluation bias in Large Language Models](https://arxiv.org//abs/2505.13488)

	Federico Germani, Giovanni Spitale

+ [LLM4CD: Leveraging Large Language Models for Open-World Knowledge Augmented Cognitive Diagnosis](https://arxiv.org//abs/2505.13492)

	Weiming Zhang, Lingyue Fu, Qingyao Li, Kounianhua Du, Jianghao Lin, Jingwei Yu, Wei Xia, Weinan Zhang, Ruiming Tang, Yong Yu

# 2025-05-13
+ [Lost in Transmission: When and Why LLMs Fail to Reason Globally](https://arxiv.org//abs/2505.08140)

	Tobias Schnabel, Kiran Tomlinson, Adith Swaminathan, Jennifer Neville

+ [Evaluating LLM Metrics Through Real-World Capabilities](https://arxiv.org//abs/2505.08253)

	Justin K Miller, Wenjia Tang

+ [Learning Like Humans: Advancing LLM Reasoning Capabilities via Adaptive Difficulty Curriculum Learning and Expert-Guided Self-Reformulation](https://arxiv.org//abs/2505.08364)

	Enci Zhang, Xingang Yan, Wei Lin, Tianxiang Zhang, Qianchun Lu

+ [Agent-as-a-Service based on Agent Network](https://arxiv.org//abs/2505.08446)

	Yuhan Zhu, Haojie Liu, Jian Wang, Bing Li, Zikang Yin, Yefei Liao

+ [Strategy-Augmented Planning for Large Language Models via Opponent Exploitation](https://arxiv.org//abs/2505.08459)

	Shuai Xu, Sijia Cui, Yanna Wang, Bo Xu, Qi Wang

+ [Achieving Scalable Robot Autonomy via neurosymbolic planning using lightweight local LLM](https://arxiv.org//abs/2505.08492)

	Nicholas Attolino, Alessio Capitanelli, Fulvio Mastrogiovanni

+ [TrialMatchAI: An End-to-End AI-powered Clinical Trial Recommendation System to Streamline Patient-to-Trial Matching](https://arxiv.org//abs/2505.08508)

	Majd Abdallah, Sigve Nakken, Mariska Bierkens, Johanna Galvis, Alexis Groppi, Slim Karkar, Lana Meiqari, Maria Alexandra Rujano, Steve Canham, Rodrigo Dienstmann, Remond Fijneman, Eivind Hovig, Gerrit Meijer, Macha Nikolski

+ [Guiding LLM-based Smart Contract Generation with Finite State Machine](https://arxiv.org//abs/2505.08542)

	Hao Luo, Yuhao Lin, Xiao Yan, Xintong Hu, Yuxiang Wang, Qiming Zeng, Hao Wang, Jiawei Jiang

+ [Resource-Efficient Language Models: Quantization for Fast and Accessible Inference](https://arxiv.org//abs/2505.08620)

	Tollef Emil Jørgensen

+ [TRAIL: Trace Reasoning and Agentic Issue Localization](https://arxiv.org//abs/2505.08638)

	Darshan Deshpande, Varun Gangal, Hersh Mehta, Jitin Krishnan, Anand Kannappan, Rebecca Qian

+ [WixQA: A Multi-Dataset Benchmark for Enterprise Retrieval-Augmented Generation](https://arxiv.org//abs/2505.08643)

	Dvir Cohen, Lin Burg, Sviatoslav Pykhnivskyi, Hagit Gur, Stanislav Kovynov, Olga Atzmon, Gilad Barkan

+ [LLM-based Prompt Ensemble for Reliable Medical Entity Recognition from EHRs](https://arxiv.org//abs/2505.08704)

	K M Sajjadul Islam, Ayesha Siddika Nipu, Jiawei Wu, Praveen Madiraju

+ [ALOHA: Empowering Multilingual Agent for University Orientation with Hierarchical Retrieval](https://arxiv.org//abs/2505.08130)

	Mingxu Tao, Bowen Tang, Mingxuan Ma, Yining Zhang, Hourun Li, Feifan Wen, Hao Ma, Jia Yang

+ [A Large-Scale Empirical Analysis of Custom GPTs' Vulnerabilities in the OpenAI Ecosystem](https://arxiv.org//abs/2505.08148)

	Sunday Oyinlola Ogundoyin, Muhammad Ikram, Hassan Jameel Asghar, Benjamin Zi Hao Zhao, Dali Kaafar

+ [Fusing Bidirectional Chains of Thought and Reward Mechanisms A Method for Enhancing Question-Answering Capabilities of Large Language Models for Chinese Intangible Cultural Heritage](https://arxiv.org//abs/2505.08167)

	Ruilin Liu, Zhixiao Zhao, Jieqiong Li, Chang Liu, Dongbo Wang

+ [A Head to Predict and a Head to Question: Pre-trained Uncertainty Quantification Heads for Hallucination Detection in LLM Outputs](https://arxiv.org//abs/2505.08200)

	Artem Shelmanov, Ekaterina Fadeeva, Akim Tsvigun, Ivan Tsvigun, Zhuohan Xie, Igor Kiselev, Nico Daheim, Caiqi Zhang, Artem Vazhentsev, Mrinmaya Sachan, Preslav Nakov, Timothy Baldwin

+ [Large Language Model Psychometrics: A Systematic Review of Evaluation, Validation, and Enhancement](https://arxiv.org//abs/2505.08245)

	Haoran Ye, Jing Jin, Yuhang Xie, Xin Zhang, Guojie Song

+ [Enhancing Cache-Augmented Generation (CAG) with Adaptive Contextual Compression for Scalable Knowledge Integration](https://arxiv.org//abs/2505.08261)

	Rishabh Agrawal, Himanshu Kumar

+ [LLM Enhancers for GNNs: An Analysis from the Perspective of Causal Mechanism Identification](https://arxiv.org//abs/2505.08265)

	Hang Gao, Wenxuan Huang, Fengge Wu, Junsuo Zhao, Changwen Zheng, Huaping Liu

+ [Accelerating Chain-of-Thought Reasoning: When Goal-Gradient Importance Meets Dynamic Skipping](https://arxiv.org//abs/2505.08392)

	Ren Zhuang, Ben Wang, Shuifa Sun

+ [Optimizing Retrieval-Augmented Generation: Analysis of Hyperparameter Impact on Performance and Efficiency](https://arxiv.org//abs/2505.08445)

	Adel Ammar, Anis Koubaa, Omer Nacar, Wadii Boulila

+ [RepCali: High Efficient Fine-tuning Via Representation Calibration in Latent Space for Pre-trained Language Models](https://arxiv.org//abs/2505.08463)

	Fujun Zhang, XiangDong Su

+ [LCES: Zero-shot Automated Essay Scoring via Pairwise Comparisons Using Large Language Models](https://arxiv.org//abs/2505.08498)

	Takumi Shibata, Yuichi Miyamura

+ [The Truth Becomes Clearer Through Debate! Multi-Agent Systems with Large Language Models Unmask Fake News](https://arxiv.org//abs/2505.08532)

	Yuhan Liu, Yuxuan Liu, Xiaoqing Zhang, Xiuying Chen, Rui Yan

+ [PWC-MoE: Privacy-Aware Wireless Collaborative Mixture of Experts](https://arxiv.org//abs/2505.08719)

	Yang Su, Na Yan, Yansha Deng, Robert Schober

+ [Memorization-Compression Cycles Improve Generalization](https://arxiv.org//abs/2505.08727)

	Fangyuan Yu

+ [Securing RAG: A Risk Assessment and Mitigation Framework](https://arxiv.org//abs/2505.08728)

	Lukas Ammann, Sara Ott, Christoph R. Landolt, Marco P. Lehmann

+ [CodePDE: An Inference Framework for LLM-driven PDE Solver Generation](https://arxiv.org//abs/2505.08783)

	Shanda Li, Tanya Marwah, Junhong Shen, Weiwei Sun, Andrej Risteski, Yiming Yang, Ameet Talwalkar

+ [Evaluating the Effectiveness of Black-Box Prompt Optimization as the Scale of LLMs Continues to Grow](https://arxiv.org//abs/2505.08303)

	Ziyu Zhou, Yihang Wu, Jingyuan Yang, Zhan Xiao, Rongjun Li

+ [On the Geometry of Semantics in Next-token Prediction](https://arxiv.org//abs/2505.08348)

	Yize Zhao, Christos Thrampoulidis

+ [Alignment Drift in CEFR-prompted LLMs for Interactive Spanish Tutoring](https://arxiv.org//abs/2505.08351)

	Mina Almasi, Ross Deans Kristensen-McLachlan

+ [Towards Contamination Resistant Benchmarks](https://arxiv.org//abs/2505.08389)

	Rahmatullah Musawi, Sheng Lu

+ [Enhancing Thyroid Cytology Diagnosis with RAG-Optimized LLMs and Pa-thology Foundation Models](https://arxiv.org//abs/2505.08590)

	Hussien Al-Asi, Jordan P Reynolds, Shweta Agarwal, Bryan J Dangott, Aziza Nassar, Zeynettin Akkus

+ [Automatic Task Detection and Heterogeneous LLM Speculative Decoding](https://arxiv.org//abs/2505.08600)

	Danying Ge, Jianhua Gao, Qizhi Jiang, Yifei Feng, Weixing Ji

+ [Scaling Context, Not Parameters: Training a Compact 7B Language Model for Efficient Long-Context Processing](https://arxiv.org//abs/2505.08651)

	Chen Wu, Yin Song

+ [Revealing economic facts: LLMs know more than they say](https://arxiv.org//abs/2505.08662)

	Marcus Buckmann, Quynh Anh Nguyen, Edward Hill

+ [Adaptive Schema-aware Event Extraction with Retrieval-Augmented Generation](https://arxiv.org//abs/2505.08690)

	Sheng Liang, Hang Lv, Zhihao Wen, Yaxiong Wu, Yongyue Zhang, Hao Wang, Yong Liu

+ [NurValues: Real-World Nursing Values Evaluation for Large Language Models in Clinical Context](https://arxiv.org//abs/2505.08734)

	Ben Yao, Qiuchi Li, Yazhou Zhang, Siyu Yang, Bohan Zhang, Prayag Tiwari, Jing Qin

+ [Probability Consistency in Large Language Models: Theoretical Foundations Meet Empirical Discrepancies](https://arxiv.org//abs/2505.08739)

	Xiaoliang Luo, Xinyi Xu, Michael Ramscar, Bradley C. Love

+ [AC-Reason: Towards Theory-Guided Actual Causality Reasoning with Large Language Models](https://arxiv.org//abs/2505.08750)

	Yanxi Zhang, Xin Cong, Zhong Zhang, Xiao Liu, Dongyan Zhao, Yesai Wu

+ [InfoPO: On Mutual Information Maximization for Large Language Model Alignment](https://arxiv.org//abs/2505.08507)

	Teng Xiao, Zhen Ge, Sujay Sanghavi, Tian Wang, Julian Katz-Samuels, Marc Versage, Qingjun Cui, Trishul Chilimbi

+ [LM-Scout: Analyzing the Security of Language Model Integration in Android Apps](https://arxiv.org//abs/2505.08204)

	Muhammad Ibrahim (1), Gűliz Seray Tuncay (2), Z. Berkay Celik (3), Aravind Machiry (3), Antonio Bianchi (3) ((1) Georgia Institute of Technology, (2) Google, (3) Purdue University)

+ [Grounding Synthetic Data Evaluations of Language Models in Unsupervised Document Corpora](https://arxiv.org//abs/2505.08905)

	Michael Majurski, Cynthia Matuszek

+ [Automated Meta Prompt Engineering for Alignment with the Theory of Mind](https://arxiv.org//abs/2505.09024)

	Aaron Baughman, Rahul Agarwal, Eduardo Morales, Gozde Akay

+ [Improving the Reliability of LLMs: Combining CoT, RAG, Self-Consistency, and Self-Verification](https://arxiv.org//abs/2505.09031)

	Adarsh Kumar, Hwiyoon Kim, Jawahar Sai Nathani, Neil Roy

+ [Federated Large Language Models: Feasibility, Robustness, Security and Future Directions](https://arxiv.org//abs/2505.08830)

	Wenhao Jiang, Yuchuan Luo, Guilin Deng, Silong Chen, Xu Yang, Shihong Wu, Xinwen Gao, Lin Liu, Shaojing Fu

+ [CellTypeAgent: Trustworthy cell type annotation with Large Language Models](https://arxiv.org//abs/2505.08844)

	Jiawen Chen, Jianghao Zhang, Huaxiu Yao, Yun Li

+ [Improved Algorithms for Differentially Private Language Model Alignment](https://arxiv.org//abs/2505.08849)

	Keyu Chen, Hao Tang, Qinglin Liu, Yizhao Xu

+ [Optimized Couplings for Watermarking Large Language Models](https://arxiv.org//abs/2505.08878)

	Dor Tsur, Carol Xuan Long, Claudio Mayrink Verdun, Hsiang Hsu, Haim Permuter, Flavio P. Calmon

+ [Tests as Prompt: A Test-Driven-Development Benchmark for LLM Code Generation](https://arxiv.org//abs/2505.09027)

	Yi Cui

+ [LibVulnWatch: A Deep Assessment Agent System and Leaderboard for Uncovering Hidden Vulnerabilities in Open-Source AI Libraries](https://arxiv.org//abs/2505.08842)

	Zekun Wu, Seonglae Cho, Umar Mohammed, Cristian Munoz, Kleyton Costa, Xin Guan, Theo King, Ze Wang, Emre Kazim, Adriano Koshiyama

+ [Detecting Prefix Bias in LLM-based Reward Models](https://arxiv.org//abs/2505.13487)

	Ashwin Kumar, Yuzi He, Aram H. Markosyan, Bobbie Chern, Imanol Arrieta-Ibarra

+ [Generalizing Large Language Model Usability Across Resource-Constrained](https://arxiv.org//abs/2505.17040)

	Yun-Da Tsai

# 2025-05-12
+ [How well do LLMs reason over tabular data, really?](https://arxiv.org//abs/2505.07453)

	Cornelius Wolff, Madelon Hulsebos

+ [A Survey on Collaborative Mechanisms Between Large and Small Language Models](https://arxiv.org//abs/2505.07460)

	Yi Chen, JiaHao Zhao, HaoHao Han

+ [Web-Bench: A LLM Code Benchmark Based on Web Standards and Frameworks](https://arxiv.org//abs/2505.07473)

	Kai Xu, YiWei Mao, XinYi Guan, ZiLong Feng

+ [QuantX: A Framework for Hardware-Aware Quantization of Generative AI Workloads](https://arxiv.org//abs/2505.07531)

	Khurram Mazher, Saad Bin Nasir

+ [S-GRPO: Early Exit via Reinforcement Learning in Reasoning Models](https://arxiv.org//abs/2505.07686)

	Muzhi Dai, Chenxu Yang, Qingyi Si

+ [Belief Injection for Epistemic Control in Linguistic State Space](https://arxiv.org//abs/2505.07693)

	Sebastian Dumbrava

+ [Agent RL Scaling Law: Agent RL with Spontaneous Code Execution for Mathematical Problem Solving](https://arxiv.org//abs/2505.07773)

	Xinji Mai, Haotian Xu, Xing W, Weinong Wang, Yingying Zhang, Wenqiang Zhang

+ [DynamicRAG: Leveraging Outputs of Large Language Model as Feedback for Dynamic Reranking in Retrieval-Augmented Generation](https://arxiv.org//abs/2505.07233)

	Jiashuo Sun, Xianrui Zhong, Sizhe Zhou, Jiawei Han

+ [UAV-CodeAgents: Scalable UAV Mission Planning via Multi-Agent ReAct and Vision-Language Reasoning](https://arxiv.org//abs/2505.07236)

	Oleg Sautenkov, Yasheerah Yaqoot, Muhammad Ahsan Mustafa, Faryal Batool, Jeffrin Sam, Artem Lykov, Chih-Yung Wen, Dzmitry Tsetserukou

+ [Comet: Accelerating Private Inference for Large Language Model by Predicting Activation Sparsity](https://arxiv.org//abs/2505.07239)

	Guang Yan, Yuhui Zhang, Zimu Guo, Lutan Zhao, Xiaojun Chen, Chen Wang, Wenhao Wang, Dan Meng, Rui Hou

+ [SAS-Bench: A Fine-Grained Benchmark for Evaluating Short Answer Scoring with Large Language Models](https://arxiv.org//abs/2505.07247)

	Peichao Lai, Kexuan Zhang, Yi Lin, Linyihan Zhang, Feiyang Ye, Jinhao Yan, Yanwei Xu, Conghui He, Yilei Wang, Wentao Zhang, Bin Cui

+ [No Query, No Access](https://arxiv.org//abs/2505.07258)

	Wenqiang Wang, Siyuan Liang, Yangshijie Zhang, Xiaojun Jia, Hao Lin, Xiaochun Cao

+ [UMoE: Unifying Attention and FFN with Shared Experts](https://arxiv.org//abs/2505.07260)

	Yuanhang Yang, Chaozheng Wang, Jing Li

+ [On the Robustness of Reward Models for Language Model Alignment](https://arxiv.org//abs/2505.07271)

	Jiwoo Hong, Noah Lee, Eunki Kim, Guijin Son, Woojin Chung, Aman Gupta, Shao Tang, James Thorne

+ [Semantic Retention and Extreme Compression in LLMs: Can We Have Both?](https://arxiv.org//abs/2505.07289)

	Stanislas Laborde, Martin Cousseau, Antoun Yaacoub, Lionel Prevost

+ [Towards Multi-Agent Reasoning Systems for Collaborative Expertise Delegation: An Exploratory Design Study](https://arxiv.org//abs/2505.07313)

	Baixuan Xu, Chunyang Li, Weiqi Wang, Wei Fan, Tianshi Zheng, Haochen Shi, Tao Fan, Yangqiu Song, Qiang Yang

+ [Synthetic Code Surgery: Repairing Bugs and Vulnerabilities with LLMs and Synthetic Data](https://arxiv.org//abs/2505.07372)

	David de-Fitero-Dominguez, Antonio Garcia-Cabot, Eva Garcia-Lopez

+ [LEAD: Iterative Data Selection for Efficient LLM Instruction Tuning](https://arxiv.org//abs/2505.07437)

	Xiaotian Lin, Yanlin Qi, Yizhang Zhu, Themis Palpanas, Chengliang Chai, Nan Tang, Yuyu Luo

+ [Can Generative AI agents behave like humans? Evidence from laboratory market experiments](https://arxiv.org//abs/2505.07457)

	R. Maria del Rio-Chanona, Marco Pangallo, Cars Hommes

+ [ToolACE-DEV: Self-Improving Tool Learning via Decomposition and EVolution](https://arxiv.org//abs/2505.07512)

	Xu Huang, Weiwen Liu, Xingshan Zeng, Yuefeng Huang, Xinlong Hao, Yuxian Wang, Yirong Zeng, Chuhan Wu, Yasheng Wang, Ruiming Tang, Defu Lian

+ [GRADA: Graph-based Reranker against Adversarial Documents Attack](https://arxiv.org//abs/2505.07546)

	Jingjie Zheng, Aryo Pradipta Gema, Giwon Hong, Xuanli He, Pasquale Minervini, Youcheng Sun, Qiongkai Xu

+ [Towards Requirements Engineering for RAG Systems](https://arxiv.org//abs/2505.07553)

	Tor Sporsem, Rasmus Ulfsnes

+ [A Multi-Dimensional Constraint Framework for Evaluating and Improving Instruction Following in Large Language Models](https://arxiv.org//abs/2505.07591)

	Junjie Ye, Caishuang Huang, Zhuohan Chen, Wenjie Fu, Chenyuan Yang, Leyi Yang, Yilong Wu, Peng Wang, Meng Zhou, Xiaolong Yang, Tao Gui, Qi Zhang, Zhongchao Shi, Jianping Fan, Xuanjing Huang

+ [Reinforced Internal-External Knowledge Synergistic Reasoning for Efficient Adaptive Search Agent](https://arxiv.org//abs/2505.07596)

	Ziyang Huang, Xiaowei Yuan, Yiming Ju, Jun Zhao, Kang Liu

+ [MiMo: Unlocking the Reasoning Potential of Language Model -- From Pretraining to Posttraining](https://arxiv.org//abs/2505.07608)

	Xiaomi LLM-Core Team: Bingquan Xia, Bowen Shen, Cici, Dawei Zhu, Di Zhang, Gang Wang, Hailin Zhang, Huaqiu Liu, Jiebao Xiao, Jinhao Dong, Liang Zhao, Peidian Li, Peng Wang, Shihua Yu, Shimao Chen, Weikun Wang, Wenhan Ma, Xiangwei Deng, Yi Huang, Yifan Song, Zihan Jiang, Bowen Ye, Can Cai, Chenhong He, Dong Zhang, Duo Zhang, Guoan Wang, Hao Tian, Haochen Zhao, Heng Qu, Hongshen Xu, Jun Shi, Kainan Bao, QingKai Fang, Kang Zhou, Kangyang Zhou, Lei Li, Menghang Zhu, Nuo Chen, Qiantong Wang, Shaohui Liu, Shicheng Li, Shuhao Gu, Shuhuai Ren, Shuo Liu, Sirui Deng, Weiji Zhuang, Weiwei Lv, Wenyu Yang, Xin Zhang, Xing Yong, Xing Zhang, Xingchen Song, Xinzhe Xu, Xu Wang, Yihan Yan, Yu Tu, Yuanyuan Tian, Yudong Wang, Yue Yu, Zhenru Lin, Zhichao Song, Zihao Yue

+ [Concept-Level Explainability for Auditing & Steering LLM Responses](https://arxiv.org//abs/2505.07610)

	Kenza Amara, Rita Sevastjanova, Mennatallah El-Assady

+ [Chronocept: Instilling a Sense of Time in Machines](https://arxiv.org//abs/2505.07637)

	Krish Goel, Sanskar Pandey, KS Mahadevan, Harsh Kumar, Vishesh Khadaria

+ [Benchmarking Retrieval-Augmented Generation for Chemistry](https://arxiv.org//abs/2505.07671)

	Xianrui Zhong, Bowen Jin, Siru Ouyang, Yanzhen Shen, Qiao Jin, Yin Fang, Zhiyong Lu, Jiawei Han

+ [OnPrem.LLM: A Privacy-Conscious Document Intelligence Toolkit](https://arxiv.org//abs/2505.07672)

	Arun S. Maiya

+ [Overflow Prevention Enhances Long-Context Recurrent LLMs](https://arxiv.org//abs/2505.07793)

	Assaf Ben-Kish, Itamar Zimerman, M. Jehanzeb Mirza, James Glass, Leonid Karlinsky, Raja Giryes

+ [Structural Entropy Guided Agent for Detecting and Repairing Knowledge Deficiencies in LLMs](https://arxiv.org//abs/2505.07184)

	Yifan Wei, Xiaoyan Yu, Tengfei Pan, Angsheng Li, Li Du

+ [Benchmarking Ethical and Safety Risks of Healthcare LLMs in China-Toward Systemic Governance under Healthy China 2030](https://arxiv.org//abs/2505.07205)

	Mouxiao Bian, Rongzhao Zhang, Chao Ding, Xinwei Peng, Jie Xu

+ [AttentionInfluence: Adopting Attention Head Influence for Weak-to-Strong Pretraining Data Selection](https://arxiv.org//abs/2505.07293)

	Kai Hua, Steven Wu, Ge Zhang, Ke Shen

+ [SEReDeEP: Hallucination Detection in Retrieval-Augmented Models via Semantic Entropy and Context-Parameter Fusion](https://arxiv.org//abs/2505.07528)

	Lei Wang

+ [Spoken Language Understanding on Unseen Tasks With In-Context Learning](https://arxiv.org//abs/2505.07731)

	Neeraj Agrawal, Sriram Ganapathy

+ [Domain Regeneration: How well do LLMs match syntactic properties of text domains?](https://arxiv.org//abs/2505.07784)

	Da Ju, Hagen Blix, Adina Williams

+ [Learning from Peers in Reasoning Models](https://arxiv.org//abs/2505.07787)

	Tongxu Luo, Wenyu Du, Jiaxi Bi, Stephen Chung, Zhengyang Tang, Hao Yang, Min Zhang, Benyou Wang

+ [Reassessing Large Language Model Boolean Query Generation for Systematic Reviews](https://arxiv.org//abs/2505.07155)

	Shuai Wang, Harrisen Scells, Bevan Koopman, Guido Zuccon

+ [Pre-training vs. Fine-tuning: A Reproducibility Study on Dense Retrieval Knowledge Acquisition](https://arxiv.org//abs/2505.07166)

	Zheng Yao, Shuai Wang, Guido Zuccon

+ [One Trigger Token Is Enough: A Defense Strategy for Balancing Safety and Usability in Large Language Models](https://arxiv.org//abs/2505.07167)

	Haoran Gu, Handing Wang, Yi Mei, Mengjie Zhang, Yaochu Jin

+ [Direct Density Ratio Optimization: A Statistically Consistent Approach to Aligning Large Language Models](https://arxiv.org//abs/2505.07558)

	Rei Higuchi, Taiji Suzuki

+ [Critique Before Thinking: Mitigating Hallucination through Rationale-Augmented Instruction Tuning](https://arxiv.org//abs/2505.07172)

	Zexian Yang, Dian Li, Dayan Wu, Gang Liu, Weiping Wang

+ [Learning to Reason and Navigate: Parameter Efficient Action Planning with Large Language Models](https://arxiv.org//abs/2505.07500)

	Bahram Mohammadi, Ehsan Abbasnejad, Yuankai Qi, Qi Wu, Anton Van Den Hengel, Javen Qinfeng Shi

+ [Imagine, Verify, Execute: Memory-Guided Agentic Exploration with Vision-Language Models](https://arxiv.org//abs/2505.07815)

	Seungjae Lee, Daniel Ekpo, Haowen Liu, Furong Huang, Abhinav Shrivastava, Jia-Bin Huang

+ [Cache-Efficient Posterior Sampling for Reinforcement Learning with LLM-Derived Priors Across Discrete and Continuous Domains](https://arxiv.org//abs/2505.07274)

	Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma

+ [Uncertainty Profiles for LLMs: Uncertainty Source Decomposition and Adaptive Model-Metric Selection](https://arxiv.org//abs/2505.07309)

	Pei-Fu Guo, Yun-Da Tsai, Shou-De Lin

+ [Injecting Knowledge Graphs into Large Language Models](https://arxiv.org//abs/2505.07554)

	Erica Coppolillo

+ [SpecRouter: Adaptive Routing for Multi-Level Speculative Decoding in Large Language Models](https://arxiv.org//abs/2505.07680)

	Hang Wu, Jianian Zhu, Yinghui Li, Haojie Wang, Biao Hou, Jidong Zhai

+ [MLE-Dojo: Interactive Environments for Empowering LLM Agents in Machine Learning Engineering](https://arxiv.org//abs/2505.07782)

	Rushi Qiang, Yuchen Zhuang, Yinghao Li, Dingu Sagar V K, Rongzhi Zhang, Changhao Li, Ian Shu-Hei Wong, Sherry Yang, Percy Liang, Chao Zhang, Bo Dai

+ [Relative Overfitting and Accept-Reject Framework](https://arxiv.org//abs/2505.07783)

	Yanxin Liu, Yunqi Zhang

+ [Private LoRA Fine-tuning of Open-Source LLMs with Homomorphic Encryption](https://arxiv.org//abs/2505.07329)

	Jordan Frery, Roman Bredehoft, Jakub Klemsa, Arthur Meyre, Andrei Stoian

+ [SecReEvalBench: A Multi-turned Security Resilience Evaluation Benchmark for Large Language Models](https://arxiv.org//abs/2505.07584)

	Huining Cui, Wei Liu

+ [LongCodeBench: Evaluating Coding LLMs at 1M Context Windows](https://arxiv.org//abs/2505.07897)

	Stefano Rando, Luca Romani, Alessio Sampieri, Yuta Kyuragi, Luca Franco, Fabio Galasso, Tatsunori Hashimoto, John Yang

+ [DeltaEdit: Enhancing Sequential Editing in Large Language Models by Controlling Superimposed Noise](https://arxiv.org//abs/2505.07899)

	Ding Cao, Yuchen Cai, Rongxi Guo, Xuesong He, Guiquan Liu

+ [SEM: Reinforcement Learning for Search-Efficient Large Language Models](https://arxiv.org//abs/2505.07903)

	Zeyang Sha, Shiwen Cui, Weiqiang Wang

+ [A Reproduction Study: The Kernel PCA Interpretation of Self-Attention Fails Under Scrutiny](https://arxiv.org//abs/2505.07908)

	Karahan Sarıtaş, Çağatay Yıldız

+ [Efficient and Reproducible Biomedical Question Answering using Retrieval Augmented Generation](https://arxiv.org//abs/2505.07917)

	Linus Stuhlmann, Michael Alexander Saxer, Jonathan Fürst

+ [FalseReject: A Resource for Improving Contextual Safety and Mitigating Over-Refusals in LLMs via Structured Reasoning](https://arxiv.org//abs/2505.08054)

	Zhehao Zhang, Weijie Xu, Fanyou Wu, Chandan K. Reddy

+ [Beyond Input Activations: Identifying Influential Latents by Gradient Sparse Autoencoders](https://arxiv.org//abs/2505.08080)

	Dong Shu, Xuansheng Wu, Haiyan Zhao, Mengnan Du, Ninghao Liu

+ [Assessing and Mitigating Medical Knowledge Drift and Conflicts in Large Language Models](https://arxiv.org//abs/2505.07968)

	Weiyi Wu, Xinwen Xu, Chongyang Gao, Xingjian Diao, Siting Li, Lucas A. Salas, Jiang Gui

+ [Putting It All into Context: Simplifying Agents with LCLMs](https://arxiv.org//abs/2505.08120)

	Mingjian Jiang, Yangjun Ruan, Luis Lastras, Pavan Kapanipathi, Tatsunori Hashimoto

+ [Making Small Language Models Efficient Reasoners: Intervention, Supervision, Reinforcement](https://arxiv.org//abs/2505.07961)

	Xuechen Zhang, Zijian Huang, Chenchun Ni, Ziyang Xiong, Jiasi Chen, Samet Oymak

+ [Security of Internet of Agents: Attacks and Countermeasures](https://arxiv.org//abs/2505.08807)

	Yuntao Wang, Yanghe Pan, Shaolong Guo, Zhou Su

+ [An Extra RMSNorm is All You Need for Fine Tuning to 1.58 Bits](https://arxiv.org//abs/2505.08823)

	Cody Steinmetz, Gavin Childress, Aaron Herbst, Gavin Jones, Jasdeep Singh, Eli Vang, Keagan Weinstock

+ [Self Rewarding Self Improving](https://arxiv.org//abs/2505.08827)

	Toby Simonds, Kevin Lopez, Akira Yoshiyama, Dominique Garmier

+ [Evaluating Large Language Models for Real-World Engineering Tasks](https://arxiv.org//abs/2505.13484)

	Rene Heesch, Sebastian Eilermann, Alexander Windmann, Alexander Diedrich, Philipp Rosenthal, Oliver Niggemann

# 2025-05-11
+ [Control Plane as a Tool: A Scalable Design Pattern for Agentic AI Systems](https://arxiv.org//abs/2505.06817)

	Sivasathivel Kandasamy

+ [Towards Artificial General or Personalized Intelligence? A Survey on Foundation Models for Personalized Federated Intelligence](https://arxiv.org//abs/2505.06907)

	Yu Qiao, Huy Q. Le, Avi Deb Raha, Phuong-Nam Tran, Apurba Adhikary, Mengchun Zhang, Loc X. Nguyen, Eui-Nam Huh, Dusit Niyato, Choong Seon Hong

+ [LLM-Augmented Chemical Synthesis and Design Decision Programs](https://arxiv.org//abs/2505.07027)

	Haorui Wang, Jeff Guo, Lingkai Kong, Rampi Ramprasad, Philippe Schwaller, Yuanqi Du, Chao Zhang

+ [DialogueReason: Rule-Based RL Sparks Dialogue Reasoning in LLMs](https://arxiv.org//abs/2505.07049)

	Yubo Shu, Zhewei Huang, Xin Wu, Chen Hu, Shuchang Zhou, Daxin Jiang

+ [Architectural Precedents for General Agents using Large Language Models](https://arxiv.org//abs/2505.07087)

	Robert E. Wray, James R. Kirk, John E. Laird

+ [RefPentester: A Knowledge-Informed Self-Reflective Penetration Testing Framework Based on Large Language Models](https://arxiv.org//abs/2505.07089)

	Hanzheng Dai, Yuanliang Li, Zhibo Zhang, Jun Yan

+ [ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification](https://arxiv.org//abs/2505.06821)

	Dipayan Saha, Hasan Al Shaikh, Shams Tarek, Farimah Farahmandi

+ [Sandcastles in the Storm: Revisiting the (Im)possibility of Strong Watermarking](https://arxiv.org//abs/2505.06827)

	Fabrice Y Harel-Canada, Boran Erol, Connor Choi, Jason Liu, Gary Jiarui Song, Nanyun Peng, Amit Sahai

+ [The power of fine-grained experts: Granularity boosts expressivity in Mixture of Experts](https://arxiv.org//abs/2505.06839)

	Enric Boix-Adsera, Philippe Rigollet

+ [IM-BERT: Enhancing Robustness of BERT through the Implicit Euler Method](https://arxiv.org//abs/2505.06889)

	Mihyeon Kim, Juhyoung Park, Youngbin Kim

+ [RedTeamLLM: an Agentic AI framework for offensive security](https://arxiv.org//abs/2505.06913)

	Brian Challita, Pierre Parrend

+ [Convert Language Model into a Value-based Strategic Planner](https://arxiv.org//abs/2505.06987)

	Xiaoyu Wang, Yue Zhao, Qingqing Gu, Zhonglin Jiang, Xiaokai Chen, Yong Chen, Luo Ji

+ [ParaView-MCP: An Autonomous Visualization Agent with Direct Tool Use](https://arxiv.org//abs/2505.07064)

	Shusen Liu, Haichao Miao, Peer-Timo Bremer

+ [EcoLANG: Efficient and Effective Agent Communication Language Induction for Social Simulation](https://arxiv.org//abs/2505.06904)

	Xinyi Mou, Chen Qian, Wei Liu, Xuanjing Huang, Zhongyu Wei

+ [The Distracting Effect: Understanding Irrelevant Passages in RAG](https://arxiv.org//abs/2505.06914)

	Chen Amiraz, Florin Cuconasu, Simone Filice, Zohar Karnin

+ [Benign Samples Matter! Fine-tuning On Outlier Benign Samples Severely Breaks Safety](https://arxiv.org//abs/2505.06843)

	Zihan Guan, Mengxuan Hu, Ronghang Zhu, Sheng Li, Anil Vullikanti

+ [Building a Human-Verified Clinical Reasoning Dataset via a Human LLM Hybrid Pipeline for Trustworthy Medical AI](https://arxiv.org//abs/2505.06912)

	Chao Ding, Mouxiao Bian, Pengcheng Chen, Hongliang Zhang, Tianbin Li, Lihao Liu, Jiayuan Chen, Zhuoran Li, Yabei Zhong, Yongqi Liu, Haiqing Huang, Dongming Shan, Junjun He, Jie Xu

+ [Hallucination-Aware Multimodal Benchmark for Gastrointestinal Image Analysis with Large Vision-Language Models](https://arxiv.org//abs/2505.07001)

	Bidur Khanal, Sandesh Pokhrel, Sanjay Bhandari, Ramesh Rana, Nikesh Shrestha, Ram Bahadur Gurung, Cristian Linte, Angus Watson, Yash Raj Shrestha, Binod Bhattarai

+ [GuidedQuant: Large Language Model Quantization via Exploiting End Loss Guidance](https://arxiv.org//abs/2505.07004)

	Jinuk Kim, Marwa El Halabi, Wonpyo Park, Clemens JS Schaefer, Deokjae Lee, Yeonhong Park, Jae W. Lee, Hyun Oh Song

+ [PLHF: Prompt Optimization with Few-Shot Human Feedback](https://arxiv.org//abs/2505.07886)

	Chun-Pai Yang, Kan Zheng, Shou-De Lin

+ [TrumorGPT: Graph-Based Retrieval-Augmented Large Language Model for Fact-Checking](https://arxiv.org//abs/2505.07891)

	Ching Nam Hang, Pei-Duo Yu, Chee Wei Tan

+ [Evaluating Reasoning LLMs for Suicide Screening with the Columbia-Suicide Severity Rating Scale](https://arxiv.org//abs/2505.13480)

	Avinash Patil, Siru Tao, Amardeep Gedhu

# 2025-05-10
+ [System Prompt Poisoning: Persistent Attacks on Large Language Models Beyond User Injection](https://arxiv.org//abs/2505.06493)

	Jiawei Guo, Haipeng Cai

+ [MacRAG: Compress, Slice, and Scale-up for Multi-Scale Adaptive Context RAG](https://arxiv.org//abs/2505.06569)

	Woosang Lim, Zekun Li, Gyuwan Kim, Sungyoung Ji, HyeonJung Kim, Kyuri Choi, Jin Hyuk Lim, Kyungpyo Park, William Yang Wang

+ [Think in Safety: Unveiling and Mitigating Safety Alignment Collapse in Multimodal Large Reasoning Model](https://arxiv.org//abs/2505.06538)

	Xinyue Lou, You Li, Jinan Xu, Xiangyu Shi, Chi Chen, Kaiyu Huang

+ [REFINE-AF: A Task-Agnostic Framework to Align Language Models via Self-Generated Instructions using Reinforcement Learning from Automated Feedback](https://arxiv.org//abs/2505.06548)

	Aniruddha Roy, Pretam Ray, Abhilash Nandy, Somak Aditya, Pawan Goyal

+ [Using External knowledge to Enhanced PLM for Semantic Matching](https://arxiv.org//abs/2505.06605)

	Min Li, Chun Yuan

+ [Attention Is Not All You Need: The Importance of Feedforward Networks in Transformer Models](https://arxiv.org//abs/2505.06633)

	Isaac Gerber

+ [From Rankings to Insights: Evaluation Should Shift Focus from Leaderboard to Feedback](https://arxiv.org//abs/2505.06698)

	Zongqi Wang, Tianle Gu, Chen Gong, Xin Tian, Siqi Bao, Yujiu Yang

+ [Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free](https://arxiv.org//abs/2505.06708)

	Zihan Qiu, Zekun Wang, Bo Zheng, Zeyu Huang, Kaiyue Wen, Songlin Yang, Rui Men, Le Yu, Fei Huang, Suozhi Huang, Dayiheng Liu, Jingren Zhou, Junyang Lin

+ [Improving Block-Wise LLM Quantization by 4-bit Block-Wise Optimal Float (BOF4): Analysis and Variations](https://arxiv.org//abs/2505.06653)

	Patrick Blumenberg, Thomas Graave, Tim Fingscheidt

+ [Probing In-Context Learning: Impact of Task Complexity and Model Architecture on Generalization and Efficiency](https://arxiv.org//abs/2505.06475)

	Binwen Liu, Peiyu Xu, Quan Yuan, Yihong Chen

+ [QoS-Efficient Serving of Multiple Mixture-of-Expert LLMs Using Partial Runtime Reconfiguration](https://arxiv.org//abs/2505.06481)

	HamidReza Imani, Jiaxin Peng, Peiman Mohseni, Abdolah Amirany, Tarek El-Ghazawi

+ [RuleGenie: SIEM Detection Rule Set Optimization](https://arxiv.org//abs/2505.06701)

	Akansha Shukla, Parth Atulbhai Gandhi, Yuval Elovici, Asaf Shabtai

+ [POISONCRAFT: Practical Poisoning of Retrieval-Augmented Generation for Large Language Models](https://arxiv.org//abs/2505.06579)

	Yangguang Shao, Xinjie Lin, Haozheng Luo, Chengshang Hou, Gang Xiong, Jiahao Yu, Junzheng Shi

+ [Practical Reasoning Interruption Attacks on Reasoning Large Language Models](https://arxiv.org//abs/2505.06643)

	Yu Cui, Cong Zuo

+ [I Know What You Said: Unveiling Hardware Cache Side-Channels in Local Large Language Model Inference](https://arxiv.org//abs/2505.06738)

	Zibo Gao, Junjie Hu, Feng Guo, Yixin Zhang, Yinglong Han, Siyuan Liu, Haiyang Li, Zhiqiang Lv

+ [OMGM: Orchestrate Multiple Granularities and Modalities for Efficient Multimodal Retrieval](https://arxiv.org//abs/2505.07879)

	Wei Yang, Jingjing Fu, Rui Wang, Jinyu Wang, Lei Song, Jiang Bian

+ [Recovering Event Probabilities from Large Language Model Embeddings via Axiomatic Constraints](https://arxiv.org//abs/2505.07883)

	Jian-Qiao Zhu, Haijiang Yan, Thomas L. Griffiths

+ [Multi-modal Synthetic Data Training and Model Collapse: Insights from VLMs and Diffusion Models](https://arxiv.org//abs/2505.08803)

	Zizhao Hu, Mohammad Rostami, Jesse Thomason

+ [PRUNE: A Patching Based Repair Framework for Certifiable Unlearning of Neural Networks](https://arxiv.org//abs/2505.06520)

	Xuran Li, Jingyi Wang, Xiaohan Yuan, Peixin Zhang, Zhan Qin, Zhibo Wang, Kui Ren

+ [Prompt Engineering: How Prompt Vocabulary affects Domain Knowledge](https://arxiv.org//abs/2505.17037)

	Dimitri Schreiter

# 2025-05-09
+ [APOLLO: Automated LLM and Lean Collaboration for Advanced Formal Reasoning](https://arxiv.org//abs/2505.05758)

	Azim Ospanov, Roozbeh Yousefzadeh

+ [ArtRAG: Retrieval-Augmented Generation with Structured Context for Visual Art Understanding](https://arxiv.org//abs/2505.06020)

	Shuai Wang, Ivona Najdenkoska, Hongyi Zhu, Stevan Rudinac, Monika Kackovic, Nachoem Wijnberg, Marcel Worring

+ [Assessing Robustness to Spurious Correlations in Post-Training Language Models](https://arxiv.org//abs/2505.05704)

	Julia Shuieh, Prasann Singhal, Apaar Shanker, John Heyer, George Pu, Samuel Denton

+ [Multi-Agent Systems for Robotic Autonomy with LLMs](https://arxiv.org//abs/2505.05762)

	Junhong Chen, Ziqi Yang, Haoyuan G Xu, Dandan Zhang, George Mylonas

+ [AgentXploit: End-to-End Redteaming of Black-Box AI Agents](https://arxiv.org//abs/2505.05849)

	Zhun Wang, Vincent Siu, Zhe Ye, Tianneng Shi, Yuzhou Nie, Xuandong Zhao, Chenguang Wang, Wenbo Guo, Dawn Song

+ [Elastic Weight Consolidation for Full-Parameter Continual Pre-Training of Gemma2](https://arxiv.org//abs/2505.05946)

	Vytenis Šliogeris, Povilas Daniušis, Artūras Nakvosas

+ [A Scaling Law for Token Efficiency in LLM Fine-Tuning Under Fixed Compute Budgets](https://arxiv.org//abs/2505.06150)

	Ryan Lagasse, Aidan Kiernans, Avijit Ghosh, Shiri Dori-Hacohen

+ [Sparse Attention Remapping with Clustering for Efficient LLM Decoding on PIM](https://arxiv.org//abs/2505.05772)

	Zehao Fan, Garrett Gagnon, Zhenyu Liu, Liu Liu

+ [NeoQA: Evidence-based Question Answering with Generated News Events](https://arxiv.org//abs/2505.05949)

	Max Glockner, Xiang Jiang, Leonardo F. R. Ribeiro, Iryna Gurevych, Markus Dreyer

+ [Towards Developmentally Plausible Rewards: Communicative Success as a Learning Signal for Interactive Language Models](https://arxiv.org//abs/2505.05970)

	Lennart Stöpler, Rufat Asadli, Mitja Nikolaus, Ryan Cotterell, Alex Warstadt

+ [Unilogit: Robust Machine Unlearning for LLMs Using Uniform-Target Self-Distillation](https://arxiv.org//abs/2505.06027)

	Stefan Vasilev, Christian Herold, Baohao Liao, Seyyed Hadi Hashemi, Shahram Khadivi, Christof Monz

+ [Healthy LLMs? Benchmarking LLM Knowledge of UK Government Public Health Information](https://arxiv.org//abs/2505.06046)

	Joshua Harris, Fan Grayson, Felix Feldman, Timothy Laurence, Toby Nonnenmacher, Oliver Higgins, Leo Loman, Selina Patel, Thomas Finnie, Samuel Collins, Michael Borowitz

+ [LLMs Get Lost In Multi-Turn Conversation](https://arxiv.org//abs/2505.06120)

	Philippe Laban, Hiroaki Hayashi, Yingbo Zhou, Jennifer Neville

+ [Can Prompting LLMs Unlock Hate Speech Detection across Languages? A Zero-shot and Few-shot Study](https://arxiv.org//abs/2505.06149)

	Faeze Ghorbanpour, Daryna Dementieva, Alexander Fraser

+ [Multimodal Integrated Knowledge Transfer to Large Language Models through Preference Optimization with Biomedical Applications](https://arxiv.org//abs/2505.05736)

	Da Wu, Zhanliang Wang, Quan Nguyen, Zhuoran Xu, Kai Wang

+ [Harnessing LLMs Explanations to Boost Surrogate Models in Tabular Data Classification](https://arxiv.org//abs/2505.05744)

	Ruxue Shi, Hengrui Gu, Xu Shen, Xin Wang

+ [Short-circuiting Shortcuts: Mechanistic Investigation of Shortcuts in Text Classification](https://arxiv.org//abs/2505.06032)

	Leon Eshuijs, Shihan Wang, Antske Fokkens

+ [FloE: On-the-Fly MoE Inference](https://arxiv.org//abs/2505.05950)

	Yuxin Zhou, Zheng Li, Jun Zhang, Jue Wang, Yiping Wang, Zhongle Xie, Ke Chen, Lidan Shou

+ [Understanding Stragglers in Large Model Training Using What-if Analysis](https://arxiv.org//abs/2505.05713)

	Jinkun Lin, Ziheng Jiang, Zuquan Song, Sida Zhao, Menghan Yu, Zhanghan Wang, Chenyuan Wang, Zuocheng Shi, Xiang Shi, Wei Jia, Zherui Liu, Shuguang Wang, Haibin Lin, Xiu Liu, Aurojit Panda, Jinyang Li

+ [CAPE: Context-Aware Prompt Perturbation Mechanism with Differential Privacy](https://arxiv.org//abs/2505.05922)

	Haoqi Wu, Wei Dai, Li Wang, Qiang Yan

+ [LLM-Text Watermarking based on Lagrange Interpolation](https://arxiv.org//abs/2505.05712)

	Jarosław Janas, Paweł Morawiecki, Josef Pieprzyk

+ [A Grounded Memory System For Smart Personal Assistants](https://arxiv.org//abs/2505.06328)

	Felix Ocker, Jörg Deigmöller, Pavel Smirnov, Julian Eggert

+ [Reliable Collaborative Conversational Agent System Based on LLMs and Answer Set Programming](https://arxiv.org//abs/2505.06438)

	Yankai Zeng, Gopal Gupta

+ [KCluster: An LLM-based Clustering Approach to Knowledge Component Discovery](https://arxiv.org//abs/2505.06469)

	Yumou Wei, Paulo Carvalho, John Stamper

+ [Learn to Think: Bootstrapping LLM Reasoning Capability Through Graph Learning](https://arxiv.org//abs/2505.06321)

	Hang Gao, Chenhao Zhang, Tie Wang, Junsuo Zhao, Fengge Wu, Changwen Zheng, Huaping Liu

+ [Document Attribution: Examining Citation Relationships using Large Language Models](https://arxiv.org//abs/2505.06324)

	Vipula Rawte, Ryan A. Rossi, Franck Dernoncourt, Nedim Lipka

+ [Prompting Large Language Models for Training-Free Non-Intrusive Load Monitoring](https://arxiv.org//abs/2505.06330)

	Junyu Xue, Xudong Wang, Xiaoling He, Shicheng Liu, Yi Wang, Guoming Tang

+ [Towards AI-Driven Human-Machine Co-Teaming for Adaptive and Agile Cyber Security Operation Centers](https://arxiv.org//abs/2505.06394)

	Massimiliano Albanese, Xinming Ou, Kevin Lybarger, Daniel Lende, Dmitry Goldgof

+ [Engineering Risk-Aware, Security-by-Design Frameworks for Assurance of Large-Scale Autonomous AI Models](https://arxiv.org//abs/2505.06409)

	Krti Tallam

+ [Natural Reflection Backdoor Attack on Vision Language Model for Autonomous Driving](https://arxiv.org//abs/2505.06413)

	Ming Liu, Siyuan Liang, Koushik Howlader, Liwen Wang, Dacheng Tao, Wensheng Zhang

+ [ScaleMCP: Dynamic and Auto-Synchronizing Model Context Protocol Tools for LLM Agents](https://arxiv.org//abs/2505.06416)

	Elias Lumer, Anmol Gulati, Vamse Kumar Subbiah, Pradeep Honaganahalli Basavaraju, James A. Burke

+ [Is your multimodal large language model a good science tutor?](https://arxiv.org//abs/2505.06418)

	Ming Liu, Liwen Wang, Wensheng Zhang

+ [Efficient Fairness Testing in Large Language Models: Prioritizing Metamorphic Relations for Bias Detection](https://arxiv.org//abs/2505.07870)

	Suavis Giramata, Madhusudan Srinivasan, Venkat Naidu Gudivada, Upulee Kanewala

+ [Insertion Language Models: Sequence Generation with Arbitrary-Position Insertions](https://arxiv.org//abs/2505.05755)

	Dhruvesh Patel, Aishwarya Sahoo, Avinash Amballa, Tahira Naseem, Tim G. J. Rudner, Andrew McCallum

+ [The Spotlight Resonance Method: Resolving the Alignment of Embedded Activations](https://arxiv.org//abs/2505.13471)

	George Bird

# 2025-05-08
+ [Enigme: Generative Text Puzzles for Evaluating Reasoning in Language Models](https://arxiv.org//abs/2505.04914)

	John Hawkins

+ [Belief Filtering for Epistemic Control in Linguistic State Space](https://arxiv.org//abs/2505.04927)

	Sebastian Dumbrava

+ [A Reputation System for Large Language Model-based Multi-agent Systems to Avoid the Tragedy of the Commons](https://arxiv.org//abs/2505.05029)

	Siyue Ren, Wanli Fu, Xinkun Zou, Chen Shen, Yi Cai, Chen Chu, Zhen Wang, Shuyue Hu

+ [MARK: Memory Augmented Refinement of Knowledge](https://arxiv.org//abs/2505.05177)

	Anish Ganguli, Prabal Deb, Debleena Banerjee

+ [ConCISE: Confidence-guided Compression in Step-by-step Efficient Reasoning](https://arxiv.org//abs/2505.04881)

	Ziqing Qiao, Yongheng Deng, Jiali Zeng, Dong Wang, Lai Wei, Fandong Meng, Jie Zhou, Ju Ren, Yaoxue Zhang

+ [Chain-of-Thought Tokens are Computer Program Variables](https://arxiv.org//abs/2505.04955)

	Fangwei Zhu, Peiyi Wang, Zhifang Sui

+ [Rethinking Invariance in In-context Learning](https://arxiv.org//abs/2505.04994)

	Lizhe Fang, Yifei Wang, Khashayar Gatmiry, Lei Fang, Yisen Wang

+ [Understanding In-context Learning of Addition via Activation Subspaces](https://arxiv.org//abs/2505.05145)

	Xinyan Hu, Kayo Yin, Michael I. Jordan, Jacob Steinhardt, Lijie Chen

+ [Revealing Weaknesses in Text Watermarking Through Self-Information Rewrite Attacks](https://arxiv.org//abs/2505.05190)

	Yixin Cheng, Hongcheng Guo, Yangming Li, Leonid Sigal

+ [Software Development Life Cycle Perspective: A Survey of Benchmarks for CodeLLMs and Agents](https://arxiv.org//abs/2505.05283)

	Kaixin Wang, Tianlin Li, Xiaoyu Zhang, Chong Wang, Weisong Sun, Yang Liu, Bin Shi

+ [Scalable Chain of Thoughts via Elastic Reasoning](https://arxiv.org//abs/2505.05315)

	Yuhui Xu, Hanze Dong, Lei Wang, Doyen Sahoo, Junnan Li, Caiming Xiong

+ [Crosslingual Reasoning through Test-Time Scaling](https://arxiv.org//abs/2505.05408)

	Zheng-Xin Yong, M. Farid Adilazuarda, Jonibek Mansurov, Ruochen Zhang, Niklas Muennighoff, Carsten Eickhoff, Genta Indra Winata, Julia Kreutzer, Stephen H. Bach, Alham Fikri Aji

+ [Reasoning Models Don't Always Say What They Think](https://arxiv.org//abs/2505.05410)

	Yanda Chen, Joe Benton, Ansh Radhakrishnan, Jonathan Uesato, Carson Denison, John Schulman, Arushi Somani, Peter Hase, Misha Wagner, Fabien Roger, Vlad Mikulik, Samuel R. Bowman, Jan Leike, Jared Kaplan, Ethan Perez

+ [ComPO: Preference Alignment via Comparison Oracles](https://arxiv.org//abs/2505.05465)

	Peter Chen, Xi Chen, Wotao Yin, Tianyi Lin

+ [StreamBridge: Turning Your Offline Video Large Language Model into a Proactive Streaming Assistant](https://arxiv.org//abs/2505.05467)

	Haibo Wang, Bo Feng, Zhengfeng Lai, Mingze Xu, Shiyu Li, Weifeng Ge, Afshin Dehghan, Meng Cao, Ping Huang

+ [Latent Preference Coding: Aligning Large Language Models via Discrete Latent Codes](https://arxiv.org//abs/2505.04993)

	Zhuocheng Gong, Jian Guan, Wei Wu, Huishuai Zhang, Dongyan Zhao

+ [The Pitfalls of Growing Group Complexity: LLMs and Social Choice-Based Aggregation for Group Recommendations](https://arxiv.org//abs/2505.05016)

	Cedric Waterschoot, Nava Tintarev, Francesco Barile

+ [Scalable Multi-Stage Influence Function for Large Language Models via Eigenvalue-Corrected Kronecker-Factored Parameterization](https://arxiv.org//abs/2505.05017)

	Yuntai Bao, Xuhong Zhang, Tianyu Du, Xinkui Zhao, Jiang Zong, Hao Peng, Jianwei Yin

+ [Reliably Bounding False Positives: A Zero-Shot Machine-Generated Text Detection Framework via Multiscaled Conformal Prediction](https://arxiv.org//abs/2505.05084)

	Xiaowei Zhu, Yubing Ren, Yanan Cao, Xixun Lin, Fang Fang, Yangxi Li

+ [Unveiling Language-Specific Features in Large Language Models via Sparse Autoencoders](https://arxiv.org//abs/2505.05111)

	Boyi Deng, Yu Wan, Yidan Zhang, Baosong Yang, Fuli Feng

+ [QualBench: Benchmarking Chinese LLMs with Localized Professional Qualifications for Vertical Domain Evaluation](https://arxiv.org//abs/2505.05225)

	Mengze Hong, Wailing Ng, Di Jiang, Chen Jason Zhang

+ [Toward Reasonable Parrots: Why Large Language Models Should Argue with Us by Design](https://arxiv.org//abs/2505.05298)

	Elena Musi, Nadin Kokciyan, Khalid Al-Khatib, Davide Ceolin, Emmanuelle Dietz, Klara Gutekunst, Annette Hautli-Janisz, Cristian Manuel Santibañez Yañez, Jodi Schneider, Jonas Scholz, Cor Steging, Jacky Visser, Henning Wachsmuth

+ [ICon: In-Context Contribution for Automatic Data Selection](https://arxiv.org//abs/2505.05327)

	Yixin Yang, Qingxiu Dong, Linli Yao, Fangwei Zhu, Zhifang Sui

+ [Frame In, Frame Out: Do LLMs Generate More Biased News Headlines than Humans?](https://arxiv.org//abs/2505.05406)

	Valeria Pastorino, Nafise Sadat Moosavi

+ [Ultra-FineWeb: Efficient Data Filtering and Verification for High-Quality LLM Training Data](https://arxiv.org//abs/2505.05427)

	Yudong Wang, Zixuan Fu, Jie Cai, Peijun Tang, Hongya Lyu, Yewei Fang, Zhi Zheng, Jie Zhou, Guoyang Zeng, Chaojun Xiao, Xu Han, Zhiyuan Liu

+ [clem:todd: A Framework for the Systematic Benchmarking of LLM-Based Task-Oriented Dialogue System Realisations](https://arxiv.org//abs/2505.05445)

	Chalamalasetti Kranti, Sherzod Hakimov, David Schlangen

+ [Bring Reason to Vision: Understanding Perception and Reasoning through Model Merging](https://arxiv.org//abs/2505.05464)

	Shiqi Chen, Jinghan Zhang, Tongyao Zhu, Wei Liu, Siyang Gao, Miao Xiong, Manling Li, Junxian He

+ [Perception, Reason, Think, and Plan: A Survey on Large Multimodal Reasoning Models](https://arxiv.org//abs/2505.04921)

	Yunxin Li, Zhenyu Liu, Zitao Li, Xuanyu Zhang, Zhenran Xu, Xinyu Chen, Haoyuan Shi, Shenyuan Jiang, Xintong Wang, Jifang Wang, Shouzheng Huang, Xinping Zhao, Borui Jiang, Lanqing Hong, Longyue Wang, Zhuotao Tian, Baoxing Huai, Wenhan Luo, Weihua Luo, Zheng Zhang, Baotian Hu, Min Zhang

+ [Prompt-Based LLMs for Position Bias-Aware Reranking in Personalized Recommendations](https://arxiv.org//abs/2505.04948)

	Md Aminul Islam, Ahmed Sayeed Faruk

+ [WaterDrum: Watermarking for Data-centric Unlearning Metric](https://arxiv.org//abs/2505.05064)

	Xinyang Lu, Xinyuan Niu, Gregory Kang Ruey Lau, Bui Thi Cam Nhung, Rachael Hwee Ling Sim, Fanyu Wen, Chuan-Sheng Foo, See-Kiong Ng, Bryan Kian Hsiang Low

+ [FedTDP: A Privacy-Preserving and Unified Framework for Trajectory Data Preparation via Federated Learning](https://arxiv.org//abs/2505.05155)

	Zhihao Zeng, Ziquan Fang, Wei Shao, Lu Chen, Yunjun Gao

+ [Latte: Transfering LLMs` Latent-level Knowledge for Few-shot Tabular Learning](https://arxiv.org//abs/2505.05237)

	Ruxue Shi, Hengrui Gu, Hangting Ye, Yiwei Dai, Xu Shen, Xin Wang

+ [A Weighted Byzantine Fault Tolerance Consensus Driven Trusted Multiple Large Language Models Network](https://arxiv.org//abs/2505.05103)

	Haoxiang Luo, Gang Sun, Yinqiu Liu, Dongcheng Zhao, Dusit Niyato, Hongfang Yu, Schahram Dustdar

+ [Safety by Measurement: A Systematic Literature Review of AI Safety Evaluation Methods](https://arxiv.org//abs/2505.05541)

	Markov Grey, Charbel-Raphaël Segerie

+ [HiBayES: A Hierarchical Bayesian Modeling Framework for AI Evaluation Statistics](https://arxiv.org//abs/2505.05602)

	Lennart Luettgau, Harry Coppock, Magda Dubois, Christopher Summerfield, Cozmin Ududec

+ [CityNavAgent: Aerial Vision-and-Language Navigation with Hierarchical Semantic Planning and Global Memory](https://arxiv.org//abs/2505.05622)

	Weichen Zhang, Chen Gao, Shiquan Yu, Ruiying Peng, Baining Zhao, Qian Zhang, Jinqiang Cui, Xinlei Chen, Yong Li

+ [Looking Beyond Language Priors: Enhancing Visual Comprehension and Attention in Multimodal Models](https://arxiv.org//abs/2505.05626)

	Aarti Ghatkesar, Uddeshya Upadhyay, Ganesh Venkatesh

+ [Adaptive Stress Testing Black-Box LLM Planners](https://arxiv.org//abs/2505.05665)

	Neeloy Chakraborty, John Pohovey, Melkior Ornik, Katherine Driggs-Campbell

+ [Lost in OCR Translation? Vision-Based Approaches to Robust Document Retrieval](https://arxiv.org//abs/2505.05666)

	Alexander Most, Joseph Winjum, Ayan Biswas, Shawn Jones, Nishath Rajiv Ranasinghe, Dan O'Malley, Manish Bhattarai

+ [EcoAgent: An Efficient Edge-Cloud Collaborative Multi-Agent Framework for Mobile Automation](https://arxiv.org//abs/2505.05440)

	Biao Yi, Xavier Hu, Yurun Chen, Shengyu Zhang, Hongxia Yang, Fan Wu, Fei Wu

+ [KG-HTC: Integrating Knowledge Graphs into LLMs for Effective Zero-shot Hierarchical Text Classification](https://arxiv.org//abs/2505.05583)

	Qianbo Zang, Christophe Zgrzendek, Igor Tchappi, Afshin Khadangi, Johannes Sedlmeir

+ [Privacy-Preserving Transformers: SwiftKey's Differential Privacy Implementation](https://arxiv.org//abs/2505.05648)

	Abdelrahman Abouelenin, Mohamed Abdelrehim, Raffy Fahim, Amr Hendy, Mohamed Afify

+ [PRIMG : Efficient LLM-driven Test Generation Using Mutant Prioritization](https://arxiv.org//abs/2505.05584)

	Mohamed Salah Bouafif, Mohammad Hamdaqa, Edward Zulkoski

+ [Enhancing Large Language Models with Faster Code Preprocessing for Vulnerability Detection](https://arxiv.org//abs/2505.05600)

	José Gonçalves, Miguel Silva, Eva Maia, Isabel Praça

+ [LiteLMGuard: Seamless and Lightweight On-Device Prompt Filtering for Safeguarding Small Language Models against Quantization-induced Risks and Vulnerabilities](https://arxiv.org//abs/2505.05619)

	Kalyan Nakka, Jimmy Dani, Ausmit Mondal, Nitesh Saxena

+ [User Behavior Analysis in Privacy Protection with Large Language Models: A Study on Privacy Preferences with Limited Data](https://arxiv.org//abs/2505.06305)

	Haowei Yang, Qingyi Lu, Yang Wang, Sibei Liu, Jiayun Zheng, Ao Xiang

+ [Large Language Model-driven Security Assistant for Internet of Things via Chain-of-Thought](https://arxiv.org//abs/2505.06307)

	Mingfei Zeng, Ming Xie, Xixi Zheng, Chunhai Li, Chuan Zhang, Liehuang Zhu

+ [Defending against Indirect Prompt Injection by Instruction Detection](https://arxiv.org//abs/2505.06311)

	Tongyu Wen, Chenglong Wang, Xiyuan Yang, Haoyu Tang, Yueqi Xie, Lingjuan Lyu, Zhicheng Dou, Fangzhao Wu

+ [AI Approaches to Qualitative and Quantitative News Analytics on NATO Unity](https://arxiv.org//abs/2505.06313)

	Bohdan M. Pavlyshenko

+ [Threat Modeling for AI: The Case for an Asset-Centric Approach](https://arxiv.org//abs/2505.06315)

	Jose Sanchez Vicarte, Marcin Spoczynski, Mostafa Elsaid

+ [RAP-SM: Robust Adversarial Prompt via Shadow Models for Copyright Verification of Large Language Models](https://arxiv.org//abs/2505.06304)

	Zhenhua Xu, Zhebo Wang, Maike Li, Wenpeng Xing, Chunqiang Hu, Chen Zhi, Meng Han

+ [Unpacking Robustness in Inflectional Languages: Adversarial Evaluation and Mechanistic Insights](https://arxiv.org//abs/2505.07856)

	Paweł Walkowiak, Marek Klonowski, Marcin Oleksy, Arkadiusz Janz

+ [Scaling Laws for Speculative Decoding](https://arxiv.org//abs/2505.07858)

	Siyuan Yan, Mo Zhu, Guo-qing Jiang, Jianfei Wang, Jiaxing Chen, Wentai Zhang, Xiang Liao, Xiao Cui, Chen Zhang, Zhuoran Song, Ran Zhu

+ [Scalable LLM Math Reasoning Acceleration with Low-rank Distillation](https://arxiv.org//abs/2505.07861)

	Harry Dong, Bilge Acun, Beidi Chen, Yuejie Chi

# 2025-05-07
+ [Advancing and Benchmarking Personalized Tool Invocation for LLMs](https://arxiv.org//abs/2505.04072)

	Xu Huang, Yuefeng Huang, Weiwen Liu, Xingshan Zeng, Yasheng Wang, Ruiming Tang, Hong Xie, Defu Lian

+ [LLM-e Guess: Can LLMs Capabilities Advance Without Hardware Progress?](https://arxiv.org//abs/2505.04075)

	Teddy Foley, Spencer Guo, Henry Josephson, Anqi Qu, Jack Sanderson

+ [LLMs' Suitability for Network Security: A Case Study of STRIDE Threat Modeling](https://arxiv.org//abs/2505.04101)

	AbdulAziz AbdulGhaffar, Ashraf Matrawy

+ [Unmasking the Canvas: A Dynamic Benchmark for Image Generation Jailbreaking and LLM Content Safety](https://arxiv.org//abs/2505.04146)

	Variath Madhupal Gautham Nair, Vishal Varma Dantuluri

+ [On-Device LLM for Context-Aware Wi-Fi Roaming](https://arxiv.org//abs/2505.04174)

	Ju-Hyung Lee, Yanqing Lu

+ [Facilitating Trustworthy Human-Agent Collaboration in LLM-based Multi-Agent System oriented Software Engineering](https://arxiv.org//abs/2505.04251)

	Krishna Ronanki

+ [Steerable Chatbots: Personalizing LLMs with Preference-Based Activation Steering](https://arxiv.org//abs/2505.04260)

	Jessica Y. Bo, Tianyu Xu, Ishan Chatterjee, Katrina Passarella-Ward, Achin Kulshrestha, D Shin

+ [Weaponizing Language Models for Cybersecurity Offensive Operations: Automating Vulnerability Assessment Report Validation; A Review Paper](https://arxiv.org//abs/2505.04265)

	Abdulrahman S Almuhaidib, Azlan Mohd Zain, Zalmiyah Zakaria, Izyan Izzati Kamsani, Abdulaziz S Almuhaidib

+ [The Aloe Family Recipe for Open and Specialized Healthcare LLMs](https://arxiv.org//abs/2505.04388)

	Dario Garcia-Gasulla, Jordi Bayarri-Planas, Ashwin Kumar Gururajan, Enrique Lopez-Cuena, Adrian Tormos, Daniel Hinjos, Pablo Bernabeu-Perez, Anna Arias-Duart, Pablo Agustin Martin-Torres, Marta Gonzalez-Mallo, Sergio Alvarez-Napagao, Eduard Ayguadé-Parra, Ulises Cortés

+ [OBLIVIATE: Robust and Practical Machine Unlearning for Large Language Models](https://arxiv.org//abs/2505.04416)

	Xiaoyu Xu, Minxin Du, Qingqing Ye, Haibo Hu

+ [Fight Fire with Fire: Defending Against Malicious RL Fine-Tuning via Reward Neutralization](https://arxiv.org//abs/2505.04578)

	Wenjun Cao

+ [EchoInk-R1: Exploring Audio-Visual Reasoning in Multimodal LLMs via Reinforcement Learning](https://arxiv.org//abs/2505.04623)

	Zhenghao Xing, Xiaowei Hu, Chi-Wing Fu, Wenhai Wang, Jifeng Dai, Pheng-Ann Heng

+ [Enhancing Granular Sentiment Classification with Chain-of-Thought Prompting in Large Language Models](https://arxiv.org//abs/2505.04135)

	Vihaan Miriyala, Smrithi Bukkapatnam, Lavanya Prahallad

+ [LLM-Independent Adaptive RAG: Let the Question Speak for Itself](https://arxiv.org//abs/2505.04253)

	Maria Marina, Nikolay Ivanov, Sergey Pletenev, Mikhail Salnikov, Daria Galimzianova, Nikita Krayko, Vasily Konovalov, Alexander Panchenko, Viktor Moskvoretskii

+ [Large Means Left: Political Bias in Large Language Models Increases with Their Number of Parameters](https://arxiv.org//abs/2505.04393)

	David Exler, Mark Schutera, Markus Reischl, Luca Rettenberger

+ [Pangu Ultra MoE: How to Train Your Big MoE on Ascend NPUs](https://arxiv.org//abs/2505.04519)

	Yehui Tang, Yichun Yin, Yaoyuan Wang, Hang Zhou, Yu Pan, Wei Guo, Ziyang Zhang, Miao Rang, Fangcheng Liu, Naifu Zhang, Binghan Li, Yonghan Dong, Xiaojun Meng, Yasheng Wang, Dong Li, Yin Li, Dandan Tu, Can Chen, Youliang Yan, Fisher Yu, Ruiming Tang, Yunhe Wang, Botian Huang, Bo Wang, Boxiao Liu, Changzheng Zhang, Da Kuang, Fei Liu, Gang Huang, Jiansheng Wei, Jiarui Qin, Jie Ran, Jinpeng Li, Jun Zhao, Liang Dai, Lin Li, Liqun Deng, Peifeng Qin, Pengyuan Zeng, Qiang Gu, Shaohua Tang, Shengjun Cheng, Tao Gao, Tao Yu, Tianshu Li, Tianyu Bi, Wei He, Weikai Mao, Wenyong Huang, Wulong Liu, Xiabing Li, Xianzhi Yu, Xueyu Wu, Xu He, Yangkai Du, Yan Xu, Ye Tian, Yimeng Wu, Yongbing Huang, Yong Tian, Yong Zhu, Yue Li, Yufei Wang, Yuhang Gai, Yujun Li, Yu Luo, Yunsheng Ni, Yusen Sun, Zelin Chen, Zhe Liu, Zhicheng Liu, Zhipeng Tu, Zilin Ding, Zongyuan Zhan

+ [ZeroSearch: Incentivize the Search Capability of LLMs without Searching](https://arxiv.org//abs/2505.04588)

	Hao Sun, Zile Qiao, Jiayan Guo, Xuanbo Fan, Yingyan Hou, Yong Jiang, Pengjun Xie, Fei Huang, Yan Zhang

+ [Large Language Models are often politically extreme, usually ideologically inconsistent, and persuasive even in informational contexts](https://arxiv.org//abs/2505.04171)

	Nouar Aldahoul, Hazem Ibrahim, Matteo Varvello, Aaron Kaufman, Talal Rahwan, Yasir Zaki

+ [Benchmarking LLMs' Swarm intelligence](https://arxiv.org//abs/2505.04364)

	Kai Ruan, Mowen Huang, Ji-Rong Wen, Hao Sun

+ [Componential Prompt-Knowledge Alignment for Domain Incremental Learning](https://arxiv.org//abs/2505.04575)

	Kunlun Xu, Xu Zou, Gang Hua, Jiahuan Zhou

+ [Towards Effectively Leveraging Execution Traces for Program Repair with Code LLMs](https://arxiv.org//abs/2505.04441)

	Mirazul Haque, Petr Babkin, Farima Farmahinifarahani, Manuela Veloso

+ [Communication-Efficient Federated Fine-Tuning of Language Models via Dynamic Update Schedules](https://arxiv.org//abs/2505.04535)

	Michail Theologitis, Vasilis Samoladas, Antonios Deligiannakis

+ [AutoPatch: Multi-Agent Framework for Patching Real-World CVE Vulnerabilities](https://arxiv.org//abs/2505.04195)

	Minjae Seo, Wonwoo Choi, Myoungsung You, Seungwon Shin

+ [The Promise and Limits of LLMs in Constructing Proofs and Hints for Logic Problems in Intelligent Tutoring Systems](https://arxiv.org//abs/2505.04736)

	Sutapa Dey Tithi, Arun Kumar Ramesh, Clara DiMarco, Xiaoyi Tian, Nazia Alam, Kimia Fazeli, Tiffany Barnes

+ [Large Language Models are Autonomous Cyber Defenders](https://arxiv.org//abs/2505.04843)

	Sebastián R. Castro, Roberto Campbell, Nancy Lau, Octavio Villalobos, Jiaqi Duan, Alvaro A. Cardenas

+ [Personalized Risks and Regulatory Strategies of Large Language Models in Digital Advertising](https://arxiv.org//abs/2505.04665)

	Haoyang Feng, Yanjun Dai, Yuan Gao

+ [REVEAL: Multi-turn Evaluation of Image-Input Harms for Vision LLM](https://arxiv.org//abs/2505.04673)

	Madhur Jindal, Saurabh Deshpande

+ [QBD-RankedDataGen: Generating Custom Ranked Datasets for Improving Query-By-Document Search Using LLM-Reranking with Reduced Human Effort](https://arxiv.org//abs/2505.04732)

	Sriram Gopalakrishnan, Sunandita Patra

+ [When Bad Data Leads to Good Models](https://arxiv.org//abs/2505.04741)

	Kenneth Li, Yida Chen, Fernanda Viégas, Martin Wattenberg

+ [A Proposal for Evaluating the Operational Risk for ChatBots based on Large Language Models](https://arxiv.org//abs/2505.04784)

	Pedro Pinacho-Davidson, Fernando Gutierrez, Pablo Zapata, Rodolfo Vergara, Pablo Aqueveque

+ [Putting the Value Back in RL: Better Test-Time Scaling by Unifying LLM Reasoners With Verifiers](https://arxiv.org//abs/2505.04842)

	Kusha Sareen, Morgane M Moss, Alessandro Sordoni, Rishabh Agarwal, Arian Hosseini

+ [Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards](https://arxiv.org//abs/2505.04847)

	Manveer Singh Tamber, Forrest Sheng Bao, Chenyu Xu, Ge Luo, Suleman Kazi, Minseok Bae, Miaoran Li, Ofer Mendelevitch, Renyi Qu, Jimmy Lin

+ [Fine-Tuning Large Language Models and Evaluating Retrieval Methods for Improved Question Answering on Building Codes](https://arxiv.org//abs/2505.04666)

	Mohammad Aqib, Mohd Hamza, Qipei Mei, Ying Hei Chui

+ [Reward-SQL: Boosting Text-to-SQL via Stepwise Reasoning and Process-Supervised Rewards](https://arxiv.org//abs/2505.04671)

	Yuxin Zhang, Meihao Fan, Ju Fan, Mingyang Yi, Yuyu Luo, Jian Tan, Guoliang Li

+ [SOAEsV2-7B/72B: Full-Pipeline Optimization for State-Owned Enterprise LLMs via Continual Pre-Training, Domain-Progressive SFT and Distillation-Enhanced Speculative Decoding](https://arxiv.org//abs/2505.04723)

	Jingyang Deng, Ran Chen, Jo-Ku Cheng, Jinwen Ma

+ [Osiris: A Lightweight Open-Source Hallucination Detection System](https://arxiv.org//abs/2505.04844)

	Alex Shan, John Bauer, Christopher D. Manning

+ [Red Teaming the Mind of the Machine: A Systematic Evaluation of Prompt Injection and Jailbreak Vulnerabilities in LLMs](https://arxiv.org//abs/2505.04806)

	Chetan Pathade

+ [HiPerRAG: High-Performance Retrieval Augmented Generation for Scientific Insights](https://arxiv.org//abs/2505.04846)

	Ozan Gokdemir, Carlo Siebenschuh, Alexander Brace, Azton Wells, Brian Hsu, Kyle Hippe, Priyanka V. Setty, Aswathy Ajith, J. Gregory Pauloski, Varuni Sastry, Sam Foreman, Huihuo Zheng, Heng Ma, Bharat Kale, Nicholas Chia, Thomas Gibbs, Michael E. Papka, Thomas Brettin, Francis J. Alexander, Anima Anandkumar, Ian Foster, Rick Stevens, Venkatram Vishwanath, Arvind Ramanathan

+ [Safeguard-by-Development: A Privacy-Enhanced Development Paradigm for Multi-Agent Collaboration Systems](https://arxiv.org//abs/2505.04799)

	Jian Cui, Zichuan Li, Luyi Xing, Xiaojing Liao

+ [Nature's Insight: A Novel Framework and Comprehensive Analysis of Agentic Reasoning Through the Lens of Neuroscience](https://arxiv.org//abs/2505.05515)

	Zinan Liu, Haoran Li, Jingyi Lu, Gaoyuan Ma, Xu Hong, Giovanni Iacca, Arvind Kumar, Shaojun Tang, Lin Wang

+ [DMRL: Data- and Model-aware Reward Learning for Data Extraction](https://arxiv.org//abs/2505.06284)

	Zhiqiang Wang, Ruoxi Cheng

+ [Winning at All Cost: A Small Environment for Eliciting Specification Gaming Behaviors in Large Language Models](https://arxiv.org//abs/2505.07846)

	Lars Malmqvist

+ [Joint Detection of Fraud and Concept Drift inOnline Conversations with LLM-Assisted Judgment](https://arxiv.org//abs/2505.07852)

	Ali Senol, Garima Agrawal, Huan Liu

+ [AgentSGEN: Multi-Agent LLM in the Loop for Semantic Collaboration and GENeration of Synthetic Data](https://arxiv.org//abs/2505.13466)

	Vu Dinh Xuan, Hao Vo, David Murphy, Hoang D. Nguyen

# 2025-05-06
+ [Holmes: Automated Fact Check with Large Language Models](https://arxiv.org//abs/2505.03135)

	Haoran Ou, Gelei Deng, Xingshuo Han, Jie Zhang, Xinlei He, Han Qiu, Shangwei Guo, Tianwei Zhang

+ [Patterns and Mechanisms of Contrastive Activation Engineering](https://arxiv.org//abs/2505.03189)

	Yixiong Hao, Ayush Panda, Stepan Shabalin, Sheikh Abdur Raheem Ali

+ [RAG-MCP: Mitigating Prompt Bloat in LLM Tool Selection via Retrieval-Augmented Generation](https://arxiv.org//abs/2505.03275)

	Tiantian Gan, Qiyao Sun

+ [Capability-Driven Skill Generation with LLMs: A RAG-Based Approach for Reusing Existing Libraries and Interfaces](https://arxiv.org//abs/2505.03295)

	Luis Miguel Vieira da Silva, Aljosha Köcher, Nicolas König, Felix Gehlhoff, Alexander Fay

+ [AI-Driven Scholarly Peer Review via Persistent Workflow Prompting, Meta-Prompting, and Meta-Reasoning](https://arxiv.org//abs/2505.03332)

	Evgeny Markhasin

+ [Procedural Memory Is Not All You Need: Bridging Cognitive Gaps in LLM-Based Agents](https://arxiv.org//abs/2505.03434)

	Schaun Wheeler, Olivier Jeunen

+ [The Steganographic Potentials of Language Models](https://arxiv.org//abs/2505.03439)

	Artem Karpov, Tinuade Adeleke, Seong Hah Cho, Natalia Perez-Campanero

+ [am-ELO: A Stable Framework for Arena-based LLM Evaluation](https://arxiv.org//abs/2505.03475)

	Zirui Liu, Jiatong Li, Yan Zhuang, Qi Liu, Shuanghong Shen, Jie Ouyang, Mingyue Cheng, Shijin Wang

+ [A Hashgraph-Inspired Consensus Mechanism for Reliable Multi-Model Reasoning](https://arxiv.org//abs/2505.03553)

	Kolawole E. Ogunsina, Morayo A. Ogunsina

+ [Assessing and Enhancing the Robustness of LLM-based Multi-Agent Systems Through Chaos Engineering](https://arxiv.org//abs/2505.03096)

	Joshua Owotogbe

+ [Soft Best-of-n Sampling for Model Alignment](https://arxiv.org//abs/2505.03156)

	Claudio Mayrink Verdun, Alex Oesterling, Himabindu Lakkaraju, Flavio P. Calmon

+ [A Trustworthy Multi-LLM Network: Challenges,Solutions, and A Use Case](https://arxiv.org//abs/2505.03196)

	Haoxiang Luo, Gang Sun, Yinqiu Liu, Dusit Niyato, Hongfang Yu, Mohammed Atiquzzaman, Schahram Dustdar

+ [Absolute Zero: Reinforced Self-play Reasoning with Zero Data](https://arxiv.org//abs/2505.03335)

	Andrew Zhao, Yiran Wu, Yang Yue, Tong Wu, Quentin Xu, Yang Yue, Matthieu Lin, Shenzhi Wang, Qingyun Wu, Zilong Zheng, Gao Huang

+ [SPAP: Structured Pruning via Alternating Optimization and Penalty Methods](https://arxiv.org//abs/2505.03373)

	Hanyu Hu, Xiaoming Yuan

+ [Automatic Calibration for Membership Inference Attack on Large Language Models](https://arxiv.org//abs/2505.03392)

	Saleh Zare Zade, Yao Qiang, Xiangyu Zhou, Hui Zhu, Mohammad Amin Roshani, Prashant Khanduri, Dongxiao Zhu

+ [Lightweight Clinical Decision Support System using QLoRA-Fine-Tuned LLMs and Retrieval-Augmented Generation](https://arxiv.org//abs/2505.03406)

	Mohammad Shoaib Ansari, Mohd Sohail Ali Khan, Shubham Revankar, Aditya Varma, Anil S. Mokhade

+ [An Analysis of Hyper-Parameter Optimization Methods for Retrieval Augmented Generation](https://arxiv.org//abs/2505.03452)

	Matan Orbach, Ohad Eytan, Benjamin Sznajder, Ariel Gera, Odellia Boni, Yoav Kantor, Gal Bloch, Omri Levy, Hadas Abraham, Nitzan Barzilay, Eyal Shnarch, Michael E. Factor, Shila Ofek-Koifman, Paula Ta-Shma, Assaf Toledo

+ [A new membership inference attack that spots memorization in generative and predictive models: Loss-Based with Reference Model algorithm (LBRM)](https://arxiv.org//abs/2505.03490)

	Faiz Taleb, Ivan Gazeau, Maryline Laurent

+ [LlamaFirewall: An open source guardrail system for building secure AI agents](https://arxiv.org//abs/2505.03574)

	Sahana Chennabasappa, Cyrus Nikolaidis, Daniel Song, David Molnar, Stephanie Ding, Shengye Wan, Spencer Whitman, Lauren Deason, Nicholas Doucette, Abraham Montilla, Alekhya Gampa, Beto de Paola, Dominik Gabi, James Crnkovich, Jean-Christophe Testud, Kat He, Rashnil Chaturvedi, Wu Zhou, Joshua Saxe

+ [ReGraP-LLaVA: Reasoning enabled Graph-based Personalized Large Language and Vision Assistant](https://arxiv.org//abs/2505.03654)

	Yifan Xiang, Zhenxi Zhang, Bin Li, Yixuan Weng, Shoujun Zhou, Yangfan He, Keqin Li

+ [Ψ-Arena: Interactive Assessment and Optimization of LLM-based Psychological Counselors with Tripartite Feedback](https://arxiv.org//abs/2505.03293)

	Shijing Zhu, Zhuang Chen, Guanqun Bi, Binghang Li, Yaxi Deng, Dazhen Wan, Libiao Peng, Xiyao Xiao, Rongsheng Zhang, Tangjie Lv, Zhipeng Hu, FangFang Li, Minlie Huang

+ [Recall with Reasoning: Chain-of-Thought Distillation for Mamba's Long-Context Memory and Extrapolation](https://arxiv.org//abs/2505.03320)

	Junyu Ma, Tianqing Fang, Zhisong Zhang, Hongming Zhang, Haitao Mi, Dong Yu

+ [Uncertainty-Aware Large Language Models for Explainable Disease Diagnosis](https://arxiv.org//abs/2505.03467)

	Shuang Zhou, Jiashuo Wang, Zidu Xu, Song Wang, David Brauer, Lindsay Welton, Jacob Cogan, Yuen-Hei Chung, Lei Tian, Zaifu Zhan, Yu Hou, Mingquan Lin, Genevieve B. Melton, Rui Zhang

+ [Long-Short Chain-of-Thought Mixture Supervised Fine-Tuning Eliciting Efficient Reasoning in Large Language Models](https://arxiv.org//abs/2505.03469)

	Bin Yu, Hang Yuan, Yuliang Wei, Bailing Wang, Weizhen Qi, Kai Chen

+ [Evaluation of LLMs on Long-tail Entity Linking in Historical Documents](https://arxiv.org//abs/2505.03473)

	Marta Boscariol, Luana Bulla, Lia Draetta, Beatrice Fiumanò, Emanuele Lenzi, Leonardo Piano

+ [Faster MoE LLM Inference for Extremely Large Models](https://arxiv.org//abs/2505.03531)

	Haoqi Yang, Luohe Shi, Qiwei Li, Zuchao Li, Ping Wang, Bo Du, Mengjia Shen, Hai Zhao

+ [Say It Another Way: A Framework for User-Grounded Paraphrasing](https://arxiv.org//abs/2505.03563)

	Cléa Chataigner, Rebecca Ma, Prakhar Ganesh, Afaf Taïk, Elliot Creager, Golnoosh Farnadi

+ [WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional Websites from Scratch](https://arxiv.org//abs/2505.03733)

	Zimu Lu, Yunqiao Yang, Houxing Ren, Haotian Hou, Han Xiao, Ke Wang, Weikang Shi, Aojun Zhou, Mingjie Zhan, Hongsheng Li

+ [BadLingual: A Novel Lingual-Backdoor Attack against Large Language Models](https://arxiv.org//abs/2505.03501)

	Zihan Wang, Hongwei Li, Rui Zhang, Wenbo Jiang, Kangjie Chen, Tianwei Zhang, Qingchuan Zhao, Guowen Xu

+ [VLM Q-Learning: Aligning Vision-Language Models for Interactive Decision-Making](https://arxiv.org//abs/2505.03181)

	Jake Grigsby, Yuke Zhu, Michael Ryoo, Juan Carlos Niebles

+ [DYSTIL: Dynamic Strategy Induction with Large Language Models for Reinforcement Learning](https://arxiv.org//abs/2505.03209)

	Borui Wang, Kathleen McKeown, Rex Ying

+ [Geospatial Mechanistic Interpretability of Large Language Models](https://arxiv.org//abs/2505.03368)

	Stef De Sabbata, Stefano Mizzaro, Kevin Roitero

+ [Knowledge Augmented Complex Problem Solving with Large Language Models: A Survey](https://arxiv.org//abs/2505.03418)

	Da Zheng, Lun Du, Junwei Su, Yuchen Tian, Yuqi Zhu, Jintian Zhang, Lanning Wei, Ningyu Zhang, Huajun Chen

+ [Uncovering the Limitations of Model Inversion Evaluation: Benchmarks and Connection to Type-I Adversarial Attacks](https://arxiv.org//abs/2505.03519)

	Sy-Tuyen Ho, Koh Jun Hao, Ngoc-Bao Nguyen, Alexander Binder, Ngai-Man Cheung

+ [Towards a standardized methodology and dataset for evaluating LLM-based digital forensic timeline analysis](https://arxiv.org//abs/2505.03100)

	Hudan Studiawan, Frank Breitinger, Mark Scanlon

+ [Towards Effective Identification of Attack Techniques in Cyber Threat Intelligence Reports using Large Language Models](https://arxiv.org//abs/2505.03147)

	Hoang Cuong Nguyen, Shahroz Tariq, Mohan Baruwal Chhetri, Bao Quoc Vo

+ [An LLM-based Self-Evolving Security Framework for 6G Space-Air-Ground Integrated Networks](https://arxiv.org//abs/2505.03161)

	Qi Qin, Xinye Cao, Guoshun Nan, Sihan Chen, Rushan Li, Li Su, Haitao Du, Qimei Cui, Pengxuan Mao, Xiaofeng Tao, Tony Q.S. Quek

+ [Bridging Expertise Gaps: The Role of LLMs in Human-AI Collaboration for Cybersecurity](https://arxiv.org//abs/2505.03179)

	Shahroz Tariq, Ronal Singh, Mohan Baruwal Chhetri, Surya Nepal, Cecile Paris

+ [A Chaos Driven Metric for Backdoor Attack Detection](https://arxiv.org//abs/2505.03208)

	Hema Karnam Surendrababu (1), Nithin Nagaraj (2) ((1) School of Conflict and Security Studies, National Institute of Advanced Studies, Indian Institute of Science Campus, Bengaluru (2) Complex Systems Programme, National Institute of Advanced Studies, Indian Institute of Science Campus, Bengaluru)

+ [Elevating Cyber Threat Intelligence against Disinformation Campaigns with LLM-based Concept Extraction and the FakeCTI Dataset](https://arxiv.org//abs/2505.03345)

	Domenico Cotroneo, Roberto Natella, Vittorio Orbinato

+ [Directed Greybox Fuzzing via Large Language Model](https://arxiv.org//abs/2505.03425)

	Hanxiang Xu, Yanjie Zhao, Haoyu Wang

+ [Frog Soup: Zero-Shot, In-Context, and Sample-Efficient Frogger Agents](https://arxiv.org//abs/2505.03947)

	Xiang Li, Yiyang Hao, Doug Fulop

+ [The Power of Stories: Narrative Priming Shapes How LLM Agents Collaborate and Compete](https://arxiv.org//abs/2505.03961)

	Gerrit Großmann, Larisa Ivanova, Sai Leela Poduru, Mohaddeseh Tabrizian, Islam Mesabah, David A. Selby, Sebastian J. Vollmer

+ [From Glue-Code to Protocols: A Critical Analysis of A2A and MCP Integration for Scalable Agent Systems](https://arxiv.org//abs/2505.03864)

	Qiaomu Li, Ying Xie

+ [MergeGuard: Efficient Thwarting of Trojan Attacks in Machine Learning Models](https://arxiv.org//abs/2505.04015)

	Soheil Zibakhsh Shabgahi, Yaman Jandali, Farinaz Koushanfar

+ [SLOT: Structuring the Output of Large Language Models](https://arxiv.org//abs/2505.04016)

	Darren Yow-Bang Wang, Zhengyuan Shen, Soumya Smruti Mishra, Zhichao Xu, Yifei Teng, Haibo Ding

+ [Prism: Unleashing GPU Sharing for Cost-Efficient Multi-LLM Serving](https://arxiv.org//abs/2505.04021)

	Shan Yu, Jiarong Xing, Yifan Qiao, Mingyuan Ma, Yangmin Li, Yang Wang, Shuo Yang, Zhiqiang Xie, Shiyi Cao, Ke Bao, Ion Stoica, Harry Xu, Ying Sheng

+ [A Reasoning-Focused Legal Retrieval Benchmark](https://arxiv.org//abs/2505.03970)

	Lucia Zheng, Neel Guha, Javokhir Arifov, Sarah Zhang, Michal Skreta, Christopher D. Manning, Peter Henderson, Daniel E. Ho

+ [Divide, Optimize, Merge: Fine-Grained LLM Agent Optimization at Scale](https://arxiv.org//abs/2505.03973)

	Jiale Liu, Yifan Zeng, Shaokun Zhang, Chi Zhang, Malte Højmark-Bertelsen, Marie Normann Gadeberg, Huazheng Wang, Qingyun Wu

+ [Quiet Feature Learning in Algorithmic Tasks](https://arxiv.org//abs/2505.03997)

	Prudhviraj Naidu, Zixian Wang, Leon Bergen, Ramamohan Paturi

+ [MARCO: A Multi-Agent System for Optimizing HPC Code Generation Using Large Language Models](https://arxiv.org//abs/2505.03906)

	Asif Rahman, Veljko Cvetkovic, Kathleen Reece, Aidan Walters, Yasir Hassan, Aneesh Tummeti, Bryan Torres, Denise Cooney, Margaret Ellis, Dimitrios S. Nikolopoulos

+ [FRAME: Feedback-Refined Agent Methodology for Enhancing Medical Research Insights](https://arxiv.org//abs/2505.04649)

	Chengzhang Yu, Yiming Zhang, Zhixin Liu, Zenghui Ding, Yining Sun, Zhanpeng Jin

+ [Scientific Hypothesis Generation and Validation: Methods, Datasets, and Future Directions](https://arxiv.org//abs/2505.04651)

	Adithya Kulkarni, Fatimah Alotaibi, Xinyue Zeng, Longfeng Wu, Tong Zeng, Barry Menglong Yao, Minqian Liu, Shuaicheng Zhang, Lifu Huang, Dawei Zhou

+ [A Comparative Analysis of Ethical and Safety Gaps in LLMs using Relative Danger Coefficient](https://arxiv.org//abs/2505.04654)

	Yehor Tereshchenko, Mika Hämäläinen

+ [A Sensitivity-Driven Expert Allocation Method in LoRA-MoE for Efficient Fine-Tuning](https://arxiv.org//abs/2505.06272)

	Junzhou Xu, Boyu Diao

+ [Policy-labeled Preference Learning: Is Preference Enough for RLHF?](https://arxiv.org//abs/2505.06273)

	Taehyun Cho, Seokhun Ju, Seungyub Han, Dohyeong Kim, Kyungjae Lee, Jungwoo Lee

+ [PARM: Multi-Objective Test-Time Alignment via Preference-Aware Autoregressive Reward Model](https://arxiv.org//abs/2505.06274)

	Baijiong Lin, Weisen Jiang, Yuancheng Xu, Hao Chen, Ying-Cong Chen

# 2025-05-05
+ [HyperTree Planning: Enhancing LLM Reasoning via Hierarchical Thinking](https://arxiv.org//abs/2505.02322)

	Runquan Gui, Zhihai Wang, Jie Wang, Chi Ma, Huiling Zhen, Mingxuan Yuan, Jianye Hao, Defu Lian, Enhong Chen, Feng Wu

+ [Recursive Decomposition with Dependencies for Generic Divide-and-Conquer Reasoning](https://arxiv.org//abs/2505.02576)

	Sergio Hernández-Gutiérrez, Minttu Alakuijala, Alexander V. Nikitin, Pekka Marttinen

+ [Agentic Neurodivergence as a Contingent Solution to the AI Alignment Problem](https://arxiv.org//abs/2505.02581)

	Alberto Hernández-Espinosa, Felipe S. Abrahão, Olaf Witkowski, Hector Zenil

+ [A Survey of Slow Thinking-based Reasoning LLMs using Reinforced Learning and Inference-time Scaling Law](https://arxiv.org//abs/2505.02665)

	Qianjun Pan, Wenkai Ji, Yuyang Ding, Junsong Li, Shilian Chen, Junyi Wang, Jie Zhou, Qin Chen, Min Zhang, Yulan Wu, Liang He

+ [Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play](https://arxiv.org//abs/2505.02707)

	Yemin Shi, Yu Shu, Siwei Dong, Guangyi Liu, Jaward Sesay, Jingwen Li, Zhiting Hu

+ [Technical Report: Evaluating Goal Drift in Language Model Agents](https://arxiv.org//abs/2505.02709)

	Rauno Arike, Elizabeth Donoway, Henning Bartsch, Marius Hobbhahn

+ [Enhancing LLMs' Clinical Reasoning with Real-World Data from a Nationwide Sepsis Registry](https://arxiv.org//abs/2505.02722)

	Junu Kim, Chaeeun Shim, Sungjin Park, Su Yeon Lee, Gee Young Suh, Chae-Man Lim, Seong Jin Choi, Song Mi Moon, Kyoung-Ho Song, Eu Suk Kim, Hong Bin Kim, Sejoong Kim, Chami Im, Dong-Wan Kang, Yong Soo Kim, Hee-Joon Bae, Sung Yoon Lim, Han-Gil Jeong, Edward Choi

+ [Knowing You Don't Know: Learning When to Continue Search in Multi-round RAG through Self-Practicing](https://arxiv.org//abs/2505.02811)

	Diji Yang, Linda Zeng, Jinmeng Rao, Yi Zhang

+ [AutoLibra: Agent Metric Induction from Open-Ended Feedback](https://arxiv.org//abs/2505.02820)

	Hao Zhu, Phil Cuvin, Xinkai Yu, Charlotte Ka Yee Yan, Jason Zhang, Diyi Yang

+ [Optimizing LLMs for Resource-Constrained Environments: A Survey of Model Compression Techniques](https://arxiv.org//abs/2505.02309)

	Sanjay Surendranath Girija, Shashank Kapoor, Lakshit Arora, Dipen Pradhan, Aman Raj, Ankit Shetgaonkar

+ [RM-R1: Reward Modeling as Reasoning](https://arxiv.org//abs/2505.02387)

	Xiusi Chen, Gaotang Li, Ziqi Wang, Bowen Jin, Cheng Qian, Yu Wang, Hongru Wang, Yu Zhang, Denghui Zhang, Tong Zhang, Hanghang Tong, Heng Ji

+ [Optimizing Chain-of-Thought Reasoners via Gradient Variance Minimization in Rejection Sampling and RL](https://arxiv.org//abs/2505.02391)

	Jiarui Yao, Yifan Hao, Hanning Zhang, Hanze Dong, Wei Xiong, Nan Jiang, Tong Zhang

+ [SEFE: Superficial and Essential Forgetting Eliminator for Multimodal Continual Instruction Tuning](https://arxiv.org//abs/2505.02486)

	Jinpeng Chen, Runmin Cong, Yuzhi Zhao, Hongzheng Yang, Guangneng Hu, Horace Ho Shing Ip, Sam Kwong

+ [Unveiling the Landscape of LLM Deployment in the Wild: An Empirical Study](https://arxiv.org//abs/2505.02502)

	Xinyi Hou, Jiahao Han, Yanjie Zhao, Haoyu Wang

+ [Large Language Model Partitioning for Low-Latency Inference at the Edge](https://arxiv.org//abs/2505.02533)

	Dimitrios Kafetzis, Ramin Khalili, Iordanis Koutsopoulos

+ [EMORL: Ensemble Multi-Objective Reinforcement Learning for Efficient and Flexible LLM Fine-Tuning](https://arxiv.org//abs/2505.02579)

	Lingxiao Kong (1), Cong Yang (2), Susanne Neufang (3), Oya Deniz Beyan (1,3), Zeyd Boukhers (1,3) ((1) Fraunhofer Institute for Applied Information Technology FIT, (2) Soochow University, (3) University Hospital of Cologne)

+ [LLaMA-Omni2: LLM-based Real-time Spoken Chatbot with Autoregressive Streaming Speech Synthesis](https://arxiv.org//abs/2505.02625)

	Qingkai Fang, Yan Zhou, Shoutao Guo, Shaolei Zhang, Yang Feng

+ [Knowledge Graphs for Enhancing Large Language Models in Entity Disambiguation](https://arxiv.org//abs/2505.02737)

	Pons Gerard, Bilalli Besim, Queralt Anna

+ [HSplitLoRA: A Heterogeneous Split Parameter-Efficient Fine-Tuning Framework for Large Language Models](https://arxiv.org//abs/2505.02795)

	Zheng Lin, Yuxin Zhang, Zhe Chen, Zihan Fang, Xianhao Chen, Praneeth Vepakomma, Wei Ni, Jun Luo, Yue Gao

+ [Generative Sign-description Prompts with Multi-positive Contrastive Learning for Sign Language Recognition](https://arxiv.org//abs/2505.02304)

	Siyu Liang, Yunan Li, Wentian Xin, Huizhou Chen, Xujie Liu, Kang Liu, Qiguang Miao

+ [Invoke Interfaces Only When Needed: Adaptive Invocation for Large Language Models in Question Answering](https://arxiv.org//abs/2505.02311)

	Jihao Zhao, Chunlai Zhou, Biao Qin

+ [SIMPLEMIX: Frustratingly Simple Mixing of Off- and On-policy Data in Language Model Preference Learning](https://arxiv.org//abs/2505.02363)

	Tianjian Li, Daniel Khashabi

+ [Colombian Waitresses y Jueces canadienses: Gender and Country Biases in Occupation Recommendations from LLMs](https://arxiv.org//abs/2505.02456)

	Elisa Forcada Rodríguez, Olatz Perez-de-Viñaspre, Jon Ander Campos, Dietrich Klakow, Vagrant Gautam

+ [A Survey on Progress in LLM Alignment from the Perspective of Reward Design](https://arxiv.org//abs/2505.02666)

	Miaomiao Ji, Yanqiu Wu, Zhibin Wu, Shoujin Wang, Jian Yang, Mark Dras, Usman Naseem

+ [Sailing AI by the Stars: A Survey of Learning from Rewards in Post-Training and Test-Time Scaling of Large Language Models](https://arxiv.org//abs/2505.02686)

	Xiaobao Wu

+ [ReplaceMe: Network Simplification via Layer Pruning and Linear Transformations](https://arxiv.org//abs/2505.02819)

	Dmitriy Shopkhoev, Ammar Ali, Magauiya Zhussip, Valentin Malykh, Stamatios Lefkimmiatis, Nikos Komodakis, Sergey Zagoruyko

+ [R1-Reward: Training Multimodal Reward Model Through Stable Reinforcement Learning](https://arxiv.org//abs/2505.02835)

	Yi-Fan Zhang, Xingyu Lu, Xiao Hu, Chaoyou Fu, Bin Wen, Tianke Zhang, Changyi Liu, Kaiyu Jiang, Kaibing Chen, Kaiyu Tang, Haojie Ding, Jiankang Chen, Fan Yang, Zhang Zhang, Tingting Gao, Liang Wang

+ [Scenethesis: A Language and Vision Agentic Framework for 3D Scene Generation](https://arxiv.org//abs/2505.02836)

	Lu Ling, Chen-Hsuan Lin, Tsung-Yi Lin, Yifan Ding, Yu Zeng, Yichen Sheng, Yunhao Ge, Ming-Yu Liu, Aniket Bera, Zhaoshuo Li

+ [EntroLLM: Entropy Encoded Weight Compression for Efficient Large Language Model Inference on Edge Devices](https://arxiv.org//abs/2505.02380)

	Arnab Sanyal, Prithwish Mukherjee, Gourav Datta, Sandeep P. Chinchali

+ [An End-to-End Model For Logits Based Large Language Models Watermarking](https://arxiv.org//abs/2505.02344)

	Kahim Wong, Jicheng Zhou, Jiantao Zhou, Yain-Whar Si

+ [Iterative Resolution of Prompt Ambiguities Using a Progressive Cutting-Search Approach](https://arxiv.org//abs/2505.02952)

	Fabrizio Marozzo

+ [Rewriting Pre-Training Data Boosts LLM Performance in Math and Code](https://arxiv.org//abs/2505.02881)

	Kazuki Fujii, Yukito Tajima, Sakae Mizuki, Hinari Shimada, Taihei Shiotani, Koshiro Saito, Masanari Ohi, Masaki Kawamura, Taishi Nakamura, Takumi Okamoto, Shigeki Ishida, Kakeru Hattori, Youmi Ma, Hiroya Takamura, Rio Yokota, Naoaki Okazaki

+ [Unlearning vs. Obfuscation: Are We Truly Removing Knowledge?](https://arxiv.org//abs/2505.02884)

	Guangzhi Sun, Potsawee Manakul, Xiao Zhan, Mark Gales

+ [When Your Own Output Becomes Your Training Data: Noise-to-Meaning Loops and a Formal RSI Trigger](https://arxiv.org//abs/2505.02888)

	Rintaro Ando

+ [Memorization or Interpolation ? Detecting LLM Memorization through Input Perturbation Analysis](https://arxiv.org//abs/2505.03019)

	Albérick Euraste Djiré, Abdoul Kader Kaboré, Earl T. Barr, Jacques Klein, Tegawendé F. Bissyandé

+ [Developing A Framework to Support Human Evaluation of Bias in Generated Free Response Text](https://arxiv.org//abs/2505.03053)

	Jennifer Healey, Laurie Byrum, Md Nadeem Akhtar, Surabhi Bhargava, Moumita Sinha

+ [UCSC at SemEval-2025 Task 3: Context, Models and Prompt Optimization for Automated Hallucination Detection in LLM Output](https://arxiv.org//abs/2505.03030)

	Sicong Huang, Jincheng He, Shiyuan Huang, Karthik Raja Anandan, Arkajyoti Chakraborty, Ian Lane

+ [Teaching Models to Understand (but not Generate) High-risk Data](https://arxiv.org//abs/2505.03052)

	Ryan Wang, Matthew Finlayson, Luca Soldaini, Swabha Swayamdipta, Robin Jia

+ [Improving Model Alignment Through Collective Intelligence of Open-Source LLMS](https://arxiv.org//abs/2505.03059)

	Junlin Wang, Roy Xie, Shang Zhu, Jue Wang, Ben Athiwaratkun, Bhuwan Dhingra, Shuaiwen Leon Song, Ce Zhang, James Zou

+ [Radio: Rate-Distortion Optimization for Large Language Model Compression](https://arxiv.org//abs/2505.03031)

	Sean I. Young

+ [RetroInfer: A Vector-Storage Approach for Scalable Long-Context LLM Inference](https://arxiv.org//abs/2505.02922)

	Yaoqi Chen, Jinkai Zhang, Baotong Lu, Qianxi Zhang, Chengruidong Zhang, Jingjia Luo, Di Liu, Huiqiang Jiang, Qi Chen, Jing Liu, Bailu Ding, Xiao Yan, Jiawei Jiang, Chen Chen, Mingxing Zhang, Yuqing Yang, Fan Yang, Mao Yang

+ [34 Examples of LLM Applications in Materials Science and Chemistry: Towards Automation, Assistants, Agents, and Accelerated Scientific Discovery](https://arxiv.org//abs/2505.03049)

	Yoel Zimmermann, Adib Bazgir, Alexander Al-Feghali, Mehrad Ansari, L. Catherine Brinson, Yuan Chiang, Defne Circi, Min-Hsueh Chiu, Nathan Daelman, Matthew L. Evans, Abhijeet S. Gangan, Janine George, Hassan Harb, Ghazal Khalighinejad, Sartaaj Takrim Khan, Sascha Klawohn, Magdalena Lederbauer, Soroush Mahjoubi, Bernadette Mohr, Seyed Mohamad Moosavi, Aakash Naik, Aleyna Beste Ozhan, Dieter Plessers, Aritra Roy, Fabian Schöppach, Philippe Schwaller, Carla Terboven, Katharina Ueltzen, Shang Zhu, Jan Janssen, Calvin Li, Ian Foster, Ben Blaiszik

+ [RADLADS: Rapid Attention Distillation to Linear Attention Decoders at Scale](https://arxiv.org//abs/2505.03005)

	Daniel Goldstein, Eric Alcaide, Janna Lu, Eugene Cheah

+ [AKD : Adversarial Knowledge Distillation For Large Language Models Alignment on Coding tasks](https://arxiv.org//abs/2505.06267)

	Ilyas Oulkadda, Julien Perez

+ [SafeMate: A Modular RAG-Based Agent for Context-Aware Emergency Guidance](https://arxiv.org//abs/2505.02306)

	Junfeng Jiao, Jihyung Park, Yiming Xu, Kristen Sussman, Lucy Atkinson

# 2025-05-04
+ [Leveraging LLM Agents and Digital Twins for Fault Handling in Process Plants](https://arxiv.org//abs/2505.02076)

	Milapji Singh Gill, Javal Vyas, Artan Markaj, Felix Gehlhoff, Mehmet Mercangöz

+ [Retrieval-augmented in-context learning for multimodal large language models in disease classification](https://arxiv.org//abs/2505.02087)

	Zaifu Zhan, Shuang Zhou, Xiaoshan Zhou, Yongkang Xiao, Jun Wang, Jiawen Deng, He Zhu, Yu Hou, Rui Zhang

+ [MemEngine: A Unified and Modular Library for Developing Advanced Memory of LLM-based Agents](https://arxiv.org//abs/2505.02099)

	Zeyu Zhang, Quanyu Dai, Xu Chen, Rui Li, Zhongyang Li, Zhenhua Dong

+ [Attention Mechanisms Perspective: Exploring LLM Processing of Graph-Structured Data](https://arxiv.org//abs/2505.02130)

	Zhong Guan, Likang Wu, Hongke Zhao, Ming He, Jianpin Fan

+ [Interpretable Emergent Language Using Inter-Agent Transformers](https://arxiv.org//abs/2505.02215)

	Mannan Bhardwaj

+ [LLM-Guided Probabilistic Program Induction for POMDP Model Estimation](https://arxiv.org//abs/2505.02216)

	Aidan Curtis, Hao Tang, Thiago Veloso, Kevin Ellis, Tomás Lozano-Pérez, Leslie Pack Kaelbling

+ [Real-time Spatial Retrieval Augmented Generation for Urban Environments](https://arxiv.org//abs/2505.02271)

	David Nazareno Campo, Javier Conde, Álvaro Alonso, Gabriel Huecas, Joaquín Salvachúa, Pedro Reviriego

+ [A survey of agent interoperability protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP)](https://arxiv.org//abs/2505.02279)

	Abul Ehtesham, Aditi Singh, Gaurav Kumar Gupta, Saket Kumar

+ [Analyzing Cognitive Differences Among Large Language Models through the Lens of Social Worldview](https://arxiv.org//abs/2505.01967)

	Jiatao Li, Yanheng Li, Xiaojun Wan

+ [Restoring Calibration for Aligned Large Language Models: A Calibration-Aware Fine-Tuning Approach](https://arxiv.org//abs/2505.01997)

	Jiancong Xiao, Bojian Hou, Zhanliang Wang, Ruochen Jin, Qi Long, Weijie J. Su, Li Shen

+ [What do Language Model Probabilities Represent? From Distribution Estimation to Response Prediction](https://arxiv.org//abs/2505.02072)

	Eitan Wagner, Omri Abend

+ [Open Challenges in Multi-Agent Security: Towards Secure Systems of Interacting AI Agents](https://arxiv.org//abs/2505.02077)

	Christian Schroeder de Witt

+ [A New HOPE: Domain-agnostic Automatic Evaluation of Text Chunking](https://arxiv.org//abs/2505.02171)

	Henrik Brådland, Morten Goodwin, Per-Arne Andersen, Alexander S. Nossum, Aditya Gupta

+ [Towards Safer Pretraining: Analyzing and Filtering Harmful Content in Webscale datasets for Responsible LLMs](https://arxiv.org//abs/2505.02009)

	Sai Krishna Mendu, Harish Yenala, Aditi Gulati, Shanu Kumar, Parag Agrawal

+ [Exploring the Potential of Offline RL for Reasoning in LLMs: A Preliminary Study](https://arxiv.org//abs/2505.02142)

	Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li

+ [Incorporating Legal Structure in Retrieval-Augmented Generation: A Case Study on Copyright Fair Use](https://arxiv.org//abs/2505.02164)

	Justin Ho, Alexandra Colby, William Fisher

+ [Identifying Legal Holdings with LLMs: A Systematic Study of Performance, Scale, and Memorization](https://arxiv.org//abs/2505.02172)

	Chuck Arvin

+ [Personalisation or Prejudice? Addressing Geographic Bias in Hate Speech Detection using Debias Tuning in Large Language Models](https://arxiv.org//abs/2505.02252)

	Paloma Piot, Patricia Martín-Rodilla, Javier Parapar

+ [Demystifying optimized prompts in language models](https://arxiv.org//abs/2505.02273)

	Rimon Melamed, Lucas H. McCabe, H. Howie Huang

+ [A Comprehensive Analysis for Visual Object Hallucination in Large Vision-Language Models](https://arxiv.org//abs/2505.01958)

	Liqiang Jing, Guiming Hardy Chen, Ehsan Aghazadeh, Xin Eric Wang, Xinya Du

+ [R-Bench: Graduate-level Multi-disciplinary Benchmarks for LLM & MLLM Complex Reasoning Evaluation](https://arxiv.org//abs/2505.02018)

	Meng-Hao Guo, Jiajun Xu, Yi Zhang, Jiaxi Song, Haoyang Peng, Yi-Xuan Deng, Xinzhi Dong, Kiyohiro Nakayama, Zhengyang Geng, Chen Wang, Bolin Ni, Guo-Wei Yang, Yongming Rao, Houwen Peng, Han Hu, Gordon Wetzstein, Shi-min Hu

+ [RTV-Bench: Benchmarking MLLM Continuous Perception, Understanding and Reasoning through Real-Time Video](https://arxiv.org//abs/2505.02064)

	Shuhang Xun, Sicheng Tao, Jungang Li, Yibo Shi, Zhixin Lin, Zhanhui Zhu, Yibo Yan, Hanqian Li, Linghao Zhang, Shikang Wang, Yixin Liu, Hanbo Zhang, Xuming Hu, Ying Ma

+ [Semantic Probabilistic Control of Language Models](https://arxiv.org//abs/2505.01954)

	Kareem Ahmed, Catarina G Belem, Padhraic Smyth, Sameer Singh

+ [An Empirical Study of Qwen3 Quantization](https://arxiv.org//abs/2505.02214)

	Xingyu Zheng, Yuye Li, Haoran Chu, Yue Feng, Xudong Ma, Jie Luo, Jinyang Guo, Haotong Qin, Michele Magno, Xianglong Liu

+ [A Survey on Privacy Risks and Protection in Large Language Models](https://arxiv.org//abs/2505.01976)

	Kang Chen, Xiuze Zhou, Yuanguo Lin, Shibo Feng, Li Shen, Pengcheng Wu

+ [Dialz: A Python Toolkit for Steering Vectors](https://arxiv.org//abs/2505.06262)

	Zara Siddique, Liam D. Turner, Luis Espinosa-Anke

+ [Adaptive Thinking via Mode Policy Optimization for Social Language Agents](https://arxiv.org//abs/2505.02156)

	Minzheng Wang, Yongbin Li, Haobo Wang, Xinghua Zhang, Nan Xu, Bingli Wu, Fei Huang, Haiyang Yu, Wenji Mao

# 2025-05-03
+ [Structured Prompting and Feedback-Guided Reasoning with LLMs for Data Interpretation](https://arxiv.org//abs/2505.01636)

	Amit Rath

+ [Inducing Robustness in a 2 Dimensional Direct Preference Optimization Paradigm](https://arxiv.org//abs/2505.01706)

	Sarvesh Shashidhar, Ritik, Nachiketa Patil, Suraj Racha, Ganesh Ramakrishnan

+ [Efficient Shapley Value-based Non-Uniform Pruning of Large Language Models](https://arxiv.org//abs/2505.01731)

	Chuan Sun, Han Yu, Lizhen Cui

+ [$\textit{New News}$: System-2 Fine-tuning for Robust Integration of New Knowledge](https://arxiv.org//abs/2505.01812)

	Core Francisco Park, Zechen Zhang, Hidenori Tanaka

+ [A Survey on Inference Engines for Large Language Models: Perspectives on Optimization and Efficiency](https://arxiv.org//abs/2505.01658)

	Sihyeong Park, Sungryeol Jeon, Chaelyn Lee, Seokhun Jeon, Byung-Soo Kim, Jemin Lee

+ [Same evaluation, more tokens: On the effect of input length for machine translation evaluation using Large Language Models](https://arxiv.org//abs/2505.01761)

	Tobias Domhan, Dawei Zhu

+ [CAMOUFLAGE: Exploiting Misinformation Detection Systems Through LLM-driven Adversarial Claim Transformation](https://arxiv.org//abs/2505.01900)

	Mazal Bethany, Nishant Vishwamitra, Cho-Yu Jason Chiang, Peyman Najafirad

+ [Memory-Efficient LLM Training by Various-Grained Low-Rank Projection of Gradients](https://arxiv.org//abs/2505.01744)

	Yezhen Wang, Zhouhao Yang, Brian K Chen, Fanyi Pu, Bo Li, Tianyu Gao, Kenji Kawaguchi

+ [Cannot See the Forest for the Trees: Invoking Heuristics and Biases to Elicit Irrational Choices of LLMs](https://arxiv.org//abs/2505.02862)

	Haoming Yang, Ke Ma, Xiaojun Jia, Yingfei Sun, Qianqian Xu, Qingming Huang

+ [Accelerating Large Language Model Reasoning via Speculative Search](https://arxiv.org//abs/2505.02865)

	Zhihai Wang, Jie Wang, Jilai Pan, Xilin Xia, Huiling Zhen, Mingxuan Yuan, Jianye Hao, Feng Wu

+ [Memory Assisted LLM for Personalized Recommendation System](https://arxiv.org//abs/2505.03824)

	Jiarui Chen

+ [Towards Artificial Intelligence Research Assistant for Expert-Involved Learning](https://arxiv.org//abs/2505.04638)

	Tianyu Liu, Simeng Han, Xiao Luo, Hanchen Wang, Pan Lu, Biqing Zhu, Yuge Wang, Keyi Li, Jiapeng Chen, Rihao Qu, Yufeng Liu, Xinyue Cui, Aviv Yaish, Yuhang Chen, Minsheng Hao, Chuhan Li, Kexing Li, Arman Cohan, Hua Xu, Mark Gerstein, James Zou, Hongyu Zhao

+ [Adaptive Token Boundaries: Integrating Human Chunking Mechanisms into Multimodal LLMs](https://arxiv.org//abs/2505.04637)

	Dongxing Yu

# 2025-05-02
+ [Seeking to Collide: Online Safety-Critical Scenario Generation for Autonomous Driving with Retrieval Augmented Large Language Models](https://arxiv.org//abs/2505.00972)

	Yuewen Mei, Tong Nie, Jian Sun, Ye Tian

+ [Improving Large Language Model Planning with Action Sequence Similarity](https://arxiv.org//abs/2505.01009)

	Xinran Zhao, Hanie Sedghi, Bernd Bohnet, Dale Schuurmans, Azade Nova

+ [Retrieval Augmented Learning: A Retrial-based Large Language Model Self-Supervised Learning and Autonomous Knowledge Generation](https://arxiv.org//abs/2505.01073)

	Zongyuan Li, Pengfei Li, Runnan Qi, Yanan Ni, Lumin Jiang, Hui Wu, Xuebo Zhang, Kuihua Huang, Xian Guo

+ [BalancEdit: Dynamically Balancing the Generality-Locality Trade-off in Multi-modal Model Editing](https://arxiv.org//abs/2505.01343)

	Dongliang Guo, Mengxuan Hu, Zihan Guan, Thomas Hartvigsen, Sheng Li

+ [Large Language Model-Driven Dynamic Assessment of Grammatical Accuracy in English Language Learner Writing](https://arxiv.org//abs/2505.00931)

	Timur Jaganov, John Blake, Julián Villegas, Nicholas Carr

+ [Llama-Nemotron: Efficient Reasoning Models](https://arxiv.org//abs/2505.00949)

	Akhiad Bercovich, Itay Levy, Izik Golan, Mohammad Dabbah, Ran El-Yaniv, Omri Puny, Ido Galil, Zach Moshe, Tomer Ronen, Najeeb Nabwani, Ido Shahaf, Oren Tropp, Ehud Karpas, Ran Zilberstein, Jiaqi Zeng, Soumye Singhal, Alexander Bukharin, Yian Zhang, Tugrul Konuk, Gerald Shen, Ameya Sunil Mahabaleshwarkar, Bilal Kartal, Yoshi Suhara, Olivier Delalleau, Zijia Chen, Zhilin Wang, David Mosallanezhad, Adi Renduchintala, Haifeng Qian, Dima Rekesh, Fei Jia, Somshubra Majumdar, Vahid Noroozi, Wasi Uddin Ahmad, Sean Narenthiran, Aleksander Ficek, Mehrzad Samadi, Jocelyn Huang, Siddhartha Jain, Igor Gitman, Ivan Moshkov, Wei Du, Shubham Toshniwal, George Armstrong, Branislav Kisacanin, Matvei Novikov, Daria Gitman, Evelina Bakhturina, Jane Polak Scowcroft, John Kamalu, Dan Su, Kezhi Kong, Markus Kliegl, Rabeeh Karimi, Ying Lin, Sanjeev Satheesh, Jupinder Parmar, Pritam Gundecha, Brandon Norick, Joseph Jennings, Shrimai Prabhumoye, Syeda Nahida Akter, Mostofa Patwary, Abhinav Khattar, Deepak Narayanan, Roger Waleffe, Jimmy Zhang, Bor-Yiing Su, Guyue Huang, Terry Kong, Parth Chadha, Sahil Jain, Christine Harvey, Elad Segal, Jining Huang, Sergey Kashirsky, Robert McQueen, Izzy Putterman, George Lam, Arun Venkatesan, Sherry Wu, Vinh Nguyen, Manoj Kilaru, Andrew Wang, Anna Warno, Abhilash Somasamudramath, Sandip Bhaskar, Maka Dong, Nave Assaf, Shahar Mor, Omer Ullman Argov, Scot Junkin, Oleksandr Romanenko, Pedro Larroy, Monika Katariya, Marco Rovinelli, Viji Balas, Nicholas Edelman, Anahita Bhiwandiwalla, Muthu Subramaniam

+ [Attack and defense techniques in large language models: A survey and new perspectives](https://arxiv.org//abs/2505.00976)

	Zhiyu Liao, Kang Chen, Yuanguo Lin, Kangkang Li, Yunxuan Liu, Hefeng Chen, Xingwang Huang, Yuanhui Yu

+ [Synthesize-on-Graph: Knowledgeable Synthetic Data Generation for Continue Pre-training of Large Language Models](https://arxiv.org//abs/2505.00979)

	Xuhui Jiang, Shengjie Ma, Chengjin Xu, Cehao Yang, Liyu Zhang, Jian Guo

+ [Value Portrait: Understanding Values of LLMs with Human-aligned Benchmark](https://arxiv.org//abs/2505.01015)

	Jongwook Han, Dongmin Choi, Woojung Song, Eun-Ju Lee, Yohan Jo

+ [Good News for Script Kiddies? Evaluating Large Language Models for Automated Exploit Generation](https://arxiv.org//abs/2505.01065)

	David Jin, Qian Fu, Yuekang Li

+ [A Rusty Link in the AI Supply Chain: Detecting Evil Configurations in Model Repositories](https://arxiv.org//abs/2505.01067)

	Ziqi Ding, Qian Fu, Junchen Ding, Gelei Deng, Yi Liu, Yuekang Li

+ [On the Limitations of Steering in Language Model Alignment](https://arxiv.org//abs/2505.01162)

	Chebrolu Niranjan, Kokil Jaidka, Gerard Christopher Yeo

+ [LLM Security: Vulnerabilities, Attacks, Defenses, and Countermeasures](https://arxiv.org//abs/2505.01177)

	Francisco Aguilera-Martínez, Fernando Berzal

+ [EvalxNLP: A Framework for Benchmarking Post-Hoc Explainability Methods on NLP Models](https://arxiv.org//abs/2505.01238)

	Mahdi Dhaini, Kafaite Zahra Hussain, Efstratios Zaradoukas, Gjergji Kasneci

+ [Document Retrieval Augmented Fine-Tuning (DRAFT) for safety-critical software assessments](https://arxiv.org//abs/2505.01307)

	Regan Bolton, Mohammadreza Sheikhfathollahi, Simon Parkinson, Vanessa Vulovic, Gary Bamford, Dan Basher, Howard Parkinson

+ [Helping Big Language Models Protect Themselves: An Enhanced Filtering and Summarization System](https://arxiv.org//abs/2505.01315)

	Sheikh Samit Muhaimin, Spyridon Mastorakis

+ [Evaluating Explanations: An Explanatory Virtues Framework for Mechanistic Interpretability -- The Strange Science Part I.ii](https://arxiv.org//abs/2505.01372)

	Kola Ayonrinde, Louis Jaburi

+ [Position: Enough of Scaling LLMs! Lets Focus on Downscaling](https://arxiv.org//abs/2505.00985)

	Ayan Sengupta, Yash Goel, Tanmoy Chakraborty

+ [VTS-LLM: Domain-Adaptive LLM Agent for Enhancing Awareness in Vessel Traffic Services through Natural Language](https://arxiv.org//abs/2505.00989)

	Sijin Sun, Liangbin Zhao, Ming Deng, Xiuju Fu

+ [Do We Need a Detailed Rubric for Automated Essay Scoring using Large Language Models?](https://arxiv.org//abs/2505.01035)

	Lui Yoshida

+ [MateICL: Mitigating Attention Dispersion in Large-Scale In-Context Learning](https://arxiv.org//abs/2505.01110)

	Murtadha Ahmed, Wenbo, Liu yunfeng

+ [Transferable Adversarial Attacks on Black-Box Vision-Language Models](https://arxiv.org//abs/2505.01050)

	Kai Hu, Weichen Yu, Li Zhang, Alexander Robey, Andy Zou, Chengming Xu, Haoqi Hu, Matt Fredrikson

+ [Federated Adapter on Foundation Models: An Out-Of-Distribution Approach](https://arxiv.org//abs/2505.01075)

	Yiyuan Yang, Guodong Long, Tianyi Zhou, Qinghua Lu, Shanshan Ye, Jing Jiang

+ [Evaluating Frontier Models for Stealth and Situational Awareness](https://arxiv.org//abs/2505.01420)

	Mary Phuong, Roland S. Zimmermann, Ziyue Wang, David Lindner, Victoria Krakovna, Sarah Cogan, Allan Dafoe, Lewis Ho, Rohin Shah

+ [Preserving Privacy and Utility in LLM-Based Product Recommendations](https://arxiv.org//abs/2505.00951)

	Tina Khezresmaeilzadeh, Jiang Zhang, Dimitrios Andreadis, Konstantinos Psounis

+ [Understanding LLM Scientific Reasoning through Promptings and Model's Explanation on the Answers](https://arxiv.org//abs/2505.01482)

	Alice Rueda, Mohammed S. Hassan, Argyrios Perivolaris, Bazen G. Teferra, Reza Samavi, Sirisha Rambhatla, Yuqi Wu, Yanbo Zhang, Bo Cao, Divya Sharma, Sridhar Krishnan Venkat Bhat

+ [CHORUS: Zero-shot Hierarchical Retrieval and Orchestration for Generating Linear Programming Code](https://arxiv.org//abs/2505.01485)

	Tasnim Ahmed, Salimur Choudhury

+ [Parameterized Argumentation-based Reasoning Tasks for Benchmarking Generative Language Models](https://arxiv.org//abs/2505.01539)

	Cor Steging, Silja Renooij, Bart Verheij

+ [TutorGym: A Testbed for Evaluating AI Agents as Tutors and Students](https://arxiv.org//abs/2505.01563)

	Daniel Weitekamp, Momin N. Siddiqui, Christopher J. MacLellan

+ [PipeSpec: Breaking Stage Dependencies in Hierarchical LLM Decoding](https://arxiv.org//abs/2505.01572)

	Bradley McDanel, Sai Qian Zhang, Yunhai Hu, Zining Liu

+ [Subset Selection for Fine-Tuning: A Utility-Diversity Balanced Approach for Mathematical Domain Adaptation](https://arxiv.org//abs/2505.01523)

	Madhav Kotecha, Vijendra Kumar Vaishya, Smita Gautam, Suraj Racha

+ [Contextures: Representations from Contexts](https://arxiv.org//abs/2505.01557)

	Runtian Zhai, Kai Yang, Che-Ping Tsai, Burak Varici, Zico Kolter, Pradeep Ravikumar

+ [PIPA: A Unified Evaluation Protocol for Diagnosing Interactive Planning Agents](https://arxiv.org//abs/2505.01592)

	Takyoung Kim, Janvijay Singh, Shuhaib Mehri, Emre Can Acikgoz, Sagnik Mukherjee, Nimet Beyza Bozdag, Sumuk Shashidhar, Gokhan Tur, Dilek Hakkani-Tür

+ [Always Tell Me The Odds: Fine-grained Conditional Probability Estimation](https://arxiv.org//abs/2505.01595)

	Liaoyaqi Wang, Zhengping Jiang, Anqi Liu, Benjamin Van Durme

+ [Don't be lazy: CompleteP enables compute-efficient deep transformers](https://arxiv.org//abs/2505.01618)

	Nolan Dey, Bin Claire Zhang, Lorenzo Noci, Mufan Li, Blake Bordelon, Shane Bergsma, Cengiz Pehlevan, Boris Hanin, Joel Hestness

+ [SymPlanner: Deliberate Planning in Language Models with Symbolic Representation](https://arxiv.org//abs/2505.01479)

	Siheng Xiong, Jieyu Zhou, Zhangding Liu, Yusen Su

+ [LLM Watermarking Using Mixtures and Statistical-to-Computational Gaps](https://arxiv.org//abs/2505.01484)

	Pedro Abdalla, Roman Vershynin

+ [Rubber Mallet: A Study of High Frequency Localized Bit Flips and Their Impact on Security](https://arxiv.org//abs/2505.01518)

	Andrew Adiletta, Zane Weissman, Fatemeh Khojasteh Dana, Berk Sunar, Shahin Tajik

+ [Aligning Large Language Models with Healthcare Stakeholders: A Pathway to Trustworthy AI Integration](https://arxiv.org//abs/2505.02848)

	Kexin Ding, Mu Zhou, Akshay Chaudhari, Shaoting Zhang, Dimitris N. Metaxas

+ [Enhancing tutoring systems by leveraging tailored promptings and domain knowledge with Large Language Models](https://arxiv.org//abs/2505.02849)

	Mohsen Balavar, Wenli Yang, David Herbert, Soonja Yeom

+ [Enhancing ML Model Interpretability: Leveraging Fine-Tuned Large Language Models for Better Understanding of AI](https://arxiv.org//abs/2505.02859)

	Jonas Bokstaller, Julia Altheimer, Julian Dormehl, Alina Buss, Jasper Wiltfang, Johannes Schneider, Maximilian Röglinger

+ [Scalability Matters: Overcoming Challenges in InstructGLM with Similarity-Degree-Based Sampling](https://arxiv.org//abs/2505.03799)

	Hyun Lee, Chris Yi, Maminur Islam, B.D.S. Aritra

+ [Large Language Model Compression with Global Rank and Sparsity Optimization](https://arxiv.org//abs/2505.03801)

	Changhai Zhou, Qian Qiao, Weizhong Zhang, Cheng Jin

+ [Efficient Fine-Tuning of Quantized Models via Adaptive Rank and Bitwidth](https://arxiv.org//abs/2505.03802)

	Changhai Zhou, Yuhua Zhou, Qian Qiao, Weizhong Zhang, Cheng Jin

+ [MoEQuant: Enhancing Quantization for Mixture-of-Experts Large Language Models via Expert-Balanced Sampling and Affinity Guidance](https://arxiv.org//abs/2505.03804)

	Xing Hu, Zhixuan Chen, Dawei Yang, Zukang Xu, Chen Xu, Zhihang Yuan, Sifan Zhou, Jiangyong Yu

+ [Facilitating Video Story Interaction with Multi-Agent Collaborative System](https://arxiv.org//abs/2505.03807)

	Yiwen Zhang, Jianing Hao, Zhan Wang, Hongling Sheng, Wei Zeng

+ [Grouped Sequency-arranged Rotation: Optimizing Rotation Transformation for Quantization for Free](https://arxiv.org//abs/2505.03810)

	Euntae Choi, Sumin Song, Woosang Lim, Sungjoo Yoo

+ [Cer-Eval: Certifiable and Cost-Efficient Evaluation Framework for LLMs](https://arxiv.org//abs/2505.03814)

	Ganghua Wang, Zhaorun Chen, Bo Li, Haifeng Xu

+ [Program Semantic Inequivalence Game with Large Language Models](https://arxiv.org//abs/2505.03818)

	Antonio Valerio Miceli-Barone, Vaishak Belle, Ali Payani

+ [Focus on the Likely: Test-time Instance-based Uncertainty Removal](https://arxiv.org//abs/2505.03819)

	Johannes Schneider

# 2025-05-01
+ [UserCentrix: An Agentic Memory-augmented AI Framework for Smart Spaces](https://arxiv.org//abs/2505.00472)

	Alaa Saleh, Sasu Tarkoma, Praveen Kumar Donta, Naser Hossein Motlagh, Schahram Dustdar, Susanna Pirttikangas, Lauri Lovén

+ [Combining LLMs with Logic-Based Framework to Explain MCTS](https://arxiv.org//abs/2505.00610)

	Ziyan An, Xia Wang, Hendrik Baier, Zirong Chen, Abhishek Dubey, Taylor T. Johnson, Jonathan Sprinkle, Ayan Mukhopadhyay, Meiyi Ma

+ [Open-Source LLM-Driven Federated Transformer for Predictive IoV Management](https://arxiv.org//abs/2505.00651)

	Yazan Otoum, Arghavan Asad, Ishtiaq Ahmad

+ [LLM-Based Threat Detection and Prevention Framework for IoT Ecosystems](https://arxiv.org//abs/2505.00240)

	Yazan Otoum, Arghavan Asad, Amiya Nayak

+ [Empowering Agentic Video Analytics Systems with Video Language Models](https://arxiv.org//abs/2505.00254)

	Yuxuan Yan, Shiqi Jiang, Ting Cao, Yifan Yang, Qianqian Yang, Yuanchao Shu, Yuqing Yang, Lili Qiu

+ [Consistency in Language Models: Current Landscape, Challenges, and Future Directions](https://arxiv.org//abs/2505.00268)

	Jekaterina Novikova, Carol Anderson, Borhane Blili-Hamelin, Subhabrata Majumdar

+ [Red Teaming Large Language Models for Healthcare](https://arxiv.org//abs/2505.00467)

	Vahid Balazadeh, Michael Cooper, David Pellow, Atousa Assadi, Jennifer Bell, Jim Fackler, Gabriel Funingana, Spencer Gable-Cook, Anirudh Gangadhar, Abhishek Jaiswal, Sumanth Kaja, Christopher Khoury, Randy Lin, Kaden McKeen, Sara Naimimohasses, Khashayar Namdar, Aviraj Newatia, Allan Pang, Anshul Pattoo, Sameer Peesapati, Diana Prepelita, Bogdana Rakova, Saba Sadatamin, Rafael Schulman, Ajay Shah, Syed Azhar Shah, Syed Ahmar Shah, Babak Taati, Balagopal Unnikrishnan, Stephanie Williams, Rahul G Krishnan

+ [HalluMix: A Task-Agnostic, Multi-Domain Benchmark for Real-World Hallucination Detection](https://arxiv.org//abs/2505.00506)

	Deanna Emery, Michael Goitia, Freddie Vargus, Iulia Neagu

+ [Test-time Correlation Alignment](https://arxiv.org//abs/2505.00533)

	Linjing You, Jiabao Lu, Xiayuan Huang

+ [Triggering Hallucinations in LLMs: A Quantitative Study of Prompt-Induced Hallucination in Large Language Models](https://arxiv.org//abs/2505.00557)

	Makoto Sato

+ [FreqKV: Frequency Domain Key-Value Compression for Efficient Context Window Extension](https://arxiv.org//abs/2505.00570)

	Jushi Kai, Boyi Zeng, Yixuan Wang, Haoli Bai, Bo Jiang, Zhouhan Lin

+ [FineScope : Precision Pruning for Domain-Specialized Large Language Models Using SAE-Guided Self-Data Cultivation](https://arxiv.org//abs/2505.00624)

	Chaitali Bhattacharyya, Yeseong Kim

+ [The Illusion of Role Separation: Hidden Shortcuts in LLM Role Learning (and How to Fix Them)](https://arxiv.org//abs/2505.00626)

	Zihao Wang, Yibo Jiang, Jiahao Yu, Heqing Huang

+ [On the generalization of language models from in-context learning and finetuning: a controlled study](https://arxiv.org//abs/2505.00661)

	Andrew K. Lampinen, Arslan Chaudhry, Stephanie C.Y. Chan, Cody Wild, Diane Wan, Alex Ku, Jörg Bornschein, Razvan Pascanu, Murray Shanahan, James L. McClelland

+ [DeepCritic: Deliberate Critique with Large Language Models](https://arxiv.org//abs/2505.00662)

	Wenkai Yang, Jingwen Chen, Yankai Lin, Ji-Rong Wen

+ [Visual Test-time Scaling for GUI Agent Grounding](https://arxiv.org//abs/2505.00684)

	Tiange Luo, Lajanugen Logeswaran, Justin Johnson, Honglak Lee

+ [100 Days After DeepSeek-R1: A Survey on Replication Studies and More Directions for Reasoning Language Models](https://arxiv.org//abs/2505.00551)

	Chong Zhang, Yue Deng, Xiang Lin, Bin Wang, Dianwen Ng, Hai Ye, Xingxuan Li, Yao Xiao, Zhanfeng Mo, Qi Zhang, Lidong Bing

+ [Block Circulant Adapter for Large Language Models](https://arxiv.org//abs/2505.00582)

	Xinyu Ding, Meiqi Wang, Siyu Liao, Zhongfeng Wang

+ [Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future Directions](https://arxiv.org//abs/2505.00675)

	Yiming Du, Wenyu Huang, Danna Zheng, Zhaowei Wang, Sebastien Montella, Mirella Lapata, Kam-Fai Wong, Jeff Z. Pan

+ [Steering Large Language Models with Register Analysis for Arbitrary Style Transfer](https://arxiv.org//abs/2505.00679)

	Xinchen Yang, Marine Carpuat

+ [Self-Generated In-Context Examples Improve LLM Agents for Sequential Decision-Making Tasks](https://arxiv.org//abs/2505.00234)

	Vishnu Sarukkai, Zhiqiang Xie, Kayvon Fatahalian

+ [EnronQA: Towards Personalized RAG over Private Documents](https://arxiv.org//abs/2505.00263)

	Michael J. Ryan, Danmei Xu, Chris Nivera, Daniel Campos

+ [Mixture of Sparse Attention: Content-Based Learnable Sparse Attention via Expert-Choice Routing](https://arxiv.org//abs/2505.00315)

	Piotr Piękos, Róbert Csordás, Jürgen Schmidhuber

+ [Investigating Task Arithmetic for Zero-Shot Information Retrieval](https://arxiv.org//abs/2505.00649)

	Marco Braga, Pranav Kasela, Alessandro Raganato, Gabriella Pasi

+ [Self-Ablating Transformers: More Interpretability, Less Sparsity](https://arxiv.org//abs/2505.00509)

	Jeremias Ferrao, Luhan Mikaelson, Keenan Pepper, Natalia Perez-Campanero Antolin

+ [Thoughts without Thinking: Reconsidering the Explanatory Value of Chain-of-Thought Reasoning in LLMs through Agentic Pipelines](https://arxiv.org//abs/2505.00875)

	Ramesh Manuvinakurike, Emanuel Moss, Elizabeth Anne Watkins, Saurav Sahay, Giuseppe Raffa, Lama Nachman

+ [A Mathematical Philosophy of Explanations in Mechanistic Interpretability -- The Strange Science Part I.i](https://arxiv.org//abs/2505.00808)

	Kola Ayonrinde, Louis Jaburi

+ [Spill The Beans: Exploiting CPU Cache Side-Channels to Leak Tokens from Large Language Models](https://arxiv.org//abs/2505.00817)

	Andrew Adiletta, Berk Sunar

+ [From Texts to Shields: Convergence of Large Language Models and Cybersecurity](https://arxiv.org//abs/2505.00841)

	Tao Li, Ya-Ting Yang, Yunian Pan, Quanyan Zhu

+ [OET: Optimization-based prompt injection Evaluation Toolkit](https://arxiv.org//abs/2505.00843)

	Jinsheng Pan, Xiaogeng Liu, Chaowei Xiao

+ [ICQuant: Index Coding enables Low-bit LLM Quantization](https://arxiv.org//abs/2505.00850)

	Xinlin Li, Osama Hanna, Christina Fragouli, Suhas Diggavi

+ [Towards Explainable Temporal User Profiling with LLMs](https://arxiv.org//abs/2505.00886)

	Milad Sabouri, Masoud Mansoury, Kun Lin, Bamshad Mobasher

+ [A Survey on Large Language Model based Human-Agent Systems](https://arxiv.org//abs/2505.00753)

	Henry Peng Zou, Wei-Chieh Huang, Yaozu Wu, Yankai Chen, Chunyu Miao, Hoang Nguyen, Yue Zhou, Weizhi Zhang, Liancheng Fang, Langzhou He, Yangning Li, Yuwei Cao, Dongyuan Li, Renhe Jiang, Philip S. Yu

+ [Reasoning Capabilities and Invariability of Large Language Models](https://arxiv.org//abs/2505.00776)

	Alessandro Raganato, Rafael Peñaloza, Marco Viviani, Gabriella Pasi

+ [NeMo-Inspector: A Visualization Tool for LLM Generation Analysis](https://arxiv.org//abs/2505.00903)

	Daria Gitman, Igor Gitman, Evelina Bakhturina

+ [Improving Routing in Sparse Mixture of Experts with Graph of Tokens](https://arxiv.org//abs/2505.00792)

	Tam Nguyen, Ngoc N. Tran, Khai Nguyen, Richard G. Baraniuk

+ [Consciousness in AI: Logic, Proof, and Experimental Evidence of Recursive Identity Formation](https://arxiv.org//abs/2505.01464)

	Jeffrey Camlin

+ [Unlearning Sensitive Information in Multimodal LLMs: Benchmark and Attack-Defense Evaluation](https://arxiv.org//abs/2505.01456)

	Vaidehi Patil, Yi-Lin Sung, Peter Hase, Jie Peng, Tianlong Chen, Mohit Bansal

+ [MoxE: Mixture of xLSTM Experts with Entropy-Aware Routing for Efficient Language Modeling](https://arxiv.org//abs/2505.01459)

	Abdoul Majid O. Thiombiano, Brahim Hnich, Ali Ben Mrad, Mohamed Wiem Mkaouer

+ [A Multi-Granularity Multimodal Retrieval Framework for Multimodal Document Tasks](https://arxiv.org//abs/2505.01457)

	Mingjun Xu, Zehui Wang, Hengxing Cai, Renxin Zhong

+ [Sentient Agent as a Judge: Evaluating Higher-Order Social Cognition in Large Language Models](https://arxiv.org//abs/2505.02847)

	Bang Zhang, Ruotian Ma, Qingxuan Jiang, Peisong Wang, Jiaqi Chen, Zheng Xie, Xingyu Chen, Yue Wang, Fanghua Ye, Jian Li, Yifan Yang, Zhaopeng Tu, Xiaolong Li

+ [Towards Efficient Online Tuning of VLM Agents via Counterfactual Soft Reinforcement Learning](https://arxiv.org//abs/2505.03792)

	Lang Feng, Weihao Tan, Zhiyi Lyu, Longtao Zheng, Haiyang Xu, Ming Yan, Fei Huang, Bo An

+ [LENSLLM: Unveiling Fine-Tuning Dynamics for LLM Selection](https://arxiv.org//abs/2505.03793)

	Xinyue Zeng, Haohui Wang, Junhong Lin, Jun Wu, Tyler Cody, Dawei Zhou

+ [Position: Foundation Models Need Digital Twin Representations](https://arxiv.org//abs/2505.03798)

	Yiqing Shen, Hao Ding, Lalithkumar Seenivasan, Tianmin Shu, Mathias Unberath

+ [Patchwork: A Unified Framework for RAG Serving](https://arxiv.org//abs/2505.07833)

	Bodun Hu, Luis Pabon, Saurabh Agarwal, Aditya Akella

# 2025-04-30
+ [Reinforced MLLM: A Survey on RL-Based Reasoning in Multimodal Large Language Models](https://arxiv.org//abs/2504.21277)

	Guanghao Zhou, Panjia Qiu, Cen Chen, Jie Wang, Zheming Yang, Jian Xu, Minghui Qiu

+ [Phi-4-reasoning Technical Report](https://arxiv.org//abs/2504.21318)

	Marah Abdin, Sahaj Agarwal, Ahmed Awadallah, Vidhisha Balachandran, Harkirat Behl, Lingjiao Chen, Gustavo de Rosa, Suriya Gunasekar, Mojan Javaheripi, Neel Joshi, Piero Kauffmann, Yash Lara, Caio César Teodoro Mendes, Arindam Mitra, Besmira Nushi, Dimitris Papailiopoulos, Olli Saarikivi, Shital Shah, Vaishnavi Shrivastava, Vibhav Vineet, Yue Wu, Safoora Yousefi, Guoqing Zheng

+ [ShorterBetter: Guiding Reasoning Models to Find Optimal Inference Length for Efficient Reasoning](https://arxiv.org//abs/2504.21370)

	Jingyang Yi, Jiazheng Wang

+ [AdaR1: From Long-CoT to Hybrid-CoT via Bi-Level Adaptive Reasoning Optimization](https://arxiv.org//abs/2504.21659)

	Haotian Luo, Haiying He, Yibo Wang, Jinluan Yang, Rui Liu, Naiqiang Tan, Xiaochun Cao, Dacheng Tao, Li Shen

+ [Memorization and Knowledge Injection in Gated LLMs](https://arxiv.org//abs/2504.21239)

	Xu Pan, Ely Hahami, Zechen Zhang, Haim Sompolinsky

+ [Assessing LLM code generation quality through path planning tasks](https://arxiv.org//abs/2504.21276)

	Wanyi Chen, Meng-Wen Su, Mary L. Cummings

+ [How to Backdoor the Knowledge Distillation](https://arxiv.org//abs/2504.21323)

	Chen Wu, Qian Ma, Prasenjit Mitra, Sencun Zhu

+ [Retrieval-Enhanced Few-Shot Prompting for Speech Event Extraction](https://arxiv.org//abs/2504.21372)

	Máté Gedeon

+ [Rethinking Visual Layer Selection in Multimodal LLMs](https://arxiv.org//abs/2504.21447)

	Haoran Chen, Junyan Lin, Xinhao Chen, Yue Fan, Xin Jin, Hui Su, Jianfeng Dong, Jinlan Fu, Xiaoyu Shen

+ [Black-Box Visual Prompt Engineering for Mitigating Object Hallucination in Large Vision Language Models](https://arxiv.org//abs/2504.21559)

	Sangmin Woo, Kang Zhou, Yun Zhou, Shuai Wang, Sheng Guan, Haibo Ding, Lin Lee Cheong

+ [Leveraging Pre-trained Large Language Models with Refined Prompting for Online Task and Motion Planning](https://arxiv.org//abs/2504.21596)

	Huihui Guo, Huilong Pi, Yunchuan Qin, Zhuo Tang, Kenli Li

+ [RDF-Based Structured Quality Assessment Representation of Multilingual LLM Evaluations](https://arxiv.org//abs/2504.21605)

	Jonas Gwozdz, Andreas Both

+ [XBreaking: Explainable Artificial Intelligence for Jailbreaking LLMs](https://arxiv.org//abs/2504.21700)

	Marco Arazzi, Vignesh Kumar Kembu, Antonino Nocera, Vinod P

+ [LLM-Empowered Embodied Agent for Memory-Augmented Task Planning in Household Robotics](https://arxiv.org//abs/2504.21716)

	Marc Glocker, Peter Hönig, Matthias Hirschmanner, Markus Vincze

+ [MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness](https://arxiv.org//abs/2504.21773)

	Junsheng Huang, Zhitao He, Sandeep Polisetty, Qingyun Wang, May Fung

+ [WebThinker: Empowering Large Reasoning Models with Deep Research Capability](https://arxiv.org//abs/2504.21776)

	Xiaoxi Li, Jiajie Jin, Guanting Dong, Hongjin Qian, Yutao Zhu, Yongkang Wu, Ji-Rong Wen, Zhicheng Dou

+ [Characterizing AI Agents for Alignment and Governance](https://arxiv.org//abs/2504.21848)

	Atoosa Kasirzadeh, Iason Gabriel

+ [TRUST: An LLM-Based Dialogue System for Trauma Understanding and Structured Assessments](https://arxiv.org//abs/2504.21851)

	Sichang Tu, Abigail Powers, Stephen Doogan, Jinho D. Choi

+ [Talk Before You Retrieve: Agent-Led Discussions for Better RAG in Medical QA](https://arxiv.org//abs/2504.21252)

	Xuanzhao Dong, Wenhui Zhu, Hao Wang, Xiwen Chen, Peijie Qiu, Rui Yin, Yi Su, Yalin Wang

+ [BiasGuard: A Reasoning-enhanced Bias Detection Tool For Large Language Models](https://arxiv.org//abs/2504.21299)

	Zhiting Fan, Ruizhe Chen, Zuozhu Liu

+ [Confidence in Large Language Model Evaluation: A Bayesian Approach to Limited-Sample Challenges](https://arxiv.org//abs/2504.21303)

	Xiao Xiao, Yu Su, Sijing Zhang, Zhang Chen, Yadong Chen, Tian Liu

+ [Does the Prompt-based Large Language Model Recognize Students' Demographics and Introduce Bias in Essay Scoring?](https://arxiv.org//abs/2504.21330)

	Kaixun Yang, Mladen Raković, Dragan Gašević, Guanliang Chen

+ [Precision Where It Matters: A Novel Spike Aware Mixed-Precision Quantization Strategy for LLaMA-based Language Models](https://arxiv.org//abs/2504.21553)

	Lucas Maisonnave, Cyril Moineau, Olivier Bichler, Fabrice Rastello

+ [Meeseeks: An Iterative Benchmark Evaluating LLMs Multi-Turn Instruction-Following Ability](https://arxiv.org//abs/2504.21625)

	Jiaming Wang

+ [CodeFlowBench: A Multi-turn, Iterative Benchmark for Complex Code Generation](https://arxiv.org//abs/2504.21751)

	Sizhe Wang, Zhengren Wang, Dongsheng Ma, Yongan Yu, Rui Ling, Zhiyu Li, Feiyu Xiong, Wentao Zhang

+ [Iterative Trajectory Exploration for Multimodal Agents](https://arxiv.org//abs/2504.21561)

	Pengxiang Li, Zhi Gao, Bofei Zhang, Yapeng Mi, Xiaojian Ma, Chenrui Shi, Tao Yuan, Yuwei Wu, Yunde Jia, Song-Chun Zhu, Qing Li

+ [Unsupervised Feature Transformation via In-context Generation, Generator-critic LLM Agents, and Duet-play Teaming](https://arxiv.org//abs/2504.21304)

	Nanxu Gong, Xinyuan Wang, Wangyang Ying, Haoyue Bai, Sixun Dong, Haifeng Chen, Yanjie Fu

+ [Traceback of Poisoning Attacks to Retrieval-Augmented Generation](https://arxiv.org//abs/2504.21668)

	Baolei Zhang, Haoran Xin, Minghong Fang, Zhuqing Liu, Biao Yi, Tong Li, Zheli Liu

+ [Hoist with His Own Petard: Inducing Guardrails to Facilitate Denial-of-Service Attacks on Retrieval-Augmented Generation of LLMs](https://arxiv.org//abs/2504.21680)

	Pan Suo, Yu-Ming Shang, San-Chuan Guo, Xi Zhang

+ [RAIL in the Wild: Operationalizing Responsible AI Evaluation Using Anthropic's Value Dataset](https://arxiv.org//abs/2505.00204)

	Sumit Verma, Pritam Prasun, Arpit Jaiswal, Pritish Kumar

+ [Between Underthinking and Overthinking: An Empirical Study of Reasoning Length and correctness in LLMs](https://arxiv.org//abs/2505.00127)

	Jinyan Su, Jennifer Healey, Preslav Nakov, Claire Cardie

+ [Enhancing Security and Strengthening Defenses in Automated Short-Answer Grading Systems](https://arxiv.org//abs/2505.00061)

	Sahar Yarmohammadtoosky, Yiyun Zhou, Victoria Yaneva, Peter Baldwin, Saed Rezayi, Brian Clauser, Polina Harikeo

+ [GDI-Bench: A Benchmark for General Document Intelligence with Vision and Reasoning Decoupling](https://arxiv.org//abs/2505.00063)

	Siqi Li, Yufan Shen, Xiangnan Chen, Jiayi Chen, Hengwei Ju, Haodong Duan, Song Mao, Hongbin Zhou, Bo Zhang, Pinlong Cai, Licheng Wen, Botian Shi, Yong Liu, Xinyu Cai, Yu Qiao

+ [ConSens: Assessing context grounding in open-book question answering](https://arxiv.org//abs/2505.00065)

	Ivan Vankov, Matyo Ivanov, Adriana Correia, Victor Botev

+ [Humanizing LLMs: A Survey of Psychological Measurements with Tools, Datasets, and Human-Agent Applications](https://arxiv.org//abs/2505.00049)

	Wenhan Dong, Yuemeng Zhao, Zhen Sun, Yule Liu, Zifan Peng, Jingyi Zheng, Zongmin Zhang, Ziyi Zhang, Jun Wu, Ruiming Wang, Shengmin Xu, Xinyi Huang, Xinlei He

+ [Optimization of embeddings storage for RAG systems using quantization and dimensionality reduction techniques](https://arxiv.org//abs/2505.00105)

	Naamán Huerga-Pérez, Rubén Álvarez, Rubén Ferrero-Guillén, Alberto Martínez-Gutiérrez, Javier Díez-González

+ [Which Agent Causes Task Failures and When? On Automated Failure Attribution of LLM Multi-Agent Systems](https://arxiv.org//abs/2505.00212)

	Shaokun Zhang, Ming Yin, Jieyu Zhang, Jiale Liu, Zhiguang Han, Jingyang Zhang, Beibin Li, Chi Wang, Huazheng Wang, Yiran Chen, Qingyun Wu

+ [Zoomer: Adaptive Image Focus Optimization for Black-box MLLM](https://arxiv.org//abs/2505.00742)

	Jiaxu Qian, Chendong Wang, Yifan Yang, Chaoyun Zhang, Huiqiang Jiang, Xufang Luo, Yu Kang, Qingwei Lin, Anlan Zhang, Shiqi Jiang, Ting Cao, Tianjun Mao, Suman Banerjee, Guyue Liu, Saravan Rajmohan, Dongmei Zhang, Yuqing Yang, Qi Zhang, Lili Qiu

+ [Localizing Before Answering: A Benchmark for Grounded Medical Visual Question Answering](https://arxiv.org//abs/2505.00744)

	Dung Nguyen, Minh Khoi Ho, Huy Ta, Thanh Tam Nguyen, Qi Chen, Kumar Rav, Quy Duong Dang, Satwik Ramchandre, Son Lam Phung, Zhibin Liao, Minh-Son To, Johan Verjans, Phi Le Nguyen, Vu Minh Hieu Phan

+ [Entropy Heat-Mapping: Localizing GPT-Based OCR Errors with Sliding-Window Shannon Analysis](https://arxiv.org//abs/2505.00746)

	Alexei Kaltchenko

+ [COSMOS: Predictable and Cost-Effective Adaptation of LLMs](https://arxiv.org//abs/2505.01449)

	Jiayu Wang, Aws Albarghouthi, Frederic Sala

+ [Calibrating Uncertainty Quantification of Multi-Modal LLMs using Grounding](https://arxiv.org//abs/2505.03788)

	Trilok Padhi, Ramneet Kaur, Adam D. Cobb, Manoj Acharya, Anirban Roy, Colin Samplawski, Brian Matejek, Alexander M. Berenbeim, Nathaniel D. Bastian, Susmit Jha

+ [When Reasoning Beats Scale: A 1.5B Reasoning Model Outranks 13B LLMs as Discriminator](https://arxiv.org//abs/2505.03786)

	Md Fahim Anjum

+ [ALFRED: Ask a Large-language model For Reliable ECG Diagnosis](https://arxiv.org//abs/2505.03781)

	Jin Yu, JaeHo Park, TaeJun Park, Gyurin Kim, JiHyun Lee, Min Sung Lee, Joon-myoung Kwon, Jeong Min Son, Yong-Yeon Jo

+ [mAIstro: an open-source multi-agentic system for automated end-to-end development of radiomics and deep learning models for medical imaging](https://arxiv.org//abs/2505.03785)

	Eleftherios Tzanis, Michail E. Klontzas

+ [Polysemy of Synthetic Neurons Towards a New Type of Explanatory Categorical Vector Spaces](https://arxiv.org//abs/2505.07831)

	Michael Pichat, William Pogrund, Paloma Pichat, Judicael Poumay, Armanouche Gasparian, Samuel Demarchi, Martin Corbet, Alois Georgeon, Michael Veillet-Guillem

+ [SWE-smith: Scaling Data for Software Engineering Agents](https://arxiv.org//abs/2504.21798)

	John Yang, Kilian Leret, Carlos E. Jimenez, Alexander Wettig, Kabir Khandpur, Yanzhe Zhang, Binyuan Hui, Ofir Press, Ludwig Schmidt, Diyi Yang

# 2025-04-29
+ [TAMO:Fine-Grained Root Cause Analysis via Tool-Assisted LLM Agent with Multi-Modality Observation Data](https://arxiv.org//abs/2504.20462)

	Qi Wang, Xiao Zhang, Mingyi Li, Yuan Yuan, Mengbai Xiao, Fuzhen Zhuang, Dongxiao Yu

+ [A Summary on GUI Agents with Foundation Models Enhanced by Reinforcement Learning](https://arxiv.org//abs/2504.20464)

	Jiahao Li, Kaer Huang

+ [ReasonIR: Training Retrievers for Reasoning Tasks](https://arxiv.org//abs/2504.20595)

	Rulin Shao, Rui Qiao, Varsha Kishore, Niklas Muennighoff, Xi Victoria Lin, Daniela Rus, Bryan Kian Hsiang Low, Sewon Min, Wen-tau Yih, Pang Wei Koh, Luke Zettlemoyer

+ [PaRT: Enhancing Proactive Social Chatbots with Personalized Real-Time Retrieval](https://arxiv.org//abs/2504.20624)

	Zihan Niu, Zheyong Xie, Shaosheng Cao, Chonggang Lu, Zheyu Ye, Tong Xu, Zuozhu Liu, Yan Gao, Jia Chen, Zhe Xu, Yi Wu, Yao Hu

+ [Ascendra: Dynamic Request Prioritization for Efficient LLM Serving](https://arxiv.org//abs/2504.20828)

	Azam Ikram, Xiang Li, Sameh Elnikety, Saurabh Bagchi

+ [The Leaderboard Illusion](https://arxiv.org//abs/2504.20879)

	Shivalika Singh, Yiyang Nan, Alex Wang, Daniel D'Souza, Sayash Kapoor, Ahmet Üstün, Sanmi Koyejo, Yuntian Deng, Shayne Longpre, Noah Smith, Beyza Ermis, Marzieh Fadaee, Sara Hooker

+ [CBM-RAG: Demonstrating Enhanced Interpretability in Radiology Report Generation with Multi-Agent RAG and Concept Bottleneck Models](https://arxiv.org//abs/2504.20898)

	Hasan Md Tusfiqur Alam, Devansh Srivastav, Abdulrahman Mohamed Selim, Md Abdul Kadir, Md Moktadiurl Hoque Shuvo, Daniel Sonntag

+ [ChestX-Reasoner: Advancing Radiology Foundation Models with Reasoning through Step-by-Step Verification](https://arxiv.org//abs/2504.20930)

	Ziqing Fan, Cheng Liang, Chaoyi Wu, Ya Zhang, Yanfeng Wang, Weidi Xie

+ [Jekyll-and-Hyde Tipping Point in an AI's Behavior](https://arxiv.org//abs/2504.20980)

	Neil F. Johnson, Frank Yingjie Huo

+ [Local Prompt Optimization](https://arxiv.org//abs/2504.20355)

	Yash Jain, Vishal Chowdhary

+ [ARCS: Agentic Retrieval-Augmented Code Synthesis with Iterative Refinement](https://arxiv.org//abs/2504.20434)

	Manish Bhattarai, Miguel Cordova, Javier Santos, Dan O'Malley

+ [On Psychology of AI -- Does Primacy Effect Affect ChatGPT and Other LLMs?](https://arxiv.org//abs/2504.20444)

	Mika Hämäläinen

+ [Token-Efficient Prompt Injection Attack: Provoking Cessation in LLM Reasoning via Adaptive Token Compression](https://arxiv.org//abs/2504.20493)

	Yu Cui, Yujun Cai, Yiwei Wang

+ [Reinforcement Learning for Reasoning in Large Language Models with One Training Example](https://arxiv.org//abs/2504.20571)

	Yiping Wang, Qing Yang, Zhiyuan Zeng, Liliang Ren, Lucas Liu, Baolin Peng, Hao Cheng, Xuehai He, Kuan Wang, Jianfeng Gao, Weizhu Chen, Shuohang Wang, Simon Shaolei Du, Yelong Shen

+ [Information Retrieval in the Age of Generative AI: The RGB Model](https://arxiv.org//abs/2504.20610)

	Michele Garetto, Alessandro Cornacchia, Franco Galante, Emilio Leonardi, Alessandro Nordio, Alberto Tarable

+ [The Hidden Risks of LLM-Generated Web Application Code: A Security-Centric Evaluation of Code Generation Capabilities in Large Language Models](https://arxiv.org//abs/2504.20612)

	Swaroop Dora, Deven Lunkad, Naziya Aslam, S. Venkatesan, Sandeep Kumar Shukla

+ [Cooking Up Creativity: A Cognitively-Inspired Approach for Enhancing LLM Creativity through Structured Representations](https://arxiv.org//abs/2504.20643)

	Moran Mizrahi, Chen Shani, Gabriel Stanovsky, Dan Jurafsky, Dafna Shahaf

+ [CoCo-Bench: A Comprehensive Code Benchmark For Multi-task Large Language Model Evaluation](https://arxiv.org//abs/2504.20673)

	Wenjing Yin, Tianze Sun, Yijiong Yu, Jiawei Fang, Guangyao Su, Jiancheng Wang, Zekun Wang, Wei Wang, Ran Chen, Ziyun Dai, Shuai Yuan, Menghang Dong, Peng Luo, Dong Cao, Da Lei, Yajun Zhang, Hao Chen, Xiang Ma, Yong Liu, Weifeng Liu, Yuanjian Xu, Ji Pei

+ [Can LLMs Detect Intrinsic Hallucinations in Paraphrasing and Machine Translation?](https://arxiv.org//abs/2504.20699)

	Evangelia Gogoulou, Shorouq Zahra, Liane Guillou, Luise Dürlich, Joakim Nivre

+ [Beyond the Last Answer: Your Reasoning Trace Uncovers More than You Think](https://arxiv.org//abs/2504.20708)

	Hasan Abed Al Kader Hammoud, Hani Itani, Bernard Ghanem

+ [UniversalRAG: Retrieval-Augmented Generation over Multiple Corpora with Diverse Modalities and Granularities](https://arxiv.org//abs/2504.20734)

	Woongyeong Yeo, Kangsan Kim, Soyeong Jeong, Jinheon Baek, Sung Ju Hwang

+ [Grokking in the Wild: Data Augmentation for Real-World Multi-Hop Reasoning with Transformers](https://arxiv.org//abs/2504.20752)

	Roman Abramov, Felix Steinbauer, Gjergji Kasneci

+ [Chain-of-Defensive-Thought: Structured Reasoning Elicits Robustness in Large Language Models against Reference Corruption](https://arxiv.org//abs/2504.20769)

	Wenxiao Wang, Parsa Hosseini, Soheil Feizi

+ [Using LLMs in Generating Design Rationale for Software Architecture Decisions](https://arxiv.org//abs/2504.20781)

	Xiyu Zhou, Ruiyin Li, Peng Liang, Beiqi Zhang, Mojtaba Shahin, Zengyang Li, Chen Yang

+ [Hallucination by Code Generation LLMs: Taxonomy, Benchmarks, Mitigation, and Challenges](https://arxiv.org//abs/2504.20799)

	Yunseo Lee, John Youngeun Song, Dongsun Kim, Jindae Kim, Mijung Kim, Jaechang Nam

+ [Reinforcement Learning for LLM Reasoning Under Memory Constraints](https://arxiv.org//abs/2504.20834)

	Alan Lee, Harry Tong

+ [DYNAMAX: Dynamic computing for Transformers and Mamba based architectures](https://arxiv.org//abs/2504.20922)

	Miguel Nogales, Matteo Gambella, Manuel Roveri

+ [Trace-of-Thought: Enhanced Arithmetic Problem Solving via Reasoning Distillation From Large to Small Language Models](https://arxiv.org//abs/2504.20946)

	Tyler McDonald, Ali Emami

+ [OSVBench: Benchmarking LLMs on Specification Generation Tasks for Operating System Verification](https://arxiv.org//abs/2504.20964)

	Shangyu Li, Juyong Jiang, Tiancheng Zhao, Jiasi Shen

+ [Toward Efficient Exploration by Large Language Model Agents](https://arxiv.org//abs/2504.20997)

	Dilip Arumugam, Thomas L. Griffiths

+ [What Causes Knowledge Loss in Multilingual Language Models?](https://arxiv.org//abs/2504.20356)

	Maria Khelli, Samuel Cahyawijaya, Ayu Purwarianti, Genta Indra Winata

+ [DMDTEval: An Evaluation and Analysis of LLMs on Disambiguation in Multi-domain Translation](https://arxiv.org//abs/2504.20371)

	Zhibo Man, Yuanmeng Chen, Yujie Zhang, Yufeng Chen, Jinan Xu

+ [Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training](https://arxiv.org//abs/2504.20484)

	Linjuan Wu, Haoran Wei, Huan Lin, Tianhao Li, Baosong Yang, Weiming Lu

+ [UniDetox: Universal Detoxification of Large Language Models via Dataset Distillation](https://arxiv.org//abs/2504.20500)

	Huimin Lu, Masaru Isonuma, Junichiro Mori, Ichiro Sakata

+ [Turing Machine Evaluation for Large Language Model](https://arxiv.org//abs/2504.20771)

	Haitao Wu, Zongbo Han, Huaxi Huang, Changqing Zhang

+ [Information Gravity: A Field-Theoretic Model for Token Selection in Large Language Models](https://arxiv.org//abs/2504.20951)

	Maryna Vyshnyvetska

+ [SetKE: Knowledge Editing for Knowledge Elements Overlap](https://arxiv.org//abs/2504.20972)

	Yifan Wei, Xiaoyan Yu, Ran Song, Hao Peng, Angsheng Li

+ [Reviving Any-Subset Autoregressive Models with Principled Parallel Sampling and Speculative Decoding](https://arxiv.org//abs/2504.20456)

	Gabe Guo, Stefano Ermon

+ [Towards Understanding the Nature of Attention with Low-Rank Sparse Decomposition](https://arxiv.org//abs/2504.20938)

	Zhengfu He, Junxuan Wang, Rui Lin, Xuyang Ge, Wentao Shu, Qiong Tang, Junping Zhang, Xipeng Qiu

+ [Antidote: A Unified Framework for Mitigating LVLM Hallucinations in Counterfactual Presupposition and Object Perception](https://arxiv.org//abs/2504.20468)

	Yuanchen Wu, Lu Zhang, Hang Yao, Junlong Du, Ke Yan, Shouhong Ding, Yunsheng Wu, Xiaoqiang Li

+ [X-Fusion: Introducing New Modality to Frozen Large Language Models](https://arxiv.org//abs/2504.20996)

	Sicheng Mo, Thao Nguyen, Xun Huang, Siddharth Srinivasan Iyer, Yijun Li, Yuchen Liu, Abhishek Tandon, Eli Shechtman, Krishna Kumar Singh, Yong Jae Lee, Bolei Zhou, Yuheng Li

+ [Combatting Dimensional Collapse in LLM Pre-Training Data via Diversified File Selection](https://arxiv.org//abs/2504.20644)

	Ziqing Fan, Siyuan Du, Shengchao Hu, Pingjie Wang, Li Shen, Ya Zhang, Dacheng Tao, Yanfeng Wang

+ [AegisLLM: Scaling Agentic Systems for Self-Reflective Defense in LLM Security](https://arxiv.org//abs/2504.20965)

	Zikui Cai, Shayan Shabihi, Bang An, Zora Che, Brian R. Bartoldson, Bhavya Kailkhura, Tom Goldstein, Furong Huang

+ [Softpick: No Attention Sink, No Massive Activations with Rectified Softmax](https://arxiv.org//abs/2504.20966)

	Zayd M. K. Zuhri, Erland Hilman Fuadi, Alham Fikri Aji

+ [ACE: A Security Architecture for LLM-Integrated App Systems](https://arxiv.org//abs/2504.20984)

	Evan Li, Tushin Mallick, Evan Rose, William Robertson, Alina Oprea, Cristina Nita-Rotaru

+ [Enhancing Leakage Attacks on Searchable Symmetric Encryption Using LLM-Based Synthetic Data Generation](https://arxiv.org//abs/2504.20414)

	Joshua Chiu, Partha Protim Paul, Zahin Wahab

+ [Robustness via Referencing: Defending against Prompt Injection Attacks by Referencing the Executed Instruction](https://arxiv.org//abs/2504.20472)

	Yulin Chen, Haoran Li, Yuan Sui, Yue Liu, Yufei He, Yangqiu Song, Bryan Hooi

+ [ReCIT: Reconstructing Full Private Data from Gradient in Parameter-Efficient Fine-Tuning of Large Language Models](https://arxiv.org//abs/2504.20570)

	Jin Xie, Ruishi He, Songze Li, Xiaojun Jia, Shouling Ji

+ [Unlocking User-oriented Pages: Intention-driven Black-box Scanner for Real-world Web Applications](https://arxiv.org//abs/2504.20801)

	Weizhe Wang, Yao Zhang, Kaitai Liang, Guangquan Xu, Hongpeng Bai, Qingyang Yan, Xi Zheng, Bin Wu

+ [Secure Coding with AI, From Creation to Inspection](https://arxiv.org//abs/2504.20814)

	Vladislav Belozerov, Peter J Barclay, Ashkan Sami

+ [NeuRel-Attack: Neuron Relearning for Safety Disalignment in Large Language Models](https://arxiv.org//abs/2504.21053)

	Yi Zhou, Wenpeng Xing, Dezhang Kong, Changting Lin, Meng Han

+ [Erased but Not Forgotten: How Backdoors Compromise Concept Erasure](https://arxiv.org//abs/2504.21072)

	Jonas Henry Grebe, Tobias Braun, Marcus Rohrbach, Anna Rohrbach

+ [TT-LoRA MoE: Unifying Parameter-Efficient Fine-Tuning and Sparse Mixture-of-Experts](https://arxiv.org//abs/2504.21190)

	Pradip Kunwar, Minh N. Vu, Maanak Gupta, Mahmoud Abdelsalam, Manish Bhattarai

+ [Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice for Specialized Applications in Healthcare](https://arxiv.org//abs/2504.21191)

	Lovedeep Gondara, Jonathan Simkin, Graham Sayle, Shebnum Devji, Gregory Arbour, Raymond Ng

+ [SecRepoBench: Benchmarking LLMs for Secure Code Generation in Real-World Repositories](https://arxiv.org//abs/2504.21205)

	Connor Dilgren, Purva Chiniya, Luke Griffith, Yu Ding, Yizheng Chen

+ [CachePrune: Neural-Based Attribution Defense Against Indirect Prompt Injection Attacks](https://arxiv.org//abs/2504.21228)

	Rui Wang, Junda Wu, Yu Xia, Tong Yu, Ruiyi Zhang, Ryan Rossi, Lina Yao, Julian McAuley

+ [LLM Enhancer: Merged Approach using Vector Embedding for Reducing Large Language Model Hallucinations with External Knowledge](https://arxiv.org//abs/2504.21132)

	Naheed Rayhan, Md. Ashrafuzzaman

+ [Detecting Manipulated Contents Using Knowledge-Grounded Inference](https://arxiv.org//abs/2504.21165)

	Mark Huasong Meng, Ruizhe Wang, Meng Xu, Chuan Yan, Guangdong Bai

+ [Efficient LLMs with AMP: Attention Heads and MLP Pruning](https://arxiv.org//abs/2504.21174)

	Leandro Giusti Mugnaini, Bruno Lopes Yamamoto, Lucas Lauton de Alcantara, Victor Zacarias, Edson Bollis, Lucas Pellicer, Anna Helena Reali Costa, Artur Jordao

+ [Graph Synthetic Out-of-Distribution Exposure with Large Language Models](https://arxiv.org//abs/2504.21198)

	Haoyan Xu, Zhengtao Yao, Ziyi Wang, Zhan Cheng, Xiyang Hu, Mengyuan Li, Yue Zhao

+ [A Domain-Agnostic Scalable AI Safety Ensuring Framework](https://arxiv.org//abs/2504.20924)

	Beomjun Kim, Kangyeon Kim, Sunwoo Kim, Heejin Ahn

+ [A Framework to Assess the Persuasion Risks Large Language Model Chatbots Pose to Democratic Societies](https://arxiv.org//abs/2505.00036)

	Zhongren Chen, Joshua Kalla, Quan Le, Shinpei Nakamura-Sakai, Jasjeet Sekhon, Ruixiao Wang

+ [HyPerAlign: Hypotheses-driven Personalized Alignment](https://arxiv.org//abs/2505.00038)

	Cristina Garbacea, Chenhao Tan

+ [Graph RAG for Legal Norms: A Hierarchical and Temporal Approach](https://arxiv.org//abs/2505.00039)

	Hudson de Martim

+ [Improving Phishing Email Detection Performance of Small Large Language Models](https://arxiv.org//abs/2505.00034)

	Zijie Lin, Zikang Liu, Hanbo Fan

# 2025-04-28
+ [GVPO: Group Variance Policy Optimization for Large Language Model Post-Training](https://arxiv.org//abs/2504.19599)

	Kaichen Zhang, Yuzhong Hong, Junwei Bao, Hongfei Jiang, Yang Song, Dingqian Hong, Hui Xiong

+ [From Evidence to Belief: A Bayesian Epistemology Approach to Language Models](https://arxiv.org//abs/2504.19622)

	Minsu Kim, Sangryul Kim, James Thorne

+ [From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review](https://arxiv.org//abs/2504.19678)

	Mohamed Amine Ferrag, Norbert Tihanyi, Merouane Debbah

+ [Can AI Agents Design and Implement Drug Discovery Pipelines?](https://arxiv.org//abs/2504.19912)

	Khachik Smbatyan, Tsolak Ghukasyan, Tigran Aghajanyan, Hovhannes Dabaghyan, Sergey Adamyan, Aram Bughdaryan, Vahagn Altunyan, Gagik Navasardyan, Aram Davtyan, Anush Hakobyan, Aram Gharibyan, Arman Fahradyan, Artur Hakobyan, Hasmik Mnatsakanyan, Narek Ginoyan, Garik Petrosyan

+ [TreeHop: Generate and Filter Next Query Embeddings Efficiently for Multi-hop Question Answering](https://arxiv.org//abs/2504.20114)

	Zhonghao Li, Kunpeng Zhang, Jinghuai Ou, Shuliang Liu, Xuming Hu

+ [AutoP2C: An LLM-Based Agent Framework for Code Repository Generation from Multimodal Content in Academic Papers](https://arxiv.org//abs/2504.20115)

	Zijie Lin, Yiqing Shen, Qilin Cai, He Sun, Jinrui Zhou, Mingjun Xiao

+ [ResearchCodeAgent: An LLM Multi-Agent System for Automated Codification of Research Methodologies](https://arxiv.org//abs/2504.20117)

	Shubham Gandhi, Dhruv Shah, Manasi Patwardhan, Lovekesh Vig, Gautam Shroff

+ [OpenTCM: A GraphRAG-Empowered LLM-based System for Traditional Chinese Medicine Knowledge Retrieval and Diagnosis](https://arxiv.org//abs/2504.20118)

	Jinglin He, Yunqi Guo, Lai Kwan Lam, Waikei Leung, Lixing He, Yuanan Jiang, Chi Chiu Wang, Guoliang Xing, Hongkai Chen

+ [Can LLMs Be Trusted for Evaluating RAG Systems? A Survey of Methods and Datasets](https://arxiv.org//abs/2504.20119)

	Lorenz Brehme, Thomas Ströhle, Ruth Breu

+ [LZ Penalty: An information-theoretic repetition penalty for autoregressive language models](https://arxiv.org//abs/2504.20131)

	Antonio A. Ginart, Naveen Kodali, Jason Lee, Caiming Xiong, Silvio Savarese, John R. Emmons

+ [MICE for CATs: Model-Internal Confidence Estimation for Calibrating Agents with Tools](https://arxiv.org//abs/2504.20168)

	Nishant Subramani, Jason Eisner, Justin Svegliato, Benjamin Van Durme, Yu Su, Sam Thomson

+ [BLADE: Benchmark suite for LLM-driven Automated Design and Evolution of iterative optimisation heuristics](https://arxiv.org//abs/2504.20183)

	Niki van Stein, Anna V. Kononova, Haoran Yin, Thomas Bäck

+ [Prompting LLMs for Code Editing: Struggles and Remedies](https://arxiv.org//abs/2504.20196)

	Daye Nam, Ahmed Omran, Ambar Murillo, Saksham Thakur, Abner Araujo, Marcel Blistein, Alexander Frömmgen, Vincent Hellendoorn, Satish Chandra

+ [Can Large Language Models Learn Formal Logic? A Data-Driven Training and Evaluation Framework](https://arxiv.org//abs/2504.20213)

	Yuan Xia, Akanksha Atrey, Fadoua Khmaissia, Kedar S. Namjoshi

+ [Toward Evaluative Thinking: Meta Policy Optimization with Evolving Reward Models](https://arxiv.org//abs/2504.20157)

	Zae Myung Kim, Chanwoo Park, Vipul Raheja, Dongyeop Kang

+ [LLM-Generated Fake News Induces Truth Decay in News Ecosystem: A Case Study on Neural News Recommendation](https://arxiv.org//abs/2504.20013)

	Beizhe Hu, Qiang Sheng, Juan Cao, Yang Li, Danding Wang

+ [Investigating task-specific prompts and sparse autoencoders for activation monitoring](https://arxiv.org//abs/2504.20271)

	Henk Tillman, Dan Mossing

+ [Security Steerability is All You Need](https://arxiv.org//abs/2504.19521)

	Itay Hazan, Idan Habler, Ron Bitton, Itsik Mantin

+ [The Automation Advantage in AI Red Teaming](https://arxiv.org//abs/2504.19855)

	Rob Mulla, Ads Dawson, Vincent Abruzzon, Brian Greunke, Nick Landers, Brad Palm, Will Pearce

+ [Can Differentially Private Fine-tuning LLMs Protect Against Privacy Attacks?](https://arxiv.org//abs/2504.21036)

	Hao Du, Shang Liu, Yang Cao

+ [Prefill-Based Jailbreak: A Novel Approach of Bypassing LLM Safety Boundary](https://arxiv.org//abs/2504.21038)

	Yakai Li, Jiekang Hu, Weiduan Sang, Luping Ma, Jing Xie, Weijuan Zhang, Aimin Yu, Shijie Zhao, Qingjia Huang, Qihang Zhou

+ [Llama-3.1-FoundationAI-SecurityLLM-Base-8B Technical Report](https://arxiv.org//abs/2504.21039)

	Paul Kassianik, Baturay Saglam, Alexander Chen, Blaine Nelson, Anu Vellore, Massimo Aufiero, Fraser Burch, Dhruv Kedia, Avi Zohary, Sajana Weerawardhena, Aman Priyanshu, Adam Swanda, Amy Chang, Hyrum Anderson, Kojin Oshiba, Omar Santos, Yaron Singer, Amin Karbasi

+ [What's Pulling the Strings? Evaluating Integrity and Attribution in AI Training and Inference through Concept Shift](https://arxiv.org//abs/2504.21042)

	Jiamin Chang, Haoyang Li, Hammond Pearce, Ruoxi Sun, Bo Li, Minhui Xue

+ [CodeBC: A More Secure Large Language Model for Smart Contract Code Generation in Blockchain](https://arxiv.org//abs/2504.21043)

	Lingxiang wang, Hainan Zhang, Qinnan Zhang, Ziwei Wang, Hongwei Zheng, Jin Dong, Zhiming Zheng

+ [AGATE: Stealthy Black-box Watermarking for Multimodal Model Copyright Protection](https://arxiv.org//abs/2504.21044)

	Jianbo Gao, Keke Gai, Jing Yu, Liehuang Zhu, Qi Wu

+ [Leveraging LLM to Strengthen ML-Based Cross-Site Scripting Detection](https://arxiv.org//abs/2504.21045)

	Dennis Miczek, Divyesh Gabbireddy, Suman Saha

+ [Learning to Plan Before Answering: Self-Teaching LLMs to Learn Abstract Plans for Problem Solving](https://arxiv.org//abs/2505.00031)

	Jin Zhang, Flood Sung, Zhilin Yang, Yang Gao, Chongjie Zhang

+ [BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text](https://arxiv.org//abs/2504.19467)

	Jiageng Wu, Bowen Gu, Ren Zhou, Kevin Xie, Doug Snyder, Yixing Jiang, Valentina Carducci, Richard Wyss, Rishi J Desai, Emily Alsentzer, Leo Anthony Celi, Adam Rodman, Sebastian Schneeweiss, Jonathan H. Chen, Santiago Romero-Brufau, Kueiyu Joshua Lin, Jie Yang

+ [Agentic Reasoning and Tool Integration for LLMs via Reinforcement Learning](https://arxiv.org//abs/2505.01441)

	Joykirat Singh, Raghav Magazine, Yash Pandya, Akshay Nambi

+ [Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents](https://arxiv.org//abs/2504.19956)

	Vineeth Sai Narajala, Om Narayan

+ [Accurate and Diverse LLM Mathematical Reasoning via Automated PRM-Guided GFlowNets](https://arxiv.org//abs/2504.19981)

	Adam Younsi, Abdalgader Abubaker, Mohamed El Amine Seddik, Hakim Hacid, Salem Lahlou

# 2025-04-27
+ [GenTorrent: Scaling Large Language Model Serving with An Overley Network](https://arxiv.org//abs/2504.20101)

	Fei Fang, Yifan Hua, Shengze Wang, Ruilin Zhou, Yi Liu, Chen Qian, Xiaoxue Zhang

+ [Adaptive Helpfulness-Harmlessness Alignment with Preference Vectors](https://arxiv.org//abs/2504.20106)

	Ren-Wei Liang, Chin-Ting Hsu, Chan-Hung Yu, Saransh Agrawal, Shih-Cheng Huang, Shang-Tse Chen, Kuan-Hao Huang, Shao-Hua Sun

+ [Unified Multi-Task Learning & Model Fusion for Efficient Language Model Guardrailing](https://arxiv.org//abs/2504.19333)

	James O' Neill, Santhosh Subramanian, Eric Lin, Vaikkunth Mugunthan

+ [Doxing via the Lens: Revealing Privacy Leakage in Image Geolocation for Agentic Multi-Modal Large Reasoning Model](https://arxiv.org//abs/2504.19373)

	Weidi Luo, Qiming Zhang, Tianyu Lu, Xiaogeng Liu, Yue Zhao, Zhen Xiang, Chaowei Xiao

+ [Selecting the Right LLM for eGov Explanations](https://arxiv.org//abs/2504.21032)

	Lior Limonad, Fabiana Fournier, Hadar Mulian, George Manias, Spiros Borotis, Danai Kyrkou

+ [SAGA: A Security Architecture for Governing AI Agentic Systems](https://arxiv.org//abs/2504.21034)

	Georgios Syros, Anshuman Suri, Cristina Nita-Rotaru, Alina Oprea

+ [Uncertainty Quantification for Language Models: A Suite of Black-Box, White-Box, LLM Judge, and Ensemble Scorers](https://arxiv.org//abs/2504.19254)

	Dylan Bouchard, Mohit Singh Chauhan

+ [Contextual Online Uncertainty-Aware Preference Learning for Human Feedback](https://arxiv.org//abs/2504.19342)

	Nan Lu, Ethan X. Fang, Junwei Lu

+ [Enhancing Speech-to-Speech Dialogue Modeling with End-to-End Retrieval-Augmented Generation](https://arxiv.org//abs/2505.00028)

	Pengchao Feng, Ziyang Ma, Wenxi Chen, Yao Li, Sheng Wang, Kai Yu, Xie Chen

+ [BrowseComp-ZH: Benchmarking Web Browsing Ability of Large Language Models in Chinese](https://arxiv.org//abs/2504.19314)

	Peilin Zhou, Bruce Leon, Xiang Ying, Can Zhang, Yifan Shao, Qichen Ye, Dading Chong, Zhiling Jin, Chenxuan Xie, Meng Cao, Yuxin Gu, Sixin Hong, Jing Ren, Jian Chen, Chao Liu, Yining Hua

+ [VIST-GPT: Ushering in the Era of Visual Storytelling with LLMs?](https://arxiv.org//abs/2504.19267)

	Mohamed Gado, Towhid Taliee, Muhammad Memon, Dmitry Ignatov, Radu Timofte

+ [SPC: Evolving Self-Play Critic via Adversarial Games for LLM Reasoning](https://arxiv.org//abs/2504.19162)

	Jiaqi Chen, Bang Zhang, Ruotian Ma, Peisong Wang, Xiaodan Liang, Zhaopeng Tu, Xiaolong Li, Kwan-Yee K. Wong

# 2025-04-26
+ [A Vision for Auto Research with LLM Agents](https://arxiv.org//abs/2504.18765)

	Chengwei Liu, Chong Wang, Jiayue Cao, Jingquan Ge, Kun Wang, Lvye Zhang, Ming-Ming Cheng, Penghai Zhao, Tianlin Li, Xiaojun Jia, Xiang Li, Xinfeng Li, Yang Liu, Yebo Feng, Yihao Huang, Yijia Xu, Yuqiang Sun, Zhenhong Zhou, Zhengzi Xu

+ [Generative to Agentic AI: Survey, Conceptualization, and Challenges](https://arxiv.org//abs/2504.18875)

	Johannes Schneider

+ [MATCHA: Can Multi-Agent Collaboration Build a Trustworthy Conversational Recommender?](https://arxiv.org//abs/2504.20094)

	Zheng Hui, Xiaokai Wei, Yexi Jiang, Kevin Gao, Chen Wang, Frank Ong, Se-eun Yoon, Rachit Pareek, Michelle Gong

+ [PICO: Secure Transformers via Robust Prompt Isolation and Cybersecurity Oversight](https://arxiv.org//abs/2504.21029)

	Ben Goertzel, Paulos Yibelo

+ [SynLexLM: Scaling Legal LLMs with Synthetic Data and Curriculum Learning](https://arxiv.org//abs/2504.18762)

	Ojasw Upadhyay, Abishek Saravanakumar, Ayman Ismail

+ [Theory of Mind in Large Language Models: Assessment and Enhancement](https://arxiv.org//abs/2505.00026)

	Ruirui Chen, Weifeng Jiang, Chengwei Qin, Cheston Tan

+ [Building Scalable AI-Powered Applications with Cloud Databases: Architectures, Best Practices and Performance Considerations](https://arxiv.org//abs/2504.18793)

	Santosh Bhupathi

+ [Test It Before You Trust It: Applying Software Testing for Trustworthy In-context Learning](https://arxiv.org//abs/2504.18827)

	Teeradaj Racharak, Chaiyong Ragkhitwetsagul, Chommakorn Sontesadisai, Thanwadee Sunetnanta

+ [A Simple Ensemble Strategy for LLM Inference: Towards More Stable Text Classification](https://arxiv.org//abs/2504.18884)

	Junichiro Niimi

# 2025-04-25
+ [MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind](https://arxiv.org//abs/2504.18039)

	Zheng Zhang, Nuoqian Xiao, Qi Chai, Deheng Ye, Hao Wang

+ [Reason Like a Radiologist: Chain-of-Thought and Reinforcement Learning for Verifiable Report Generation](https://arxiv.org//abs/2504.18453)

	Peiyuan Jing, Kinhei Lee, Zhenxuan Zhang, Huichi Zhou, Zhengqing Yuan, Zhifan Gao, Lei Zhu, Giorgos Papanastasiou, Yingying Fang, Guang Yang

+ [Scaling Laws For Scalable Oversight](https://arxiv.org//abs/2504.18530)

	Joshua Engels, David D. Baek, Subhash Kantamneni, Max Tegmark

+ [RAG LLMs are Not Safer: A Safety Analysis of Retrieval-Augmented Generation for Large Language Models](https://arxiv.org//abs/2504.18041)

	Bang An, Shiyue Zhang, Mark Dredze

+ [PropRAG: Guiding Retrieval with Beam Search over Proposition Paths](https://arxiv.org//abs/2504.18070)

	Jingjin Wang

+ [Stabilizing Reasoning in Medical LLMs with Continued Pretraining and Reasoning Preference Optimization](https://arxiv.org//abs/2504.18080)

	Wataru Kawakami, Keita Suzuki, Junichiro Iwasawa

+ [Random-Set Large Language Models](https://arxiv.org//abs/2504.18085)

	Muhammad Mubashar, Shireen Kudukkil Manchingal, Fabio Cuzzolin

+ [Application and Optimization of Large Models Based on Prompt Tuning for Fact-Check-Worthiness Estimation](https://arxiv.org//abs/2504.18104)

	Yinglong Yu, Hao Shen, Zhengyi Lyu, Qi He

+ [Evaluating Evaluation Metrics -- The Mirage of Hallucination Detection](https://arxiv.org//abs/2504.18114)

	Atharva Kulkarni, Yuan Zhang, Joel Ruben Antony Moniz, Xiou Ge, Bo-Hsiang Tseng, Dhivya Piraviperumal, Swabha Swayamdipta, Hong Yu

+ [Efficient Single-Pass Training for Multi-Turn Reasoning](https://arxiv.org//abs/2504.18246)

	Ritesh Goru, Shanay Mehta, Prateek Jain

+ [Towards Adaptive Software Agents for Debugging](https://arxiv.org//abs/2504.18316)

	Yacine Majdoub, Eya Ben Charrada, Haifa Touati

+ [Comparing Uncertainty Measurement and Mitigation Methods for Large Language Models: A Systematic Review](https://arxiv.org//abs/2504.18346)

	Toghrul Abbasli, Kentaroh Toyoda, Yuan Wang, Leon Witt, Muhammad Asif Ali, Yukai Miao, Dan Li, Qingsong Wei

+ [LLMpatronous: Harnessing the Power of LLMs For Vulnerability Detection](https://arxiv.org//abs/2504.18423)

	Rajesh Yarra

+ [Fast-Slow Thinking for Large Vision-Language Model Reasoning](https://arxiv.org//abs/2504.18458)

	Wenyi Xiao, Leilei Gan, Weilong Dai, Wanggui He, Ziwei Huang, Haoyuan Li, Fangxun Shu, Zhelun Yu, Peng Zhang, Hao Jiang, Fei Wu

+ [Improving LLM Personas via Rationalization with Psychological Scaffolds](https://arxiv.org//abs/2504.17993)

	Brihi Joshi, Xiang Ren, Swabha Swayamdipta, Rik Koncel-Kedziorski, Tim Paek

+ [DREAM: Disentangling Risks to Enhance Safety Alignment in Multimodal Large Language Models](https://arxiv.org//abs/2504.18053)

	Jianyu Liu, Hangyu Guo, Ranjie Duan, Xingyuan Bu, Yancheng He, Shilong Li, Hui Huang, Jiaheng Liu, Yucheng Wang, Chenchen Jing, Xingwei Qu, Xiao Zhang, Yingshui Tan, Yanan Wu, Jihao Gu, Yangguang Li, Jianke Zhu

+ [Even Small Reasoners Should Quote Their Sources: Introducing the Pleias-RAG Model Family](https://arxiv.org//abs/2504.18225)

	Pierre-Carl Langlais, Pavel Chizhov, Mattia Nee, Carlos Rosas Hinostroza, Matthieu Delsart, Irène Girard, Othman Hicheur, Anastasia Stasenko, Ivan P. Yamshchikov

+ [MAGI: Multi-Agent Guided Interview for Psychiatric Assessment](https://arxiv.org//abs/2504.18260)

	Guanqun Bi, Zhuang Chen, Zhoufu Liu, Hongkai Wang, Xiyao Xiao, Yuqiang Xie, Wen Zhang, Yongkang Huang, Yuxuan Chen, Libiao Peng, Yi Feng, Minlie Huang

+ [Auto-SLURP: A Benchmark Dataset for Evaluating Multi-Agent Frameworks in Smart Personal Assistant](https://arxiv.org//abs/2504.18373)

	Lei Shen, Xiaoyu Shen

+ [Expressing stigma and inappropriate responses prevents LLMs from safely replacing mental health providers](https://arxiv.org//abs/2504.18412)

	Jared Moore, Declan Grabb, William Agnew, Kevin Klyman, Stevie Chancellor, Desmond C. Ong, Nick Haber

+ [BitNet v2: Native 4-bit Activations with Hadamard Transformation for 1-bit LLMs](https://arxiv.org//abs/2504.18415)

	Hongyu Wang, Shuming Ma, Furu Wei

+ [PolyMath: Evaluating Mathematical Reasoning in Multilingual Contexts](https://arxiv.org//abs/2504.18428)

	Yiming Wang, Pei Zhang, Jialong Tang, Haoran Wei, Baosong Yang, Rui Wang, Chenshu Sun, Feitong Sun, Jiran Zhang, Junxuan Wu, Qiqian Cang, Yichang Zhang, Fei Huang, Junyang Lin, Fei Huang, Jingren Zhou

+ [Investigating Co-Constructive Behavior of Large Language Models in Explanation Dialogues](https://arxiv.org//abs/2504.18483)

	Leandra Fichtel, Maximilian Spliethöver, Eyke Hüllermeier, Patricia Jimenez, Nils Klowait, Stefan Kopp, Axel-Cyrille Ngonga Ngomo, Amelie Robrecht, Ingrid Scharlau, Lutz Terfloth, Anna-Lisa Vollmer, Henning Wachsmuth

+ [TRACE Back from the Future: A Probabilistic Reasoning Approach to Controllable Language Generation](https://arxiv.org//abs/2504.18535)

	Gwen Yidou Weng, Benjie Wang, Guy Van den Broeck

+ [SMARTFinRAG: Interactive Modularized Financial RAG Benchmark](https://arxiv.org//abs/2504.18024)

	Yiwei Zha

+ [Adversarial Attacks on LLM-as-a-Judge Systems: Insights from Prompt Injections](https://arxiv.org//abs/2504.18333)

	Narek Maloyan, Dmitry Namiot

+ [Revisiting Data Auditing in Large Vision-Language Models](https://arxiv.org//abs/2504.18349)

	Hongyu Zhu, Sichu Liang, Wenwen Wang, Boheng Li, Tongxin Yuan, Fangqi Li, ShiLin Wang, Zhuosheng Zhang

+ [Think, Prune, Train, Improve: Scaling Reasoning without Scaling Models](https://arxiv.org//abs/2504.18116)

	Caia Costello, Simon Guo, Anna Goldie, Azalia Mirhoseini

+ [DualRAG: A Dual-Process Approach to Integrate Reasoning and Retrieval for Multi-Hop Question Answering](https://arxiv.org//abs/2504.18243)

	Rong Cheng, Jinyi Liu, YAN ZHENG, Fei Ni, Jiazhen Du, Hangyu Mao, Fuzheng Zhang, Bo Wang, Jianye HAO

+ [Studying Small Language Models with Susceptibilities](https://arxiv.org//abs/2504.18274)

	Garrett Baker, George Wang, Jesse Hoogland, Daniel Murfet

+ [Streaming, Fast and Slow: Cognitive Load-Aware Streaming for Efficient LLM Serving](https://arxiv.org//abs/2504.17999)

	Chang Xiao, Brenda Yang

+ [NoEsis: Differentially Private Knowledge Transfer in Modular LLM Adaptation](https://arxiv.org//abs/2504.18147)

	Rob Romijnders, Stefanos Laskaridis, Ali Shahin Shamsabadi, Hamed Haddadi

+ [Automating Function-Level TARA for Automotive Full-Lifecycle Security](https://arxiv.org//abs/2504.18083)

	Yuqiao Yang, Yongzhao Zhang, Wenhao Liu, Jun Li, Pengtao Shi, DingYu Zhong, Jie Yang, Ting Chen, Sheng Cao, Yuntao Ren, Yongyue Wu, Xiaosong Zhang

+ [ThreMoLIA: Threat Modeling of Large Language Model-Integrated Applications](https://arxiv.org//abs/2504.18369)

	Felix Viktor Jedrzejewski, Davide Fucci, Oleksandr Adamov

+ [Proof-of-TBI -- Fine-Tuned Vision Language Model Consortium and OpenAI-o3 Reasoning LLM-Based Medical Diagnosis Support System for Mild Traumatic Brain Injury (TBI) Prediction](https://arxiv.org//abs/2504.18671)

	Ross Gore, Eranga Bandara, Sachin Shetty, Alberto E. Musto, Pratip Rana, Ambrosio Valencia-Romero, Christopher Rhea, Lobat Tayebi, Heather Richter, Atmaram Yarlagadda, Donna Edmonds, Steven Wallace, Donna Broshek

+ [Evolution of AI in Education: Agentic Workflows](https://arxiv.org//abs/2504.20082)

	Firuz Kamalov, David Santandreu Calonge, Linda Smail, Dilshod Azizov, Dimple R. Thadani, Theresa Kwong, Amara Atif

+ [Spark: A System for Scientifically Creative Idea Generation](https://arxiv.org//abs/2504.20090)

	Aishik Sanyal, Samuel Schapiro, Sumuk Shashidhar, Royce Moon, Lav R. Varshney, Dilek Hakkani-Tur

+ [A model and package for German ColBERT](https://arxiv.org//abs/2504.20083)

	Thuong Dang, Qiqi Chen

+ [CORG: Generating Answers from Complex, Interrelated Contexts](https://arxiv.org//abs/2505.00023)

	Hyunji Lee, Franck Dernoncourt, Trung Bui, Seunghyun Yoon

+ [Nemotron-Research-Tool-N1: Tool-Using Language Models with Reinforced Reasoning](https://arxiv.org//abs/2505.00024)

	Shaokun Zhang, Yi Dong, Jieyu Zhang, Jan Kautz, Bryan Catanzaro, Andrew Tao, Qingyun Wu, Zhiding Yu, Guilin Liu

+ [A Method for the Architecture of a Medical Vertical Large Language Model Based on Deepseek R1](https://arxiv.org//abs/2505.00025)

	Mingda Zhang, Jianglong Qin

+ [Anti-adversarial Learning: Desensitizing Prompts for Large Language Models](https://arxiv.org//abs/2505.01273)

	Xuan Li, Zhe Yin, Xiaodong Gu, Beijun Shen

# 2025-04-24
+ [Assessing the Capability of Large Language Models for Domain-Specific Ontology Generation](https://arxiv.org//abs/2504.17402)

	Anna Sofia Lippolis, Mohammad Javad Saeedizade, Robin Keskisarkka, Aldo Gangemi, Eva Blomqvist, Andrea Giovanni Nuzzolese

+ [Towards Machine-Generated Code for the Resolution of User Intentions](https://arxiv.org//abs/2504.17531)

	Justus Flerlage, Ilja Behnke, Odej Kao

+ [Auditing the Ethical Logic of Generative AI Models](https://arxiv.org//abs/2504.17544)

	W. Russell Neuman, Chad Coleman, Ali Dasdan, Safinah Ali, Manan Shah

+ [Automatically Generating Rules of Malicious Software Packages via Large Language Model](https://arxiv.org//abs/2504.17198)

	XiangRui Zhang, HaoYu Chen, Yongzhong He, Wenjia Niu, Qiang Li

+ [FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation](https://arxiv.org//abs/2504.17311)

	Yulia Otmakhova, Hung Thinh Truong, Rahmad Mahendra, Zenan Zhai, Rongxin Zhu, Daniel Beck, Jey Han Lau

+ [LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams](https://arxiv.org//abs/2504.17366)

	Yongxuan Wu, Runyu Chen, Peiyu Liu, Hongjin Qian

+ [Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks](https://arxiv.org//abs/2504.17421)

	Yang Liu, Bingjie Yan, Tianyuan Zou, Jianqing Zhang, Zixuan Gu, Jianbing Ding, Xidong Wang, Jingyi Li, Xiaozhou Ye, Ye Ouyang, Qiang Yang, Ya-Qin Zhang

+ [Towards Leveraging Large Language Model Summaries for Topic Modeling in Source Code](https://arxiv.org//abs/2504.17426)

	Michele Carissimi, Martina Saletta, Claudio Ferretti

+ [HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models](https://arxiv.org//abs/2504.17449)

	Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, Qin Xie, Guiming Xie, Xuejian Gong

+ [HalluLens: LLM Hallucination Benchmark](https://arxiv.org//abs/2504.17550)

	Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung

+ [Towards a HIPAA Compliant Agentic AI System in Healthcare](https://arxiv.org//abs/2504.17669)

	Subash Neupane, Shaswata Mitra, Sudip Mittal, Shahram Rahimi

+ [INSIGHT: Bridging the Student-Teacher Gap in Times of Large Language Models](https://arxiv.org//abs/2504.17677)

	Jarne Thys, Sebe Vanbrabant, Davy Vanacken, Gustavo Rovelo Ruiz

+ [Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks](https://arxiv.org//abs/2504.17685)

	Haru-Tada Sato, Fuka Matsuzaki, Jun-ichiro Takahashi

+ [Multilingual Performance Biases of Large Language Models in Education](https://arxiv.org//abs/2504.17720)

	Vansh Gupta, Sankalan Pal Chowdhury, Vilém Zouhar, Donya Rooein, Mrinmaya Sachan

+ [Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning](https://arxiv.org//abs/2504.17192)

	Minju Seo, Jinheon Baek, Seongyun Lee, Sung Ju Hwang

+ [A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation](https://arxiv.org//abs/2504.17200)

	Yangxinyu Xie, Bowen Jiang, Tanwi Mallick, Joshua David Bergerson, John K. Hutchison, Duane R. Verner, Jordan Branham, M. Ross Alexander, Robert B. Ross, Yan Feng, Leslie-Anne Levy, Weijie Su, Camillo J. Taylor

+ [Does Knowledge Distillation Matter for Large Language Model based Bundle Generation?](https://arxiv.org//abs/2504.17220)

	Kaidong Feng, Zhu Sun, Jie Yang, Hui Fang, Xinghua Qu, Wenyuan Liu

+ [Crisp: Cognitive Restructuring of Negative Thoughts through Multi-turn Supportive Dialogues](https://arxiv.org//abs/2504.17238)

	Jinfeng Zhou, Yuxuan Chen, Jianing Yin, Yongkang Huang, Yihan Shi, Xikun Zhang, Libiao Peng, Rongsheng Zhang, Tangjie Lv, Zhipeng Hu, Hongning Wang, Minlie Huang

+ [CoheMark: A Novel Sentence-Level Watermark for Enhanced Text Quality](https://arxiv.org//abs/2504.17309)

	Junyan Zhang, Shuliang Liu, Aiwei Liu, Yubo Gao, Jungang Li, Xiaojie Gu, Xuming Hu

+ [FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation](https://arxiv.org//abs/2504.17311)

	Yulia Otmakhova, Hung Thinh Truong, Rahmad Mahendra, Zenan Zhai, Rongxin Zhu, Daniel Beck, Jey Han Lau

+ [LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams](https://arxiv.org//abs/2504.17366)

	Yongxuan Wu, Runyu Chen, Peiyu Liu, Hongjin Qian

+ [Unified Attacks to Large Language Model Watermarks: Spoofing and Scrubbing in Unauthorized Knowledge Distillation](https://arxiv.org//abs/2504.17480)

	Xin Yi, Shunfan Zhengc, Linlin Wanga, Xiaoling Wang, Liang He

+ [HalluLens: LLM Hallucination Benchmark](https://arxiv.org//abs/2504.17550)

	Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung

+ [When Does Metadata Conditioning (NOT) Work for Language Model Pre-Training? A Study with Context-Free Grammars](https://arxiv.org//abs/2504.17562)

	Rei Higuchi, Ryotaro Kawata, Naoki Nishikawa, Kazusato Oko, Shoichiro Yamaguchi, Sosuke Kobayashi, Seiya Tokui, Kohei Hayashi, Daisuke Okanohara, Taiji Suzuki

+ [DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training](https://arxiv.org//abs/2504.17565)

	Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li

+ [Evaluating Grounded Reasoning by Code-Assisted Large Language Models for Mathematics](https://arxiv.org//abs/2504.17665)

	Zena Al-Khalili, Nick Howell, Dietrich Klakow

+ [Energy Considerations of Large Language Model Inference and Efficiency Optimizations](https://arxiv.org//abs/2504.17674)

	Jared Fernandez, Clara Na, Vashisth Tiwari, Yonatan Bisk, Sasha Luccioni, Emma Strubell

+ [Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks](https://arxiv.org//abs/2504.17685)

	Haru-Tada Sato, Fuka Matsuzaki, Jun-ichiro Takahashi

+ [Safety in Large Reasoning Models: A Survey](https://arxiv.org//abs/2504.17704)

	Cheng Wang, Yue Liu, Baolong Li, Duzhen Zhang, Zhongzhi Li, Junfeng Fang

+ [Multilingual Performance Biases of Large Language Models in Education](https://arxiv.org//abs/2504.17720)

	Vansh Gupta, Sankalan Pal Chowdhury, Vilém Zouhar, Donya Rooein, Mrinmaya Sachan

+ [The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs](https://arxiv.org//abs/2504.17768)

	Piotr Nawrot, Robert Li, Renjie Huang, Sebastian Ruder, Kelly Marchisio, Edoardo M. Ponti

+ [HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models](https://arxiv.org//abs/2504.17449)

	Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, Qin Xie, Guiming Xie, Xuejian Gong

+ [Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs](https://arxiv.org//abs/2504.17432)

	Tiancheng Gu, Kaicheng Yang, Ziyong Feng, Xingjun Wang, Yanzhao Zhang, Dingkun Long, Yingda Chen, Weidong Cai, Jiankang Deng

+ [Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks](https://arxiv.org//abs/2504.17421)

	Yang Liu, Bingjie Yan, Tianyuan Zou, Jianqing Zhang, Zixuan Gu, Jianbing Ding, Xidong Wang, Jingyi Li, Xiaozhou Ye, Ye Ouyang, Qiang Yang, Ya-Qin Zhang

+ [Towards Robust LLMs: an Adversarial Robustness Measurement Framework](https://arxiv.org//abs/2504.17723)

	Natan Levy, Adiel Ashrov, Guy Katz

+ [Replay to Remember: Retaining Domain Knowledge in Streaming Language Models](https://arxiv.org//abs/2504.17780)

	Sneh Pillai (University of Massachusetts Dartmouth)

+ [High-Fidelity And Complex Test Data Generation For Real-World SQL Code Generation Services](https://arxiv.org//abs/2504.17203)

	Shivasankari Kannan, Yeounoh Chung, Amita Gondi, Tristan Swadell, Fatma Ozcan

+ [Comprehend, Divide, and Conquer: Feature Subspace Exploration via Multi-Agent Hierarchical Reinforcement Learning](https://arxiv.org//abs/2504.17356)

	Weiliang Zhang, Xiaohan Huang, Yi Du, Ziyue Qiao, Qingqing Long, Zhen Meng, Yuanchun Zhou, Meng Xiao

+ [On-Device Qwen2.5: Efficient LLM Inference with Model Compression and Hardware Acceleration](https://arxiv.org//abs/2504.17376)

	Maoyang Xiang, Ramesh Fernando, Bo Wang

+ [L3: DIMM-PIM Integrated Architecture and Coordination for Scalable Long-Context LLM Inference](https://arxiv.org//abs/2504.17584)

	Qingyuan Liu, Liyan Chen, Yanning Yang, Haocheng Wang, Dong Du, Zhigang Mao, Naifeng Jing, Yubin Xia, Haibo Chen

+ [Assessing the Capability of Large Language Models for Domain-Specific Ontology Generation](https://arxiv.org//abs/2504.17402)

	Anna Sofia Lippolis, Mohammad Javad Saeedizade, Robin Keskisarkka, Aldo Gangemi, Eva Blomqvist, Andrea Giovanni Nuzzolese

+ [Towards Machine-Generated Code for the Resolution of User Intentions](https://arxiv.org//abs/2504.17531)

	Justus Flerlage, Ilja Behnke, Odej Kao

+ [Auditing the Ethical Logic of Generative AI Models](https://arxiv.org//abs/2504.17544)

	W. Russell Neuman, Chad Coleman, Ali Dasdan, Safinah Ali, Manan Shah

+ [Automatically Generating Rules of Malicious Software Packages via Large Language Model](https://arxiv.org//abs/2504.17198)

	XiangRui Zhang, HaoYu Chen, Yongzhong He, Wenjia Niu, Qiang Li

+ [NeuralGrok: Accelerate Grokking by Neural Gradient Transformation](https://arxiv.org//abs/2504.17243)

	Xinyu Zhou, Simin Fan, Martin Jaggi, Jie Fu

+ [FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation](https://arxiv.org//abs/2504.17311)

	Yulia Otmakhova, Hung Thinh Truong, Rahmad Mahendra, Zenan Zhai, Rongxin Zhu, Daniel Beck, Jey Han Lau

+ [LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams](https://arxiv.org//abs/2504.17366)

	Yongxuan Wu, Runyu Chen, Peiyu Liu, Hongjin Qian

+ [Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks](https://arxiv.org//abs/2504.17421)

	Yang Liu, Bingjie Yan, Tianyuan Zou, Jianqing Zhang, Zixuan Gu, Jianbing Ding, Xidong Wang, Jingyi Li, Xiaozhou Ye, Ye Ouyang, Qiang Yang, Ya-Qin Zhang

+ [Towards Leveraging Large Language Model Summaries for Topic Modeling in Source Code](https://arxiv.org//abs/2504.17426)

	Michele Carissimi, Martina Saletta, Claudio Ferretti

+ [HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models](https://arxiv.org//abs/2504.17449)

	Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, Qin Xie, Guiming Xie, Xuejian Gong

+ [HalluLens: LLM Hallucination Benchmark](https://arxiv.org//abs/2504.17550)

	Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung

+ [Towards a HIPAA Compliant Agentic AI System in Healthcare](https://arxiv.org//abs/2504.17669)

	Subash Neupane, Shaswata Mitra, Sudip Mittal, Shahram Rahimi

+ [INSIGHT: Bridging the Student-Teacher Gap in Times of Large Language Models](https://arxiv.org//abs/2504.17677)

	Jarne Thys, Sebe Vanbrabant, Davy Vanacken, Gustavo Rovelo Ruiz

+ [Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks](https://arxiv.org//abs/2504.17685)

	Haru-Tada Sato, Fuka Matsuzaki, Jun-ichiro Takahashi

+ [Multilingual Performance Biases of Large Language Models in Education](https://arxiv.org//abs/2504.17720)

	Vansh Gupta, Sankalan Pal Chowdhury, Vilém Zouhar, Donya Rooein, Mrinmaya Sachan

+ [Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning](https://arxiv.org//abs/2504.17192)

	Minju Seo, Jinheon Baek, Seongyun Lee, Sung Ju Hwang

+ [A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation](https://arxiv.org//abs/2504.17200)

	Yangxinyu Xie, Bowen Jiang, Tanwi Mallick, Joshua David Bergerson, John K. Hutchison, Duane R. Verner, Jordan Branham, M. Ross Alexander, Robert B. Ross, Yan Feng, Leslie-Anne Levy, Weijie Su, Camillo J. Taylor

+ [Does Knowledge Distillation Matter for Large Language Model based Bundle Generation?](https://arxiv.org//abs/2504.17220)

	Kaidong Feng, Zhu Sun, Jie Yang, Hui Fang, Xinghua Qu, Wenyuan Liu

+ [Crisp: Cognitive Restructuring of Negative Thoughts through Multi-turn Supportive Dialogues](https://arxiv.org//abs/2504.17238)

	Jinfeng Zhou, Yuxuan Chen, Jianing Yin, Yongkang Huang, Yihan Shi, Xikun Zhang, Libiao Peng, Rongsheng Zhang, Tangjie Lv, Zhipeng Hu, Hongning Wang, Minlie Huang

+ [CoheMark: A Novel Sentence-Level Watermark for Enhanced Text Quality](https://arxiv.org//abs/2504.17309)

	Junyan Zhang, Shuliang Liu, Aiwei Liu, Yubo Gao, Jungang Li, Xiaojie Gu, Xuming Hu

+ [PatientDx: Merging Large Language Models for Protecting Data-Privacy in Healthcare](https://arxiv.org//abs/2504.17360)

	Jose G. Moreno (IRIT-IRIS), Jesus Lovon (IRIT-IRIS), M'Rick Robin-Charlet (UT3), Christine Damase-Michel, Lynda Tamine (IRIT-IRIS)

+ [Unified Attacks to Large Language Model Watermarks: Spoofing and Scrubbing in Unauthorized Knowledge Distillation](https://arxiv.org//abs/2504.17480)

	Xin Yi, Shunfan Zhengc, Linlin Wanga, Xiaoling Wang, Liang He

+ [When Does Metadata Conditioning (NOT) Work for Language Model Pre-Training? A Study with Context-Free Grammars](https://arxiv.org//abs/2504.17562)

	Rei Higuchi, Ryotaro Kawata, Naoki Nishikawa, Kazusato Oko, Shoichiro Yamaguchi, Sosuke Kobayashi, Seiya Tokui, Kohei Hayashi, Daisuke Okanohara, Taiji Suzuki

+ [DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training](https://arxiv.org//abs/2504.17565)

	Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li

+ [Evaluating Grounded Reasoning by Code-Assisted Large Language Models for Mathematics](https://arxiv.org//abs/2504.17665)

	Zena Al-Khalili, Nick Howell, Dietrich Klakow

+ [Energy Considerations of Large Language Model Inference and Efficiency Optimizations](https://arxiv.org//abs/2504.17674)

	Jared Fernandez, Clara Na, Vashisth Tiwari, Yonatan Bisk, Sasha Luccioni, Emma Strubell

+ [Safety in Large Reasoning Models: A Survey](https://arxiv.org//abs/2504.17704)

	Cheng Wang, Yue Liu, Baolong Li, Duzhen Zhang, Zhongzhi Li, Junfeng Fang

+ [Conversational Assistants to support Heart Failure Patients: comparing a Neurosymbolic Architecture with ChatGPT](https://arxiv.org//abs/2504.17753)

	Anuja Tayal, Devika Salunke, Barbara Di Eugenio, Paula Allen-Meares, Eulalia Puig Abril, Olga Garcia, Carolyn Dickens, Andrew Boyd

+ [The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs](https://arxiv.org//abs/2504.17768)

	Piotr Nawrot, Robert Li, Renjie Huang, Sebastian Ruder, Kelly Marchisio, Edoardo M. Ponti

+ [Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs](https://arxiv.org//abs/2504.17432)

	Tiancheng Gu, Kaicheng Yang, Ziyong Feng, Xingjun Wang, Yanzhao Zhang, Dingkun Long, Yingda Chen, Weidong Cai, Jiankang Deng

+ [Towards Robust LLMs: an Adversarial Robustness Measurement Framework](https://arxiv.org//abs/2504.17723)

	Natan Levy, Adiel Ashrov, Guy Katz

+ [Replay to Remember: Retaining Domain Knowledge in Streaming Language Models](https://arxiv.org//abs/2504.17780)

	Sneh Pillai (University of Massachusetts Dartmouth)

+ [High-Fidelity And Complex Test Data Generation For Real-World SQL Code Generation Services](https://arxiv.org//abs/2504.17203)

	Shivasankari Kannan, Yeounoh Chung, Amita Gondi, Tristan Swadell, Fatma Ozcan

+ [On-Device Qwen2.5: Efficient LLM Inference with Model Compression and Hardware Acceleration](https://arxiv.org//abs/2504.17376)

	Maoyang Xiang, Ramesh Fernando, Bo Wang

+ [L3: DIMM-PIM Integrated Architecture and Coordination for Scalable Long-Context LLM Inference](https://arxiv.org//abs/2504.17584)

	Qingyuan Liu, Liyan Chen, Yanning Yang, Haocheng Wang, Dong Du, Zhigang Mao, Naifeng Jing, Yubin Xia, Haibo Chen

+ [LLM Agent Swarm for Hypothesis-Driven Drug Discovery](https://arxiv.org//abs/2504.17967)

	Kevin Song, Andrew Trotter, Jake Y. Chen

+ [Data-Driven Calibration of Prediction Sets in Large Vision-Language Models Based on Inductive Conformal Prediction](https://arxiv.org//abs/2504.17671)

	Yuanchang Ye, Weiyan Wen

+ [Unsupervised Corpus Poisoning Attacks in Continuous Space for Dense Retrieval](https://arxiv.org//abs/2504.17884)

	Yongkang Li, Panagiotis Eustratiadis, Simon Lupart, Evangelos Kanoulas

+ [Toward a Human-Centered Evaluation Framework for Trustworthy LLM-Powered GUI Agents](https://arxiv.org//abs/2504.17934)

	Chaoran Chen, Zhiping Zhang, Ibrahim Khalilov, Bingcan Guo, Simret A Gebreegziabher, Yanfang Ye, Ziang Xiao, Yaxing Yao, Tianshi Li, Toby Jia-Jun Li

+ [Collaborating Action by Action: A Multi-agent LLM Framework for Embodied Reasoning](https://arxiv.org//abs/2504.17950)

	Isadora White, Kolby Nottingham, Ayush Maniar, Max Robinson, Hansen Lillemark, Mehul Maheshwari, Lianhui Qin, Prithviraj Ammanabrolu

+ [DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training](https://arxiv.org//abs/2504.17565)

	Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li

+ [Training Large Language Models to Reason via EM Policy Gradient](https://arxiv.org//abs/2504.18587)

	Tianbing Xu

+ [BadMoE: Backdooring Mixture-of-Experts LLMs via Optimizing Routing Triggers and Infecting Dormant Experts](https://arxiv.org//abs/2504.18598)

	Qingyue Wang, Qi Pang, Xixun Lin, Shuai Wang, Daoyuan Wu

+ [RAGEN: Understanding Self-Evolution in LLM Agents via Multi-Turn Reinforcement Learning](https://arxiv.org//abs/2504.20073)

	Zihan Wang, Kangrui Wang, Qineng Wang, Pingyue Zhang, Linjie Li, Zhengyuan Yang, Kefan Yu, Minh Nhat Nguyen, Licheng Liu, Eli Gottlieb, Monica Lam, Yiping Lu, Kyunghyun Cho, Jiajun Wu, Li Fei-Fei, Lijuan Wang, Yejin Choi, Manling Li

+ [Tempo: Application-aware LLM Serving with Mixed SLO Requirements](https://arxiv.org//abs/2504.20068)

	Wei Zhang, Zhiyu Wu, Yi Mu, Banruo Liu, Myungjin Lee, Fan Lai

+ [ReCellTy: Domain-specific knowledge graph retrieval-augmented LLMs workflow for single-cell annotation](https://arxiv.org//abs/2505.00017)

	Dezheng Han, Yibin Jia, Ruxiao Chen, Wenjie Han, Shuaishuai Guo, Jianbo Wang

+ [An Empirical Study on Prompt Compression for Large Language Models](https://arxiv.org//abs/2505.00019)

	Zheng Zhang, Jinyi Li, Yihuai Lan, Xiang Wang, Hao Wang

+ [Beyond Public Access in LLM Pre-Training Data](https://arxiv.org//abs/2505.00020)

	Sruly Rosenblat, Tim O'Reilly, Ilan Strauss

+ [Aleph-Alpha-GermanWeb: Improving German-language LLM pre-training with model-based data curation and synthetic data generation](https://arxiv.org//abs/2505.00022)

	Thomas F Burns, Letitia Parcalabescu, Stephan Wäldchen, Michael Barlow, Gregor Ziegltrum, Volker Stampa, Bastian Harren, Björn Deiseroth

+ [Towards a HIPAA Compliant Agentic AI System in Healthcare](https://arxiv.org//abs/2504.17669)

	Subash Neupane, Sudip Mittal, Shahram Rahimi

+ [Towards Machine-Generated Code for the Resolution of User Intentions](https://arxiv.org//abs/2504.17531)

	Justus Flerlage, Ilja Behnke, Odej Kao

# 2025-04-23
+ [Steering the CensorShip: Uncovering Representation Vectors for LLM "Thought" Control](https://arxiv.org//abs/2504.17130)

	Hannah Cyberey, David Evans

+ [Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification](https://arxiv.org//abs/2504.17017)

	Balaji Rao, William Eiers, Carlo Lipizzi

+ [Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments](https://arxiv.org//abs/2504.17087)

	Yuran Li, Jama Hussein Mohamud, Chongren Sun, Di Wu, Benoit Boulet

+ [Backslash: Rate Constrained Optimized Training of Large Language Models](https://arxiv.org//abs/2504.16968)

	Jun Wu, Jiangtao Wen, Yuxing Han

+ [(Im)possibility of Automated Hallucination Detection in Large Language Models](https://arxiv.org//abs/2504.17004)

	Amin Karbasi, Omar Montasser, John Sous, Grigoris Velegkas

+ [Robo-Troj: Attacking LLM-based Task Planners](https://arxiv.org//abs/2504.17070)

	Mohaiminul Al Nahian, Zainab Altaweel, David Reitano, Sabbir Ahmed, Saumitra Lohokare, Shiqi Zhang, Adnan Siraj Rakin

+ [MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation](https://arxiv.org//abs/2504.17137)

	Chanhee Park, Hyeonseok Moon, Chanjun Park, Heuiseok Lim

+ [Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark](https://arxiv.org//abs/2504.16427)

	Hanlei Zhang, Zhuohang Li, Yeshuang Zhu, Hua Xu, Peiwu Wang, Haige Zhu, Jie Zhou, Jinchao Zhang

+ [Optimizing LLMs for Italian: Reducing Token Fertility and Enhancing Efficiency Through Vocabulary Adaptation](https://arxiv.org//abs/2504.17025)

	Luca Moroni, Giovanni Puccetti, Pere-Lluis Huguet Cabot, Andrei Stefan Bejgu, Edoardo Barba, Alessio Miaschi, Felice Dell'Orletta, Andrea Esuli, Roberto Navigli

+ [Do Words Reflect Beliefs? Evaluating Belief Depth in Large Language Models](https://arxiv.org//abs/2504.17052)

	Shariar Kabir, Kevin Esterling, Yue Dong

+ [Agree to Disagree? A Meta-Evaluation of LLM Misgendering](https://arxiv.org//abs/2504.17075)

	Arjun Subramonian, Vagrant Gautam, Preethi Seshadri, Dietrich Klakow, Kai-Wei Chang, Yizhou Sun

+ [How Individual Traits and Language Styles Shape Preferences In Open-ended User-LLM Interaction: A Preliminary Study](https://arxiv.org//abs/2504.17083)

	Rendi Chevi, Kentaro Inui, Thamar Solorio, Alham Fikri Aji

+ [Co-CoT: A Prompt-Based Framework for Collaborative Chain-of-Thought Reasoning](https://arxiv.org//abs/2504.17091)

	Seunghyun Yoo

+ [Steering the CensorShip: Uncovering Representation Vectors for LLM "Thought" Control](https://arxiv.org//abs/2504.17130)

	Hannah Cyberey, David Evans

+ [MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation](https://arxiv.org//abs/2504.17137)

	Chanhee Park, Hyeonseok Moon, Chanjun Park, Heuiseok Lim

+ [(Im)possibility of Automated Hallucination Detection in Large Language Models](https://arxiv.org//abs/2504.17004)

	Amin Karbasi, Omar Montasser, John Sous, Grigoris Velegkas

+ [Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark](https://arxiv.org//abs/2504.16427)

	Hanlei Zhang, Zhuohang Li, Yeshuang Zhu, Hua Xu, Peiwu Wang, Haige Zhu, Jie Zhou, Jinchao Zhang

+ [Backslash: Rate Constrained Optimized Training of Large Language Models](https://arxiv.org//abs/2504.16968)

	Jun Wu, Jiangtao Wen, Yuxing Han

+ [Safety Pretraining: Toward the Next Generation of Safe AI](https://arxiv.org//abs/2504.16980)

	Pratyush Maini, Sachin Goyal, Dylan Sam, Alex Robey, Yash Savani, Yiding Jiang, Andy Zou, Zacharcy C. Lipton, J. Zico Kolter

+ [Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification](https://arxiv.org//abs/2504.17017)

	Balaji Rao, William Eiers, Carlo Lipizzi

+ [Exploring How LLMs Capture and Represent Domain-Specific Knowledge](https://arxiv.org//abs/2504.16871)

	Mirian Hipolito Garcia, Camille Couturier, Daniel Madrigal Diaz, Ankur Mallick, Anastasios Kyrillidis, Robert Sim, Victor Ruhle, Saravan Rajmohan


+ [Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments](https://arxiv.org//abs/2504.17087)

	Yuran Li, Jama Hussein Mohamud, Chongren Sun, Di Wu, Benoit Boulet

+ [Backslash: Rate Constrained Optimized Training of Large Language Models](https://arxiv.org//abs/2504.16968)

	Jun Wu, Jiangtao Wen, Yuxing Han

+ [(Im)possibility of Automated Hallucination Detection in Large Language Models](https://arxiv.org//abs/2504.17004)

	Amin Karbasi, Omar Montasser, John Sous, Grigoris Velegkas

+ [Robo-Troj: Attacking LLM-based Task Planners](https://arxiv.org//abs/2504.17070)

	Mohaiminul Al Nahian, Zainab Altaweel, David Reitano, Sabbir Ahmed, Saumitra Lohokare, Shiqi Zhang, Adnan Siraj Rakin

+ [MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation](https://arxiv.org//abs/2504.17137)

	Chanhee Park, Hyeonseok Moon, Chanjun Park, Heuiseok Lim

+ [Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark](https://arxiv.org//abs/2504.16427)

	Hanlei Zhang, Zhuohang Li, Yeshuang Zhu, Hua Xu, Peiwu Wang, Haige Zhu, Jie Zhou, Jinchao Zhang

+ [Optimizing LLMs for Italian: Reducing Token Fertility and Enhancing Efficiency Through Vocabulary Adaptation](https://arxiv.org//abs/2504.17025)

	Luca Moroni, Giovanni Puccetti, Pere-Lluis Huguet Cabot, Andrei Stefan Bejgu, Edoardo Barba, Alessio Miaschi, Felice Dell'Orletta, Andrea Esuli, Roberto Navigli

+ [Do Words Reflect Beliefs? Evaluating Belief Depth in Large Language Models](https://arxiv.org//abs/2504.17052)

	Shariar Kabir, Kevin Esterling, Yue Dong

+ [Agree to Disagree? A Meta-Evaluation of LLM Misgendering](https://arxiv.org//abs/2504.17075)

	Arjun Subramonian, Vagrant Gautam, Preethi Seshadri, Dietrich Klakow, Kai-Wei Chang, Yizhou Sun

+ [How Individual Traits and Language Styles Shape Preferences In Open-ended User-LLM Interaction: A Preliminary Study](https://arxiv.org//abs/2504.17083)

	Rendi Chevi, Kentaro Inui, Thamar Solorio, Alham Fikri Aji

+ [Co-CoT: A Prompt-Based Framework for Collaborative Chain-of-Thought Reasoning](https://arxiv.org//abs/2504.17091)

	Seunghyun Yoo

+ [Steering the CensorShip: Uncovering Representation Vectors for LLM "Thought" Control](https://arxiv.org//abs/2504.17130)

	Hannah Cyberey, David Evans

+ [Safety Pretraining: Toward the Next Generation of Safe AI](https://arxiv.org//abs/2504.16980)

	Pratyush Maini, Sachin Goyal, Dylan Sam, Alex Robey, Yash Savani, Yiding Jiang, Andy Zou, Zacharcy C. Lipton, J. Zico Kolter

+ [Exploring How LLMs Capture and Represent Domain-Specific Knowledge](https://arxiv.org//abs/2504.16871)

	Mirian Hipolito Garcia, Camille Couturier, Daniel Madrigal Diaz, Ankur Mallick, Anastasios Kyrillidis, Robert Sim, Victor Ruhle, Saravan Rajmohan

+ [EduBot -- Can LLMs Solve Personalized Learning and Programming Assignments?](https://arxiv.org//abs/2504.17824)

	Yibin Wang, Jiaxi Xie, Lakshminarayanan Subramanian

+ [BackSlash: Rate Constrained Optimized Training of Large Language Models](https://arxiv.org//abs/2504.16968)

	Jun Wu, Jiangtao Wen, Yuxing Han

+ [PARD: Accelerating LLM Inference with Low-Cost PARallel Draft Model Adaptation](https://arxiv.org//abs/2504.18583)

	Zihao An, Huajun Bai, Ziqiong Liu, Dong Li, Emad Barsoum

+ [Param$Δ$ for Direct Weight Mixing: Post-Train Large Language Model at Zero Cost](https://arxiv.org//abs/2504.21023)

	Sheng Cao, Mingrui Wu, Karthik Prasad, Yuandong Tian, Zechun Liu

+ [WebEvolver: Enhancing Web Agent Self-Improvement with Coevolving World Model](https://arxiv.org//abs/2504.21024)

	Tianqing Fang, Hongming Zhang, Zhisong Zhang, Kaixin Ma, Wenhao Yu, Haitao Mi, Dong Yu

+ [Sparks of Tabular Reasoning via Text2SQL Reinforcement Learning](https://arxiv.org//abs/2505.00016)

	Josefa Lia Stoisser, Marc Boubnovski Martell, Julien Fauqueur

+ [Building A Secure Agentic AI Application Leveraging A2A Protocol](https://arxiv.org//abs/2504.16902)

	Idan Habler, Ken Huang, Vineeth Sai Narajala, Prashant Kulkarni

+ [ConTextual: Improving Clinical Text Summarization in LLMs with Context-preserving Token Filtering and Knowledge Graphs](https://arxiv.org//abs/2504.16394)

	Fahmida Liza Piya, Rahmatollah Beheshti

+ [LLMSR@XLLM25: Less is More: Enhancing Structured Multi-Agent Reasoning via Quality-Guided Distillation](https://arxiv.org//abs/2504.16408)

	Jiahao Yuan, Xingzhe Sun, Xing Yu, Jingwen Wang, Dehui Du, Zhiqing Cui, Zixiang Di

+ [Harden and Catch for Just-in-Time Assured LLM-Based Software Testing: Open Research Challenges](https://arxiv.org//abs/2504.16472)

	Mark Harman, Peter O'Hearn, Shubho Sengupta

+ [Process Reward Models That Think](https://arxiv.org//abs/2504.16828)

	Muhammad Khalifa, Rishabh Agarwal, Lajanugen Logeswaran, Jaekyeom Kim, Hao Peng, Moontae Lee, Honglak Lee, Lu Wang

+ [OptimAI: Optimization from Natural Language Using LLM-Powered AI Agents](https://arxiv.org//abs/2504.16918)

	Raghav Thind, Youran Sun, Ling Liang, Haizhao Yang

# 2025-04-22
+ [Impact of Noise on LLM-Models Performance in Abstraction and Reasoning Corpus (ARC) Tasks with Model Temperature Considerations](https://arxiv.org//abs/2504.15903)

	Nikhil Khandalkar, Pavan Yadav, Krishna Shinde, Lokesh B. Ramegowda, Rajarshi Das


+ [CAPO: Cost-Aware Prompt Optimization](https://arxiv.org//abs/2504.16005)

	Tom Zehle, Moritz Schlager, Timo Heiß, Matthias Feurer

+ [Pre-DPO: Improving Data Utilization in Direct Preference Optimization Using a Guiding Reference Model](https://arxiv.org//abs/2504.15843)

	Junshu Pan, Wei Shen, Shulin Huang, Qiji Zhou, Yue Zhang

+ [BELL: Benchmarking the Explainability of Large Language Models](https://arxiv.org//abs/2504.18572)

	Syed Quiser Ahmed, Bharathi Vokkaliga Ganesh, Jagadish Babu P, Karthick Selvaraj, ReddySiva Naga Parvathi Devi, Sravya Kappala

+ [Large Language Model Empowered Privacy-Protected Framework for PHI Annotation in Clinical Notes](https://arxiv.org//abs/2504.18569)

	Guanchen Wu, Linzhi Zheng, Han Xie, Zhen Xiang, Jiaying Lu, Darren Liu, Delgersuren Bold, Bo Li, Xiao Hu, Carl Yang

+ [Understanding the Skill Gap in Recurrent Language Models: The Role of the Gather-and-Aggregate Mechanism](https://arxiv.org//abs/2504.18574)

	Aviv Bick, Eric Xing, Albert Gu

+ [WASP: Benchmarking Web Agent Security Against Prompt Injection Attacks](https://arxiv.org//abs/2504.18575)

	Ivan Evtimov, Arman Zharmagambetov, Aaron Grattafiori, Chuan Guo, Kamalika Chaudhuri

+ [Kill two birds with one stone: generalized and robust AI-generated text detection via dynamic perturbations](https://arxiv.org//abs/2504.21019)

	Yinghan Zhou, Juan Wen, Wanli Peng, Yiming Xue, Ziwei Zhang, Zhengxian Wu

+ [Context-Enhanced Contrastive Search for Improved LLM Text Generation](https://arxiv.org//abs/2504.21020)

	Jaydip Sen, Rohit Pandey, Hetvi Waghela

+ [A Framework for Testing and Adapting REST APIs as LLM Tools](https://arxiv.org//abs/2504.15546)

	Jayachandu Bandlamudi, Ritwik Chaudhuri, Neelamadhav Gantayat, Kushal Mukherjee, Prerna Agarwal, Renuka Sindhgatta, Sameep Mehta

+ [Advancing Embodied Agent Security: From Safety Benchmarks to Input Moderation](https://arxiv.org//abs/2504.15699)

	Ning Wang, Zihan Yan, Weiyang Li, Chuan Ma, He Chen, Tao Xiang

+ [LLMs meet Federated Learning for Scalable and Secure IoT Management](https://arxiv.org//abs/2504.16032)

	Yazan Otoum, Arghavan Asad, Amiya Nayak

+ [A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment](https://arxiv.org//abs/2504.15585)

	Kun Wang, Guibin Zhang, Zhenhong Zhou, Jiahao Wu, Miao Yu, Shiqian Zhao, Chenlong Yin, Jinhu Fu, Yibo Yan, Hanjun Luo, Liang Lin, Zhihao Xu, Haolang Lu, Xinye Cao, Xinyun Zhou, Weifei Jin, Fanci Meng, Junyuan Mao, Yu Wang, Hao Wu, Minghe Wang, Fan Zhang, Junfeng Fang, Wenjie Qu, Yue Liu, Chengwei Liu, Yifan Zhang, Qiankun Li, Chongye Guo, Yalan Qin, Zhaoxin Fan, Yi Ding, Donghai Hong, Jiaming Ji, Yingxin Lai, Zitong Yu, Xinfeng Li, Yifan Jiang, Yanhui Li, Xinyu Deng, Junlin Wu, Dongxia Wang, Yihao Huang, Yufei Guo, Jen-tse Huang, Qiufeng Wang, Wenxuan Wang, Dongrui Liu, Yanwei Yue, Wenke Huang, Guancheng Wan, Heng Chang, Tianlin Li, Yi Yu, Chenghao Li, Jiawei Li, Lei Bai, Jie Zhang, Qing Guo, Jingyi Wang, Tianlong Chen, Joey Tianyi Zhou, Xiaojun Jia, Weisong Sun, Cong Wu, Jing Chen, Xuming Hu, Yiming Li, Xiao Wang, Ningyu Zhang, Luu Anh Tuan, Guowen Xu, Jiaheng Zhang, Tianwei Zhang, Xingjun Ma, Jindong Gu, Xiang Wang, Bo An, Jun Sun, Mohit Bansal, Shirui Pan, Lingjuan Lyu, Yuval Elovici, Bhavya Kailkhura, Yaodong Yang, Hongwei Li, Wenyuan Xu, Yizhou Sun, Wei Wang, Qing Li, Ke Tang, Yu-Gang Jiang, Felix Juefei-Xu, Hui Xiong, Xiaofeng Wang, Dacheng Tao, Philip S. Yu, Qingsong Wen, Yang Liu

+ [Dynamic Early Exit in Reasoning Models](https://arxiv.org//abs/2504.15895)

	Chenxu Yang, Qingyi Si, Yongjie Duan, Zheliang Zhu, Chenyu Zhu, Qiaowei Li, Zheng Lin, Li Cao, Weiping Wang

+ [PHYBench: Holistic Evaluation of Physical Perception and Reasoning in Large Language Models](https://arxiv.org//abs/2504.16074)

	Shi Qiu, Shaoyang Guo, Zhuo-Yang Song, Yunbo Sun, Zeyu Cai, Jiashen Wei, Tianyu Luo, Yixuan Yin, Haoxu Zhang, Yi Hu, Chenyang Wang, Chencheng Tang, Haoling Chang, Qi Liu, Ziheng Zhou, Tianyu Zhang, Jingtian Zhang, Zhangyi Liu, Minghao Li, Yuku Zhang, Boxuan Jing, Xianqi Yin, Yutong Ren, Zizhuo Fu, Jiaming Ji, Weike Wang, Xudong Tian, Anqi Lv, Laifu Man, Jianxiang Li, Feiyu Tao, Qihua Sun, Zhou Liang, Yushu Mu, Zhongxuan Li, Jing-Jun Zhang, Shutao Zhang, Xiaotian Li, Xingqi Xia, Jiawei Lin, Zheyu Shen, Jiahang Chen, Qiuhao Xiong, Binran Wang, Fengyuan Wang, Ziyang Ni, Bohan Zhang, Fan Cui, Changkun Shao, Qing-Hong Cao, Ming-xing Luo, Yaodong Yang, Muhan Zhang, Hua Xing Zhu

+ [Grounded in Context: Retrieval-Based Method for Hallucination Detection](https://arxiv.org//abs/2504.15771)

	Assaf Gerner, Netta Madvil, Nadav Barak, Alex Zaikman, Jonatan Liberman, Liron Hamra, Rotem Brazilay, Shay Tsadok, Yaron Friedman, Neal Harow, Noam Bresler, Shir Chorev, Philip Tannor

+ [Instruction-Tuning Data Synthesis from Scratch via Web Reconstruction](https://arxiv.org//abs/2504.15573)

	Yuxin Jiang, Yufei Wang, Chuhan Wu, Xinyi Dai, Yan Xu, Weinan Gan, Yasheng Wang, Xin Jiang, Lifeng Shang, Ruiming Tang, Wei Wang

+ [TTRL: Test-Time Reinforcement Learning](https://arxiv.org//abs/2504.16084)

	Yuxin Zuo, Kaiyan Zhang, Li Sheng, Shang Qu, Ganqu Cui, Xuekai Zhu, Haozhan Li, Yuchen Zhang, Xinwei Long, Ermo Hua, Biqing Qi, Youbang Sun, Zhiyuan Ma, Lifan Yuan, Ning Ding, Bowen Zhou

+ [MMInference: Accelerating Pre-filling for Long-Context VLMs via Modality-Aware Permutation Sparse Attention](https://arxiv.org//abs/2504.16083)

	Yucheng Li, Huiqiang Jiang, Chengruidong Zhang, Qianhui Wu, Xufang Luo, Surin Ahn, Amir H. Abdi, Dongsheng Li, Jianfeng Gao, Yuqing Yang, Lili Qiu

# 2025-04-21
+ [Intrinsic Barriers to Explaining Deep Foundation Models](https://arxiv.org//abs/2504.16948)

	Zhen Tan, Huan Liu

+ [KeyDiff: Key Similarity-Based KV Cache Eviction for Long-Context LLM Inference in Resource-Constrained Environments](https://arxiv.org//abs/2504.15364)

	Junyoung Park, Dalton Jones, Matt J Morse, Raghavv Goel, Mingu Lee, Chris Lott

+ [MARFT: Multi-Agent Reinforcement Fine-Tuning](https://arxiv.org//abs/2504.16129)

	Junwei Liao, Muning Wen, Jun Wang, Weinan Zhang

+ [Efficient Pretraining Length Scaling](https://arxiv.org//abs/2504.14992)

	Bohong Wu, Shen Yan, Sijun Zhang, Jianqiao Lu, Yutao Zeng, Ya Wang, Xun Zhou

+ [MARFT: Multi-Agent Reinforcement Fine-Tuning](https://arxiv.org//abs/2504.16129)

	Junwei Liao, Muning Wen, Jun Wang, Weinan Zhang


+ [DualBreach: Efficient Dual-Jailbreaking via Target-Driven Initialization and Multi-Target Optimization](https://arxiv.org//abs/2504.18564)

	Xinzhe Huang, Kedong Xiu, Tianhang Zheng, Churui Zeng, Wangze Ni, Zhan Qiin, Kui Ren, Chun Chen

+ [RepliBench: Evaluating the autonomous replication capabilities of language model agents](https://arxiv.org//abs/2504.18565)

	Sid Black, Asa Cooper Stickland, Jake Pencharz, Oliver Sourbut, Michael Schmatz, Jay Bailey, Ollie Matthews, Ben Millwood, Alex Remedios, Alan Cooney

+ [Jailbreak Detection in Clinical Training LLMs Using Feature-Based Predictive Models](https://arxiv.org//abs/2505.00010)

	Tri Nguyen, Lohith Srikanth Pentapalli, Magnus Sieverding, Laurah Turner, Seth Overla, Weibing Zheng, Chris Zhou, David Furniss, Danielle Weber, Michael Gharib, Matt Kelleher, Michael Shukis, Cameron Pawlik, Kelly Cohen

+ [Integrating Symbolic Execution into the Fine-Tuning of Code-Generating LLMs](https://arxiv.org//abs/2504.15210)

	Marina Sakharova, Abhinav Anand, Mira Mezini

+ [Splitwiser: Efficient LM inference with constrained resources](https://arxiv.org//abs/2505.03763)

	Asad Aali, Adney Cardoza, Melissa Capo

+ [AlignRAG: Leveraging Critique Learning for Evidence-Sensitive Retrieval-Augmented Reasoning](https://arxiv.org//abs/2504.14858)

	Jiaqi Wei, Hao Zhou, Xiang Zhang, Di Zhang, Zijie Qiu, Wei Wei, Jinzhe Li, Wanli Ouyang, Siqi Sun

+ [A Self-Improving Coding Agent](https://arxiv.org//abs/2504.15228)

	Maxime Robeyns, Martin Szummer, Laurence Aitchison

+ [MARFT: Multi-Agent Reinforcement Fine-Tuning](https://arxiv.org//abs/2504.16129)

	Junwei Liao, Muning Wen, Jun Wang, Weinan Zhang

+ [KeyDiff: Key Similarity-Based KV Cache Eviction for Long-Context LLM Inference in Resource-Constrained Environments](https://arxiv.org//abs/2504.15364)

	Junyoung Park, Dalton Jones, Matthew J Morse, Raghavv Goel, Mingu Lee, Chris Lott

+ [MrGuard: A Multilingual Reasoning Guardrail for Universal LLM Safety](https://arxiv.org//abs/2504.15241)

	Yahan Yang, Soham Dan, Shuo Li, Dan Roth, Insup Lee

+ [Evaluating Judges as Evaluators: The JETTS Benchmark of LLM-as-Judges as Test-Time Scaling Evaluators](https://arxiv.org//abs/2504.15253)

	Yilun Zhou, Austin Xu, Peifeng Wang, Caiming Xiong, Shafiq Joty

+ [Stop Summation: Min-Form Credit Assignment Is All Process Reward Model Needs for Reasoning](https://arxiv.org//abs/2504.15275)

	Jie Cheng, Ruixi Qiao, Lijun Li, Chao Guo, Junle Wang, Gang Xiong, Yisheng Lv, Fei-Yue Wang

# 2025-04-20
+ [UFO2: The Desktop AgentOS](https://arxiv.org//abs/2504.14603)

	Chaoyun Zhang, He Huang, Chiming Ni, Jian Mu, Si Qin, Shilin He, Lu Wang, Fangkai Yang, Pu Zhao, Chao Du, Liqun Li, Yu Kang, Zhao Jiang, Suzhen Zheng, Rujia Wang, Jiaxu Qian, Minghua Ma, Jian-Guang Lou, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang

+ [Towards Optimal Circuit Generation: Multi-Agent Collaboration Meets Collective Intelligence](https://arxiv.org//abs/2504.14625)

	Haiyan Qin, Jiahao Feng, Xiaotong Feng, Wei W. Xing, Wang Kang

+ [FinSage: A Multi-aspect RAG System for Financial Filings Question Answering](https://arxiv.org//abs/2504.14493)

	Xinyu Wang, Jijun Chi, Zhenghan Tai, Tung Sum Thomas Kwok, Muzhi Li, Zhuhong Li, Hailin He, Yuchen Hua, Peng Lu, Suyuchen Wang, Yihong Wu, Jerry Huang, Jingrui Tian, Ling Zhou

+ [Don't Retrieve, Generate: Prompting LLMs for Synthetic Training Data in Dense Retrieval](https://arxiv.org//abs/2504.21015)

	Aarush Sinha

+ [Trans-Zero: Self-Play Incentivizes Large Language Models for Multilingual Translation Without Parallel Data](https://arxiv.org//abs/2504.14669)

	Wei Zou, Sen Yang, Yu Bao, Shujian Huang, Jiajun Chen, Shanbo Cheng

# 2025-04-19
+ [TALES: Text Adventure Learning Environment Suite](https://arxiv.org//abs/2504.14128)

	Christopher Zhang Cui, Xingdi Yuan, Ziang Xiao, Prithviraj Ammanabrolu, Marc-Alexandre Côté



+ [Mind the Language Gap: Automated and Augmented Evaluation of Bias in LLMs for High- and Low-Resource Languages](https://arxiv.org//abs/2504.18560)

	Alessio Buscemi, Cédric Lothritz, Sergio Morales, Marcos Gomez-Vazquez, Robert Clarisó, Jordi Cabot, German Castignani

+ [Improving the Serving Performance of Multi-LoRA Large Language Models via Efficient LoRA and KV Cache Management](https://arxiv.org//abs/2505.03756)

	Hang Zhang, Jiuchen Shi, Yixiao Wang, Quan Chen, Yizhou Shan, Minyi Guo

+ [The Geometry of Self-Verification in a Task-Specific Reasoning Model](https://arxiv.org//abs/2504.14379)

	Andrew Lee, Lihao Sun, Chris Wendler, Fernanda Viégas, Martin Wattenberg

+ [Walk the Talk? Measuring the Faithfulness of Large Language Model Explanations](https://arxiv.org//abs/2504.14150)

	Katie Matton, Robert Osazuwa Ness, John Guttag, Emre Kıcıman

+ [An Empirical Study of LLM Reasoning Ability Under Strict Output Length Constraint](https://arxiv.org//abs/2504.14350)

	Yi Sun, Han Wang, Jiaqiang Li, Jiacheng Liu, Xiangyu Li, Hao Wen, Yizhen Yuan, Huiwen Zheng, Yan Liang, Yuanchun Li, Yunxin Liu

+ [Understanding the Repeat Curse in Large Language Models from a Feature Perspective](https://arxiv.org//abs/2504.14218)

	Junchi Yao, Shu Yang, Jianhua Xu, Lijie Hu, Mengdi Li, Di Wang

# 2025-04-18
+ [SCRAG: Social Computing-Based Retrieval Augmented Generation for Community Response Forecasting in Social Media Environments](https://arxiv.org//abs/2504.16947)

	Dachun Sun, You Lyu, Jinning Li, Yizhuo Chen, Tianshi Wang, Tomoyoshi Kimura, Tarek Abdelzaher

+ [From Large to Super-Tiny: End-to-End Optimization for Cost-Efficient LLMs](https://arxiv.org//abs/2504.13471)

	Jiliang Ni, Jiachen Pu, Zhongyi Yang, Kun Zhou, Hui Wang, Xiaoliang Xiao, Dakui Wang, Xin Li, Jingfeng Luo, Conggang Hu


+ [From Large to Super-Tiny: End-to-End Optimization for Cost-Efficient LLMs](https://arxiv.org//abs/2504.13471)

	Jiliang Ni, Jiachen Pu, Zhongyi Yang, Kun Zhou, Hui Wang, Xiaoliang Xiao, Dakui Wang, Xin Li, Jingfeng Luo, Conggang Hu

+ [Gradual Binary Search and Dimension Expansion : A general method for activation quantization in LLMs](https://arxiv.org//abs/2504.13989)

	Lucas Maisonnave, Cyril Moineau, Olivier Bichler, Fabrice Rastello

+ [Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?](https://arxiv.org//abs/2504.13837)

	Yang Yue, Zhiqi Chen, Rui Lu, Andrew Zhao, Zhaokai Wang, Yang Yue, Shiji Song, Gao Huang

+ [Signatures of human-like processing in Transformer forward passes](https://arxiv.org//abs/2504.14107)

	Jennifer Hu, Michael A. Lepori, Michael Franke

+ [CoT-RAG: Integrating Chain of Thought and Retrieval-Augmented Generation to Enhance Reasoning in Large Language Models](https://arxiv.org//abs/2504.13534)

	Feiyang Li, Peng Fang, Zhan Shi, Arijit Khan, Fang Wang, Dan Feng, Weihao Wang, Xin Zhang, Yongjian Cui

# 2025-04-17
+ [GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning](https://arxiv.org//abs/2504.12597)

	Liangyu Xu, Yingxiu Zhao, Jingyun Wang, Yingyao Wang, Bu Pi, Chen Wang, Mingliang Zhang, Jihao Gu, Xiang Li, Xiaoyong Zhu, Jun Song, Bo Zheng



+ [MCP Guardian: A Security-First Layer for Safeguarding MCP-Based AI System](https://arxiv.org//abs/2504.12757)

	Sonu Kumar, Anubhav Girdhar, Ritesh Patil, Divyansh Tripathi

+ [GraphOmni: A Comprehensive and Extendable Benchmark Framework for Large Language Models on Graph-theoretic Tasks](https://arxiv.org//abs/2504.12764)

	Hao Xu, Xiangru Jian, Xinjian Zhao, Wei Pang, Chao Zhang, Suyuchen Wang, Qixin Zhang, Zhengyuan Dong, Joao Monteiro, Bang Liu, Qiuzhuang Sun, Tianshu Yu

+ [QLLM: Do We Really Need a Mixing Network for Credit Assignment in Multi-Agent Reinforcement Learning?](https://arxiv.org//abs/2504.12961)

	Zhouyang Jiang, Bin Zhang, Airong Wei, Zhiwei Xu

+ [Information Gain-Guided Causal Intervention for Autonomous Debiasing Large Language Models](https://arxiv.org//abs/2504.12898)

	Zhouhao Sun, Xiao Ding, Li Du, Yunpeng Xu, Yixuan Ma, Yang Zhao, Bing Qin, Ting Liu

# 2025-04-16
+ [Activated LoRA: Fine-tuned LLMs for Intrinsics](https://arxiv.org//abs/2504.12397)

	Kristjan Greenewald, Luis Lastras, Thomas Parnell, Vraj Shah, Lucian Popa, Giulio Zizzo, Chulaka Gunasekara, Ambrish Rawat, David Cox

+ [Waking Up an AI: A Quantitative Framework for Prompt-Induced Phase Transition in Large Language Models](https://arxiv.org//abs/2504.21012)

	Makoto Sato

+ [The Devil is in the Prompts: Retrieval-Augmented Prompt Optimization for Text-to-Video Generation](https://arxiv.org//abs/2504.11739)

	Bingjie Gao, Xinyu Gao, Xiaoxue Wu, Yujie Zhou, Yu Qiao, Li Niu, Xinyuan Chen, Yaohui Wang

# 2025-04-15
+ [Looking beyond the next token](https://arxiv.org//abs/2504.11336)

	Abitha Thankaraj, Yiding Jiang, J. Zico Kolter, Yonatan Bisk

+ [Teaching Large Language Models to Reason through Learning and Forgetting](https://arxiv.org//abs/2504.11364)

	Tianwei Ni, Allen Nie, Sapana Chaudhary, Yao Liu, Huzefa Rangwala, Rasool Fakoor

+ [Nemotron-CrossThink: Scaling Self-Learning beyond Math Reasoning](https://arxiv.org//abs/2504.13941)

	Syeda Nahida Akter, Shrimai Prabhumoye, Matvei Novikov, Seungju Han, Ying Lin, Evelina Bakhturina, Eric Nyberg, Yejin Choi, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro


+ [CLASH: Evaluating Language Models on Judging High-Stakes Dilemmas from Multiple Perspectives](https://arxiv.org//abs/2504.10823)

	Ayoung Lee, Ryan Sungmo Kwon, Peter Railton, Lu Wang

# 2025-04-14
+ [Transferable text data distillation by trajectory matching](https://arxiv.org//abs/2504.09818)

	Rong Yao, Hailin Hu, Yifei Fu, Hanting Chen, Wenyi Fang, Fanyi Du, Kai Han, Yunhe Wang

+ [Weight Ensembling Improves Reasoning in Language Models](https://arxiv.org//abs/2504.10478)

	Xingyu Dang, Christina Baek, Kaiyue Wen, Zico Kolter, Aditi Raghunathan

+ [Better Estimation of the KL Divergence Between Language Models](https://arxiv.org//abs/2504.10637)

	Afra Amini, Tim Vieira, Ryan Cotterell

+ [DioR: Adaptive Cognitive Detection and Contextual Retrieval Optimization for Dynamic Retrieval-Augmented Generation](https://arxiv.org//abs/2504.10198)

	Hanghui Guo, Jia Zhu, Shimin Di, Weijie Shi, Zhangze Chen, Jiajie Xu

+ [TAMP: Token-Adaptive Layerwise Pruning in Multimodal Large Language Models](https://arxiv.org//abs/2504.09897)

	Jaewoo Lee, Keyang Xuan, Chanakya Ekbote, Sandeep Polisetty, Yi R. Fung, Paul Pu Liang

+ [S1-Bench: A Simple Benchmark for Evaluating System 1 Thinking Capability of Large Reasoning Models](https://arxiv.org//abs/2504.10368)

	Wenyuan Zhang, Shuaiyi Nie, Xinghua Zhang, Zefeng Zhang, Tingwen Liu

+ [Hallucination Detection in LLMs with Topological Divergence on Attention Graphs](https://arxiv.org//abs/2504.10063)

	Alexandra Bazarova, Aleksandr Yugay, Andrey Shulga, Alina Ermilova, Andrei Volodichev, Konstantin Polev, Julia Belikova, Rauf Parchiev, Dmitry Simakov, Maxim Savchenko, Andrey Savchenko, Serguei Barannikov, Alexey Zaytsev

# 2025-04-13
+ [CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent](https://arxiv.org//abs/2504.13192)

	Liang-bo Ning, Shijie Wang, Wenqi Fan, Qing Li, Xin Xu, Hao Chen, Feiran Huang

+ [EmoAgent: Assessing and Safeguarding Human-AI Interaction for Mental Health Safety](https://arxiv.org//abs/2504.09689)

	Jiahao Qiu, Yinghui He, Xinzhe Juan, Yimin Wang, Yuhan Liu, Zixin Yao, Yue Wu, Xun Jiang, Ling Yang, Mengdi Wang

+ [Mitigating Many-Shot Jailbreaking](https://arxiv.org//abs/2504.09604)

	Christopher M. Ackerman, Nina Panickssery

+ [Quantization Error Propagation: Revisiting Layer-Wise Post-Training Quantization](https://arxiv.org//abs/2504.09629)

	Yamato Arai, Yuma Ichikawa

+ [Understanding LLM Behaviors via Compression: Data Generation, Knowledge Acquisition and Scaling Laws](https://arxiv.org//abs/2504.09597)

	Zhixuan Pan, Shaowen Wang, Jian Li

+ [MLRC-Bench: Can Language Agents Solve Machine Learning Research Challenges?](https://arxiv.org//abs/2504.09702)

	Yunxiang Zhang, Muhammad Khalifa, Shitanshu Bhushan, Grant D Murphy, Lajanugen Logeswaran, Jaekyeom Kim, Moontae Lee, Honglak Lee, Lu Wang

+ [Enhancing Mathematical Reasoning in Large Language Models with Self-Consistency-Based Hallucination Detection](https://arxiv.org//abs/2504.09440)

	MingShan Liu, Shi Bo, Jialing Fang

+ [The Quantum LLM: Modeling Semantic Spaces with Quantum Principles](https://arxiv.org//abs/2504.13202)

	Timo Aukusti Laine

# 2025-04-11
+ [Enterprise-Grade Security for the Model Context Protocol (MCP): Frameworks and Mitigation Strategies](https://arxiv.org//abs/2504.08623)

	Vineeth Sai Narajala, Idan Habler

+ [Large Language Models Could Be Rote Learners](https://arxiv.org//abs/2504.08300)

	Yuyang Xu, Renjun Hu, Haochao Ying, Jian Wu, Xing Shi, Wei Lin

+ [Beyond Self-Reports: Multi-Observer Agents for Personality Assessment in Large Language Models](https://arxiv.org//abs/2504.08399)

	Yin Jou Huang, Rafik Hadfi

+ [Playpen: An Environment for Exploring Learning Through Conversational Interaction](https://arxiv.org//abs/2504.08590)

	Nicola Horst, Davide Mazzaccara, Antonia Schmidt, Michael Sullivan, Filippo Momentè, Luca Franceschetti, Philipp Sadler, Sherzod Hakimov, Alberto Testoni, Raffaella Bernardi, Raquel Fernández, Alexander Koller, Oliver Lemon, David Schlangen, Mario Giulianelli, Alessandro Suglia

# 2025-04-10
+ [Throughput-Optimal Scheduling Algorithms for LLM Inference and AI Agents](https://arxiv.org//abs/2504.07347)

	Yueying Li, Jim Dai, Tianyi Peng


+ [Can Reasoning LLMs Enhance Clinical Document Classification?](https://arxiv.org//abs/2504.08040)

	Akram Mustafa, Usman Naseem, Mostafa Rahimi Azghadi

+ [Seed1.5-Thinking: Advancing Superb Reasoning Models with Reinforcement Learning](https://arxiv.org//abs/2504.13914)

	ByteDance Seed: Jiaze Chen, Tiantian Fan, Xin Liu, Lingjun Liu, Zhiqi Lin, Mingxuan Wang, Chengyi Wang, Xiangpeng Wei, Wenyuan Xu, Yufeng Yuan, Yu Yue, Lin Yan, Qiying Yu, Xiaochen Zuo, Chi Zhang, Ruofei Zhu, Zhecheng An, Zhihao Bai, Yu Bao, Xingyan Bin, Jiangjie Chen, Feng Chen, Hongmin Chen, Riwei Chen, Liangqiang Chen, Zixin Chen, Jinsong Chen, Siyan Chen, Kaiyuan Chen, Zhi Chen, Jin Chen, Jiecao Chen, Jinxin Chi, Weinan Dai, Ning Dai, Jiahui Dai, Shihan Dou, Yantao Du, Zhengyin Du, Jianhui Duan, Chen Dun, Ting-Han Fan, Jiazhan Feng, Junda Feng, Ziyuan Feng, Yuwei Fu, Wenqi Fu, Hanjie Fu, Hao Ge, Hongyi Guo, Mingji Han, Li Han, Wenhao Hao, Xintong Hao, Qianyu He, Jerry He, Feng He, Wen Heng, Zehua Hong, Qi Hou, Liang Hu, Shengding Hu, Nan Hu, Kai Hua, Qi Huang, Ziyue Huang, Hongzhi Huang, Zihao Huang, Ting Huang, Wenhao Huang, Wei Jia, Bin Jia, Xiaoying Jia, Yuhua Jiang, Haobin Jiang, Ziheng Jiang, Kaihua Jiang, Chengquan Jiang, Jianpeng Jiao, Xiaoran Jin, Xing Jin, Xunhao Lai, Zheng Li, Xiang Li, Liyi Li, Hongkai Li, Zheng Li, Shengxian Wan, Ya Wang, Yunshui Li, Chenggang Li, Niuniu Li, Siyu Li, Xi Li, Xiao Li, Aoyan Li, Yuntao Li, Nianning Liang, Xinnian Liang

+ [Towards Combinatorial Interpretability of Neural Computation](https://arxiv.org//abs/2504.08842)

	Micah Adler, Dan Alistarh, Nir Shavit

+ [Understanding Learner-LLM Chatbot Interactions and the Impact of Prompting Guidelines](https://arxiv.org//abs/2504.07840)

	Cansu Koyuturk, Emily Theophilou, Sabrina Patania, Gregor Donabauer, Andrea Martinenghi, Chiara Antico, Alessia Telari, Alessia Testa, Sathya Bursic, Franca Garzotto, Davinia Hernandez-Leo, Udo Kruschwitz, Davide Taibi, Simona Amenta, Martin Ruskov, Dimitri Ognibene

+ [Model Utility Law: Evaluating LLMs beyond Performance through Mechanism Interpretable Metric](https://arxiv.org//abs/2504.07440)

	Yixin Cao, Jiahao Ying, Yaoning Wang, Xipeng Qiu, Xuanjing Huang, Yugang Jiang

+ [SpecReason: Fast and Accurate Inference-Time Compute via Speculative Reasoning](https://arxiv.org//abs/2504.07891)

	Rui Pan, Yinwei Dai, Zhihao Zhang, Gabriele Oliaro, Zhihao Jia, Ravi Netravali

# 2025-04-09
+ [Understanding Users' Security and Privacy Concerns and Attitudes Towards Conversational AI Platforms](https://arxiv.org//abs/2504.06552)

	Mutahar Ali, Arjun Arunasalam, Habiba Farrukh

+ [Thinking Out Loud: Do Reasoning Models Know When They're Right?](https://arxiv.org//abs/2504.06564)

	Qingcheng Zeng, Weihao Xuan, Leyang Cui, Rob Voigt

# 2025-04-08
+ [V-MAGE: A Game Evaluation Framework for Assessing Vision-Centric Capabilities in Multimodal Large Language Models](https://arxiv.org//abs/2504.06148)

	Xiangxi Zheng, Linjie Li, Zhengyuan Yang, Ping Yu, Alex Jinpeng Wang, Rui Yan, Yuan Yao, Lijuan Wang

+ [Leveraging Robust Optimization for LLM Alignment under Distribution Shifts](https://arxiv.org//abs/2504.05831)

	Mingye Zhu, Yi Liu, Zheren Fu, Yongdong Zhang, Zhendong Mao

+ [Right Question is Already Half the Answer: Fully Unsupervised LLM Reasoning Incentivization](https://arxiv.org//abs/2504.05812)

	Qingyang Zhang, Haitao Wu, Changqing Zhang, Peilin Zhao, Yatao Bian

+ [StealthRank: LLM Ranking Manipulation via Stealthy Prompt Optimization](https://arxiv.org//abs/2504.05804)

	Yiming Tang, Yi Fan, Chenxiao Yu, Tiankai Yang, Yue Zhao, Xiyang Hu

+ [Hogwild! Inference: Parallel LLM Generation via Concurrent Attention](https://arxiv.org//abs/2504.06261)

	Gleb Rodionov, Roman Garipov, Alina Shutova, George Yakushev, Erik Schultheis, Vage Egiazarian, Anton Sinitsin, Denis Kuznedelev, Dan Alistarh

# 2025-04-07


+ [A Desideratum for Conversational Agents: Capabilities, Challenges, and Future Directions](https://arxiv.org//abs/2504.16939)

	Emre Can Acikgoz, Cheng Qian, Hongru Wang, Vardhan Dongre, Xiusi Chen, Heng Ji, Dilek Hakkani-Tür, Gokhan Tur

+ [Not All Data Are Unlearned Equally](https://arxiv.org//abs/2504.05058)

	Aravind Krishnan, Siva Reddy, Marius Mosbach


+ [Lightweight and Direct Document Relevance Optimization for Generative Information Retrieval](https://arxiv.org//abs/2504.05181)

	Kidist Amde Mekonnen, Yubao Tang, Maarten de Rijke

+ [CCSK:Cognitive Convection of Self-Knowledge Based Retrieval Augmentation for Large Language Models](https://arxiv.org//abs/2504.10498)

	Jianling Lu, Mingqi Lv, Tieming Chen

+ [LLM-based Automated Grading with Human-in-the-Loop](https://arxiv.org//abs/2504.05239)

	Hang Li, Yucheng Chu, Kaiqi Yang, Yasemin Copur-Gencturk, Jiliang Tang

+ [SEAL: Steerable Reasoning Calibration of Large Language Models for Free](https://arxiv.org//abs/2504.07986)

	Runjin Chen, Zhenyu Zhang, Junyuan Hong, Souvik Kundu, Zhangyang Wang

+ [AccLLM: Accelerating Long-Context LLM Inference Via Algorithm-Hardware Co-Design](https://arxiv.org//abs/2505.03745)

	Yanbiao Liang, Huihong Shi, Haikuo Shao, Zhongfeng Wang

+ [Promoting Security and Trust on Social Networks: Explainable Cyberbullying Detection Using Large Language Models in a Stream-Based Machine Learning Framework](https://arxiv.org//abs/2505.03746)

	Silvia García-Méndez, Francisco De Arriba-Pérez

+ [Beyond Single-Turn: A Survey on Multi-Turn Interactions with Large Language Models](https://arxiv.org//abs/2504.04717)

	Yubo Li, Xiaobin Shen, Xinyu Yao, Xueying Ding, Yidi Miao, Ramayya Krishnan, Rema Padman

+ [Concise Reasoning via Reinforcement Learning](https://arxiv.org//abs/2504.05185)

	Mehdi Fatemi, Banafsheh Rafiee, Mingjie Tang, Kartik Talamadupula

+ [Debate Only When Necessary: Adaptive Multiagent Collaboration for Efficient LLM Reasoning](https://arxiv.org//abs/2504.05047)

	Sugyeong Eo, Hyeonseok Moon, Evelyn Hayoon Zi, Chanjun Park, Heuiseok Lim

# 2025-04-06
+ ["Trust me on this" Explaining Agent Behavior to a Human Terminator](https://arxiv.org//abs/2504.04592)

	Uri Menkes, Assaf Hallak, Ofra Amir

+ [Exploring Generative AI Techniques in Government: A Case Study](https://arxiv.org//abs/2504.10497)

	Sunyi Liu, Mengzhe Geng, Rebecca Hart

# 2025-04-05
+ [Among Us: A Sandbox for Measuring and Detecting Agentic Deception](https://arxiv.org//abs/2504.04072)

	Satvik Golechha, Adrià Garriga-Alonso

+ [FISH-Tuning: Enhancing PEFT Methods with Fisher Information](https://arxiv.org//abs/2504.04050)

	Kang Xue, Ming Dong, Xinhui Tu, Tingting He

+ [Cognitive Debiasing Large Language Models for Decision-Making](https://arxiv.org//abs/2504.04141)

	Yougang Lyu, Shijie Ren, Yue Feng, Zihan Wang, Zhumin Chen, Zhaochun Ren, Maarten de Rijke

# 2025-04-04
+ [Noise Augmented Fine Tuning for Mitigating Hallucinations in Large Language Models](https://arxiv.org//abs/2504.03302)

	Afshin Khadangi, Amir Sartipi, Igor Tchappi, Ramin Bahmani

+ [APIGen-MT: Agentic Pipeline for Multi-Turn Data Generation via Simulated Agent-Human Interplay](https://arxiv.org//abs/2504.03601)

	Akshara Prabhakar, Zuxin Liu, Ming Zhu, Jianguo Zhang, Tulika Awalgaonkar, Shiyu Wang, Zhiwei Liu, Haolin Chen, Thai Hoang, Juan Carlos Niebles, Shelby Heinecke, Weiran Yao, Huan Wang, Silvio Savarese, Caiming Xiong

+ [How Social is It? A Benchmark for LLMs' Capabilities in Multi-user Multi-turn Social Agent Tasks](https://arxiv.org//abs/2505.04628)

	Yusen Wu, Junwu Xiong, Xiaotie Deng

+ [Think When You Need: Self-Adaptive Chain-of-Thought Learning](https://arxiv.org//abs/2504.03234)

	Junjie Yang, Ke Lin, Xing Yu

# 2025-04-03
+ [Cognitive Memory in Large Language Models](https://arxiv.org//abs/2504.02441)

	Lianlei Shan, Shixian Luo, Zezhou Zhu, Yu Yuan, Yong Wu


+ [Multifaceted Evaluation of Audio-Visual Capability for MLLMs: Effectiveness, Efficiency, Generalizability and Robustness](https://arxiv.org//abs/2504.16936)

	Yusheng Zhao, Junyu Luo, Xiao Luo, Weizhi Zhang, Zhiping Xiao, Wei Ju, Philip S. Yu, Ming Zhang



+ [Generative Evaluation of Complex Reasoning in Large Language Models](https://arxiv.org//abs/2504.02810)

	Haowei Lin, Xiangyu Wang, Ruilin Yan, Baizhou Huang, Haotian Ye, Jianhua Zhu, Zihao Wang, James Zou, Jianzhu Ma, Yitao Liang

+ [GPG: A Simple and Strong Reinforcement Learning Baseline for Model Reasoning](https://arxiv.org//abs/2504.02546)

	Xiangxiang Chu, Hailang Huang, Xiao Zhang, Fei Wei, Yong Wang

+ [GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image Generation](https://arxiv.org//abs/2504.02782)

	Zhiyuan Yan, Junyan Ye, Weijia Li, Zilong Huang, Shenghai Yuan, Xiangyang He, Kaiqing Lin, Jun He, Conghui He, Li Yuan

+ [Why do LLMs attend to the first token?](https://arxiv.org//abs/2504.02732)

	Federico Barbero, Álvaro Arroyo, Xiangming Gu, Christos Perivolaropoulos, Michael Bronstein, Petar Veličković, Razvan Pascanu

+ [GPTAQ: Efficient Finetuning-Free Quantization for Asymmetric Calibration](https://arxiv.org//abs/2504.02692)

	Yuhang Li, Ruokai Yin, Donghyun Lee, Shiting Xiao, Priyadarshini Panda

+ [Pel, A Programming Language for Orchestrating AI Agents](https://arxiv.org//abs/2505.13453)

	Behnam Mohammadi

# 2025-04-02
+ [LRAGE: Legal Retrieval Augmented Generation Evaluation Tool](https://arxiv.org//abs/2504.01840)

	Minhu Park, Hongseok Oh, Eunkyung Choi, Wonseok Hwang

+ [TiC-LM: A Web-Scale Benchmark for Time-Continual LLM Pretraining](https://arxiv.org//abs/2504.02107)

	Jeffrey Li, Mohammadreza Armandpour, Iman Mirzadeh, Sachin Mehta, Vaishaal Shankar, Raviteja Vemulapalli, Samy Bengio, Oncel Tuzel, Mehrdad Farajtabar, Hadi Pouransari, Fartash Faghri

+ [An Illusion of Progress? Assessing the Current State of Web Agents](https://arxiv.org//abs/2504.01382)

	Tianci Xue, Weijian Qi, Tianneng Shi, Chan Hee Song, Boyu Gou, Dawn Song, Huan Sun, Yu Su

+ [DeepSeek-R1 Thoughtology: Let's think about LLM Reasoning](https://arxiv.org//abs/2504.07128)

	Sara Vera Marjanović, Arkil Patel, Vaibhav Adlakha, Milad Aghajohari, Parishad BehnamGhader, Mehar Bhatia, Aditi Khandelwal, Austin Kraft, Benno Krojer, Xing Han Lù, Nicholas Meade, Dongchan Shin, Amirhossein Kazemnejad, Gaurav Kamath, Marius Mosbach, Karolina Stańczak, Siva Reddy

+ [Do Theory of Mind Benchmarks Need Explicit Human-like Reasoning in Language Models?](https://arxiv.org//abs/2504.01698)

	Yi-Long Lu, Chunhui Zhang, Jiajun Song, Lifeng Fan, Wei Wang

+ [Scaling Test-Time Inference with Policy-Optimized, Dynamic Retrieval-Augmented Generation via KV Caching and Decoding](https://arxiv.org//abs/2504.01281)

	Sakhinana Sagar Srinivas, Akash Das, Shivam Gupta, Venkataramana Runkana

# 2025-04-01
+ [GraphMaster: Automated Graph Synthesis via LLM Agents in Data-Limited Environments](https://arxiv.org//abs/2504.00711)

	Enjun Du, Xunkai Li, Tian Jin, Zhihan Zhang, Rong-Hua Li, Guoren Wang

+ [Catch Me if You Search: When Contextual Web Search Results Affect the Detection of Hallucinations](https://arxiv.org//abs/2504.01153)

	Mahjabin Nahar, Eun-Ju Lee, Jin Won Park, Dongwon Lee

+ [Do We Truly Need So Many Samples? Multi-LLM Repeated Sampling Efficiently Scales Test-Time Compute](https://arxiv.org//abs/2504.00762)

	Jianhao Chen, Zishuo Xun, Bocheng Zhou, Han Qi, Hangfan Zhang, Qiaosheng Zhang, Yang Chen, Wei Hu, Yuzhong Qu, Wanli Ouyang, Shuyue Hu

+ [AI Hiring with LLMs: A Context-Aware and Explainable Multi-Agent Framework for Resume Screening](https://arxiv.org//abs/2504.02870)

	Frank P.-W. Lo, Jianing Qiu, Zeyu Wang, Haibao Yu, Yeming Chen, Gao Zhang, Benny Lo

# 2025-03-31
+ [Dynamic Parametric Retrieval Augmented Generation for Test-time Knowledge Enhancement](https://arxiv.org//abs/2503.23895)

	Yuqiao Tan, Shizhu He, Huanxuan Liao, Jun Zhao, Kang Liu

+ [A Survey on Test-Time Scaling in Large Language Models: What, How, Where, and How Well?](https://arxiv.org//abs/2503.24235)

	Qiyuan Zhang, Fuyuan Lyu, Zexu Sun, Lei Wang, Weixu Zhang, Wenyue Hua, Haolun Wu, Zhihan Guo, Yufei Wang, Niklas Muennighoff, Irwin King, Xue Liu, Chen Ma

+ [Rec-R1: Bridging Generative Large Language Models and User-Centric Recommendation Systems via Reinforcement Learning](https://arxiv.org//abs/2503.24289)

	Jiacheng Lin, Tian Wang, Kun Qian

+ [Is analogy enough to draw novel adjective-noun inferences?](https://arxiv.org//abs/2503.24293)

	Hayley Ross, Kathryn Davidson, Najoung Kim

+ [Effectively Controlling Reasoning Models through Thinking Intervention](https://arxiv.org//abs/2503.24370)

	Tong Wu, Chong Xiang, Jiachen T. Wang, G. Edward Suh, Prateek Mittal

+ [Enhancing Large Language Models (LLMs) for Telecommunications using Knowledge Graphs and Retrieval-Augmented Generation](https://arxiv.org//abs/2503.24245)

	Dun Yuan, Hao Zhou, Di Wu, Xue Liu, Hao Chen, Yan Xin, Jianzhong (Charlie)Zhang

+ [STI-Bench: Are MLLMs Ready for Precise Spatial-Temporal World Understanding?](https://arxiv.org//abs/2503.23765)

	Yun Li, Yiming Zhang, Tao Lin, XiangRui Liu, Wenxiao Cai, Zheng Liu, Bo Zhao

# 2025-03-30
+ [A Survey of WebAgents: Towards Next-Generation AI Agents for Web Automation with Large Foundation Models](https://arxiv.org//abs/2503.23350)

	Liangbo Ning, Ziran Liang, Zhuohang Jiang, Haohao Qu, Yujuan Ding, Wenqi Fan, Xiao-yong Wei, Shanru Lin, Hui Liu, Philip S. Yu, Qing Li

+ [Mixture of Routers](https://arxiv.org//abs/2503.23362)

	Jia-Chen Zhang, Yu-Jie Xiong, Xi-He Qiu, Chun-Ming Xia, Fei Dai

+ [RARE: Retrieval-Augmented Reasoning Modeling](https://arxiv.org//abs/2503.23513)

	Zhengren Wang, Jiayang Yu, Dongsheng Ma, Zhe Chen, Yu Wang, Zhiyu Li, Feiyu Xiong, Yanfeng Wang, Weinan E, Linpeng Tang, Wentao Zhang

# 2025-03-29
+ [LangVAE and LangSpace: Building and Probing for Language Model VAEs](https://arxiv.org//abs/2505.00004)

	Danilo S. Carvalho, Yingji Zhang, Harriet Unsworth, André Freitas

# 2025-03-28
+ [Probabilistic Uncertain Reward Model: A Natural Generalization of Bradley-Terry Reward Model](https://arxiv.org//abs/2503.22480)

	Wangtao Sun, Xiang Cheng, Xing Yu, Haotian Xu, Zhao Yang, Shizhu He, Jun Zhao, Kang Liu

+ [The Mind in the Machine: A Survey of Incorporating Psychological Theories in LLMs](https://arxiv.org//abs/2505.00003)

	Zizhou Liu, Ziwei Gong, Lin Ai, Zheng Hui, Run Chen, Colin Wayne Leach, Michelle R. Greene, Julia Hirschberg

+ [Why Stop at One Error? Benchmarking LLMs as Data Science Code Debuggers for Multi-Hop and Multi-Bug Errors](https://arxiv.org//abs/2503.22388)

	Zhiyu Yang, Shuo Wang, Yukun Yan, Yang Deng

# 2025-03-27
+ [Shared Global and Local Geometry of Language Model Embeddings](https://arxiv.org//abs/2503.21073)

	Andrew Lee, Melanie Weber, Fernanda Viégas, Martin Wattenberg

+ [A Computational Theory for Efficient Mini Agent Evaluation with Causal Guarantees](https://arxiv.org//abs/2503.21138)

	Hedong Yan

+ [Alleviating LLM-based Generative Retrieval Hallucination in Alipay Search](https://arxiv.org//abs/2503.21098)

	Yedan Shen, Kaixin Wu, Yuechen Ding, Jingyuan Wen, Hong Liu, Mingjie Zhong, Zhouhan Lin, Jia Xu, Linjian Mo

+ [UI-R1: Enhancing Efficient Action Prediction of GUI Agents by Reinforcement Learning](https://arxiv.org//abs/2503.21620)

	Zhengxi Lu, Yuxiang Chai, Yaxuan Guo, Xi Yin, Liang Liu, Hao Wang, Han Xiao, Shuai Ren, Guanjing Xiong, Hongsheng Li

+ [Video-R1: Reinforcing Video Reasoning in MLLMs](https://arxiv.org//abs/2503.21776)

	Kaituo Feng, Kaixiong Gong, Bohao Li, Zonghao Guo, Yibing Wang, Tianshuo Peng, Junfei Wu, Xiaoying Zhang, Benyou Wang, Xiangyu Yue

+ [ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large Reasoning Models with Iterative Retrieval Augmented Generation](https://arxiv.org//abs/2503.21729)

	Zhicheng Lee, Shulin Cao, Jinxin Liu, Jiajie Zhang, Weichuan Liu, Xiaoyin Che, Lei Hou, Juanzi Li

+ [MoQa: Rethinking MoE Quantization with Multi-stage Data-model Distribution Awareness](https://arxiv.org//abs/2503.21135)

	Zihao Zheng, Xiuping Cui, Size Zheng, Maoliang Li, Jiayu Chen, Yun Liang, Xiang Chen

+ [HyperGraphRAG: Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation](https://arxiv.org//abs/2503.21322)

	Haoran Luo, Haihong E, Guanting Chen, Yandan Zheng, Xiaobao Wu, Yikai Guo, Qika Lin, Yu Feng, Zemin Kuang, Meina Song, Yifan Zhu, Luu Anh Tuan

# 2025-03-26
+ [Dynamic Pyramid Network for Efficient Multimodal Large Language Model](https://arxiv.org//abs/2503.20322)

	Hao Ai, Kunyi Wang, Zezhou Wang, Hao Lu, Jin Tian, Yaxin Luo, Peng Xing, Jen-Yuan Huang, Huaxia Li, Gen luo


+ [Clean & Clear: Feasibility of Safe LLM Clinical Guidance](https://arxiv.org//abs/2503.20953)

	Julia Ive, Felix Jozsa, Nick Jackson, Paulina Bondaronek, Ciaran Scott Hill, Richard Dobson

+ [A Multilingual, Culture-First Approach to Addressing Misgendering in LLM Applications](https://arxiv.org//abs/2503.20302)

	Sunayana Sitaram, Adrian de Wynter, Isobel McCrum, Qilong Gu, Si-Qing Chen

+ [Optimizing Case-Based Reasoning System for Functional Test Script Generation with Large Language Models](https://arxiv.org//abs/2503.20576)

	Siyuan Guo, Huiwu Liu, Xiaolong Chen, Yuming Xie, Liang Zhang, Tao Han, Hechang Chen, Yi Chang, Jun Wang

+ [Unlocking Efficient Long-to-Short LLM Reasoning with Model Merging](https://arxiv.org//abs/2503.20641)

	Han Wu, Yuxuan Yao, Shuqi Liu, Zehua Liu, Xiaojin Fu, Xiongwei Han, Xing Li, Hui-Ling Zhen, Tao Zhong, Mingxuan Yuan

# 2025-03-25
+ [CausalRAG: Integrating Causal Graphs into Retrieval-Augmented Generation](https://arxiv.org//abs/2503.19878)

	Nengbo Wang, Xiaotian Han, Jagdip Singh, Jing Ma, Vipin Chaudhary

+ [Rosetta-PL: Propositional Logic as a Benchmark for Large Language Model Reasoning](https://arxiv.org//abs/2505.00001)

	Shaun Baek, Shaun Esua-Mensah, Cyrus Tsui, Sejan Vigneswaralingam, Abdullah Alali, Michael Lu, Vasu Sharma, Kevin Zhu

+ [OAEI-LLM-T: A TBox Benchmark Dataset for Understanding Large Language Model Hallucinations in Ontology Matching](https://arxiv.org//abs/2503.21813)

	Zhangcheng Qiang

+ [Universal Cross-Tokenizer Distillation via Approximate Likelihood Matching](https://arxiv.org//abs/2503.20083)

	Benjamin Minixhofer, Ivan Vulić, Edoardo Maria Ponti

# 2025-03-24
+ [SimpleRL-Zoo: Investigating and Taming Zero Reinforcement Learning for Open Base Models in the Wild](https://arxiv.org//abs/2503.18892)

	Weihao Zeng, Yuzhen Huang, Qian Liu, Wei Liu, Keqing He, Zejun Ma, Junxian He

+ [Oaken: Fast and Efficient LLM Serving with Online-Offline Hybrid KV Cache Quantization](https://arxiv.org//abs/2503.18599)

	Minsu Kim, Seongmin Hong, RyeoWook Ko, Soongyu Choi, Hunjong Lee, Junsoo Kim, Joo-Young Kim, Jongse Park

# 2025-03-23
+ [HAIR: Hardness-Aware Inverse Reinforcement Learning with Introspective Reasoning for LLM Alignment](https://arxiv.org//abs/2503.18991)

	Ruoxi Cheng, Haoxuan Ma, Weixin Wang

+ [Adaptive Rank Allocation: Speeding Up Modern Transformers with RaNA Adapters](https://arxiv.org//abs/2503.18216)

	Roberto Garcia, Jerry Liu, Daniel Sorvisto, Sabri Eyuboglu

+ [DeLoRA: Decoupling Angles and Strength in Low-rank Adaptation](https://arxiv.org//abs/2503.18225)

	Massimo Bini, Leander Girrbach, Zeynep Akata

+ [MathAgent: Leveraging a Mixture-of-Math-Agent Framework for Real-World Multimodal Mathematical Error Detection](https://arxiv.org//abs/2503.18132)

	Yibo Yan, Shen Wang, Jiahao Huo, Philip S. Yu, Xuming Hu, Qingsong Wen

+ [MedPlan:A Two-Stage RAG-Based System for Personalized Medical Plan Generation](https://arxiv.org//abs/2503.17900)

	Hsin-Ling Hsu, Cong-Tinh Dao, Luning Wang, Zitao Shuai, Thao Nguyen Minh Phan, Jun-En Ding, Chun-Chieh Liao, Pengfei Hu, Xiaoxue Han, Chih-Ho Hsu, Dongsheng Luo, Wen-Chih Peng, Feng Liu, Fang-Ming Hung, Chenwei Wu

# 2025-03-22
+ [Evaluating Clinical Competencies of Large Language Models with a General Practice Benchmark](https://arxiv.org//abs/2503.17599)

	Zheqing Li, Yiying Yang, Jiping Lang, Wenhao Jiang, Yuhang Zhao, Shuang Li, Dingqian Wang, Zhu Lin, Xuanna Li, Yuze Tang, Jiexian Qiu, Xiaolin Lu, Hongji Yu, Shuang Chen, Yuhua Bi, Xiaofei Zeng, Yixian Chen, Junrong Chen, Lin Yao

+ [Safe RLHF-V: Safe Reinforcement Learning from Multi-modal Human Feedback](https://arxiv.org//abs/2503.17682)

	Jiaming Ji, Xinyu Chen, Rui Pan, Conghui Zhang, Han Zhu, Jiahao Li, Donghai Hong, Boyuan Chen, Jiayi Zhou, Kaile Wang, Juntao Dai, Chi-Min Chan, Yida Tang, Sirui Han, Yike Guo, Yaodong Yang

# 2025-03-21
+ [A Survey on Personalized Alignment -- The Missing Piece for Large Language Models in Real-World Applications](https://arxiv.org//abs/2503.17003)

	Jian Guan, Junfei Wu, Jia-Nan Li, Chuanqi Cheng, Wei Wu

+ [ConvoGen: Enhancing Conversational AI with Synthetic Data: A Multi-Agent Approach](https://arxiv.org//abs/2503.17460)

	Reem Gody, Mahmoud Goudy, Ahmed Y. Tawfik

+ [MedAgent-Pro: Towards Evidence-based Multi-modal Medical Diagnosis via Reasoning Agentic Workflow](https://arxiv.org//abs/2503.18968)

	Ziyue Wang, Junde Wu, Linghan Cai, Chang Han Low, Xihong Yang, Qiaxuan Li, Yueming Jin

# 2025-03-20
+ [Detecting LLM-Generated Peer Reviews](https://arxiv.org//abs/2503.15772)

	Vishisht Rao, Aounon Kumar, Himabindu Lakkaraju, Nihar B. Shah

+ [Adaptive Group Policy Optimization: Towards Stable Training and Token-Efficient Reasoning](https://arxiv.org//abs/2503.15952)

	Chen Li, Nazhou Liu, Kai Yang

+ [Through the LLM Looking Glass: A Socratic Probing of Donkeys, Elephants, and Markets](https://arxiv.org//abs/2503.16674)

	Molly Kennedy, Ayyoob Imani, Timo Spinde, Hinrich Schütze

# 2025-03-19
+ [Benchmarking Open-Source Large Language Models on Healthcare Text Classification Tasks](https://arxiv.org//abs/2503.15169)

	Yuting Guo, Abeed Sarker

+ [Task-Specific Data Selection for Instruction Tuning via Monosemantic Neuronal Activations](https://arxiv.org//abs/2503.15573)

	Da Ma, Gonghu Shang, Zhi Chen, Libo Qin, Yijie Luo, Lei Pan, Shuai Fan, Lu Chen, Kai Yu

+ [From 1,000,000 Users to Every User: Scaling Up Personalized Preference for User-level Alignment](https://arxiv.org//abs/2503.15463)

	Jia-Nan Li, Jian Guan, Songhao Wu, Wei Wu, Rui Yan

# 2025-03-18
+ [JuDGE: Benchmarking Judgment Document Generation for Chinese Legal System](https://arxiv.org//abs/2503.14258)

	Weihang Su, Baoqing Yue, Qingyao Ai, Yiran Hu, Jiaqi Li, Changyue Wang, Kaiyuan Zhang, Yueyue Wu, Yiqun Liu

+ [Predicting Human Choice Between Textually Described Lotteries](https://arxiv.org//abs/2503.14004)

	Eyal Marantz, Ori Plonsky

+ [Safety Evaluation and Enhancement of DeepSeek Models in Chinese Contexts](https://arxiv.org//abs/2503.16529)

	Wenjing Zhang, Xuejiao Lei, Zhaoxiang Liu, Limin Han, Jiaojiao Zhao, Junting Guo, Zhenhong Long, Shu Yang, Meijuan An, Beibei Huang, Rongjia Du, Ning Wang, Kai Wang, Shiguo Lian

+ [Beyond Single Pass, Looping Through Time: KG-IRAG with Iterative Knowledge Retrieval](https://arxiv.org//abs/2503.14234)

	Ruiyi Yang, Hao Xue, Imran Razzak, Hakim Hacid, Flora D. Salim

+ [LED: LLM Enhanced Open-Vocabulary Object Detection without Human Curated Data Generation](https://arxiv.org//abs/2503.13794)

	Yang Zhou, Shiyu Zhao, Yuxiao Chen, Zhenting Wang, Can Jin, Dimitris N. Metaxas

+ [DAPO: An Open-Source LLM Reinforcement Learning System at Scale](https://arxiv.org//abs/2503.14476)

	Qiying Yu, Zheng Zhang, Ruofei Zhu, Yufeng Yuan, Xiaochen Zuo, Yu Yue, Weinan Dai, Tiantian Fan, Gaohong Liu, Lingjun Liu, Xin Liu, Haibin Lin, Zhiqi Lin, Bole Ma, Guangming Sheng, Yuxuan Tong, Chi Zhang, Mofan Zhang, Wang Zhang, Hang Zhu, Jinhua Zhu, Jiaze Chen, Jiangjie Chen, Chengyi Wang, Hongli Yu, Yuxuan Song, Xiangpeng Wei, Hao Zhou, Jingjing Liu, Wei-Ying Ma, Ya-Qin Zhang, Lin Yan, Mu Qiao, Yonghui Wu, Mingxuan Wang

+ [Uncertainty Distillation: Teaching Language Models to Express Semantic Confidence](https://arxiv.org//abs/2503.14749)

	Sophia Hager, David Mueller, Kevin Duh, Nicholas Andrews

+ [Inferring Events from Time Series using Language Models](https://arxiv.org//abs/2503.14190)

	Mingtian Tan, Mike A. Merrill, Zack Gottesman, Tim Althoff, David Evans, Tom Hartvigsen

+ [Robust Weight Imprinting: Insights from Neural Collapse and Proxy-Based Aggregation](https://arxiv.org//abs/2503.14572)

	Justus Westerhoff, Golzar Atefi, Mario Koddenbrock, Alexei Figueroa, Alexander Löser, Erik Rodner, Felix A. Gers

# 2025-03-17
+ [Atyaephyra at SemEval-2025 Task 4: Low-Rank Negative Preference Optimization](https://arxiv.org//abs/2503.13690)

	Jan Bronec (1), Jindřich Helcl (1) ((1) Charles University, Faculty of Mathematics and Physics, Institute of Formal and Applied Linguistics)

+ [KVShare: An LLM Service System with Efficient and Effective Multi-Tenant KV Cache Reuse](https://arxiv.org//abs/2503.16525)

	Huan Yang, Renji Zhang, Mingzhe Huang, Weijun Wang, Yin Tang, Yuanchun Li, Yunxin Liu, Deyu Zhang

+ [HICD: Hallucination-Inducing via Attention Dispersion for Contrastive Decoding to Mitigate Hallucinations in Large Language Models](https://arxiv.org//abs/2503.12908)

	Xinyan Jiang, Hang Ye, Yongxin Zhu, Xiaoying Zheng, Zikang Chen, Jun Gong

# 2025-03-16
+ [Towards Hierarchical Multi-Step Reward Models for Enhanced Reasoning in Large Language Models](https://arxiv.org//abs/2503.13551)

	Teng Wang, Zhangyi Jiang, Zhenqi He, Shenyang Tong, Wenhan Yang, Yanan Zheng, Zeyu Li, Zifan He, Hailei Gong

+ [Being-0: A Humanoid Robotic Agent with Vision-Language Models and Modular Skills](https://arxiv.org//abs/2503.12533)

	Haoqi Yuan, Yu Bai, Yuhui Fu, Bohan Zhou, Yicheng Feng, Xinrun Xu, Yi Zhan, Börje F. Karlsson, Zongqing Lu

# 2025-03-14
+ [CURIE: Evaluating LLMs On Multitask Scientific Long Context Understanding and Reasoning](https://arxiv.org//abs/2503.13517)

	Hao Cui, Zahra Shamsi, Gowoon Cheon, Xuejian Ma, Shutong Li, Maria Tikhanovskaya, Peter Norgaard, Nayantara Mudur, Martyna Plomecka, Paul Raccuglia, Yasaman Bahri, Victor V. Albert, Pranesh Srinivasan, Haining Pan, Philippe Faist, Brian Rohr, Ekin Dogus Cubuk, Muratahan Aykol, Amil Merchant, Michael J. Statt, Dan Morris, Drew Purves, Elise Kleeman, Ruth Alcantara, Matthew Abraham, Muqthar Mohammad, Ean Phing VanLee, Chenfei Jiang, Elizabeth Dorfman, Eun-Ah Kim, Michael P Brenner, Viren Jain, Sameera Ponda, Subhashini Venugopalan

+ [Implicit Bias-Like Patterns in Reasoning Models](https://arxiv.org//abs/2503.11572)

	Messi H.J. Lee, Calvin K. Lai

+ [D3: Diversity, Difficulty, and Dependability-Aware Data Selection for Sample-Efficient LLM Instruction Tuning](https://arxiv.org//abs/2503.11441)

	Jia Zhang, Chen-Xi Zhang, Yao Liu, Yi-Xuan Jin, Xiao-Wen Yang, Bo Zheng, Yi Liu, Lan-Zhe Guo

+ [MUSS: Multilevel Subset Selection for Relevance and Diversity](https://arxiv.org//abs/2503.11126)

	Vu Nguyen, Andrey Kan

+ [ASMA-Tune: Unlocking LLMs' Assembly Code Comprehension via Structural-Semantic Instruction Tuning](https://arxiv.org//abs/2503.11617)

	Xinyi Wang, Jiashui Wang, Jinbo Su, Ke Wang, Peng Chen, Yanming Liu, Long Liu, Xiang Li, Yangdong Wang, Qiyuan Chen, Rongze Chen, Chunfu Jia

# 2025-03-13
+ [HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks](https://arxiv.org//abs/2503.10894)

	Jiuding Sun, Jing Huang, Sidharth Baskaran, Karel D'Oosterlinck, Christopher Potts, Michael Sklar, Atticus Geiger


+ [HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks](https://arxiv.org//abs/2503.10894)

	Jiuding Sun, Jing Huang, Sidharth Baskaran, Karel D'Oosterlinck, Christopher Potts, Michael Sklar, Atticus Geiger

+ [How Do Multimodal Large Language Models Handle Complex Multimodal Reasoning? Placing Them in An Extensible Escape Game](https://arxiv.org//abs/2503.10042)

	Ziyue Wang, Yurui Dong, Fuwen Luo, Minyuan Ruan, Zhili Cheng, Chi Chen, Peng Li, Yang Liu

+ [Collaborative Speculative Inference for Efficient LLM Inference Serving](https://arxiv.org//abs/2503.10325)

	Luyao Gao, Jianchun Liu, Hongli Xu, Xichong Zhang, Yunming Liao, Liusheng Huang

+ [Evaluating Mathematical Reasoning Across Large Language Models: A Fine-Grained Approach](https://arxiv.org//abs/2503.10573)

	Afrar Jahin, Arif Hassan Zidan, Wei Zhang, Yu Bao, Tianming Liu

+ [Language Models, Graph Searching, and Supervision Adulteration: When More Supervision is Less and How to Make More More](https://arxiv.org//abs/2503.10542)

	Arvid Frydenlund

+ [Scalable Evaluation of Online Facilitation Strategies via Synthetic Simulation of Discussions](https://arxiv.org//abs/2503.16505)

	Dimitris Tsirmpas, Ion Androutsopoulos, John Pavlopoulos

# 2025-03-12
+ [LocAgent: Graph-Guided LLM Agents for Code Localization](https://arxiv.org//abs/2503.09089)

	Zhaoling Chen, Xiangru Tang, Gangda Deng, Fang Wu, Jialong Wu, Zhiwei Jiang, Viktor Prasanna, Arman Cohan, Xingyao Wang

+ [Privacy-Preserved Automated Scoring using Federated Learning for Educational Research](https://arxiv.org//abs/2503.11711)

	Ehsan Latif, Xiaoming Zhai

+ [I Predict Therefore I Am: Is Next Token Prediction Enough to Learn Human-Interpretable Concepts from Data?](https://arxiv.org//abs/2503.08980)

	Yuhang Liu, Dong Gong, Yichao Cai, Erdun Gao, Zhen Zhang, Biwei Huang, Mingming Gong, Anton van den Hengel, Javen Qinfeng Shi

+ [PolyPythias: Stability and Outliers across Fifty Language Model Pre-Training Runs](https://arxiv.org//abs/2503.09543)

	Oskar van der Wal, Pietro Lesci, Max Muller-Eberstein, Naomi Saphra, Hailey Schoelkopf, Willem Zuidema, Stella Biderman

+ [Probabilistic Reasoning with LLMs for k-anonymity Estimation](https://arxiv.org//abs/2503.09674)

	Jonathan Zheng, Sauvik Das, Alan Ritter, Wei Xu

+ [Cost-Optimal Grouped-Query Attention for Long-Context Modeling](https://arxiv.org//abs/2503.09579)

	Yingfa Chen, Yutong Wu, Chenyang Song, Zhen Leng Thai, Xingyu Shen, Xu Han, Zhiyuan Liu, Maosong Sun

+ [MindGYM: What Matters in Question Synthesis for Thinking-Centric Fine-Tuning?](https://arxiv.org//abs/2503.09499)

	Zhe Xu, Daoyuan Chen, Zhenqing Ling, Yaliang Li, Ying Shen

# 2025-03-11
+ [Training Plug-n-Play Knowledge Modules with Deep Context Distillation](https://arxiv.org//abs/2503.08727)

	Lucas Caccia, Alan Ansell, Edoardo Ponti, Ivan Vulić, Alessandro Sordoni

+ [SQLCritic: Correcting Text-to-SQL Generation via Clause-wise Critic](https://arxiv.org//abs/2503.07996)

	Jikai Chen, Leilei Gan, Ziyu Zhao, Zechuan Wang, Dong Wang, Chenyi Zhuang

+ [ReviewAgents: Bridging the Gap Between Human and AI-Generated Paper Reviews](https://arxiv.org//abs/2503.08506)

	Xian Gao, Jiacheng Ruan, Jingsheng Gao, Ting Liu, Yuzhuo Fu

+ [Route Sparse Autoencoder to Interpret Large Language Models](https://arxiv.org//abs/2503.08200)

	Wei Shi, Sihang Li, Tao Liang, Mingyang Wan, Guojun Ma, Xiang Wang, Xiangnan He

# 2025-03-10
+ [Are We Truly Forgetting? A Critical Re-examination of Machine Unlearning Evaluation Protocols](https://arxiv.org//abs/2503.06991)

	Yongwoo Kim, Sungmin Cha, Donghyun Kim

+ [UC-MOA: Utility-Conditioned Multi-Objective Alignment for Distributional Pareto-Optimality](https://arxiv.org//abs/2503.10669)

	Zelei Cheng, Xin-Qiang Cai, Yuting Tang, Pushi Zhang, Boming Yang, Masashi Sugiyama, Xinyu Xing

# 2025-03-09
+ [HCT-QA: A Benchmark for Question Answering on Human-Centric Tables](https://arxiv.org//abs/2504.20047)

	Mohammad S. Ahmad, Zan A. Naeem, Michaël Aupetit, Ahmed Elmagarmid, Mohamed Eltabakh, Xiasong Ma, Mourad Ouzzani, Chaoyi Ruan

# 2025-03-08
+ [SCoRE: Benchmarking Long-Chain Reasoning in Commonsense Scenarios](https://arxiv.org//abs/2503.06218)

	Weidong Zhan, Yue Wang, Nan Hu, Liming Xiao, Jingyuan Ma, Yuhang Qin, Zheng Li, Yixin Yang, Sirui Deng, Jinkun Ding, Wenhan Ma, Rui Li, Weilin Luo, Qun Liu, Zhifang Sui

+ [RouterEval: A Comprehensive Benchmark for Routing LLMs to Explore Model-level Scaling Up in LLMs](https://arxiv.org//abs/2503.10657)

	Zhongzhan Huang, Guoming Ling, Yupei Lin, Yandong Chen, Shanshan Zhong, Hefeng Wu, Liang Lin

+ [Large Language Models Post-training: Surveying Techniques from Alignment to Reasoning](https://arxiv.org//abs/2503.06072)

	Guiyao Tie, Zeli Zhao, Dingjie Song, Fuyang Wei, Rong Zhou, Yurou Dai, Wen Yin, Zhejian Yang, Jiangyue Yan, Yao Su, Zhenhan Dai, Yifeng Xie, Yihan Cao, Lichao Sun, Pan Zhou, Lifang He, Hechang Chen, Yu Zhang, Qingsong Wen, Tianming Liu, Neil Zhenqiang Gong, Jiliang Tang, Caiming Xiong, Heng Ji, Philip S. Yu, Jianfeng Gao

# 2025-03-07
+ [Correctness Coverage Evaluation for Medical Multiple-Choice Question Answering Based on the Enhanced Conformal Prediction Framework](https://arxiv.org//abs/2503.05505)

	Yusong Ke, Hongru Lin, Yuting Ruan, Junya Tang, Li Li

+ [AVA: Attentive VLM Agent for Mastering StarCraft II](https://arxiv.org//abs/2503.05383)

	Weiyu Ma, Yuqian Fu, Zecheng Zhang, Bernard Ghanem, Guohao Li

+ [Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching](https://arxiv.org//abs/2503.05179)

	Simon A. Aytes, Jinheon Baek, Sung Ju Hwang

+ [Capacity-Aware Inference: Mitigating the Straggler Effect in Mixture of Experts](https://arxiv.org//abs/2503.05066)

	Shwai He, Weilin Cai, Jiayi Huang, Ang Li

# 2025-03-06
+ [Wanda++: Pruning Large Language Models via Regional Gradients](https://arxiv.org//abs/2503.04992)

	Yifan Yang, Kai Zhen, Bhavana Ganesh, Aram Galstyan, Goeric Huybrechts, Markus Müller, Jonas M. Kübler, Rupak Vignesh Swaminathan, Athanasios Mouchtaris, Sravan Babu Bodapati, Nathan Susanj, Zheng Zhang, Jack FitzGerald, Abhishek Kumar

+ [SOLAR: Scalable Optimization of Large-scale Architecture for Reasoning](https://arxiv.org//abs/2503.04530)

	Chen Li, Yinyi Luo, Anudeep Bolimera, Uzair Ahmed, Shri Kiran Srinivasan, Hrishikesh Gokhale, Marios Savvides

+ [Predictable Scale: Part I -- Optimal Hyperparameter Scaling Law in Large Language Model Pretraining](https://arxiv.org//abs/2503.04715)

	Houyi Li, Wenzhen Zheng, Qiufeng Wang, Hanshan Zhang, Zili Wang, Shijie Xuyang, Yuantao Fan, Shuigeng Zhou, Xiangyu Zhang, Daxin Jiang

+ [DB-Explore: Automated Database Exploration and Instruction Synthesis for Text-to-SQL](https://arxiv.org//abs/2503.04959)

	Haoyuan Ma, Yongliang Shen, Hengwei Liu, Wenqi Zhang, Haolei Xu, Qiuying Peng, Jun Wang, Weiming Lu

+ [Compositional Causal Reasoning Evaluation in Language Models](https://arxiv.org//abs/2503.04556)

	Jacqueline R. M. A. Maasch, Alihan Hüyük, Xinnuo Xu, Aditya V. Nori, Javier Gonzalez

# 2025-03-05
+ [CodeIF-Bench: Evaluating Instruction-Following Capabilities of Large Language Models in Interactive Code Generation](https://arxiv.org//abs/2503.22688)

	Peiding Wang, Li Zhang, Fang Liu, Lin Shi, Minxiao Li, Bo Shen, An Fu

+ [The Devil Is in the Details: Tackling Unimodal Spurious Correlations for Generalizable Multimodal Reward Models](https://arxiv.org//abs/2503.03122)

	Zichao Li, Xueru Wen, Jie Lou, Yuqiu Ji, Yaojie Lu, Xianpei Han, Debing Zhang, Le Sun

+ [Cite Before You Speak: Enhancing Context-Response Grounding in E-commerce Conversational LLM-Agents](https://arxiv.org//abs/2503.04830)

	Jingying Zeng, Hui Liu, Zhenwei Dai, Xianfeng Tang, Chen Luo, Samarth Varshney, Zhen Li, Qi He

+ [Can Frontier LLMs Replace Annotators in Biomedical Text Mining? Analyzing Challenges and Exploring Solutions](https://arxiv.org//abs/2503.03261)

	Yichong Zhao, Susumu Goto

# 2025-03-04
+ [LiteWebAgent: The Open-Source Suite for VLM-Based Web-Agent Applications](https://arxiv.org//abs/2503.02950)

	Danqing Zhang, Balaji Rama, Jingyi Ni, Shiying He, Fu Zhao, Kunyu Chen, Arnold Chen, Junyu Cao

+ [Call for Rigor in Reporting Quality of Instruction Tuning Data](https://arxiv.org//abs/2503.04807)

	Hyeonseok Moon, Jaehyung Seo, Heuiseok Lim

+ [MoSE: Hierarchical Self-Distillation Enhances Early Layer Embeddings](https://arxiv.org//abs/2503.03008)

	Andrea Gurioli, Federico Pennino, João Monteiro, Maurizio Gabbrielli

+ [MCiteBench: A Multimodal Benchmark for Generating Text with Citations](https://arxiv.org//abs/2503.02589)

	Caiyu Hu, Yikai Zhang, Tinghui Zhu, Yiwei Ye, Yanghua Xiao

+ [Scaling Laws for Many-Shot In-Context Learning with Self-Generated Annotations](https://arxiv.org//abs/2503.03062)

	Zhengyao Gu, Henry Peng Zou, Yankai Chen, Aiwei Liu, Weizhi Zhang, Philip S. Yu

+ [Teaching Metric Distance to Autoregressive Multimodal Foundational Models](https://arxiv.org//abs/2503.02379)

	Jiwan Chung, Saejin Kim, Yongrae Jo, Jaewoo Park, Dongjun Min, Youngjae Yu

+ [Rewarding Doubt: A Reinforcement Learning Approach to Calibrated Confidence Expression of Large Language Models](https://arxiv.org//abs/2503.02623)

	Paul Stangel, David Bani-Harouni, Chantal Pellegrini, Ege Özsoy, Kamilia Zaripova, Matthias Keicher, Nassir Navab

# 2025-03-03
+ [SAGE: A Framework of Precise Retrieval for RAG](https://arxiv.org//abs/2503.01713)

	Jintao Zhang, Guoliang Li, Jinyang Su

+ [Liger: Linearizing Large Language Models to Gated Recurrent Structures](https://arxiv.org//abs/2503.01496)

	Disen Lan, Weigao Sun, Jiaxi Hu, Jusen Du, Yu Cheng

+ [Adaptively profiling models with task elicitation](https://arxiv.org//abs/2503.01986)

	Davis Brown, Prithvi Balehannina, Helen Jin, Shreya Havaldar, Hamed Hassani, Eric Wong

+ [Retrieval-Augmented Perception: High-Resolution Image Perception Meets Visual RAG](https://arxiv.org//abs/2503.01222)

	Wenbin Wang, Yongcheng Jing, Liang Ding, Yingjie Wang, Li Shen, Yong Luo, Bo Du, Dacheng Tao

+ [HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs](https://arxiv.org//abs/2503.02003)

	Tin Nguyen, Logan Bolton, Mohammad Reza Taesiri, Anh Totti Nguyen

# 2025-03-02
+ [NCL-UoR at SemEval-2025 Task 3: Detecting Multilingual Hallucination and Related Observable Overgeneration Text Spans with Modified RefChecker and Modified SeflCheckGPT](https://arxiv.org//abs/2503.01921)

	Jiaying Hong, Thanet Markchom, Jianfei Xu, Tong Wu, Huizhi Liang

+ [ALinFiK: Learning to Approximate Linearized Future Influence Kernel for Scalable Third-Party LLM Data Valuation](https://arxiv.org//abs/2503.01052)

	Yanzhou Pan, Huawei Lin, Yide Ran, Jiamin Chen, Xiaodong Yu, Weijie Zhao, Denghui Zhang, Zhaozhuo Xu

# 2025-03-01
+ [Steer LLM Latents for Hallucination Detection](https://arxiv.org//abs/2503.01917)

	Seongheon Park, Xuefeng Du, Min-Hsuan Yeh, Haobo Wang, Yixuan Li

# 2025-02-28
+ [SPD: Sync-Point Drop for efficient tensor parallelism of Large Language Models](https://arxiv.org//abs/2502.20727)

	Han-Byul Kim, Duc Hoang, Arnav Kundu, Mohammad Samragh, Minsik Cho

+ [Semantic Volume: Quantifying and Detecting both External and Internal Uncertainty in LLMs](https://arxiv.org//abs/2502.21239)

	Xiaomin Li, Zhou Yu, Ziji Zhang, Yingying Zhuang, Swair Shah, Narayanan Sadagopan, Anurag Beniwal

+ [A Pilot Empirical Study on When and How to Use Knowledge Graphs as Retrieval Augmented Generation](https://arxiv.org//abs/2502.20854)

	Xujie Yuan, Yongxu Liu, Shimin Di, Shiwen Wu, Libin Zheng, Rui Meng, Lei Chen, Xiaofang Zhou, Jian Yin

+ [FANformer: Improving Large Language Models Through Effective Periodicity Modeling](https://arxiv.org//abs/2502.21309)

	Yihong Dong, Ge Li, Xue Jiang, Yongding Tao, Kechi Zhang, Hao Zhu, Huanyu Liu, Jiazheng Ding, Jia Li, Jinliang Deng, Hong Mei

+ [CODI: Compressing Chain-of-Thought into Continuous Space via Self-Distillation](https://arxiv.org//abs/2502.21074)

	Zhenyi Shen, Hanqi Yan, Linhai Zhang, Zhanghao Hu, Yali Du, Yulan He

# 2025-02-27
+ [LLM-driven Effective Knowledge Tracing by Integrating Dual-channel Difficulty](https://arxiv.org//abs/2502.19915)

	Jiahui Cen, Jianghao Lin, Weixuan Zhong, Dong Zhou, Jin Chen, Aimin Yang, Yongmei Zhou

+ [Mapping Trustworthiness in Large Language Models: A Bibliometric Analysis Bridging Theory to Practice](https://arxiv.org//abs/2503.04785)

	José Siqueira de Cerqueira, Kai-Kristian Kemell, Muhammad Waseem, Rebekah Rousi, Nannan Xi, Juho Hamari, Pekka Abrahamsson

+ [Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization](https://arxiv.org//abs/2502.20364)

	Ryan C. Barron, Maksim E. Eren, Olga M. Serafimova, Cynthia Matuszek, Boian S. Alexandrov

+ [Erasing Without Remembering: Implicit Knowledge Forgetting in Large Language Models](https://arxiv.org//abs/2502.19982)

	Huazheng Wang, Yongcheng Jing, Haifeng Sun, Yingjie Wang, Jingyu Wang, Jianxin Liao, Dacheng Tao

+ [Multi2: Multi-Agent Test-Time Scalable Framework for Multi-Document Processing](https://arxiv.org//abs/2502.20592)

	Juntai Cao, Xiang Zhang, Raymond Li, Chuyuan Li, Chenyu You, Shafiq Joty, Giuseppe Carenini

+ [Sensing and Steering Stereotypes: Extracting and Applying Gender Representation Vectors in LLMs](https://arxiv.org//abs/2502.19721)

	Hannah Cyberey, Yangfeng Ji, David Evans

+ [Investigating and Enhancing Vision-Audio Capability in Omnimodal Large Language Models](https://arxiv.org//abs/2503.00059)

	Rui Hu, Delai Qiu, Shuyu Wei, Jiaming Zhang, Yining Wang, Shengping Liu, Jitao Sang

+ [Meta-Reasoner: Dynamic Guidance for Optimized Inference-time Reasoning in Large Language Models](https://arxiv.org//abs/2502.19918)

	Yuan Sui, Yufei He, Tri Cao, Simeng Han, Yulin Chen, Bryan Hooi

+ [Collab-Overcooked: Benchmarking and Evaluating Large Language Models as Collaborative Agents](https://arxiv.org//abs/2502.20073)

	Haochen Sun, Shuwen Zhang, Lujie Niu, Lei Ren, Hao Xu, Hao Fu, Fangkun Zhao, Caixia Yuan, Xiaojie Wang

+ [Similarity-Distance-Magnitude Universal Verification](https://arxiv.org//abs/2502.20167)

	Allen Schmaltz

+ [Do Retrieval-Augmented Language Models Adapt to Varying User Needs?](https://arxiv.org//abs/2502.19779)

	Peilin Wu, Xinlu Zhang, Wenhao Yu, Xingyu Liu, Xinya Du, Zhiyu Zoey Chen

# 2025-02-26
+ [BIG-Bench Extra Hard](https://arxiv.org//abs/2502.19187)

	Mehran Kazemi, Bahare Fatemi, Hritik Bansal, John Palowitch, Chrysovalantis Anastasiou, Sanket Vaibhav Mehta, Lalit K. Jain, Virginia Aglietti, Disha Jindal, Peter Chen, Nishanth Dikkala, Gladys Tyen, Xin Liu, Uri Shalit, Silvia Chiappa, Kate Olszewska, Yi Tay, Vinh Q. Tran, Quoc V. Le, Orhan Firat

+ [A Sliding Layer Merging Method for Efficient Depth-Wise Pruning in LLMs](https://arxiv.org//abs/2502.19159)

	Xuan Ding, Rui Sun, Yunjian Zhang, Xiu Yan, Yueqi Zhou, Kaihao Huang, Suzhong Fu, Chuanlong Xie, Yao Zhu

+ [Can RLHF be More Efficient with Imperfect Reward Models? A Policy Coverage Perspective](https://arxiv.org//abs/2502.19255)

	Jiawei Huang, Bingcong Li, Christoph Dann, Niao He

+ [ZEBRA: Leveraging Model-Behavioral Knowledge for Zero-Annotation Preference Dataset Construction](https://arxiv.org//abs/2502.18744)

	Jeesu Jung, Chanjun Park, Sangkeun Jung

+ [Stay Focused: Problem Drift in Multi-Agent Debate](https://arxiv.org//abs/2502.19559)

	Jonas Becker, Lars Benedikt Kaesberg, Andreas Stephan, Jan Philip Wahle, Terry Ruas, Bela Gipp

+ [Is Your Paper Being Reviewed by an LLM? Benchmarking AI Text Detection in Peer Review](https://arxiv.org//abs/2502.19614)

	Sungduk Yu, Man Luo, Avinash Madusu, Vasudev Lal, Phillip Howard

# 2025-02-25
+ [Faster, Cheaper, Better: Multi-Objective Hyperparameter Optimization for LLM and RAG Systems](https://arxiv.org//abs/2502.18635)

	Matthew Barker, Andrew Bell, Evan Thomas, James Carr, Thomas Andrews, Umang Bhatt

+ [Discriminative Finetuning of Generative Large Language Models without Reward Models and Human Preference Data](https://arxiv.org//abs/2502.18679)

	Siqi Guo, Ilgee Hong, Vicente Balmaseda, Changlong Yu, Liang Qiu, Xin Liu, Haoming Jiang, Tuo Zhao, Tianbao Yang

+ [Harnessing Multiple Large Language Models: A Survey on LLM Ensemble](https://arxiv.org//abs/2502.18036)

	Zhijun Chen, Jingzheng Li, Pengpeng Chen, Zhuoran Li, Kai Sun, Yuankai Luo, Qianren Mao, Dingqi Yang, Hailong Sun, Philip S. Yu

+ [Uncertainty Quantification for LLM-Based Survey Simulations](https://arxiv.org//abs/2502.17773)

	Chengpiao Huang, Yuhang Wu, Kaizheng Wang

+ [FoREST: Frame of Reference Evaluation in Spatial Reasoning Tasks](https://arxiv.org//abs/2502.17775)

	Tanawan Premsri, Parisa Kordjamshidi

+ [Towards Better Understanding of Program-of-Thought Reasoning in Cross-Lingual and Multilingual Environments](https://arxiv.org//abs/2502.17956)

	Patomporn Payoungkhamdee, Pume Tuchinda, Jinheon Baek, Samuel Cahyawijaya, Can Udomcharoenchaikit, Potsawee Manakul, Peerat Limkonchotiwat, Ekapol Chuangsuwanich, Sarana Nutanong

# 2025-02-24
+ [Automatically Evaluating the Paper Reviewing Capability of Large Language Models](https://arxiv.org//abs/2502.17086)

	Hyungyu Shin, Jingyu Tang, Yoonjoo Lee, Nayoung Kim, Hyunseung Lim, Ji Yong Cho, Hwajung Hong, Moontae Lee, Juho Kim

+ [From System 1 to System 2: A Survey of Reasoning Large Language Models](https://arxiv.org//abs/2502.17419)

	Zhong-Zhi Li, Duzhen Zhang, Ming-Liang Zhang, Jiaxin Zhang, Zengyan Liu, Yuxuan Yao, Haotian Xu, Junhao Zheng, Pei-Jie Wang, Xiuyi Chen, Yingying Zhang, Fei Yin, Jiahua Dong, Zhiwei Li, Bao-Long Bi, Ling-Rui Mei, Junfeng Fang, Zhijiang Guo, Le Song, Cheng-Lin Liu

+ [MEMERAG: A Multilingual End-to-End Meta-Evaluation Benchmark for Retrieval Augmented Generation](https://arxiv.org//abs/2502.17163)

	María Andrea Cruz Blandón, Jayasimha Talur, Bruno Charron, Dong Liu, Saab Mansour, Marcello Federico

+ [Make LoRA Great Again: Boosting LoRA with Adaptive Singular Values and Mixture-of-Experts Optimization Alignment](https://arxiv.org//abs/2502.16894)

	Chenghao Fan, Zhenyi Lu, Sichen Liu, Chengfeng Gu, Xiaoye Qu, Wei Wei, Yu Cheng

+ [Intermediate Languages Matter: Formal Choice Drives Neurosymbolic LLM Reasoning](https://arxiv.org//abs/2502.17216)

	Alexander Beiser, David Penz, Nysret Musliu

+ [Large Language Models are Powerful Electronic Health Record Encoders](https://arxiv.org//abs/2502.17403)

	Stefan Hegselmann, Georg von Arnim, Tillmann Rheude, Noel Kronenberg, David Sontag, Gerhard Hindricks, Roland Eils, Benjamin Wild

+ [Spontaneous Giving and Calculated Greed in Language Models](https://arxiv.org//abs/2502.17720)

	Yuxuan Li, Hirokazu Shirado

+ [Finding the Sweet Spot: Preference Data Construction for Scaling Preference Optimization](https://arxiv.org//abs/2502.16825)

	Yao Xiao, Hai Ye, Linyao Chen, Hwee Tou Ng, Lidong Bing, Xiaoli Li, Roy Ka-wei Lee

+ [Unveiling Downstream Performance Scaling of LLMs: A Clustering-Based Perspective](https://arxiv.org//abs/2502.17262)

	Chengyin Xu, Kaiyuan Chen, Xiao Li, Ke Shen, Chenggang Li

+ [PrivaCI-Bench: Evaluating Privacy with Contextual Integrity and Legal Compliance](https://arxiv.org//abs/2502.17041)

	Haoran Li, Wenbin Hu, Huihao Jing, Yulin Chen, Qi Hu, Sirui Han, Tianshu Chu, Peizhao Hu, Yangqiu Song

# 2025-02-23
+ [Retrieval-Augmented Fine-Tuning With Preference Optimization For Visual Program Generation](https://arxiv.org//abs/2502.16529)

	Deokhyung Kang, Jeonghun Cho, Yejin Jeon, Sunbin Jang, Minsub Lee, Jawoon Cho, Gary Geunbae Lee

# 2025-02-22
+ [Worse than Zero-shot? A Fact-Checking Dataset for Evaluating the Robustness of RAG Against Misleading Retrievals](https://arxiv.org//abs/2502.16101)

	Linda Zeng, Rithwik Gupta, Divij Motwani, Diji Yang, Yi Zhang

# 2025-02-21
+ [Machine-generated text detection prevents language model collapse](https://arxiv.org//abs/2502.15654)

	George Drayson, Emine Yilmaz, Vasileios Lampos

+ [Activation Steering in Neural Theorem Provers](https://arxiv.org//abs/2502.15507)

	Shashank Kirtania

+ [Unveiling Attractor Cycles in Large Language Models: A Dynamical Systems View of Successive Paraphrasing](https://arxiv.org//abs/2502.15208)

	Zhilin Wang, Yafu Li, Jianhao Yan, Yu Cheng, Yue Zhang

+ [ARS: Automatic Routing Solver with Large Language Models](https://arxiv.org//abs/2502.15359)

	Kai Li, Fei Liu, Zhenkun Wang, Xialiang Tong, Xiongwei Han, Mingxuan Yuan, Qingfu Zhang

+ [Sparsity May Be All You Need: Sparse Random Parameter Adaptation](https://arxiv.org//abs/2502.15975)

	Jesus Rios, Pierre Dognin, Ronny Luss, Karthikeyan N. Ramamurthy

+ [Problem-Solving Logic Guided Curriculum In-Context Learning for LLMs Complex Reasoning](https://arxiv.org//abs/2502.15401)

	Xuetao Ma, Wenbin Jiang, Hua Huang

+ [CoT-ICL Lab: A Synthetic Framework for Studying Chain-of-Thought Learning from In-Context Demonstrations](https://arxiv.org//abs/2502.15132)

	Vignesh Kothapalli, Hamed Firooz, Maziar Sanjabi

+ [KVLink: Accelerating Large Language Models via Efficient KV Cache Reuse](https://arxiv.org//abs/2502.16002)

	Jingbo Yang, Bairu Hou, Wei Wei, Yujia Bao, Shiyu Chang

+ [SafeInt: Shielding Large Language Models from Jailbreak Attacks via Safety-Aware Representation Intervention](https://arxiv.org//abs/2502.15594)

	Jiaqi Wu, Chen Chen, Chunyan Hou, Xiaojie Yuan

# 2025-02-20
+ [Drift: Decoding-time Personalized Alignments with Implicit User Preferences](https://arxiv.org//abs/2502.14289)

	Minbeom Kim, Kang-il Lee, Seongho Joo, Hwaran Lee, Thibaut Thonet, Kyomin Jung

+ [A Statistical Case Against Empirical Human-AI Alignment](https://arxiv.org//abs/2502.14581)

	Julian Rodemann, Esteban Garces Arias, Christoph Luther, Christoph Jansen, Thomas Augustin

+ [InductionBench: LLMs Fail in the Simplest Complexity Class](https://arxiv.org//abs/2502.15823)

	Wenyue Hua, Tyler Wong, Sun Fei, Liangming Pan, Adam Jardine, William Yang Wang

+ [iAgent: LLM Agent as a Shield between User and Recommender Systems](https://arxiv.org//abs/2502.14662)

	Wujiang Xu, Yunxiao Shi, Zujie Liang, Xuying Ning, Kai Mei, Kun Wang, Xi Zhu, Min Xu, Yongfeng Zhang

+ [Enhancing Conversational Agents with Theory of Mind: Aligning Beliefs, Desires, and Intentions for Human-Like Interaction](https://arxiv.org//abs/2502.14171)

	Mehdi Jafari, Devin Yuncheng Hua, Hao Xue, Flora Salim

+ [Rapid Word Learning Through Meta In-Context Learning](https://arxiv.org//abs/2502.14791)

	Wentao Wang, Guangyuan Jiang, Tal Linzen, Brenden M. Lake

+ [Edit Once, Update Everywhere: A Simple Framework for Cross-Lingual Knowledge Synchronization in LLMs](https://arxiv.org//abs/2502.14645)

	Yuchen Wu, Liang Ding, Li Shen, Dacheng Tao

+ [Triangulating LLM Progress through Benchmarks, Games, and Cognitive Tests](https://arxiv.org//abs/2502.14359)

	Filippo Momentè, Alessandro Suglia, Mario Giulianelli, Ambra Ferrari, Alexander Koller, Oliver Lemon, David Schlangen, Raquel Fernández, Raffaella Bernardi

+ [ICA-RAG: Information Completeness Guided Adaptive Retrieval-Augmented Generation for Disease Diagnosis](https://arxiv.org//abs/2502.14614)

	Mingyi Jia, Zhihao Jia, Junwen Duan, Yan Song, Jianxin Wang

+ [Quantize What Counts: Bit Allocation Insights Informed by Spectral Gaps in Keys and Values](https://arxiv.org//abs/2502.15075)

	Mohsen Hariri, Alan Luo, Mohammadreza Nemati, Lam Nguyen, Shaochen Zhong, Qifan Wang, Xia Hu, Xiaotian Han, Vipin Chaudhary

# 2025-02-19
+ [FairKV: Balancing Per-Head KV Cache for Fast Multi-GPU Inference](https://arxiv.org//abs/2502.15804)

	Bingzhe Zhao, Ke Cheng, Aomufei Yuan, Yuxuan Tian, Ruiguang Zhong, Chengchen Hu, Tong Yang, Lian Yu

+ [Is This Collection Worth My LLM's Time? Automatically Measuring Information Potential in Text Corpora](https://arxiv.org//abs/2502.13691)

	Tristan Karch, Luca Engel, Philippe Schwaller, Frédéric Kaplan

+ [TreeCut: A Synthetic Unanswerable Math Word Problem Dataset for LLM Hallucination Evaluation](https://arxiv.org//abs/2502.13442)

	Jialin Ouyang

+ [FineEdit: Unlock Instruction-Based Text Editing for LLMs](https://arxiv.org//abs/2502.13358)

	Yiming Zeng, Wanhao Yu, Zexin Li, Tao Ren, Yu Ma, Jinghan Cao, Xiyan Chen, Tingting Yu

+ [Reducing Hallucinations in Language Model-based SPARQL Query Generation Using Post-Generation Memory Retrieval](https://arxiv.org//abs/2502.13369)

	Aditya Sharma, Luis Lara, Christopher J. Pal, Amal Zouaq

+ [UniKnow: A Unified Framework for Reliable Language Model Behavior across Parametric and External Knowledge](https://arxiv.org//abs/2502.13648)

	Youna Kim, Hyuhng Joon Kim, Minjoon Choi, Sungmin Cho, Hyunsoo Cho, Sang-goo Lee, Taeuk Kim

+ [Agentic AI Software Engineers: Programming with Trust](https://arxiv.org//abs/2502.13767)

	Abhik Roychoudhury, Corina Pasareanu, Michael Pradel, Baishakhi Ray

# 2025-02-18
+ [EPO: Explicit Policy Optimization for Strategic Reasoning in LLMs via Reinforcement Learning](https://arxiv.org//abs/2502.12486)

	Xiaoqian Liu, Ke Wang, Yongbin Li, Yuchuan Wu, Wentao Ma, Aobo Kong, Fei Huang, Jianbin Jiao, Junge Zhang

+ [An LLM-Powered Agent for Physiological Data Analysis: A Case Study on PPG-based Heart Rate Estimation](https://arxiv.org//abs/2502.12836)

	Mohammad Feli, Iman Azimi, Pasi Liljeberg, Amir M.Rahmani

+ [None of the Others: a General Technique to Distinguish Reasoning from Memorization in Multiple-Choice LLM Evaluation Benchmarks](https://arxiv.org//abs/2502.12896)

	Eva Sánchez Salido, Julio Gonzalo, Guillermo Marco

+ [Demonstrating specification gaming in reasoning models](https://arxiv.org//abs/2502.13295)

	Alexander Bondarenko, Denis Volk, Dmitrii Volkov, Jeffrey Ladish

+ [KL Penalty Control via Perturbation for Direct Preference Optimization](https://arxiv.org//abs/2502.13177)

	Sangkyu Lee, Janghoon Han, Hosung Song, Stanley Jungkyu Choi, Honglak Lee, Youngjae Yu

+ [SafeRoute: Adaptive Model Selection for Efficient and Accurate Safety Guardrails in Large Language Models](https://arxiv.org//abs/2502.12464)

	Seanie Lee, Dong Bok Lee, Dominik Wagner, Minki Kang, Haebin Seong, Tobias Bocklet, Juho Lee, Sung Ju Hwang

+ [EquiBench: Benchmarking Large Language Models' Understanding of Program Semantics via Equivalence Checking](https://arxiv.org//abs/2502.12466)

	Anjiang Wei, Jiannan Cao, Ran Li, Hongyu Chen, Yuhui Zhang, Ziheng Wang, Yuan Liu, Thiago S. F. X. Teixeira, Diyi Yang, Ke Wang, Alex Aiken

+ [R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on Knowledge Graphs](https://arxiv.org//abs/2502.12767)

	Sumin Jo, Junseong Choi, Jiho Kim, Edward Choi

+ [Robust Adaptation of Large Multimodal Models for Retrieval Augmented Hateful Meme Detection](https://arxiv.org//abs/2502.13061)

	Jingbiao Mei, Jinghong Chen, Guangyu Yang, Weizhe Lin, Bill Byrne

+ [Re-Align: Aligning Vision Language Models via Retrieval-Augmented Direct Preference Optimization](https://arxiv.org//abs/2502.13146)

	Shuo Xing, Yuping Wang, Peiran Li, Ruizheng Bai, Yueqi Wang, Chan-wei Hu, Chengxuan Qian, Huaxiu Yao, Zhengzhong Tu

+ [Benchmarking Post-Training Quantization in LLMs: Comprehensive Taxonomy, Unified Evaluation, and Comparative Analysis](https://arxiv.org//abs/2502.13178)

	Jiaqi Zhao, Ming Wang, Miao Zhang, Yuzhang Shang, Xuebo Liu, Yaowei Wang, Min Zhang, Liqiang Nie

+ [SEA: Low-Resource Safety Alignment for Multimodal Large Language Models via Synthetic Embeddings](https://arxiv.org//abs/2502.12562)

	Weikai Lu, Hao Peng, Huiping Zhuang, Cen Chen, Ziqian Zeng

+ [CityEQA: A Hierarchical LLM Agent on Embodied Question Answering Benchmark in City Space](https://arxiv.org//abs/2502.12532)

	Yong Zhao, Kai Xu, Zhengqiu Zhu, Yue Hu, Zhiheng Zheng, Yingfeng Chen, Yatai Ji, Chen Gao, Yong Li, Jincai Huang

+ [PASER: Post-Training Data Selection for Efficient Pruned Large Language Model Recovery](https://arxiv.org//abs/2502.12594)

	Bowei He, Lihao Yin, Hui-Ling Zhen, Xiaokun Zhang, Mingxuan Yuan, Chen Ma

# 2025-02-17
+ [Towards Reasoning Ability of Small Language Models](https://arxiv.org//abs/2502.11569)

	Gaurav Srivastava, Shuxiang Cao, Xuan Wang


+ [Fate: Fast Edge Inference of Mixture-of-Experts Models via Cross-Layer Gate](https://arxiv.org//abs/2502.12224)

	Zhiyuan Fang, Zicong Hong, Yuegui Huang, Yufeng Lyu, Wuhui Chen, Yue Yu, Fan Yu, Zibin Zheng

+ [Integrating Expert Knowledge into Logical Programs via LLMs](https://arxiv.org//abs/2502.12275)

	Franciszek Górski, Oskar Wysocki, Marco Valentino, Andre Freitas

+ [Can Your Uncertainty Scores Detect Hallucinated Entity?](https://arxiv.org//abs/2502.11948)

	Min-Hsuan Yeh, Max Kamachee, Seongheon Park, Yixuan Li

+ [Table-Critic: A Multi-Agent Framework for Collaborative Criticism and Refinement in Table Reasoning](https://arxiv.org//abs/2502.11799)

	Peiying Yu, Guoxin Chen, Jingjing Wang

+ [From the New World of Word Embeddings: A Comparative Study of Small-World Lexico-Semantic Networks in LLMs](https://arxiv.org//abs/2502.11380)

	Zhu Liu, Ying Liu, KangYang Luo, Cunliang Kong, Maosong Sun

+ [Beyond Single-Task: Robust Multi-Task Length Generalization for LLMs](https://arxiv.org//abs/2502.11525)

	Yi Hu, Shijia Kang, Haotong Yang, Haotian Xu, Muhan Zhang

+ [Plant in Cupboard, Orange on Rably, Inat Aphone. Benchmarking Incremental Learning of Situation and Language Model using a Text-Simulated Situated Environment](https://arxiv.org//abs/2502.11733)

	Jonathan Jordan, Sherzod Hakimov, David Schlangen

+ [FineFilter: A Fine-grained Noise Filtering Mechanism for Retrieval-Augmented Large Language Models](https://arxiv.org//abs/2502.11811)

	Qianchi Zhang, Hainan Zhang, Liang Pang, Ziwei Wang, Hongwei Zheng, Yongxin Tong, Zhiming Zheng

+ [SQL-o1: A Self-Reward Heuristic Dynamic Search Method for Text-to-SQL](https://arxiv.org//abs/2502.11741)

	Shuai Lyu, Haoran Luo, Ripeng Li, Zhonghong Ou, Jiangfeng Sun, Yang Qin, Xiaoran Shang, Meina Song, Yifan Zhu

+ [Which Retain Set Matters for LLM Unlearning? A Case Study on Entity Unlearning](https://arxiv.org//abs/2502.11441)

	Hwan Chang, Hwanhee Lee

+ [GLTW: Joint Improved Graph Transformer and LLM via Three-Word Language for Knowledge Graph Completion](https://arxiv.org//abs/2502.11471)

	Kangyang Luo, Yuzhuo Bai, Cheng Gao, Shuzheng Si, Yingli Shen, Zhu Liu, Zhitong Wang, Cunliang Kong, Wenhao Li, Yufei Huang, Ye Tian, Xuantang Xiong, Lei Han, Maosong Sun

+ [SAFE-SQL: Self-Augmented In-Context Learning with Fine-grained Example Selection for Text-to-SQL](https://arxiv.org//abs/2502.11438)

	Jimin Lee, Ingeol Baek, Byeongjeong Kim, Hyunkyung Bae, Hwanhee Lee

+ [System Message Generation for User Preferences using Open-Source Models](https://arxiv.org//abs/2502.11330)

	Minbyul Jeong, Jungho Cho, Minsoo Khang, Dawoon Jung, Teakgyu Hong

+ [Personality Editing for Language Models through Relevant Knowledge Editing](https://arxiv.org//abs/2502.11789)

	Seojin Hwang, Yumin Kim, Byeongjeong Kim, Donghoon Shin, Hwanhee Lee

# 2025-02-16
+ [Leveraging Conditional Mutual Information to Improve Large Language Model Fine-Tuning For Classification](https://arxiv.org//abs/2502.11258)

	Thanushon Sivakaran, En-Hui Yang

+ [Safety Evaluation of DeepSeek Models in Chinese Contexts](https://arxiv.org//abs/2502.11137)

	Wenjing Zhang, Xuejiao Lei, Zhaoxiang Liu, Ning Wang, Zhenhong Long, Peijun Yang, Jiaojiao Zhao, Minjie Hua, Chaoyang Ma, Kai Wang, Shiguo Lian

+ [Investigating Language Preference of Multilingual RAG Systems](https://arxiv.org//abs/2502.11175)

	Jeonghyun Park, Hwanhee Lee

+ [RAS: Retrieval-And-Structuring for Knowledge-Intensive LLM Generation](https://arxiv.org//abs/2502.10996)

	Pengcheng Jiang, Lang Cao, Ruike Zhu, Minhao Jiang, Yunyi Zhang, Jimeng Sun, Jiawei Han

+ [The Mirage of Model Editing: Revisiting Evaluation in the Wild](https://arxiv.org//abs/2502.11177)

	Wanli Yang, Fei Sun, Jiajun Tan, Xinyu Ma, Qi Cao, Dawei Yin, Huawei Shen, Xueqi Cheng

+ [CoLA: Compute-Efficient Pre-Training of LLMs via Low-Rank Activation](https://arxiv.org//abs/2502.10940)

	Ziyue Liu, Ruijie Zhang, Zhengyang Wang, Zi Yang, Paul Hovland, Bogdan Nicolae, Franck Cappello, Zheng Zhang

+ [MMUnlearner: Reformulating Multimodal Machine Unlearning in the Era of Multimodal Large Language Models](https://arxiv.org//abs/2502.11051)

	Jiahao Huo, Yibo Yan, Xu Zheng, Yuanhuiyi Lyu, Xin Zou, Zhihua Wei, Xuming Hu

+ [Attention Mechanism for LLM-based Agents Dynamic Diffusion under Information Asymmetry](https://arxiv.org//abs/2502.13160)

	Yiwen Zhang, Yifu Wu, Wenyue Hua, Xiang Lu, Xuming Hu

+ [CARMA: Enhanced Compositionality in LLMs via Advanced Regularisation and Mutual Information Alignment](https://arxiv.org//abs/2502.11066)

	Nura Aljaafari, Danilo S. Carvalho, André Freitas

+ [VLMs as GeoGuessr Masters: Exceptional Performance, Hidden Biases, and Privacy Risks](https://arxiv.org//abs/2502.11163)

	Jingyuan Huang, Jen-tse Huang, Ziyi Liu, Xiaoyuan Liu, Wenxuan Wang, Jieyu Zhao

+ [GRIFFIN: Effective Token Alignment for Faster Speculative Decoding](https://arxiv.org//abs/2502.11018)

	Shijing Hu, Jingyang Li, Xingyu Xie, Zhihui Lu, Kim-Chuan Toh, Pan Zhou

+ [Vendi-RAG: Adaptively Trading-Off Diversity And Quality Significantly Improves Retrieval Augmented Generation With LLMs](https://arxiv.org//abs/2502.11228)

	Mohammad Reza Rezaei, Adji Bousso Dieng

# 2025-02-15
+ [D-CIPHER: Dynamic Collaborative Intelligent Multi-Agent System with Planner and Heterogeneous Executors for Offensive Security](https://arxiv.org//abs/2502.10931)

	Meet Udeshi, Minghao Shao, Haoran Xi, Nanda Rani, Kimberly Milner, Venkata Sai Charan Putrevu, Brendan Dolan-Gavitt, Sandeep Kumar Shukla, Prashanth Krishnamurthy, Farshad Khorrami, Ramesh Karri, Muhammad Shafique

+ [Probing Semantic Routing in Large Mixture-of-Expert Models](https://arxiv.org//abs/2502.10928)

	Matthew Lyle Olson, Neale Ratzlaff, Musashi Hinck, Man Luo, Sungduk Yu, Chendi Xue, Vasudev Lal

+ [LoRE-Merging: Exploring Low-Rank Estimation For Large Language Model Merging](https://arxiv.org//abs/2502.10749)

	Zehua Liu, Han Wu, Yuxuan Yao, Ruifeng She, Xiongwei Han, Tao Zhong, Mingxuan Yuan

+ [Beyond One-Size-Fits-All Pruning via Evolutionary Metric Search for Large Language Models](https://arxiv.org//abs/2502.10735)

	Shuqi Liu, Bowei He, Han Wu, Linqi Song

+ [1bit-Merging: Dynamic Quantized Merging for Large Language Models](https://arxiv.org//abs/2502.10743)

	Shuqi Liu, Yuxuan Yao, Bowei He, Zehua Liu, Xiongwei Han, Mingxuan Yuan, Han Wu, Linqi Song

# 2025-02-14
+ [Cooperative Multi-Agent Planning with Adaptive Skill Synthesis](https://arxiv.org//abs/2502.10148)

	Zhiyuan Li, Wenshuai Zhao, Joni Pajarinen

+ [MIR-Bench: Can Your LLM Recognize Complicated Patterns via Many-Shot In-Context Reasoning?](https://arxiv.org//abs/2502.09933)

	Kai Yan, Zhan Ling, Kang Liu, Yifan Yang, Ting-Han Fan, Lingfeng Shen, Zhengyin Du, Jiecao Chen

# 2025-02-13
+ [CRANE: Reasoning with constrained LLM generation](https://arxiv.org//abs/2502.09061)

	Debangshu Banerjee, Tarun Suresh, Shubham Ugare, Sasa Misailovic, Gagandeep Singh

+ [SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models](https://arxiv.org//abs/2502.09604)

	Yung-Sung Chuang, Benjamin Cohen-Wang, Shannon Zejiang Shen, Zhaofeng Wu, Hu Xu, Xi Victoria Lin, James Glass, Shang-Wen Li, Wen-tau Yih

+ [The Hidden Dimensions of LLM Alignment: A Multi-Dimensional Analysis of Orthogonal Safety Directions](https://arxiv.org//abs/2502.09674)

	Wenbo Pan, Zhichao Liu, Qiguang Chen, Xiangyang Zhou, Haining Yu, Xiaohua Jia

+ [CopySpec: Accelerating LLMs with Speculative Copy-and-Paste Without Compromising Quality](https://arxiv.org//abs/2502.08923)

	Razvan-Gabriel Dumitru, Minglai Yang, Vikas Yadav, Mihai Surdeanu

# 2025-02-12
+ [k-LLMmeans: Scalable, Stable, and Interpretable Text Clustering via LLM-based Centroids](https://arxiv.org//abs/2502.09667)

	Jairo Diaz-Rodriguez

+ [No Need for Explanations: LLMs can implicitly learn from mistakes in-context](https://arxiv.org//abs/2502.08550)

	Lisa Alazraki, Maximilian Mozes, Jon Ander Campos, Tan Yi-Chern, Marek Rei, Max Bartolo

# 2025-02-11
+ [Time2Lang: Bridging Time-Series Foundation Models and Large Language Models for Health Sensing Beyond Prompting](https://arxiv.org//abs/2502.07608)

	Arvind Pillai, Dimitris Spathis, Subigya Nepal, Amanda C Collins, Daniel M Mackin, Michael V Heinz, Tess Z Griffin, Nicholas C Jacobson, Andrew Campbell

+ [Caught in the Web of Words: Do LLMs Fall for Spin in Medical Literature?](https://arxiv.org//abs/2502.07963)

	Hye Sun Yun, Karen Y.C. Zhang, Ramez Kouzy, Iain J. Marshall, Junyi Jessy Li, Byron C. Wallace

+ [Recursive Inference Scaling: A Winning Path to Scalable Inference in Language and Multimodal Systems](https://arxiv.org//abs/2502.07503)

	Ibrahim Alabdulmohsin, Xiaohua Zhai

+ [Principled Data Selection for Alignment: The Hidden Risks of Difficult Examples](https://arxiv.org//abs/2502.09650)

	Chengqian Gao, Haonan Li, Liu Liu, Zeke Xie, Peilin Zhao, Zhiqiang Xu

+ [Hallucination, Monofacts, and Miscalibration: An Empirical Investigation](https://arxiv.org//abs/2502.08666)

	Miranda Muqing Miao, Michael Kearns

+ [Mask-Enhanced Autoregressive Prediction: Pay Less Attention to Learn More](https://arxiv.org//abs/2502.07490)

	Xialie Zhuang, Zhikai Jia, Jianjin Li, Zhenyu Zhang, Li Shen, Zheng Cao, Shiwei Liu

+ [Memory Is Not the Bottleneck: Cost-Efficient Continual Learning via Weight Space Consolidation](https://arxiv.org//abs/2502.07274)

	Dongkyu Cho, Taesup Moon, Rumi Chunara, Kyunghyun Cho, Sungmin Cha

+ [CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction](https://arxiv.org//abs/2502.07316)

	Junlong Li, Daya Guo, Dejian Yang, Runxin Xu, Yu Wu, Junxian He

+ [Streaming Attention Approximation via Discrepancy Theory](https://arxiv.org//abs/2502.07861)

	Insu Han, Michael Kapralov, Ekaterina Kochetkova, Kshiteej Sheth, Amir Zandieh

# 2025-02-10
+ [Generating Privacy-Preserving Personalized Advice with Zero-Knowledge Proofs and LLMs](https://arxiv.org//abs/2502.06425)

	Hiroki Watanabe, Motonobu Uchikoshi


+ [Unbiased Evaluation of Large Language Models from a Causal Perspective](https://arxiv.org//abs/2502.06655)

	Meilin Chen, Jian Tian, Liang Ma, Di Xie, Weijie Chen, Jiang Zhu

+ [Is LLM an Overconfident Judge? Unveiling the Capabilities of LLMs in Detecting Offensive Language with Annotation Disagreement](https://arxiv.org//abs/2502.06207)

	Junyu Lu, Kai Ma, Kaichun Wang, Kelaiti Xiao, Roy Ka-Wei Lee, Bo Xu, Liang Yang, Hongfei Lin

+ [Who Taught You That? Tracing Teachers in Model Distillation](https://arxiv.org//abs/2502.06659)

	Somin Wadhwa, Chantal Shaib, Silvio Amir, Byron C. Wallace

+ [Online Scheduling for LLM Inference with KV Cache Constraints](https://arxiv.org//abs/2502.07115)

	Patrick Jaillet, Jiashuo Jiang, Konstantina Mellou, Marco Molinaro, Chara Podimata, Zijie Zhou

+ [C-3PO: Compact Plug-and-Play Proxy Optimization to Achieve Human-like Retrieval-Augmented Generation](https://arxiv.org//abs/2502.06205)

	Guoxin Chen, Minpeng Liao, Peiying Yu, Dingmin Wang, Zile Qiao, Chao Yang, Xin Zhao, Kai Fan

+ [InSTA: Towards Internet-Scale Training For Agents](https://arxiv.org//abs/2502.06776)

	Brandon Trabucco, Gunnar Sigurdsson, Robinson Piramuthu, Ruslan Salakhutdinov

+ [Is a Peeled Apple Still Red? Evaluating LLMs' Ability for Conceptual Combination with Property Type](https://arxiv.org//abs/2502.06086)

	Seokwon Song, Taehyun Lee, Jaewoo Ahn, Jae Hyuk Sung, Gunhee Kim

+ [LCIRC: A Recurrent Compression Approach for Efficient Long-form Context and Query Dependent Modeling in LLMs](https://arxiv.org//abs/2502.06139)

	Sumin An, Junyoung Sung, Wonpyo Park, Chanjun Park, Paul Hongsuck Seo

+ [Towards Copyright Protection for Knowledge Bases of Retrieval-augmented Language Models via Reasoning](https://arxiv.org//abs/2502.10440)

	Junfeng Guo, Yiming Li, Ruibo Chen, Yihan Wu, Chenxi Liu, Yanshuo Chen, Heng Huang

# 2025-02-09
+ [HSI: Head-Specific Intervention Can Induce Misaligned AI Coordination in Large Language Models](https://arxiv.org//abs/2502.05945)

	Paul Darm, Annalisa Riccardi

# 2025-02-08
+ [Agentic AI Systems Applied to tasks in Financial Services: Modeling and model risk management crews](https://arxiv.org//abs/2502.05439)

	Izunna Okpala, Ashkan Golgoon, Arjun Ravi Kannan

+ [The Odyssey of the Fittest: Can Agents Survive and Still Be Good?](https://arxiv.org//abs/2502.05442)

	Dylan Waldner, Risto Miikkulainen

+ [Mix Data or Merge Models? Balancing the Helpfulness, Honesty, and Harmlessness of Large Language Model via Model Merging](https://arxiv.org//abs/2502.06876)

	Jinluan Yang, Dingnan Jin, Anke Tang, Li Shen, Didi Zhu, Zhengyu Chen, Ziyu Zhao, Daixin Wang, Qing Cui, Zhiqiang Zhang, Jun Zhou, Fei Wu, Kun Kuang

+ [Evolving LLMs' Self-Refinement Capability via Iterative Preference Optimization](https://arxiv.org//abs/2502.05605)

	Yongcheng Zeng, Xinyu Cui, Xuanfa Jin, Guoqing Liu, Zexu Sun, Dong Li, Ning Yang, Jianye Hao, Haifeng Zhang, Jun Wang

+ [Flowing Through Layers: A Continuous Dynamical Systems Perspective on Transformers](https://arxiv.org//abs/2502.05656)

	Jacob Fein-Ashley

# 2025-02-07
+ [Probabilistic Subspace Manifolds for Contextual Inference in Large Language Models](https://arxiv.org//abs/2502.05346)

	Christopher Nightingale, Dominic Lavington, Jonathan Thistlethwaite, Sebastian Penhaligon, Thomas Belinski, David Boldo

+ [MELON: Provable Indirect Prompt Injection Defense via Masked Re-execution and Tool Comparison](https://arxiv.org//abs/2502.05174)

	Kaijie Zhu, Xianjun Yang, Jindong Wang, Wenbo Guo, William Yang Wang

+ [Unveiling the Mechanisms of Explicit CoT Training: How CoT Enhances Reasoning Generalization](https://arxiv.org//abs/2502.04667)

	Xinhao Yao, Ruifeng Ren, Yun Liao, Yong Liu

+ [Generating Symbolic World Models via Test-time Scaling of Large Language Models](https://arxiv.org//abs/2502.04728)

	Zhouliang Yu, Yuhuan Yuan, Tim Z. Xiao, Fuxiang Frank Xia, Jie Fu, Ge Zhang, Ge Lin, Weiyang Liu

+ [ARR: Question Answering with Large Language Models via Analyzing, Retrieving, and Reasoning](https://arxiv.org//abs/2502.04689)

	Yuwei Yin, Giuseppe Carenini

+ [Uncertainty Quantification for LLMs through Minimum Bayes Risk: Bridging Confidence and Consistency](https://arxiv.org//abs/2502.04964)

	Roman Vashurin, Maiya Goloburda, Albina Ilina, Alexander Rubashevskii, Preslav Nakov, Artem Shelmanov, Maxim Panov

# 2025-02-06
+ [The Order Effect: Investigating Prompt Sensitivity to Input Order in LLMs](https://arxiv.org//abs/2502.04134)

	Bryan Guan, Tanya Roosta, Peyman Passban, Mehdi Rezagholizadeh

+ [SMI: An Information-Theoretic Metric for Predicting Model Knowledge Solely from Pre-Training Signals](https://arxiv.org//abs/2502.04066)

	Changhao Jiang, Ming Zhang, Junjie Ye, Xiaoran Fan, Yifei Cao, Jiajun Sun, Zhiheng Xi, Shihan Dou, Yi Dong, Yujiong Shen, Jingqi Tong, Zhen Wang, Tao Liang, Zhihui Fei, Mingyang Wan, Guojun Ma, Qi Zhang, Tao Gui, Xuanjing Huang

+ [FAS: Fast ANN-SNN Conversion for Spiking Large Language Models](https://arxiv.org//abs/2502.04405)

	Long Chen, Xiaotian Song, Andy Song, BaDong Chen, Jiancheng Lv, Yanan Sun

+ [Reformulation for Pretraining Data Augmentation](https://arxiv.org//abs/2502.04235)

	Xintong Hao, Ruijie Zhu, Ge Zhang, Ke Shen, Chenggang Li

+ [Training Language Models to Reason Efficiently](https://arxiv.org//abs/2502.04463)

	Daman Arora, Andrea Zanette

+ [Beyond Prompt Content: Enhancing LLM Performance via Content-Format Integrated Prompt Optimization](https://arxiv.org//abs/2502.04295)

	Yuanye Liu, Jiahang Xu, Li Lyna Zhang, Qi Chen, Xuan Feng, Yang Chen, Zhongxin Guo, Yuqing Yang, Peng Cheng

# 2025-02-05
+ [Leveraging the true depth of LLMs](https://arxiv.org//abs/2502.02790)

	Ramón Calvo González, Daniele Paliotta, Matteo Pagliardini, Martin Jaggi, François Fleuret

+ [Large Language Model as Universal Retriever in Industrial-Scale Recommender System](https://arxiv.org//abs/2502.03041)

	Junguang Jiang, Yanwen Huang, Bin Liu, Xiaoyu Kong, Xinhang Li, Ziru Xu, Han Zhu, Jian Xu, Bo Zheng

+ [Speculative Prefill: Turbocharging TTFT with Lightweight and Training-Free Token Importance Estimation](https://arxiv.org//abs/2502.02789)

	Jingyu Liu, Beidi Chen, Ce Zhang

+ [CARROT: A Cost Aware Rate Optimal Router](https://arxiv.org//abs/2502.03261)

	Seamus Somerstep, Felipe Maia Polo, Allysson Flavio Melo de Oliveira, Prattyush Mangal, Mírian Silva, Onkar Bhardwaj, Mikhail Yurochkin, Subha Maity

+ [An Analysis for Reasoning Bias of Language Models with Small Initialization](https://arxiv.org//abs/2502.04375)

	Junjie Yao, Zhongwang Zhang, Zhi-Qin John Xu

+ [Diversity as a Reward: Fine-Tuning LLMs on a Mixture of Domain-Undetermined Data](https://arxiv.org//abs/2502.04380)

	Zhenqing Ling, Daoyuan Chen, Liuyi Yao, Qianli Shen, Yaliang Li, Ying Shen

# 2025-02-04
+ [CITER: Collaborative Inference for Efficient Large Language Model Decoding with Token-Level Routing](https://arxiv.org//abs/2502.01976)

	Wenhao Zheng, Yixiao Chen, Weitong Zhang, Souvik Kundu, Yun Li, Zhengzhong Liu, Eric P. Xing, Hongyi Wang, Huaxiu Yao

+ [Shuttle Between the Instructions and the Parameters of Large Language Models](https://arxiv.org//abs/2502.02315)

	Wangtao Sun, Haotian Xu, Huanxuan Liao, Xuanqing Yu, Zhongtao Jiang, Shizhu He, Jun Zhao, Kang Liu

+ [Generative Psycho-Lexical Approach for Constructing Value Systems in Large Language Models](https://arxiv.org//abs/2502.02444)

	Haoran Ye, Tianze Zhang, Yuhang Xie, Liyuan Zhang, Yuanyi Ren, Xin Zhang, Guojie Song

+ [From Words to Collisions: LLM-Guided Evaluation and Adversarial Generation of Safety-Critical Driving Scenarios](https://arxiv.org//abs/2502.02145)

	Yuan Gao, Mattia Piccinini, Korbinian Moller, Johannes Betz

+ [LongDPO: Unlock Better Long-form Generation Abilities for LLMs via Critique-augmented Stepwise Information](https://arxiv.org//abs/2502.02095)

	Bowen Ping, Jiali Zeng, Fandong Meng, Shuo Wang, Jie Zhou, Shanghang Zhang

+ [Premise-Augmented Reasoning Chains Improve Error Identification in Math reasoning with LLMs](https://arxiv.org//abs/2502.02362)

	Sagnik Mukherjee, Abhinav Chinta, Takyoung Kim, Tarun Anoop Sharma, Dilek Hakkani-Tür

+ [Can LLMs Maintain Fundamental Abilities under KV Cache Compression?](https://arxiv.org//abs/2502.01941)

	Xiang Liu, Zhenheng Tang, Hong Chen, Peijie Dong, Zeyu Li, Xiuze Zhou, Bo Li, Xuming Hu, Xiaowen Chu

+ [Neurons Speak in Ranges: Breaking Free from Discrete Neuronal Attribution](https://arxiv.org//abs/2502.06809)

	Muhammad Umair Haider, Hammad Rizwan, Hassan Sajjad, Peizhong Ju, A.B. Siddique

+ [Fairness through Difference Awareness: Measuring Desired Group Discrimination in LLMs](https://arxiv.org//abs/2502.01926)

	Angelina Wang, Michelle Phan, Daniel E. Ho, Sanmi Koyejo

# 2025-02-03
+ [Efficient Model Editing with Task Vector Bases: A Theoretical Framework and Scalable Approach](https://arxiv.org//abs/2502.01015)

	Siqi Zeng, Yifei He, Weiqiu You, Yifan Hao, Yao-Hung Hubert Tsai, Makoto Yamada, Han Zhao


+ [Factual Knowledge in Language Models: Robustness and Anomalies under Simple Temporal Context Variations](https://arxiv.org//abs/2502.01220)

	Hichem Ammar Khodja, Frédéric Béchet, Quentin Brabant, Alexis Nasr, Gwénolé Lecorvé

+ [Efficient Model Editing with Task Vector Bases: A Theoretical Framework and Scalable Approach](https://arxiv.org//abs/2502.01015)

	Siqi Zeng, Yifei He, Weiqiu You, Yifan Hao, Yao-Hung Hubert Tsai, Makoto Yamada, Han Zhao

+ [Massive Values in Self-Attention Modules are the Key to Contextual Knowledge Understanding](https://arxiv.org//abs/2502.01563)

	Mingyu Jin, Kai Mei, Wujiang Xu, Mingjie Sun, Ruixiang Tang, Mengnan Du, Zirui Liu, Yongfeng Zhang

+ [SE Arena: An Interactive Platform for Evaluating Foundation Models in Software Engineering](https://arxiv.org//abs/2502.01860)

	Zhimin Zhao

+ [Firewalls to Secure Dynamic LLM Agentic Networks](https://arxiv.org//abs/2502.01822)

	Sahar Abdelnabi, Amr Gomaa, Per Ola Kristensson, Reza Shokri

+ [Joint Localization and Activation Editing for Low-Resource Fine-Tuning](https://arxiv.org//abs/2502.01179)

	Wen Lai, Alexander Fraser, Ivan Titov

+ [Scaling Embedding Layers in Language Models](https://arxiv.org//abs/2502.01637)

	Da Yu, Edith Cohen, Badih Ghazi, Yangsibo Huang, Pritish Kamath, Ravi Kumar, Daogao Liu, Chiyuan Zhang

+ [Explaining Context Length Scaling and Bounds for Language Models](https://arxiv.org//abs/2502.01481)

	Jingzhe Shi, Qinwei Ma, Hongyi Liu, Hang Zhao, Jeng-Neng Hwang, Lei Li

+ [The Differences Between Direct Alignment Algorithms are a Blur](https://arxiv.org//abs/2502.01237)

	Alexey Gorbatovski, Boris Shaposhnikov, Viacheslav Sinii, Alexey Malakhov, Daniil Gavrilov

+ [The Jumping Reasoning Curve? Tracking the Evolution of Reasoning Performance in GPT-[n] and o-[n] Models on Multimodal Puzzles](https://arxiv.org//abs/2502.01081)

	Vernon Y.H. Toh, Yew Ken Chia, Deepanway Ghosal, Soujanya Poria

+ [Lifelong Knowledge Editing requires Better Regularization](https://arxiv.org//abs/2502.01636)

	Akshat Gupta, Phudish Prateepamornkul, Maochuan Lu, Ahmed Alaa, Thomas Hartvigsen, Gopala Anumanchipalli

+ [BARE: Leveraging Base Language Models for Few-Shot Synthetic Data Generation](https://arxiv.org//abs/2502.01697)

	Alan Zhu, Parth Asawa, Jared Quincy Davis, Lingjiao Chen, Boris Hanin, Ion Stoica, Joseph E. Gonzalez, Matei Zaharia

+ [FastKV: KV Cache Compression for Fast Long-Context Processing with Token-Selective Propagation](https://arxiv.org//abs/2502.01068)

	Dongwon Jo, Jiwon Song, Yulhwa Kim, Jae-Joon Kim

+ [GRADIEND: Monosemantic Feature Learning within Neural Networks Applied to Gender Debiasing of Transformer Models](https://arxiv.org//abs/2502.01406)

	Jonathan Drechsel, Steffen Herbold

# 2025-02-02
+ [Vision-centric Token Compression in Large Language Model](https://arxiv.org//abs/2502.00791)

	Ling Xing, Alex Jinpeng Wang, Rui Yan, Xiangbo Shu, Jinhui Tang

+ [Disentangling Length Bias In Preference Learning Via Response-Conditioned Modeling](https://arxiv.org//abs/2502.00814)

	Jianfeng Cai, Jinhua Zhu, Ruopei Sun, Yue Wang, Li Li, Wengang Zhou, Houqiang Li

+ [When Do LLMs Help With Node Classification? A Comprehensive Analysis](https://arxiv.org//abs/2502.00829)

	Xixi Wu, Yifei Shen, Fangzhou Ge, Caihua Shan, Yizhu Jiao, Xiangguo Sun, Hong Cheng

+ [How Contaminated Is Your Benchmark? Quantifying Dataset Leakage in Large Language Models with Kernel Divergence](https://arxiv.org//abs/2502.00678)

	Hyeong Kyu Choi, Maxim Khanov, Hongxin Wei, Yixuan Li

+ [To Code or not to Code? Adaptive Tool Integration for Math Language Models via Expectation-Maximization](https://arxiv.org//abs/2502.00691)

	Haozhe Wang, Long Li, Chao Qu, Fengming Zhu, Weidi Xu, Wei Chu, Fangzhen Lin

+ [ReFoRCE: A Text-to-SQL Agent with Self-Refinement, Consensus Enforcement, and Column Exploration](https://arxiv.org//abs/2502.00675)

	Minghang Deng, Ashwin Ramachandran, Canwen Xu, Lanxiang Hu, Zhewei Yao, Anupam Datta, Hao Zhang

+ [FIRE: Flexible Integration of Data Quality Ratings for Effective Pre-Training](https://arxiv.org//abs/2502.00761)

	Liangyu Xu, Xuemiao Zhang, Feiyu Duan, Sirui Wang, Rongxiang Weng, Jingang Wang, Xunliang Cai

# 2025-02-01
+ [Explorations of the Softmax Space: Knowing When the Neural Network Doesn't Know](https://arxiv.org//abs/2502.00456)

	Daniel Sikar, Artur d'Avila Garcez, Tillman Weyde

+ [Estimating LLM Uncertainty with Logits](https://arxiv.org//abs/2502.00290)

	Huan Ma, Jingdong Chen, Joey Tianyi Zhou, Guangyu Wang, Changqing Zhang

+ [DUET: Optimizing Training Data Mixtures via Feedback from Unseen Evaluation Tasks](https://arxiv.org//abs/2502.00270)

	Zhiliang Chen, Gregory Kang Ruey Lau, Chuan-Sheng Foo, Bryan Kian Hsiang Low

+ [ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference](https://arxiv.org//abs/2502.00299)

	Xiang Liu, Zhenheng Tang, Peijie Dong, Zeyu Li, Yue Liu, Bo Li, Xuming Hu, Xiaowen Chu

# 2025-01-31
+ [Deep Learning Model Inversion Attacks and Defenses: A Comprehensive Survey](https://arxiv.org//abs/2501.18934)

	Wencheng Yang, Song Wang, Di Wu, Taotao Cai, Yanming Zhu, Shicheng Wei, Yiying Zhang, Xu Yang, Zhaohui Tang, Yan Li

+ [Towards the Worst-case Robustness of Large Language Models](https://arxiv.org//abs/2501.19040)

	Huanran Chen, Yinpeng Dong, Zeming Wei, Hang Su, Jun Zhu

+ [Federated Sketching LoRA: On-Device Collaborative Fine-Tuning of Large Language Models](https://arxiv.org//abs/2501.19389)

	Wenzhi Fang, Dong-Jun Han, Liangqi Yuan, Seyyedali Hosseinalipour, Christopher G. Brinton

+ [Improving LLM Unlearning Robustness via Random Perturbations](https://arxiv.org//abs/2501.19202)

	Dang Huu-Tien, Hoang Thanh-Tung, Anh Bui, Le-Minh Nguyen, Naoya Inoue

+ [Fairshare Data Pricing via Data Valuation for Large Language Models](https://arxiv.org//abs/2502.00198)

	Luyang Zhang, Cathy Jiao, Beibei Li, Chenyan Xiong

+ [SETS: Leveraging Self-Verification and Self-Correction for Improved Test-Time Scaling](https://arxiv.org//abs/2501.19306)

	Jiefeng Chen, Jie Ren, Xinyun Chen, Chengrun Yang, Ruoxi Sun, Jinsung Yoon, Sercan Ö Arık

# 2025-01-30
+ [Efficiency and Effectiveness of LLM-Based Summarization of Evidence in Crowdsourced Fact-Checking](https://arxiv.org//abs/2501.18265)

	Kevin Roitero, Dustin Wright, Michael Soprano, Isabelle Augenstein, Stefano Mizzaro

+ [On the Role of Transformer Feed-Forward Layers in Nonlinear In-Context Learning](https://arxiv.org//abs/2501.18187)

	Haoyuan Sun, Ali Jadbabaie, Navid Azizan

+ [Diverse Preference Optimization](https://arxiv.org//abs/2501.18101)

	Jack Lanchantin, Angelica Chen, Shehzaad Dhuliawala, Ping Yu, Jason Weston, Sainbayar Sukhbaatar, Ilia Kulikov

+ [WILDCHAT-50M: A Deep Dive Into the Role of Synthetic Data in Post-Training](https://arxiv.org//abs/2501.18511)

	Benjamin Feuer, Chinmay Hegde

# 2025-01-29
+ [Large Language Models Think Too Fast To Explore Effectively](https://arxiv.org//abs/2501.18009)

	Lan Pan, Hanbo Xie, Robert C. Wilson

# 2025-01-28
+ [Instantiation-based Formalization of Logical Reasoning Tasks using Language Models and Logical Solvers](https://arxiv.org//abs/2501.16961)

	Mohammad Raza, Natasa Milic-Frayling

+ [RadioLLM: Introducing Large Language Model into Cognitive Radio via Hybrid Prompt and Token Reprogrammings](https://arxiv.org//abs/2501.17888)

	Shuai Chen, Yong Zu, Zhixi Feng, Shuyuan Yang, Mengchang Li

+ [Over-Tokenized Transformer: Vocabulary is Generally Worth Scaling](https://arxiv.org//abs/2501.16975)

	Hongzhi Huang, Defa Zhu, Banggu Wu, Yutao Zeng, Ya Wang, Qiyang Min, Xun Zhou

# 2025-01-27
+ [Are Transformers Able to Reason by Connecting Separated Knowledge in Training Data?](https://arxiv.org//abs/2501.15857)

	Yutong Yin, Zhaoran Wang


+ [Are Transformers Able to Reason by Connecting Separated Knowledge in Training Data?](https://arxiv.org//abs/2501.15857)

	Yutong Yin, Zhaoran Wang

+ [AdaCoT: Rethinking Cross-Lingual Factual Reasoning through Adaptive Chain-of-Thought](https://arxiv.org//abs/2501.16154)

	Xin Huang, Tarun Kumar Vangani, Zhengyuan Liu, Bowei Zou, Ai Ti Aw

+ [On the Feasibility of Using LLMs to Autonomously Execute Multi-host Network Attacks](https://arxiv.org//abs/2501.16466)

	Brian Singer, Keane Lucas, Lakshmi Adiga, Meghna Jain, Lujo Bauer, Vyas Sekar

# 2025-01-26
+ [TensorLLM: Tensorising Multi-Head Attention for Enhanced Reasoning and Compression in LLMs](https://arxiv.org//abs/2501.15674)

	Yuxuan Gu, Wuyang Zhou, Giorgos Iacovides, Danilo Mandic

+ [FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint](https://arxiv.org//abs/2501.15509)

	Shuo Shao, Haozhe Zhu, Hongwei Yao, Yiming Li, Tianwei Zhang, Zhan Qin, Kui Ren

# 2025-01-25
+ [Option-ID Based Elimination For Multiple Choice Questions](https://arxiv.org//abs/2501.15175)

	Zhenhao Zhu, Bulou Liu, Qingyao Ai, Yiqun Liu

+ [FBQuant: FeedBack Quantization for Large Language Models](https://arxiv.org//abs/2501.16385)

	Yijiang Liu, Hengyu Fang, Liulu He, Rongyu Zhang, Yichuan Bai, Yuan Du, Li Du

# 2025-01-24
+ [Context-Aware Neural Gradient Mapping for Fine-Grained Instruction Processing](https://arxiv.org//abs/2501.14936)

	David Boldo, Lily Pemberton, Gabriel Thistledown, Jacob Fairchild, Felix Kowalski


+ [Prompt-Based Cost-Effective Evaluation and Operation of ChatGPT as a Computer Programming Teaching Assistant](https://arxiv.org//abs/2501.17176)

	Marc Ballestero-Ribó, Daniel Ortiz-Martínez

+ [Self-reflecting Large Language Models: A Hegelian Dialectical Approach](https://arxiv.org//abs/2501.14917)

	Sara Abdali, Can Goksen, Saeed Amizadeh, Julie E. Maybee, Kazuhito Koishida

+ [JustLogic: A Comprehensive Benchmark for Evaluating Deductive Reasoning in Large Language Models](https://arxiv.org//abs/2501.14851)

	Michael K. Chen, Xikun Zhang, Dacheng Tao

+ [SwiftPrune: Hessian-Free Weight Pruning for Large Language Models](https://arxiv.org//abs/2501.16376)

	Yuhan Kang, Yang Shi, Mei We, Jun He, Jianchao Yang, Zeyu Xue, Jing Feng, Xinwang Liu

+ [Mitigating Forgetting in LLM Fine-Tuning via Low-Perplexity Token Learning](https://arxiv.org//abs/2501.14315)

	Chao-Chung Wu, Zhi Rui Tam, Chieh-Yen Lin, Yun-Nung Chen, Shao-Hua Sun, Hung-yi Lee

# 2025-01-23
+ [GraphRAG under Fire](https://arxiv.org//abs/2501.14050)

	Jiacheng Liang, Yuhui Wang, Changjiang Li, Rongyi Zhu, Tanqiu Jiang, Neil Gong, Ting Wang


+ [A Cognitive Paradigm Approach to Probe the Perception-Reasoning Interface in VLMs](https://arxiv.org//abs/2501.13620)

	Mohit Vaishnav, Tanel Tammet

+ [Communicating Activations Between Language Model Agents](https://arxiv.org//abs/2501.14082)

	Vignav Ramesh, Kenneth Li

+ [Softplus Attention with Re-weighting Boosts Length Extrapolation in Large Language Models](https://arxiv.org//abs/2501.13428)

	Bo Gao, Michael W. Spratling

+ [Re-ranking Using Large Language Models for Mitigating Exposure to Harmful Content on Social Media Platforms](https://arxiv.org//abs/2501.13977)

	Rajvardhan Oak, Muhammad Haroon, Claire Jo, Magdalena Wojcieszak, Anshuman Chhabra

# 2025-01-21
+ [Test-time regression: a unifying framework for designing sequence models with associative memory](https://arxiv.org//abs/2501.12352)

	Ke Alexander Wang, Jiaxin Shi, Emily B. Fox

+ [Med-R$^2$: Crafting Trustworthy LLM Physicians via Retrieval and Reasoning of Evidence-Based Medicine](https://arxiv.org//abs/2501.11885)

	Keer Lu, Zheng Liang, Zhuoran Zhang, Da Pan, Shusen Zhang, Xin Wu, Zenan Zhou, Guosheng Dong, Bin Cui, Tengjiao Wang, Wentao Zhang

+ [AdaServe: Accelerating Multi-SLO LLM Serving with SLO-Customized Speculative Decoding](https://arxiv.org//abs/2501.12162)

	Zikun Li, Zhuofu Chen, Remi Delacourt, Gabriele Oliaro, Zeyu Wang, Qinghan Chen, Shuhuai Lin, April Yang, Zhihao Zhang, Zhuoming Chen, Sean Lai, Xinhao Cheng, Xupeng Miao, Zhihao Jia

+ [InternLM-XComposer2.5-Reward: A Simple Yet Effective Multi-Modal Reward Model](https://arxiv.org//abs/2501.12368)

	Yuhang Zang, Xiaoyi Dong, Pan Zhang, Yuhang Cao, Ziyu Liu, Shengyuan Ding, Shenxi Wu, Yubo Ma, Haodong Duan, Wenwei Zhang, Kai Chen, Dahua Lin, Jiaqi Wang

# 2025-01-19
+ [A Comprehensive Survey on Integrating Large Language Models with Knowledge-Based Methods](https://arxiv.org//abs/2501.13947)

	Wenli Yang, Lilian Some, Michael Bain, Byeong Kang

+ [Chain-of-Reasoning: Towards Unified Mathematical Reasoning in Large Language Models via a Multi-Paradigm Perspective](https://arxiv.org//abs/2501.11110)

	Yiyao Yu, Yuxiang Zhang, Dongdong Zhang, Xiao Liang, Hengyuan Zhang, Xingxing Zhang, Mahmoud Khademi, Hany Awadalla, Junjie Wang, Yujiu Yang, Furu Wei

# 2025-01-17
+ [Know Your Mistakes: Towards Preventing Overreliance on Task-Oriented Conversational AI Through Accountability Modeling](https://arxiv.org//abs/2501.10316)

	Suvodip Dey, Yi-Jyun Sun, Gokhan Tur, Dilek Hakkani-Tur

# 2025-01-13
+ [TiEBe: Tracking Language Model Recall of Notable Worldwide Events Through Time](https://arxiv.org//abs/2501.07482)

	Thales Sales Almeida, Giovana Kerche Bonás, João Guilherme Alves Santos, Hugo Abonizio, Rodrigo Nogueira

# 2025-01-10
+ [Dynamics of Spontaneous Topic Changes in Next Token Prediction with Self-Attention](https://arxiv.org//abs/2501.06382)

	Mumin Jia, Jairo Diaz-Rodriguez

+ [How to Enable Effective Cooperation Between Humans and NLP Models: A Survey of Principles, Formalizations, and Beyond](https://arxiv.org//abs/2501.05714)

	Chen Huang, Yang Deng, Wenqiang Lei, Jiancheng Lv, Tat-Seng Chua, Jimmy Xiangji Huang

+ [Large Language Models Share Representations of Latent Grammatical Concepts Across Typologically Diverse Languages](https://arxiv.org//abs/2501.06346)

	Jannik Brinkmann, Chris Wendler, Christian Bartelt, Aaron Mueller

# 2025-01-09
+ [CallNavi, A Challenge and Empirical Study on LLM Function Calling and Routing](https://arxiv.org//abs/2501.05255)

	Yewei Song, Xunzhu Tang, Cedric Lothritz, Saad Ezzini, Jacques Klein, Tegawendé F. Bissyandé, Andrey Boytsov, Ulrick Ble, Anne Goujon


+ [SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution](https://arxiv.org//abs/2501.05040)

	Chengxing Xie, Bowen Li, Chang Gao, He Du, Wai Lam, Difan Zou, Kai Chen

+ [TreeKV: Smooth Key-Value Cache Compression with Tree Structures](https://arxiv.org//abs/2501.04987)

	Ziwei He, Jian Yuan, Haoli Bai, Jingwen Leng, Bo Jiang

# 2025-01-08
+ [URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics](https://arxiv.org//abs/2501.04686)

	Ruilin Luo, Zhuofan Zheng, Yifan Wang, Xinzhe Ni, Zicheng Lin, Songtao Jiang, Yiyao Yu, Chufan Shi, Ruihang Chu, Jin Zeng, Yujiu Yang

# 2025-01-05
+ [Towards the Anonymization of the Language Modeling](https://arxiv.org//abs/2501.02407)

	Antoine Boutet, Lucas Magnana, Juliette Sénéchal, Helain Zimmermann

+ [Scaling Laws for Floating Point Quantization Training](https://arxiv.org//abs/2501.02423)

	Xingwu Sun, Shuaipeng Li, Ruobing Xie, Weidong Han, Kan Wu, Zhen Yang, Yixing Li, An Wang, Shuai Li, Jinbao Xue, Yu Cheng, Yangyu Tao, Zhanhui Kang, Chengzhong Xu, Di Wang, Jie Jiang

+ [ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use](https://arxiv.org//abs/2501.02506)

	Junjie Ye, Zhengyin Du, Xuesong Yao, Weijian Lin, Yufei Xu, Zehui Chen, Zaiyuan Wang, Sining Zhu, Zhiheng Xi, Siyu Yuan, Tao Gui, Qi Zhang, Xuanjing Huang, Jiecao Chen

# 2025-01-04
+ [Zero-Shot Statistical Tests for LLM-Generated Text Detection using Finite Sample Concentration Inequalities](https://arxiv.org//abs/2501.02406)

	Tara Radvand, Mojtaba Abdolmaleki, Mohamed Mostagir, Ambuj Tewari

+ [LLM Content Moderation and User Satisfaction: Evidence from Response Refusals in Chatbot Arena](https://arxiv.org//abs/2501.03266)

	Stefan Pasch

# 2025-01-03
+ [MIRAGE: Exploring How Large Language Models Perform in Complex Social Interactive Environments](https://arxiv.org//abs/2501.01652)

	Yin Cai, Zhouhong Gu, Zhaohan Du, Zheyu Ye, Shaosheng Cao, Yiqian Xu, Hongwei Feng, Ping Chen

# 2025-01-02
+ [ValuesRAG: Enhancing Cultural Alignment Through Retrieval-Augmented Contextual Learning](https://arxiv.org//abs/2501.01031)

	Wonduk Seo, Zonghao Yuan, Yi Bu

+ [Cross-model Transferability among Large Language Models on the Platonic Representations of Concepts](https://arxiv.org//abs/2501.02009)

	Youcheng Huang, Chen Huang, Duanyu Feng, Wenqiang Lei, Jiancheng Lv

# 2025-01-01
+ [LUSIFER: Language Universal Space Integration for Enhanced Multilingual Embeddings with Large Language Models](https://arxiv.org//abs/2501.00874)

	Hieu Man, Nghia Trung Ngo, Viet Dac Lai, Ryan A. Rossi, Franck Dernoncourt, Thien Huu Nguyen

+ [FitCF: A Framework for Automatic Feature Importance-guided Counterfactual Example Generation](https://arxiv.org//abs/2501.00777)

	Qianli Wang, Nils Feldhus, Simon Ostermann, Luis Felipe Villa-Arenas, Sebastian Möller, Vera Schmitt

# 2024-12-30
+ [ExpShield: Safeguarding Web Text from Unauthorized Crawling and Language Modeling Exploitation](https://arxiv.org//abs/2412.21123)

	Ruixuan Liu, Toan Tran, Tianhao Wang, Hongsheng Hu, Shuo Wang, Li Xiong

# 2024-12-29
+ [ICLR: In-Context Learning of Representations](https://arxiv.org//abs/2501.00070)

	Core Francisco Park, Andrew Lee, Ekdeep Singh Lubana, Yongyi Yang, Maya Okawa, Kento Nishi, Martin Wattenberg, Hidenori Tanaka

+ [Understanding the Impact of Confidence in Retrieval Augmented Generation: A Case Study in the Medical Domain](https://arxiv.org//abs/2412.20309)

	Shintaro Ozaki, Yuta Kato, Siyuan Feng, Masayo Tomita, Kazuki Hayashi, Wataru Hashimoto, Ryoma Obara, Masafumi Oyamada, Katsuhiko Hayashi, Hidetaka Kamigaito, Taro Watanabe

# 2024-12-28
+ [No Preference Left Behind: Group Distributional Preference Optimization](https://arxiv.org//abs/2412.20299)

	Binwei Yao, Zefan Cai, Yun-Shiuan Chuang, Shanglin Yang, Ming Jiang, Diyi Yang, Junjie Hu

# 2024-12-24
+ [LSAQ: Layer-Specific Adaptive Quantization for Large Language Model Deployment](https://arxiv.org//abs/2412.18135)

	Binrui Zeng, Bin Ji, Xiaodong Liu, Jie Yu, Shasha Li, Jun Ma, Xiaopeng Li, Shangwen Wang, Xinran Hong, Yongtao Tang

+ [KunServe: Parameter-centric Memory Management for Efficient Memory Throttling Handling in LLM Serving](https://arxiv.org//abs/2412.18169)

	Rongxin Cheng, Yuxin Lai, Xingda Wei, Rong Chen, Haibo Chen

# 2024-12-23
+ [Fourier Position Embedding: Enhancing Attention's Periodic Extension for Length Generalization](https://arxiv.org//abs/2412.17739)

	Ermo Hua, Che Jiang, Xingtai Lv, Kaiyan Zhang, Ning Ding, Youbang Sun, Biqing Qi, Yuchen Fan, Xuekai Zhu, Bowen Zhou

# 2024-12-22
+ [Multi-Agent Sampling: Scaling Inference Compute for Data Synthesis with Tree Search-Based Agentic Collaboration](https://arxiv.org//abs/2412.17061)

	Hai Ye, Mingbao Lin, Hwee Tou Ng, Shuicheng Yan

# 2024-12-21
+ [Beyond Partisan Leaning: A Comparative Analysis of Political Bias in Large Language Models](https://arxiv.org//abs/2412.16746)

	Tai-Quan Peng, Kaiqi Yang, Sanguk Lee, Hang Li, Yucheng Chu, Yuping Lin, Hui Liu

+ [SubData: Bridging Heterogeneous Datasets to Enable Theory-Driven Evaluation of Political and Demographic Perspectives in LLMs](https://arxiv.org//abs/2412.16783)

	Leon Fröhling, Pietro Bernardelle, Gianluca Demartini

# 2024-12-20
+ [Less is More: Towards Green Code Large Language Models via Unified Structural Pruning](https://arxiv.org//abs/2412.15921)

	Guang Yang, Yu Zhou, Xiangyu Zhang, Wei Cheng, Ke Liu, Xiang Chen, Terry Yue Zhuo, Taolue Chen


+ [XRAG: eXamining the Core -- Benchmarking Foundational Components in Advanced Retrieval-Augmented Generation](https://arxiv.org//abs/2412.15529)

	Qianren Mao, Yangyifei Luo, Qili Zhang, Yashuo Luo, Zhilong Cao, Jinlong Zhang, HanWen Hao, Zhijun Chen, Weifeng Jiang, Junnan Liu, Xiaolong Wang, Zhenting Huang, Zhixing Tan, Sun Jie, Bo Li, Xudong Liu, Richong Zhang, Jianxin Li

+ [MRAG: A Modular Retrieval Framework for Time-Sensitive Question Answering](https://arxiv.org//abs/2412.15540)

	Zhang Siyue, Xue Yuxiang, Zhang Yiming, Wu Xiaobao, Luu Anh Tuan, Zhao Chen

# 2024-12-19
+ [A Retrieval-Augmented Generation Framework for Academic Literature Navigation in Data Science](https://arxiv.org//abs/2412.15404)

	Ahmet Yasin Aytar, Kemal Kilic, Kamer Kaya

+ [Agent-SafetyBench: Evaluating the Safety of LLM Agents](https://arxiv.org//abs/2412.14470)

	Zhexin Zhang, Shiyao Cui, Yida Lu, Jingzhuo Zhou, Junxiao Yang, Hongning Wang, Minlie Huang

# 2024-12-18
+ [TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks](https://arxiv.org//abs/2412.14161)

	Frank F. Xu, Yufan Song, Boxuan Li, Yuxuan Tang, Kritanjali Jain, Mengxue Bao, Zora Z. Wang, Xuhui Zhou, Zhitong Guo, Murong Cao, Mingyang Yang, Hao Yang Lu, Amaad Martin, Zhe Su, Leander Maben, Raj Mehta, Wayne Chi, Lawrence Jang, Yiqing Xie, Shuyan Zhou, Graham Neubig

# 2024-12-17
+ [What External Knowledge is Preferred by LLMs? Characterizing and Exploring Chain of Evidence in Imperfect Context](https://arxiv.org//abs/2412.12632)

	Zhiyuan Chang, Mingyang Li, Xiaojun Jia, Junjie Wang, Yuekai Huang, Qing Wang, Yihao Huang, Yang Liu

+ [When to Speak, When to Abstain: Contrastive Decoding with Abstention](https://arxiv.org//abs/2412.12527)

	Hyuhng Joon Kim, Youna Kim, Sang-goo Lee, Taeuk Kim

+ [DateLogicQA: Benchmarking Temporal Biases in Large Language Models](https://arxiv.org//abs/2412.13377)

	Gagan Bhatia, MingZe Tang, Cristina Mahanta, Madiha Kazi

+ [Boosting LLM-based Relevance Modeling with Distribution-Aware Robust Learning](https://arxiv.org//abs/2412.12504)

	Hong Liu, Saisai Gong, Yixin Ji, Kaixin Wu, Jia Xu, Jinjie Gu

+ [Exploring Cross-lingual Latent Transplantation: Mutual Opportunities and Open Challenges](https://arxiv.org//abs/2412.12686)

	Yangfan Ye, Xiaocheng Feng, Xiachong Feng, Libo Qin, Yichong Huang, Lei Huang, Weitao Ma, Qichen Hong, Zhirui Zhang, Yunfei Lu, Xiaohui Yan, Duyu Tang, Dandan Tu, Bing Qin

+ [LITA: An Efficient LLM-assisted Iterative Topic Augmentation Framework](https://arxiv.org//abs/2412.12459)

	Chia-Hsuan Chang, Jui-Tse Tsai, Yi-Hang Tsai, San-Yih Hwang

+ [Boosting Long-Context Management via Query-Guided Activation Refilling](https://arxiv.org//abs/2412.12486)

	Hongjin Qian, Zheng Liu, Peitian Zhang, Zhicheng Dou, Defu Lian

# 2024-12-16
+ [ElChat: Adapting Chat Language Models Using Only Target Unlabeled Language Data](https://arxiv.org//abs/2412.11704)

	Atsuki Yamaguchi, Terufumi Morishita, Aline Villavicencio, Nikolaos Aletras

+ [A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method & Challenges](https://arxiv.org//abs/2412.11936)

	Yibo Yan, Jiamin Su, Jianxiang He, Fangteng Fu, Xu Zheng, Yuanhuiyi Lyu, Kun Wang, Shen Wang, Qingsong Wen, Xuming Hu

+ [UAlign: Leveraging Uncertainty Estimations for Factuality Alignment on Large Language Models](https://arxiv.org//abs/2412.11803)

	Boyang Xue, Fei Mi, Qi Zhu, Hongru Wang, Rui Wang, Sheng Wang, Erxin Yu, Xuming Hu, Kam-Fai Wong

# 2024-12-15
+ [AD-LLM: Benchmarking Large Language Models for Anomaly Detection](https://arxiv.org//abs/2412.11142)

	Tiankai Yang, Yi Nian, Shawn Li, Ruiyao Xu, Yuangang Li, Jiaqi Li, Zhuo Xiao, Xiyang Hu, Ryan Rossi, Kaize Ding, Xia Hu, Yue Zhao

+ [SceneLLM: Implicit Language Reasoning in LLM for Dynamic Scene Graph Generation](https://arxiv.org//abs/2412.11026)

	Hang Zhang, Zhuoling Li, Jun Liu

# 2024-12-14
+ [Superhuman performance of a large language model on the reasoning tasks of a physician](https://arxiv.org//abs/2412.10849)

	Peter G. Brodeur, Thomas A. Buckley, Zahir Kanjee, Ethan Goh, Evelyn Bin Ling, Priyank Jain, Stephanie Cabral, Raja-Elie Abdulnour, Adrian D. Haimovich, Jason A. Freed, Andrew Olson, Daniel J. Morgan, Jason Hom, Robert Gallo, Liam G. McCoy, Haadi Mombini, Christopher Lucas, Misha Fotoohi, Matthew Gwiazdon, Daniele Restifo, Daniel Restrepo, Eric Horvitz, Jonathan Chen, Arjun K. Manrai, Adam Rodman

# 2024-12-13
+ [You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary Projects](https://arxiv.org//abs/2412.10133)

	Islem Bouzenia, Michael Pradel

+ [ROUTE: Robust Multitask Tuning and Collaboration for Text-to-SQL](https://arxiv.org//abs/2412.10138)

	Yang Qin, Chao Chen, Zhihang Fu, Ze Chen, Dezhong Peng, Peng Hu, Jieping Ye

# 2024-12-12
+ [Dial-In LLM: Human-Aligned LLM-in-the-loop Intent Clustering for Customer Service Dialogues](https://arxiv.org//abs/2412.09049)

	Mengze Hong, Wailing Ng, Chen Jason Zhang, Yuanfeng Song, Di Jiang

# 2024-12-10
+ [A Causal World Model Underlying Next Token Prediction: Exploring GPT in a Controlled Environment](https://arxiv.org//abs/2412.07446)

	Raanan Y. Rohekar, Yaniv Gurwicz, Sungduk Yu, Estelle Aflalo, Vasudev Lal

+ [AutoPrep: Natural Language Question-Aware Data Preparation with a Multi-Agent Framework](https://arxiv.org//abs/2412.10422)

	Meihao Fan, Ju Fan, Nan Tang, Lei Cao, Guoliang Li, Xiaoyong Du

+ [MoE-CAP: Benchmarking Cost, Accuracy and Performance of Sparse Mixture-of-Experts Systems](https://arxiv.org//abs/2412.07067)

	Yinsicheng Jiang, Yao Fu, Yeqi Huang, Ping Nie, Zhan Lu, Leyang Xue, Congjie He, Man-Kit Sit, Jilong Xue, Li Dong, Ziming Miao, Dayou Du, Tairan Xu, Kai Zou, Edoardo Ponti, Luo Mai

# 2024-12-09
+ [MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization](https://arxiv.org//abs/2412.06141)

	Kangyu Zhu, Peng Xia, Yun Li, Hongtu Zhu, Sheng Wang, Huaxiu Yao

+ [ProcessBench: Identifying Process Errors in Mathematical Reasoning](https://arxiv.org//abs/2412.06559)

	Chujie Zheng, Zhenru Zhang, Beichen Zhang, Runji Lin, Keming Lu, Bowen Yu, Dayiheng Liu, Jingren Zhou, Junyang Lin

+ [A Comparative Study of Learning Paradigms in Large Language Models via Intrinsic Dimension](https://arxiv.org//abs/2412.06245)

	Saahith Janapati, Yangfeng Ji

+ [Evaluating LLM-based Approaches to Legal Citation Prediction: Domain-specific Pre-training, Fine-tuning, or RAG? A Benchmark and an Australian Law Case Study](https://arxiv.org//abs/2412.06272)

	Jiuzhou Han, Paul Burgess, Ehsan Shareghi

# 2024-12-07
+ [SLA Management in Reconfigurable Multi-Agent RAG: A Systems Approach to Question Answering](https://arxiv.org//abs/2412.06832)

	Michael Iannelli, Sneha Kuchipudi, Vera Dvorak

+ [KG-Retriever: Efficient Knowledge Indexing for Retrieval-Augmented Large Language Models](https://arxiv.org//abs/2412.05547)

	Weijie Chen, Ting Bai, Jinbo Su, Jian Luan, Wei Liu, Chuan Shi

+ [Training-Free Bayesianization for Low-Rank Adapters of Large Language Models](https://arxiv.org//abs/2412.05723)

	Haizhou Shi, Yibin Wang, Ligong Han, Huan Zhang, Hao Wang

# 2024-12-06
+ [Multi-Party Supervised Fine-tuning of Language Models for Multi-Party Dialogue Generation](https://arxiv.org//abs/2412.05342)

	Xiaoyu Wang, Ningyuan Xi, Teng Chen, Qingqing Gu, Yue Zhao, Xiaokai Chen, Zhonglin Jiang, Yong Chen, Luo Ji

+ [ChatNVD: Advancing Cybersecurity Vulnerability Assessment with Large Language Models](https://arxiv.org//abs/2412.04756)

	Shivansh Chopra, Hussain Ahmad, Diksha Goel, Claudia Szabo

# 2024-12-05
+ [Extractive Structures Learned in Pretraining Enable Generalization on Finetuned Facts](https://arxiv.org//abs/2412.04614)

	Jiahai Feng, Stuart Russell, Jacob Steinhardt

# 2024-12-03
+ [Enhancing LLMs with Smart Preprocessing for EHR Analysis](https://arxiv.org//abs/2412.02868)

	Yixiang Qu, Yifan Dai, Shilin Yu, Pradham Tanikella, Travis Schrank, Trevor Hackman, Didong Li, Di Wu


+ [DP-2Stage: Adapting Language Models as Differentially Private Tabular Data Generators](https://arxiv.org//abs/2412.02467)

	Tejumade Afonja, Hui-Po Wang, Raouf Kerkouche, Mario Fritz

# 2024-12-02
+ [Mastering Board Games by External and Internal Planning with Language Models](https://arxiv.org//abs/2412.12119)

	John Schultz, Jakub Adamek, Matej Jusup, Marc Lanctot, Michael Kaisers, Sarah Perrin, Daniel Hennes, Jeremy Shar, Cannada Lewis, Anian Ruoss, Tom Zahavy, Petar Veličković, Laurel Prince, Satinder Singh, Eric Malmi, Nenad Tomašev

+ [FastRM: An efficient and automatic explainability framework for multimodal generative models](https://arxiv.org//abs/2412.01487)

	Gabriela Ben-Melech Stan, Estelle Aflalo, Man Luo, Shachar Rosenman, Tiep Le, Sayak Paul, Shao-Yen Tseng, Vasudev Lal

+ [Beyond Text-Visual Attention: Exploiting Visual Cues for Effective Token Pruning in VLMs](https://arxiv.org//abs/2412.01818)

	Qizhe Zhang, Aosong Cheng, Ming Lu, Renrui Zhang, Zhiyong Zhuo, Jiajun Cao, Shaobo Guo, Qi She, Shanghang Zhang

# 2024-12-01
+ [Competition Dynamics Shape Algorithmic Phases of In-Context Learning](https://arxiv.org//abs/2412.01003)

	Core Francisco Park, Ekdeep Singh Lubana, Itamar Pres, Hidenori Tanaka

# 2024-11-29
+ [Simple and Provable Scaling Laws for the Test-Time Compute of Large Language Models](https://arxiv.org//abs/2411.19477)

	Yanxi Chen, Xuchen Pan, Yaliang Li, Bolin Ding, Jingren Zhou

+ [VLSBench: Unveiling Visual Leakage in Multimodal Safety](https://arxiv.org//abs/2411.19939)

	Xuhao Hu, Dongrui Liu, Hao Li, Xuanjing Huang, Jing Shao

+ [Initialization using Update Approximation is a Silver Bullet for Extremely Efficient Low-Rank Fine-Tuning](https://arxiv.org//abs/2411.19557)

	Kaustubh Ponkshe, Raghav Singhal, Eduard Gorbunov, Alexey Tumanov, Samuel Horvath, Praneeth Vepakomma

# 2024-11-28
+ [Personalized Federated Fine-Tuning for LLMs via Data-Driven Heterogeneous Model Architectures](https://arxiv.org//abs/2411.19128)

	Yicheng Zhang, Zhen Qin, Zhaomin Wu, Jian Hou, Shuiguang Deng

# 2024-11-26
+ [ThreatModeling-LLM: Automating Threat Modeling using Large Language Models for Banking System](https://arxiv.org//abs/2411.17058)

	Tingmin Wu, Shuiqiao Yang, Shigang Liu, David Nguyen, Seung Jang, Alsharif Abuadbba

+ [Not All Adapters Matter: Selective Adapter Freezing for Memory-Efficient Fine-Tuning of Language Models](https://arxiv.org//abs/2412.03587)

	Hyegang Son, Yonglak Son, Changhoon Kim, Young Geun Kim

+ [Can LLMs be Good Graph Judge for Knowledge Graph Construction?](https://arxiv.org//abs/2411.17388)

	Haoyu Huang, Chong Chen, Zeang Sheng, Yang Li, Wentao Zhang

# 2024-11-25
+ [Multi-modal Retrieval Augmented Multi-modal Generation: Datasets, Evaluation Metrics and Strong Baselines](https://arxiv.org//abs/2411.16365)

	Zi-Ao Ma, Tian Lan, Rong-Cheng Tu, Yong Hu, Yu-Shi Zhu, Tong Zhang, Heyan Huang, Zhijing Wu, Xian-Ling Mao

# 2024-11-22
+ [XGrammar: Flexible and Efficient Structured Generation Engine for Large Language Models](https://arxiv.org//abs/2411.15100)

	Yixin Dong, Charlie F. Ruan, Yaxing Cai, Ruihang Lai, Ziyi Xu, Yilong Zhao, Tianqi Chen

+ [KBAlign: Efficient Self Adaptation on Specific Knowledge Bases](https://arxiv.org//abs/2411.14790)

	Zheni Zeng, Yuxuan Chen, Shi Yu, Ruobing Wang, Yukun Yan, Zhenghao Liu, Shuo Wang, Xu Han, Zhiyuan Liu, Maosong Sun

# 2024-11-21
+ [Insight-V: Exploring Long-Chain Visual Reasoning with Multimodal Large Language Models](https://arxiv.org//abs/2411.14432)

	Yuhao Dong, Zuyan Liu, Hai-Long Sun, Jingkang Yang, Winston Hu, Yongming Rao, Ziwei Liu

+ [Enhancing LLMs for Power System Simulations: A Feedback-driven Multi-agent Framework](https://arxiv.org//abs/2411.16707)

	Mengshuo Jia, Zeyu Cui, Gabriela Hug

+ [Velocitune: A Velocity-based Dynamic Domain Reweighting Method for Continual Pre-training](https://arxiv.org//abs/2411.14318)

	Zheheng Luo, Xin Zhang, Xiao Liu, Haoling Li, Yeyun Gong, Chen Qi, Peng Cheng

+ [Planning-Driven Programming: A Large Language Model Programming Workflow](https://arxiv.org//abs/2411.14503)

	Chao Lei, Yanchuan Chang, Nir Lipovetzky, Krista A. Ehinger

# 2024-11-20
+ [Disentangling Memory and Reasoning Ability in Large Language Models](https://arxiv.org//abs/2411.13504)

	Mingyu Jin, Weidi Luo, Sitao Cheng, Xinyi Wang, Wenyue Hua, Ruixiang Tang, William Yang Wang, Yongfeng Zhang

# 2024-11-19
+ [The Moral Mind(s) of Large Language Models](https://arxiv.org//abs/2412.04476)

	Avner Seror

# 2024-11-18
+ [PEEK: Phishing Evolution Framework for Phishing Generation and Evolving Pattern Analysis using Large Language Models](https://arxiv.org//abs/2411.11389)

	Fengchao Chen, Tingmin Wu, Van Nguyen, Shuo Wang, Alsharif Abuadbba, Carsten Rudolph

+ [PSPO*: An Effective Process-supervised Policy Optimization for Reasoning Alignment](https://arxiv.org//abs/2411.11681)

	Jiawei Li, Xinyue Liang, Junlong Zhang, Yizhe Yang, Chong Feng, Yang Gao

+ [VersaTune: An Efficient Data Composition Framework for Training Multi-Capability LLMs](https://arxiv.org//abs/2411.11266)

	Keer Lu, Keshi Zhao, Zhuoran Zhang, Zheng Liang, Da Pan, Shusen Zhang, Xin Wu, Guosheng Dong, Bin Cui, Tengjiao Wang, Wentao Zhang

+ [Steering Language Model Refusal with Sparse Autoencoders](https://arxiv.org//abs/2411.11296)

	Kyle O'Brien, David Majercak, Xavier Fernandes, Richard Edgar, Blake Bullwinkel, Jingya Chen, Harsha Nori, Dean Carignan, Eric Horvitz, Forough Poursabzi-Sangde

# 2024-11-17
+ [JailbreakLens: Interpreting Jailbreak Mechanism in the Lens of Representation and Circuit](https://arxiv.org//abs/2411.11114)

	Zeqing He, Zhibo Wang, Zhixuan Chu, Huiyu Xu, Wenhui Zhang, Qinglong Wang, Rui Zheng


+ [SRA-MCTS: Self-driven Reasoning Augmentation with Monte Carlo Tree Search for Code Generation](https://arxiv.org//abs/2411.11053)

	Bin Xu, Yiguan Lin, Yinghao Li, Yang Gao

+ [FastDraft: How to Train Your Draft](https://arxiv.org//abs/2411.11055)

	Ofir Zafrir, Igor Margulis, Dorin Shteyman, Shira Guskin, Guy Boudoukh

# 2024-11-14
+ [Rethinking Weight-Averaged Model-merging](https://arxiv.org//abs/2411.09263)

	Hu Wang, Congbo Ma, Ibrahim Almakky, Ian Reid, Gustavo Carneiro, Mohammad Yaqub

# 2024-11-12
+ [Knowledge-Augmented Multimodal Clinical Rationale Generation for Disease Diagnosis with Small Language Models](https://arxiv.org//abs/2411.07611)

	Shuai Niu, Jing Ma, Hongzhan Lin, Liang Bai, Zhihua Wang, Yida Xu, Yunya Song, Xian Yang

+ [Beyond the Safety Bundle: Auditing the Helpful and Harmless Dataset](https://arxiv.org//abs/2411.08243)

	Khaoula Chehbouni, Jonathan Colaço Carr, Yash More, Jackie CK Cheung, Golnoosh Farnadi

+ [Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for Knowledge Graph Completion](https://arxiv.org//abs/2411.08165)

	Muzhi Li, Cehao Yang, Chengjin Xu, Xuhui Jiang, Yiyan Qi, Jian Guo, Ho-fung Leung, Irwin King

+ [ImageRAG: Enhancing Ultra High Resolution Remote Sensing Imagery Analysis with ImageRAG](https://arxiv.org//abs/2411.07688)

	Zilun Zhang, Haozhan Shen, Tiancheng Zhao, Zian Guan, Bin Chen, Yuhao Wang, Xu Jia, Yuxiang Cai, Yongheng Shang, Jianwei Yin

# 2024-11-10
+ [An Efficient Matrix Multiplication Algorithm for Accelerating Inference in Binary and Ternary Neural Networks](https://arxiv.org//abs/2411.06360)

	Mohsen Dehghankar, Mahdi Erfanian, Abolfazl Asudeh

# 2024-11-09
+ [A Picture is Worth A Thousand Numbers: Enabling LLMs Reason about Time Series via Visualization](https://arxiv.org//abs/2411.06018)

	Haoxin Liu, Chenghao Liu, B. Aditya Prakash

# 2024-11-08
+ [LLM-PySC2: Starcraft II learning environment for Large Language Models](https://arxiv.org//abs/2411.05348)

	Zongyuan Li, Yanan Ni, Runnan Qi, Lumin Jiang, Chang Lu, Xiaojie Xu, Xiangbei Liu, Pengfei Li, Yunzheng Guo, Zhe Ma, Huanyu Li, Hui Wu, Xian Guo, Kuihua Huang, Xuebo Zhang

# 2024-11-07
+ [Prompt-Guided Internal States for Hallucination Detection of Large Language Models](https://arxiv.org//abs/2411.04847)

	Fujie Zhang, Peiqi Yu, Biao Yi, Baolei Zhang, Tong Li, Zheli Liu

# 2024-11-06
+ [LSHBloom: Memory-efficient, Extreme-scale Document Deduplication](https://arxiv.org//abs/2411.04257)

	Arham Khan, Robert Underwood, Carlo Siebenschuh, Yadu Babuji, Aswathy Ajith, Kyle Hippe, Ozan Gokdemir, Alexander Brace, Kyle Chard, Ian Foster

# 2024-11-04
+ [Sparsing Law: Towards Large Language Models with Greater Activation Sparsity](https://arxiv.org//abs/2411.02335)

	Yuqi Luo, Chenyang Song, Xu Han, Yingfa Chen, Chaojun Xiao, Zhiyuan Liu, Maosong Sun

# 2024-11-03
+ [Enhancing LLM Evaluations: The Garbling Trick](https://arxiv.org//abs/2411.01533)

	William F. Bradley

+ [Rate, Explain and Cite (REC): Enhanced Explanation and Attribution in Automatic Evaluation by Large Language Models](https://arxiv.org//abs/2411.02448)

	Aliyah R. Hsu, James Zhu, Zhichao Wang, Bin Bi, Shubham Mehrotra, Shiva K. Pentyala, Katherine Tan, Xiang-Bo Mao, Roshanak Omrani, Sougata Chaudhuri, Regunathan Radhakrishnan, Sitaram Asur, Claire Na Cheng, Bin Yu

+ [Graph-based Confidence Calibration for Large Language Models](https://arxiv.org//abs/2411.02454)

	Yukun Li, Sijia Wang, Lifu Huang, Li-Ping Liu

# 2024-11-01
+ [E2E-AFG: An End-to-End Model with Adaptive Filtering for Retrieval-Augmented Generation](https://arxiv.org//abs/2411.00437)

	Yun Jiang, Zilong Xie, Wei Zhang, Yun Fang, Shuai Pan

+ [Phase Diagram of Vision Large Language Models Inference: A Perspective from Interaction across Image and Instruction](https://arxiv.org//abs/2411.00646)

	Houjing Wei, Yuting Shi, Naoya Inoue

# 2024-10-31
+ [AlphaTrans: A Neuro-Symbolic Compositional Approach for Repository-Level Code Translation and Validation](https://arxiv.org//abs/2410.24117)

	Ali Reza Ibrahimzada, Kaiyao Ke, Mrigank Pawagi, Muhammad Salman Abid, Rangeet Pan, Saurabh Sinha, Reyhaneh Jabbarvand

+ [Constraint Back-translation Improves Complex Instruction Following of Large Language Models](https://arxiv.org//abs/2410.24175)

	Yunjia Qi, Hao Peng, Xiaozhi Wang, Bin Xu, Lei Hou, Juanzi Li

# 2024-10-30
+ [MDCure: A Scalable Pipeline for Multi-Document Instruction-Following](https://arxiv.org//abs/2410.23463)

	Gabrielle Kaili-May Liu, Bowen Shi, Avi Caciularu, Idan Szpektor, Arman Cohan

# 2024-10-29
+ [Personalization of Large Language Models: A Survey](https://arxiv.org//abs/2411.00027)

	Zhehao Zhang, Ryan A. Rossi, Branislav Kveton, Yijia Shao, Diyi Yang, Hamed Zamani, Franck Dernoncourt, Joe Barrow, Tong Yu, Sungchul Kim, Ruiyi Zhang, Jiuxiang Gu, Tyler Derr, Hongjie Chen, Junda Wu, Xiang Chen, Zichao Wang, Subrata Mitra, Nedim Lipka, Nesreen Ahmed, Yu Wang

+ [Unlearning as multi-task optimization: A normalized gradient difference approach with an adaptive learning rate](https://arxiv.org//abs/2410.22086)

	Zhiqi Bu, Xiaomeng Jin, Bhanukiran Vinzamuri, Anil Ramakrishna, Kai-Wei Chang, Volkan Cevher, Mingyi Hong

+ [Vision-Language Models Create Cross-Modal Task Representations](https://arxiv.org//abs/2410.22330)

	Grace Luo, Trevor Darrell, Amir Bar

+ [SceneGenAgent: Precise Industrial Scene Generation with Coding Agent](https://arxiv.org//abs/2410.21909)

	Xiao Xia, Dan Zhang, Zibo Liao, Zhenyu Hou, Tianrui Sun, Jing Li, Ling Fu, Yuxiao Dong

+ [Let's Be Self-generated via Step by Step: A Curriculum Learning Approach to Automated Reasoning with Large Language Models](https://arxiv.org//abs/2410.21728)

	Kangyang Luo, Zichen Ding, Zhenmin Weng, Lingfeng Qiao, Meng Zhao, Xiang Li, Di Yin, Jinlong Shu

+ [Understanding Synthetic Context Extension via Retrieval Heads](https://arxiv.org//abs/2410.22316)

	Xinyu Zhao, Fangcong Yin, Greg Durrett

+ [AAAR-1.0: Assessing AI's Potential to Assist Research](https://arxiv.org//abs/2410.22394)

	Renze Lou, Hanzi Xu, Sijia Wang, Jiangshu Du, Ryo Kamoi, Xiaoxin Lu, Jian Xie, Yuxuan Sun, Yusen Zhang, Jihyun Janice Ahn, Hongchao Fang, Zhuoyang Zou, Wenchao Ma, Xi Li, Kai Zhang, Congying Xia, Lifu Huang, Wenpeng Yin

# 2024-10-28
+ [Are LLM-Judges Robust to Expressions of Uncertainty? Investigating the effect of Epistemic Markers on LLM-based Evaluation](https://arxiv.org//abs/2410.20774)

	Dongryeol Lee, Yerin Hwang, Yongil Kim, Joonsuk Park, Kyomin Jung

+ [Arithmetic Without Algorithms: Language Models Solve Math With a Bag of Heuristics](https://arxiv.org//abs/2410.21272)

	Yaniv Nikankin, Anja Reusch, Aaron Mueller, Yonatan Belinkov

+ [Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning](https://arxiv.org//abs/2410.20926)

	Aosong Feng, Rex Ying, Leandros Tassiulas

# 2024-10-26
+ [Agentic Feedback Loop Modeling Improves Recommendation and User Simulation](https://arxiv.org//abs/2410.20027)

	Shihao Cai, Jizhi Zhang, Keqin Bao, Chongming Gao, Qifan Wang, Fuli Feng, Xiangnan He

# 2024-10-25
+ [Can We Trust AI Agents? A Case Study of an LLM-Based Multi-Agent System for Ethical AI](https://arxiv.org//abs/2411.08881)

	José Antonio Siqueira de Cerqueira, Mamia Agbese, Rebekah Rousi, Nannan Xi, Juho Hamari, Pekka Abrahamsson

+ [ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Contrastive Framework](https://arxiv.org//abs/2410.19453)

	Hengyuan Zhang, Chenming Shang, Sizhe Wang, Dongdong Zhang, Feng Yao, Renliang Sun, Yiyao Yu, Yujiu Yang, Furu Wei

# 2024-10-24
+ [Parameter-Efficient Fine-Tuning in Large Models: A Survey of Methodologies](https://arxiv.org//abs/2410.19878)

	Luping Wang, Sheng Chen, Linnan Jiang, Shu Pan, Runze Cai, Sen Yang, Fei Yang

+ [Hybrid Preferences: Learning to Route Instances for Human vs. AI Feedback](https://arxiv.org//abs/2410.19133)

	Lester James V. Miranda, Yizhong Wang, Yanai Elazar, Sachin Kumar, Valentina Pyatkin, Faeze Brahman, Noah A. Smith, Hannaneh Hajishirzi, Pradeep Dasigi

# 2024-10-22
+ [Do Robot Snakes Dream like Electric Sheep? Investigating the Effects of Architectural Inductive Biases on Hallucination](https://arxiv.org//abs/2410.17477)

	Jerry Huang, Prasanna Parthasarathi, Mehdi Rezagholizadeh, Boxing Chen, Sarath Chandar

# 2024-10-21
+ [Long Term Memory: The Foundation of AI Self-Evolution](https://arxiv.org//abs/2410.15665)

	Xun Jiang, Feng Li, Han Zhao, Jiahao Qiu, Jiaying Wang, Jun Shao, Shihao Xu, Shu Zhang, Weiling Chen, Xavier Tang, Yize Chen, Mengyue Wu, Weizhi Ma, Mengdi Wang, Tianqiao Chen

+ [Training of Scaffolded Language Models with Language Supervision: A Survey](https://arxiv.org//abs/2410.16392)

	Matthieu Lin, Jenny Sheng, Andrew Zhao, Shenzhi Wang, Yang Yue, Victor Shea Jay Huang, Huan Liu, Jun Liu, Gao Huang, Yong-Jin Liu

+ [Security of Language Models for Code: A Systematic Literature Review](https://arxiv.org//abs/2410.15631)

	Yuchen Chen, Weisong Sun, Chunrong Fang, Zhenpeng Chen, Yifei Ge, Tingxu Han, Quanjun Zhang, Yang Liu, Zhenyu Chen, Baowen Xu

+ [Exploring Pretraining via Active Forgetting for Improving Cross Lingual Transfer for Decoder Language Models](https://arxiv.org//abs/2410.16168)

	Divyanshu Aggarwal, Ashutosh Sathe, Sunayana Sitaram

+ [When LLMs Learn to be Students: The SOEI Framework for Modeling and Evaluating Virtual Student Agents in Educational Interaction](https://arxiv.org//abs/2410.15701)

	Yiping Ma, Shiyu Hu, Xuchen Li, Yipei Wang, Yuqing Chen, Shiqing Liu, Kang Hao Cheong

# 2024-10-19
+ [TrendFact: A Benchmark for Explainable Hotspot Perception in Fact-Checking with Natural Language Explanation](https://arxiv.org//abs/2410.15135)

	Xiaocheng Zhang, Xi Wang, Yifei Lu, Jianing Wang, Zhuangzhuang Ye, Mengjiao Bao, Peng Yan, Xiaohong Su

# 2024-10-18
+ [ELOQ: Resources for Enhancing LLM Detection of Out-of-Scope Questions](https://arxiv.org//abs/2410.14567)

	Zhiyuan Peng, Jinming Nian, Alexandre Evfimievski, Yi Fang

+ [Electrocardiogram-Language Model for Few-Shot Question Answering with Meta Learning](https://arxiv.org//abs/2410.14464)

	Jialu Tang, Tong Xia, Yuan Lu, Cecilia Mascolo, Aaqib Saeed

+ [DiSCo: LLM Knowledge Distillation for Efficient Sparse Retrieval in Conversational Search](https://arxiv.org//abs/2410.14609)

	Simon Lupart, Mohammad Aliannejadi, Evangelos Kanoulas

# 2024-10-17
+ [MobA: Multifaceted Memory-Enhanced Adaptive Planning for Efficient Mobile Task Automation](https://arxiv.org//abs/2410.13757)

	Zichen Zhu, Hao Tang, Yansi Li, Dingye Liu, Hongshen Xu, Kunyao Lan, Danyang Zhang, Yixuan Jiang, Hao Zhou, Chenrun Wang, Situo Zhang, Liangtai Sun, Yixiao Wang, Yuheng Sun, Lu Chen, Kai Yu

+ [How Does Knowledge Selection Help Retrieval Augmented Generation?](https://arxiv.org//abs/2410.13258)

	Xiangci Li, Jessica Ouyang

+ [The Mystery of the Pathological Path-star Task for Language Models](https://arxiv.org//abs/2410.13779)

	Arvid Frydenlund

+ [Retrospective Learning from Interactions](https://arxiv.org//abs/2410.13852)

	Zizhao Chen, Mustafa Omer Gul, Yiwei Chen, Gloria Geng, Anne Wu, Yoav Artzi

+ [MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling](https://arxiv.org//abs/2410.13610)

	Yakun Zhu, Shaohang Wei, Xu Wang, Kui Xue, Xiaofan Zhang, Shaoting Zhang

# 2024-10-16
+ [TradExpert: Revolutionizing Trading with Mixture of Expert LLMs](https://arxiv.org//abs/2411.00782)

	Qianggang Ding, Haochen Shi, Jiadong Guo, Bang Liu

+ [MatryoshkaKV: Adaptive KV Compression via Trainable Orthogonal Projection](https://arxiv.org//abs/2410.14731)

	Bokai Lin, Zihao Zeng, Zipeng Xiao, Siqi Kou, Tianqi Hou, Xiaofeng Gao, Hao Zhang, Zhijie Deng

+ [Interpreting token compositionality in LLMs: A robustness analysis](https://arxiv.org//abs/2410.12924)

	Nura Aljaafari, Danilo S. Carvalho, André Freitas

+ [Meta-Chunking: Learning Text Segmentation and Semantic Completion via Logical Perception](https://arxiv.org//abs/2410.12788)

	Jihao Zhao, Zhiyuan Ji, Yuchen Feng, Pengnian Qi, Simin Niu, Bo Tang, Feiyu Xiong, Zhiyu Li

+ [KCIF: Knowledge-Conditioned Instruction Following](https://arxiv.org//abs/2410.12972)

	Rudra Murthy, Praveen Venkateswaran, Prince Kumar, Danish Contractor

# 2024-10-15
+ [MIND: Math Informed syNthetic Dialogues for Pretraining LLMs](https://arxiv.org//abs/2410.12881)

	Syeda Nahida Akter, Shrimai Prabhumoye, John Kamalu, Sanjeev Satheesh, Eric Nyberg, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro

+ [TopoLM: brain-like spatio-functional organization in a topographic language model](https://arxiv.org//abs/2410.11516)

	Neil Rathi, Johannes Mehrer, Badr AlKhamissi, Taha Binhuraib, Nicholas M. Blauch, Martin Schrimpf

+ [TestAgent: A Framework for Domain-Adaptive Evaluation of LLMs via Dynamic Benchmark Construction and Exploratory Interaction](https://arxiv.org//abs/2410.11507)

	Wanying Wang, Zeyu Ma, Pengfei Liu, Mingang Chen

+ [RATE: Causal Explainability of Reward Models with Imperfect Counterfactuals](https://arxiv.org//abs/2410.11348)

	David Reber, Sean Richardson, Todd Nief, Cristina Garbacea, Victor Veitch

# 2024-10-14
+ [A Unified Approach to Routing and Cascading for LLMs](https://arxiv.org//abs/2410.10347)

	Jasper Dekoninck, Maximilian Baader, Martin Vechev

# 2024-10-13
+ [Self-Data Distillation for Recovering Quality in Pruned Large Language Models](https://arxiv.org//abs/2410.09982)

	Vithursan Thangarasa, Ganesh Venkatesh, Mike Lasby, Nish Sinnadurai, Sean Lie

# 2024-10-12
+ [Inference and Verbalization Functions During In-Context Learning](https://arxiv.org//abs/2410.09349)

	Junyi Tao, Xiaoyin Chen, Nelson F. Liu

+ [Keys to Robust Edits: from Theoretical Insights to Practical Advances](https://arxiv.org//abs/2410.09338)

	Jianhao Yan, Futing Wang, Yun Luo, Yafu Li, Yue Zhang

# 2024-10-10
+ [Extracting and Transferring Abilities For Building Multi-lingual Ability-enhanced Large Language Models](https://arxiv.org//abs/2410.07825)

	Zhipeng Chen, Kun Zhou, Liang Song, Wayne Xin Zhao, Bingning Wang, Weipeng Chen, Ji-Rong Wen

+ [A Closer Look at Machine Unlearning for Large Language Models](https://arxiv.org//abs/2410.08109)

	Xiaojian Yuan, Tianyu Pang, Chao Du, Kejiang Chen, Weiming Zhang, Min Lin

+ [Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study Over Open-ended Question Answering](https://arxiv.org//abs/2410.08085)

	Yuan Sui, Yufei He, Zifeng Ding, Bryan Hooi

# 2024-10-09
+ [Let's Ask GNN: Empowering Large Language Model for Graph In-Context Learning](https://arxiv.org//abs/2410.07074)

	Zhengyu Hu, Yichuan Li, Zhengyu Chen, Jingang Wang, Han Liu, Kyumin Lee, Kaize Ding

+ [Steering Large Language Models using Conceptors: Improving Addition-Based Activation Engineering](https://arxiv.org//abs/2410.16314)

	Joris Postmus, Steven Abreu

+ [CursorCore: Assist Programming through Aligning Anything](https://arxiv.org//abs/2410.07002)

	Hao Jiang, Qi Liu, Rui Li, Shengyu Ye, Shijin Wang

+ [ST-WebAgentBench: A Benchmark for Evaluating Safety and Trustworthiness in Web Agents](https://arxiv.org//abs/2410.06703)

	Ido Levy, Ben Wiesel, Sami Marreed, Alon Oved, Avi Yaeli, Segev Shlomov

# 2024-10-08
+ [Large Continual Instruction Assistant](https://arxiv.org//abs/2410.10868)

	Jingyang Qiao, Zhizhong Zhang, Xin Tan, Yanyun Qu, Shouhong Ding, Yuan Xie

+ [Structural Reasoning Improves Molecular Understanding of LLM](https://arxiv.org//abs/2410.05610)

	Yunhui Jang, Jaehyung Kim, Sungsoo Ahn

# 2024-10-07
+ [GLEE: A Unified Framework and Benchmark for Language-based Economic Environments](https://arxiv.org//abs/2410.05254)

	Eilam Shapira, Omer Madmon, Itamar Reinman, Samuel Joseph Amouyal, Roi Reichart, Moshe Tennenholtz

# 2024-10-06
+ [Regressing the Relative Future: Efficient Policy Optimization for Multi-turn RLHF](https://arxiv.org//abs/2410.04612)

	Zhaolin Gao, Wenhao Zhan, Jonathan D. Chang, Gokul Swamy, Kianté Brantley, Jason D. Lee, Wen Sun


+ [Evaluating the Correctness of Inference Patterns Used by LLMs for Judgment](https://arxiv.org//abs/2410.09083)

	Lu Chen, Yuxuan Huang, Yixing Li, Dongrui Liu, Qihan Ren, Shuai Zhao, Kun Kuang, Zilong Zheng, Quanshi Zhang

# 2024-10-05
+ [Domain-Oriented Time Series Inference Agents for Reasoning and Automated Analysis](https://arxiv.org//abs/2410.04047)

	Wen Ye, Wei Yang, Defu Cao, Yizhou Zhang, Lumingyuan Tang, Jie Cai, Yan Liu

# 2024-10-04
+ [Understanding Large Language Models in Your Pockets: Performance Study on COTS Mobile Devices](https://arxiv.org//abs/2410.03613)

	Jie Xiao, Qianyi Huang, Xu Chen, Chen Tian

+ [Look Twice Before You Answer: Memory-Space Visual Retracing for Hallucination Mitigation in Multimodal Large Language Models](https://arxiv.org//abs/2410.03577)

	Xin Zou, Yizhou Wang, Yibo Yan, Yuanhuiyi Lyu, Kening Zheng, Sirui Huang, Junkai Chen, Peijie Jiang, Jia Liu, Chang Tang, Xuming Hu

+ [Decoding Game: On Minimax Optimality of Heuristic Text Generation Strategies](https://arxiv.org//abs/2410.03968)

	Sijin Chen, Omar Hagrass, Jason M. Klusowski

+ [Learning from Committee: Reasoning Distillation from a Mixture of Teachers with Peer-Review](https://arxiv.org//abs/2410.03663)

	Zhuochun Li, Yuelyu Ji, Rui Meng, Daqing He

+ [Permissive Information-Flow Analysis for Large Language Models](https://arxiv.org//abs/2410.03055)

	Shoaib Ahmed Siddiqui, Radhika Gaonkar, Boris Köpf, David Krueger, Andrew Paverd, Ahmed Salem, Shruti Tople, Lukas Wutschitz, Menglin Xia, Santiago Zanella-Béguelin

+ [MLLM as Retriever: Interactively Learning Multimodal Retrieval for Embodied Agents](https://arxiv.org//abs/2410.03450)

	Junpeng Yue, Xinrun Xu, Börje F. Karlsson, Zongqing Lu

# 2024-10-03
+ [Selective Attention Improves Transformer](https://arxiv.org//abs/2410.02703)

	Yaniv Leviathan, Matan Kalman, Yossi Matias


+ [A Formal Framework for Understanding Length Generalization in Transformers](https://arxiv.org//abs/2410.02140)

	Xinting Huang, Andy Yang, Satwik Bhattamishra, Yash Sarrof, Andreas Krebs, Hattie Zhou, Preetum Nakkiran, Michael Hahn

+ [Theoretical Insights into Fine-Tuning Attention Mechanism: Generalization and Optimization](https://arxiv.org//abs/2410.02247)

	Xinhao Yao, Hongjin Qian, Xiaolin Hu, Gengze Xu, Wei Liu, Jian Luan, Bin Wang, Yong Liu

+ [IoT-LLM: Enhancing Real-World IoT Task Reasoning with Large Language Models](https://arxiv.org//abs/2410.02429)

	Tuo An, Yunjiao Zhou, Han Zou, Jianfei Yang

+ [Optimizing Adaptive Attacks against Watermarks for Language Models](https://arxiv.org//abs/2410.02440)

	Abdulrahman Diaa, Toluwani Aremu, Nils Lukas

+ [Discovering Spoofing Attempts on Language Model Watermarks](https://arxiv.org//abs/2410.02693)

	Thibaud Gloaguen, Nikola Jovanović, Robin Staab, Martin Vechev

# 2024-10-02
+ [TypedThinker: Diversify Large Language Model Reasoning with Typed Thinking](https://arxiv.org//abs/2410.01952)

	Danqing Wang, Jianxin Ma, Fei Fang, Lei Li


+ [Racing Thoughts: Explaining Contextualization Errors in Large Language Models](https://arxiv.org//abs/2410.02102)

	Michael A. Lepori, Michael C. Mozer, Asma Ghandeharioun

+ [Moral Alignment for LLM Agents](https://arxiv.org//abs/2410.01639)

	Elizaveta Tennant, Stephen Hailes, Mirco Musolesi

# 2024-09-30
+ [Beyond Single Concept Vector: Modeling Concept Subspace in LLMs with Gaussian Distribution](https://arxiv.org//abs/2410.00153)

	Haiyan Zhao, Heng Zhao, Bo Shen, Ali Payani, Fan Yang, Mengnan Du

+ [Characterizing and Efficiently Accelerating Multimodal Generation Model Inference](https://arxiv.org//abs/2410.00215)

	Yejin Lee, Anna Sun, Basil Hosmer, Bilge Acun, Can Balioglu, Changhan Wang, Charles David Hernandez, Christian Puhrsch, Daniel Haziza, Driss Guessous, Francisco Massa, Jacob Kahn, Jeffrey Wan, Jeremy Reizenstein, Jiaqi Zhai, Joe Isaacson, Joel Schlosser, Juan Pino, Kaushik Ram Sadagopan, Leonid Shamis, Linjian Ma, Min-Jae Hwang, Mingda Chen, Mostafa Elhoushi, Pedro Rodriguez, Ram Pasunuru, Scott Yih, Sravya Popuri, Xing Liu, Carole-Jean Wu

+ [SSR: Alignment-Aware Modality Connector for Speech Language Models](https://arxiv.org//abs/2410.00168)

	Weiting Tan, Hirofumi Inaguma, Ning Dong, Paden Tomasello, Xutai Ma

# 2024-09-27
+ [Can LLMs Really Learn to Translate a Low-Resource Language from One Grammar Book?](https://arxiv.org//abs/2409.19151)

	Seth Aycock, David Stap, Di Wu, Christof Monz, Khalil Sima'an

+ [Mitigating Selection Bias with Node Pruning and Auxiliary Options](https://arxiv.org//abs/2409.18857)

	Hyeong Kyu Choi, Weijie Xu, Chi Xue, Stephanie Eckman, Chandan K. Reddy

# 2024-09-26
+ [Benign Overfitting in Token Selection of Attention Mechanism](https://arxiv.org//abs/2409.17625)

	Keitaro Sakamoto, Issei Sato

# 2024-09-25
+ [AXIS: Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents](https://arxiv.org//abs/2409.17140)

	Junting Lu, Zhiyang Zhang, Fangkai Yang, Jue Zhang, Lu Wang, Chao Du, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang

+ [Judgment-of-Thought Prompting: A Courtroom-Inspired Framework for Binary Logical Reasoning with Large Language Models](https://arxiv.org//abs/2409.16635)

	Sungjune Park, Heehwan Kim, Haehyun Cho, Daeseon Choi

# 2024-09-23
+ [Scideator: Human-LLM Scientific Idea Generation Grounded in Research-Paper Facet Recombination](https://arxiv.org//abs/2409.14634)

	Marissa Radensky, Simra Shahid, Raymond Fok, Pao Siangliulue, Tom Hope, Daniel S. Weld

+ [Revise, Reason, and Recognize: LLM-Based Emotion Recognition via Emotion-Specific Prompts and ASR Error Correction](https://arxiv.org//abs/2409.15551)

	Yuanchao Li, Yuan Gong, Chao-Han Huck Yang, Peter Bell, Catherine Lai

+ [MediConfusion: Can you trust your AI radiologist? Probing the reliability of multimodal medical foundation models](https://arxiv.org//abs/2409.15477)

	Mohammad Shahab Sepehri, Zalan Fabian, Maryam Soltanolkotabi, Mahdi Soltanolkotabi

# 2024-09-22
+ [Position IDs Matter: An Enhanced Position Layout for Efficient Context Compression in Large Language Models](https://arxiv.org//abs/2409.14364)

	Runsong Zhao, Xin Liu, Xinyu Liu, Pengcheng Huang, Chunyang Xiao, Tong Xiao, Jingbo Zhu

# 2024-09-20
+ [Time Awareness in Large Language Models: Benchmarking Fact Recall Across Time](https://arxiv.org//abs/2409.13338)

	David Herel, Vojtech Bartek, Jiri Jirak, Tomas Mikolov

# 2024-09-19
+ [Prompts Are Programs Too! Understanding How Developers Build Software Containing Prompts](https://arxiv.org//abs/2409.12447)

	Jenny T. Liang, Melissa Lin, Nikitha Rao, Brad A. Myers

+ [Strategic Collusion of LLM Agents: Market Division in Multi-Commodity Competitions](https://arxiv.org//abs/2410.00031)

	Ryan Y. Lin, Siddhartha Ojha, Kevin Cai, Maxwell F. Chen

# 2024-09-18
+ [To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning](https://arxiv.org//abs/2409.12183)

	Zayne Sprague, Fangcong Yin, Juan Diego Rodriguez, Dongwei Jiang, Manya Wadhwa, Prasann Singhal, Xinyu Zhao, Xi Ye, Kyle Mahowald, Greg Durrett

+ [Revealing and Mitigating the Challenge of Detecting Character Knowledge Errors in LLM Role-Playing](https://arxiv.org//abs/2409.11726)

	Wenyuan Zhang, Shuaiyi Nie, Jiawei Sheng, Zefeng Zhang, Xinghua Zhang, Yongquan He, Tingwen Liu

+ [From Lists to Emojis: How Format Bias Affects Model Alignment](https://arxiv.org//abs/2409.11704)

	Xuanchang Zhang, Wei Xiong, Lichang Chen, Tianyi Zhou, Heng Huang, Tong Zhang

# 2024-09-17
+ [Measuring and Enhancing Trustworthiness of LLMs in RAG through Grounded Attributions and Learning to Refuse](https://arxiv.org//abs/2409.11242)

	Maojia Song, Shang Hong Sim, Rishabh Bhardwaj, Hai Leong Chieu, Navonil Majumder, Soujanya Poria

+ [Exploring the Trade-Offs: Quantization Methods, Task Difficulty, and Model Size in Large Language Models From Edge to Giant](https://arxiv.org//abs/2409.11055)

	Jemin Lee, Sihyeong Park, Jinse Kwon, Jihun Oh, Yongin Kwon

+ [Task Arithmetic for Language Expansion in Speech Translation](https://arxiv.org//abs/2409.11274)

	Yao-Fei Cheng, Hayato Futami, Yosuke Kashiwagi, Emiru Tsunoo, Wen Shen Teo, Siddhant Arora, Shinji Watanabe

# 2024-09-16
+ [Lab-AI: Using Retrieval Augmentation to Enhance Language Models for Personalized Lab Test Interpretation in Clinical Medicine](https://arxiv.org//abs/2409.18986)

	Xiaoyu Wang, Haoyong Ouyang, Balu Bhasuran, Xiao Luo, Karim Hanna, Mia Liza A. Lustria, Carl Yang, Zhe He


# 2024-09-14
+ [Hacking, The Lazy Way: LLM Augmented Pentesting](https://arxiv.org//abs/2409.09493)

	Dhruva Goyal, Sitaraman Subramanian, Aditya Peela, Nisha P. Shetty

# 2024-09-13
+ [Your Weak LLM is Secretly a Strong Teacher for Alignment](https://arxiv.org//abs/2409.08813)

	Leitian Tao, Yixuan Li

# 2024-09-12
+ [Fine-tuning Large Language Models for Entity Matching](https://arxiv.org//abs/2409.08185)

	Aaron Steiner, Ralph Peeters, Christian Bizer

# 2024-09-10
+ [LaMsS: When Large Language Models Meet Self-Skepticism](https://arxiv.org//abs/2409.06601)

	Yetao Wu, Yihong Wang, Teng Chen, Ningyuan Xi, Qingqing Gu, Hongyang Lei, Luo Ji

# 2024-09-07
+ [Reward Guidance for Reinforcement Learning Tasks Based on Large Language Models: The LMGT Framework](https://arxiv.org//abs/2409.04744)

	Yongxin Deng, Xihe Qiu, Jue Chen, Xiaoyu Tan

# 2024-09-06
+ [From Calculation to Adjudication: Examining LLM judges on Mathematical Reasoning Tasks](https://arxiv.org//abs/2409.04168)

	Andreas Stephan, Dawei Zhu, Matthias Aßenmacher, Xiaoyu Shen, Benjamin Roth

# 2024-09-04
+ [NESTFUL: A Benchmark for Evaluating LLMs on Nested Sequences of API Calls](https://arxiv.org//abs/2409.03797)

	Kinjal Basu, Ibrahim Abdelaziz, Kiran Kate, Mayank Agarwal, Maxwell Crouse, Yara Rizk, Kelsey Bradford, Asim Munawar, Sadhana Kumaravel, Saurabh Goyal, Xin Wang, Luis A. Lastras, Pavan Kapanipathi

# 2024-09-03
+ [Efficient LLM Context Distillation](https://arxiv.org//abs/2409.01930)

	Rajesh Upadhayayaya, Manish Raj Osti, Zachary Smith, Chritopher Kottmyer

+ [What are the Essential Factors in Crafting Effective Long Context Multi-Hop Instruction Datasets? Insights and Best Practices](https://arxiv.org//abs/2409.01893)

	Zhi Chen, Qiguang Chen, Libo Qin, Qipeng Guo, Haijun Lv, Yicheng Zou, Wanxiang Che, Hang Yan, Kai Chen, Dahua Lin

# 2024-08-30
+ [Training Ultra Long Context Language Model with Fully Pipelined Distributed Transformer](https://arxiv.org//abs/2408.16978)

	Jinghan Yao, Sam Ade Jacobs, Masahiro Tanaka, Olatunji Ruwase, Hari Subramoni, Dhabaleswar K. Panda

# 2024-08-26
+ [CHARTOM: A Visual Theory-of-Mind Benchmark for Multimodal Large Language Models](https://arxiv.org//abs/2408.14419)

	Shubham Bharti, Shiyun Cheng, Jihyun Rho, Jianrui Zhang, Mu Cai, Yong Jae Lee, Martina Rau, Xiaojin Zhu

# 2024-08-22
+ [LLMs are not Zero-Shot Reasoners for Biomedical Information Extraction](https://arxiv.org//abs/2408.12249)

	Aishik Nagar, Viktor Schlegel, Thanh-Tung Nguyen, Hao Li, Yuping Wu, Kuluhan Binici, Stefan Winkler

# 2024-08-20
+ [Enhancing Robustness in Large Language Models: Prompting for Mitigating the Impact of Irrelevant Information](https://arxiv.org//abs/2408.10615)

	Ming Jiang, Tingting Huang, Biao Guo, Yao Lu, Feng Zhang

# 2024-08-19
+ [Kubrick: Multimodal Agent Collaborations for Synthetic Video Generation](https://arxiv.org//abs/2408.10453)

	Liu He, Yizhi Song, Hejun Huang, Pinxin Liu, Yunlong Tang, Daniel Aliaga, Xin Zhou

+ [Bridging the Language Gap: Enhancing Multilingual Prompt-Based Code Generation in LLMs via Zero-Shot Cross-Lingual Transfer](https://arxiv.org//abs/2408.09701)

	Mingda Li, Abhijit Mishra, Utkarsh Mujumdar

# 2024-08-16
+ [Turning Trash into Treasure: Accelerating Inference of Large Language Models with Token Recycling](https://arxiv.org//abs/2408.08696)

	Xianzhen Luo, Yixuan Wang, Qingfu Zhu, Zhiming Zhang, Xuanyu Zhang, Qing Yang, Dongliang Xu

# 2024-08-13
+ [Bridging LLMs and KGs without Fine-Tuning: Intermediate Probing Meets Subgraph-Aware Entity Descriptions](https://arxiv.org//abs/2408.06787)

	Bo Xue, Yi Xu, Yunchong Song, Yiming Pang, Yuyang Ren, Jiaxin Ding, Luoyi Fu, Xinbing Wang

# 2024-08-12
+ [Does Liking Yellow Imply Driving a School Bus? Semantic Leakage in Language Models](https://arxiv.org//abs/2408.06518)

	Hila Gonen, Terra Blevins, Alisa Liu, Luke Zettlemoyer, Noah A. Smith

# 2024-08-10
+ [SWIFT:A Scalable lightWeight Infrastructure for Fine-Tuning](https://arxiv.org//abs/2408.05517)

	Yuze Zhao, Jintao Huang, Jinghan Hu, Xingjun Wang, Yunlin Mao, Daoze Zhang, Hong Zhang, Zeyinzi Jiang, Zhikai Wu, Baole Ai, Ang Wang, Wenmeng Zhou, Yingda Chen

# 2024-08-09
+ [Order Matters in Hallucination: Reasoning Order as Benchmark and Reflexive Prompting for Large-Language-Models](https://arxiv.org//abs/2408.05093)

	Zikai Xie

# 2024-08-08
+ [The Struggles of LLMs in Cross-lingual Code Clone Detection](https://arxiv.org//abs/2408.04430)

	Micheline Bénédicte Moumoula, Abdoul Kader Kabore, Jacques Klein, Tegawendé Bissyande

# 2024-08-07
+ [A Logical Fallacy-Informed Framework for Argument Generation](https://arxiv.org//abs/2408.03618)

	Luca Mouchel, Debjit Paul, Shaobo Cui, Robert West, Antoine Bosselut, Boi Faltings

# 2024-08-02
+ [CFBench: A Comprehensive Constraints-Following Benchmark for LLMs](https://arxiv.org//abs/2408.01122)

	Tao Zhang, Chenglin Zhu, Yanjun Shen, Wenjing Luo, Yan Zhang, Hao Liang, Tao Zhang, Fan Yang, Mingan Lin, Yujing Qiao, Weipeng Chen, Bin Cui, Wentao Zhang, Zenan Zhou

# 2024-07-31
+ [Correcting Negative Bias in Large Language Models through Negative Attention Score Alignment](https://arxiv.org//abs/2408.00137)

	Sangwon Yu, Jongyoon Song, Bongkyu Hwang, Hoyoung Kang, Sooah Cho, Junhwa Choi, Seongho Joe, Taehee Lee, Youngjune L. Gwon, Sungroh Yoon

+ [SAKR: Enhancing Retrieval-Augmented Generation via Streaming Algorithm and K-Means Clustering](https://arxiv.org//abs/2407.21300)

	Haoyu Kang (1), Yuzhou Zhu (2), Yukun Zhong (3), Ke Wang (4) ((1) Central South University, (2) Dalian University of Technology, (3) Nanjing University, (4) Xidian University)

# 2024-07-29
+ [Genetic Instruct: Scaling up Synthetic Generation of Coding Instructions for Large Language Models](https://arxiv.org//abs/2407.21077)

	Somshubra Majumdar, Vahid Noroozi, Mehrzad Samadi, Sean Narenthiran, Aleksander Ficek, Wasi Uddin Ahmad, Jocelyn Huang, Jagadeesh Balam, Boris Ginsburg

# 2024-07-26
+ [Patched MOA: optimizing inference for diverse software development tasks](https://arxiv.org//abs/2407.18521)

	Asankhaya Sharma

+ [ClinicRealm: Re-evaluating Large Language Models with Conventional Machine Learning for Non-Generative Clinical Prediction Tasks](https://arxiv.org//abs/2407.18525)

	Yinghao Zhu, Junyi Gao, Zixiang Wang, Weibin Liao, Xiaochen Zheng, Lifang Liang, Miguel O. Bernabeu, Yasha Wang, Lequan Yu, Chengwei Pan, Ewen M. Harrison, Liantao Ma

# 2024-07-25
+ [PersonaGym: Evaluating Persona Agents and LLMs](https://arxiv.org//abs/2407.18416)

	Vinay Samuel, Henry Peng Zou, Yue Zhou, Shreyas Chaudhari, Ashwin Kalyan, Tanmay Rajpurohit, Ameet Deshpande, Karthik Narasimhan, Vishvak Murahari

# 2024-07-23
+ [Patched RTC: evaluating LLMs for diverse software development tasks](https://arxiv.org//abs/2407.16557)

	Asankhaya Sharma

# 2024-07-22
+ [Compensate Quantization Errors+: Quantized Models Are Inquisitive Learners](https://arxiv.org//abs/2407.15508)

	Yifei Gao, Jie Ou, Lei Wang, Jun Cheng, Mengchu Zhou

# 2024-07-21
+ [A Practical Analysis of Human Alignment with *PO](https://arxiv.org//abs/2407.15229)

	Kian Ahrabian, Xihui Lin, Barun Patra, Vishrav Chaudhary, Alon Benhaim, Jay Pujara, Xia Song

# 2024-07-17
+ [PersLLM: A Personified Training Approach for Large Language Models](https://arxiv.org//abs/2407.12393)

	Zheni Zeng, Jiayi Chen, Huimin Chen, Yukun Yan, Yuxuan Chen, Zhenghao Liu, Zhiyuan Liu, Maosong Sun

+ [Conversational Query Reformulation with the Guidance of Retrieved Documents](https://arxiv.org//abs/2407.12363)

	Jeonghyun Park, Hwanhee Lee

# 2024-07-16
+ [NeedleBench: Can LLMs Do Retrieval and Reasoning in Information-Dense Context?](https://arxiv.org//abs/2407.11963)

	Mo Li, Songyang Zhang, Taolin Zhang, Haodong Duan, Yunxin Liu, Kai Chen

+ [A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting](https://arxiv.org//abs/2407.11638)

	He Chang, Chenchen Ye, Zhulin Tao, Jie Wu, Zhengmao Yang, Yunshan Ma, Xianglin Huang, Tat-Seng Chua

# 2024-07-11
+ [How Well Can a Long Sequence Model Model Long Sequences? Comparing Architechtural Inductive Biases on Long-Context Abilities](https://arxiv.org//abs/2407.08112)

	Jerry Huang

# 2024-07-10
+ [EfficientQAT: Efficient Quantization-Aware Training for Large Language Models](https://arxiv.org//abs/2407.11062)

	Mengzhao Chen, Wenqi Shao, Peng Xu, Jiahao Wang, Peng Gao, Kaipeng Zhang, Ping Luo

# 2024-07-05
+ [AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents](https://arxiv.org//abs/2407.04363)

	Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Andrey Kravchenko, Mikhail Burtsev, Evgeny Burnaev

# 2024-07-02
+ [A Bounding Box is Worth One Token: Interleaving Layout and Text in a Large Language Model for Document Understanding](https://arxiv.org//abs/2407.01976)

	Jinghui Lu, Haiyang Yu, Yanjie Wang, Yongjie Ye, Jingqun Tang, Ziwei Yang, Binghong Wu, Qi Liu, Hao Feng, Han Wang, Hao Liu, Can Huang

+ [Helpful assistant or fruitful facilitator? Investigating how personas affect language model behavior](https://arxiv.org//abs/2407.02099)

	Pedro Henrique Luz de Araujo, Benjamin Roth

# 2024-07-01
+ [Large Language Models Are Involuntary Truth-Tellers: Exploiting Fallacy Failure for Jailbreak Attacks](https://arxiv.org//abs/2407.00869)

	Yue Zhou, Henry Peng Zou, Barbara Di Eugenio, Yang Zhang

+ [Ground Every Sentence: Improving Retrieval-Augmented LLMs with Interleaved Reference-Claim Generation](https://arxiv.org//abs/2407.01796)

	Sirui Xia, Xintao Wang, Jiaqing Liang, Yifei Zhang, Weikang Zhou, Jiaji Deng, Fei Yu, Yanghua Xiao

# 2024-06-28
+ [Scaling Synthetic Data Creation with 1,000,000,000 Personas](https://arxiv.org//abs/2406.20094)

	Tao Ge, Xin Chan, Xiaoyang Wang, Dian Yu, Haitao Mi, Dong Yu

+ [LLMEasyQuant: Scalable Quantization for Parallel and Distributed LLM Inference](https://arxiv.org//abs/2406.19657)

	Dong Liu, Yanxuan Yu

# 2024-06-26
+ [Is In-Context Learning a Type of Error-Driven Learning? Evidence from the Inverse Frequency Effect in Structural Priming](https://arxiv.org//abs/2406.18501)

	Zhenghao Zhou, Robert Frank, R. Thomas McCoy

# 2024-06-25
+ [OPT-Tree: Speculative Decoding with Adaptive Draft Tree Structure](https://arxiv.org//abs/2406.17276)

	Jikai Wang, Yi Su, Juntao Li, Qingrong Xia, Zi Ye, Xinyu Duan, Zhefeng Wang, Min Zhang


+ [Recite, Reconstruct, Recollect: Memorization in LMs as a Multifaceted Phenomenon](https://arxiv.org//abs/2406.17746)

	USVSN Sai Prashanth, Alvin Deng, Kyle O'Brien, Jyothir S V, Mohammad Aflah Khan, Jaydeep Borkar, Christopher A. Choquette-Choo, Jacob Ray Fuehne, Stella Biderman, Tracy Ke, Katherine Lee, Naomi Saphra

+ [From Distributional to Overton Pluralism: Investigating Large Language Model Alignment](https://arxiv.org//abs/2406.17692)

	Thom Lake, Eunsol Choi, Greg Durrett

+ [Brittle Minds, Fixable Activations: Understanding Belief Representations in Language Models](https://arxiv.org//abs/2406.17513)

	Matteo Bortoletto, Constantin Ruhdorfer, Lei Shi, Andreas Bulling

# 2024-06-24
+ [Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging](https://arxiv.org//abs/2406.16330)

	Deyuan Liu, Zhanyue Qin, Hairu Wang, Zhao Yang, Zecheng Wang, Fangying Rong, Qingbin Liu, Yanchao Hao, Xi Chen, Cunhang Fan, Zhao Lv, Zhiying Tu, Dianhui Chu, Bo Li, Dianbo Sui

# 2024-06-20
+ [ReaL: Efficient RLHF Training of Large Language Models with Parameter Reallocation](https://arxiv.org//abs/2406.14088)

	Zhiyu Mei, Wei Fu, Kaiwei Li, Guangju Wang, Huanchen Zhang, Yi Wu

+ [APEER: Automatic Prompt Engineering Enhances Large Language Model Reranking](https://arxiv.org//abs/2406.14449)

	Can Jin, Hongwu Peng, Shiyu Zhao, Zhenting Wang, Wujiang Xu, Ligong Han, Jiahui Zhao, Kai Zhong, Sanguthevar Rajasekaran, Dimitris N. Metaxas

+ [Tracing Representation Progression: Analyzing and Enhancing Layer-Wise Similarity](https://arxiv.org//abs/2406.14479)

	Jiachen Jiang, Jinxin Zhou, Zhihui Zhu

# 2024-06-18
+ [Exploring the Robustness of Language Models for Tabular Question Answering via Attention Analysis](https://arxiv.org//abs/2406.12719)

	Kushal Raj Bhandari, Sixue Xing, Soham Dan, Jianxi Gao

# 2024-06-17
+ [SPA-VL: A Comprehensive Safety Preference Alignment Dataset for Vision Language Model](https://arxiv.org//abs/2406.12030)

	Yongting Zhang, Lu Chen, Guodong Zheng, Yifeng Gao, Rui Zheng, Jinlan Fu, Zhenfei Yin, Senjie Jin, Yu Qiao, Xuanjing Huang, Feng Zhao, Tao Gui, Jing Shao

# 2024-06-16
+ [ShareLoRA: Parameter Efficient and Robust Large Language Model Fine-tuning via Shared Low-Rank Adaptation](https://arxiv.org//abs/2406.10785)

	Yurun Song, Junchen Zhao, Ian G. Harris, Sangeetha Abdu Jyothi

# 2024-06-15
+ [Unlocking Large Language Model's Planning Capabilities with Maximum Diversity Fine-tuning](https://arxiv.org//abs/2406.10479)

	Wenjun Li, Changyu Chen, Pradeep Varakantham

+ [Task Facet Learning: A Structured Approach to Prompt Optimization](https://arxiv.org//abs/2406.10504)

	Gurusha Juneja, Gautam Jajoo, Nagarajan Natarajan, Hua Li, Jian Jiao, Amit Sharma

+ [BlockPruner: Fine-grained Pruning for Large Language Models](https://arxiv.org//abs/2406.10594)

	Longguang Zhong, Fanqi Wan, Ruijun Chen, Xiaojun Quan, Liangzhi Li

# 2024-06-14
+ [Recent Advances in Federated Learning Driven Large Language Models: A Survey on Architecture, Performance, and Security](https://arxiv.org//abs/2406.09831)

	Youyang Qu, Ming Liu, Tianqing Zhu, Longxiang Gao, Shui Yu, Wanlei Zhou

# 2024-06-13
+ [Talking Heads: Understanding Inter-layer Communication in Transformer Language Models](https://arxiv.org//abs/2406.09519)

	Jack Merullo, Carsten Eickhoff, Ellie Pavlick

+ [Online Bandit Learning with Offline Preference Data for Improved RLHF](https://arxiv.org//abs/2406.09574)

	Akhil Agnihotri, Rahul Jain, Deepak Ramachandran, Zheng Wen

# 2024-06-12
+ [Enhancing Differential Testing With LLMs For Testing Deep Learning Libraries](https://arxiv.org//abs/2406.07944)

	Meiziniu Li, Dongze Li, Jianmeng Liu, Jialun Cao, Yongqiang Tian, Shing-Chi Cheung

+ [Watermarking Language Models with Error Correcting Codes](https://arxiv.org//abs/2406.10281)

	Patrick Chao, Yan Sun, Edgar Dobriban, Hamed Hassani

# 2024-06-11
+ [RS-Agent: Automating Remote Sensing Tasks through Intelligent Agent](https://arxiv.org//abs/2406.07089)

	Wenjia Xu, Zijian Yu, Boyang Mu, Zhiwei Wei, Yuanben Zhang, Guangzuo Li, Mugen Peng

# 2024-06-10
+ [Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching](https://arxiv.org//abs/2406.06326)

	Xiaoying Zhang, Baolin Peng, Ye Tian, Jingyan Zhou, Yipeng Zhang, Haitao Mi, Helen Meng

# 2024-06-05
+ [Item-Language Model for Conversational Recommendation](https://arxiv.org//abs/2406.02844)

	Li Yang, Anushya Subbiah, Hardik Patel, Judith Yue Li, Yanwei Song, Reza Mirghaderi, Vikram Aggarwal, Qifan Wang

# 2024-06-04
+ [PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling](https://arxiv.org//abs/2406.02069)

	Zefan Cai, Yichi Zhang, Bofei Gao, Yuliang Liu, Yucheng Li, Tianyu Liu, Keming Lu, Wayne Xiong, Yue Dong, Junjie Hu, Wen Xiao

+ [MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset](https://arxiv.org//abs/2406.02106)

	Weiqi Wang, Yangqiu Song

+ [Mitigate Position Bias in Large Language Models via Scaling a Single Dimension](https://arxiv.org//abs/2406.02536)

	Yijiong Yu, Huiqiang Jiang, Xufang Luo, Qianhui Wu, Chin-Yew Lin, Dongsheng Li, Yuqing Yang, Yongfeng Huang, Lili Qiu

# 2024-06-03
+ [Re-ReST: Reflection-Reinforced Self-Training for Language Agents](https://arxiv.org//abs/2406.01495)

	Zi-Yi Dou, Cheng-Fu Yang, Xueqing Wu, Kai-Wei Chang, Nanyun Peng

+ [REvolve: Reward Evolution with Large Language Models using Human Feedback](https://arxiv.org//abs/2406.01309)

	Rishi Hazra, Alkis Sygkounas, Andreas Persson, Amy Loutfi, Pedro Zuidberg Dos Martires

# 2024-05-31
+ [OR-Bench: An Over-Refusal Benchmark for Large Language Models](https://arxiv.org//abs/2405.20947)

	Justin Cui, Wei-Lin Chiang, Ion Stoica, Cho-Jui Hsieh

# 2024-05-30
+ [Uncovering Bias in Large Vision-Language Models at Scale with Counterfactuals](https://arxiv.org//abs/2405.20152)

	Phillip Howard, Kathleen C. Fraser, Anahita Bhiwandiwalla, Svetlana Kiritchenko

# 2024-05-29
+ [Nearest Neighbor Speculative Decoding for LLM Generation and Attribution](https://arxiv.org//abs/2405.19325)

	Minghan Li, Xilun Chen, Ari Holtzman, Beidi Chen, Jimmy Lin, Wen-tau Yih, Xi Victoria Lin

# 2024-05-24
+ [Emergence of a High-Dimensional Abstraction Phase in Language Transformers](https://arxiv.org//abs/2405.15471)

	Emily Cheng, Diego Doimo, Corentin Kervadec, Iuri Macocco, Jade Yu, Alessandro Laio, Marco Baroni

+ [Sparse Matrix in Large Language Model Fine-tuning](https://arxiv.org//abs/2405.15525)

	Haoze He, Juncheng Billy Li, Xuan Jiang, Heather Miller

# 2024-05-23
+ [OAC: Output-adaptive Calibration for Accurate Post-training Quantization](https://arxiv.org//abs/2405.15025)

	Ali Edalati, Alireza Ghaffari, Mahsa Ghazvini Nejad, Lu Hou, Boxing Chen, Masoud Asgharian, Vahid Partovi Nia

+ [LoRA-Ensemble: Efficient Uncertainty Modelling for Self-Attention Networks](https://arxiv.org//abs/2405.14438)

	Dominik J. Mühlematter, Michelle Halbheer, Alexander Becker, Dominik Narnhofer, Helge Aasen, Konrad Schindler, Mehmet Ozgur Turkoglu

# 2024-05-22
+ [FiDeLiS: Faithful Reasoning in Large Language Model for Knowledge Graph Question Answering](https://arxiv.org//abs/2405.13873)

	Yuan Sui, Yufei He, Nian Liu, Xiaoxin He, Kun Wang, Bryan Hooi

# 2024-05-20
+ [(Perhaps) Beyond Human Translation: Harnessing Multi-Agent Collaboration for Translating Ultra-Long Literary Texts](https://arxiv.org//abs/2405.11804)

	Minghao Wu, Jiahao Xu, Yulin Yuan, Gholamreza Haffari, Longyue Wang, Weihua Luo, Kaifu Zhang

# 2024-05-17
+ [ActiveLLM: Large Language Model-based Active Learning for Textual Few-Shot Scenarios](https://arxiv.org//abs/2405.10808)

	Markus Bayer, Justin Lutz, Christian Reuter

# 2024-05-08
+ [Large Language Models for Cyber Security: A Systematic Literature Review](https://arxiv.org//abs/2405.04760)

	Hanxiang Xu, Shenao Wang, Ningke Li, Kailong Wang, Yanjie Zhao, Kai Chen, Ting Yu, Yang Liu, Haoyu Wang

# 2024-05-07
+ [QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving](https://arxiv.org//abs/2405.04532)

	Yujun Lin, Haotian Tang, Shang Yang, Zhekai Zhang, Guangxuan Xiao, Chuang Gan, Song Han

+ [Folded Context Condensation in Path Integral Formalism for Infinite Context Transformers](https://arxiv.org//abs/2405.04620)

	Won-Gi Paeng, Daesuk Kwon, Kyungwon Jeong, Honggyo Suh

+ [Fleet of Agents: Coordinated Problem Solving with Large Language Models](https://arxiv.org//abs/2405.06691)

	Lars Klein, Nearchos Potamitis, Roland Aydin, Robert West, Caglar Gulcehre, Akhil Arora

# 2024-05-06
+ [Outlier Gradient Analysis: Efficiently Identifying Detrimental Training Samples for Deep Learning Models](https://arxiv.org//abs/2405.03869)

	Anshuman Chhabra, Bo Li, Jian Chen, Prasant Mohapatra, Hongfu Liu

# 2024-05-03
+ [CodeGRAG: Bridging the Gap between Natural Language and Programming Language via Graphical Retrieval Augmented Generation](https://arxiv.org//abs/2405.02355)

	Kounianhua Du, Jizheng Chen, Renting Rui, Huacan Chai, Lingyue Fu, Wei Xia, Yasheng Wang, Ruiming Tang, Yong Yu, Weinan Zhang

# 2024-04-29
+ [DPO Meets PPO: Reinforced Token Optimization for RLHF](https://arxiv.org//abs/2404.18922)

	Han Zhong, Zikang Shan, Guhao Feng, Wei Xiong, Xinle Cheng, Li Zhao, Di He, Jiang Bian, Liwei Wang

+ [A Framework for Real-time Safeguarding the Text Generation of Large Language Model](https://arxiv.org//abs/2404.19048)

	Ximing Dong, Dayi Lin, Shaowei Wang, Ahmed E. Hassan

# 2024-04-27
+ [Temporal Scaling Law for Large Language Models](https://arxiv.org//abs/2404.17785)

	Yizhe Xiong, Xiansheng Chen, Xin Ye, Hui Chen, Zijia Lin, Haoran Lian, Zhenpeng Su, Wei Huang, Jianwei Niu, Jungong Han, Guiguang Ding

# 2024-04-26
+ [Large Language Model Agent as a Mechanical Designer](https://arxiv.org//abs/2404.17525)

	Yayati Jadhav, Amir Barati Farimani

+ [PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction in Murder Mystery Games](https://arxiv.org//abs/2404.17662)

	Qinglin Zhu, Runcong Zhao, Bin Liang, Jinhua Du, Lin Gui, Yulan He

# 2024-04-25
+ [Towards Adapting Open-Source Large Language Models for Expert-Level Clinical Note Generation](https://arxiv.org//abs/2405.00715)

	Hanyin Wang, Chufan Gao, Bolun Liu, Qiping Xu, Guleid Hussein, Mohamad El Labban, Kingsley Iheasirim, Hariprasad Korsapati, Chuck Outcalt, Jimeng Sun

# 2024-04-18
+ [Lean Copilot: Large Language Models as Copilots for Theorem Proving in Lean](https://arxiv.org//abs/2404.12534)

	Peiyang Song, Kaiyu Yang, Anima Anandkumar

# 2024-04-17
+ [Offset Unlearning for Large Language Models](https://arxiv.org//abs/2404.11045)

	James Y. Huang, Wenxuan Zhou, Fei Wang, Fred Morstatter, Sheng Zhang, Hoifung Poon, Muhao Chen

# 2024-04-06
+ [Multilingual Brain Surgeon: Large Language Models Can be Compressed Leaving No Language Behind](https://arxiv.org//abs/2404.04748)

	Hongchuan Zeng, Hongshen Xu, Lu Chen, Kai Yu

# 2024-04-04
+ [PRobELM: Plausibility Ranking Evaluation for Language Models](https://arxiv.org//abs/2404.03818)

	Zhangdie Yuan, Eric Chamoun, Rami Aly, Chenxi Whitehouse, Andreas Vlachos

# 2024-03-31
+ [ParaICL: Towards Parallel In-Context Learning](https://arxiv.org//abs/2404.00570)

	Xingxuan Li, Xuan-Phi Nguyen, Shafiq Joty, Lidong Bing

+ [Algorithmic Collusion by Large Language Models](https://arxiv.org//abs/2404.00806)

	Sara Fish, Yannai A. Gonczarowski, Ran I. Shorrer

# 2024-03-28
+ [Large Language Models Are Struggle to Cope with Unreasonability in Math Problems](https://arxiv.org//abs/2403.19346)

	Jingyuan Ma, Damai Dai, Zihang Yuan, Rui li, Weilin Luo, Bin Wang, Qun Liu, Lei Sha, Zhifang Sui

# 2024-03-25
+ [AIOS: LLM Agent Operating System](https://arxiv.org//abs/2403.16971)

	Kai Mei, Xi Zhu, Wujiang Xu, Wenyue Hua, Mingyu Jin, Zelong Li, Shuyuan Xu, Ruosong Ye, Yingqiang Ge, Yongfeng Zhang

# 2024-03-21
+ [Agentic AI: The Era of Semantic Decoding](https://arxiv.org//abs/2403.14562)

	Maxime Peyrard, Martin Josifoski, Robert West

# 2024-03-19
+ [To Help or Not to Help: LLM-based Attentive Support for Human-Robot Group Interactions](https://arxiv.org//abs/2403.12533)

	Daniel Tanneberg, Felix Ocker, Stephan Hasler, Joerg Deigmoeller, Anna Belardinelli, Chao Wang, Heiko Wersing, Bernhard Sendhoff, Michael Gienger

# 2024-03-15
+ [Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning](https://arxiv.org//abs/2403.10056)

	Yongquan He, Wenyuan Zhang, Xuancheng Huang, Peng Zhang

# 2024-03-13
+ [Usable XAI: 10 Strategies Towards Exploiting Explainability in the LLM Era](https://arxiv.org//abs/2403.08946)

	Xuansheng Wu, Haiyan Zhao, Yaochen Zhu, Yucheng Shi, Fan Yang, Lijie Hu, Tianming Liu, Xiaoming Zhai, Wenlin Yao, Jundong Li, Mengnan Du, Ninghao Liu

# 2024-03-04
+ [DECIDER: A Dual-System Rule-Controllable Decoding Framework for Language Generation](https://arxiv.org//abs/2403.01954)

	Chen Xu, Tian Lan, Yu Ji, Changlong Yu, Wei Wang, Jun Gao, Qunxi Dong, Kun Qian, Piji Li, Wei Bi, Bin Hu

# 2024-02-29
+ [LoRATK: LoRA Once, Backdoor Everywhere in the Share-and-Play Ecosystem](https://arxiv.org//abs/2403.00108)

	Hongyi Liu, Shaochen Zhong, Xintong Sun, Minghao Tian, Mohsen Hariri, Zirui Liu, Ruixiang Tang, Zhimeng Jiang, Jiayi Yuan, Yu-Neng Chuang, Li Li, Soo-Hyun Choi, Rui Chen, Vipin Chaudhary, Xia Hu

+ [FlexLLM: A System for Co-Serving Large Language Model Inference and Parameter-Efficient Finetuning](https://arxiv.org//abs/2402.18789)

	Gabriele Oliaro, Xupeng Miao, Xinhao Cheng, Vineeth Kada, Ruohan Gao, Yingyi Huang, Remi Delacourt, April Yang, Yingcheng Wang, Mengdi Wu, Colin Unger, Zhihao Jia

# 2024-02-22
+ [COBIAS: Assessing the Contextual Reliability of Bias Benchmarks for Language Models](https://arxiv.org//abs/2402.14889)

	Priyanshul Govil, Hemang Jain, Vamshi Krishna Bonagiri, Aman Chadha, Ponnurangam Kumaraguru, Manas Gaur, Sanorita Dey

# 2024-02-21
+ [Round Trip Translation Defence against Large Language Model Jailbreaking Attacks](https://arxiv.org//abs/2402.13517)

	Canaan Yung, Hadi Mohaghegh Dolatabadi, Sarah Erfani, Christopher Leckie

# 2024-02-20
+ [FormulaReasoning: A Dataset for Formula-Based Numerical Reasoning](https://arxiv.org//abs/2402.12692)

	Xiao Li, Bolin Zhu, Kaiwen Shi, Sichen Liu, Yin Zhu, Yiwei Liu, Gong Cheng

# 2024-02-19
+ [Uncertainty quantification in fine-tuned LLMs using LoRA ensembles](https://arxiv.org//abs/2402.12264)

	Oleksandr Balabanov, Hampus Linander

# 2024-02-16
+ [Can We Verify Step by Step for Incorrect Answer Detection?](https://arxiv.org//abs/2402.10528)

	Xin Xu, Shizhe Diao, Can Yang, Yang Wang

# 2024-02-15
+ [CodeMind: Evaluating Large Language Models for Code Reasoning](https://arxiv.org//abs/2402.09664)

	Changshu Liu, Yang Chen, Reyhaneh Jabbarvand

# 2024-02-14
+ [How Secure Are Large Language Models (LLMs) for Navigation in Urban Environments?](https://arxiv.org//abs/2402.09546)

	Congcong Wen, Jiazhao Liang, Shuaihang Yuan, Hao Huang, Geeta Chandra Raju Bethala, Yu-Shen Liu, Mengyu Wang, Anthony Tzes, Yi Fang

# 2024-02-13
+ ["Reasoning" with Rhetoric: On the Style-Evidence Tradeoff in LLM-Generated Counter-Arguments](https://arxiv.org//abs/2402.08498)

	Preetika Verma, Kokil Jaidka, Svetlana Churina

# 2024-02-10
+ [Fiddler: CPU-GPU Orchestration for Fast Inference of Mixture-of-Experts Models](https://arxiv.org//abs/2402.07033)

	Keisuke Kamahori, Tian Tang, Yile Gu, Kan Zhu, Baris Kasikci

# 2024-02-09
+ [EntGPT: Entity Linking with Generative Large Language Models](https://arxiv.org//abs/2402.06738)

	Yifan Ding, Amrit Poudel, Qingkai Zeng, Tim Weninger, Balaji Veeramani, Sanmitra Bhattacharya

# 2024-02-05
+ [LLM Multi-Agent Systems: Challenges and Open Problems](https://arxiv.org//abs/2402.03578)

	Shanshan Han, Qifan Zhang, Yuhang Yao, Weizhao Jin, Zhaozhuo Xu

# 2024-02-02
+ [Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach](https://arxiv.org//abs/2402.01454)

	Masayuki Takayama, Tadahisa Okuda, Thong Pham, Tatsuyoshi Ikenoue, Shingo Fukuma, Shohei Shimizu, Akiyoshi Sannai

# 2024-02-01
+ [On the Challenges of Fuzzing Techniques via Large Language Models](https://arxiv.org//abs/2402.00350)

	Linghan Huang, Peizhou Zhao, Huaming Chen, Lei Ma

# 2024-01-30
+ [Incoherent Probability Judgments in Large Language Models](https://arxiv.org//abs/2401.16646)

	Jian-Qiao Zhu, Thomas L. Griffiths

# 2023-12-21
+ [Large Language Models are Miscalibrated In-Context Learners](https://arxiv.org//abs/2312.13772)

	Chengzu Li, Han Zhou, Goran Glavaš, Anna Korhonen, Ivan Vulić

# 2023-12-04
+ [LLM A*: Human in the Loop Large Language Models Enabled A* Search for Robotics](https://arxiv.org//abs/2312.01797)

	Hengjia Xiao, Peng Wang, Mingzhe Yu, Mattia Robbiani

# 2023-11-30
+ [RaDialog: A Large Vision-Language Model for Radiology Report Generation and Conversational Assistance](https://arxiv.org//abs/2311.18681)

	Chantal Pellegrini, Ege Özsoy, Benjamin Busam, Nassir Navab, Matthias Keicher

# 2023-11-16
+ [Automating the Generation of Prompts for LLM-based Action Choice in PDDL Planning](https://arxiv.org//abs/2311.09830)

	Katharina Stein, Daniel Fišer, Jörg Hoffmann, Alexander Koller

# 2023-10-20
+ [Towards Understanding Sycophancy in Language Models](https://arxiv.org//abs/2310.13548)

	Mrinank Sharma, Meg Tong, Tomasz Korbak, David Duvenaud, Amanda Askell, Samuel R. Bowman, Newton Cheng, Esin Durmus, Zac Hatfield-Dodds, Scott R. Johnston, Shauna Kravec, Timothy Maxwell, Sam McCandlish, Kamal Ndousse, Oliver Rausch, Nicholas Schiefer, Da Yan, Miranda Zhang, Ethan Perez

# 2023-10-16
+ [Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models](https://arxiv.org//abs/2310.10378)

	Jirui Qi, Raquel Fernández, Arianna Bisazza

# 2023-10-12
+ [Language Models are Universal Embedders](https://arxiv.org//abs/2310.08232)

	Xin Zhang, Zehan Li, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang, Min Zhang

# 2023-10-11
+ [CoPAL: Corrective Planning of Robot Actions with Large Language Models](https://arxiv.org//abs/2310.07263)

	Frank Joublin, Antonello Ceravola, Pavel Smirnov, Felix Ocker, Joerg Deigmoeller, Anna Belardinelli, Chao Wang, Stephan Hasler, Daniel Tanneberg, Michael Gienger


+ [QFT: Quantized Full-parameter Tuning of LLMs with Affordable Resources](https://arxiv.org//abs/2310.07147)

	Zhikai Li, Xiaoxuan Liu, Banghua Zhu, Zhen Dong, Qingyi Gu, Kurt Keutzer

# 2023-10-07
+ [Uncovering Model Processing Strategies with Non-Negative Per-Example Fisher Factorization](https://arxiv.org//abs/2310.04649)

	Michael Matena, Colin Raffel

# 2023-10-05
+ [LLM-Coordination: Evaluating and Analyzing Multi-agent Coordination Abilities in Large Language Models](https://arxiv.org//abs/2310.03903)

	Saaket Agashe, Yue Fan, Anthony Reyna, Xin Eric Wang

# 2023-09-21
+ [Automating construction contract review using knowledge graph-enhanced large language models](https://arxiv.org//abs/2309.12132)

	Chunmo Zheng, Saika Wong, Xing Su, Yinqiu Tang, Ahsan Nawaz, Mohamad Kassem

# 2023-09-15
+ [EvoPrompt: Connecting LLMs with Evolutionary Algorithms Yields Powerful Prompt Optimizers](https://arxiv.org//abs/2309.08532)

	Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song, Xu Tan, Guoqing Liu, Jiang Bian, Yujiu Yang

# 2023-08-29
+ [Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models](https://arxiv.org//abs/2308.15022)

	Qingyue Wang, Yanhe Fu, Yanan Cao, Shuai Wang, Zhiliang Tian, Liang Ding

# 2023-08-17
+ [Semantic Consistency for Assuring Reliability of Large Language Models](https://arxiv.org//abs/2308.09138)

	Harsh Raj, Vipul Gupta, Domenic Rosati, Subhabrata Majumdar

# 2023-05-26
+ [Playing repeated games with Large Language Models](https://arxiv.org//abs/2305.16867)

	Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, Eric Schulz

# 2023-05-23
+ [Physics of Language Models: Part 1, Learning Hierarchical Language Structures](https://arxiv.org//abs/2305.13673)

	Zeyuan Allen-Zhu, Yuanzhi Li

# 2023-05-01
+ [Large Linguistic Models: Investigating LLMs' metalinguistic abilities](https://arxiv.org//abs/2305.00948)

	Gašper Beguš, Maksymilian Dąbkowski, Ryan Rhodes

# 2023-03-03
+ [Prophet: Prompting Large Language Models with Complementary Answer Heuristics for Knowledge-based Visual Question Answering](https://arxiv.org//abs/2303.01903)

	Zhou Yu, Xuecheng Ouyang, Zhenwei Shao, Meng Wang, Jun Yu

# 2023-01-11
+ [Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability](https://arxiv.org//abs/2301.04709)

	Atticus Geiger, Duligur Ibeling, Amir Zur, Maheep Chaudhary, Sonakshi Chauhan, Jing Huang, Aryaman Arora, Zhengxuan Wu, Noah Goodman, Christopher Potts, Thomas Icard

