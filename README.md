# LLM-wisdom
The papers related to the LLM wisdom, including test-time scaling, knowledge editing, model recognition, capacity enhancement, RAG, Agent, internal mechanism of LLM and etc. 

# 2025-05-14
+ [Reproducibility Study of "Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents"](https://arxiv.org//abs/2505.09289)

	Pedro M. P. Curvo, Mara Dragomir, Salvador Torpes, Mohammadmahdi Rahimi

+ [The Influence of Human-inspired Agentic Sophistication in LLM-driven Strategic Reasoners](https://arxiv.org//abs/2505.09396)

	Vince Trencsenyi, Agnieszka Mensfelt, Kostas Stathis

+ [Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?](https://arxiv.org//abs/2505.09614)

	Anthony GX-Chen, Dongyan Lin, Mandana Samiei, Doina Precup, Blake A. Richards, Rob Fergus, Kenneth Marino

+ [SALM: A Multi-Agent Framework for Language Model-Driven Social Network Simulation](https://arxiv.org//abs/2505.09081)

	Gaurav Koley

+ [CEC-Zero: Chinese Error Correction Solution Based on LLM](https://arxiv.org//abs/2505.09082)

	Sophie Zhang, Zhiming Lin

+ [Human-like Cognitive Generalization for Large Models via Brain-in-the-loop Supervision](https://arxiv.org//abs/2505.09085)

	Jiaxuan Chen, Yu Qi, Yueming Wang, Gang Pan

+ [Air-Ground Collaboration for Language-Specified Missions in Unknown Environments](https://arxiv.org//abs/2505.09108)

	Fernando Cladera, Zachary Ravichandran, Jason Hughes, Varun Murali, Carlos Nieto-Granda, M. Ani Hsieh, George J. Pappas, Camillo J. Taylor, Vijay Kumar

+ [ELIS: Efficient LLM Iterative Scheduling System with Response Length Predictor](https://arxiv.org//abs/2505.09142)

	Seungbeom Choi, Jeonghoe Goo, Eunjoo Jeon, Mingyu Yang, Minsung Jang

+ [Focus, Merge, Rank: Improved Question Answering Based on Semi-structured Knowledge Bases](https://arxiv.org//abs/2505.09246)

	Derian Boer, Stephen Roth, Stefan Kramer

+ [CXMArena: Unified Dataset to benchmark performance in realistic CXM Scenarios](https://arxiv.org//abs/2505.09436)

	Raghav Garg, Kapil Sharma, Karan Gupta

+ [Deploying Foundation Model-Enabled Air and Ground Robots in the Field: Challenges and Opportunities](https://arxiv.org//abs/2505.09477)

	Zachary Ravichandran, Fernando Cladera, Jason Hughes, Varun Murali, M. Ani Hsieh, George J. Pappas, Camillo J. Taylor, Vijay Kumar

+ [WorldView-Bench: A Benchmark for Evaluating Global Cultural Perspectives in Large Language Models](https://arxiv.org//abs/2505.09595)

	Abdullah Mushtaq, Imran Taj, Rafay Naeem, Ibrahim Ghaznavi, Junaid Qadir

+ [Atomic Consistency Preference Optimization for Long-Form Question Answering](https://arxiv.org//abs/2505.09039)

	Jingfeng Chen, Raghuveer Thirukovalluru, Junlin Wang, Kaiwei Luo, Bhuwan Dhingra

+ [A Comprehensive Analysis of Large Language Model Outputs: Similarity, Diversity, and Bias](https://arxiv.org//abs/2505.09056)

	Brandon Smith, Mohamed Reda Bouadjenek, Tahsin Alamgir Kheya, Phillip Dawson, Sunil Aryal

+ [Scent of Knowledge: Optimizing Search-Enhanced Reasoning with Information Foraging](https://arxiv.org//abs/2505.09316)

	Hongjin Qian, Zheng Liu

+ [Llama See, Llama Do: A Mechanistic Perspective on Contextual Entrainment and Distraction in LLMs](https://arxiv.org//abs/2505.09338)

	Jingcheng Niu, Xingdi Yuan, Tong Wang, Hamidreza Saghir, Amir H. Abdi

+ [Qwen3 Technical Report](https://arxiv.org//abs/2505.09388)

	An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, Chujie Zheng, Dayiheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao Ge, Haoran Wei, Huan Lin, Jialong Tang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jing Zhou, Jingren Zhou, Junyang Lin, Kai Dang, Keqin Bao, Kexin Yang, Le Yu, Lianghao Deng, Mei Li, Mingfeng Xue, Mingze Li, Pei Zhang, Peng Wang, Qin Zhu, Rui Men, Ruize Gao, Shixuan Liu, Shuang Luo, Tianhao Li, Tianyi Tang, Wenbiao Yin, Xingzhang Ren, Xinyu Wang, Xinyu Zhang, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yinger Zhang, Yu Wan, Yuqiong Liu, Zekun Wang, Zeyu Cui, Zhenru Zhang, Zhipeng Zhou, Zihan Qiu

+ [PT-MoE: An Efficient Finetuning Framework for Integrating Mixture-of-Experts into Prompt Tuning](https://arxiv.org//abs/2505.09519)

	Zongqian Li, Yixuan Su, Nigel Collier

+ [Ornithologist: Towards Trustworthy "Reasoning" about Central Bank Communications](https://arxiv.org//abs/2505.09083)

	Dominic Zaun Eu Jones

+ [FaceShield: Explainable Face Anti-Spoofing with Multimodal Large Language Models](https://arxiv.org//abs/2505.09415)

	Hongyang Wang, Yichen Shi, Zhuofu Tao, Yuhao Gao, Liepiao Zhang, Xun Lin, Jun Feng, Xiaochen Yuan, Zitong Yu, Xiaochun Cao

+ [SafePath: Conformal Prediction for Safe LLM-Based Autonomous Navigation](https://arxiv.org//abs/2505.09427)

	Achref Doula, Max Mühläuser, Alejandro Sanchez Guinea

+ [Layered Unlearning for Adversarial Relearning](https://arxiv.org//abs/2505.09500)

	Timothy Qian, Vinith Suriyakumar, Ashia Wilson, Dylan Hadfield-Menell

+ [Adversarial Suffix Filtering: a Defense Pipeline for LLMs](https://arxiv.org//abs/2505.09602)

	David Khachaturov, Robert Mullins

+ [Instantiating Standards: Enabling Standard-Driven Text TTP Extraction with Evolvable Memory](https://arxiv.org//abs/2505.09261)

	Cheng Meng, ZhengWei Jiang, QiuYun Wang, XinYi Li, ChunYan Ma, FangMing Dong, FangLi Ren, BaoXu Liu

# 2025-05-13
+ [Lost in Transmission: When and Why LLMs Fail to Reason Globally](https://arxiv.org//abs/2505.08140)

	Tobias Schnabel, Kiran Tomlinson, Adith Swaminathan, Jennifer Neville

+ [Evaluating LLM Metrics Through Real-World Capabilities](https://arxiv.org//abs/2505.08253)

	Justin K Miller, Wenjia Tang

+ [Learning Like Humans: Advancing LLM Reasoning Capabilities via Adaptive Difficulty Curriculum Learning and Expert-Guided Self-Reformulation](https://arxiv.org//abs/2505.08364)

	Enci Zhang, Xingang Yan, Wei Lin, Tianxiang Zhang, Qianchun Lu

+ [Agent-as-a-Service based on Agent Network](https://arxiv.org//abs/2505.08446)

	Yuhan Zhu, Haojie Liu, Jian Wang, Bing Li, Zikang Yin, Yefei Liao

+ [Strategy-Augmented Planning for Large Language Models via Opponent Exploitation](https://arxiv.org//abs/2505.08459)

	Shuai Xu, Sijia Cui, Yanna Wang, Bo Xu, Qi Wang

+ [Achieving Scalable Robot Autonomy via neurosymbolic planning using lightweight local LLM](https://arxiv.org//abs/2505.08492)

	Nicholas Attolino, Alessio Capitanelli, Fulvio Mastrogiovanni

+ [TrialMatchAI: An End-to-End AI-powered Clinical Trial Recommendation System to Streamline Patient-to-Trial Matching](https://arxiv.org//abs/2505.08508)

	Majd Abdallah, Sigve Nakken, Mariska Bierkens, Johanna Galvis, Alexis Groppi, Slim Karkar, Lana Meiqari, Maria Alexandra Rujano, Steve Canham, Rodrigo Dienstmann, Remond Fijneman, Eivind Hovig, Gerrit Meijer, Macha Nikolski

+ [Guiding LLM-based Smart Contract Generation with Finite State Machine](https://arxiv.org//abs/2505.08542)

	Hao Luo, Yuhao Lin, Xiao Yan, Xintong Hu, Yuxiang Wang, Qiming Zeng, Hao Wang, Jiawei Jiang

+ [Resource-Efficient Language Models: Quantization for Fast and Accessible Inference](https://arxiv.org//abs/2505.08620)

	Tollef Emil Jørgensen

+ [TRAIL: Trace Reasoning and Agentic Issue Localization](https://arxiv.org//abs/2505.08638)

	Darshan Deshpande, Varun Gangal, Hersh Mehta, Jitin Krishnan, Anand Kannappan, Rebecca Qian

+ [WixQA: A Multi-Dataset Benchmark for Enterprise Retrieval-Augmented Generation](https://arxiv.org//abs/2505.08643)

	Dvir Cohen, Lin Burg, Sviatoslav Pykhnivskyi, Hagit Gur, Stanislav Kovynov, Olga Atzmon, Gilad Barkan

+ [LLM-based Prompt Ensemble for Reliable Medical Entity Recognition from EHRs](https://arxiv.org//abs/2505.08704)

	K M Sajjadul Islam, Ayesha Siddika Nipu, Jiawei Wu, Praveen Madiraju

+ [ALOHA: Empowering Multilingual Agent for University Orientation with Hierarchical Retrieval](https://arxiv.org//abs/2505.08130)

	Mingxu Tao, Bowen Tang, Mingxuan Ma, Yining Zhang, Hourun Li, Feifan Wen, Hao Ma, Jia Yang

+ [A Large-Scale Empirical Analysis of Custom GPTs' Vulnerabilities in the OpenAI Ecosystem](https://arxiv.org//abs/2505.08148)

	Sunday Oyinlola Ogundoyin, Muhammad Ikram, Hassan Jameel Asghar, Benjamin Zi Hao Zhao, Dali Kaafar

+ [Fusing Bidirectional Chains of Thought and Reward Mechanisms A Method for Enhancing Question-Answering Capabilities of Large Language Models for Chinese Intangible Cultural Heritage](https://arxiv.org//abs/2505.08167)

	Ruilin Liu, Zhixiao Zhao, Jieqiong Li, Chang Liu, Dongbo Wang

+ [A Head to Predict and a Head to Question: Pre-trained Uncertainty Quantification Heads for Hallucination Detection in LLM Outputs](https://arxiv.org//abs/2505.08200)

	Artem Shelmanov, Ekaterina Fadeeva, Akim Tsvigun, Ivan Tsvigun, Zhuohan Xie, Igor Kiselev, Nico Daheim, Caiqi Zhang, Artem Vazhentsev, Mrinmaya Sachan, Preslav Nakov, Timothy Baldwin

+ [Large Language Model Psychometrics: A Systematic Review of Evaluation, Validation, and Enhancement](https://arxiv.org//abs/2505.08245)

	Haoran Ye, Jing Jin, Yuhang Xie, Xin Zhang, Guojie Song

+ [Enhancing Cache-Augmented Generation (CAG) with Adaptive Contextual Compression for Scalable Knowledge Integration](https://arxiv.org//abs/2505.08261)

	Rishabh Agrawal, Himanshu Kumar

+ [LLM Enhancers for GNNs: An Analysis from the Perspective of Causal Mechanism Identification](https://arxiv.org//abs/2505.08265)

	Hang Gao, Wenxuan Huang, Fengge Wu, Junsuo Zhao, Changwen Zheng, Huaping Liu

+ [Accelerating Chain-of-Thought Reasoning: When Goal-Gradient Importance Meets Dynamic Skipping](https://arxiv.org//abs/2505.08392)

	Ren Zhuang, Ben Wang, Shuifa Sun

+ [Optimizing Retrieval-Augmented Generation: Analysis of Hyperparameter Impact on Performance and Efficiency](https://arxiv.org//abs/2505.08445)

	Adel Ammar, Anis Koubaa, Omer Nacar, Wadii Boulila

+ [RepCali: High Efficient Fine-tuning Via Representation Calibration in Latent Space for Pre-trained Language Models](https://arxiv.org//abs/2505.08463)

	Fujun Zhang, XiangDong Su

+ [LCES: Zero-shot Automated Essay Scoring via Pairwise Comparisons Using Large Language Models](https://arxiv.org//abs/2505.08498)

	Takumi Shibata, Yuichi Miyamura

+ [The Truth Becomes Clearer Through Debate! Multi-Agent Systems with Large Language Models Unmask Fake News](https://arxiv.org//abs/2505.08532)

	Yuhan Liu, Yuxuan Liu, Xiaoqing Zhang, Xiuying Chen, Rui Yan

+ [PWC-MoE: Privacy-Aware Wireless Collaborative Mixture of Experts](https://arxiv.org//abs/2505.08719)

	Yang Su, Na Yan, Yansha Deng, Robert Schober

+ [Memorization-Compression Cycles Improve Generalization](https://arxiv.org//abs/2505.08727)

	Fangyuan Yu

+ [Securing RAG: A Risk Assessment and Mitigation Framework](https://arxiv.org//abs/2505.08728)

	Lukas Ammann, Sara Ott, Christoph R. Landolt, Marco P. Lehmann

+ [CodePDE: An Inference Framework for LLM-driven PDE Solver Generation](https://arxiv.org//abs/2505.08783)

	Shanda Li, Tanya Marwah, Junhong Shen, Weiwei Sun, Andrej Risteski, Yiming Yang, Ameet Talwalkar

+ [Evaluating the Effectiveness of Black-Box Prompt Optimization as the Scale of LLMs Continues to Grow](https://arxiv.org//abs/2505.08303)

	Ziyu Zhou, Yihang Wu, Jingyuan Yang, Zhan Xiao, Rongjun Li

+ [On the Geometry of Semantics in Next-token Prediction](https://arxiv.org//abs/2505.08348)

	Yize Zhao, Christos Thrampoulidis

+ [Alignment Drift in CEFR-prompted LLMs for Interactive Spanish Tutoring](https://arxiv.org//abs/2505.08351)

	Mina Almasi, Ross Deans Kristensen-McLachlan

+ [Towards Contamination Resistant Benchmarks](https://arxiv.org//abs/2505.08389)

	Rahmatullah Musawi, Sheng Lu

+ [Enhancing Thyroid Cytology Diagnosis with RAG-Optimized LLMs and Pa-thology Foundation Models](https://arxiv.org//abs/2505.08590)

	Hussien Al-Asi, Jordan P Reynolds, Shweta Agarwal, Bryan J Dangott, Aziza Nassar, Zeynettin Akkus

+ [Automatic Task Detection and Heterogeneous LLM Speculative Decoding](https://arxiv.org//abs/2505.08600)

	Danying Ge, Jianhua Gao, Qizhi Jiang, Yifei Feng, Weixing Ji

+ [Scaling Context, Not Parameters: Training a Compact 7B Language Model for Efficient Long-Context Processing](https://arxiv.org//abs/2505.08651)

	Chen Wu, Yin Song

+ [Revealing economic facts: LLMs know more than they say](https://arxiv.org//abs/2505.08662)

	Marcus Buckmann, Quynh Anh Nguyen, Edward Hill

+ [Adaptive Schema-aware Event Extraction with Retrieval-Augmented Generation](https://arxiv.org//abs/2505.08690)

	Sheng Liang, Hang Lv, Zhihao Wen, Yaxiong Wu, Yongyue Zhang, Hao Wang, Yong Liu

+ [NurValues: Real-World Nursing Values Evaluation for Large Language Models in Clinical Context](https://arxiv.org//abs/2505.08734)

	Ben Yao, Qiuchi Li, Yazhou Zhang, Siyu Yang, Bohan Zhang, Prayag Tiwari, Jing Qin

+ [Probability Consistency in Large Language Models: Theoretical Foundations Meet Empirical Discrepancies](https://arxiv.org//abs/2505.08739)

	Xiaoliang Luo, Xinyi Xu, Michael Ramscar, Bradley C. Love

+ [AC-Reason: Towards Theory-Guided Actual Causality Reasoning with Large Language Models](https://arxiv.org//abs/2505.08750)

	Yanxi Zhang, Xin Cong, Zhong Zhang, Xiao Liu, Dongyan Zhao, Yesai Wu

+ [InfoPO: On Mutual Information Maximization for Large Language Model Alignment](https://arxiv.org//abs/2505.08507)

	Teng Xiao, Zhen Ge, Sujay Sanghavi, Tian Wang, Julian Katz-Samuels, Marc Versage, Qingjun Cui, Trishul Chilimbi

+ [LM-Scout: Analyzing the Security of Language Model Integration in Android Apps](https://arxiv.org//abs/2505.08204)

	Muhammad Ibrahim (1), Gűliz Seray Tuncay (2), Z. Berkay Celik (3), Aravind Machiry (3), Antonio Bianchi (3) ((1) Georgia Institute of Technology, (2) Google, (3) Purdue University)

+ [Grounding Synthetic Data Evaluations of Language Models in Unsupervised Document Corpora](https://arxiv.org//abs/2505.08905)

	Michael Majurski, Cynthia Matuszek

+ [Automated Meta Prompt Engineering for Alignment with the Theory of Mind](https://arxiv.org//abs/2505.09024)

	Aaron Baughman, Rahul Agarwal, Eduardo Morales, Gozde Akay

+ [Improving the Reliability of LLMs: Combining CoT, RAG, Self-Consistency, and Self-Verification](https://arxiv.org//abs/2505.09031)

	Adarsh Kumar, Hwiyoon Kim, Jawahar Sai Nathani, Neil Roy

+ [Federated Large Language Models: Feasibility, Robustness, Security and Future Directions](https://arxiv.org//abs/2505.08830)

	Wenhao Jiang, Yuchuan Luo, Guilin Deng, Silong Chen, Xu Yang, Shihong Wu, Xinwen Gao, Lin Liu, Shaojing Fu

+ [CellTypeAgent: Trustworthy cell type annotation with Large Language Models](https://arxiv.org//abs/2505.08844)

	Jiawen Chen, Jianghao Zhang, Huaxiu Yao, Yun Li

+ [Improved Algorithms for Differentially Private Language Model Alignment](https://arxiv.org//abs/2505.08849)

	Keyu Chen, Hao Tang, Qinglin Liu, Yizhao Xu

+ [Optimized Couplings for Watermarking Large Language Models](https://arxiv.org//abs/2505.08878)

	Dor Tsur, Carol Xuan Long, Claudio Mayrink Verdun, Hsiang Hsu, Haim Permuter, Flavio P. Calmon

+ [Tests as Prompt: A Test-Driven-Development Benchmark for LLM Code Generation](https://arxiv.org//abs/2505.09027)

	Yi Cui

+ [LibVulnWatch: A Deep Assessment Agent System and Leaderboard for Uncovering Hidden Vulnerabilities in Open-Source AI Libraries](https://arxiv.org//abs/2505.08842)

	Zekun Wu, Seonglae Cho, Umar Mohammed, Cristian Munoz, Kleyton Costa, Xin Guan, Theo King, Ze Wang, Emre Kazim, Adriano Koshiyama

# 2025-05-12
+ [How well do LLMs reason over tabular data, really?](https://arxiv.org//abs/2505.07453)

	Cornelius Wolff, Madelon Hulsebos

+ [A Survey on Collaborative Mechanisms Between Large and Small Language Models](https://arxiv.org//abs/2505.07460)

	Yi Chen, JiaHao Zhao, HaoHao Han

+ [Web-Bench: A LLM Code Benchmark Based on Web Standards and Frameworks](https://arxiv.org//abs/2505.07473)

	Kai Xu, YiWei Mao, XinYi Guan, ZiLong Feng

+ [QuantX: A Framework for Hardware-Aware Quantization of Generative AI Workloads](https://arxiv.org//abs/2505.07531)

	Khurram Mazher, Saad Bin Nasir

+ [S-GRPO: Early Exit via Reinforcement Learning in Reasoning Models](https://arxiv.org//abs/2505.07686)

	Muzhi Dai, Chenxu Yang, Qingyi Si

+ [Belief Injection for Epistemic Control in Linguistic State Space](https://arxiv.org//abs/2505.07693)

	Sebastian Dumbrava

+ [Agent RL Scaling Law: Agent RL with Spontaneous Code Execution for Mathematical Problem Solving](https://arxiv.org//abs/2505.07773)

	Xinji Mai, Haotian Xu, Xing W, Weinong Wang, Yingying Zhang, Wenqiang Zhang

+ [DynamicRAG: Leveraging Outputs of Large Language Model as Feedback for Dynamic Reranking in Retrieval-Augmented Generation](https://arxiv.org//abs/2505.07233)

	Jiashuo Sun, Xianrui Zhong, Sizhe Zhou, Jiawei Han

+ [UAV-CodeAgents: Scalable UAV Mission Planning via Multi-Agent ReAct and Vision-Language Reasoning](https://arxiv.org//abs/2505.07236)

	Oleg Sautenkov, Yasheerah Yaqoot, Muhammad Ahsan Mustafa, Faryal Batool, Jeffrin Sam, Artem Lykov, Chih-Yung Wen, Dzmitry Tsetserukou

+ [Comet: Accelerating Private Inference for Large Language Model by Predicting Activation Sparsity](https://arxiv.org//abs/2505.07239)

	Guang Yan, Yuhui Zhang, Zimu Guo, Lutan Zhao, Xiaojun Chen, Chen Wang, Wenhao Wang, Dan Meng, Rui Hou

+ [SAS-Bench: A Fine-Grained Benchmark for Evaluating Short Answer Scoring with Large Language Models](https://arxiv.org//abs/2505.07247)

	Peichao Lai, Kexuan Zhang, Yi Lin, Linyihan Zhang, Feiyang Ye, Jinhao Yan, Yanwei Xu, Conghui He, Yilei Wang, Wentao Zhang, Bin Cui

+ [No Query, No Access](https://arxiv.org//abs/2505.07258)

	Wenqiang Wang, Siyuan Liang, Yangshijie Zhang, Xiaojun Jia, Hao Lin, Xiaochun Cao

+ [UMoE: Unifying Attention and FFN with Shared Experts](https://arxiv.org//abs/2505.07260)

	Yuanhang Yang, Chaozheng Wang, Jing Li

+ [On the Robustness of Reward Models for Language Model Alignment](https://arxiv.org//abs/2505.07271)

	Jiwoo Hong, Noah Lee, Eunki Kim, Guijin Son, Woojin Chung, Aman Gupta, Shao Tang, James Thorne

+ [Semantic Retention and Extreme Compression in LLMs: Can We Have Both?](https://arxiv.org//abs/2505.07289)

	Stanislas Laborde, Martin Cousseau, Antoun Yaacoub, Lionel Prevost

+ [Towards Multi-Agent Reasoning Systems for Collaborative Expertise Delegation: An Exploratory Design Study](https://arxiv.org//abs/2505.07313)

	Baixuan Xu, Chunyang Li, Weiqi Wang, Wei Fan, Tianshi Zheng, Haochen Shi, Tao Fan, Yangqiu Song, Qiang Yang

+ [Synthetic Code Surgery: Repairing Bugs and Vulnerabilities with LLMs and Synthetic Data](https://arxiv.org//abs/2505.07372)

	David de-Fitero-Dominguez, Antonio Garcia-Cabot, Eva Garcia-Lopez

+ [LEAD: Iterative Data Selection for Efficient LLM Instruction Tuning](https://arxiv.org//abs/2505.07437)

	Xiaotian Lin, Yanlin Qi, Yizhang Zhu, Themis Palpanas, Chengliang Chai, Nan Tang, Yuyu Luo

+ [Can Generative AI agents behave like humans? Evidence from laboratory market experiments](https://arxiv.org//abs/2505.07457)

	R. Maria del Rio-Chanona, Marco Pangallo, Cars Hommes

+ [ToolACE-DEV: Self-Improving Tool Learning via Decomposition and EVolution](https://arxiv.org//abs/2505.07512)

	Xu Huang, Weiwen Liu, Xingshan Zeng, Yuefeng Huang, Xinlong Hao, Yuxian Wang, Yirong Zeng, Chuhan Wu, Yasheng Wang, Ruiming Tang, Defu Lian

+ [GRADA: Graph-based Reranker against Adversarial Documents Attack](https://arxiv.org//abs/2505.07546)

	Jingjie Zheng, Aryo Pradipta Gema, Giwon Hong, Xuanli He, Pasquale Minervini, Youcheng Sun, Qiongkai Xu

+ [Towards Requirements Engineering for RAG Systems](https://arxiv.org//abs/2505.07553)

	Tor Sporsem, Rasmus Ulfsnes

+ [A Multi-Dimensional Constraint Framework for Evaluating and Improving Instruction Following in Large Language Models](https://arxiv.org//abs/2505.07591)

	Junjie Ye, Caishuang Huang, Zhuohan Chen, Wenjie Fu, Chenyuan Yang, Leyi Yang, Yilong Wu, Peng Wang, Meng Zhou, Xiaolong Yang, Tao Gui, Qi Zhang, Zhongchao Shi, Jianping Fan, Xuanjing Huang

+ [Reinforced Internal-External Knowledge Synergistic Reasoning for Efficient Adaptive Search Agent](https://arxiv.org//abs/2505.07596)

	Ziyang Huang, Xiaowei Yuan, Yiming Ju, Jun Zhao, Kang Liu

+ [MiMo: Unlocking the Reasoning Potential of Language Model -- From Pretraining to Posttraining](https://arxiv.org//abs/2505.07608)

	Xiaomi LLM-Core Team: Bingquan Xia, Bowen Shen, Cici, Dawei Zhu, Di Zhang, Gang Wang, Hailin Zhang, Huaqiu Liu, Jiebao Xiao, Jinhao Dong, Liang Zhao, Peidian Li, Peng Wang, Shihua Yu, Shimao Chen, Weikun Wang, Wenhan Ma, Xiangwei Deng, Yi Huang, Yifan Song, Zihan Jiang, Bowen Ye, Can Cai, Chenhong He, Dong Zhang, Duo Zhang, Guoan Wang, Hao Tian, Haochen Zhao, Heng Qu, Hongshen Xu, Jun Shi, Kainan Bao, QingKai Fang, Kang Zhou, Kangyang Zhou, Lei Li, Menghang Zhu, Nuo Chen, Qiantong Wang, Shaohui Liu, Shicheng Li, Shuhao Gu, Shuhuai Ren, Shuo Liu, Sirui Deng, Weiji Zhuang, Weiwei Lv, Wenyu Yang, Xin Zhang, Xing Yong, Xing Zhang, Xingchen Song, Xinzhe Xu, Xu Wang, Yihan Yan, Yu Tu, Yuanyuan Tian, Yudong Wang, Yue Yu, Zhenru Lin, Zhichao Song, Zihao Yue

+ [Concept-Level Explainability for Auditing & Steering LLM Responses](https://arxiv.org//abs/2505.07610)

	Kenza Amara, Rita Sevastjanova, Mennatallah El-Assady

+ [Chronocept: Instilling a Sense of Time in Machines](https://arxiv.org//abs/2505.07637)

	Krish Goel, Sanskar Pandey, KS Mahadevan, Harsh Kumar, Vishesh Khadaria

+ [Benchmarking Retrieval-Augmented Generation for Chemistry](https://arxiv.org//abs/2505.07671)

	Xianrui Zhong, Bowen Jin, Siru Ouyang, Yanzhen Shen, Qiao Jin, Yin Fang, Zhiyong Lu, Jiawei Han

+ [OnPrem.LLM: A Privacy-Conscious Document Intelligence Toolkit](https://arxiv.org//abs/2505.07672)

	Arun S. Maiya

+ [Overflow Prevention Enhances Long-Context Recurrent LLMs](https://arxiv.org//abs/2505.07793)

	Assaf Ben-Kish, Itamar Zimerman, M. Jehanzeb Mirza, James Glass, Leonid Karlinsky, Raja Giryes

+ [Structural Entropy Guided Agent for Detecting and Repairing Knowledge Deficiencies in LLMs](https://arxiv.org//abs/2505.07184)

	Yifan Wei, Xiaoyan Yu, Tengfei Pan, Angsheng Li, Li Du

+ [Benchmarking Ethical and Safety Risks of Healthcare LLMs in China-Toward Systemic Governance under Healthy China 2030](https://arxiv.org//abs/2505.07205)

	Mouxiao Bian, Rongzhao Zhang, Chao Ding, Xinwei Peng, Jie Xu

+ [AttentionInfluence: Adopting Attention Head Influence for Weak-to-Strong Pretraining Data Selection](https://arxiv.org//abs/2505.07293)

	Kai Hua, Steven Wu, Ge Zhang, Ke Shen

+ [SEReDeEP: Hallucination Detection in Retrieval-Augmented Models via Semantic Entropy and Context-Parameter Fusion](https://arxiv.org//abs/2505.07528)

	Lei Wang

+ [Spoken Language Understanding on Unseen Tasks With In-Context Learning](https://arxiv.org//abs/2505.07731)

	Neeraj Agrawal, Sriram Ganapathy

+ [Domain Regeneration: How well do LLMs match syntactic properties of text domains?](https://arxiv.org//abs/2505.07784)

	Da Ju, Hagen Blix, Adina Williams

+ [Learning from Peers in Reasoning Models](https://arxiv.org//abs/2505.07787)

	Tongxu Luo, Wenyu Du, Jiaxi Bi, Stephen Chung, Zhengyang Tang, Hao Yang, Min Zhang, Benyou Wang

+ [Reassessing Large Language Model Boolean Query Generation for Systematic Reviews](https://arxiv.org//abs/2505.07155)

	Shuai Wang, Harrisen Scells, Bevan Koopman, Guido Zuccon

+ [Pre-training vs. Fine-tuning: A Reproducibility Study on Dense Retrieval Knowledge Acquisition](https://arxiv.org//abs/2505.07166)

	Zheng Yao, Shuai Wang, Guido Zuccon

+ [One Trigger Token Is Enough: A Defense Strategy for Balancing Safety and Usability in Large Language Models](https://arxiv.org//abs/2505.07167)

	Haoran Gu, Handing Wang, Yi Mei, Mengjie Zhang, Yaochu Jin

+ [Direct Density Ratio Optimization: A Statistically Consistent Approach to Aligning Large Language Models](https://arxiv.org//abs/2505.07558)

	Rei Higuchi, Taiji Suzuki

+ [Critique Before Thinking: Mitigating Hallucination through Rationale-Augmented Instruction Tuning](https://arxiv.org//abs/2505.07172)

	Zexian Yang, Dian Li, Dayan Wu, Gang Liu, Weiping Wang

+ [Learning to Reason and Navigate: Parameter Efficient Action Planning with Large Language Models](https://arxiv.org//abs/2505.07500)

	Bahram Mohammadi, Ehsan Abbasnejad, Yuankai Qi, Qi Wu, Anton Van Den Hengel, Javen Qinfeng Shi

+ [Imagine, Verify, Execute: Memory-Guided Agentic Exploration with Vision-Language Models](https://arxiv.org//abs/2505.07815)

	Seungjae Lee, Daniel Ekpo, Haowen Liu, Furong Huang, Abhinav Shrivastava, Jia-Bin Huang

+ [Cache-Efficient Posterior Sampling for Reinforcement Learning with LLM-Derived Priors Across Discrete and Continuous Domains](https://arxiv.org//abs/2505.07274)

	Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma

+ [Uncertainty Profiles for LLMs: Uncertainty Source Decomposition and Adaptive Model-Metric Selection](https://arxiv.org//abs/2505.07309)

	Pei-Fu Guo, Yun-Da Tsai, Shou-De Lin

+ [Injecting Knowledge Graphs into Large Language Models](https://arxiv.org//abs/2505.07554)

	Erica Coppolillo

+ [SpecRouter: Adaptive Routing for Multi-Level Speculative Decoding in Large Language Models](https://arxiv.org//abs/2505.07680)

	Hang Wu, Jianian Zhu, Yinghui Li, Haojie Wang, Biao Hou, Jidong Zhai

+ [MLE-Dojo: Interactive Environments for Empowering LLM Agents in Machine Learning Engineering](https://arxiv.org//abs/2505.07782)

	Rushi Qiang, Yuchen Zhuang, Yinghao Li, Dingu Sagar V K, Rongzhi Zhang, Changhao Li, Ian Shu-Hei Wong, Sherry Yang, Percy Liang, Chao Zhang, Bo Dai

+ [Relative Overfitting and Accept-Reject Framework](https://arxiv.org//abs/2505.07783)

	Yanxin Liu, Yunqi Zhang

+ [Private LoRA Fine-tuning of Open-Source LLMs with Homomorphic Encryption](https://arxiv.org//abs/2505.07329)

	Jordan Frery, Roman Bredehoft, Jakub Klemsa, Arthur Meyre, Andrei Stoian

+ [SecReEvalBench: A Multi-turned Security Resilience Evaluation Benchmark for Large Language Models](https://arxiv.org//abs/2505.07584)

	Huining Cui, Wei Liu

+ [LongCodeBench: Evaluating Coding LLMs at 1M Context Windows](https://arxiv.org//abs/2505.07897)

	Stefano Rando, Luca Romani, Alessio Sampieri, Yuta Kyuragi, Luca Franco, Fabio Galasso, Tatsunori Hashimoto, John Yang

+ [DeltaEdit: Enhancing Sequential Editing in Large Language Models by Controlling Superimposed Noise](https://arxiv.org//abs/2505.07899)

	Ding Cao, Yuchen Cai, Rongxi Guo, Xuesong He, Guiquan Liu

+ [SEM: Reinforcement Learning for Search-Efficient Large Language Models](https://arxiv.org//abs/2505.07903)

	Zeyang Sha, Shiwen Cui, Weiqiang Wang

+ [A Reproduction Study: The Kernel PCA Interpretation of Self-Attention Fails Under Scrutiny](https://arxiv.org//abs/2505.07908)

	Karahan Sarıtaş, Çağatay Yıldız

+ [Efficient and Reproducible Biomedical Question Answering using Retrieval Augmented Generation](https://arxiv.org//abs/2505.07917)

	Linus Stuhlmann, Michael Alexander Saxer, Jonathan Fürst

+ [FalseReject: A Resource for Improving Contextual Safety and Mitigating Over-Refusals in LLMs via Structured Reasoning](https://arxiv.org//abs/2505.08054)

	Zhehao Zhang, Weijie Xu, Fanyou Wu, Chandan K. Reddy

+ [Beyond Input Activations: Identifying Influential Latents by Gradient Sparse Autoencoders](https://arxiv.org//abs/2505.08080)

	Dong Shu, Xuansheng Wu, Haiyan Zhao, Mengnan Du, Ninghao Liu

+ [Assessing and Mitigating Medical Knowledge Drift and Conflicts in Large Language Models](https://arxiv.org//abs/2505.07968)

	Weiyi Wu, Xinwen Xu, Chongyang Gao, Xingjian Diao, Siting Li, Lucas A. Salas, Jiang Gui

+ [Putting It All into Context: Simplifying Agents with LCLMs](https://arxiv.org//abs/2505.08120)

	Mingjian Jiang, Yangjun Ruan, Luis Lastras, Pavan Kapanipathi, Tatsunori Hashimoto

+ [Making Small Language Models Efficient Reasoners: Intervention, Supervision, Reinforcement](https://arxiv.org//abs/2505.07961)

	Xuechen Zhang, Zijian Huang, Chenchun Ni, Ziyang Xiong, Jiasi Chen, Samet Oymak

+ [Security of Internet of Agents: Attacks and Countermeasures](https://arxiv.org//abs/2505.08807)

	Yuntao Wang, Yanghe Pan, Shaolong Guo, Zhou Su

+ [An Extra RMSNorm is All You Need for Fine Tuning to 1.58 Bits](https://arxiv.org//abs/2505.08823)

	Cody Steinmetz, Gavin Childress, Aaron Herbst, Gavin Jones, Jasdeep Singh, Eli Vang, Keagan Weinstock

+ [Self Rewarding Self Improving](https://arxiv.org//abs/2505.08827)

	Toby Simonds, Kevin Lopez, Akira Yoshiyama, Dominique Garmier

# 2025-05-11
+ [Control Plane as a Tool: A Scalable Design Pattern for Agentic AI Systems](https://arxiv.org//abs/2505.06817)

	Sivasathivel Kandasamy

+ [Towards Artificial General or Personalized Intelligence? A Survey on Foundation Models for Personalized Federated Intelligence](https://arxiv.org//abs/2505.06907)

	Yu Qiao, Huy Q. Le, Avi Deb Raha, Phuong-Nam Tran, Apurba Adhikary, Mengchun Zhang, Loc X. Nguyen, Eui-Nam Huh, Dusit Niyato, Choong Seon Hong

+ [LLM-Augmented Chemical Synthesis and Design Decision Programs](https://arxiv.org//abs/2505.07027)

	Haorui Wang, Jeff Guo, Lingkai Kong, Rampi Ramprasad, Philippe Schwaller, Yuanqi Du, Chao Zhang

+ [DialogueReason: Rule-Based RL Sparks Dialogue Reasoning in LLMs](https://arxiv.org//abs/2505.07049)

	Yubo Shu, Zhewei Huang, Xin Wu, Chen Hu, Shuchang Zhou, Daxin Jiang

+ [Architectural Precedents for General Agents using Large Language Models](https://arxiv.org//abs/2505.07087)

	Robert E. Wray, James R. Kirk, John E. Laird

+ [RefPentester: A Knowledge-Informed Self-Reflective Penetration Testing Framework Based on Large Language Models](https://arxiv.org//abs/2505.07089)

	Hanzheng Dai, Yuanliang Li, Zhibo Zhang, Jun Yan

+ [ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification](https://arxiv.org//abs/2505.06821)

	Dipayan Saha, Hasan Al Shaikh, Shams Tarek, Farimah Farahmandi

+ [Sandcastles in the Storm: Revisiting the (Im)possibility of Strong Watermarking](https://arxiv.org//abs/2505.06827)

	Fabrice Y Harel-Canada, Boran Erol, Connor Choi, Jason Liu, Gary Jiarui Song, Nanyun Peng, Amit Sahai

+ [The power of fine-grained experts: Granularity boosts expressivity in Mixture of Experts](https://arxiv.org//abs/2505.06839)

	Enric Boix-Adsera, Philippe Rigollet

+ [IM-BERT: Enhancing Robustness of BERT through the Implicit Euler Method](https://arxiv.org//abs/2505.06889)

	Mihyeon Kim, Juhyoung Park, Youngbin Kim

+ [RedTeamLLM: an Agentic AI framework for offensive security](https://arxiv.org//abs/2505.06913)

	Brian Challita, Pierre Parrend

+ [Convert Language Model into a Value-based Strategic Planner](https://arxiv.org//abs/2505.06987)

	Xiaoyu Wang, Yue Zhao, Qingqing Gu, Zhonglin Jiang, Xiaokai Chen, Yong Chen, Luo Ji

+ [ParaView-MCP: An Autonomous Visualization Agent with Direct Tool Use](https://arxiv.org//abs/2505.07064)

	Shusen Liu, Haichao Miao, Peer-Timo Bremer

+ [EcoLANG: Efficient and Effective Agent Communication Language Induction for Social Simulation](https://arxiv.org//abs/2505.06904)

	Xinyi Mou, Chen Qian, Wei Liu, Xuanjing Huang, Zhongyu Wei

+ [The Distracting Effect: Understanding Irrelevant Passages in RAG](https://arxiv.org//abs/2505.06914)

	Chen Amiraz, Florin Cuconasu, Simone Filice, Zohar Karnin

+ [Benign Samples Matter! Fine-tuning On Outlier Benign Samples Severely Breaks Safety](https://arxiv.org//abs/2505.06843)

	Zihan Guan, Mengxuan Hu, Ronghang Zhu, Sheng Li, Anil Vullikanti

+ [Building a Human-Verified Clinical Reasoning Dataset via a Human LLM Hybrid Pipeline for Trustworthy Medical AI](https://arxiv.org//abs/2505.06912)

	Chao Ding, Mouxiao Bian, Pengcheng Chen, Hongliang Zhang, Tianbin Li, Lihao Liu, Jiayuan Chen, Zhuoran Li, Yabei Zhong, Yongqi Liu, Haiqing Huang, Dongming Shan, Junjun He, Jie Xu

+ [Hallucination-Aware Multimodal Benchmark for Gastrointestinal Image Analysis with Large Vision-Language Models](https://arxiv.org//abs/2505.07001)

	Bidur Khanal, Sandesh Pokhrel, Sanjay Bhandari, Ramesh Rana, Nikesh Shrestha, Ram Bahadur Gurung, Cristian Linte, Angus Watson, Yash Raj Shrestha, Binod Bhattarai

+ [GuidedQuant: Large Language Model Quantization via Exploiting End Loss Guidance](https://arxiv.org//abs/2505.07004)

	Jinuk Kim, Marwa El Halabi, Wonpyo Park, Clemens JS Schaefer, Deokjae Lee, Yeonhong Park, Jae W. Lee, Hyun Oh Song

+ [PLHF: Prompt Optimization with Few-Shot Human Feedback](https://arxiv.org//abs/2505.07886)

	Chun-Pai Yang, Kan Zheng, Shou-De Lin

+ [TrumorGPT: Graph-Based Retrieval-Augmented Large Language Model for Fact-Checking](https://arxiv.org//abs/2505.07891)

	Ching Nam Hang, Pei-Duo Yu, Chee Wei Tan

# 2025-05-10
+ [System Prompt Poisoning: Persistent Attacks on Large Language Models Beyond User Injection](https://arxiv.org//abs/2505.06493)

	Jiawei Guo, Haipeng Cai

+ [MacRAG: Compress, Slice, and Scale-up for Multi-Scale Adaptive Context RAG](https://arxiv.org//abs/2505.06569)

	Woosang Lim, Zekun Li, Gyuwan Kim, Sungyoung Ji, HyeonJung Kim, Kyuri Choi, Jin Hyuk Lim, Kyungpyo Park, William Yang Wang

+ [Think in Safety: Unveiling and Mitigating Safety Alignment Collapse in Multimodal Large Reasoning Model](https://arxiv.org//abs/2505.06538)

	Xinyue Lou, You Li, Jinan Xu, Xiangyu Shi, Chi Chen, Kaiyu Huang

+ [REFINE-AF: A Task-Agnostic Framework to Align Language Models via Self-Generated Instructions using Reinforcement Learning from Automated Feedback](https://arxiv.org//abs/2505.06548)

	Aniruddha Roy, Pretam Ray, Abhilash Nandy, Somak Aditya, Pawan Goyal

+ [Using External knowledge to Enhanced PLM for Semantic Matching](https://arxiv.org//abs/2505.06605)

	Min Li, Chun Yuan

+ [Attention Is Not All You Need: The Importance of Feedforward Networks in Transformer Models](https://arxiv.org//abs/2505.06633)

	Isaac Gerber

+ [From Rankings to Insights: Evaluation Should Shift Focus from Leaderboard to Feedback](https://arxiv.org//abs/2505.06698)

	Zongqi Wang, Tianle Gu, Chen Gong, Xin Tian, Siqi Bao, Yujiu Yang

+ [Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free](https://arxiv.org//abs/2505.06708)

	Zihan Qiu, Zekun Wang, Bo Zheng, Zeyu Huang, Kaiyue Wen, Songlin Yang, Rui Men, Le Yu, Fei Huang, Suozhi Huang, Dayiheng Liu, Jingren Zhou, Junyang Lin

+ [Improving Block-Wise LLM Quantization by 4-bit Block-Wise Optimal Float (BOF4): Analysis and Variations](https://arxiv.org//abs/2505.06653)

	Patrick Blumenberg, Thomas Graave, Tim Fingscheidt

+ [Probing In-Context Learning: Impact of Task Complexity and Model Architecture on Generalization and Efficiency](https://arxiv.org//abs/2505.06475)

	Binwen Liu, Peiyu Xu, Quan Yuan, Yihong Chen

+ [QoS-Efficient Serving of Multiple Mixture-of-Expert LLMs Using Partial Runtime Reconfiguration](https://arxiv.org//abs/2505.06481)

	HamidReza Imani, Jiaxin Peng, Peiman Mohseni, Abdolah Amirany, Tarek El-Ghazawi

+ [RuleGenie: SIEM Detection Rule Set Optimization](https://arxiv.org//abs/2505.06701)

	Akansha Shukla, Parth Atulbhai Gandhi, Yuval Elovici, Asaf Shabtai

+ [POISONCRAFT: Practical Poisoning of Retrieval-Augmented Generation for Large Language Models](https://arxiv.org//abs/2505.06579)

	Yangguang Shao, Xinjie Lin, Haozheng Luo, Chengshang Hou, Gang Xiong, Jiahao Yu, Junzheng Shi

+ [Practical Reasoning Interruption Attacks on Reasoning Large Language Models](https://arxiv.org//abs/2505.06643)

	Yu Cui, Cong Zuo

+ [I Know What You Said: Unveiling Hardware Cache Side-Channels in Local Large Language Model Inference](https://arxiv.org//abs/2505.06738)

	Zibo Gao, Junjie Hu, Feng Guo, Yixin Zhang, Yinglong Han, Siyuan Liu, Haiyang Li, Zhiqiang Lv

+ [OMGM: Orchestrate Multiple Granularities and Modalities for Efficient Multimodal Retrieval](https://arxiv.org//abs/2505.07879)

	Wei Yang, Jingjing Fu, Rui Wang, Jinyu Wang, Lei Song, Jiang Bian

+ [Recovering Event Probabilities from Large Language Model Embeddings via Axiomatic Constraints](https://arxiv.org//abs/2505.07883)

	Jian-Qiao Zhu, Haijiang Yan, Thomas L. Griffiths

+ [Multi-modal Synthetic Data Training and Model Collapse: Insights from VLMs and Diffusion Models](https://arxiv.org//abs/2505.08803)

	Zizhao Hu, Mohammad Rostami, Jesse Thomason

# 2025-05-09
+ [APOLLO: Automated LLM and Lean Collaboration for Advanced Formal Reasoning](https://arxiv.org//abs/2505.05758)

	Azim Ospanov, Roozbeh Yousefzadeh

+ [ArtRAG: Retrieval-Augmented Generation with Structured Context for Visual Art Understanding](https://arxiv.org//abs/2505.06020)

	Shuai Wang, Ivona Najdenkoska, Hongyi Zhu, Stevan Rudinac, Monika Kackovic, Nachoem Wijnberg, Marcel Worring

+ [Assessing Robustness to Spurious Correlations in Post-Training Language Models](https://arxiv.org//abs/2505.05704)

	Julia Shuieh, Prasann Singhal, Apaar Shanker, John Heyer, George Pu, Samuel Denton

+ [Multi-Agent Systems for Robotic Autonomy with LLMs](https://arxiv.org//abs/2505.05762)

	Junhong Chen, Ziqi Yang, Haoyuan G Xu, Dandan Zhang, George Mylonas

+ [AgentXploit: End-to-End Redteaming of Black-Box AI Agents](https://arxiv.org//abs/2505.05849)

	Zhun Wang, Vincent Siu, Zhe Ye, Tianneng Shi, Yuzhou Nie, Xuandong Zhao, Chenguang Wang, Wenbo Guo, Dawn Song

+ [Elastic Weight Consolidation for Full-Parameter Continual Pre-Training of Gemma2](https://arxiv.org//abs/2505.05946)

	Vytenis Šliogeris, Povilas Daniušis, Artūras Nakvosas

+ [A Scaling Law for Token Efficiency in LLM Fine-Tuning Under Fixed Compute Budgets](https://arxiv.org//abs/2505.06150)

	Ryan Lagasse, Aidan Kiernans, Avijit Ghosh, Shiri Dori-Hacohen

+ [Sparse Attention Remapping with Clustering for Efficient LLM Decoding on PIM](https://arxiv.org//abs/2505.05772)

	Zehao Fan, Garrett Gagnon, Zhenyu Liu, Liu Liu

+ [NeoQA: Evidence-based Question Answering with Generated News Events](https://arxiv.org//abs/2505.05949)

	Max Glockner, Xiang Jiang, Leonardo F. R. Ribeiro, Iryna Gurevych, Markus Dreyer

+ [Towards Developmentally Plausible Rewards: Communicative Success as a Learning Signal for Interactive Language Models](https://arxiv.org//abs/2505.05970)

	Lennart Stöpler, Rufat Asadli, Mitja Nikolaus, Ryan Cotterell, Alex Warstadt

+ [Unilogit: Robust Machine Unlearning for LLMs Using Uniform-Target Self-Distillation](https://arxiv.org//abs/2505.06027)

	Stefan Vasilev, Christian Herold, Baohao Liao, Seyyed Hadi Hashemi, Shahram Khadivi, Christof Monz

+ [Healthy LLMs? Benchmarking LLM Knowledge of UK Government Public Health Information](https://arxiv.org//abs/2505.06046)

	Joshua Harris, Fan Grayson, Felix Feldman, Timothy Laurence, Toby Nonnenmacher, Oliver Higgins, Leo Loman, Selina Patel, Thomas Finnie, Samuel Collins, Michael Borowitz

+ [LLMs Get Lost In Multi-Turn Conversation](https://arxiv.org//abs/2505.06120)

	Philippe Laban, Hiroaki Hayashi, Yingbo Zhou, Jennifer Neville

+ [Can Prompting LLMs Unlock Hate Speech Detection across Languages? A Zero-shot and Few-shot Study](https://arxiv.org//abs/2505.06149)

	Faeze Ghorbanpour, Daryna Dementieva, Alexander Fraser

+ [Multimodal Integrated Knowledge Transfer to Large Language Models through Preference Optimization with Biomedical Applications](https://arxiv.org//abs/2505.05736)

	Da Wu, Zhanliang Wang, Quan Nguyen, Zhuoran Xu, Kai Wang

+ [Harnessing LLMs Explanations to Boost Surrogate Models in Tabular Data Classification](https://arxiv.org//abs/2505.05744)

	Ruxue Shi, Hengrui Gu, Xu Shen, Xin Wang

+ [Short-circuiting Shortcuts: Mechanistic Investigation of Shortcuts in Text Classification](https://arxiv.org//abs/2505.06032)

	Leon Eshuijs, Shihan Wang, Antske Fokkens

+ [FloE: On-the-Fly MoE Inference](https://arxiv.org//abs/2505.05950)

	Yuxin Zhou, Zheng Li, Jun Zhang, Jue Wang, Yiping Wang, Zhongle Xie, Ke Chen, Lidan Shou

+ [Understanding Stragglers in Large Model Training Using What-if Analysis](https://arxiv.org//abs/2505.05713)

	Jinkun Lin, Ziheng Jiang, Zuquan Song, Sida Zhao, Menghan Yu, Zhanghan Wang, Chenyuan Wang, Zuocheng Shi, Xiang Shi, Wei Jia, Zherui Liu, Shuguang Wang, Haibin Lin, Xiu Liu, Aurojit Panda, Jinyang Li

+ [CAPE: Context-Aware Prompt Perturbation Mechanism with Differential Privacy](https://arxiv.org//abs/2505.05922)

	Haoqi Wu, Wei Dai, Li Wang, Qiang Yan

+ [LLM-Text Watermarking based on Lagrange Interpolation](https://arxiv.org//abs/2505.05712)

	Jarosław Janas, Paweł Morawiecki, Josef Pieprzyk

+ [A Grounded Memory System For Smart Personal Assistants](https://arxiv.org//abs/2505.06328)

	Felix Ocker, Jörg Deigmöller, Pavel Smirnov, Julian Eggert

+ [Reliable Collaborative Conversational Agent System Based on LLMs and Answer Set Programming](https://arxiv.org//abs/2505.06438)

	Yankai Zeng, Gopal Gupta

+ [KCluster: An LLM-based Clustering Approach to Knowledge Component Discovery](https://arxiv.org//abs/2505.06469)

	Yumou Wei, Paulo Carvalho, John Stamper

+ [Learn to Think: Bootstrapping LLM Reasoning Capability Through Graph Learning](https://arxiv.org//abs/2505.06321)

	Hang Gao, Chenhao Zhang, Tie Wang, Junsuo Zhao, Fengge Wu, Changwen Zheng, Huaping Liu

+ [Document Attribution: Examining Citation Relationships using Large Language Models](https://arxiv.org//abs/2505.06324)

	Vipula Rawte, Ryan A. Rossi, Franck Dernoncourt, Nedim Lipka

+ [Prompting Large Language Models for Training-Free Non-Intrusive Load Monitoring](https://arxiv.org//abs/2505.06330)

	Junyu Xue, Xudong Wang, Xiaoling He, Shicheng Liu, Yi Wang, Guoming Tang

+ [Towards AI-Driven Human-Machine Co-Teaming for Adaptive and Agile Cyber Security Operation Centers](https://arxiv.org//abs/2505.06394)

	Massimiliano Albanese, Xinming Ou, Kevin Lybarger, Daniel Lende, Dmitry Goldgof

+ [Engineering Risk-Aware, Security-by-Design Frameworks for Assurance of Large-Scale Autonomous AI Models](https://arxiv.org//abs/2505.06409)

	Krti Tallam

+ [Natural Reflection Backdoor Attack on Vision Language Model for Autonomous Driving](https://arxiv.org//abs/2505.06413)

	Ming Liu, Siyuan Liang, Koushik Howlader, Liwen Wang, Dacheng Tao, Wensheng Zhang

+ [ScaleMCP: Dynamic and Auto-Synchronizing Model Context Protocol Tools for LLM Agents](https://arxiv.org//abs/2505.06416)

	Elias Lumer, Anmol Gulati, Vamse Kumar Subbiah, Pradeep Honaganahalli Basavaraju, James A. Burke

+ [Is your multimodal large language model a good science tutor?](https://arxiv.org//abs/2505.06418)

	Ming Liu, Liwen Wang, Wensheng Zhang

+ [Efficient Fairness Testing in Large Language Models: Prioritizing Metamorphic Relations for Bias Detection](https://arxiv.org//abs/2505.07870)

	Suavis Giramata, Madhusudan Srinivasan, Venkat Naidu Gudivada, Upulee Kanewala

# 2025-05-08
+ [Enigme: Generative Text Puzzles for Evaluating Reasoning in Language Models](https://arxiv.org//abs/2505.04914)

	John Hawkins

+ [Belief Filtering for Epistemic Control in Linguistic State Space](https://arxiv.org//abs/2505.04927)

	Sebastian Dumbrava

+ [A Reputation System for Large Language Model-based Multi-agent Systems to Avoid the Tragedy of the Commons](https://arxiv.org//abs/2505.05029)

	Siyue Ren, Wanli Fu, Xinkun Zou, Chen Shen, Yi Cai, Chen Chu, Zhen Wang, Shuyue Hu

+ [MARK: Memory Augmented Refinement of Knowledge](https://arxiv.org//abs/2505.05177)

	Anish Ganguli, Prabal Deb, Debleena Banerjee

+ [ConCISE: Confidence-guided Compression in Step-by-step Efficient Reasoning](https://arxiv.org//abs/2505.04881)

	Ziqing Qiao, Yongheng Deng, Jiali Zeng, Dong Wang, Lai Wei, Fandong Meng, Jie Zhou, Ju Ren, Yaoxue Zhang

+ [Chain-of-Thought Tokens are Computer Program Variables](https://arxiv.org//abs/2505.04955)

	Fangwei Zhu, Peiyi Wang, Zhifang Sui

+ [Rethinking Invariance in In-context Learning](https://arxiv.org//abs/2505.04994)

	Lizhe Fang, Yifei Wang, Khashayar Gatmiry, Lei Fang, Yisen Wang

+ [Understanding In-context Learning of Addition via Activation Subspaces](https://arxiv.org//abs/2505.05145)

	Xinyan Hu, Kayo Yin, Michael I. Jordan, Jacob Steinhardt, Lijie Chen

+ [Revealing Weaknesses in Text Watermarking Through Self-Information Rewrite Attacks](https://arxiv.org//abs/2505.05190)

	Yixin Cheng, Hongcheng Guo, Yangming Li, Leonid Sigal

+ [Software Development Life Cycle Perspective: A Survey of Benchmarks for CodeLLMs and Agents](https://arxiv.org//abs/2505.05283)

	Kaixin Wang, Tianlin Li, Xiaoyu Zhang, Chong Wang, Weisong Sun, Yang Liu, Bin Shi

+ [Scalable Chain of Thoughts via Elastic Reasoning](https://arxiv.org//abs/2505.05315)

	Yuhui Xu, Hanze Dong, Lei Wang, Doyen Sahoo, Junnan Li, Caiming Xiong

+ [Crosslingual Reasoning through Test-Time Scaling](https://arxiv.org//abs/2505.05408)

	Zheng-Xin Yong, M. Farid Adilazuarda, Jonibek Mansurov, Ruochen Zhang, Niklas Muennighoff, Carsten Eickhoff, Genta Indra Winata, Julia Kreutzer, Stephen H. Bach, Alham Fikri Aji

+ [Reasoning Models Don't Always Say What They Think](https://arxiv.org//abs/2505.05410)

	Yanda Chen, Joe Benton, Ansh Radhakrishnan, Jonathan Uesato, Carson Denison, John Schulman, Arushi Somani, Peter Hase, Misha Wagner, Fabien Roger, Vlad Mikulik, Samuel R. Bowman, Jan Leike, Jared Kaplan, Ethan Perez

+ [ComPO: Preference Alignment via Comparison Oracles](https://arxiv.org//abs/2505.05465)

	Peter Chen, Xi Chen, Wotao Yin, Tianyi Lin

+ [StreamBridge: Turning Your Offline Video Large Language Model into a Proactive Streaming Assistant](https://arxiv.org//abs/2505.05467)

	Haibo Wang, Bo Feng, Zhengfeng Lai, Mingze Xu, Shiyu Li, Weifeng Ge, Afshin Dehghan, Meng Cao, Ping Huang

+ [Latent Preference Coding: Aligning Large Language Models via Discrete Latent Codes](https://arxiv.org//abs/2505.04993)

	Zhuocheng Gong, Jian Guan, Wei Wu, Huishuai Zhang, Dongyan Zhao

+ [The Pitfalls of Growing Group Complexity: LLMs and Social Choice-Based Aggregation for Group Recommendations](https://arxiv.org//abs/2505.05016)

	Cedric Waterschoot, Nava Tintarev, Francesco Barile

+ [Scalable Multi-Stage Influence Function for Large Language Models via Eigenvalue-Corrected Kronecker-Factored Parameterization](https://arxiv.org//abs/2505.05017)

	Yuntai Bao, Xuhong Zhang, Tianyu Du, Xinkui Zhao, Jiang Zong, Hao Peng, Jianwei Yin

+ [Reliably Bounding False Positives: A Zero-Shot Machine-Generated Text Detection Framework via Multiscaled Conformal Prediction](https://arxiv.org//abs/2505.05084)

	Xiaowei Zhu, Yubing Ren, Yanan Cao, Xixun Lin, Fang Fang, Yangxi Li

+ [Unveiling Language-Specific Features in Large Language Models via Sparse Autoencoders](https://arxiv.org//abs/2505.05111)

	Boyi Deng, Yu Wan, Yidan Zhang, Baosong Yang, Fuli Feng

+ [QualBench: Benchmarking Chinese LLMs with Localized Professional Qualifications for Vertical Domain Evaluation](https://arxiv.org//abs/2505.05225)

	Mengze Hong, Wailing Ng, Di Jiang, Chen Jason Zhang

+ [Toward Reasonable Parrots: Why Large Language Models Should Argue with Us by Design](https://arxiv.org//abs/2505.05298)

	Elena Musi, Nadin Kokciyan, Khalid Al-Khatib, Davide Ceolin, Emmanuelle Dietz, Klara Gutekunst, Annette Hautli-Janisz, Cristian Manuel Santibañez Yañez, Jodi Schneider, Jonas Scholz, Cor Steging, Jacky Visser, Henning Wachsmuth

+ [ICon: In-Context Contribution for Automatic Data Selection](https://arxiv.org//abs/2505.05327)

	Yixin Yang, Qingxiu Dong, Linli Yao, Fangwei Zhu, Zhifang Sui

+ [Frame In, Frame Out: Do LLMs Generate More Biased News Headlines than Humans?](https://arxiv.org//abs/2505.05406)

	Valeria Pastorino, Nafise Sadat Moosavi

+ [Ultra-FineWeb: Efficient Data Filtering and Verification for High-Quality LLM Training Data](https://arxiv.org//abs/2505.05427)

	Yudong Wang, Zixuan Fu, Jie Cai, Peijun Tang, Hongya Lyu, Yewei Fang, Zhi Zheng, Jie Zhou, Guoyang Zeng, Chaojun Xiao, Xu Han, Zhiyuan Liu

+ [clem:todd: A Framework for the Systematic Benchmarking of LLM-Based Task-Oriented Dialogue System Realisations](https://arxiv.org//abs/2505.05445)

	Chalamalasetti Kranti, Sherzod Hakimov, David Schlangen

+ [Bring Reason to Vision: Understanding Perception and Reasoning through Model Merging](https://arxiv.org//abs/2505.05464)

	Shiqi Chen, Jinghan Zhang, Tongyao Zhu, Wei Liu, Siyang Gao, Miao Xiong, Manling Li, Junxian He

+ [Perception, Reason, Think, and Plan: A Survey on Large Multimodal Reasoning Models](https://arxiv.org//abs/2505.04921)

	Yunxin Li, Zhenyu Liu, Zitao Li, Xuanyu Zhang, Zhenran Xu, Xinyu Chen, Haoyuan Shi, Shenyuan Jiang, Xintong Wang, Jifang Wang, Shouzheng Huang, Xinping Zhao, Borui Jiang, Lanqing Hong, Longyue Wang, Zhuotao Tian, Baoxing Huai, Wenhan Luo, Weihua Luo, Zheng Zhang, Baotian Hu, Min Zhang

+ [Prompt-Based LLMs for Position Bias-Aware Reranking in Personalized Recommendations](https://arxiv.org//abs/2505.04948)

	Md Aminul Islam, Ahmed Sayeed Faruk

+ [WaterDrum: Watermarking for Data-centric Unlearning Metric](https://arxiv.org//abs/2505.05064)

	Xinyang Lu, Xinyuan Niu, Gregory Kang Ruey Lau, Bui Thi Cam Nhung, Rachael Hwee Ling Sim, Fanyu Wen, Chuan-Sheng Foo, See-Kiong Ng, Bryan Kian Hsiang Low

+ [FedTDP: A Privacy-Preserving and Unified Framework for Trajectory Data Preparation via Federated Learning](https://arxiv.org//abs/2505.05155)

	Zhihao Zeng, Ziquan Fang, Wei Shao, Lu Chen, Yunjun Gao

+ [Latte: Transfering LLMs` Latent-level Knowledge for Few-shot Tabular Learning](https://arxiv.org//abs/2505.05237)

	Ruxue Shi, Hengrui Gu, Hangting Ye, Yiwei Dai, Xu Shen, Xin Wang

+ [A Weighted Byzantine Fault Tolerance Consensus Driven Trusted Multiple Large Language Models Network](https://arxiv.org//abs/2505.05103)

	Haoxiang Luo, Gang Sun, Yinqiu Liu, Dongcheng Zhao, Dusit Niyato, Hongfang Yu, Schahram Dustdar

+ [Safety by Measurement: A Systematic Literature Review of AI Safety Evaluation Methods](https://arxiv.org//abs/2505.05541)

	Markov Grey, Charbel-Raphaël Segerie

+ [HiBayES: A Hierarchical Bayesian Modeling Framework for AI Evaluation Statistics](https://arxiv.org//abs/2505.05602)

	Lennart Luettgau, Harry Coppock, Magda Dubois, Christopher Summerfield, Cozmin Ududec

+ [CityNavAgent: Aerial Vision-and-Language Navigation with Hierarchical Semantic Planning and Global Memory](https://arxiv.org//abs/2505.05622)

	Weichen Zhang, Chen Gao, Shiquan Yu, Ruiying Peng, Baining Zhao, Qian Zhang, Jinqiang Cui, Xinlei Chen, Yong Li

+ [Looking Beyond Language Priors: Enhancing Visual Comprehension and Attention in Multimodal Models](https://arxiv.org//abs/2505.05626)

	Aarti Ghatkesar, Uddeshya Upadhyay, Ganesh Venkatesh

+ [Adaptive Stress Testing Black-Box LLM Planners](https://arxiv.org//abs/2505.05665)

	Neeloy Chakraborty, John Pohovey, Melkior Ornik, Katherine Driggs-Campbell

+ [Lost in OCR Translation? Vision-Based Approaches to Robust Document Retrieval](https://arxiv.org//abs/2505.05666)

	Alexander Most, Joseph Winjum, Ayan Biswas, Shawn Jones, Nishath Rajiv Ranasinghe, Dan O'Malley, Manish Bhattarai

+ [EcoAgent: An Efficient Edge-Cloud Collaborative Multi-Agent Framework for Mobile Automation](https://arxiv.org//abs/2505.05440)

	Biao Yi, Xavier Hu, Yurun Chen, Shengyu Zhang, Hongxia Yang, Fan Wu, Fei Wu

+ [KG-HTC: Integrating Knowledge Graphs into LLMs for Effective Zero-shot Hierarchical Text Classification](https://arxiv.org//abs/2505.05583)

	Qianbo Zang, Christophe Zgrzendek, Igor Tchappi, Afshin Khadangi, Johannes Sedlmeir

+ [Privacy-Preserving Transformers: SwiftKey's Differential Privacy Implementation](https://arxiv.org//abs/2505.05648)

	Abdelrahman Abouelenin, Mohamed Abdelrehim, Raffy Fahim, Amr Hendy, Mohamed Afify

+ [PRIMG : Efficient LLM-driven Test Generation Using Mutant Prioritization](https://arxiv.org//abs/2505.05584)

	Mohamed Salah Bouafif, Mohammad Hamdaqa, Edward Zulkoski

+ [Enhancing Large Language Models with Faster Code Preprocessing for Vulnerability Detection](https://arxiv.org//abs/2505.05600)

	José Gonçalves, Miguel Silva, Eva Maia, Isabel Praça

+ [LiteLMGuard: Seamless and Lightweight On-Device Prompt Filtering for Safeguarding Small Language Models against Quantization-induced Risks and Vulnerabilities](https://arxiv.org//abs/2505.05619)

	Kalyan Nakka, Jimmy Dani, Ausmit Mondal, Nitesh Saxena

+ [User Behavior Analysis in Privacy Protection with Large Language Models: A Study on Privacy Preferences with Limited Data](https://arxiv.org//abs/2505.06305)

	Haowei Yang, Qingyi Lu, Yang Wang, Sibei Liu, Jiayun Zheng, Ao Xiang

+ [Large Language Model-driven Security Assistant for Internet of Things via Chain-of-Thought](https://arxiv.org//abs/2505.06307)

	Mingfei Zeng, Ming Xie, Xixi Zheng, Chunhai Li, Chuan Zhang, Liehuang Zhu

+ [Defending against Indirect Prompt Injection by Instruction Detection](https://arxiv.org//abs/2505.06311)

	Tongyu Wen, Chenglong Wang, Xiyuan Yang, Haoyu Tang, Yueqi Xie, Lingjuan Lyu, Zhicheng Dou, Fangzhao Wu

+ [AI Approaches to Qualitative and Quantitative News Analytics on NATO Unity](https://arxiv.org//abs/2505.06313)

	Bohdan M. Pavlyshenko

+ [Threat Modeling for AI: The Case for an Asset-Centric Approach](https://arxiv.org//abs/2505.06315)

	Jose Sanchez Vicarte, Marcin Spoczynski, Mostafa Elsaid

+ [RAP-SM: Robust Adversarial Prompt via Shadow Models for Copyright Verification of Large Language Models](https://arxiv.org//abs/2505.06304)

	Zhenhua Xu, Zhebo Wang, Maike Li, Wenpeng Xing, Chunqiang Hu, Chen Zhi, Meng Han

+ [Unpacking Robustness in Inflectional Languages: Adversarial Evaluation and Mechanistic Insights](https://arxiv.org//abs/2505.07856)

	Paweł Walkowiak, Marek Klonowski, Marcin Oleksy, Arkadiusz Janz

+ [Scaling Laws for Speculative Decoding](https://arxiv.org//abs/2505.07858)

	Siyuan Yan, Mo Zhu, Guo-qing Jiang, Jianfei Wang, Jiaxing Chen, Wentai Zhang, Xiang Liao, Xiao Cui, Chen Zhang, Zhuoran Song, Ran Zhu

+ [Scalable LLM Math Reasoning Acceleration with Low-rank Distillation](https://arxiv.org//abs/2505.07861)

	Harry Dong, Bilge Acun, Beidi Chen, Yuejie Chi

# 2025-05-07
+ [Advancing and Benchmarking Personalized Tool Invocation for LLMs](https://arxiv.org//abs/2505.04072)

	Xu Huang, Yuefeng Huang, Weiwen Liu, Xingshan Zeng, Yasheng Wang, Ruiming Tang, Hong Xie, Defu Lian

+ [LLM-e Guess: Can LLMs Capabilities Advance Without Hardware Progress?](https://arxiv.org//abs/2505.04075)

	Teddy Foley, Spencer Guo, Henry Josephson, Anqi Qu, Jack Sanderson

+ [LLMs' Suitability for Network Security: A Case Study of STRIDE Threat Modeling](https://arxiv.org//abs/2505.04101)

	AbdulAziz AbdulGhaffar, Ashraf Matrawy

+ [Unmasking the Canvas: A Dynamic Benchmark for Image Generation Jailbreaking and LLM Content Safety](https://arxiv.org//abs/2505.04146)

	Variath Madhupal Gautham Nair, Vishal Varma Dantuluri

+ [On-Device LLM for Context-Aware Wi-Fi Roaming](https://arxiv.org//abs/2505.04174)

	Ju-Hyung Lee, Yanqing Lu

+ [Facilitating Trustworthy Human-Agent Collaboration in LLM-based Multi-Agent System oriented Software Engineering](https://arxiv.org//abs/2505.04251)

	Krishna Ronanki

+ [Steerable Chatbots: Personalizing LLMs with Preference-Based Activation Steering](https://arxiv.org//abs/2505.04260)

	Jessica Y. Bo, Tianyu Xu, Ishan Chatterjee, Katrina Passarella-Ward, Achin Kulshrestha, D Shin

+ [Weaponizing Language Models for Cybersecurity Offensive Operations: Automating Vulnerability Assessment Report Validation; A Review Paper](https://arxiv.org//abs/2505.04265)

	Abdulrahman S Almuhaidib, Azlan Mohd Zain, Zalmiyah Zakaria, Izyan Izzati Kamsani, Abdulaziz S Almuhaidib

+ [The Aloe Family Recipe for Open and Specialized Healthcare LLMs](https://arxiv.org//abs/2505.04388)

	Dario Garcia-Gasulla, Jordi Bayarri-Planas, Ashwin Kumar Gururajan, Enrique Lopez-Cuena, Adrian Tormos, Daniel Hinjos, Pablo Bernabeu-Perez, Anna Arias-Duart, Pablo Agustin Martin-Torres, Marta Gonzalez-Mallo, Sergio Alvarez-Napagao, Eduard Ayguadé-Parra, Ulises Cortés

+ [OBLIVIATE: Robust and Practical Machine Unlearning for Large Language Models](https://arxiv.org//abs/2505.04416)

	Xiaoyu Xu, Minxin Du, Qingqing Ye, Haibo Hu

+ [Fight Fire with Fire: Defending Against Malicious RL Fine-Tuning via Reward Neutralization](https://arxiv.org//abs/2505.04578)

	Wenjun Cao

+ [EchoInk-R1: Exploring Audio-Visual Reasoning in Multimodal LLMs via Reinforcement Learning](https://arxiv.org//abs/2505.04623)

	Zhenghao Xing, Xiaowei Hu, Chi-Wing Fu, Wenhai Wang, Jifeng Dai, Pheng-Ann Heng

+ [Enhancing Granular Sentiment Classification with Chain-of-Thought Prompting in Large Language Models](https://arxiv.org//abs/2505.04135)

	Vihaan Miriyala, Smrithi Bukkapatnam, Lavanya Prahallad

+ [LLM-Independent Adaptive RAG: Let the Question Speak for Itself](https://arxiv.org//abs/2505.04253)

	Maria Marina, Nikolay Ivanov, Sergey Pletenev, Mikhail Salnikov, Daria Galimzianova, Nikita Krayko, Vasily Konovalov, Alexander Panchenko, Viktor Moskvoretskii

+ [Large Means Left: Political Bias in Large Language Models Increases with Their Number of Parameters](https://arxiv.org//abs/2505.04393)

	David Exler, Mark Schutera, Markus Reischl, Luca Rettenberger

+ [Pangu Ultra MoE: How to Train Your Big MoE on Ascend NPUs](https://arxiv.org//abs/2505.04519)

	Yehui Tang, Yichun Yin, Yaoyuan Wang, Hang Zhou, Yu Pan, Wei Guo, Ziyang Zhang, Miao Rang, Fangcheng Liu, Naifu Zhang, Binghan Li, Yonghan Dong, Xiaojun Meng, Yasheng Wang, Dong Li, Yin Li, Dandan Tu, Can Chen, Youliang Yan, Fisher Yu, Ruiming Tang, Yunhe Wang, Botian Huang, Bo Wang, Boxiao Liu, Changzheng Zhang, Da Kuang, Fei Liu, Gang Huang, Jiansheng Wei, Jiarui Qin, Jie Ran, Jinpeng Li, Jun Zhao, Liang Dai, Lin Li, Liqun Deng, Peifeng Qin, Pengyuan Zeng, Qiang Gu, Shaohua Tang, Shengjun Cheng, Tao Gao, Tao Yu, Tianshu Li, Tianyu Bi, Wei He, Weikai Mao, Wenyong Huang, Wulong Liu, Xiabing Li, Xianzhi Yu, Xueyu Wu, Xu He, Yangkai Du, Yan Xu, Ye Tian, Yimeng Wu, Yongbing Huang, Yong Tian, Yong Zhu, Yue Li, Yufei Wang, Yuhang Gai, Yujun Li, Yu Luo, Yunsheng Ni, Yusen Sun, Zelin Chen, Zhe Liu, Zhicheng Liu, Zhipeng Tu, Zilin Ding, Zongyuan Zhan

+ [ZeroSearch: Incentivize the Search Capability of LLMs without Searching](https://arxiv.org//abs/2505.04588)

	Hao Sun, Zile Qiao, Jiayan Guo, Xuanbo Fan, Yingyan Hou, Yong Jiang, Pengjun Xie, Fei Huang, Yan Zhang

+ [Large Language Models are often politically extreme, usually ideologically inconsistent, and persuasive even in informational contexts](https://arxiv.org//abs/2505.04171)

	Nouar Aldahoul, Hazem Ibrahim, Matteo Varvello, Aaron Kaufman, Talal Rahwan, Yasir Zaki

+ [Benchmarking LLMs' Swarm intelligence](https://arxiv.org//abs/2505.04364)

	Kai Ruan, Mowen Huang, Ji-Rong Wen, Hao Sun

+ [Componential Prompt-Knowledge Alignment for Domain Incremental Learning](https://arxiv.org//abs/2505.04575)

	Kunlun Xu, Xu Zou, Gang Hua, Jiahuan Zhou

+ [Towards Effectively Leveraging Execution Traces for Program Repair with Code LLMs](https://arxiv.org//abs/2505.04441)

	Mirazul Haque, Petr Babkin, Farima Farmahinifarahani, Manuela Veloso

+ [Communication-Efficient Federated Fine-Tuning of Language Models via Dynamic Update Schedules](https://arxiv.org//abs/2505.04535)

	Michail Theologitis, Vasilis Samoladas, Antonios Deligiannakis

+ [AutoPatch: Multi-Agent Framework for Patching Real-World CVE Vulnerabilities](https://arxiv.org//abs/2505.04195)

	Minjae Seo, Wonwoo Choi, Myoungsung You, Seungwon Shin

+ [The Promise and Limits of LLMs in Constructing Proofs and Hints for Logic Problems in Intelligent Tutoring Systems](https://arxiv.org//abs/2505.04736)

	Sutapa Dey Tithi, Arun Kumar Ramesh, Clara DiMarco, Xiaoyi Tian, Nazia Alam, Kimia Fazeli, Tiffany Barnes

+ [Large Language Models are Autonomous Cyber Defenders](https://arxiv.org//abs/2505.04843)

	Sebastián R. Castro, Roberto Campbell, Nancy Lau, Octavio Villalobos, Jiaqi Duan, Alvaro A. Cardenas

+ [Personalized Risks and Regulatory Strategies of Large Language Models in Digital Advertising](https://arxiv.org//abs/2505.04665)

	Haoyang Feng, Yanjun Dai, Yuan Gao

+ [REVEAL: Multi-turn Evaluation of Image-Input Harms for Vision LLM](https://arxiv.org//abs/2505.04673)

	Madhur Jindal, Saurabh Deshpande

+ [QBD-RankedDataGen: Generating Custom Ranked Datasets for Improving Query-By-Document Search Using LLM-Reranking with Reduced Human Effort](https://arxiv.org//abs/2505.04732)

	Sriram Gopalakrishnan, Sunandita Patra

+ [When Bad Data Leads to Good Models](https://arxiv.org//abs/2505.04741)

	Kenneth Li, Yida Chen, Fernanda Viégas, Martin Wattenberg

+ [A Proposal for Evaluating the Operational Risk for ChatBots based on Large Language Models](https://arxiv.org//abs/2505.04784)

	Pedro Pinacho-Davidson, Fernando Gutierrez, Pablo Zapata, Rodolfo Vergara, Pablo Aqueveque

+ [Putting the Value Back in RL: Better Test-Time Scaling by Unifying LLM Reasoners With Verifiers](https://arxiv.org//abs/2505.04842)

	Kusha Sareen, Morgane M Moss, Alessandro Sordoni, Rishabh Agarwal, Arian Hosseini

+ [Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards](https://arxiv.org//abs/2505.04847)

	Manveer Singh Tamber, Forrest Sheng Bao, Chenyu Xu, Ge Luo, Suleman Kazi, Minseok Bae, Miaoran Li, Ofer Mendelevitch, Renyi Qu, Jimmy Lin

+ [Fine-Tuning Large Language Models and Evaluating Retrieval Methods for Improved Question Answering on Building Codes](https://arxiv.org//abs/2505.04666)

	Mohammad Aqib, Mohd Hamza, Qipei Mei, Ying Hei Chui

+ [Reward-SQL: Boosting Text-to-SQL via Stepwise Reasoning and Process-Supervised Rewards](https://arxiv.org//abs/2505.04671)

	Yuxin Zhang, Meihao Fan, Ju Fan, Mingyang Yi, Yuyu Luo, Jian Tan, Guoliang Li

+ [SOAEsV2-7B/72B: Full-Pipeline Optimization for State-Owned Enterprise LLMs via Continual Pre-Training, Domain-Progressive SFT and Distillation-Enhanced Speculative Decoding](https://arxiv.org//abs/2505.04723)

	Jingyang Deng, Ran Chen, Jo-Ku Cheng, Jinwen Ma

+ [Osiris: A Lightweight Open-Source Hallucination Detection System](https://arxiv.org//abs/2505.04844)

	Alex Shan, John Bauer, Christopher D. Manning

+ [Red Teaming the Mind of the Machine: A Systematic Evaluation of Prompt Injection and Jailbreak Vulnerabilities in LLMs](https://arxiv.org//abs/2505.04806)

	Chetan Pathade

+ [HiPerRAG: High-Performance Retrieval Augmented Generation for Scientific Insights](https://arxiv.org//abs/2505.04846)

	Ozan Gokdemir, Carlo Siebenschuh, Alexander Brace, Azton Wells, Brian Hsu, Kyle Hippe, Priyanka V. Setty, Aswathy Ajith, J. Gregory Pauloski, Varuni Sastry, Sam Foreman, Huihuo Zheng, Heng Ma, Bharat Kale, Nicholas Chia, Thomas Gibbs, Michael E. Papka, Thomas Brettin, Francis J. Alexander, Anima Anandkumar, Ian Foster, Rick Stevens, Venkatram Vishwanath, Arvind Ramanathan

+ [Safeguard-by-Development: A Privacy-Enhanced Development Paradigm for Multi-Agent Collaboration Systems](https://arxiv.org//abs/2505.04799)

	Jian Cui, Zichuan Li, Luyi Xing, Xiaojing Liao

+ [Nature's Insight: A Novel Framework and Comprehensive Analysis of Agentic Reasoning Through the Lens of Neuroscience](https://arxiv.org//abs/2505.05515)

	Zinan Liu, Haoran Li, Jingyi Lu, Gaoyuan Ma, Xu Hong, Giovanni Iacca, Arvind Kumar, Shaojun Tang, Lin Wang

+ [DMRL: Data- and Model-aware Reward Learning for Data Extraction](https://arxiv.org//abs/2505.06284)

	Zhiqiang Wang, Ruoxi Cheng

+ [Winning at All Cost: A Small Environment for Eliciting Specification Gaming Behaviors in Large Language Models](https://arxiv.org//abs/2505.07846)

	Lars Malmqvist

+ [Joint Detection of Fraud and Concept Drift inOnline Conversations with LLM-Assisted Judgment](https://arxiv.org//abs/2505.07852)

	Ali Senol, Garima Agrawal, Huan Liu

# 2025-05-06
+ [Holmes: Automated Fact Check with Large Language Models](https://arxiv.org//abs/2505.03135)

	Haoran Ou, Gelei Deng, Xingshuo Han, Jie Zhang, Xinlei He, Han Qiu, Shangwei Guo, Tianwei Zhang

+ [Patterns and Mechanisms of Contrastive Activation Engineering](https://arxiv.org//abs/2505.03189)

	Yixiong Hao, Ayush Panda, Stepan Shabalin, Sheikh Abdur Raheem Ali

+ [RAG-MCP: Mitigating Prompt Bloat in LLM Tool Selection via Retrieval-Augmented Generation](https://arxiv.org//abs/2505.03275)

	Tiantian Gan, Qiyao Sun

+ [Capability-Driven Skill Generation with LLMs: A RAG-Based Approach for Reusing Existing Libraries and Interfaces](https://arxiv.org//abs/2505.03295)

	Luis Miguel Vieira da Silva, Aljosha Köcher, Nicolas König, Felix Gehlhoff, Alexander Fay

+ [AI-Driven Scholarly Peer Review via Persistent Workflow Prompting, Meta-Prompting, and Meta-Reasoning](https://arxiv.org//abs/2505.03332)

	Evgeny Markhasin

+ [Procedural Memory Is Not All You Need: Bridging Cognitive Gaps in LLM-Based Agents](https://arxiv.org//abs/2505.03434)

	Schaun Wheeler, Olivier Jeunen

+ [The Steganographic Potentials of Language Models](https://arxiv.org//abs/2505.03439)

	Artem Karpov, Tinuade Adeleke, Seong Hah Cho, Natalia Perez-Campanero

+ [am-ELO: A Stable Framework for Arena-based LLM Evaluation](https://arxiv.org//abs/2505.03475)

	Zirui Liu, Jiatong Li, Yan Zhuang, Qi Liu, Shuanghong Shen, Jie Ouyang, Mingyue Cheng, Shijin Wang

+ [A Hashgraph-Inspired Consensus Mechanism for Reliable Multi-Model Reasoning](https://arxiv.org//abs/2505.03553)

	Kolawole E. Ogunsina, Morayo A. Ogunsina

+ [Assessing and Enhancing the Robustness of LLM-based Multi-Agent Systems Through Chaos Engineering](https://arxiv.org//abs/2505.03096)

	Joshua Owotogbe

+ [Soft Best-of-n Sampling for Model Alignment](https://arxiv.org//abs/2505.03156)

	Claudio Mayrink Verdun, Alex Oesterling, Himabindu Lakkaraju, Flavio P. Calmon

+ [A Trustworthy Multi-LLM Network: Challenges,Solutions, and A Use Case](https://arxiv.org//abs/2505.03196)

	Haoxiang Luo, Gang Sun, Yinqiu Liu, Dusit Niyato, Hongfang Yu, Mohammed Atiquzzaman, Schahram Dustdar

+ [Absolute Zero: Reinforced Self-play Reasoning with Zero Data](https://arxiv.org//abs/2505.03335)

	Andrew Zhao, Yiran Wu, Yang Yue, Tong Wu, Quentin Xu, Yang Yue, Matthieu Lin, Shenzhi Wang, Qingyun Wu, Zilong Zheng, Gao Huang

+ [SPAP: Structured Pruning via Alternating Optimization and Penalty Methods](https://arxiv.org//abs/2505.03373)

	Hanyu Hu, Xiaoming Yuan

+ [Automatic Calibration for Membership Inference Attack on Large Language Models](https://arxiv.org//abs/2505.03392)

	Saleh Zare Zade, Yao Qiang, Xiangyu Zhou, Hui Zhu, Mohammad Amin Roshani, Prashant Khanduri, Dongxiao Zhu

+ [Lightweight Clinical Decision Support System using QLoRA-Fine-Tuned LLMs and Retrieval-Augmented Generation](https://arxiv.org//abs/2505.03406)

	Mohammad Shoaib Ansari, Mohd Sohail Ali Khan, Shubham Revankar, Aditya Varma, Anil S. Mokhade

+ [An Analysis of Hyper-Parameter Optimization Methods for Retrieval Augmented Generation](https://arxiv.org//abs/2505.03452)

	Matan Orbach, Ohad Eytan, Benjamin Sznajder, Ariel Gera, Odellia Boni, Yoav Kantor, Gal Bloch, Omri Levy, Hadas Abraham, Nitzan Barzilay, Eyal Shnarch, Michael E. Factor, Shila Ofek-Koifman, Paula Ta-Shma, Assaf Toledo

+ [A new membership inference attack that spots memorization in generative and predictive models: Loss-Based with Reference Model algorithm (LBRM)](https://arxiv.org//abs/2505.03490)

	Faiz Taleb, Ivan Gazeau, Maryline Laurent

+ [LlamaFirewall: An open source guardrail system for building secure AI agents](https://arxiv.org//abs/2505.03574)

	Sahana Chennabasappa, Cyrus Nikolaidis, Daniel Song, David Molnar, Stephanie Ding, Shengye Wan, Spencer Whitman, Lauren Deason, Nicholas Doucette, Abraham Montilla, Alekhya Gampa, Beto de Paola, Dominik Gabi, James Crnkovich, Jean-Christophe Testud, Kat He, Rashnil Chaturvedi, Wu Zhou, Joshua Saxe

+ [ReGraP-LLaVA: Reasoning enabled Graph-based Personalized Large Language and Vision Assistant](https://arxiv.org//abs/2505.03654)

	Yifan Xiang, Zhenxi Zhang, Bin Li, Yixuan Weng, Shoujun Zhou, Yangfan He, Keqin Li

+ [Ψ-Arena: Interactive Assessment and Optimization of LLM-based Psychological Counselors with Tripartite Feedback](https://arxiv.org//abs/2505.03293)

	Shijing Zhu, Zhuang Chen, Guanqun Bi, Binghang Li, Yaxi Deng, Dazhen Wan, Libiao Peng, Xiyao Xiao, Rongsheng Zhang, Tangjie Lv, Zhipeng Hu, FangFang Li, Minlie Huang

+ [Recall with Reasoning: Chain-of-Thought Distillation for Mamba's Long-Context Memory and Extrapolation](https://arxiv.org//abs/2505.03320)

	Junyu Ma, Tianqing Fang, Zhisong Zhang, Hongming Zhang, Haitao Mi, Dong Yu

+ [Uncertainty-Aware Large Language Models for Explainable Disease Diagnosis](https://arxiv.org//abs/2505.03467)

	Shuang Zhou, Jiashuo Wang, Zidu Xu, Song Wang, David Brauer, Lindsay Welton, Jacob Cogan, Yuen-Hei Chung, Lei Tian, Zaifu Zhan, Yu Hou, Mingquan Lin, Genevieve B. Melton, Rui Zhang

+ [Long-Short Chain-of-Thought Mixture Supervised Fine-Tuning Eliciting Efficient Reasoning in Large Language Models](https://arxiv.org//abs/2505.03469)

	Bin Yu, Hang Yuan, Yuliang Wei, Bailing Wang, Weizhen Qi, Kai Chen

+ [Evaluation of LLMs on Long-tail Entity Linking in Historical Documents](https://arxiv.org//abs/2505.03473)

	Marta Boscariol, Luana Bulla, Lia Draetta, Beatrice Fiumanò, Emanuele Lenzi, Leonardo Piano

+ [Faster MoE LLM Inference for Extremely Large Models](https://arxiv.org//abs/2505.03531)

	Haoqi Yang, Luohe Shi, Qiwei Li, Zuchao Li, Ping Wang, Bo Du, Mengjia Shen, Hai Zhao

+ [Say It Another Way: A Framework for User-Grounded Paraphrasing](https://arxiv.org//abs/2505.03563)

	Cléa Chataigner, Rebecca Ma, Prakhar Ganesh, Afaf Taïk, Elliot Creager, Golnoosh Farnadi

+ [WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional Websites from Scratch](https://arxiv.org//abs/2505.03733)

	Zimu Lu, Yunqiao Yang, Houxing Ren, Haotian Hou, Han Xiao, Ke Wang, Weikang Shi, Aojun Zhou, Mingjie Zhan, Hongsheng Li

+ [BadLingual: A Novel Lingual-Backdoor Attack against Large Language Models](https://arxiv.org//abs/2505.03501)

	Zihan Wang, Hongwei Li, Rui Zhang, Wenbo Jiang, Kangjie Chen, Tianwei Zhang, Qingchuan Zhao, Guowen Xu

+ [VLM Q-Learning: Aligning Vision-Language Models for Interactive Decision-Making](https://arxiv.org//abs/2505.03181)

	Jake Grigsby, Yuke Zhu, Michael Ryoo, Juan Carlos Niebles

+ [DYSTIL: Dynamic Strategy Induction with Large Language Models for Reinforcement Learning](https://arxiv.org//abs/2505.03209)

	Borui Wang, Kathleen McKeown, Rex Ying

+ [Geospatial Mechanistic Interpretability of Large Language Models](https://arxiv.org//abs/2505.03368)

	Stef De Sabbata, Stefano Mizzaro, Kevin Roitero

+ [Knowledge Augmented Complex Problem Solving with Large Language Models: A Survey](https://arxiv.org//abs/2505.03418)

	Da Zheng, Lun Du, Junwei Su, Yuchen Tian, Yuqi Zhu, Jintian Zhang, Lanning Wei, Ningyu Zhang, Huajun Chen

+ [Uncovering the Limitations of Model Inversion Evaluation: Benchmarks and Connection to Type-I Adversarial Attacks](https://arxiv.org//abs/2505.03519)

	Sy-Tuyen Ho, Koh Jun Hao, Ngoc-Bao Nguyen, Alexander Binder, Ngai-Man Cheung

+ [Towards a standardized methodology and dataset for evaluating LLM-based digital forensic timeline analysis](https://arxiv.org//abs/2505.03100)

	Hudan Studiawan, Frank Breitinger, Mark Scanlon

+ [Towards Effective Identification of Attack Techniques in Cyber Threat Intelligence Reports using Large Language Models](https://arxiv.org//abs/2505.03147)

	Hoang Cuong Nguyen, Shahroz Tariq, Mohan Baruwal Chhetri, Bao Quoc Vo

+ [An LLM-based Self-Evolving Security Framework for 6G Space-Air-Ground Integrated Networks](https://arxiv.org//abs/2505.03161)

	Qi Qin, Xinye Cao, Guoshun Nan, Sihan Chen, Rushan Li, Li Su, Haitao Du, Qimei Cui, Pengxuan Mao, Xiaofeng Tao, Tony Q.S. Quek

+ [Bridging Expertise Gaps: The Role of LLMs in Human-AI Collaboration for Cybersecurity](https://arxiv.org//abs/2505.03179)

	Shahroz Tariq, Ronal Singh, Mohan Baruwal Chhetri, Surya Nepal, Cecile Paris

+ [A Chaos Driven Metric for Backdoor Attack Detection](https://arxiv.org//abs/2505.03208)

	Hema Karnam Surendrababu (1), Nithin Nagaraj (2) ((1) School of Conflict and Security Studies, National Institute of Advanced Studies, Indian Institute of Science Campus, Bengaluru (2) Complex Systems Programme, National Institute of Advanced Studies, Indian Institute of Science Campus, Bengaluru)

+ [Elevating Cyber Threat Intelligence against Disinformation Campaigns with LLM-based Concept Extraction and the FakeCTI Dataset](https://arxiv.org//abs/2505.03345)

	Domenico Cotroneo, Roberto Natella, Vittorio Orbinato

+ [Directed Greybox Fuzzing via Large Language Model](https://arxiv.org//abs/2505.03425)

	Hanxiang Xu, Yanjie Zhao, Haoyu Wang

+ [Frog Soup: Zero-Shot, In-Context, and Sample-Efficient Frogger Agents](https://arxiv.org//abs/2505.03947)

	Xiang Li, Yiyang Hao, Doug Fulop

+ [The Power of Stories: Narrative Priming Shapes How LLM Agents Collaborate and Compete](https://arxiv.org//abs/2505.03961)

	Gerrit Großmann, Larisa Ivanova, Sai Leela Poduru, Mohaddeseh Tabrizian, Islam Mesabah, David A. Selby, Sebastian J. Vollmer

+ [From Glue-Code to Protocols: A Critical Analysis of A2A and MCP Integration for Scalable Agent Systems](https://arxiv.org//abs/2505.03864)

	Qiaomu Li, Ying Xie

+ [MergeGuard: Efficient Thwarting of Trojan Attacks in Machine Learning Models](https://arxiv.org//abs/2505.04015)

	Soheil Zibakhsh Shabgahi, Yaman Jandali, Farinaz Koushanfar

+ [SLOT: Structuring the Output of Large Language Models](https://arxiv.org//abs/2505.04016)

	Darren Yow-Bang Wang, Zhengyuan Shen, Soumya Smruti Mishra, Zhichao Xu, Yifei Teng, Haibo Ding

+ [Prism: Unleashing GPU Sharing for Cost-Efficient Multi-LLM Serving](https://arxiv.org//abs/2505.04021)

	Shan Yu, Jiarong Xing, Yifan Qiao, Mingyuan Ma, Yangmin Li, Yang Wang, Shuo Yang, Zhiqiang Xie, Shiyi Cao, Ke Bao, Ion Stoica, Harry Xu, Ying Sheng

+ [A Reasoning-Focused Legal Retrieval Benchmark](https://arxiv.org//abs/2505.03970)

	Lucia Zheng, Neel Guha, Javokhir Arifov, Sarah Zhang, Michal Skreta, Christopher D. Manning, Peter Henderson, Daniel E. Ho

+ [Divide, Optimize, Merge: Fine-Grained LLM Agent Optimization at Scale](https://arxiv.org//abs/2505.03973)

	Jiale Liu, Yifan Zeng, Shaokun Zhang, Chi Zhang, Malte Højmark-Bertelsen, Marie Normann Gadeberg, Huazheng Wang, Qingyun Wu

+ [Quiet Feature Learning in Algorithmic Tasks](https://arxiv.org//abs/2505.03997)

	Prudhviraj Naidu, Zixian Wang, Leon Bergen, Ramamohan Paturi

+ [MARCO: A Multi-Agent System for Optimizing HPC Code Generation Using Large Language Models](https://arxiv.org//abs/2505.03906)

	Asif Rahman, Veljko Cvetkovic, Kathleen Reece, Aidan Walters, Yasir Hassan, Aneesh Tummeti, Bryan Torres, Denise Cooney, Margaret Ellis, Dimitrios S. Nikolopoulos

+ [FRAME: Feedback-Refined Agent Methodology for Enhancing Medical Research Insights](https://arxiv.org//abs/2505.04649)

	Chengzhang Yu, Yiming Zhang, Zhixin Liu, Zenghui Ding, Yining Sun, Zhanpeng Jin

+ [Scientific Hypothesis Generation and Validation: Methods, Datasets, and Future Directions](https://arxiv.org//abs/2505.04651)

	Adithya Kulkarni, Fatimah Alotaibi, Xinyue Zeng, Longfeng Wu, Tong Zeng, Barry Menglong Yao, Minqian Liu, Shuaicheng Zhang, Lifu Huang, Dawei Zhou

+ [A Comparative Analysis of Ethical and Safety Gaps in LLMs using Relative Danger Coefficient](https://arxiv.org//abs/2505.04654)

	Yehor Tereshchenko, Mika Hämäläinen

+ [A Sensitivity-Driven Expert Allocation Method in LoRA-MoE for Efficient Fine-Tuning](https://arxiv.org//abs/2505.06272)

	Junzhou Xu, Boyu Diao

+ [Policy-labeled Preference Learning: Is Preference Enough for RLHF?](https://arxiv.org//abs/2505.06273)

	Taehyun Cho, Seokhun Ju, Seungyub Han, Dohyeong Kim, Kyungjae Lee, Jungwoo Lee

+ [PARM: Multi-Objective Test-Time Alignment via Preference-Aware Autoregressive Reward Model](https://arxiv.org//abs/2505.06274)

	Baijiong Lin, Weisen Jiang, Yuancheng Xu, Hao Chen, Ying-Cong Chen

# 2025-05-05
+ [HyperTree Planning: Enhancing LLM Reasoning via Hierarchical Thinking](https://arxiv.org//abs/2505.02322)

	Runquan Gui, Zhihai Wang, Jie Wang, Chi Ma, Huiling Zhen, Mingxuan Yuan, Jianye Hao, Defu Lian, Enhong Chen, Feng Wu

+ [Recursive Decomposition with Dependencies for Generic Divide-and-Conquer Reasoning](https://arxiv.org//abs/2505.02576)

	Sergio Hernández-Gutiérrez, Minttu Alakuijala, Alexander V. Nikitin, Pekka Marttinen

+ [Agentic Neurodivergence as a Contingent Solution to the AI Alignment Problem](https://arxiv.org//abs/2505.02581)

	Alberto Hernández-Espinosa, Felipe S. Abrahão, Olaf Witkowski, Hector Zenil

+ [A Survey of Slow Thinking-based Reasoning LLMs using Reinforced Learning and Inference-time Scaling Law](https://arxiv.org//abs/2505.02665)

	Qianjun Pan, Wenkai Ji, Yuyang Ding, Junsong Li, Shilian Chen, Junyi Wang, Jie Zhou, Qin Chen, Min Zhang, Yulan Wu, Liang He

+ [Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play](https://arxiv.org//abs/2505.02707)

	Yemin Shi, Yu Shu, Siwei Dong, Guangyi Liu, Jaward Sesay, Jingwen Li, Zhiting Hu

+ [Technical Report: Evaluating Goal Drift in Language Model Agents](https://arxiv.org//abs/2505.02709)

	Rauno Arike, Elizabeth Donoway, Henning Bartsch, Marius Hobbhahn

+ [Enhancing LLMs' Clinical Reasoning with Real-World Data from a Nationwide Sepsis Registry](https://arxiv.org//abs/2505.02722)

	Junu Kim, Chaeeun Shim, Sungjin Park, Su Yeon Lee, Gee Young Suh, Chae-Man Lim, Seong Jin Choi, Song Mi Moon, Kyoung-Ho Song, Eu Suk Kim, Hong Bin Kim, Sejoong Kim, Chami Im, Dong-Wan Kang, Yong Soo Kim, Hee-Joon Bae, Sung Yoon Lim, Han-Gil Jeong, Edward Choi

+ [Knowing You Don't Know: Learning When to Continue Search in Multi-round RAG through Self-Practicing](https://arxiv.org//abs/2505.02811)

	Diji Yang, Linda Zeng, Jinmeng Rao, Yi Zhang

+ [AutoLibra: Agent Metric Induction from Open-Ended Feedback](https://arxiv.org//abs/2505.02820)

	Hao Zhu, Phil Cuvin, Xinkai Yu, Charlotte Ka Yee Yan, Jason Zhang, Diyi Yang

+ [Optimizing LLMs for Resource-Constrained Environments: A Survey of Model Compression Techniques](https://arxiv.org//abs/2505.02309)

	Sanjay Surendranath Girija, Shashank Kapoor, Lakshit Arora, Dipen Pradhan, Aman Raj, Ankit Shetgaonkar

+ [RM-R1: Reward Modeling as Reasoning](https://arxiv.org//abs/2505.02387)

	Xiusi Chen, Gaotang Li, Ziqi Wang, Bowen Jin, Cheng Qian, Yu Wang, Hongru Wang, Yu Zhang, Denghui Zhang, Tong Zhang, Hanghang Tong, Heng Ji

+ [Optimizing Chain-of-Thought Reasoners via Gradient Variance Minimization in Rejection Sampling and RL](https://arxiv.org//abs/2505.02391)

	Jiarui Yao, Yifan Hao, Hanning Zhang, Hanze Dong, Wei Xiong, Nan Jiang, Tong Zhang

+ [SEFE: Superficial and Essential Forgetting Eliminator for Multimodal Continual Instruction Tuning](https://arxiv.org//abs/2505.02486)

	Jinpeng Chen, Runmin Cong, Yuzhi Zhao, Hongzheng Yang, Guangneng Hu, Horace Ho Shing Ip, Sam Kwong

+ [Unveiling the Landscape of LLM Deployment in the Wild: An Empirical Study](https://arxiv.org//abs/2505.02502)

	Xinyi Hou, Jiahao Han, Yanjie Zhao, Haoyu Wang

+ [Large Language Model Partitioning for Low-Latency Inference at the Edge](https://arxiv.org//abs/2505.02533)

	Dimitrios Kafetzis, Ramin Khalili, Iordanis Koutsopoulos

+ [EMORL: Ensemble Multi-Objective Reinforcement Learning for Efficient and Flexible LLM Fine-Tuning](https://arxiv.org//abs/2505.02579)

	Lingxiao Kong (1), Cong Yang (2), Susanne Neufang (3), Oya Deniz Beyan (1,3), Zeyd Boukhers (1,3) ((1) Fraunhofer Institute for Applied Information Technology FIT, (2) Soochow University, (3) University Hospital of Cologne)

+ [LLaMA-Omni2: LLM-based Real-time Spoken Chatbot with Autoregressive Streaming Speech Synthesis](https://arxiv.org//abs/2505.02625)

	Qingkai Fang, Yan Zhou, Shoutao Guo, Shaolei Zhang, Yang Feng

+ [Knowledge Graphs for Enhancing Large Language Models in Entity Disambiguation](https://arxiv.org//abs/2505.02737)

	Pons Gerard, Bilalli Besim, Queralt Anna

+ [HSplitLoRA: A Heterogeneous Split Parameter-Efficient Fine-Tuning Framework for Large Language Models](https://arxiv.org//abs/2505.02795)

	Zheng Lin, Yuxin Zhang, Zhe Chen, Zihan Fang, Xianhao Chen, Praneeth Vepakomma, Wei Ni, Jun Luo, Yue Gao

+ [Generative Sign-description Prompts with Multi-positive Contrastive Learning for Sign Language Recognition](https://arxiv.org//abs/2505.02304)

	Siyu Liang, Yunan Li, Wentian Xin, Huizhou Chen, Xujie Liu, Kang Liu, Qiguang Miao

+ [Invoke Interfaces Only When Needed: Adaptive Invocation for Large Language Models in Question Answering](https://arxiv.org//abs/2505.02311)

	Jihao Zhao, Chunlai Zhou, Biao Qin

+ [SIMPLEMIX: Frustratingly Simple Mixing of Off- and On-policy Data in Language Model Preference Learning](https://arxiv.org//abs/2505.02363)

	Tianjian Li, Daniel Khashabi

+ [Colombian Waitresses y Jueces canadienses: Gender and Country Biases in Occupation Recommendations from LLMs](https://arxiv.org//abs/2505.02456)

	Elisa Forcada Rodríguez, Olatz Perez-de-Viñaspre, Jon Ander Campos, Dietrich Klakow, Vagrant Gautam

+ [A Survey on Progress in LLM Alignment from the Perspective of Reward Design](https://arxiv.org//abs/2505.02666)

	Miaomiao Ji, Yanqiu Wu, Zhibin Wu, Shoujin Wang, Jian Yang, Mark Dras, Usman Naseem

+ [Sailing AI by the Stars: A Survey of Learning from Rewards in Post-Training and Test-Time Scaling of Large Language Models](https://arxiv.org//abs/2505.02686)

	Xiaobao Wu

+ [ReplaceMe: Network Simplification via Layer Pruning and Linear Transformations](https://arxiv.org//abs/2505.02819)

	Dmitriy Shopkhoev, Ammar Ali, Magauiya Zhussip, Valentin Malykh, Stamatios Lefkimmiatis, Nikos Komodakis, Sergey Zagoruyko

+ [R1-Reward: Training Multimodal Reward Model Through Stable Reinforcement Learning](https://arxiv.org//abs/2505.02835)

	Yi-Fan Zhang, Xingyu Lu, Xiao Hu, Chaoyou Fu, Bin Wen, Tianke Zhang, Changyi Liu, Kaiyu Jiang, Kaibing Chen, Kaiyu Tang, Haojie Ding, Jiankang Chen, Fan Yang, Zhang Zhang, Tingting Gao, Liang Wang

+ [Scenethesis: A Language and Vision Agentic Framework for 3D Scene Generation](https://arxiv.org//abs/2505.02836)

	Lu Ling, Chen-Hsuan Lin, Tsung-Yi Lin, Yifan Ding, Yu Zeng, Yichen Sheng, Yunhao Ge, Ming-Yu Liu, Aniket Bera, Zhaoshuo Li

+ [EntroLLM: Entropy Encoded Weight Compression for Efficient Large Language Model Inference on Edge Devices](https://arxiv.org//abs/2505.02380)

	Arnab Sanyal, Prithwish Mukherjee, Gourav Datta, Sandeep P. Chinchali

+ [An End-to-End Model For Logits Based Large Language Models Watermarking](https://arxiv.org//abs/2505.02344)

	Kahim Wong, Jicheng Zhou, Jiantao Zhou, Yain-Whar Si

+ [Iterative Resolution of Prompt Ambiguities Using a Progressive Cutting-Search Approach](https://arxiv.org//abs/2505.02952)

	Fabrizio Marozzo

+ [Rewriting Pre-Training Data Boosts LLM Performance in Math and Code](https://arxiv.org//abs/2505.02881)

	Kazuki Fujii, Yukito Tajima, Sakae Mizuki, Hinari Shimada, Taihei Shiotani, Koshiro Saito, Masanari Ohi, Masaki Kawamura, Taishi Nakamura, Takumi Okamoto, Shigeki Ishida, Kakeru Hattori, Youmi Ma, Hiroya Takamura, Rio Yokota, Naoaki Okazaki

+ [Unlearning vs. Obfuscation: Are We Truly Removing Knowledge?](https://arxiv.org//abs/2505.02884)

	Guangzhi Sun, Potsawee Manakul, Xiao Zhan, Mark Gales

+ [When Your Own Output Becomes Your Training Data: Noise-to-Meaning Loops and a Formal RSI Trigger](https://arxiv.org//abs/2505.02888)

	Rintaro Ando

+ [Memorization or Interpolation ? Detecting LLM Memorization through Input Perturbation Analysis](https://arxiv.org//abs/2505.03019)

	Albérick Euraste Djiré, Abdoul Kader Kaboré, Earl T. Barr, Jacques Klein, Tegawendé F. Bissyandé

+ [Developing A Framework to Support Human Evaluation of Bias in Generated Free Response Text](https://arxiv.org//abs/2505.03053)

	Jennifer Healey, Laurie Byrum, Md Nadeem Akhtar, Surabhi Bhargava, Moumita Sinha

+ [UCSC at SemEval-2025 Task 3: Context, Models and Prompt Optimization for Automated Hallucination Detection in LLM Output](https://arxiv.org//abs/2505.03030)

	Sicong Huang, Jincheng He, Shiyuan Huang, Karthik Raja Anandan, Arkajyoti Chakraborty, Ian Lane

+ [Teaching Models to Understand (but not Generate) High-risk Data](https://arxiv.org//abs/2505.03052)

	Ryan Wang, Matthew Finlayson, Luca Soldaini, Swabha Swayamdipta, Robin Jia

+ [Improving Model Alignment Through Collective Intelligence of Open-Source LLMS](https://arxiv.org//abs/2505.03059)

	Junlin Wang, Roy Xie, Shang Zhu, Jue Wang, Ben Athiwaratkun, Bhuwan Dhingra, Shuaiwen Leon Song, Ce Zhang, James Zou

+ [Radio: Rate-Distortion Optimization for Large Language Model Compression](https://arxiv.org//abs/2505.03031)

	Sean I. Young

+ [RetroInfer: A Vector-Storage Approach for Scalable Long-Context LLM Inference](https://arxiv.org//abs/2505.02922)

	Yaoqi Chen, Jinkai Zhang, Baotong Lu, Qianxi Zhang, Chengruidong Zhang, Jingjia Luo, Di Liu, Huiqiang Jiang, Qi Chen, Jing Liu, Bailu Ding, Xiao Yan, Jiawei Jiang, Chen Chen, Mingxing Zhang, Yuqing Yang, Fan Yang, Mao Yang

+ [34 Examples of LLM Applications in Materials Science and Chemistry: Towards Automation, Assistants, Agents, and Accelerated Scientific Discovery](https://arxiv.org//abs/2505.03049)

	Yoel Zimmermann, Adib Bazgir, Alexander Al-Feghali, Mehrad Ansari, L. Catherine Brinson, Yuan Chiang, Defne Circi, Min-Hsueh Chiu, Nathan Daelman, Matthew L. Evans, Abhijeet S. Gangan, Janine George, Hassan Harb, Ghazal Khalighinejad, Sartaaj Takrim Khan, Sascha Klawohn, Magdalena Lederbauer, Soroush Mahjoubi, Bernadette Mohr, Seyed Mohamad Moosavi, Aakash Naik, Aleyna Beste Ozhan, Dieter Plessers, Aritra Roy, Fabian Schöppach, Philippe Schwaller, Carla Terboven, Katharina Ueltzen, Shang Zhu, Jan Janssen, Calvin Li, Ian Foster, Ben Blaiszik

+ [RADLADS: Rapid Attention Distillation to Linear Attention Decoders at Scale](https://arxiv.org//abs/2505.03005)

	Daniel Goldstein, Eric Alcaide, Janna Lu, Eugene Cheah

+ [AKD : Adversarial Knowledge Distillation For Large Language Models Alignment on Coding tasks](https://arxiv.org//abs/2505.06267)

	Ilyas Oulkadda, Julien Perez

+ [SafeMate: A Modular RAG-Based Agent for Context-Aware Emergency Guidance](https://arxiv.org//abs/2505.02306)

	Junfeng Jiao, Jihyung Park, Yiming Xu, Kristen Sussman, Lucy Atkinson

# 2025-05-04
+ [Leveraging LLM Agents and Digital Twins for Fault Handling in Process Plants](https://arxiv.org//abs/2505.02076)

	Milapji Singh Gill, Javal Vyas, Artan Markaj, Felix Gehlhoff, Mehmet Mercangöz

+ [Retrieval-augmented in-context learning for multimodal large language models in disease classification](https://arxiv.org//abs/2505.02087)

	Zaifu Zhan, Shuang Zhou, Xiaoshan Zhou, Yongkang Xiao, Jun Wang, Jiawen Deng, He Zhu, Yu Hou, Rui Zhang

+ [MemEngine: A Unified and Modular Library for Developing Advanced Memory of LLM-based Agents](https://arxiv.org//abs/2505.02099)

	Zeyu Zhang, Quanyu Dai, Xu Chen, Rui Li, Zhongyang Li, Zhenhua Dong

+ [Attention Mechanisms Perspective: Exploring LLM Processing of Graph-Structured Data](https://arxiv.org//abs/2505.02130)

	Zhong Guan, Likang Wu, Hongke Zhao, Ming He, Jianpin Fan

+ [Interpretable Emergent Language Using Inter-Agent Transformers](https://arxiv.org//abs/2505.02215)

	Mannan Bhardwaj

+ [LLM-Guided Probabilistic Program Induction for POMDP Model Estimation](https://arxiv.org//abs/2505.02216)

	Aidan Curtis, Hao Tang, Thiago Veloso, Kevin Ellis, Tomás Lozano-Pérez, Leslie Pack Kaelbling

+ [Real-time Spatial Retrieval Augmented Generation for Urban Environments](https://arxiv.org//abs/2505.02271)

	David Nazareno Campo, Javier Conde, Álvaro Alonso, Gabriel Huecas, Joaquín Salvachúa, Pedro Reviriego

+ [A survey of agent interoperability protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP)](https://arxiv.org//abs/2505.02279)

	Abul Ehtesham, Aditi Singh, Gaurav Kumar Gupta, Saket Kumar

+ [Analyzing Cognitive Differences Among Large Language Models through the Lens of Social Worldview](https://arxiv.org//abs/2505.01967)

	Jiatao Li, Yanheng Li, Xiaojun Wan

+ [Restoring Calibration for Aligned Large Language Models: A Calibration-Aware Fine-Tuning Approach](https://arxiv.org//abs/2505.01997)

	Jiancong Xiao, Bojian Hou, Zhanliang Wang, Ruochen Jin, Qi Long, Weijie J. Su, Li Shen

+ [What do Language Model Probabilities Represent? From Distribution Estimation to Response Prediction](https://arxiv.org//abs/2505.02072)

	Eitan Wagner, Omri Abend

+ [Open Challenges in Multi-Agent Security: Towards Secure Systems of Interacting AI Agents](https://arxiv.org//abs/2505.02077)

	Christian Schroeder de Witt

+ [A New HOPE: Domain-agnostic Automatic Evaluation of Text Chunking](https://arxiv.org//abs/2505.02171)

	Henrik Brådland, Morten Goodwin, Per-Arne Andersen, Alexander S. Nossum, Aditya Gupta

+ [Towards Safer Pretraining: Analyzing and Filtering Harmful Content in Webscale datasets for Responsible LLMs](https://arxiv.org//abs/2505.02009)

	Sai Krishna Mendu, Harish Yenala, Aditi Gulati, Shanu Kumar, Parag Agrawal

+ [Exploring the Potential of Offline RL for Reasoning in LLMs: A Preliminary Study](https://arxiv.org//abs/2505.02142)

	Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li

+ [Incorporating Legal Structure in Retrieval-Augmented Generation: A Case Study on Copyright Fair Use](https://arxiv.org//abs/2505.02164)

	Justin Ho, Alexandra Colby, William Fisher

+ [Identifying Legal Holdings with LLMs: A Systematic Study of Performance, Scale, and Memorization](https://arxiv.org//abs/2505.02172)

	Chuck Arvin

+ [Personalisation or Prejudice? Addressing Geographic Bias in Hate Speech Detection using Debias Tuning in Large Language Models](https://arxiv.org//abs/2505.02252)

	Paloma Piot, Patricia Martín-Rodilla, Javier Parapar

+ [Demystifying optimized prompts in language models](https://arxiv.org//abs/2505.02273)

	Rimon Melamed, Lucas H. McCabe, H. Howie Huang

+ [A Comprehensive Analysis for Visual Object Hallucination in Large Vision-Language Models](https://arxiv.org//abs/2505.01958)

	Liqiang Jing, Guiming Hardy Chen, Ehsan Aghazadeh, Xin Eric Wang, Xinya Du

+ [R-Bench: Graduate-level Multi-disciplinary Benchmarks for LLM & MLLM Complex Reasoning Evaluation](https://arxiv.org//abs/2505.02018)

	Meng-Hao Guo, Jiajun Xu, Yi Zhang, Jiaxi Song, Haoyang Peng, Yi-Xuan Deng, Xinzhi Dong, Kiyohiro Nakayama, Zhengyang Geng, Chen Wang, Bolin Ni, Guo-Wei Yang, Yongming Rao, Houwen Peng, Han Hu, Gordon Wetzstein, Shi-min Hu

+ [RTV-Bench: Benchmarking MLLM Continuous Perception, Understanding and Reasoning through Real-Time Video](https://arxiv.org//abs/2505.02064)

	Shuhang Xun, Sicheng Tao, Jungang Li, Yibo Shi, Zhixin Lin, Zhanhui Zhu, Yibo Yan, Hanqian Li, Linghao Zhang, Shikang Wang, Yixin Liu, Hanbo Zhang, Xuming Hu, Ying Ma

+ [Semantic Probabilistic Control of Language Models](https://arxiv.org//abs/2505.01954)

	Kareem Ahmed, Catarina G Belem, Padhraic Smyth, Sameer Singh

+ [An Empirical Study of Qwen3 Quantization](https://arxiv.org//abs/2505.02214)

	Xingyu Zheng, Yuye Li, Haoran Chu, Yue Feng, Xudong Ma, Jie Luo, Jinyang Guo, Haotong Qin, Michele Magno, Xianglong Liu

+ [A Survey on Privacy Risks and Protection in Large Language Models](https://arxiv.org//abs/2505.01976)

	Kang Chen, Xiuze Zhou, Yuanguo Lin, Shibo Feng, Li Shen, Pengcheng Wu

+ [Dialz: A Python Toolkit for Steering Vectors](https://arxiv.org//abs/2505.06262)

	Zara Siddique, Liam D. Turner, Luis Espinosa-Anke

# 2025-05-03
+ [Structured Prompting and Feedback-Guided Reasoning with LLMs for Data Interpretation](https://arxiv.org//abs/2505.01636)

	Amit Rath

+ [Inducing Robustness in a 2 Dimensional Direct Preference Optimization Paradigm](https://arxiv.org//abs/2505.01706)

	Sarvesh Shashidhar, Ritik, Nachiketa Patil, Suraj Racha, Ganesh Ramakrishnan

+ [Efficient Shapley Value-based Non-Uniform Pruning of Large Language Models](https://arxiv.org//abs/2505.01731)

	Chuan Sun, Han Yu, Lizhen Cui

+ [$\textit{New News}$: System-2 Fine-tuning for Robust Integration of New Knowledge](https://arxiv.org//abs/2505.01812)

	Core Francisco Park, Zechen Zhang, Hidenori Tanaka

+ [A Survey on Inference Engines for Large Language Models: Perspectives on Optimization and Efficiency](https://arxiv.org//abs/2505.01658)

	Sihyeong Park, Sungryeol Jeon, Chaelyn Lee, Seokhun Jeon, Byung-Soo Kim, Jemin Lee

+ [Same evaluation, more tokens: On the effect of input length for machine translation evaluation using Large Language Models](https://arxiv.org//abs/2505.01761)

	Tobias Domhan, Dawei Zhu

+ [CAMOUFLAGE: Exploiting Misinformation Detection Systems Through LLM-driven Adversarial Claim Transformation](https://arxiv.org//abs/2505.01900)

	Mazal Bethany, Nishant Vishwamitra, Cho-Yu Jason Chiang, Peyman Najafirad

+ [Memory-Efficient LLM Training by Various-Grained Low-Rank Projection of Gradients](https://arxiv.org//abs/2505.01744)

	Yezhen Wang, Zhouhao Yang, Brian K Chen, Fanyi Pu, Bo Li, Tianyu Gao, Kenji Kawaguchi

+ [Cannot See the Forest for the Trees: Invoking Heuristics and Biases to Elicit Irrational Choices of LLMs](https://arxiv.org//abs/2505.02862)

	Haoming Yang, Ke Ma, Xiaojun Jia, Yingfei Sun, Qianqian Xu, Qingming Huang

+ [Accelerating Large Language Model Reasoning via Speculative Search](https://arxiv.org//abs/2505.02865)

	Zhihai Wang, Jie Wang, Jilai Pan, Xilin Xia, Huiling Zhen, Mingxuan Yuan, Jianye Hao, Feng Wu

+ [Memory Assisted LLM for Personalized Recommendation System](https://arxiv.org//abs/2505.03824)

	Jiarui Chen

+ [Towards Artificial Intelligence Research Assistant for Expert-Involved Learning](https://arxiv.org//abs/2505.04638)

	Tianyu Liu, Simeng Han, Xiao Luo, Hanchen Wang, Pan Lu, Biqing Zhu, Yuge Wang, Keyi Li, Jiapeng Chen, Rihao Qu, Yufeng Liu, Xinyue Cui, Aviv Yaish, Yuhang Chen, Minsheng Hao, Chuhan Li, Kexing Li, Arman Cohan, Hua Xu, Mark Gerstein, James Zou, Hongyu Zhao

+ [Adaptive Token Boundaries: Integrating Human Chunking Mechanisms into Multimodal LLMs](https://arxiv.org//abs/2505.04637)

	Dongxing Yu

# 2025-05-02
+ [Seeking to Collide: Online Safety-Critical Scenario Generation for Autonomous Driving with Retrieval Augmented Large Language Models](https://arxiv.org//abs/2505.00972)

	Yuewen Mei, Tong Nie, Jian Sun, Ye Tian

+ [Improving Large Language Model Planning with Action Sequence Similarity](https://arxiv.org//abs/2505.01009)

	Xinran Zhao, Hanie Sedghi, Bernd Bohnet, Dale Schuurmans, Azade Nova

+ [Retrieval Augmented Learning: A Retrial-based Large Language Model Self-Supervised Learning and Autonomous Knowledge Generation](https://arxiv.org//abs/2505.01073)

	Zongyuan Li, Pengfei Li, Runnan Qi, Yanan Ni, Lumin Jiang, Hui Wu, Xuebo Zhang, Kuihua Huang, Xian Guo

+ [BalancEdit: Dynamically Balancing the Generality-Locality Trade-off in Multi-modal Model Editing](https://arxiv.org//abs/2505.01343)

	Dongliang Guo, Mengxuan Hu, Zihan Guan, Thomas Hartvigsen, Sheng Li

+ [Large Language Model-Driven Dynamic Assessment of Grammatical Accuracy in English Language Learner Writing](https://arxiv.org//abs/2505.00931)

	Timur Jaganov, John Blake, Julián Villegas, Nicholas Carr

+ [Llama-Nemotron: Efficient Reasoning Models](https://arxiv.org//abs/2505.00949)

	Akhiad Bercovich, Itay Levy, Izik Golan, Mohammad Dabbah, Ran El-Yaniv, Omri Puny, Ido Galil, Zach Moshe, Tomer Ronen, Najeeb Nabwani, Ido Shahaf, Oren Tropp, Ehud Karpas, Ran Zilberstein, Jiaqi Zeng, Soumye Singhal, Alexander Bukharin, Yian Zhang, Tugrul Konuk, Gerald Shen, Ameya Sunil Mahabaleshwarkar, Bilal Kartal, Yoshi Suhara, Olivier Delalleau, Zijia Chen, Zhilin Wang, David Mosallanezhad, Adi Renduchintala, Haifeng Qian, Dima Rekesh, Fei Jia, Somshubra Majumdar, Vahid Noroozi, Wasi Uddin Ahmad, Sean Narenthiran, Aleksander Ficek, Mehrzad Samadi, Jocelyn Huang, Siddhartha Jain, Igor Gitman, Ivan Moshkov, Wei Du, Shubham Toshniwal, George Armstrong, Branislav Kisacanin, Matvei Novikov, Daria Gitman, Evelina Bakhturina, Jane Polak Scowcroft, John Kamalu, Dan Su, Kezhi Kong, Markus Kliegl, Rabeeh Karimi, Ying Lin, Sanjeev Satheesh, Jupinder Parmar, Pritam Gundecha, Brandon Norick, Joseph Jennings, Shrimai Prabhumoye, Syeda Nahida Akter, Mostofa Patwary, Abhinav Khattar, Deepak Narayanan, Roger Waleffe, Jimmy Zhang, Bor-Yiing Su, Guyue Huang, Terry Kong, Parth Chadha, Sahil Jain, Christine Harvey, Elad Segal, Jining Huang, Sergey Kashirsky, Robert McQueen, Izzy Putterman, George Lam, Arun Venkatesan, Sherry Wu, Vinh Nguyen, Manoj Kilaru, Andrew Wang, Anna Warno, Abhilash Somasamudramath, Sandip Bhaskar, Maka Dong, Nave Assaf, Shahar Mor, Omer Ullman Argov, Scot Junkin, Oleksandr Romanenko, Pedro Larroy, Monika Katariya, Marco Rovinelli, Viji Balas, Nicholas Edelman, Anahita Bhiwandiwalla, Muthu Subramaniam

+ [Attack and defense techniques in large language models: A survey and new perspectives](https://arxiv.org//abs/2505.00976)

	Zhiyu Liao, Kang Chen, Yuanguo Lin, Kangkang Li, Yunxuan Liu, Hefeng Chen, Xingwang Huang, Yuanhui Yu

+ [Synthesize-on-Graph: Knowledgeable Synthetic Data Generation for Continue Pre-training of Large Language Models](https://arxiv.org//abs/2505.00979)

	Xuhui Jiang, Shengjie Ma, Chengjin Xu, Cehao Yang, Liyu Zhang, Jian Guo

+ [Value Portrait: Understanding Values of LLMs with Human-aligned Benchmark](https://arxiv.org//abs/2505.01015)

	Jongwook Han, Dongmin Choi, Woojung Song, Eun-Ju Lee, Yohan Jo

+ [Good News for Script Kiddies? Evaluating Large Language Models for Automated Exploit Generation](https://arxiv.org//abs/2505.01065)

	David Jin, Qian Fu, Yuekang Li

+ [A Rusty Link in the AI Supply Chain: Detecting Evil Configurations in Model Repositories](https://arxiv.org//abs/2505.01067)

	Ziqi Ding, Qian Fu, Junchen Ding, Gelei Deng, Yi Liu, Yuekang Li

+ [On the Limitations of Steering in Language Model Alignment](https://arxiv.org//abs/2505.01162)

	Chebrolu Niranjan, Kokil Jaidka, Gerard Christopher Yeo

+ [LLM Security: Vulnerabilities, Attacks, Defenses, and Countermeasures](https://arxiv.org//abs/2505.01177)

	Francisco Aguilera-Martínez, Fernando Berzal

+ [EvalxNLP: A Framework for Benchmarking Post-Hoc Explainability Methods on NLP Models](https://arxiv.org//abs/2505.01238)

	Mahdi Dhaini, Kafaite Zahra Hussain, Efstratios Zaradoukas, Gjergji Kasneci

+ [Document Retrieval Augmented Fine-Tuning (DRAFT) for safety-critical software assessments](https://arxiv.org//abs/2505.01307)

	Regan Bolton, Mohammadreza Sheikhfathollahi, Simon Parkinson, Vanessa Vulovic, Gary Bamford, Dan Basher, Howard Parkinson

+ [Helping Big Language Models Protect Themselves: An Enhanced Filtering and Summarization System](https://arxiv.org//abs/2505.01315)

	Sheikh Samit Muhaimin, Spyridon Mastorakis

+ [Evaluating Explanations: An Explanatory Virtues Framework for Mechanistic Interpretability -- The Strange Science Part I.ii](https://arxiv.org//abs/2505.01372)

	Kola Ayonrinde, Louis Jaburi

+ [Position: Enough of Scaling LLMs! Lets Focus on Downscaling](https://arxiv.org//abs/2505.00985)

	Ayan Sengupta, Yash Goel, Tanmoy Chakraborty

+ [VTS-LLM: Domain-Adaptive LLM Agent for Enhancing Awareness in Vessel Traffic Services through Natural Language](https://arxiv.org//abs/2505.00989)

	Sijin Sun, Liangbin Zhao, Ming Deng, Xiuju Fu

+ [Do We Need a Detailed Rubric for Automated Essay Scoring using Large Language Models?](https://arxiv.org//abs/2505.01035)

	Lui Yoshida

+ [MateICL: Mitigating Attention Dispersion in Large-Scale In-Context Learning](https://arxiv.org//abs/2505.01110)

	Murtadha Ahmed, Wenbo, Liu yunfeng

+ [Transferable Adversarial Attacks on Black-Box Vision-Language Models](https://arxiv.org//abs/2505.01050)

	Kai Hu, Weichen Yu, Li Zhang, Alexander Robey, Andy Zou, Chengming Xu, Haoqi Hu, Matt Fredrikson

+ [Federated Adapter on Foundation Models: An Out-Of-Distribution Approach](https://arxiv.org//abs/2505.01075)

	Yiyuan Yang, Guodong Long, Tianyi Zhou, Qinghua Lu, Shanshan Ye, Jing Jiang

+ [Evaluating Frontier Models for Stealth and Situational Awareness](https://arxiv.org//abs/2505.01420)

	Mary Phuong, Roland S. Zimmermann, Ziyue Wang, David Lindner, Victoria Krakovna, Sarah Cogan, Allan Dafoe, Lewis Ho, Rohin Shah

+ [Preserving Privacy and Utility in LLM-Based Product Recommendations](https://arxiv.org//abs/2505.00951)

	Tina Khezresmaeilzadeh, Jiang Zhang, Dimitrios Andreadis, Konstantinos Psounis

+ [Understanding LLM Scientific Reasoning through Promptings and Model's Explanation on the Answers](https://arxiv.org//abs/2505.01482)

	Alice Rueda, Mohammed S. Hassan, Argyrios Perivolaris, Bazen G. Teferra, Reza Samavi, Sirisha Rambhatla, Yuqi Wu, Yanbo Zhang, Bo Cao, Divya Sharma, Sridhar Krishnan Venkat Bhat

+ [CHORUS: Zero-shot Hierarchical Retrieval and Orchestration for Generating Linear Programming Code](https://arxiv.org//abs/2505.01485)

	Tasnim Ahmed, Salimur Choudhury

+ [Parameterized Argumentation-based Reasoning Tasks for Benchmarking Generative Language Models](https://arxiv.org//abs/2505.01539)

	Cor Steging, Silja Renooij, Bart Verheij

+ [TutorGym: A Testbed for Evaluating AI Agents as Tutors and Students](https://arxiv.org//abs/2505.01563)

	Daniel Weitekamp, Momin N. Siddiqui, Christopher J. MacLellan

+ [PipeSpec: Breaking Stage Dependencies in Hierarchical LLM Decoding](https://arxiv.org//abs/2505.01572)

	Bradley McDanel, Sai Qian Zhang, Yunhai Hu, Zining Liu

+ [Subset Selection for Fine-Tuning: A Utility-Diversity Balanced Approach for Mathematical Domain Adaptation](https://arxiv.org//abs/2505.01523)

	Madhav Kotecha, Vijendra Kumar Vaishya, Smita Gautam, Suraj Racha

+ [Contextures: Representations from Contexts](https://arxiv.org//abs/2505.01557)

	Runtian Zhai, Kai Yang, Che-Ping Tsai, Burak Varici, Zico Kolter, Pradeep Ravikumar

+ [PIPA: A Unified Evaluation Protocol for Diagnosing Interactive Planning Agents](https://arxiv.org//abs/2505.01592)

	Takyoung Kim, Janvijay Singh, Shuhaib Mehri, Emre Can Acikgoz, Sagnik Mukherjee, Nimet Beyza Bozdag, Sumuk Shashidhar, Gokhan Tur, Dilek Hakkani-Tür

+ [Always Tell Me The Odds: Fine-grained Conditional Probability Estimation](https://arxiv.org//abs/2505.01595)

	Liaoyaqi Wang, Zhengping Jiang, Anqi Liu, Benjamin Van Durme

+ [Don't be lazy: CompleteP enables compute-efficient deep transformers](https://arxiv.org//abs/2505.01618)

	Nolan Dey, Bin Claire Zhang, Lorenzo Noci, Mufan Li, Blake Bordelon, Shane Bergsma, Cengiz Pehlevan, Boris Hanin, Joel Hestness

+ [SymPlanner: Deliberate Planning in Language Models with Symbolic Representation](https://arxiv.org//abs/2505.01479)

	Siheng Xiong, Jieyu Zhou, Zhangding Liu, Yusen Su

+ [LLM Watermarking Using Mixtures and Statistical-to-Computational Gaps](https://arxiv.org//abs/2505.01484)

	Pedro Abdalla, Roman Vershynin

+ [Rubber Mallet: A Study of High Frequency Localized Bit Flips and Their Impact on Security](https://arxiv.org//abs/2505.01518)

	Andrew Adiletta, Zane Weissman, Fatemeh Khojasteh Dana, Berk Sunar, Shahin Tajik

+ [Aligning Large Language Models with Healthcare Stakeholders: A Pathway to Trustworthy AI Integration](https://arxiv.org//abs/2505.02848)

	Kexin Ding, Mu Zhou, Akshay Chaudhari, Shaoting Zhang, Dimitris N. Metaxas

+ [Enhancing tutoring systems by leveraging tailored promptings and domain knowledge with Large Language Models](https://arxiv.org//abs/2505.02849)

	Mohsen Balavar, Wenli Yang, David Herbert, Soonja Yeom

+ [Enhancing ML Model Interpretability: Leveraging Fine-Tuned Large Language Models for Better Understanding of AI](https://arxiv.org//abs/2505.02859)

	Jonas Bokstaller, Julia Altheimer, Julian Dormehl, Alina Buss, Jasper Wiltfang, Johannes Schneider, Maximilian Röglinger

+ [Scalability Matters: Overcoming Challenges in InstructGLM with Similarity-Degree-Based Sampling](https://arxiv.org//abs/2505.03799)

	Hyun Lee, Chris Yi, Maminur Islam, B.D.S. Aritra

+ [Large Language Model Compression with Global Rank and Sparsity Optimization](https://arxiv.org//abs/2505.03801)

	Changhai Zhou, Qian Qiao, Weizhong Zhang, Cheng Jin

+ [Efficient Fine-Tuning of Quantized Models via Adaptive Rank and Bitwidth](https://arxiv.org//abs/2505.03802)

	Changhai Zhou, Yuhua Zhou, Qian Qiao, Weizhong Zhang, Cheng Jin

+ [MoEQuant: Enhancing Quantization for Mixture-of-Experts Large Language Models via Expert-Balanced Sampling and Affinity Guidance](https://arxiv.org//abs/2505.03804)

	Xing Hu, Zhixuan Chen, Dawei Yang, Zukang Xu, Chen Xu, Zhihang Yuan, Sifan Zhou, Jiangyong Yu

+ [Facilitating Video Story Interaction with Multi-Agent Collaborative System](https://arxiv.org//abs/2505.03807)

	Yiwen Zhang, Jianing Hao, Zhan Wang, Hongling Sheng, Wei Zeng

+ [Grouped Sequency-arranged Rotation: Optimizing Rotation Transformation for Quantization for Free](https://arxiv.org//abs/2505.03810)

	Euntae Choi, Sumin Song, Woosang Lim, Sungjoo Yoo

+ [Cer-Eval: Certifiable and Cost-Efficient Evaluation Framework for LLMs](https://arxiv.org//abs/2505.03814)

	Ganghua Wang, Zhaorun Chen, Bo Li, Haifeng Xu

+ [Program Semantic Inequivalence Game with Large Language Models](https://arxiv.org//abs/2505.03818)

	Antonio Valerio Miceli-Barone, Vaishak Belle, Ali Payani

+ [Focus on the Likely: Test-time Instance-based Uncertainty Removal](https://arxiv.org//abs/2505.03819)

	Johannes Schneider

# 2025-05-01
+ [UserCentrix: An Agentic Memory-augmented AI Framework for Smart Spaces](https://arxiv.org//abs/2505.00472)

	Alaa Saleh, Sasu Tarkoma, Praveen Kumar Donta, Naser Hossein Motlagh, Schahram Dustdar, Susanna Pirttikangas, Lauri Lovén

+ [Combining LLMs with Logic-Based Framework to Explain MCTS](https://arxiv.org//abs/2505.00610)

	Ziyan An, Xia Wang, Hendrik Baier, Zirong Chen, Abhishek Dubey, Taylor T. Johnson, Jonathan Sprinkle, Ayan Mukhopadhyay, Meiyi Ma

+ [Open-Source LLM-Driven Federated Transformer for Predictive IoV Management](https://arxiv.org//abs/2505.00651)

	Yazan Otoum, Arghavan Asad, Ishtiaq Ahmad

+ [LLM-Based Threat Detection and Prevention Framework for IoT Ecosystems](https://arxiv.org//abs/2505.00240)

	Yazan Otoum, Arghavan Asad, Amiya Nayak

+ [Empowering Agentic Video Analytics Systems with Video Language Models](https://arxiv.org//abs/2505.00254)

	Yuxuan Yan, Shiqi Jiang, Ting Cao, Yifan Yang, Qianqian Yang, Yuanchao Shu, Yuqing Yang, Lili Qiu

+ [Consistency in Language Models: Current Landscape, Challenges, and Future Directions](https://arxiv.org//abs/2505.00268)

	Jekaterina Novikova, Carol Anderson, Borhane Blili-Hamelin, Subhabrata Majumdar

+ [Red Teaming Large Language Models for Healthcare](https://arxiv.org//abs/2505.00467)

	Vahid Balazadeh, Michael Cooper, David Pellow, Atousa Assadi, Jennifer Bell, Jim Fackler, Gabriel Funingana, Spencer Gable-Cook, Anirudh Gangadhar, Abhishek Jaiswal, Sumanth Kaja, Christopher Khoury, Randy Lin, Kaden McKeen, Sara Naimimohasses, Khashayar Namdar, Aviraj Newatia, Allan Pang, Anshul Pattoo, Sameer Peesapati, Diana Prepelita, Bogdana Rakova, Saba Sadatamin, Rafael Schulman, Ajay Shah, Syed Azhar Shah, Syed Ahmar Shah, Babak Taati, Balagopal Unnikrishnan, Stephanie Williams, Rahul G Krishnan

+ [HalluMix: A Task-Agnostic, Multi-Domain Benchmark for Real-World Hallucination Detection](https://arxiv.org//abs/2505.00506)

	Deanna Emery, Michael Goitia, Freddie Vargus, Iulia Neagu

+ [Test-time Correlation Alignment](https://arxiv.org//abs/2505.00533)

	Linjing You, Jiabao Lu, Xiayuan Huang

+ [Triggering Hallucinations in LLMs: A Quantitative Study of Prompt-Induced Hallucination in Large Language Models](https://arxiv.org//abs/2505.00557)

	Makoto Sato

+ [FreqKV: Frequency Domain Key-Value Compression for Efficient Context Window Extension](https://arxiv.org//abs/2505.00570)

	Jushi Kai, Boyi Zeng, Yixuan Wang, Haoli Bai, Bo Jiang, Zhouhan Lin

+ [FineScope : Precision Pruning for Domain-Specialized Large Language Models Using SAE-Guided Self-Data Cultivation](https://arxiv.org//abs/2505.00624)

	Chaitali Bhattacharyya, Yeseong Kim

+ [The Illusion of Role Separation: Hidden Shortcuts in LLM Role Learning (and How to Fix Them)](https://arxiv.org//abs/2505.00626)

	Zihao Wang, Yibo Jiang, Jiahao Yu, Heqing Huang

+ [On the generalization of language models from in-context learning and finetuning: a controlled study](https://arxiv.org//abs/2505.00661)

	Andrew K. Lampinen, Arslan Chaudhry, Stephanie C.Y. Chan, Cody Wild, Diane Wan, Alex Ku, Jörg Bornschein, Razvan Pascanu, Murray Shanahan, James L. McClelland

+ [DeepCritic: Deliberate Critique with Large Language Models](https://arxiv.org//abs/2505.00662)

	Wenkai Yang, Jingwen Chen, Yankai Lin, Ji-Rong Wen

+ [Visual Test-time Scaling for GUI Agent Grounding](https://arxiv.org//abs/2505.00684)

	Tiange Luo, Lajanugen Logeswaran, Justin Johnson, Honglak Lee

+ [100 Days After DeepSeek-R1: A Survey on Replication Studies and More Directions for Reasoning Language Models](https://arxiv.org//abs/2505.00551)

	Chong Zhang, Yue Deng, Xiang Lin, Bin Wang, Dianwen Ng, Hai Ye, Xingxuan Li, Yao Xiao, Zhanfeng Mo, Qi Zhang, Lidong Bing

+ [Block Circulant Adapter for Large Language Models](https://arxiv.org//abs/2505.00582)

	Xinyu Ding, Meiqi Wang, Siyu Liao, Zhongfeng Wang

+ [Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future Directions](https://arxiv.org//abs/2505.00675)

	Yiming Du, Wenyu Huang, Danna Zheng, Zhaowei Wang, Sebastien Montella, Mirella Lapata, Kam-Fai Wong, Jeff Z. Pan

+ [Steering Large Language Models with Register Analysis for Arbitrary Style Transfer](https://arxiv.org//abs/2505.00679)

	Xinchen Yang, Marine Carpuat

+ [Self-Generated In-Context Examples Improve LLM Agents for Sequential Decision-Making Tasks](https://arxiv.org//abs/2505.00234)

	Vishnu Sarukkai, Zhiqiang Xie, Kayvon Fatahalian

+ [EnronQA: Towards Personalized RAG over Private Documents](https://arxiv.org//abs/2505.00263)

	Michael J. Ryan, Danmei Xu, Chris Nivera, Daniel Campos

+ [Mixture of Sparse Attention: Content-Based Learnable Sparse Attention via Expert-Choice Routing](https://arxiv.org//abs/2505.00315)

	Piotr Piękos, Róbert Csordás, Jürgen Schmidhuber

+ [Investigating Task Arithmetic for Zero-Shot Information Retrieval](https://arxiv.org//abs/2505.00649)

	Marco Braga, Pranav Kasela, Alessandro Raganato, Gabriella Pasi

+ [Self-Ablating Transformers: More Interpretability, Less Sparsity](https://arxiv.org//abs/2505.00509)

	Jeremias Ferrao, Luhan Mikaelson, Keenan Pepper, Natalia Perez-Campanero Antolin

+ [Thoughts without Thinking: Reconsidering the Explanatory Value of Chain-of-Thought Reasoning in LLMs through Agentic Pipelines](https://arxiv.org//abs/2505.00875)

	Ramesh Manuvinakurike, Emanuel Moss, Elizabeth Anne Watkins, Saurav Sahay, Giuseppe Raffa, Lama Nachman

+ [A Mathematical Philosophy of Explanations in Mechanistic Interpretability -- The Strange Science Part I.i](https://arxiv.org//abs/2505.00808)

	Kola Ayonrinde, Louis Jaburi

+ [Spill The Beans: Exploiting CPU Cache Side-Channels to Leak Tokens from Large Language Models](https://arxiv.org//abs/2505.00817)

	Andrew Adiletta, Berk Sunar

+ [From Texts to Shields: Convergence of Large Language Models and Cybersecurity](https://arxiv.org//abs/2505.00841)

	Tao Li, Ya-Ting Yang, Yunian Pan, Quanyan Zhu

+ [OET: Optimization-based prompt injection Evaluation Toolkit](https://arxiv.org//abs/2505.00843)

	Jinsheng Pan, Xiaogeng Liu, Chaowei Xiao

+ [ICQuant: Index Coding enables Low-bit LLM Quantization](https://arxiv.org//abs/2505.00850)

	Xinlin Li, Osama Hanna, Christina Fragouli, Suhas Diggavi

+ [Towards Explainable Temporal User Profiling with LLMs](https://arxiv.org//abs/2505.00886)

	Milad Sabouri, Masoud Mansoury, Kun Lin, Bamshad Mobasher

+ [A Survey on Large Language Model based Human-Agent Systems](https://arxiv.org//abs/2505.00753)

	Henry Peng Zou, Wei-Chieh Huang, Yaozu Wu, Yankai Chen, Chunyu Miao, Hoang Nguyen, Yue Zhou, Weizhi Zhang, Liancheng Fang, Langzhou He, Yangning Li, Yuwei Cao, Dongyuan Li, Renhe Jiang, Philip S. Yu

+ [Reasoning Capabilities and Invariability of Large Language Models](https://arxiv.org//abs/2505.00776)

	Alessandro Raganato, Rafael Peñaloza, Marco Viviani, Gabriella Pasi

+ [NeMo-Inspector: A Visualization Tool for LLM Generation Analysis](https://arxiv.org//abs/2505.00903)

	Daria Gitman, Igor Gitman, Evelina Bakhturina

+ [Improving Routing in Sparse Mixture of Experts with Graph of Tokens](https://arxiv.org//abs/2505.00792)

	Tam Nguyen, Ngoc N. Tran, Khai Nguyen, Richard G. Baraniuk

+ [Consciousness in AI: Logic, Proof, and Experimental Evidence of Recursive Identity Formation](https://arxiv.org//abs/2505.01464)

	Jeffrey Camlin

+ [Unlearning Sensitive Information in Multimodal LLMs: Benchmark and Attack-Defense Evaluation](https://arxiv.org//abs/2505.01456)

	Vaidehi Patil, Yi-Lin Sung, Peter Hase, Jie Peng, Tianlong Chen, Mohit Bansal

+ [MoxE: Mixture of xLSTM Experts with Entropy-Aware Routing for Efficient Language Modeling](https://arxiv.org//abs/2505.01459)

	Abdoul Majid O. Thiombiano, Brahim Hnich, Ali Ben Mrad, Mohamed Wiem Mkaouer

+ [A Multi-Granularity Multimodal Retrieval Framework for Multimodal Document Tasks](https://arxiv.org//abs/2505.01457)

	Mingjun Xu, Zehui Wang, Hengxing Cai, Renxin Zhong

+ [Sentient Agent as a Judge: Evaluating Higher-Order Social Cognition in Large Language Models](https://arxiv.org//abs/2505.02847)

	Bang Zhang, Ruotian Ma, Qingxuan Jiang, Peisong Wang, Jiaqi Chen, Zheng Xie, Xingyu Chen, Yue Wang, Fanghua Ye, Jian Li, Yifan Yang, Zhaopeng Tu, Xiaolong Li

+ [Towards Efficient Online Tuning of VLM Agents via Counterfactual Soft Reinforcement Learning](https://arxiv.org//abs/2505.03792)

	Lang Feng, Weihao Tan, Zhiyi Lyu, Longtao Zheng, Haiyang Xu, Ming Yan, Fei Huang, Bo An

+ [LENSLLM: Unveiling Fine-Tuning Dynamics for LLM Selection](https://arxiv.org//abs/2505.03793)

	Xinyue Zeng, Haohui Wang, Junhong Lin, Jun Wu, Tyler Cody, Dawei Zhou

+ [Position: Foundation Models Need Digital Twin Representations](https://arxiv.org//abs/2505.03798)

	Yiqing Shen, Hao Ding, Lalithkumar Seenivasan, Tianmin Shu, Mathias Unberath

+ [Patchwork: A Unified Framework for RAG Serving](https://arxiv.org//abs/2505.07833)

	Bodun Hu, Luis Pabon, Saurabh Agarwal, Aditya Akella

# 2025-04-30
+ [Reinforced MLLM: A Survey on RL-Based Reasoning in Multimodal Large Language Models](https://arxiv.org//abs/2504.21277)

	Guanghao Zhou, Panjia Qiu, Cen Chen, Jie Wang, Zheming Yang, Jian Xu, Minghui Qiu

+ [Phi-4-reasoning Technical Report](https://arxiv.org//abs/2504.21318)

	Marah Abdin, Sahaj Agarwal, Ahmed Awadallah, Vidhisha Balachandran, Harkirat Behl, Lingjiao Chen, Gustavo de Rosa, Suriya Gunasekar, Mojan Javaheripi, Neel Joshi, Piero Kauffmann, Yash Lara, Caio César Teodoro Mendes, Arindam Mitra, Besmira Nushi, Dimitris Papailiopoulos, Olli Saarikivi, Shital Shah, Vaishnavi Shrivastava, Vibhav Vineet, Yue Wu, Safoora Yousefi, Guoqing Zheng

+ [ShorterBetter: Guiding Reasoning Models to Find Optimal Inference Length for Efficient Reasoning](https://arxiv.org//abs/2504.21370)

	Jingyang Yi, Jiazheng Wang

+ [AdaR1: From Long-CoT to Hybrid-CoT via Bi-Level Adaptive Reasoning Optimization](https://arxiv.org//abs/2504.21659)

	Haotian Luo, Haiying He, Yibo Wang, Jinluan Yang, Rui Liu, Naiqiang Tan, Xiaochun Cao, Dacheng Tao, Li Shen

+ [Memorization and Knowledge Injection in Gated LLMs](https://arxiv.org//abs/2504.21239)

	Xu Pan, Ely Hahami, Zechen Zhang, Haim Sompolinsky

+ [Assessing LLM code generation quality through path planning tasks](https://arxiv.org//abs/2504.21276)

	Wanyi Chen, Meng-Wen Su, Mary L. Cummings

+ [How to Backdoor the Knowledge Distillation](https://arxiv.org//abs/2504.21323)

	Chen Wu, Qian Ma, Prasenjit Mitra, Sencun Zhu

+ [Retrieval-Enhanced Few-Shot Prompting for Speech Event Extraction](https://arxiv.org//abs/2504.21372)

	Máté Gedeon

+ [Rethinking Visual Layer Selection in Multimodal LLMs](https://arxiv.org//abs/2504.21447)

	Haoran Chen, Junyan Lin, Xinhao Chen, Yue Fan, Xin Jin, Hui Su, Jianfeng Dong, Jinlan Fu, Xiaoyu Shen

+ [Black-Box Visual Prompt Engineering for Mitigating Object Hallucination in Large Vision Language Models](https://arxiv.org//abs/2504.21559)

	Sangmin Woo, Kang Zhou, Yun Zhou, Shuai Wang, Sheng Guan, Haibo Ding, Lin Lee Cheong

+ [Leveraging Pre-trained Large Language Models with Refined Prompting for Online Task and Motion Planning](https://arxiv.org//abs/2504.21596)

	Huihui Guo, Huilong Pi, Yunchuan Qin, Zhuo Tang, Kenli Li

+ [RDF-Based Structured Quality Assessment Representation of Multilingual LLM Evaluations](https://arxiv.org//abs/2504.21605)

	Jonas Gwozdz, Andreas Both

+ [XBreaking: Explainable Artificial Intelligence for Jailbreaking LLMs](https://arxiv.org//abs/2504.21700)

	Marco Arazzi, Vignesh Kumar Kembu, Antonino Nocera, Vinod P

+ [LLM-Empowered Embodied Agent for Memory-Augmented Task Planning in Household Robotics](https://arxiv.org//abs/2504.21716)

	Marc Glocker, Peter Hönig, Matthias Hirschmanner, Markus Vincze

+ [MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness](https://arxiv.org//abs/2504.21773)

	Junsheng Huang, Zhitao He, Sandeep Polisetty, Qingyun Wang, May Fung

+ [WebThinker: Empowering Large Reasoning Models with Deep Research Capability](https://arxiv.org//abs/2504.21776)

	Xiaoxi Li, Jiajie Jin, Guanting Dong, Hongjin Qian, Yutao Zhu, Yongkang Wu, Ji-Rong Wen, Zhicheng Dou

+ [Characterizing AI Agents for Alignment and Governance](https://arxiv.org//abs/2504.21848)

	Atoosa Kasirzadeh, Iason Gabriel

+ [TRUST: An LLM-Based Dialogue System for Trauma Understanding and Structured Assessments](https://arxiv.org//abs/2504.21851)

	Sichang Tu, Abigail Powers, Stephen Doogan, Jinho D. Choi

+ [Talk Before You Retrieve: Agent-Led Discussions for Better RAG in Medical QA](https://arxiv.org//abs/2504.21252)

	Xuanzhao Dong, Wenhui Zhu, Hao Wang, Xiwen Chen, Peijie Qiu, Rui Yin, Yi Su, Yalin Wang

+ [BiasGuard: A Reasoning-enhanced Bias Detection Tool For Large Language Models](https://arxiv.org//abs/2504.21299)

	Zhiting Fan, Ruizhe Chen, Zuozhu Liu

+ [Confidence in Large Language Model Evaluation: A Bayesian Approach to Limited-Sample Challenges](https://arxiv.org//abs/2504.21303)

	Xiao Xiao, Yu Su, Sijing Zhang, Zhang Chen, Yadong Chen, Tian Liu

+ [Does the Prompt-based Large Language Model Recognize Students' Demographics and Introduce Bias in Essay Scoring?](https://arxiv.org//abs/2504.21330)

	Kaixun Yang, Mladen Raković, Dragan Gašević, Guanliang Chen

+ [Precision Where It Matters: A Novel Spike Aware Mixed-Precision Quantization Strategy for LLaMA-based Language Models](https://arxiv.org//abs/2504.21553)

	Lucas Maisonnave, Cyril Moineau, Olivier Bichler, Fabrice Rastello

+ [Meeseeks: An Iterative Benchmark Evaluating LLMs Multi-Turn Instruction-Following Ability](https://arxiv.org//abs/2504.21625)

	Jiaming Wang

+ [CodeFlowBench: A Multi-turn, Iterative Benchmark for Complex Code Generation](https://arxiv.org//abs/2504.21751)

	Sizhe Wang, Zhengren Wang, Dongsheng Ma, Yongan Yu, Rui Ling, Zhiyu Li, Feiyu Xiong, Wentao Zhang

+ [Iterative Trajectory Exploration for Multimodal Agents](https://arxiv.org//abs/2504.21561)

	Pengxiang Li, Zhi Gao, Bofei Zhang, Yapeng Mi, Xiaojian Ma, Chenrui Shi, Tao Yuan, Yuwei Wu, Yunde Jia, Song-Chun Zhu, Qing Li

+ [Unsupervised Feature Transformation via In-context Generation, Generator-critic LLM Agents, and Duet-play Teaming](https://arxiv.org//abs/2504.21304)

	Nanxu Gong, Xinyuan Wang, Wangyang Ying, Haoyue Bai, Sixun Dong, Haifeng Chen, Yanjie Fu

+ [Traceback of Poisoning Attacks to Retrieval-Augmented Generation](https://arxiv.org//abs/2504.21668)

	Baolei Zhang, Haoran Xin, Minghong Fang, Zhuqing Liu, Biao Yi, Tong Li, Zheli Liu

+ [Hoist with His Own Petard: Inducing Guardrails to Facilitate Denial-of-Service Attacks on Retrieval-Augmented Generation of LLMs](https://arxiv.org//abs/2504.21680)

	Pan Suo, Yu-Ming Shang, San-Chuan Guo, Xi Zhang

+ [RAIL in the Wild: Operationalizing Responsible AI Evaluation Using Anthropic's Value Dataset](https://arxiv.org//abs/2505.00204)

	Sumit Verma, Pritam Prasun, Arpit Jaiswal, Pritish Kumar

+ [Between Underthinking and Overthinking: An Empirical Study of Reasoning Length and correctness in LLMs](https://arxiv.org//abs/2505.00127)

	Jinyan Su, Jennifer Healey, Preslav Nakov, Claire Cardie

+ [Enhancing Security and Strengthening Defenses in Automated Short-Answer Grading Systems](https://arxiv.org//abs/2505.00061)

	Sahar Yarmohammadtoosky, Yiyun Zhou, Victoria Yaneva, Peter Baldwin, Saed Rezayi, Brian Clauser, Polina Harikeo

+ [GDI-Bench: A Benchmark for General Document Intelligence with Vision and Reasoning Decoupling](https://arxiv.org//abs/2505.00063)

	Siqi Li, Yufan Shen, Xiangnan Chen, Jiayi Chen, Hengwei Ju, Haodong Duan, Song Mao, Hongbin Zhou, Bo Zhang, Pinlong Cai, Licheng Wen, Botian Shi, Yong Liu, Xinyu Cai, Yu Qiao

+ [ConSens: Assessing context grounding in open-book question answering](https://arxiv.org//abs/2505.00065)

	Ivan Vankov, Matyo Ivanov, Adriana Correia, Victor Botev

+ [Humanizing LLMs: A Survey of Psychological Measurements with Tools, Datasets, and Human-Agent Applications](https://arxiv.org//abs/2505.00049)

	Wenhan Dong, Yuemeng Zhao, Zhen Sun, Yule Liu, Zifan Peng, Jingyi Zheng, Zongmin Zhang, Ziyi Zhang, Jun Wu, Ruiming Wang, Shengmin Xu, Xinyi Huang, Xinlei He

+ [Optimization of embeddings storage for RAG systems using quantization and dimensionality reduction techniques](https://arxiv.org//abs/2505.00105)

	Naamán Huerga-Pérez, Rubén Álvarez, Rubén Ferrero-Guillén, Alberto Martínez-Gutiérrez, Javier Díez-González

+ [Which Agent Causes Task Failures and When? On Automated Failure Attribution of LLM Multi-Agent Systems](https://arxiv.org//abs/2505.00212)

	Shaokun Zhang, Ming Yin, Jieyu Zhang, Jiale Liu, Zhiguang Han, Jingyang Zhang, Beibin Li, Chi Wang, Huazheng Wang, Yiran Chen, Qingyun Wu

+ [Zoomer: Adaptive Image Focus Optimization for Black-box MLLM](https://arxiv.org//abs/2505.00742)

	Jiaxu Qian, Chendong Wang, Yifan Yang, Chaoyun Zhang, Huiqiang Jiang, Xufang Luo, Yu Kang, Qingwei Lin, Anlan Zhang, Shiqi Jiang, Ting Cao, Tianjun Mao, Suman Banerjee, Guyue Liu, Saravan Rajmohan, Dongmei Zhang, Yuqing Yang, Qi Zhang, Lili Qiu

+ [Localizing Before Answering: A Benchmark for Grounded Medical Visual Question Answering](https://arxiv.org//abs/2505.00744)

	Dung Nguyen, Minh Khoi Ho, Huy Ta, Thanh Tam Nguyen, Qi Chen, Kumar Rav, Quy Duong Dang, Satwik Ramchandre, Son Lam Phung, Zhibin Liao, Minh-Son To, Johan Verjans, Phi Le Nguyen, Vu Minh Hieu Phan

+ [Entropy Heat-Mapping: Localizing GPT-Based OCR Errors with Sliding-Window Shannon Analysis](https://arxiv.org//abs/2505.00746)

	Alexei Kaltchenko

+ [COSMOS: Predictable and Cost-Effective Adaptation of LLMs](https://arxiv.org//abs/2505.01449)

	Jiayu Wang, Aws Albarghouthi, Frederic Sala

+ [Calibrating Uncertainty Quantification of Multi-Modal LLMs using Grounding](https://arxiv.org//abs/2505.03788)

	Trilok Padhi, Ramneet Kaur, Adam D. Cobb, Manoj Acharya, Anirban Roy, Colin Samplawski, Brian Matejek, Alexander M. Berenbeim, Nathaniel D. Bastian, Susmit Jha

+ [When Reasoning Beats Scale: A 1.5B Reasoning Model Outranks 13B LLMs as Discriminator](https://arxiv.org//abs/2505.03786)

	Md Fahim Anjum

+ [ALFRED: Ask a Large-language model For Reliable ECG Diagnosis](https://arxiv.org//abs/2505.03781)

	Jin Yu, JaeHo Park, TaeJun Park, Gyurin Kim, JiHyun Lee, Min Sung Lee, Joon-myoung Kwon, Jeong Min Son, Yong-Yeon Jo

+ [mAIstro: an open-source multi-agentic system for automated end-to-end development of radiomics and deep learning models for medical imaging](https://arxiv.org//abs/2505.03785)

	Eleftherios Tzanis, Michail E. Klontzas

+ [Polysemy of Synthetic Neurons Towards a New Type of Explanatory Categorical Vector Spaces](https://arxiv.org//abs/2505.07831)

	Michael Pichat, William Pogrund, Paloma Pichat, Judicael Poumay, Armanouche Gasparian, Samuel Demarchi, Martin Corbet, Alois Georgeon, Michael Veillet-Guillem

# 2025-04-29
+ [TAMO:Fine-Grained Root Cause Analysis via Tool-Assisted LLM Agent with Multi-Modality Observation Data](https://arxiv.org//abs/2504.20462)

	Qi Wang, Xiao Zhang, Mingyi Li, Yuan Yuan, Mengbai Xiao, Fuzhen Zhuang, Dongxiao Yu

+ [A Summary on GUI Agents with Foundation Models Enhanced by Reinforcement Learning](https://arxiv.org//abs/2504.20464)

	Jiahao Li, Kaer Huang

+ [ReasonIR: Training Retrievers for Reasoning Tasks](https://arxiv.org//abs/2504.20595)

	Rulin Shao, Rui Qiao, Varsha Kishore, Niklas Muennighoff, Xi Victoria Lin, Daniela Rus, Bryan Kian Hsiang Low, Sewon Min, Wen-tau Yih, Pang Wei Koh, Luke Zettlemoyer

+ [PaRT: Enhancing Proactive Social Chatbots with Personalized Real-Time Retrieval](https://arxiv.org//abs/2504.20624)

	Zihan Niu, Zheyong Xie, Shaosheng Cao, Chonggang Lu, Zheyu Ye, Tong Xu, Zuozhu Liu, Yan Gao, Jia Chen, Zhe Xu, Yi Wu, Yao Hu

+ [Ascendra: Dynamic Request Prioritization for Efficient LLM Serving](https://arxiv.org//abs/2504.20828)

	Azam Ikram, Xiang Li, Sameh Elnikety, Saurabh Bagchi

+ [The Leaderboard Illusion](https://arxiv.org//abs/2504.20879)

	Shivalika Singh, Yiyang Nan, Alex Wang, Daniel D'Souza, Sayash Kapoor, Ahmet Üstün, Sanmi Koyejo, Yuntian Deng, Shayne Longpre, Noah Smith, Beyza Ermis, Marzieh Fadaee, Sara Hooker

+ [CBM-RAG: Demonstrating Enhanced Interpretability in Radiology Report Generation with Multi-Agent RAG and Concept Bottleneck Models](https://arxiv.org//abs/2504.20898)

	Hasan Md Tusfiqur Alam, Devansh Srivastav, Abdulrahman Mohamed Selim, Md Abdul Kadir, Md Moktadiurl Hoque Shuvo, Daniel Sonntag

+ [ChestX-Reasoner: Advancing Radiology Foundation Models with Reasoning through Step-by-Step Verification](https://arxiv.org//abs/2504.20930)

	Ziqing Fan, Cheng Liang, Chaoyi Wu, Ya Zhang, Yanfeng Wang, Weidi Xie

+ [Jekyll-and-Hyde Tipping Point in an AI's Behavior](https://arxiv.org//abs/2504.20980)

	Neil F. Johnson, Frank Yingjie Huo

+ [Local Prompt Optimization](https://arxiv.org//abs/2504.20355)

	Yash Jain, Vishal Chowdhary

+ [ARCS: Agentic Retrieval-Augmented Code Synthesis with Iterative Refinement](https://arxiv.org//abs/2504.20434)

	Manish Bhattarai, Miguel Cordova, Javier Santos, Dan O'Malley

+ [On Psychology of AI -- Does Primacy Effect Affect ChatGPT and Other LLMs?](https://arxiv.org//abs/2504.20444)

	Mika Hämäläinen

+ [Token-Efficient Prompt Injection Attack: Provoking Cessation in LLM Reasoning via Adaptive Token Compression](https://arxiv.org//abs/2504.20493)

	Yu Cui, Yujun Cai, Yiwei Wang

+ [Reinforcement Learning for Reasoning in Large Language Models with One Training Example](https://arxiv.org//abs/2504.20571)

	Yiping Wang, Qing Yang, Zhiyuan Zeng, Liliang Ren, Lucas Liu, Baolin Peng, Hao Cheng, Xuehai He, Kuan Wang, Jianfeng Gao, Weizhu Chen, Shuohang Wang, Simon Shaolei Du, Yelong Shen

+ [Information Retrieval in the Age of Generative AI: The RGB Model](https://arxiv.org//abs/2504.20610)

	Michele Garetto, Alessandro Cornacchia, Franco Galante, Emilio Leonardi, Alessandro Nordio, Alberto Tarable

+ [The Hidden Risks of LLM-Generated Web Application Code: A Security-Centric Evaluation of Code Generation Capabilities in Large Language Models](https://arxiv.org//abs/2504.20612)

	Swaroop Dora, Deven Lunkad, Naziya Aslam, S. Venkatesan, Sandeep Kumar Shukla

+ [Cooking Up Creativity: A Cognitively-Inspired Approach for Enhancing LLM Creativity through Structured Representations](https://arxiv.org//abs/2504.20643)

	Moran Mizrahi, Chen Shani, Gabriel Stanovsky, Dan Jurafsky, Dafna Shahaf

+ [CoCo-Bench: A Comprehensive Code Benchmark For Multi-task Large Language Model Evaluation](https://arxiv.org//abs/2504.20673)

	Wenjing Yin, Tianze Sun, Yijiong Yu, Jiawei Fang, Guangyao Su, Jiancheng Wang, Zekun Wang, Wei Wang, Ran Chen, Ziyun Dai, Shuai Yuan, Menghang Dong, Peng Luo, Dong Cao, Da Lei, Yajun Zhang, Hao Chen, Xiang Ma, Yong Liu, Weifeng Liu, Yuanjian Xu, Ji Pei

+ [Can LLMs Detect Intrinsic Hallucinations in Paraphrasing and Machine Translation?](https://arxiv.org//abs/2504.20699)

	Evangelia Gogoulou, Shorouq Zahra, Liane Guillou, Luise Dürlich, Joakim Nivre

+ [Beyond the Last Answer: Your Reasoning Trace Uncovers More than You Think](https://arxiv.org//abs/2504.20708)

	Hasan Abed Al Kader Hammoud, Hani Itani, Bernard Ghanem

+ [UniversalRAG: Retrieval-Augmented Generation over Multiple Corpora with Diverse Modalities and Granularities](https://arxiv.org//abs/2504.20734)

	Woongyeong Yeo, Kangsan Kim, Soyeong Jeong, Jinheon Baek, Sung Ju Hwang

+ [Grokking in the Wild: Data Augmentation for Real-World Multi-Hop Reasoning with Transformers](https://arxiv.org//abs/2504.20752)

	Roman Abramov, Felix Steinbauer, Gjergji Kasneci

+ [Chain-of-Defensive-Thought: Structured Reasoning Elicits Robustness in Large Language Models against Reference Corruption](https://arxiv.org//abs/2504.20769)

	Wenxiao Wang, Parsa Hosseini, Soheil Feizi

+ [Using LLMs in Generating Design Rationale for Software Architecture Decisions](https://arxiv.org//abs/2504.20781)

	Xiyu Zhou, Ruiyin Li, Peng Liang, Beiqi Zhang, Mojtaba Shahin, Zengyang Li, Chen Yang

+ [Hallucination by Code Generation LLMs: Taxonomy, Benchmarks, Mitigation, and Challenges](https://arxiv.org//abs/2504.20799)

	Yunseo Lee, John Youngeun Song, Dongsun Kim, Jindae Kim, Mijung Kim, Jaechang Nam

+ [Reinforcement Learning for LLM Reasoning Under Memory Constraints](https://arxiv.org//abs/2504.20834)

	Alan Lee, Harry Tong

+ [DYNAMAX: Dynamic computing for Transformers and Mamba based architectures](https://arxiv.org//abs/2504.20922)

	Miguel Nogales, Matteo Gambella, Manuel Roveri

+ [Trace-of-Thought: Enhanced Arithmetic Problem Solving via Reasoning Distillation From Large to Small Language Models](https://arxiv.org//abs/2504.20946)

	Tyler McDonald, Ali Emami

+ [OSVBench: Benchmarking LLMs on Specification Generation Tasks for Operating System Verification](https://arxiv.org//abs/2504.20964)

	Shangyu Li, Juyong Jiang, Tiancheng Zhao, Jiasi Shen

+ [Toward Efficient Exploration by Large Language Model Agents](https://arxiv.org//abs/2504.20997)

	Dilip Arumugam, Thomas L. Griffiths

+ [What Causes Knowledge Loss in Multilingual Language Models?](https://arxiv.org//abs/2504.20356)

	Maria Khelli, Samuel Cahyawijaya, Ayu Purwarianti, Genta Indra Winata

+ [DMDTEval: An Evaluation and Analysis of LLMs on Disambiguation in Multi-domain Translation](https://arxiv.org//abs/2504.20371)

	Zhibo Man, Yuanmeng Chen, Yujie Zhang, Yufeng Chen, Jinan Xu

+ [Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training](https://arxiv.org//abs/2504.20484)

	Linjuan Wu, Haoran Wei, Huan Lin, Tianhao Li, Baosong Yang, Weiming Lu

+ [UniDetox: Universal Detoxification of Large Language Models via Dataset Distillation](https://arxiv.org//abs/2504.20500)

	Huimin Lu, Masaru Isonuma, Junichiro Mori, Ichiro Sakata

+ [Turing Machine Evaluation for Large Language Model](https://arxiv.org//abs/2504.20771)

	Haitao Wu, Zongbo Han, Huaxi Huang, Changqing Zhang

+ [Information Gravity: A Field-Theoretic Model for Token Selection in Large Language Models](https://arxiv.org//abs/2504.20951)

	Maryna Vyshnyvetska

+ [SetKE: Knowledge Editing for Knowledge Elements Overlap](https://arxiv.org//abs/2504.20972)

	Yifan Wei, Xiaoyan Yu, Ran Song, Hao Peng, Angsheng Li

+ [Reviving Any-Subset Autoregressive Models with Principled Parallel Sampling and Speculative Decoding](https://arxiv.org//abs/2504.20456)

	Gabe Guo, Stefano Ermon

+ [Towards Understanding the Nature of Attention with Low-Rank Sparse Decomposition](https://arxiv.org//abs/2504.20938)

	Zhengfu He, Junxuan Wang, Rui Lin, Xuyang Ge, Wentao Shu, Qiong Tang, Junping Zhang, Xipeng Qiu

+ [Antidote: A Unified Framework for Mitigating LVLM Hallucinations in Counterfactual Presupposition and Object Perception](https://arxiv.org//abs/2504.20468)

	Yuanchen Wu, Lu Zhang, Hang Yao, Junlong Du, Ke Yan, Shouhong Ding, Yunsheng Wu, Xiaoqiang Li

+ [X-Fusion: Introducing New Modality to Frozen Large Language Models](https://arxiv.org//abs/2504.20996)

	Sicheng Mo, Thao Nguyen, Xun Huang, Siddharth Srinivasan Iyer, Yijun Li, Yuchen Liu, Abhishek Tandon, Eli Shechtman, Krishna Kumar Singh, Yong Jae Lee, Bolei Zhou, Yuheng Li

+ [Combatting Dimensional Collapse in LLM Pre-Training Data via Diversified File Selection](https://arxiv.org//abs/2504.20644)

	Ziqing Fan, Siyuan Du, Shengchao Hu, Pingjie Wang, Li Shen, Ya Zhang, Dacheng Tao, Yanfeng Wang

+ [AegisLLM: Scaling Agentic Systems for Self-Reflective Defense in LLM Security](https://arxiv.org//abs/2504.20965)

	Zikui Cai, Shayan Shabihi, Bang An, Zora Che, Brian R. Bartoldson, Bhavya Kailkhura, Tom Goldstein, Furong Huang

+ [Softpick: No Attention Sink, No Massive Activations with Rectified Softmax](https://arxiv.org//abs/2504.20966)

	Zayd M. K. Zuhri, Erland Hilman Fuadi, Alham Fikri Aji

+ [ACE: A Security Architecture for LLM-Integrated App Systems](https://arxiv.org//abs/2504.20984)

	Evan Li, Tushin Mallick, Evan Rose, William Robertson, Alina Oprea, Cristina Nita-Rotaru

+ [Enhancing Leakage Attacks on Searchable Symmetric Encryption Using LLM-Based Synthetic Data Generation](https://arxiv.org//abs/2504.20414)

	Joshua Chiu, Partha Protim Paul, Zahin Wahab

+ [Robustness via Referencing: Defending against Prompt Injection Attacks by Referencing the Executed Instruction](https://arxiv.org//abs/2504.20472)

	Yulin Chen, Haoran Li, Yuan Sui, Yue Liu, Yufei He, Yangqiu Song, Bryan Hooi

+ [ReCIT: Reconstructing Full Private Data from Gradient in Parameter-Efficient Fine-Tuning of Large Language Models](https://arxiv.org//abs/2504.20570)

	Jin Xie, Ruishi He, Songze Li, Xiaojun Jia, Shouling Ji

+ [Unlocking User-oriented Pages: Intention-driven Black-box Scanner for Real-world Web Applications](https://arxiv.org//abs/2504.20801)

	Weizhe Wang, Yao Zhang, Kaitai Liang, Guangquan Xu, Hongpeng Bai, Qingyang Yan, Xi Zheng, Bin Wu

+ [Secure Coding with AI, From Creation to Inspection](https://arxiv.org//abs/2504.20814)

	Vladislav Belozerov, Peter J Barclay, Ashkan Sami

+ [NeuRel-Attack: Neuron Relearning for Safety Disalignment in Large Language Models](https://arxiv.org//abs/2504.21053)

	Yi Zhou, Wenpeng Xing, Dezhang Kong, Changting Lin, Meng Han

+ [Erased but Not Forgotten: How Backdoors Compromise Concept Erasure](https://arxiv.org//abs/2504.21072)

	Jonas Henry Grebe, Tobias Braun, Marcus Rohrbach, Anna Rohrbach

+ [TT-LoRA MoE: Unifying Parameter-Efficient Fine-Tuning and Sparse Mixture-of-Experts](https://arxiv.org//abs/2504.21190)

	Pradip Kunwar, Minh N. Vu, Maanak Gupta, Mahmoud Abdelsalam, Manish Bhattarai

+ [Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice for Specialized Applications in Healthcare](https://arxiv.org//abs/2504.21191)

	Lovedeep Gondara, Jonathan Simkin, Graham Sayle, Shebnum Devji, Gregory Arbour, Raymond Ng

+ [SecRepoBench: Benchmarking LLMs for Secure Code Generation in Real-World Repositories](https://arxiv.org//abs/2504.21205)

	Connor Dilgren, Purva Chiniya, Luke Griffith, Yu Ding, Yizheng Chen

+ [CachePrune: Neural-Based Attribution Defense Against Indirect Prompt Injection Attacks](https://arxiv.org//abs/2504.21228)

	Rui Wang, Junda Wu, Yu Xia, Tong Yu, Ruiyi Zhang, Ryan Rossi, Lina Yao, Julian McAuley

+ [LLM Enhancer: Merged Approach using Vector Embedding for Reducing Large Language Model Hallucinations with External Knowledge](https://arxiv.org//abs/2504.21132)

	Naheed Rayhan, Md. Ashrafuzzaman

+ [Detecting Manipulated Contents Using Knowledge-Grounded Inference](https://arxiv.org//abs/2504.21165)

	Mark Huasong Meng, Ruizhe Wang, Meng Xu, Chuan Yan, Guangdong Bai

+ [Efficient LLMs with AMP: Attention Heads and MLP Pruning](https://arxiv.org//abs/2504.21174)

	Leandro Giusti Mugnaini, Bruno Lopes Yamamoto, Lucas Lauton de Alcantara, Victor Zacarias, Edson Bollis, Lucas Pellicer, Anna Helena Reali Costa, Artur Jordao

+ [Graph Synthetic Out-of-Distribution Exposure with Large Language Models](https://arxiv.org//abs/2504.21198)

	Haoyan Xu, Zhengtao Yao, Ziyi Wang, Zhan Cheng, Xiyang Hu, Mengyuan Li, Yue Zhao

+ [A Domain-Agnostic Scalable AI Safety Ensuring Framework](https://arxiv.org//abs/2504.20924)

	Beomjun Kim, Kangyeon Kim, Sunwoo Kim, Heejin Ahn

+ [A Framework to Assess the Persuasion Risks Large Language Model Chatbots Pose to Democratic Societies](https://arxiv.org//abs/2505.00036)

	Zhongren Chen, Joshua Kalla, Quan Le, Shinpei Nakamura-Sakai, Jasjeet Sekhon, Ruixiao Wang

+ [HyPerAlign: Hypotheses-driven Personalized Alignment](https://arxiv.org//abs/2505.00038)

	Cristina Garbacea, Chenhao Tan

+ [Graph RAG for Legal Norms: A Hierarchical and Temporal Approach](https://arxiv.org//abs/2505.00039)

	Hudson de Martim

+ [Improving Phishing Email Detection Performance of Small Large Language Models](https://arxiv.org//abs/2505.00034)

	Zijie Lin, Zikang Liu, Hanbo Fan

# 2025-04-28
+ [GVPO: Group Variance Policy Optimization for Large Language Model Post-Training](https://arxiv.org//abs/2504.19599)

	Kaichen Zhang, Yuzhong Hong, Junwei Bao, Hongfei Jiang, Yang Song, Dingqian Hong, Hui Xiong

+ [From Evidence to Belief: A Bayesian Epistemology Approach to Language Models](https://arxiv.org//abs/2504.19622)

	Minsu Kim, Sangryul Kim, James Thorne

+ [From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review](https://arxiv.org//abs/2504.19678)

	Mohamed Amine Ferrag, Norbert Tihanyi, Merouane Debbah

+ [Can AI Agents Design and Implement Drug Discovery Pipelines?](https://arxiv.org//abs/2504.19912)

	Khachik Smbatyan, Tsolak Ghukasyan, Tigran Aghajanyan, Hovhannes Dabaghyan, Sergey Adamyan, Aram Bughdaryan, Vahagn Altunyan, Gagik Navasardyan, Aram Davtyan, Anush Hakobyan, Aram Gharibyan, Arman Fahradyan, Artur Hakobyan, Hasmik Mnatsakanyan, Narek Ginoyan, Garik Petrosyan

+ [TreeHop: Generate and Filter Next Query Embeddings Efficiently for Multi-hop Question Answering](https://arxiv.org//abs/2504.20114)

	Zhonghao Li, Kunpeng Zhang, Jinghuai Ou, Shuliang Liu, Xuming Hu

+ [AutoP2C: An LLM-Based Agent Framework for Code Repository Generation from Multimodal Content in Academic Papers](https://arxiv.org//abs/2504.20115)

	Zijie Lin, Yiqing Shen, Qilin Cai, He Sun, Jinrui Zhou, Mingjun Xiao

+ [ResearchCodeAgent: An LLM Multi-Agent System for Automated Codification of Research Methodologies](https://arxiv.org//abs/2504.20117)

	Shubham Gandhi, Dhruv Shah, Manasi Patwardhan, Lovekesh Vig, Gautam Shroff

+ [OpenTCM: A GraphRAG-Empowered LLM-based System for Traditional Chinese Medicine Knowledge Retrieval and Diagnosis](https://arxiv.org//abs/2504.20118)

	Jinglin He, Yunqi Guo, Lai Kwan Lam, Waikei Leung, Lixing He, Yuanan Jiang, Chi Chiu Wang, Guoliang Xing, Hongkai Chen

+ [Can LLMs Be Trusted for Evaluating RAG Systems? A Survey of Methods and Datasets](https://arxiv.org//abs/2504.20119)

	Lorenz Brehme, Thomas Ströhle, Ruth Breu

+ [LZ Penalty: An information-theoretic repetition penalty for autoregressive language models](https://arxiv.org//abs/2504.20131)

	Antonio A. Ginart, Naveen Kodali, Jason Lee, Caiming Xiong, Silvio Savarese, John R. Emmons

+ [MICE for CATs: Model-Internal Confidence Estimation for Calibrating Agents with Tools](https://arxiv.org//abs/2504.20168)

	Nishant Subramani, Jason Eisner, Justin Svegliato, Benjamin Van Durme, Yu Su, Sam Thomson

+ [BLADE: Benchmark suite for LLM-driven Automated Design and Evolution of iterative optimisation heuristics](https://arxiv.org//abs/2504.20183)

	Niki van Stein, Anna V. Kononova, Haoran Yin, Thomas Bäck

+ [Prompting LLMs for Code Editing: Struggles and Remedies](https://arxiv.org//abs/2504.20196)

	Daye Nam, Ahmed Omran, Ambar Murillo, Saksham Thakur, Abner Araujo, Marcel Blistein, Alexander Frömmgen, Vincent Hellendoorn, Satish Chandra

+ [Can Large Language Models Learn Formal Logic? A Data-Driven Training and Evaluation Framework](https://arxiv.org//abs/2504.20213)

	Yuan Xia, Akanksha Atrey, Fadoua Khmaissia, Kedar S. Namjoshi

+ [Toward Evaluative Thinking: Meta Policy Optimization with Evolving Reward Models](https://arxiv.org//abs/2504.20157)

	Zae Myung Kim, Chanwoo Park, Vipul Raheja, Dongyeop Kang

+ [LLM-Generated Fake News Induces Truth Decay in News Ecosystem: A Case Study on Neural News Recommendation](https://arxiv.org//abs/2504.20013)

	Beizhe Hu, Qiang Sheng, Juan Cao, Yang Li, Danding Wang

+ [Investigating task-specific prompts and sparse autoencoders for activation monitoring](https://arxiv.org//abs/2504.20271)

	Henk Tillman, Dan Mossing

+ [Security Steerability is All You Need](https://arxiv.org//abs/2504.19521)

	Itay Hazan, Idan Habler, Ron Bitton, Itsik Mantin

+ [The Automation Advantage in AI Red Teaming](https://arxiv.org//abs/2504.19855)

	Rob Mulla, Ads Dawson, Vincent Abruzzon, Brian Greunke, Nick Landers, Brad Palm, Will Pearce

+ [Can Differentially Private Fine-tuning LLMs Protect Against Privacy Attacks?](https://arxiv.org//abs/2504.21036)

	Hao Du, Shang Liu, Yang Cao

+ [Prefill-Based Jailbreak: A Novel Approach of Bypassing LLM Safety Boundary](https://arxiv.org//abs/2504.21038)

	Yakai Li, Jiekang Hu, Weiduan Sang, Luping Ma, Jing Xie, Weijuan Zhang, Aimin Yu, Shijie Zhao, Qingjia Huang, Qihang Zhou

+ [Llama-3.1-FoundationAI-SecurityLLM-Base-8B Technical Report](https://arxiv.org//abs/2504.21039)

	Paul Kassianik, Baturay Saglam, Alexander Chen, Blaine Nelson, Anu Vellore, Massimo Aufiero, Fraser Burch, Dhruv Kedia, Avi Zohary, Sajana Weerawardhena, Aman Priyanshu, Adam Swanda, Amy Chang, Hyrum Anderson, Kojin Oshiba, Omar Santos, Yaron Singer, Amin Karbasi

+ [What's Pulling the Strings? Evaluating Integrity and Attribution in AI Training and Inference through Concept Shift](https://arxiv.org//abs/2504.21042)

	Jiamin Chang, Haoyang Li, Hammond Pearce, Ruoxi Sun, Bo Li, Minhui Xue

+ [CodeBC: A More Secure Large Language Model for Smart Contract Code Generation in Blockchain](https://arxiv.org//abs/2504.21043)

	Lingxiang wang, Hainan Zhang, Qinnan Zhang, Ziwei Wang, Hongwei Zheng, Jin Dong, Zhiming Zheng

+ [AGATE: Stealthy Black-box Watermarking for Multimodal Model Copyright Protection](https://arxiv.org//abs/2504.21044)

	Jianbo Gao, Keke Gai, Jing Yu, Liehuang Zhu, Qi Wu

+ [Leveraging LLM to Strengthen ML-Based Cross-Site Scripting Detection](https://arxiv.org//abs/2504.21045)

	Dennis Miczek, Divyesh Gabbireddy, Suman Saha

+ [Learning to Plan Before Answering: Self-Teaching LLMs to Learn Abstract Plans for Problem Solving](https://arxiv.org//abs/2505.00031)

	Jin Zhang, Flood Sung, Zhilin Yang, Yang Gao, Chongjie Zhang

+ [BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text](https://arxiv.org//abs/2504.19467)

	Jiageng Wu, Bowen Gu, Ren Zhou, Kevin Xie, Doug Snyder, Yixing Jiang, Valentina Carducci, Richard Wyss, Rishi J Desai, Emily Alsentzer, Leo Anthony Celi, Adam Rodman, Sebastian Schneeweiss, Jonathan H. Chen, Santiago Romero-Brufau, Kueiyu Joshua Lin, Jie Yang

+ [Agentic Reasoning and Tool Integration for LLMs via Reinforcement Learning](https://arxiv.org//abs/2505.01441)

	Joykirat Singh, Raghav Magazine, Yash Pandya, Akshay Nambi

+ [Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents](https://arxiv.org//abs/2504.19956)

	Vineeth Sai Narajala, Om Narayan

+ [Accurate and Diverse LLM Mathematical Reasoning via Automated PRM-Guided GFlowNets](https://arxiv.org//abs/2504.19981)

	Adam Younsi, Abdalgader Abubaker, Mohamed El Amine Seddik, Hakim Hacid, Salem Lahlou

# 2025-04-27
+ [GenTorrent: Scaling Large Language Model Serving with An Overley Network](https://arxiv.org//abs/2504.20101)

	Fei Fang, Yifan Hua, Shengze Wang, Ruilin Zhou, Yi Liu, Chen Qian, Xiaoxue Zhang

+ [Adaptive Helpfulness-Harmlessness Alignment with Preference Vectors](https://arxiv.org//abs/2504.20106)

	Ren-Wei Liang, Chin-Ting Hsu, Chan-Hung Yu, Saransh Agrawal, Shih-Cheng Huang, Shang-Tse Chen, Kuan-Hao Huang, Shao-Hua Sun

+ [Unified Multi-Task Learning & Model Fusion for Efficient Language Model Guardrailing](https://arxiv.org//abs/2504.19333)

	James O' Neill, Santhosh Subramanian, Eric Lin, Vaikkunth Mugunthan

+ [Doxing via the Lens: Revealing Privacy Leakage in Image Geolocation for Agentic Multi-Modal Large Reasoning Model](https://arxiv.org//abs/2504.19373)

	Weidi Luo, Qiming Zhang, Tianyu Lu, Xiaogeng Liu, Yue Zhao, Zhen Xiang, Chaowei Xiao

+ [Selecting the Right LLM for eGov Explanations](https://arxiv.org//abs/2504.21032)

	Lior Limonad, Fabiana Fournier, Hadar Mulian, George Manias, Spiros Borotis, Danai Kyrkou

+ [SAGA: A Security Architecture for Governing AI Agentic Systems](https://arxiv.org//abs/2504.21034)

	Georgios Syros, Anshuman Suri, Cristina Nita-Rotaru, Alina Oprea

+ [Uncertainty Quantification for Language Models: A Suite of Black-Box, White-Box, LLM Judge, and Ensemble Scorers](https://arxiv.org//abs/2504.19254)

	Dylan Bouchard, Mohit Singh Chauhan

+ [Contextual Online Uncertainty-Aware Preference Learning for Human Feedback](https://arxiv.org//abs/2504.19342)

	Nan Lu, Ethan X. Fang, Junwei Lu

+ [Enhancing Speech-to-Speech Dialogue Modeling with End-to-End Retrieval-Augmented Generation](https://arxiv.org//abs/2505.00028)

	Pengchao Feng, Ziyang Ma, Wenxi Chen, Yao Li, Sheng Wang, Kai Yu, Xie Chen

+ [BrowseComp-ZH: Benchmarking Web Browsing Ability of Large Language Models in Chinese](https://arxiv.org//abs/2504.19314)

	Peilin Zhou, Bruce Leon, Xiang Ying, Can Zhang, Yifan Shao, Qichen Ye, Dading Chong, Zhiling Jin, Chenxuan Xie, Meng Cao, Yuxin Gu, Sixin Hong, Jing Ren, Jian Chen, Chao Liu, Yining Hua

+ [VIST-GPT: Ushering in the Era of Visual Storytelling with LLMs?](https://arxiv.org//abs/2504.19267)

	Mohamed Gado, Towhid Taliee, Muhammad Memon, Dmitry Ignatov, Radu Timofte

# 2025-04-26
+ [A Vision for Auto Research with LLM Agents](https://arxiv.org//abs/2504.18765)

	Chengwei Liu, Chong Wang, Jiayue Cao, Jingquan Ge, Kun Wang, Lvye Zhang, Ming-Ming Cheng, Penghai Zhao, Tianlin Li, Xiaojun Jia, Xiang Li, Xinfeng Li, Yang Liu, Yebo Feng, Yihao Huang, Yijia Xu, Yuqiang Sun, Zhenhong Zhou, Zhengzi Xu

+ [Generative to Agentic AI: Survey, Conceptualization, and Challenges](https://arxiv.org//abs/2504.18875)

	Johannes Schneider

+ [MATCHA: Can Multi-Agent Collaboration Build a Trustworthy Conversational Recommender?](https://arxiv.org//abs/2504.20094)

	Zheng Hui, Xiaokai Wei, Yexi Jiang, Kevin Gao, Chen Wang, Frank Ong, Se-eun Yoon, Rachit Pareek, Michelle Gong

+ [PICO: Secure Transformers via Robust Prompt Isolation and Cybersecurity Oversight](https://arxiv.org//abs/2504.21029)

	Ben Goertzel, Paulos Yibelo

+ [SynLexLM: Scaling Legal LLMs with Synthetic Data and Curriculum Learning](https://arxiv.org//abs/2504.18762)

	Ojasw Upadhyay, Abishek Saravanakumar, Ayman Ismail

+ [Theory of Mind in Large Language Models: Assessment and Enhancement](https://arxiv.org//abs/2505.00026)

	Ruirui Chen, Weifeng Jiang, Chengwei Qin, Cheston Tan

+ [Building Scalable AI-Powered Applications with Cloud Databases: Architectures, Best Practices and Performance Considerations](https://arxiv.org//abs/2504.18793)

	Santosh Bhupathi

+ [Test It Before You Trust It: Applying Software Testing for Trustworthy In-context Learning](https://arxiv.org//abs/2504.18827)

	Teeradaj Racharak, Chaiyong Ragkhitwetsagul, Chommakorn Sontesadisai, Thanwadee Sunetnanta

+ [A Simple Ensemble Strategy for LLM Inference: Towards More Stable Text Classification](https://arxiv.org//abs/2504.18884)

	Junichiro Niimi

# 2025-04-25
+ [MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind](https://arxiv.org//abs/2504.18039)

	Zheng Zhang, Nuoqian Xiao, Qi Chai, Deheng Ye, Hao Wang

+ [Reason Like a Radiologist: Chain-of-Thought and Reinforcement Learning for Verifiable Report Generation](https://arxiv.org//abs/2504.18453)

	Peiyuan Jing, Kinhei Lee, Zhenxuan Zhang, Huichi Zhou, Zhengqing Yuan, Zhifan Gao, Lei Zhu, Giorgos Papanastasiou, Yingying Fang, Guang Yang

+ [Scaling Laws For Scalable Oversight](https://arxiv.org//abs/2504.18530)

	Joshua Engels, David D. Baek, Subhash Kantamneni, Max Tegmark

+ [RAG LLMs are Not Safer: A Safety Analysis of Retrieval-Augmented Generation for Large Language Models](https://arxiv.org//abs/2504.18041)

	Bang An, Shiyue Zhang, Mark Dredze

+ [PropRAG: Guiding Retrieval with Beam Search over Proposition Paths](https://arxiv.org//abs/2504.18070)

	Jingjin Wang

+ [Stabilizing Reasoning in Medical LLMs with Continued Pretraining and Reasoning Preference Optimization](https://arxiv.org//abs/2504.18080)

	Wataru Kawakami, Keita Suzuki, Junichiro Iwasawa

+ [Random-Set Large Language Models](https://arxiv.org//abs/2504.18085)

	Muhammad Mubashar, Shireen Kudukkil Manchingal, Fabio Cuzzolin

+ [Application and Optimization of Large Models Based on Prompt Tuning for Fact-Check-Worthiness Estimation](https://arxiv.org//abs/2504.18104)

	Yinglong Yu, Hao Shen, Zhengyi Lyu, Qi He

+ [Evaluating Evaluation Metrics -- The Mirage of Hallucination Detection](https://arxiv.org//abs/2504.18114)

	Atharva Kulkarni, Yuan Zhang, Joel Ruben Antony Moniz, Xiou Ge, Bo-Hsiang Tseng, Dhivya Piraviperumal, Swabha Swayamdipta, Hong Yu

+ [Efficient Single-Pass Training for Multi-Turn Reasoning](https://arxiv.org//abs/2504.18246)

	Ritesh Goru, Shanay Mehta, Prateek Jain

+ [Towards Adaptive Software Agents for Debugging](https://arxiv.org//abs/2504.18316)

	Yacine Majdoub, Eya Ben Charrada, Haifa Touati

+ [Comparing Uncertainty Measurement and Mitigation Methods for Large Language Models: A Systematic Review](https://arxiv.org//abs/2504.18346)

	Toghrul Abbasli, Kentaroh Toyoda, Yuan Wang, Leon Witt, Muhammad Asif Ali, Yukai Miao, Dan Li, Qingsong Wei

+ [LLMpatronous: Harnessing the Power of LLMs For Vulnerability Detection](https://arxiv.org//abs/2504.18423)

	Rajesh Yarra

+ [Fast-Slow Thinking for Large Vision-Language Model Reasoning](https://arxiv.org//abs/2504.18458)

	Wenyi Xiao, Leilei Gan, Weilong Dai, Wanggui He, Ziwei Huang, Haoyuan Li, Fangxun Shu, Zhelun Yu, Peng Zhang, Hao Jiang, Fei Wu

+ [Improving LLM Personas via Rationalization with Psychological Scaffolds](https://arxiv.org//abs/2504.17993)

	Brihi Joshi, Xiang Ren, Swabha Swayamdipta, Rik Koncel-Kedziorski, Tim Paek

+ [DREAM: Disentangling Risks to Enhance Safety Alignment in Multimodal Large Language Models](https://arxiv.org//abs/2504.18053)

	Jianyu Liu, Hangyu Guo, Ranjie Duan, Xingyuan Bu, Yancheng He, Shilong Li, Hui Huang, Jiaheng Liu, Yucheng Wang, Chenchen Jing, Xingwei Qu, Xiao Zhang, Yingshui Tan, Yanan Wu, Jihao Gu, Yangguang Li, Jianke Zhu

+ [Even Small Reasoners Should Quote Their Sources: Introducing the Pleias-RAG Model Family](https://arxiv.org//abs/2504.18225)

	Pierre-Carl Langlais, Pavel Chizhov, Mattia Nee, Carlos Rosas Hinostroza, Matthieu Delsart, Irène Girard, Othman Hicheur, Anastasia Stasenko, Ivan P. Yamshchikov

+ [MAGI: Multi-Agent Guided Interview for Psychiatric Assessment](https://arxiv.org//abs/2504.18260)

	Guanqun Bi, Zhuang Chen, Zhoufu Liu, Hongkai Wang, Xiyao Xiao, Yuqiang Xie, Wen Zhang, Yongkang Huang, Yuxuan Chen, Libiao Peng, Yi Feng, Minlie Huang

+ [Auto-SLURP: A Benchmark Dataset for Evaluating Multi-Agent Frameworks in Smart Personal Assistant](https://arxiv.org//abs/2504.18373)

	Lei Shen, Xiaoyu Shen

+ [Expressing stigma and inappropriate responses prevents LLMs from safely replacing mental health providers](https://arxiv.org//abs/2504.18412)

	Jared Moore, Declan Grabb, William Agnew, Kevin Klyman, Stevie Chancellor, Desmond C. Ong, Nick Haber

+ [BitNet v2: Native 4-bit Activations with Hadamard Transformation for 1-bit LLMs](https://arxiv.org//abs/2504.18415)

	Hongyu Wang, Shuming Ma, Furu Wei

+ [PolyMath: Evaluating Mathematical Reasoning in Multilingual Contexts](https://arxiv.org//abs/2504.18428)

	Yiming Wang, Pei Zhang, Jialong Tang, Haoran Wei, Baosong Yang, Rui Wang, Chenshu Sun, Feitong Sun, Jiran Zhang, Junxuan Wu, Qiqian Cang, Yichang Zhang, Fei Huang, Junyang Lin, Fei Huang, Jingren Zhou

+ [Investigating Co-Constructive Behavior of Large Language Models in Explanation Dialogues](https://arxiv.org//abs/2504.18483)

	Leandra Fichtel, Maximilian Spliethöver, Eyke Hüllermeier, Patricia Jimenez, Nils Klowait, Stefan Kopp, Axel-Cyrille Ngonga Ngomo, Amelie Robrecht, Ingrid Scharlau, Lutz Terfloth, Anna-Lisa Vollmer, Henning Wachsmuth

+ [TRACE Back from the Future: A Probabilistic Reasoning Approach to Controllable Language Generation](https://arxiv.org//abs/2504.18535)

	Gwen Yidou Weng, Benjie Wang, Guy Van den Broeck

+ [SMARTFinRAG: Interactive Modularized Financial RAG Benchmark](https://arxiv.org//abs/2504.18024)

	Yiwei Zha

+ [Adversarial Attacks on LLM-as-a-Judge Systems: Insights from Prompt Injections](https://arxiv.org//abs/2504.18333)

	Narek Maloyan, Dmitry Namiot

+ [Revisiting Data Auditing in Large Vision-Language Models](https://arxiv.org//abs/2504.18349)

	Hongyu Zhu, Sichu Liang, Wenwen Wang, Boheng Li, Tongxin Yuan, Fangqi Li, ShiLin Wang, Zhuosheng Zhang

+ [Think, Prune, Train, Improve: Scaling Reasoning without Scaling Models](https://arxiv.org//abs/2504.18116)

	Caia Costello, Simon Guo, Anna Goldie, Azalia Mirhoseini

+ [DualRAG: A Dual-Process Approach to Integrate Reasoning and Retrieval for Multi-Hop Question Answering](https://arxiv.org//abs/2504.18243)

	Rong Cheng, Jinyi Liu, YAN ZHENG, Fei Ni, Jiazhen Du, Hangyu Mao, Fuzheng Zhang, Bo Wang, Jianye HAO

+ [Studying Small Language Models with Susceptibilities](https://arxiv.org//abs/2504.18274)

	Garrett Baker, George Wang, Jesse Hoogland, Daniel Murfet

+ [Streaming, Fast and Slow: Cognitive Load-Aware Streaming for Efficient LLM Serving](https://arxiv.org//abs/2504.17999)

	Chang Xiao, Brenda Yang

+ [NoEsis: Differentially Private Knowledge Transfer in Modular LLM Adaptation](https://arxiv.org//abs/2504.18147)

	Rob Romijnders, Stefanos Laskaridis, Ali Shahin Shamsabadi, Hamed Haddadi

+ [Automating Function-Level TARA for Automotive Full-Lifecycle Security](https://arxiv.org//abs/2504.18083)

	Yuqiao Yang, Yongzhao Zhang, Wenhao Liu, Jun Li, Pengtao Shi, DingYu Zhong, Jie Yang, Ting Chen, Sheng Cao, Yuntao Ren, Yongyue Wu, Xiaosong Zhang

+ [ThreMoLIA: Threat Modeling of Large Language Model-Integrated Applications](https://arxiv.org//abs/2504.18369)

	Felix Viktor Jedrzejewski, Davide Fucci, Oleksandr Adamov

+ [Proof-of-TBI -- Fine-Tuned Vision Language Model Consortium and OpenAI-o3 Reasoning LLM-Based Medical Diagnosis Support System for Mild Traumatic Brain Injury (TBI) Prediction](https://arxiv.org//abs/2504.18671)

	Ross Gore, Eranga Bandara, Sachin Shetty, Alberto E. Musto, Pratip Rana, Ambrosio Valencia-Romero, Christopher Rhea, Lobat Tayebi, Heather Richter, Atmaram Yarlagadda, Donna Edmonds, Steven Wallace, Donna Broshek

+ [Evolution of AI in Education: Agentic Workflows](https://arxiv.org//abs/2504.20082)

	Firuz Kamalov, David Santandreu Calonge, Linda Smail, Dilshod Azizov, Dimple R. Thadani, Theresa Kwong, Amara Atif

+ [Spark: A System for Scientifically Creative Idea Generation](https://arxiv.org//abs/2504.20090)

	Aishik Sanyal, Samuel Schapiro, Sumuk Shashidhar, Royce Moon, Lav R. Varshney, Dilek Hakkani-Tur

+ [A model and package for German ColBERT](https://arxiv.org//abs/2504.20083)

	Thuong Dang, Qiqi Chen

+ [CORG: Generating Answers from Complex, Interrelated Contexts](https://arxiv.org//abs/2505.00023)

	Hyunji Lee, Franck Dernoncourt, Trung Bui, Seunghyun Yoon

+ [Nemotron-Research-Tool-N1: Tool-Using Language Models with Reinforced Reasoning](https://arxiv.org//abs/2505.00024)

	Shaokun Zhang, Yi Dong, Jieyu Zhang, Jan Kautz, Bryan Catanzaro, Andrew Tao, Qingyun Wu, Zhiding Yu, Guilin Liu

+ [A Method for the Architecture of a Medical Vertical Large Language Model Based on Deepseek R1](https://arxiv.org//abs/2505.00025)

	Mingda Zhang, Jianglong Qin

+ [Anti-adversarial Learning: Desensitizing Prompts for Large Language Models](https://arxiv.org//abs/2505.01273)

	Xuan Li, Zhe Yin, Xiaodong Gu, Beijun Shen

# 2025-04-24
+ [Assessing the Capability of Large Language Models for Domain-Specific Ontology Generation](https://arxiv.org//abs/2504.17402)

	Anna Sofia Lippolis, Mohammad Javad Saeedizade, Robin Keskisarkka, Aldo Gangemi, Eva Blomqvist, Andrea Giovanni Nuzzolese

+ [Towards Machine-Generated Code for the Resolution of User Intentions](https://arxiv.org//abs/2504.17531)

	Justus Flerlage, Ilja Behnke, Odej Kao

+ [Auditing the Ethical Logic of Generative AI Models](https://arxiv.org//abs/2504.17544)

	W. Russell Neuman, Chad Coleman, Ali Dasdan, Safinah Ali, Manan Shah

+ [Automatically Generating Rules of Malicious Software Packages via Large Language Model](https://arxiv.org//abs/2504.17198)

	XiangRui Zhang, HaoYu Chen, Yongzhong He, Wenjia Niu, Qiang Li

+ [FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation](https://arxiv.org//abs/2504.17311)

	Yulia Otmakhova, Hung Thinh Truong, Rahmad Mahendra, Zenan Zhai, Rongxin Zhu, Daniel Beck, Jey Han Lau

+ [LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams](https://arxiv.org//abs/2504.17366)

	Yongxuan Wu, Runyu Chen, Peiyu Liu, Hongjin Qian

+ [Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks](https://arxiv.org//abs/2504.17421)

	Yang Liu, Bingjie Yan, Tianyuan Zou, Jianqing Zhang, Zixuan Gu, Jianbing Ding, Xidong Wang, Jingyi Li, Xiaozhou Ye, Ye Ouyang, Qiang Yang, Ya-Qin Zhang

+ [Towards Leveraging Large Language Model Summaries for Topic Modeling in Source Code](https://arxiv.org//abs/2504.17426)

	Michele Carissimi, Martina Saletta, Claudio Ferretti

+ [HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models](https://arxiv.org//abs/2504.17449)

	Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, Qin Xie, Guiming Xie, Xuejian Gong

+ [HalluLens: LLM Hallucination Benchmark](https://arxiv.org//abs/2504.17550)

	Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung

+ [Towards a HIPAA Compliant Agentic AI System in Healthcare](https://arxiv.org//abs/2504.17669)

	Subash Neupane, Shaswata Mitra, Sudip Mittal, Shahram Rahimi

+ [INSIGHT: Bridging the Student-Teacher Gap in Times of Large Language Models](https://arxiv.org//abs/2504.17677)

	Jarne Thys, Sebe Vanbrabant, Davy Vanacken, Gustavo Rovelo Ruiz

+ [Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks](https://arxiv.org//abs/2504.17685)

	Haru-Tada Sato, Fuka Matsuzaki, Jun-ichiro Takahashi

+ [Multilingual Performance Biases of Large Language Models in Education](https://arxiv.org//abs/2504.17720)

	Vansh Gupta, Sankalan Pal Chowdhury, Vilém Zouhar, Donya Rooein, Mrinmaya Sachan

+ [Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning](https://arxiv.org//abs/2504.17192)

	Minju Seo, Jinheon Baek, Seongyun Lee, Sung Ju Hwang

+ [A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation](https://arxiv.org//abs/2504.17200)

	Yangxinyu Xie, Bowen Jiang, Tanwi Mallick, Joshua David Bergerson, John K. Hutchison, Duane R. Verner, Jordan Branham, M. Ross Alexander, Robert B. Ross, Yan Feng, Leslie-Anne Levy, Weijie Su, Camillo J. Taylor

+ [Does Knowledge Distillation Matter for Large Language Model based Bundle Generation?](https://arxiv.org//abs/2504.17220)

	Kaidong Feng, Zhu Sun, Jie Yang, Hui Fang, Xinghua Qu, Wenyuan Liu

+ [Crisp: Cognitive Restructuring of Negative Thoughts through Multi-turn Supportive Dialogues](https://arxiv.org//abs/2504.17238)

	Jinfeng Zhou, Yuxuan Chen, Jianing Yin, Yongkang Huang, Yihan Shi, Xikun Zhang, Libiao Peng, Rongsheng Zhang, Tangjie Lv, Zhipeng Hu, Hongning Wang, Minlie Huang

+ [CoheMark: A Novel Sentence-Level Watermark for Enhanced Text Quality](https://arxiv.org//abs/2504.17309)

	Junyan Zhang, Shuliang Liu, Aiwei Liu, Yubo Gao, Jungang Li, Xiaojie Gu, Xuming Hu

+ [FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation](https://arxiv.org//abs/2504.17311)

	Yulia Otmakhova, Hung Thinh Truong, Rahmad Mahendra, Zenan Zhai, Rongxin Zhu, Daniel Beck, Jey Han Lau

+ [LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams](https://arxiv.org//abs/2504.17366)

	Yongxuan Wu, Runyu Chen, Peiyu Liu, Hongjin Qian

+ [Unified Attacks to Large Language Model Watermarks: Spoofing and Scrubbing in Unauthorized Knowledge Distillation](https://arxiv.org//abs/2504.17480)

	Xin Yi, Shunfan Zhengc, Linlin Wanga, Xiaoling Wang, Liang He

+ [HalluLens: LLM Hallucination Benchmark](https://arxiv.org//abs/2504.17550)

	Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung

+ [When Does Metadata Conditioning (NOT) Work for Language Model Pre-Training? A Study with Context-Free Grammars](https://arxiv.org//abs/2504.17562)

	Rei Higuchi, Ryotaro Kawata, Naoki Nishikawa, Kazusato Oko, Shoichiro Yamaguchi, Sosuke Kobayashi, Seiya Tokui, Kohei Hayashi, Daisuke Okanohara, Taiji Suzuki

+ [DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training](https://arxiv.org//abs/2504.17565)

	Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li

+ [Evaluating Grounded Reasoning by Code-Assisted Large Language Models for Mathematics](https://arxiv.org//abs/2504.17665)

	Zena Al-Khalili, Nick Howell, Dietrich Klakow

+ [Energy Considerations of Large Language Model Inference and Efficiency Optimizations](https://arxiv.org//abs/2504.17674)

	Jared Fernandez, Clara Na, Vashisth Tiwari, Yonatan Bisk, Sasha Luccioni, Emma Strubell

+ [Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks](https://arxiv.org//abs/2504.17685)

	Haru-Tada Sato, Fuka Matsuzaki, Jun-ichiro Takahashi

+ [Safety in Large Reasoning Models: A Survey](https://arxiv.org//abs/2504.17704)

	Cheng Wang, Yue Liu, Baolong Li, Duzhen Zhang, Zhongzhi Li, Junfeng Fang

+ [Multilingual Performance Biases of Large Language Models in Education](https://arxiv.org//abs/2504.17720)

	Vansh Gupta, Sankalan Pal Chowdhury, Vilém Zouhar, Donya Rooein, Mrinmaya Sachan

+ [The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs](https://arxiv.org//abs/2504.17768)

	Piotr Nawrot, Robert Li, Renjie Huang, Sebastian Ruder, Kelly Marchisio, Edoardo M. Ponti

+ [HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models](https://arxiv.org//abs/2504.17449)

	Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, Qin Xie, Guiming Xie, Xuejian Gong

+ [Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs](https://arxiv.org//abs/2504.17432)

	Tiancheng Gu, Kaicheng Yang, Ziyong Feng, Xingjun Wang, Yanzhao Zhang, Dingkun Long, Yingda Chen, Weidong Cai, Jiankang Deng

+ [Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks](https://arxiv.org//abs/2504.17421)

	Yang Liu, Bingjie Yan, Tianyuan Zou, Jianqing Zhang, Zixuan Gu, Jianbing Ding, Xidong Wang, Jingyi Li, Xiaozhou Ye, Ye Ouyang, Qiang Yang, Ya-Qin Zhang

+ [Towards Robust LLMs: an Adversarial Robustness Measurement Framework](https://arxiv.org//abs/2504.17723)

	Natan Levy, Adiel Ashrov, Guy Katz

+ [Replay to Remember: Retaining Domain Knowledge in Streaming Language Models](https://arxiv.org//abs/2504.17780)

	Sneh Pillai (University of Massachusetts Dartmouth)

+ [High-Fidelity And Complex Test Data Generation For Real-World SQL Code Generation Services](https://arxiv.org//abs/2504.17203)

	Shivasankari Kannan, Yeounoh Chung, Amita Gondi, Tristan Swadell, Fatma Ozcan

+ [Comprehend, Divide, and Conquer: Feature Subspace Exploration via Multi-Agent Hierarchical Reinforcement Learning](https://arxiv.org//abs/2504.17356)

	Weiliang Zhang, Xiaohan Huang, Yi Du, Ziyue Qiao, Qingqing Long, Zhen Meng, Yuanchun Zhou, Meng Xiao

+ [On-Device Qwen2.5: Efficient LLM Inference with Model Compression and Hardware Acceleration](https://arxiv.org//abs/2504.17376)

	Maoyang Xiang, Ramesh Fernando, Bo Wang

+ [L3: DIMM-PIM Integrated Architecture and Coordination for Scalable Long-Context LLM Inference](https://arxiv.org//abs/2504.17584)

	Qingyuan Liu, Liyan Chen, Yanning Yang, Haocheng Wang, Dong Du, Zhigang Mao, Naifeng Jing, Yubin Xia, Haibo Chen

+ [Assessing the Capability of Large Language Models for Domain-Specific Ontology Generation](https://arxiv.org//abs/2504.17402)

	Anna Sofia Lippolis, Mohammad Javad Saeedizade, Robin Keskisarkka, Aldo Gangemi, Eva Blomqvist, Andrea Giovanni Nuzzolese

+ [Towards Machine-Generated Code for the Resolution of User Intentions](https://arxiv.org//abs/2504.17531)

	Justus Flerlage, Ilja Behnke, Odej Kao

+ [Auditing the Ethical Logic of Generative AI Models](https://arxiv.org//abs/2504.17544)

	W. Russell Neuman, Chad Coleman, Ali Dasdan, Safinah Ali, Manan Shah

+ [Automatically Generating Rules of Malicious Software Packages via Large Language Model](https://arxiv.org//abs/2504.17198)

	XiangRui Zhang, HaoYu Chen, Yongzhong He, Wenjia Niu, Qiang Li

+ [NeuralGrok: Accelerate Grokking by Neural Gradient Transformation](https://arxiv.org//abs/2504.17243)

	Xinyu Zhou, Simin Fan, Martin Jaggi, Jie Fu

+ [FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation](https://arxiv.org//abs/2504.17311)

	Yulia Otmakhova, Hung Thinh Truong, Rahmad Mahendra, Zenan Zhai, Rongxin Zhu, Daniel Beck, Jey Han Lau

+ [LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams](https://arxiv.org//abs/2504.17366)

	Yongxuan Wu, Runyu Chen, Peiyu Liu, Hongjin Qian

+ [Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks](https://arxiv.org//abs/2504.17421)

	Yang Liu, Bingjie Yan, Tianyuan Zou, Jianqing Zhang, Zixuan Gu, Jianbing Ding, Xidong Wang, Jingyi Li, Xiaozhou Ye, Ye Ouyang, Qiang Yang, Ya-Qin Zhang

+ [Towards Leveraging Large Language Model Summaries for Topic Modeling in Source Code](https://arxiv.org//abs/2504.17426)

	Michele Carissimi, Martina Saletta, Claudio Ferretti

+ [HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models](https://arxiv.org//abs/2504.17449)

	Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, Qin Xie, Guiming Xie, Xuejian Gong

+ [HalluLens: LLM Hallucination Benchmark](https://arxiv.org//abs/2504.17550)

	Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung

+ [Towards a HIPAA Compliant Agentic AI System in Healthcare](https://arxiv.org//abs/2504.17669)

	Subash Neupane, Shaswata Mitra, Sudip Mittal, Shahram Rahimi

+ [INSIGHT: Bridging the Student-Teacher Gap in Times of Large Language Models](https://arxiv.org//abs/2504.17677)

	Jarne Thys, Sebe Vanbrabant, Davy Vanacken, Gustavo Rovelo Ruiz

+ [Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks](https://arxiv.org//abs/2504.17685)

	Haru-Tada Sato, Fuka Matsuzaki, Jun-ichiro Takahashi

+ [Multilingual Performance Biases of Large Language Models in Education](https://arxiv.org//abs/2504.17720)

	Vansh Gupta, Sankalan Pal Chowdhury, Vilém Zouhar, Donya Rooein, Mrinmaya Sachan

+ [Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning](https://arxiv.org//abs/2504.17192)

	Minju Seo, Jinheon Baek, Seongyun Lee, Sung Ju Hwang

+ [A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation](https://arxiv.org//abs/2504.17200)

	Yangxinyu Xie, Bowen Jiang, Tanwi Mallick, Joshua David Bergerson, John K. Hutchison, Duane R. Verner, Jordan Branham, M. Ross Alexander, Robert B. Ross, Yan Feng, Leslie-Anne Levy, Weijie Su, Camillo J. Taylor

+ [Does Knowledge Distillation Matter for Large Language Model based Bundle Generation?](https://arxiv.org//abs/2504.17220)

	Kaidong Feng, Zhu Sun, Jie Yang, Hui Fang, Xinghua Qu, Wenyuan Liu

+ [Crisp: Cognitive Restructuring of Negative Thoughts through Multi-turn Supportive Dialogues](https://arxiv.org//abs/2504.17238)

	Jinfeng Zhou, Yuxuan Chen, Jianing Yin, Yongkang Huang, Yihan Shi, Xikun Zhang, Libiao Peng, Rongsheng Zhang, Tangjie Lv, Zhipeng Hu, Hongning Wang, Minlie Huang

+ [CoheMark: A Novel Sentence-Level Watermark for Enhanced Text Quality](https://arxiv.org//abs/2504.17309)

	Junyan Zhang, Shuliang Liu, Aiwei Liu, Yubo Gao, Jungang Li, Xiaojie Gu, Xuming Hu

+ [PatientDx: Merging Large Language Models for Protecting Data-Privacy in Healthcare](https://arxiv.org//abs/2504.17360)

	Jose G. Moreno (IRIT-IRIS), Jesus Lovon (IRIT-IRIS), M'Rick Robin-Charlet (UT3), Christine Damase-Michel, Lynda Tamine (IRIT-IRIS)

+ [Unified Attacks to Large Language Model Watermarks: Spoofing and Scrubbing in Unauthorized Knowledge Distillation](https://arxiv.org//abs/2504.17480)

	Xin Yi, Shunfan Zhengc, Linlin Wanga, Xiaoling Wang, Liang He

+ [When Does Metadata Conditioning (NOT) Work for Language Model Pre-Training? A Study with Context-Free Grammars](https://arxiv.org//abs/2504.17562)

	Rei Higuchi, Ryotaro Kawata, Naoki Nishikawa, Kazusato Oko, Shoichiro Yamaguchi, Sosuke Kobayashi, Seiya Tokui, Kohei Hayashi, Daisuke Okanohara, Taiji Suzuki

+ [DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training](https://arxiv.org//abs/2504.17565)

	Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li

+ [Evaluating Grounded Reasoning by Code-Assisted Large Language Models for Mathematics](https://arxiv.org//abs/2504.17665)

	Zena Al-Khalili, Nick Howell, Dietrich Klakow

+ [Energy Considerations of Large Language Model Inference and Efficiency Optimizations](https://arxiv.org//abs/2504.17674)

	Jared Fernandez, Clara Na, Vashisth Tiwari, Yonatan Bisk, Sasha Luccioni, Emma Strubell

+ [Safety in Large Reasoning Models: A Survey](https://arxiv.org//abs/2504.17704)

	Cheng Wang, Yue Liu, Baolong Li, Duzhen Zhang, Zhongzhi Li, Junfeng Fang

+ [Conversational Assistants to support Heart Failure Patients: comparing a Neurosymbolic Architecture with ChatGPT](https://arxiv.org//abs/2504.17753)

	Anuja Tayal, Devika Salunke, Barbara Di Eugenio, Paula Allen-Meares, Eulalia Puig Abril, Olga Garcia, Carolyn Dickens, Andrew Boyd

+ [The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs](https://arxiv.org//abs/2504.17768)

	Piotr Nawrot, Robert Li, Renjie Huang, Sebastian Ruder, Kelly Marchisio, Edoardo M. Ponti

+ [Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs](https://arxiv.org//abs/2504.17432)

	Tiancheng Gu, Kaicheng Yang, Ziyong Feng, Xingjun Wang, Yanzhao Zhang, Dingkun Long, Yingda Chen, Weidong Cai, Jiankang Deng

+ [Towards Robust LLMs: an Adversarial Robustness Measurement Framework](https://arxiv.org//abs/2504.17723)

	Natan Levy, Adiel Ashrov, Guy Katz

+ [Replay to Remember: Retaining Domain Knowledge in Streaming Language Models](https://arxiv.org//abs/2504.17780)

	Sneh Pillai (University of Massachusetts Dartmouth)

+ [High-Fidelity And Complex Test Data Generation For Real-World SQL Code Generation Services](https://arxiv.org//abs/2504.17203)

	Shivasankari Kannan, Yeounoh Chung, Amita Gondi, Tristan Swadell, Fatma Ozcan

+ [On-Device Qwen2.5: Efficient LLM Inference with Model Compression and Hardware Acceleration](https://arxiv.org//abs/2504.17376)

	Maoyang Xiang, Ramesh Fernando, Bo Wang

+ [L3: DIMM-PIM Integrated Architecture and Coordination for Scalable Long-Context LLM Inference](https://arxiv.org//abs/2504.17584)

	Qingyuan Liu, Liyan Chen, Yanning Yang, Haocheng Wang, Dong Du, Zhigang Mao, Naifeng Jing, Yubin Xia, Haibo Chen

+ [LLM Agent Swarm for Hypothesis-Driven Drug Discovery](https://arxiv.org//abs/2504.17967)

	Kevin Song, Andrew Trotter, Jake Y. Chen

+ [Data-Driven Calibration of Prediction Sets in Large Vision-Language Models Based on Inductive Conformal Prediction](https://arxiv.org//abs/2504.17671)

	Yuanchang Ye, Weiyan Wen

+ [Unsupervised Corpus Poisoning Attacks in Continuous Space for Dense Retrieval](https://arxiv.org//abs/2504.17884)

	Yongkang Li, Panagiotis Eustratiadis, Simon Lupart, Evangelos Kanoulas

+ [Toward a Human-Centered Evaluation Framework for Trustworthy LLM-Powered GUI Agents](https://arxiv.org//abs/2504.17934)

	Chaoran Chen, Zhiping Zhang, Ibrahim Khalilov, Bingcan Guo, Simret A Gebreegziabher, Yanfang Ye, Ziang Xiao, Yaxing Yao, Tianshi Li, Toby Jia-Jun Li

+ [Collaborating Action by Action: A Multi-agent LLM Framework for Embodied Reasoning](https://arxiv.org//abs/2504.17950)

	Isadora White, Kolby Nottingham, Ayush Maniar, Max Robinson, Hansen Lillemark, Mehul Maheshwari, Lianhui Qin, Prithviraj Ammanabrolu

+ [DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training](https://arxiv.org//abs/2504.17565)

	Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li

+ [Training Large Language Models to Reason via EM Policy Gradient](https://arxiv.org//abs/2504.18587)

	Tianbing Xu

+ [BadMoE: Backdooring Mixture-of-Experts LLMs via Optimizing Routing Triggers and Infecting Dormant Experts](https://arxiv.org//abs/2504.18598)

	Qingyue Wang, Qi Pang, Xixun Lin, Shuai Wang, Daoyuan Wu

+ [RAGEN: Understanding Self-Evolution in LLM Agents via Multi-Turn Reinforcement Learning](https://arxiv.org//abs/2504.20073)

	Zihan Wang, Kangrui Wang, Qineng Wang, Pingyue Zhang, Linjie Li, Zhengyuan Yang, Kefan Yu, Minh Nhat Nguyen, Licheng Liu, Eli Gottlieb, Monica Lam, Yiping Lu, Kyunghyun Cho, Jiajun Wu, Li Fei-Fei, Lijuan Wang, Yejin Choi, Manling Li

+ [Tempo: Application-aware LLM Serving with Mixed SLO Requirements](https://arxiv.org//abs/2504.20068)

	Wei Zhang, Zhiyu Wu, Yi Mu, Banruo Liu, Myungjin Lee, Fan Lai

+ [ReCellTy: Domain-specific knowledge graph retrieval-augmented LLMs workflow for single-cell annotation](https://arxiv.org//abs/2505.00017)

	Dezheng Han, Yibin Jia, Ruxiao Chen, Wenjie Han, Shuaishuai Guo, Jianbo Wang

+ [An Empirical Study on Prompt Compression for Large Language Models](https://arxiv.org//abs/2505.00019)

	Zheng Zhang, Jinyi Li, Yihuai Lan, Xiang Wang, Hao Wang

+ [Beyond Public Access in LLM Pre-Training Data](https://arxiv.org//abs/2505.00020)

	Sruly Rosenblat, Tim O'Reilly, Ilan Strauss

+ [Aleph-Alpha-GermanWeb: Improving German-language LLM pre-training with model-based data curation and synthetic data generation](https://arxiv.org//abs/2505.00022)

	Thomas F Burns, Letitia Parcalabescu, Stephan Wäldchen, Michael Barlow, Gregor Ziegltrum, Volker Stampa, Bastian Harren, Björn Deiseroth

+ [Towards a HIPAA Compliant Agentic AI System in Healthcare](https://arxiv.org//abs/2504.17669)

	Subash Neupane, Sudip Mittal, Shahram Rahimi

# 2025-04-23
+ [Steering the CensorShip: Uncovering Representation Vectors for LLM "Thought" Control](https://arxiv.org//abs/2504.17130)

	Hannah Cyberey, David Evans

+ [Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification](https://arxiv.org//abs/2504.17017)

	Balaji Rao, William Eiers, Carlo Lipizzi

+ [Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments](https://arxiv.org//abs/2504.17087)

	Yuran Li, Jama Hussein Mohamud, Chongren Sun, Di Wu, Benoit Boulet

+ [Backslash: Rate Constrained Optimized Training of Large Language Models](https://arxiv.org//abs/2504.16968)

	Jun Wu, Jiangtao Wen, Yuxing Han

+ [(Im)possibility of Automated Hallucination Detection in Large Language Models](https://arxiv.org//abs/2504.17004)

	Amin Karbasi, Omar Montasser, John Sous, Grigoris Velegkas

+ [Robo-Troj: Attacking LLM-based Task Planners](https://arxiv.org//abs/2504.17070)

	Mohaiminul Al Nahian, Zainab Altaweel, David Reitano, Sabbir Ahmed, Saumitra Lohokare, Shiqi Zhang, Adnan Siraj Rakin

+ [MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation](https://arxiv.org//abs/2504.17137)

	Chanhee Park, Hyeonseok Moon, Chanjun Park, Heuiseok Lim

+ [Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark](https://arxiv.org//abs/2504.16427)

	Hanlei Zhang, Zhuohang Li, Yeshuang Zhu, Hua Xu, Peiwu Wang, Haige Zhu, Jie Zhou, Jinchao Zhang

+ [Optimizing LLMs for Italian: Reducing Token Fertility and Enhancing Efficiency Through Vocabulary Adaptation](https://arxiv.org//abs/2504.17025)

	Luca Moroni, Giovanni Puccetti, Pere-Lluis Huguet Cabot, Andrei Stefan Bejgu, Edoardo Barba, Alessio Miaschi, Felice Dell'Orletta, Andrea Esuli, Roberto Navigli

+ [Do Words Reflect Beliefs? Evaluating Belief Depth in Large Language Models](https://arxiv.org//abs/2504.17052)

	Shariar Kabir, Kevin Esterling, Yue Dong

+ [Agree to Disagree? A Meta-Evaluation of LLM Misgendering](https://arxiv.org//abs/2504.17075)

	Arjun Subramonian, Vagrant Gautam, Preethi Seshadri, Dietrich Klakow, Kai-Wei Chang, Yizhou Sun

+ [How Individual Traits and Language Styles Shape Preferences In Open-ended User-LLM Interaction: A Preliminary Study](https://arxiv.org//abs/2504.17083)

	Rendi Chevi, Kentaro Inui, Thamar Solorio, Alham Fikri Aji

+ [Co-CoT: A Prompt-Based Framework for Collaborative Chain-of-Thought Reasoning](https://arxiv.org//abs/2504.17091)

	Seunghyun Yoo

+ [Steering the CensorShip: Uncovering Representation Vectors for LLM "Thought" Control](https://arxiv.org//abs/2504.17130)

	Hannah Cyberey, David Evans

+ [MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation](https://arxiv.org//abs/2504.17137)

	Chanhee Park, Hyeonseok Moon, Chanjun Park, Heuiseok Lim

+ [(Im)possibility of Automated Hallucination Detection in Large Language Models](https://arxiv.org//abs/2504.17004)

	Amin Karbasi, Omar Montasser, John Sous, Grigoris Velegkas

+ [Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark](https://arxiv.org//abs/2504.16427)

	Hanlei Zhang, Zhuohang Li, Yeshuang Zhu, Hua Xu, Peiwu Wang, Haige Zhu, Jie Zhou, Jinchao Zhang

+ [Backslash: Rate Constrained Optimized Training of Large Language Models](https://arxiv.org//abs/2504.16968)

	Jun Wu, Jiangtao Wen, Yuxing Han

+ [Safety Pretraining: Toward the Next Generation of Safe AI](https://arxiv.org//abs/2504.16980)

	Pratyush Maini, Sachin Goyal, Dylan Sam, Alex Robey, Yash Savani, Yiding Jiang, Andy Zou, Zacharcy C. Lipton, J. Zico Kolter

+ [Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification](https://arxiv.org//abs/2504.17017)

	Balaji Rao, William Eiers, Carlo Lipizzi

+ [Exploring How LLMs Capture and Represent Domain-Specific Knowledge](https://arxiv.org//abs/2504.16871)

	Mirian Hipolito Garcia, Camille Couturier, Daniel Madrigal Diaz, Ankur Mallick, Anastasios Kyrillidis, Robert Sim, Victor Ruhle, Saravan Rajmohan


+ [Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments](https://arxiv.org//abs/2504.17087)

	Yuran Li, Jama Hussein Mohamud, Chongren Sun, Di Wu, Benoit Boulet

+ [Backslash: Rate Constrained Optimized Training of Large Language Models](https://arxiv.org//abs/2504.16968)

	Jun Wu, Jiangtao Wen, Yuxing Han

+ [(Im)possibility of Automated Hallucination Detection in Large Language Models](https://arxiv.org//abs/2504.17004)

	Amin Karbasi, Omar Montasser, John Sous, Grigoris Velegkas

+ [Robo-Troj: Attacking LLM-based Task Planners](https://arxiv.org//abs/2504.17070)

	Mohaiminul Al Nahian, Zainab Altaweel, David Reitano, Sabbir Ahmed, Saumitra Lohokare, Shiqi Zhang, Adnan Siraj Rakin

+ [MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation](https://arxiv.org//abs/2504.17137)

	Chanhee Park, Hyeonseok Moon, Chanjun Park, Heuiseok Lim

+ [Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark](https://arxiv.org//abs/2504.16427)

	Hanlei Zhang, Zhuohang Li, Yeshuang Zhu, Hua Xu, Peiwu Wang, Haige Zhu, Jie Zhou, Jinchao Zhang

+ [Optimizing LLMs for Italian: Reducing Token Fertility and Enhancing Efficiency Through Vocabulary Adaptation](https://arxiv.org//abs/2504.17025)

	Luca Moroni, Giovanni Puccetti, Pere-Lluis Huguet Cabot, Andrei Stefan Bejgu, Edoardo Barba, Alessio Miaschi, Felice Dell'Orletta, Andrea Esuli, Roberto Navigli

+ [Do Words Reflect Beliefs? Evaluating Belief Depth in Large Language Models](https://arxiv.org//abs/2504.17052)

	Shariar Kabir, Kevin Esterling, Yue Dong

+ [Agree to Disagree? A Meta-Evaluation of LLM Misgendering](https://arxiv.org//abs/2504.17075)

	Arjun Subramonian, Vagrant Gautam, Preethi Seshadri, Dietrich Klakow, Kai-Wei Chang, Yizhou Sun

+ [How Individual Traits and Language Styles Shape Preferences In Open-ended User-LLM Interaction: A Preliminary Study](https://arxiv.org//abs/2504.17083)

	Rendi Chevi, Kentaro Inui, Thamar Solorio, Alham Fikri Aji

+ [Co-CoT: A Prompt-Based Framework for Collaborative Chain-of-Thought Reasoning](https://arxiv.org//abs/2504.17091)

	Seunghyun Yoo

+ [Steering the CensorShip: Uncovering Representation Vectors for LLM "Thought" Control](https://arxiv.org//abs/2504.17130)

	Hannah Cyberey, David Evans

+ [Safety Pretraining: Toward the Next Generation of Safe AI](https://arxiv.org//abs/2504.16980)

	Pratyush Maini, Sachin Goyal, Dylan Sam, Alex Robey, Yash Savani, Yiding Jiang, Andy Zou, Zacharcy C. Lipton, J. Zico Kolter

+ [Exploring How LLMs Capture and Represent Domain-Specific Knowledge](https://arxiv.org//abs/2504.16871)

	Mirian Hipolito Garcia, Camille Couturier, Daniel Madrigal Diaz, Ankur Mallick, Anastasios Kyrillidis, Robert Sim, Victor Ruhle, Saravan Rajmohan

+ [EduBot -- Can LLMs Solve Personalized Learning and Programming Assignments?](https://arxiv.org//abs/2504.17824)

	Yibin Wang, Jiaxi Xie, Lakshminarayanan Subramanian

+ [BackSlash: Rate Constrained Optimized Training of Large Language Models](https://arxiv.org//abs/2504.16968)

	Jun Wu, Jiangtao Wen, Yuxing Han

+ [PARD: Accelerating LLM Inference with Low-Cost PARallel Draft Model Adaptation](https://arxiv.org//abs/2504.18583)

	Zihao An, Huajun Bai, Ziqiong Liu, Dong Li, Emad Barsoum

+ [Param$Δ$ for Direct Weight Mixing: Post-Train Large Language Model at Zero Cost](https://arxiv.org//abs/2504.21023)

	Sheng Cao, Mingrui Wu, Karthik Prasad, Yuandong Tian, Zechun Liu

+ [WebEvolver: Enhancing Web Agent Self-Improvement with Coevolving World Model](https://arxiv.org//abs/2504.21024)

	Tianqing Fang, Hongming Zhang, Zhisong Zhang, Kaixin Ma, Wenhao Yu, Haitao Mi, Dong Yu

+ [Sparks of Tabular Reasoning via Text2SQL Reinforcement Learning](https://arxiv.org//abs/2505.00016)

	Josefa Lia Stoisser, Marc Boubnovski Martell, Julien Fauqueur

+ [Building A Secure Agentic AI Application Leveraging A2A Protocol](https://arxiv.org//abs/2504.16902)

	Idan Habler, Ken Huang, Vineeth Sai Narajala, Prashant Kulkarni

+ [ConTextual: Improving Clinical Text Summarization in LLMs with Context-preserving Token Filtering and Knowledge Graphs](https://arxiv.org//abs/2504.16394)

	Fahmida Liza Piya, Rahmatollah Beheshti

+ [LLMSR@XLLM25: Less is More: Enhancing Structured Multi-Agent Reasoning via Quality-Guided Distillation](https://arxiv.org//abs/2504.16408)

	Jiahao Yuan, Xingzhe Sun, Xing Yu, Jingwen Wang, Dehui Du, Zhiqing Cui, Zixiang Di

+ [Harden and Catch for Just-in-Time Assured LLM-Based Software Testing: Open Research Challenges](https://arxiv.org//abs/2504.16472)

	Mark Harman, Peter O'Hearn, Shubho Sengupta

# 2025-04-22
+ [Impact of Noise on LLM-Models Performance in Abstraction and Reasoning Corpus (ARC) Tasks with Model Temperature Considerations](https://arxiv.org//abs/2504.15903)

	Nikhil Khandalkar, Pavan Yadav, Krishna Shinde, Lokesh B. Ramegowda, Rajarshi Das


+ [CAPO: Cost-Aware Prompt Optimization](https://arxiv.org//abs/2504.16005)

	Tom Zehle, Moritz Schlager, Timo Heiß, Matthias Feurer

+ [Pre-DPO: Improving Data Utilization in Direct Preference Optimization Using a Guiding Reference Model](https://arxiv.org//abs/2504.15843)

	Junshu Pan, Wei Shen, Shulin Huang, Qiji Zhou, Yue Zhang

+ [BELL: Benchmarking the Explainability of Large Language Models](https://arxiv.org//abs/2504.18572)

	Syed Quiser Ahmed, Bharathi Vokkaliga Ganesh, Jagadish Babu P, Karthick Selvaraj, ReddySiva Naga Parvathi Devi, Sravya Kappala

+ [Large Language Model Empowered Privacy-Protected Framework for PHI Annotation in Clinical Notes](https://arxiv.org//abs/2504.18569)

	Guanchen Wu, Linzhi Zheng, Han Xie, Zhen Xiang, Jiaying Lu, Darren Liu, Delgersuren Bold, Bo Li, Xiao Hu, Carl Yang

+ [Understanding the Skill Gap in Recurrent Language Models: The Role of the Gather-and-Aggregate Mechanism](https://arxiv.org//abs/2504.18574)

	Aviv Bick, Eric Xing, Albert Gu

+ [WASP: Benchmarking Web Agent Security Against Prompt Injection Attacks](https://arxiv.org//abs/2504.18575)

	Ivan Evtimov, Arman Zharmagambetov, Aaron Grattafiori, Chuan Guo, Kamalika Chaudhuri

+ [Kill two birds with one stone: generalized and robust AI-generated text detection via dynamic perturbations](https://arxiv.org//abs/2504.21019)

	Yinghan Zhou, Juan Wen, Wanli Peng, Yiming Xue, Ziwei Zhang, Zhengxian Wu

+ [Context-Enhanced Contrastive Search for Improved LLM Text Generation](https://arxiv.org//abs/2504.21020)

	Jaydip Sen, Rohit Pandey, Hetvi Waghela

+ [A Framework for Testing and Adapting REST APIs as LLM Tools](https://arxiv.org//abs/2504.15546)

	Jayachandu Bandlamudi, Ritwik Chaudhuri, Neelamadhav Gantayat, Kushal Mukherjee, Prerna Agarwal, Renuka Sindhgatta, Sameep Mehta

+ [Advancing Embodied Agent Security: From Safety Benchmarks to Input Moderation](https://arxiv.org//abs/2504.15699)

	Ning Wang, Zihan Yan, Weiyang Li, Chuan Ma, He Chen, Tao Xiang

+ [LLMs meet Federated Learning for Scalable and Secure IoT Management](https://arxiv.org//abs/2504.16032)

	Yazan Otoum, Arghavan Asad, Amiya Nayak

# 2025-04-21
+ [Intrinsic Barriers to Explaining Deep Foundation Models](https://arxiv.org//abs/2504.16948)

	Zhen Tan, Huan Liu

+ [KeyDiff: Key Similarity-Based KV Cache Eviction for Long-Context LLM Inference in Resource-Constrained Environments](https://arxiv.org//abs/2504.15364)

	Junyoung Park, Dalton Jones, Matt J Morse, Raghavv Goel, Mingu Lee, Chris Lott

+ [MARFT: Multi-Agent Reinforcement Fine-Tuning](https://arxiv.org//abs/2504.16129)

	Junwei Liao, Muning Wen, Jun Wang, Weinan Zhang

+ [Efficient Pretraining Length Scaling](https://arxiv.org//abs/2504.14992)

	Bohong Wu, Shen Yan, Sijun Zhang, Jianqiao Lu, Yutao Zeng, Ya Wang, Xun Zhou

+ [MARFT: Multi-Agent Reinforcement Fine-Tuning](https://arxiv.org//abs/2504.16129)

	Junwei Liao, Muning Wen, Jun Wang, Weinan Zhang


+ [DualBreach: Efficient Dual-Jailbreaking via Target-Driven Initialization and Multi-Target Optimization](https://arxiv.org//abs/2504.18564)

	Xinzhe Huang, Kedong Xiu, Tianhang Zheng, Churui Zeng, Wangze Ni, Zhan Qiin, Kui Ren, Chun Chen

+ [RepliBench: Evaluating the autonomous replication capabilities of language model agents](https://arxiv.org//abs/2504.18565)

	Sid Black, Asa Cooper Stickland, Jake Pencharz, Oliver Sourbut, Michael Schmatz, Jay Bailey, Ollie Matthews, Ben Millwood, Alex Remedios, Alan Cooney

+ [Jailbreak Detection in Clinical Training LLMs Using Feature-Based Predictive Models](https://arxiv.org//abs/2505.00010)

	Tri Nguyen, Lohith Srikanth Pentapalli, Magnus Sieverding, Laurah Turner, Seth Overla, Weibing Zheng, Chris Zhou, David Furniss, Danielle Weber, Michael Gharib, Matt Kelleher, Michael Shukis, Cameron Pawlik, Kelly Cohen

+ [Integrating Symbolic Execution into the Fine-Tuning of Code-Generating LLMs](https://arxiv.org//abs/2504.15210)

	Marina Sakharova, Abhinav Anand, Mira Mezini

+ [Splitwiser: Efficient LM inference with constrained resources](https://arxiv.org//abs/2505.03763)

	Asad Aali, Adney Cardoza, Melissa Capo

# 2025-04-20
+ [UFO2: The Desktop AgentOS](https://arxiv.org//abs/2504.14603)

	Chaoyun Zhang, He Huang, Chiming Ni, Jian Mu, Si Qin, Shilin He, Lu Wang, Fangkai Yang, Pu Zhao, Chao Du, Liqun Li, Yu Kang, Zhao Jiang, Suzhen Zheng, Rujia Wang, Jiaxu Qian, Minghua Ma, Jian-Guang Lou, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang

+ [Towards Optimal Circuit Generation: Multi-Agent Collaboration Meets Collective Intelligence](https://arxiv.org//abs/2504.14625)

	Haiyan Qin, Jiahao Feng, Xiaotong Feng, Wei W. Xing, Wang Kang

+ [FinSage: A Multi-aspect RAG System for Financial Filings Question Answering](https://arxiv.org//abs/2504.14493)

	Xinyu Wang, Jijun Chi, Zhenghan Tai, Tung Sum Thomas Kwok, Muzhi Li, Zhuhong Li, Hailin He, Yuchen Hua, Peng Lu, Suyuchen Wang, Yihong Wu, Jerry Huang, Jingrui Tian, Ling Zhou

+ [Don't Retrieve, Generate: Prompting LLMs for Synthetic Training Data in Dense Retrieval](https://arxiv.org//abs/2504.21015)

	Aarush Sinha

# 2025-04-19
+ [TALES: Text Adventure Learning Environment Suite](https://arxiv.org//abs/2504.14128)

	Christopher Zhang Cui, Xingdi Yuan, Ziang Xiao, Prithviraj Ammanabrolu, Marc-Alexandre Côté



+ [Mind the Language Gap: Automated and Augmented Evaluation of Bias in LLMs for High- and Low-Resource Languages](https://arxiv.org//abs/2504.18560)

	Alessio Buscemi, Cédric Lothritz, Sergio Morales, Marcos Gomez-Vazquez, Robert Clarisó, Jordi Cabot, German Castignani

+ [Improving the Serving Performance of Multi-LoRA Large Language Models via Efficient LoRA and KV Cache Management](https://arxiv.org//abs/2505.03756)

	Hang Zhang, Jiuchen Shi, Yixiao Wang, Quan Chen, Yizhou Shan, Minyi Guo

+ [The Geometry of Self-Verification in a Task-Specific Reasoning Model](https://arxiv.org//abs/2504.14379)

	Andrew Lee, Lihao Sun, Chris Wendler, Fernanda Viégas, Martin Wattenberg

# 2025-04-18
+ [SCRAG: Social Computing-Based Retrieval Augmented Generation for Community Response Forecasting in Social Media Environments](https://arxiv.org//abs/2504.16947)

	Dachun Sun, You Lyu, Jinning Li, Yizhuo Chen, Tianshi Wang, Tomoyoshi Kimura, Tarek Abdelzaher

+ [From Large to Super-Tiny: End-to-End Optimization for Cost-Efficient LLMs](https://arxiv.org//abs/2504.13471)

	Jiliang Ni, Jiachen Pu, Zhongyi Yang, Kun Zhou, Hui Wang, Xiaoliang Xiao, Dakui Wang, Xin Li, Jingfeng Luo, Conggang Hu


+ [From Large to Super-Tiny: End-to-End Optimization for Cost-Efficient LLMs](https://arxiv.org//abs/2504.13471)

	Jiliang Ni, Jiachen Pu, Zhongyi Yang, Kun Zhou, Hui Wang, Xiaoliang Xiao, Dakui Wang, Xin Li, Jingfeng Luo, Conggang Hu

+ [Gradual Binary Search and Dimension Expansion : A general method for activation quantization in LLMs](https://arxiv.org//abs/2504.13989)

	Lucas Maisonnave, Cyril Moineau, Olivier Bichler, Fabrice Rastello

# 2025-04-17
+ [GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning](https://arxiv.org//abs/2504.12597)

	Liangyu Xu, Yingxiu Zhao, Jingyun Wang, Yingyao Wang, Bu Pi, Chen Wang, Mingliang Zhang, Jihao Gu, Xiang Li, Xiaoyong Zhu, Jun Song, Bo Zheng



# 2025-04-16
+ [Activated LoRA: Fine-tuned LLMs for Intrinsics](https://arxiv.org//abs/2504.12397)

	Kristjan Greenewald, Luis Lastras, Thomas Parnell, Vraj Shah, Lucian Popa, Giulio Zizzo, Chulaka Gunasekara, Ambrish Rawat, David Cox

+ [Waking Up an AI: A Quantitative Framework for Prompt-Induced Phase Transition in Large Language Models](https://arxiv.org//abs/2504.21012)

	Makoto Sato

+ [The Devil is in the Prompts: Retrieval-Augmented Prompt Optimization for Text-to-Video Generation](https://arxiv.org//abs/2504.11739)

	Bingjie Gao, Xinyu Gao, Xiaoxue Wu, Yujie Zhou, Yu Qiao, Li Niu, Xinyuan Chen, Yaohui Wang

# 2025-04-15
+ [Looking beyond the next token](https://arxiv.org//abs/2504.11336)

	Abitha Thankaraj, Yiding Jiang, J. Zico Kolter, Yonatan Bisk

+ [Teaching Large Language Models to Reason through Learning and Forgetting](https://arxiv.org//abs/2504.11364)

	Tianwei Ni, Allen Nie, Sapana Chaudhary, Yao Liu, Huzefa Rangwala, Rasool Fakoor

+ [Nemotron-CrossThink: Scaling Self-Learning beyond Math Reasoning](https://arxiv.org//abs/2504.13941)

	Syeda Nahida Akter, Shrimai Prabhumoye, Matvei Novikov, Seungju Han, Ying Lin, Evelina Bakhturina, Eric Nyberg, Yejin Choi, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro


# 2025-04-14
+ [Transferable text data distillation by trajectory matching](https://arxiv.org//abs/2504.09818)

	Rong Yao, Hailin Hu, Yifei Fu, Hanting Chen, Wenyi Fang, Fanyi Du, Kai Han, Yunhe Wang

+ [Weight Ensembling Improves Reasoning in Language Models](https://arxiv.org//abs/2504.10478)

	Xingyu Dang, Christina Baek, Kaiyue Wen, Zico Kolter, Aditi Raghunathan

+ [Better Estimation of the KL Divergence Between Language Models](https://arxiv.org//abs/2504.10637)

	Afra Amini, Tim Vieira, Ryan Cotterell

# 2025-04-13
+ [CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent](https://arxiv.org//abs/2504.13192)

	Liang-bo Ning, Shijie Wang, Wenqi Fan, Qing Li, Xin Xu, Hao Chen, Feiran Huang

+ [EmoAgent: Assessing and Safeguarding Human-AI Interaction for Mental Health Safety](https://arxiv.org//abs/2504.09689)

	Jiahao Qiu, Yinghui He, Xinzhe Juan, Yimin Wang, Yuhan Liu, Zixin Yao, Yue Wu, Xun Jiang, Ling Yang, Mengdi Wang

+ [Mitigating Many-Shot Jailbreaking](https://arxiv.org//abs/2504.09604)

	Christopher M. Ackerman, Nina Panickssery

# 2025-04-11
+ [Enterprise-Grade Security for the Model Context Protocol (MCP): Frameworks and Mitigation Strategies](https://arxiv.org//abs/2504.08623)

	Vineeth Sai Narajala, Idan Habler

# 2025-04-10
+ [Throughput-Optimal Scheduling Algorithms for LLM Inference and AI Agents](https://arxiv.org//abs/2504.07347)

	Yueying Li, Jim Dai, Tianyi Peng


+ [Can Reasoning LLMs Enhance Clinical Document Classification?](https://arxiv.org//abs/2504.08040)

	Akram Mustafa, Usman Naseem, Mostafa Rahimi Azghadi

+ [Seed1.5-Thinking: Advancing Superb Reasoning Models with Reinforcement Learning](https://arxiv.org//abs/2504.13914)

	ByteDance Seed: Jiaze Chen, Tiantian Fan, Xin Liu, Lingjun Liu, Zhiqi Lin, Mingxuan Wang, Chengyi Wang, Xiangpeng Wei, Wenyuan Xu, Yufeng Yuan, Yu Yue, Lin Yan, Qiying Yu, Xiaochen Zuo, Chi Zhang, Ruofei Zhu, Zhecheng An, Zhihao Bai, Yu Bao, Xingyan Bin, Jiangjie Chen, Feng Chen, Hongmin Chen, Riwei Chen, Liangqiang Chen, Zixin Chen, Jinsong Chen, Siyan Chen, Kaiyuan Chen, Zhi Chen, Jin Chen, Jiecao Chen, Jinxin Chi, Weinan Dai, Ning Dai, Jiahui Dai, Shihan Dou, Yantao Du, Zhengyin Du, Jianhui Duan, Chen Dun, Ting-Han Fan, Jiazhan Feng, Junda Feng, Ziyuan Feng, Yuwei Fu, Wenqi Fu, Hanjie Fu, Hao Ge, Hongyi Guo, Mingji Han, Li Han, Wenhao Hao, Xintong Hao, Qianyu He, Jerry He, Feng He, Wen Heng, Zehua Hong, Qi Hou, Liang Hu, Shengding Hu, Nan Hu, Kai Hua, Qi Huang, Ziyue Huang, Hongzhi Huang, Zihao Huang, Ting Huang, Wenhao Huang, Wei Jia, Bin Jia, Xiaoying Jia, Yuhua Jiang, Haobin Jiang, Ziheng Jiang, Kaihua Jiang, Chengquan Jiang, Jianpeng Jiao, Xiaoran Jin, Xing Jin, Xunhao Lai, Zheng Li, Xiang Li, Liyi Li, Hongkai Li, Zheng Li, Shengxian Wan, Ya Wang, Yunshui Li, Chenggang Li, Niuniu Li, Siyu Li, Xi Li, Xiao Li, Aoyan Li, Yuntao Li, Nianning Liang, Xinnian Liang

+ [Towards Combinatorial Interpretability of Neural Computation](https://arxiv.org//abs/2504.08842)

	Micah Adler, Dan Alistarh, Nir Shavit

+ [Understanding Learner-LLM Chatbot Interactions and the Impact of Prompting Guidelines](https://arxiv.org//abs/2504.07840)

	Cansu Koyuturk, Emily Theophilou, Sabrina Patania, Gregor Donabauer, Andrea Martinenghi, Chiara Antico, Alessia Telari, Alessia Testa, Sathya Bursic, Franca Garzotto, Davinia Hernandez-Leo, Udo Kruschwitz, Davide Taibi, Simona Amenta, Martin Ruskov, Dimitri Ognibene

# 2025-04-07


+ [A Desideratum for Conversational Agents: Capabilities, Challenges, and Future Directions](https://arxiv.org//abs/2504.16939)

	Emre Can Acikgoz, Cheng Qian, Hongru Wang, Vardhan Dongre, Xiusi Chen, Heng Ji, Dilek Hakkani-Tür, Gokhan Tur

+ [Not All Data Are Unlearned Equally](https://arxiv.org//abs/2504.05058)

	Aravind Krishnan, Siva Reddy, Marius Mosbach


+ [Lightweight and Direct Document Relevance Optimization for Generative Information Retrieval](https://arxiv.org//abs/2504.05181)

	Kidist Amde Mekonnen, Yubao Tang, Maarten de Rijke

+ [CCSK:Cognitive Convection of Self-Knowledge Based Retrieval Augmentation for Large Language Models](https://arxiv.org//abs/2504.10498)

	Jianling Lu, Mingqi Lv, Tieming Chen

+ [LLM-based Automated Grading with Human-in-the-Loop](https://arxiv.org//abs/2504.05239)

	Hang Li, Yucheng Chu, Kaiqi Yang, Yasemin Copur-Gencturk, Jiliang Tang

+ [SEAL: Steerable Reasoning Calibration of Large Language Models for Free](https://arxiv.org//abs/2504.07986)

	Runjin Chen, Zhenyu Zhang, Junyuan Hong, Souvik Kundu, Zhangyang Wang

+ [AccLLM: Accelerating Long-Context LLM Inference Via Algorithm-Hardware Co-Design](https://arxiv.org//abs/2505.03745)

	Yanbiao Liang, Huihong Shi, Haikuo Shao, Zhongfeng Wang

+ [Promoting Security and Trust on Social Networks: Explainable Cyberbullying Detection Using Large Language Models in a Stream-Based Machine Learning Framework](https://arxiv.org//abs/2505.03746)

	Silvia García-Méndez, Francisco De Arriba-Pérez

+ [Beyond Single-Turn: A Survey on Multi-Turn Interactions with Large Language Models](https://arxiv.org//abs/2504.04717)

	Yubo Li, Xiaobin Shen, Xinyu Yao, Xueying Ding, Yidi Miao, Ramayya Krishnan, Rema Padman

# 2025-04-06
+ ["Trust me on this" Explaining Agent Behavior to a Human Terminator](https://arxiv.org//abs/2504.04592)

	Uri Menkes, Assaf Hallak, Ofra Amir

+ [Exploring Generative AI Techniques in Government: A Case Study](https://arxiv.org//abs/2504.10497)

	Sunyi Liu, Mengzhe Geng, Rebecca Hart

# 2025-04-04
+ [Noise Augmented Fine Tuning for Mitigating Hallucinations in Large Language Models](https://arxiv.org//abs/2504.03302)

	Afshin Khadangi, Amir Sartipi, Igor Tchappi, Ramin Bahmani

+ [APIGen-MT: Agentic Pipeline for Multi-Turn Data Generation via Simulated Agent-Human Interplay](https://arxiv.org//abs/2504.03601)

	Akshara Prabhakar, Zuxin Liu, Ming Zhu, Jianguo Zhang, Tulika Awalgaonkar, Shiyu Wang, Zhiwei Liu, Haolin Chen, Thai Hoang, Juan Carlos Niebles, Shelby Heinecke, Weiran Yao, Huan Wang, Silvio Savarese, Caiming Xiong

+ [How Social is It? A Benchmark for LLMs' Capabilities in Multi-user Multi-turn Social Agent Tasks](https://arxiv.org//abs/2505.04628)

	Yusen Wu, Junwu Xiong, Xiaotie Deng

# 2025-04-03
+ [Cognitive Memory in Large Language Models](https://arxiv.org//abs/2504.02441)

	Lianlei Shan, Shixian Luo, Zezhou Zhu, Yu Yuan, Yong Wu


+ [Multifaceted Evaluation of Audio-Visual Capability for MLLMs: Effectiveness, Efficiency, Generalizability and Robustness](https://arxiv.org//abs/2504.16936)

	Yusheng Zhao, Junyu Luo, Xiao Luo, Weizhi Zhang, Zhiping Xiao, Wei Ju, Philip S. Yu, Ming Zhang



+ [Generative Evaluation of Complex Reasoning in Large Language Models](https://arxiv.org//abs/2504.02810)

	Haowei Lin, Xiangyu Wang, Ruilin Yan, Baizhou Huang, Haotian Ye, Jianhua Zhu, Zihao Wang, James Zou, Jianzhu Ma, Yitao Liang

+ [GPG: A Simple and Strong Reinforcement Learning Baseline for Model Reasoning](https://arxiv.org//abs/2504.02546)

	Xiangxiang Chu, Hailang Huang, Xiao Zhang, Fei Wei, Yong Wang

+ [GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image Generation](https://arxiv.org//abs/2504.02782)

	Zhiyuan Yan, Junyan Ye, Weijia Li, Zilong Huang, Shenghai Yuan, Xiangyang He, Kaiqing Lin, Jun He, Conghui He, Li Yuan

+ [Why do LLMs attend to the first token?](https://arxiv.org//abs/2504.02732)

	Federico Barbero, Álvaro Arroyo, Xiangming Gu, Christos Perivolaropoulos, Michael Bronstein, Petar Veličković, Razvan Pascanu

+ [GPTAQ: Efficient Finetuning-Free Quantization for Asymmetric Calibration](https://arxiv.org//abs/2504.02692)

	Yuhang Li, Ruokai Yin, Donghyun Lee, Shiting Xiao, Priyadarshini Panda

# 2025-04-02
+ [LRAGE: Legal Retrieval Augmented Generation Evaluation Tool](https://arxiv.org//abs/2504.01840)

	Minhu Park, Hongseok Oh, Eunkyung Choi, Wonseok Hwang

+ [TiC-LM: A Web-Scale Benchmark for Time-Continual LLM Pretraining](https://arxiv.org//abs/2504.02107)

	Jeffrey Li, Mohammadreza Armandpour, Iman Mirzadeh, Sachin Mehta, Vaishaal Shankar, Raviteja Vemulapalli, Samy Bengio, Oncel Tuzel, Mehrdad Farajtabar, Hadi Pouransari, Fartash Faghri

+ [An Illusion of Progress? Assessing the Current State of Web Agents](https://arxiv.org//abs/2504.01382)

	Tianci Xue, Weijian Qi, Tianneng Shi, Chan Hee Song, Boyu Gou, Dawn Song, Huan Sun, Yu Su

+ [DeepSeek-R1 Thoughtology: Let's think about LLM Reasoning](https://arxiv.org//abs/2504.07128)

	Sara Vera Marjanović, Arkil Patel, Vaibhav Adlakha, Milad Aghajohari, Parishad BehnamGhader, Mehar Bhatia, Aditi Khandelwal, Austin Kraft, Benno Krojer, Xing Han Lù, Nicholas Meade, Dongchan Shin, Amirhossein Kazemnejad, Gaurav Kamath, Marius Mosbach, Karolina Stańczak, Siva Reddy

# 2025-04-01
+ [GraphMaster: Automated Graph Synthesis via LLM Agents in Data-Limited Environments](https://arxiv.org//abs/2504.00711)

	Enjun Du, Xunkai Li, Tian Jin, Zhihan Zhang, Rong-Hua Li, Guoren Wang

+ [Catch Me if You Search: When Contextual Web Search Results Affect the Detection of Hallucinations](https://arxiv.org//abs/2504.01153)

	Mahjabin Nahar, Eun-Ju Lee, Jin Won Park, Dongwon Lee

+ [Do We Truly Need So Many Samples? Multi-LLM Repeated Sampling Efficiently Scales Test-Time Compute](https://arxiv.org//abs/2504.00762)

	Jianhao Chen, Zishuo Xun, Bocheng Zhou, Han Qi, Hangfan Zhang, Qiaosheng Zhang, Yang Chen, Wei Hu, Yuzhong Qu, Wanli Ouyang, Shuyue Hu

+ [AI Hiring with LLMs: A Context-Aware and Explainable Multi-Agent Framework for Resume Screening](https://arxiv.org//abs/2504.02870)

	Frank P.-W. Lo, Jianing Qiu, Zeyu Wang, Haibao Yu, Yeming Chen, Gao Zhang, Benny Lo

# 2025-03-31
+ [Dynamic Parametric Retrieval Augmented Generation for Test-time Knowledge Enhancement](https://arxiv.org//abs/2503.23895)

	Yuqiao Tan, Shizhu He, Huanxuan Liao, Jun Zhao, Kang Liu

+ [A Survey on Test-Time Scaling in Large Language Models: What, How, Where, and How Well?](https://arxiv.org//abs/2503.24235)

	Qiyuan Zhang, Fuyuan Lyu, Zexu Sun, Lei Wang, Weixu Zhang, Wenyue Hua, Haolun Wu, Zhihan Guo, Yufei Wang, Niklas Muennighoff, Irwin King, Xue Liu, Chen Ma

+ [Rec-R1: Bridging Generative Large Language Models and User-Centric Recommendation Systems via Reinforcement Learning](https://arxiv.org//abs/2503.24289)

	Jiacheng Lin, Tian Wang, Kun Qian

+ [Is analogy enough to draw novel adjective-noun inferences?](https://arxiv.org//abs/2503.24293)

	Hayley Ross, Kathryn Davidson, Najoung Kim

# 2025-03-30
+ [A Survey of WebAgents: Towards Next-Generation AI Agents for Web Automation with Large Foundation Models](https://arxiv.org//abs/2503.23350)

	Liangbo Ning, Ziran Liang, Zhuohang Jiang, Haohao Qu, Yujuan Ding, Wenqi Fan, Xiao-yong Wei, Shanru Lin, Hui Liu, Philip S. Yu, Qing Li

# 2025-03-29
+ [LangVAE and LangSpace: Building and Probing for Language Model VAEs](https://arxiv.org//abs/2505.00004)

	Danilo S. Carvalho, Yingji Zhang, Harriet Unsworth, André Freitas

# 2025-03-28
+ [Probabilistic Uncertain Reward Model: A Natural Generalization of Bradley-Terry Reward Model](https://arxiv.org//abs/2503.22480)

	Wangtao Sun, Xiang Cheng, Xing Yu, Haotian Xu, Zhao Yang, Shizhu He, Jun Zhao, Kang Liu

+ [The Mind in the Machine: A Survey of Incorporating Psychological Theories in LLMs](https://arxiv.org//abs/2505.00003)

	Zizhou Liu, Ziwei Gong, Lin Ai, Zheng Hui, Run Chen, Colin Wayne Leach, Michelle R. Greene, Julia Hirschberg

# 2025-03-27
+ [Shared Global and Local Geometry of Language Model Embeddings](https://arxiv.org//abs/2503.21073)

	Andrew Lee, Melanie Weber, Fernanda Viégas, Martin Wattenberg

+ [A Computational Theory for Efficient Mini Agent Evaluation with Causal Guarantees](https://arxiv.org//abs/2503.21138)

	Hedong Yan

+ [Alleviating LLM-based Generative Retrieval Hallucination in Alipay Search](https://arxiv.org//abs/2503.21098)

	Yedan Shen, Kaixin Wu, Yuechen Ding, Jingyuan Wen, Hong Liu, Mingjie Zhong, Zhouhan Lin, Jia Xu, Linjian Mo

+ [UI-R1: Enhancing Efficient Action Prediction of GUI Agents by Reinforcement Learning](https://arxiv.org//abs/2503.21620)

	Zhengxi Lu, Yuxiang Chai, Yaxuan Guo, Xi Yin, Liang Liu, Hao Wang, Han Xiao, Shuai Ren, Guanjing Xiong, Hongsheng Li

+ [Video-R1: Reinforcing Video Reasoning in MLLMs](https://arxiv.org//abs/2503.21776)

	Kaituo Feng, Kaixiong Gong, Bohao Li, Zonghao Guo, Yibing Wang, Tianshuo Peng, Junfei Wu, Xiaoying Zhang, Benyou Wang, Xiangyu Yue

# 2025-03-26
+ [Dynamic Pyramid Network for Efficient Multimodal Large Language Model](https://arxiv.org//abs/2503.20322)

	Hao Ai, Kunyi Wang, Zezhou Wang, Hao Lu, Jin Tian, Yaxin Luo, Peng Xing, Jen-Yuan Huang, Huaxia Li, Gen luo


+ [Clean & Clear: Feasibility of Safe LLM Clinical Guidance](https://arxiv.org//abs/2503.20953)

	Julia Ive, Felix Jozsa, Nick Jackson, Paulina Bondaronek, Ciaran Scott Hill, Richard Dobson

# 2025-03-25
+ [CausalRAG: Integrating Causal Graphs into Retrieval-Augmented Generation](https://arxiv.org//abs/2503.19878)

	Nengbo Wang, Xiaotian Han, Jagdip Singh, Jing Ma, Vipin Chaudhary

+ [Rosetta-PL: Propositional Logic as a Benchmark for Large Language Model Reasoning](https://arxiv.org//abs/2505.00001)

	Shaun Baek, Shaun Esua-Mensah, Cyrus Tsui, Sejan Vigneswaralingam, Abdullah Alali, Michael Lu, Vasu Sharma, Kevin Zhu

+ [OAEI-LLM-T: A TBox Benchmark Dataset for Understanding Large Language Model Hallucinations in Ontology Matching](https://arxiv.org//abs/2503.21813)

	Zhangcheng Qiang

# 2025-03-24
+ [SimpleRL-Zoo: Investigating and Taming Zero Reinforcement Learning for Open Base Models in the Wild](https://arxiv.org//abs/2503.18892)

	Weihao Zeng, Yuzhen Huang, Qian Liu, Wei Liu, Keqing He, Zejun Ma, Junxian He

+ [Oaken: Fast and Efficient LLM Serving with Online-Offline Hybrid KV Cache Quantization](https://arxiv.org//abs/2503.18599)

	Minsu Kim, Seongmin Hong, RyeoWook Ko, Soongyu Choi, Hunjong Lee, Junsoo Kim, Joo-Young Kim, Jongse Park

# 2025-03-23
+ [HAIR: Hardness-Aware Inverse Reinforcement Learning with Introspective Reasoning for LLM Alignment](https://arxiv.org//abs/2503.18991)

	Ruoxi Cheng, Haoxuan Ma, Weixin Wang

+ [Adaptive Rank Allocation: Speeding Up Modern Transformers with RaNA Adapters](https://arxiv.org//abs/2503.18216)

	Roberto Garcia, Jerry Liu, Daniel Sorvisto, Sabri Eyuboglu

# 2025-03-22
+ [Evaluating Clinical Competencies of Large Language Models with a General Practice Benchmark](https://arxiv.org//abs/2503.17599)

	Zheqing Li, Yiying Yang, Jiping Lang, Wenhao Jiang, Yuhang Zhao, Shuang Li, Dingqian Wang, Zhu Lin, Xuanna Li, Yuze Tang, Jiexian Qiu, Xiaolin Lu, Hongji Yu, Shuang Chen, Yuhua Bi, Xiaofei Zeng, Yixian Chen, Junrong Chen, Lin Yao

# 2025-03-21
+ [A Survey on Personalized Alignment -- The Missing Piece for Large Language Models in Real-World Applications](https://arxiv.org//abs/2503.17003)

	Jian Guan, Junfei Wu, Jia-Nan Li, Chuanqi Cheng, Wei Wu

+ [ConvoGen: Enhancing Conversational AI with Synthetic Data: A Multi-Agent Approach](https://arxiv.org//abs/2503.17460)

	Reem Gody, Mahmoud Goudy, Ahmed Y. Tawfik

# 2025-03-19
+ [Benchmarking Open-Source Large Language Models on Healthcare Text Classification Tasks](https://arxiv.org//abs/2503.15169)

	Yuting Guo, Abeed Sarker

# 2025-03-18
+ [JuDGE: Benchmarking Judgment Document Generation for Chinese Legal System](https://arxiv.org//abs/2503.14258)

	Weihang Su, Baoqing Yue, Qingyao Ai, Yiran Hu, Jiaqi Li, Changyue Wang, Kaiyuan Zhang, Yueyue Wu, Yiqun Liu

+ [Predicting Human Choice Between Textually Described Lotteries](https://arxiv.org//abs/2503.14004)

	Eyal Marantz, Ori Plonsky

# 2025-03-17
+ [Atyaephyra at SemEval-2025 Task 4: Low-Rank Negative Preference Optimization](https://arxiv.org//abs/2503.13690)

	Jan Bronec (1), Jindřich Helcl (1) ((1) Charles University, Faculty of Mathematics and Physics, Institute of Formal and Applied Linguistics)

# 2025-03-16
+ [Towards Hierarchical Multi-Step Reward Models for Enhanced Reasoning in Large Language Models](https://arxiv.org//abs/2503.13551)

	Teng Wang, Zhangyi Jiang, Zhenqi He, Shenyang Tong, Wenhan Yang, Yanan Zheng, Zeyu Li, Zifan He, Hailei Gong

+ [Being-0: A Humanoid Robotic Agent with Vision-Language Models and Modular Skills](https://arxiv.org//abs/2503.12533)

	Haoqi Yuan, Yu Bai, Yuhui Fu, Bohan Zhou, Yicheng Feng, Xinrun Xu, Yi Zhan, Börje F. Karlsson, Zongqing Lu

# 2025-03-14
+ [CURIE: Evaluating LLMs On Multitask Scientific Long Context Understanding and Reasoning](https://arxiv.org//abs/2503.13517)

	Hao Cui, Zahra Shamsi, Gowoon Cheon, Xuejian Ma, Shutong Li, Maria Tikhanovskaya, Peter Norgaard, Nayantara Mudur, Martyna Plomecka, Paul Raccuglia, Yasaman Bahri, Victor V. Albert, Pranesh Srinivasan, Haining Pan, Philippe Faist, Brian Rohr, Ekin Dogus Cubuk, Muratahan Aykol, Amil Merchant, Michael J. Statt, Dan Morris, Drew Purves, Elise Kleeman, Ruth Alcantara, Matthew Abraham, Muqthar Mohammad, Ean Phing VanLee, Chenfei Jiang, Elizabeth Dorfman, Eun-Ah Kim, Michael P Brenner, Viren Jain, Sameera Ponda, Subhashini Venugopalan

# 2025-03-13
+ [HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks](https://arxiv.org//abs/2503.10894)

	Jiuding Sun, Jing Huang, Sidharth Baskaran, Karel D'Oosterlinck, Christopher Potts, Michael Sklar, Atticus Geiger


+ [HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks](https://arxiv.org//abs/2503.10894)

	Jiuding Sun, Jing Huang, Sidharth Baskaran, Karel D'Oosterlinck, Christopher Potts, Michael Sklar, Atticus Geiger

+ [How Do Multimodal Large Language Models Handle Complex Multimodal Reasoning? Placing Them in An Extensible Escape Game](https://arxiv.org//abs/2503.10042)

	Ziyue Wang, Yurui Dong, Fuwen Luo, Minyuan Ruan, Zhili Cheng, Chi Chen, Peng Li, Yang Liu

# 2025-03-12
+ [LocAgent: Graph-Guided LLM Agents for Code Localization](https://arxiv.org//abs/2503.09089)

	Zhaoling Chen, Xiangru Tang, Gangda Deng, Fang Wu, Jialong Wu, Zhiwei Jiang, Viktor Prasanna, Arman Cohan, Xingyao Wang

+ [Privacy-Preserved Automated Scoring using Federated Learning for Educational Research](https://arxiv.org//abs/2503.11711)

	Ehsan Latif, Xiaoming Zhai

+ [I Predict Therefore I Am: Is Next Token Prediction Enough to Learn Human-Interpretable Concepts from Data?](https://arxiv.org//abs/2503.08980)

	Yuhang Liu, Dong Gong, Yichao Cai, Erdun Gao, Zhen Zhang, Biwei Huang, Mingming Gong, Anton van den Hengel, Javen Qinfeng Shi

# 2025-03-11
+ [Training Plug-n-Play Knowledge Modules with Deep Context Distillation](https://arxiv.org//abs/2503.08727)

	Lucas Caccia, Alan Ansell, Edoardo Ponti, Ivan Vulić, Alessandro Sordoni

# 2025-03-09
+ [HCT-QA: A Benchmark for Question Answering on Human-Centric Tables](https://arxiv.org//abs/2504.20047)

	Mohammad S. Ahmad, Zan A. Naeem, Michaël Aupetit, Ahmed Elmagarmid, Mohamed Eltabakh, Xiasong Ma, Mourad Ouzzani, Chaoyi Ruan

# 2025-03-07
+ [Correctness Coverage Evaluation for Medical Multiple-Choice Question Answering Based on the Enhanced Conformal Prediction Framework](https://arxiv.org//abs/2503.05505)

	Yusong Ke, Hongru Lin, Yuting Ruan, Junya Tang, Li Li

+ [AVA: Attentive VLM Agent for Mastering StarCraft II](https://arxiv.org//abs/2503.05383)

	Weiyu Ma, Yuqian Fu, Zecheng Zhang, Bernard Ghanem, Guohao Li

# 2025-03-06
+ [Wanda++: Pruning Large Language Models via Regional Gradients](https://arxiv.org//abs/2503.04992)

	Yifan Yang, Kai Zhen, Bhavana Ganesh, Aram Galstyan, Goeric Huybrechts, Markus Müller, Jonas M. Kübler, Rupak Vignesh Swaminathan, Athanasios Mouchtaris, Sravan Babu Bodapati, Nathan Susanj, Zheng Zhang, Jack FitzGerald, Abhishek Kumar

# 2025-03-05
+ [CodeIF-Bench: Evaluating Instruction-Following Capabilities of Large Language Models in Interactive Code Generation](https://arxiv.org//abs/2503.22688)

	Peiding Wang, Li Zhang, Fang Liu, Lin Shi, Minxiao Li, Bo Shen, An Fu

+ [The Devil Is in the Details: Tackling Unimodal Spurious Correlations for Generalizable Multimodal Reward Models](https://arxiv.org//abs/2503.03122)

	Zichao Li, Xueru Wen, Jie Lou, Yuqiu Ji, Yaojie Lu, Xianpei Han, Debing Zhang, Le Sun

+ [Cite Before You Speak: Enhancing Context-Response Grounding in E-commerce Conversational LLM-Agents](https://arxiv.org//abs/2503.04830)

	Jingying Zeng, Hui Liu, Zhenwei Dai, Xianfeng Tang, Chen Luo, Samarth Varshney, Zhen Li, Qi He

# 2025-03-04
+ [LiteWebAgent: The Open-Source Suite for VLM-Based Web-Agent Applications](https://arxiv.org//abs/2503.02950)

	Danqing Zhang, Balaji Rama, Jingyi Ni, Shiying He, Fu Zhao, Kunyu Chen, Arnold Chen, Junyu Cao

# 2025-03-03
+ [SAGE: A Framework of Precise Retrieval for RAG](https://arxiv.org//abs/2503.01713)

	Jintao Zhang, Guoliang Li, Jinyang Su

+ [Liger: Linearizing Large Language Models to Gated Recurrent Structures](https://arxiv.org//abs/2503.01496)

	Disen Lan, Weigao Sun, Jiaxi Hu, Jusen Du, Yu Cheng

# 2025-03-02
+ [NCL-UoR at SemEval-2025 Task 3: Detecting Multilingual Hallucination and Related Observable Overgeneration Text Spans with Modified RefChecker and Modified SeflCheckGPT](https://arxiv.org//abs/2503.01921)

	Jiaying Hong, Thanet Markchom, Jianfei Xu, Tong Wu, Huizhi Liang

+ [ALinFiK: Learning to Approximate Linearized Future Influence Kernel for Scalable Third-Party LLM Data Valuation](https://arxiv.org//abs/2503.01052)

	Yanzhou Pan, Huawei Lin, Yide Ran, Jiamin Chen, Xiaodong Yu, Weijie Zhao, Denghui Zhang, Zhaozhuo Xu

# 2025-02-28
+ [SPD: Sync-Point Drop for efficient tensor parallelism of Large Language Models](https://arxiv.org//abs/2502.20727)

	Han-Byul Kim, Duc Hoang, Arnav Kundu, Mohammad Samragh, Minsik Cho

+ [Semantic Volume: Quantifying and Detecting both External and Internal Uncertainty in LLMs](https://arxiv.org//abs/2502.21239)

	Xiaomin Li, Zhou Yu, Ziji Zhang, Yingying Zhuang, Swair Shah, Narayanan Sadagopan, Anurag Beniwal

# 2025-02-27
+ [LLM-driven Effective Knowledge Tracing by Integrating Dual-channel Difficulty](https://arxiv.org//abs/2502.19915)

	Jiahui Cen, Jianghao Lin, Weixuan Zhong, Dong Zhou, Jin Chen, Aimin Yang, Yongmei Zhou

+ [Mapping Trustworthiness in Large Language Models: A Bibliometric Analysis Bridging Theory to Practice](https://arxiv.org//abs/2503.04785)

	José Siqueira de Cerqueira, Kai-Kristian Kemell, Muhammad Waseem, Rebekah Rousi, Nannan Xi, Juho Hamari, Pekka Abrahamsson

+ [Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization](https://arxiv.org//abs/2502.20364)

	Ryan C. Barron, Maksim E. Eren, Olga M. Serafimova, Cynthia Matuszek, Boian S. Alexandrov

# 2025-02-26
+ [BIG-Bench Extra Hard](https://arxiv.org//abs/2502.19187)

	Mehran Kazemi, Bahare Fatemi, Hritik Bansal, John Palowitch, Chrysovalantis Anastasiou, Sanket Vaibhav Mehta, Lalit K. Jain, Virginia Aglietti, Disha Jindal, Peter Chen, Nishanth Dikkala, Gladys Tyen, Xin Liu, Uri Shalit, Silvia Chiappa, Kate Olszewska, Yi Tay, Vinh Q. Tran, Quoc V. Le, Orhan Firat

+ [A Sliding Layer Merging Method for Efficient Depth-Wise Pruning in LLMs](https://arxiv.org//abs/2502.19159)

	Xuan Ding, Rui Sun, Yunjian Zhang, Xiu Yan, Yueqi Zhou, Kaihao Huang, Suzhong Fu, Chuanlong Xie, Yao Zhu

# 2025-02-25
+ [Faster, Cheaper, Better: Multi-Objective Hyperparameter Optimization for LLM and RAG Systems](https://arxiv.org//abs/2502.18635)

	Matthew Barker, Andrew Bell, Evan Thomas, James Carr, Thomas Andrews, Umang Bhatt

+ [Discriminative Finetuning of Generative Large Language Models without Reward Models and Human Preference Data](https://arxiv.org//abs/2502.18679)

	Siqi Guo, Ilgee Hong, Vicente Balmaseda, Changlong Yu, Liang Qiu, Xin Liu, Haoming Jiang, Tuo Zhao, Tianbao Yang

# 2025-02-24
+ [Automatically Evaluating the Paper Reviewing Capability of Large Language Models](https://arxiv.org//abs/2502.17086)

	Hyungyu Shin, Jingyu Tang, Yoonjoo Lee, Nayoung Kim, Hyunseung Lim, Ji Yong Cho, Hwajung Hong, Moontae Lee, Juho Kim

+ [From System 1 to System 2: A Survey of Reasoning Large Language Models](https://arxiv.org//abs/2502.17419)

	Zhong-Zhi Li, Duzhen Zhang, Ming-Liang Zhang, Jiaxin Zhang, Zengyan Liu, Yuxuan Yao, Haotian Xu, Junhao Zheng, Pei-Jie Wang, Xiuyi Chen, Yingying Zhang, Fei Yin, Jiahua Dong, Zhiwei Li, Bao-Long Bi, Ling-Rui Mei, Junfeng Fang, Zhijiang Guo, Le Song, Cheng-Lin Liu

+ [MEMERAG: A Multilingual End-to-End Meta-Evaluation Benchmark for Retrieval Augmented Generation](https://arxiv.org//abs/2502.17163)

	María Andrea Cruz Blandón, Jayasimha Talur, Bruno Charron, Dong Liu, Saab Mansour, Marcello Federico

# 2025-02-21
+ [Machine-generated text detection prevents language model collapse](https://arxiv.org//abs/2502.15654)

	George Drayson, Emine Yilmaz, Vasileios Lampos

+ [Activation Steering in Neural Theorem Provers](https://arxiv.org//abs/2502.15507)

	Shashank Kirtania

# 2025-02-20
+ [Drift: Decoding-time Personalized Alignments with Implicit User Preferences](https://arxiv.org//abs/2502.14289)

	Minbeom Kim, Kang-il Lee, Seongho Joo, Hwaran Lee, Thibaut Thonet, Kyomin Jung

+ [A Statistical Case Against Empirical Human-AI Alignment](https://arxiv.org//abs/2502.14581)

	Julian Rodemann, Esteban Garces Arias, Christoph Luther, Christoph Jansen, Thomas Augustin

+ [InductionBench: LLMs Fail in the Simplest Complexity Class](https://arxiv.org//abs/2502.15823)

	Wenyue Hua, Tyler Wong, Sun Fei, Liangming Pan, Adam Jardine, William Yang Wang

# 2025-02-18
+ [EPO: Explicit Policy Optimization for Strategic Reasoning in LLMs via Reinforcement Learning](https://arxiv.org//abs/2502.12486)

	Xiaoqian Liu, Ke Wang, Yongbin Li, Yuchuan Wu, Wentao Ma, Aobo Kong, Fei Huang, Jianbin Jiao, Junge Zhang

+ [An LLM-Powered Agent for Physiological Data Analysis: A Case Study on PPG-based Heart Rate Estimation](https://arxiv.org//abs/2502.12836)

	Mohammad Feli, Iman Azimi, Pasi Liljeberg, Amir M.Rahmani

+ [None of the Others: a General Technique to Distinguish Reasoning from Memorization in Multiple-Choice LLM Evaluation Benchmarks](https://arxiv.org//abs/2502.12896)

	Eva Sánchez Salido, Julio Gonzalo, Guillermo Marco

# 2025-02-17
+ [Towards Reasoning Ability of Small Language Models](https://arxiv.org//abs/2502.11569)

	Gaurav Srivastava, Shuxiang Cao, Xuan Wang


+ [Fate: Fast Edge Inference of Mixture-of-Experts Models via Cross-Layer Gate](https://arxiv.org//abs/2502.12224)

	Zhiyuan Fang, Zicong Hong, Yuegui Huang, Yufeng Lyu, Wuhui Chen, Yue Yu, Fan Yu, Zibin Zheng

+ [Integrating Expert Knowledge into Logical Programs via LLMs](https://arxiv.org//abs/2502.12275)

	Franciszek Górski, Oskar Wysocki, Marco Valentino, Andre Freitas

# 2025-02-16
+ [Leveraging Conditional Mutual Information to Improve Large Language Model Fine-Tuning For Classification](https://arxiv.org//abs/2502.11258)

	Thanushon Sivakaran, En-Hui Yang

+ [Safety Evaluation of DeepSeek Models in Chinese Contexts](https://arxiv.org//abs/2502.11137)

	Wenjing Zhang, Xuejiao Lei, Zhaoxiang Liu, Ning Wang, Zhenhong Long, Peijun Yang, Jiaojiao Zhao, Minjie Hua, Chaoyang Ma, Kai Wang, Shiguo Lian

# 2025-02-15
+ [D-CIPHER: Dynamic Collaborative Intelligent Multi-Agent System with Planner and Heterogeneous Executors for Offensive Security](https://arxiv.org//abs/2502.10931)

	Meet Udeshi, Minghao Shao, Haoran Xi, Nanda Rani, Kimberly Milner, Venkata Sai Charan Putrevu, Brendan Dolan-Gavitt, Sandeep Kumar Shukla, Prashanth Krishnamurthy, Farshad Khorrami, Ramesh Karri, Muhammad Shafique

# 2025-02-14
+ [Cooperative Multi-Agent Planning with Adaptive Skill Synthesis](https://arxiv.org//abs/2502.10148)

	Zhiyuan Li, Wenshuai Zhao, Joni Pajarinen

# 2025-02-13
+ [CRANE: Reasoning with constrained LLM generation](https://arxiv.org//abs/2502.09061)

	Debangshu Banerjee, Tarun Suresh, Shubham Ugare, Sasa Misailovic, Gagandeep Singh

# 2025-02-12
+ [k-LLMmeans: Scalable, Stable, and Interpretable Text Clustering via LLM-based Centroids](https://arxiv.org//abs/2502.09667)

	Jairo Diaz-Rodriguez

# 2025-02-11
+ [Time2Lang: Bridging Time-Series Foundation Models and Large Language Models for Health Sensing Beyond Prompting](https://arxiv.org//abs/2502.07608)

	Arvind Pillai, Dimitris Spathis, Subigya Nepal, Amanda C Collins, Daniel M Mackin, Michael V Heinz, Tess Z Griffin, Nicholas C Jacobson, Andrew Campbell

+ [Caught in the Web of Words: Do LLMs Fall for Spin in Medical Literature?](https://arxiv.org//abs/2502.07963)

	Hye Sun Yun, Karen Y.C. Zhang, Ramez Kouzy, Iain J. Marshall, Junyi Jessy Li, Byron C. Wallace

+ [Recursive Inference Scaling: A Winning Path to Scalable Inference in Language and Multimodal Systems](https://arxiv.org//abs/2502.07503)

	Ibrahim Alabdulmohsin, Xiaohua Zhai

+ [Principled Data Selection for Alignment: The Hidden Risks of Difficult Examples](https://arxiv.org//abs/2502.09650)

	Chengqian Gao, Haonan Li, Liu Liu, Zeke Xie, Peilin Zhao, Zhiqiang Xu

# 2025-02-10
+ [Generating Privacy-Preserving Personalized Advice with Zero-Knowledge Proofs and LLMs](https://arxiv.org//abs/2502.06425)

	Hiroki Watanabe, Motonobu Uchikoshi


+ [Unbiased Evaluation of Large Language Models from a Causal Perspective](https://arxiv.org//abs/2502.06655)

	Meilin Chen, Jian Tian, Liang Ma, Di Xie, Weijie Chen, Jiang Zhu

# 2025-02-09
+ [HSI: Head-Specific Intervention Can Induce Misaligned AI Coordination in Large Language Models](https://arxiv.org//abs/2502.05945)

	Paul Darm, Annalisa Riccardi

# 2025-02-08
+ [Agentic AI Systems Applied to tasks in Financial Services: Modeling and model risk management crews](https://arxiv.org//abs/2502.05439)

	Izunna Okpala, Ashkan Golgoon, Arjun Ravi Kannan

+ [The Odyssey of the Fittest: Can Agents Survive and Still Be Good?](https://arxiv.org//abs/2502.05442)

	Dylan Waldner, Risto Miikkulainen

# 2025-02-07
+ [Probabilistic Subspace Manifolds for Contextual Inference in Large Language Models](https://arxiv.org//abs/2502.05346)

	Christopher Nightingale, Dominic Lavington, Jonathan Thistlethwaite, Sebastian Penhaligon, Thomas Belinski, David Boldo

+ [MELON: Provable Indirect Prompt Injection Defense via Masked Re-execution and Tool Comparison](https://arxiv.org//abs/2502.05174)

	Kaijie Zhu, Xianjun Yang, Jindong Wang, Wenbo Guo, William Yang Wang

+ [Unveiling the Mechanisms of Explicit CoT Training: How CoT Enhances Reasoning Generalization](https://arxiv.org//abs/2502.04667)

	Xinhao Yao, Ruifeng Ren, Yun Liao, Yong Liu

+ [Generating Symbolic World Models via Test-time Scaling of Large Language Models](https://arxiv.org//abs/2502.04728)

	Zhouliang Yu, Yuhuan Yuan, Tim Z. Xiao, Fuxiang Frank Xia, Jie Fu, Ge Zhang, Ge Lin, Weiyang Liu

# 2025-02-06
+ [The Order Effect: Investigating Prompt Sensitivity to Input Order in LLMs](https://arxiv.org//abs/2502.04134)

	Bryan Guan, Tanya Roosta, Peyman Passban, Mehdi Rezagholizadeh

+ [SMI: An Information-Theoretic Metric for Predicting Model Knowledge Solely from Pre-Training Signals](https://arxiv.org//abs/2502.04066)

	Changhao Jiang, Ming Zhang, Junjie Ye, Xiaoran Fan, Yifei Cao, Jiajun Sun, Zhiheng Xi, Shihan Dou, Yi Dong, Yujiong Shen, Jingqi Tong, Zhen Wang, Tao Liang, Zhihui Fei, Mingyang Wan, Guojun Ma, Qi Zhang, Tao Gui, Xuanjing Huang

+ [FAS: Fast ANN-SNN Conversion for Spiking Large Language Models](https://arxiv.org//abs/2502.04405)

	Long Chen, Xiaotian Song, Andy Song, BaDong Chen, Jiancheng Lv, Yanan Sun

# 2025-02-04
+ [CITER: Collaborative Inference for Efficient Large Language Model Decoding with Token-Level Routing](https://arxiv.org//abs/2502.01976)

	Wenhao Zheng, Yixiao Chen, Weitong Zhang, Souvik Kundu, Yun Li, Zhengzhong Liu, Eric P. Xing, Hongyi Wang, Huaxiu Yao

# 2025-02-03
+ [Efficient Model Editing with Task Vector Bases: A Theoretical Framework and Scalable Approach](https://arxiv.org//abs/2502.01015)

	Siqi Zeng, Yifei He, Weiqiu You, Yifan Hao, Yao-Hung Hubert Tsai, Makoto Yamada, Han Zhao


+ [Factual Knowledge in Language Models: Robustness and Anomalies under Simple Temporal Context Variations](https://arxiv.org//abs/2502.01220)

	Hichem Ammar Khodja, Frédéric Béchet, Quentin Brabant, Alexis Nasr, Gwénolé Lecorvé

+ [Efficient Model Editing with Task Vector Bases: A Theoretical Framework and Scalable Approach](https://arxiv.org//abs/2502.01015)

	Siqi Zeng, Yifei He, Weiqiu You, Yifan Hao, Yao-Hung Hubert Tsai, Makoto Yamada, Han Zhao

+ [Massive Values in Self-Attention Modules are the Key to Contextual Knowledge Understanding](https://arxiv.org//abs/2502.01563)

	Mingyu Jin, Kai Mei, Wujiang Xu, Mingjie Sun, Ruixiang Tang, Mengnan Du, Zirui Liu, Yongfeng Zhang

+ [SE Arena: An Interactive Platform for Evaluating Foundation Models in Software Engineering](https://arxiv.org//abs/2502.01860)

	Zhimin Zhao

+ [Firewalls to Secure Dynamic LLM Agentic Networks](https://arxiv.org//abs/2502.01822)

	Sahar Abdelnabi, Amr Gomaa, Per Ola Kristensson, Reza Shokri

# 2025-02-01
+ [Explorations of the Softmax Space: Knowing When the Neural Network Doesn't Know](https://arxiv.org//abs/2502.00456)

	Daniel Sikar, Artur d'Avila Garcez, Tillman Weyde

+ [Estimating LLM Uncertainty with Logits](https://arxiv.org//abs/2502.00290)

	Huan Ma, Jingdong Chen, Joey Tianyi Zhou, Guangyu Wang, Changqing Zhang

# 2025-01-31
+ [Deep Learning Model Inversion Attacks and Defenses: A Comprehensive Survey](https://arxiv.org//abs/2501.18934)

	Wencheng Yang, Song Wang, Di Wu, Taotao Cai, Yanming Zhu, Shicheng Wei, Yiying Zhang, Xu Yang, Zhaohui Tang, Yan Li

+ [Towards the Worst-case Robustness of Large Language Models](https://arxiv.org//abs/2501.19040)

	Huanran Chen, Yinpeng Dong, Zeming Wei, Hang Su, Jun Zhu

# 2025-01-30
+ [Efficiency and Effectiveness of LLM-Based Summarization of Evidence in Crowdsourced Fact-Checking](https://arxiv.org//abs/2501.18265)

	Kevin Roitero, Dustin Wright, Michael Soprano, Isabelle Augenstein, Stefano Mizzaro

# 2025-01-29
+ [Large Language Models Think Too Fast To Explore Effectively](https://arxiv.org//abs/2501.18009)

	Lan Pan, Hanbo Xie, Robert C. Wilson

# 2025-01-28
+ [Instantiation-based Formalization of Logical Reasoning Tasks using Language Models and Logical Solvers](https://arxiv.org//abs/2501.16961)

	Mohammad Raza, Natasa Milic-Frayling

+ [RadioLLM: Introducing Large Language Model into Cognitive Radio via Hybrid Prompt and Token Reprogrammings](https://arxiv.org//abs/2501.17888)

	Shuai Chen, Yong Zu, Zhixi Feng, Shuyuan Yang, Mengchang Li

# 2025-01-27
+ [Are Transformers Able to Reason by Connecting Separated Knowledge in Training Data?](https://arxiv.org//abs/2501.15857)

	Yutong Yin, Zhaoran Wang


+ [Are Transformers Able to Reason by Connecting Separated Knowledge in Training Data?](https://arxiv.org//abs/2501.15857)

	Yutong Yin, Zhaoran Wang

+ [AdaCoT: Rethinking Cross-Lingual Factual Reasoning through Adaptive Chain-of-Thought](https://arxiv.org//abs/2501.16154)

	Xin Huang, Tarun Kumar Vangani, Zhengyuan Liu, Bowei Zou, Ai Ti Aw

# 2025-01-24
+ [Context-Aware Neural Gradient Mapping for Fine-Grained Instruction Processing](https://arxiv.org//abs/2501.14936)

	David Boldo, Lily Pemberton, Gabriel Thistledown, Jacob Fairchild, Felix Kowalski


+ [Prompt-Based Cost-Effective Evaluation and Operation of ChatGPT as a Computer Programming Teaching Assistant](https://arxiv.org//abs/2501.17176)

	Marc Ballestero-Ribó, Daniel Ortiz-Martínez

+ [Self-reflecting Large Language Models: A Hegelian Dialectical Approach](https://arxiv.org//abs/2501.14917)

	Sara Abdali, Can Goksen, Saeed Amizadeh, Julie E. Maybee, Kazuhito Koishida

+ [JustLogic: A Comprehensive Benchmark for Evaluating Deductive Reasoning in Large Language Models](https://arxiv.org//abs/2501.14851)

	Michael K. Chen, Xikun Zhang, Dacheng Tao

# 2025-01-23
+ [GraphRAG under Fire](https://arxiv.org//abs/2501.14050)

	Jiacheng Liang, Yuhui Wang, Changjiang Li, Rongyi Zhu, Tanqiu Jiang, Neil Gong, Ting Wang


+ [A Cognitive Paradigm Approach to Probe the Perception-Reasoning Interface in VLMs](https://arxiv.org//abs/2501.13620)

	Mohit Vaishnav, Tanel Tammet

+ [Communicating Activations Between Language Model Agents](https://arxiv.org//abs/2501.14082)

	Vignav Ramesh, Kenneth Li

+ [Softplus Attention with Re-weighting Boosts Length Extrapolation in Large Language Models](https://arxiv.org//abs/2501.13428)

	Bo Gao, Michael W. Spratling

# 2025-01-21
+ [Test-time regression: a unifying framework for designing sequence models with associative memory](https://arxiv.org//abs/2501.12352)

	Ke Alexander Wang, Jiaxin Shi, Emily B. Fox

# 2025-01-19
+ [A Comprehensive Survey on Integrating Large Language Models with Knowledge-Based Methods](https://arxiv.org//abs/2501.13947)

	Wenli Yang, Lilian Some, Michael Bain, Byeong Kang

+ [Chain-of-Reasoning: Towards Unified Mathematical Reasoning in Large Language Models via a Multi-Paradigm Perspective](https://arxiv.org//abs/2501.11110)

	Yiyao Yu, Yuxiang Zhang, Dongdong Zhang, Xiao Liang, Hengyuan Zhang, Xingxing Zhang, Mahmoud Khademi, Hany Awadalla, Junjie Wang, Yujiu Yang, Furu Wei

# 2025-01-10
+ [Dynamics of Spontaneous Topic Changes in Next Token Prediction with Self-Attention](https://arxiv.org//abs/2501.06382)

	Mumin Jia, Jairo Diaz-Rodriguez

# 2025-01-09
+ [CallNavi, A Challenge and Empirical Study on LLM Function Calling and Routing](https://arxiv.org//abs/2501.05255)

	Yewei Song, Xunzhu Tang, Cedric Lothritz, Saad Ezzini, Jacques Klein, Tegawendé F. Bissyandé, Andrey Boytsov, Ulrick Ble, Anne Goujon


+ [SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution](https://arxiv.org//abs/2501.05040)

	Chengxing Xie, Bowen Li, Chang Gao, He Du, Wai Lam, Difan Zou, Kai Chen

# 2025-01-05
+ [Towards the Anonymization of the Language Modeling](https://arxiv.org//abs/2501.02407)

	Antoine Boutet, Lucas Magnana, Juliette Sénéchal, Helain Zimmermann

+ [Scaling Laws for Floating Point Quantization Training](https://arxiv.org//abs/2501.02423)

	Xingwu Sun, Shuaipeng Li, Ruobing Xie, Weidong Han, Kan Wu, Zhen Yang, Yixing Li, An Wang, Shuai Li, Jinbao Xue, Yu Cheng, Yangyu Tao, Zhanhui Kang, Chengzhong Xu, Di Wang, Jie Jiang

# 2025-01-03
+ [MIRAGE: Exploring How Large Language Models Perform in Complex Social Interactive Environments](https://arxiv.org//abs/2501.01652)

	Yin Cai, Zhouhong Gu, Zhaohan Du, Zheyu Ye, Shaosheng Cao, Yiqian Xu, Hongwei Feng, Ping Chen

# 2025-01-02
+ [ValuesRAG: Enhancing Cultural Alignment Through Retrieval-Augmented Contextual Learning](https://arxiv.org//abs/2501.01031)

	Wonduk Seo, Zonghao Yuan, Yi Bu

# 2025-01-01
+ [LUSIFER: Language Universal Space Integration for Enhanced Multilingual Embeddings with Large Language Models](https://arxiv.org//abs/2501.00874)

	Hieu Man, Nghia Trung Ngo, Viet Dac Lai, Ryan A. Rossi, Franck Dernoncourt, Thien Huu Nguyen

# 2024-12-30
+ [ExpShield: Safeguarding Web Text from Unauthorized Crawling and Language Modeling Exploitation](https://arxiv.org//abs/2412.21123)

	Ruixuan Liu, Toan Tran, Tianhao Wang, Hongsheng Hu, Shuo Wang, Li Xiong

# 2024-12-29
+ [ICLR: In-Context Learning of Representations](https://arxiv.org//abs/2501.00070)

	Core Francisco Park, Andrew Lee, Ekdeep Singh Lubana, Yongyi Yang, Maya Okawa, Kento Nishi, Martin Wattenberg, Hidenori Tanaka

+ [Understanding the Impact of Confidence in Retrieval Augmented Generation: A Case Study in the Medical Domain](https://arxiv.org//abs/2412.20309)

	Shintaro Ozaki, Yuta Kato, Siyuan Feng, Masayo Tomita, Kazuki Hayashi, Wataru Hashimoto, Ryoma Obara, Masafumi Oyamada, Katsuhiko Hayashi, Hidetaka Kamigaito, Taro Watanabe

# 2024-12-28
+ [No Preference Left Behind: Group Distributional Preference Optimization](https://arxiv.org//abs/2412.20299)

	Binwei Yao, Zefan Cai, Yun-Shiuan Chuang, Shanglin Yang, Ming Jiang, Diyi Yang, Junjie Hu

# 2024-12-24
+ [LSAQ: Layer-Specific Adaptive Quantization for Large Language Model Deployment](https://arxiv.org//abs/2412.18135)

	Binrui Zeng, Bin Ji, Xiaodong Liu, Jie Yu, Shasha Li, Jun Ma, Xiaopeng Li, Shangwen Wang, Xinran Hong, Yongtao Tang

# 2024-12-23
+ [Fourier Position Embedding: Enhancing Attention's Periodic Extension for Length Generalization](https://arxiv.org//abs/2412.17739)

	Ermo Hua, Che Jiang, Xingtai Lv, Kaiyan Zhang, Ning Ding, Youbang Sun, Biqing Qi, Yuchen Fan, Xuekai Zhu, Bowen Zhou

# 2024-12-21
+ [Beyond Partisan Leaning: A Comparative Analysis of Political Bias in Large Language Models](https://arxiv.org//abs/2412.16746)

	Tai-Quan Peng, Kaiqi Yang, Sanguk Lee, Hang Li, Yucheng Chu, Yuping Lin, Hui Liu

# 2024-12-20
+ [Less is More: Towards Green Code Large Language Models via Unified Structural Pruning](https://arxiv.org//abs/2412.15921)

	Guang Yang, Yu Zhou, Xiangyu Zhang, Wei Cheng, Ke Liu, Xiang Chen, Terry Yue Zhuo, Taolue Chen


# 2024-12-19
+ [A Retrieval-Augmented Generation Framework for Academic Literature Navigation in Data Science](https://arxiv.org//abs/2412.15404)

	Ahmet Yasin Aytar, Kemal Kilic, Kamer Kaya

# 2024-12-16
+ [ElChat: Adapting Chat Language Models Using Only Target Unlabeled Language Data](https://arxiv.org//abs/2412.11704)

	Atsuki Yamaguchi, Terufumi Morishita, Aline Villavicencio, Nikolaos Aletras

# 2024-12-15
+ [AD-LLM: Benchmarking Large Language Models for Anomaly Detection](https://arxiv.org//abs/2412.11142)

	Tiankai Yang, Yi Nian, Shawn Li, Ruiyao Xu, Yuangang Li, Jiaqi Li, Zhuo Xiao, Xiyang Hu, Ryan Rossi, Kaize Ding, Xia Hu, Yue Zhao

+ [SceneLLM: Implicit Language Reasoning in LLM for Dynamic Scene Graph Generation](https://arxiv.org//abs/2412.11026)

	Hang Zhang, Zhuoling Li, Jun Liu

# 2024-12-13
+ [You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary Projects](https://arxiv.org//abs/2412.10133)

	Islem Bouzenia, Michael Pradel

# 2024-12-10
+ [A Causal World Model Underlying Next Token Prediction: Exploring GPT in a Controlled Environment](https://arxiv.org//abs/2412.07446)

	Raanan Y. Rohekar, Yaniv Gurwicz, Sungduk Yu, Estelle Aflalo, Vasudev Lal

+ [AutoPrep: Natural Language Question-Aware Data Preparation with a Multi-Agent Framework](https://arxiv.org//abs/2412.10422)

	Meihao Fan, Ju Fan, Nan Tang, Lei Cao, Guoliang Li, Xiaoyong Du

# 2024-12-07
+ [SLA Management in Reconfigurable Multi-Agent RAG: A Systems Approach to Question Answering](https://arxiv.org//abs/2412.06832)

	Michael Iannelli, Sneha Kuchipudi, Vera Dvorak

+ [KG-Retriever: Efficient Knowledge Indexing for Retrieval-Augmented Large Language Models](https://arxiv.org//abs/2412.05547)

	Weijie Chen, Ting Bai, Jinbo Su, Jian Luan, Wei Liu, Chuan Shi

# 2024-12-06
+ [Multi-Party Supervised Fine-tuning of Language Models for Multi-Party Dialogue Generation](https://arxiv.org//abs/2412.05342)

	Xiaoyu Wang, Ningyuan Xi, Teng Chen, Qingqing Gu, Yue Zhao, Xiaokai Chen, Zhonglin Jiang, Yong Chen, Luo Ji

# 2024-12-03
+ [Enhancing LLMs with Smart Preprocessing for EHR Analysis](https://arxiv.org//abs/2412.02868)

	Yixiang Qu, Yifan Dai, Shilin Yu, Pradham Tanikella, Travis Schrank, Trevor Hackman, Didong Li, Di Wu


+ [DP-2Stage: Adapting Language Models as Differentially Private Tabular Data Generators](https://arxiv.org//abs/2412.02467)

	Tejumade Afonja, Hui-Po Wang, Raouf Kerkouche, Mario Fritz

# 2024-12-02
+ [Mastering Board Games by External and Internal Planning with Language Models](https://arxiv.org//abs/2412.12119)

	John Schultz, Jakub Adamek, Matej Jusup, Marc Lanctot, Michael Kaisers, Sarah Perrin, Daniel Hennes, Jeremy Shar, Cannada Lewis, Anian Ruoss, Tom Zahavy, Petar Veličković, Laurel Prince, Satinder Singh, Eric Malmi, Nenad Tomašev

+ [FastRM: An efficient and automatic explainability framework for multimodal generative models](https://arxiv.org//abs/2412.01487)

	Gabriela Ben-Melech Stan, Estelle Aflalo, Man Luo, Shachar Rosenman, Tiep Le, Sayak Paul, Shao-Yen Tseng, Vasudev Lal

+ [Beyond Text-Visual Attention: Exploiting Visual Cues for Effective Token Pruning in VLMs](https://arxiv.org//abs/2412.01818)

	Qizhe Zhang, Aosong Cheng, Ming Lu, Renrui Zhang, Zhiyong Zhuo, Jiajun Cao, Shaobo Guo, Qi She, Shanghang Zhang

# 2024-12-01
+ [Competition Dynamics Shape Algorithmic Phases of In-Context Learning](https://arxiv.org//abs/2412.01003)

	Core Francisco Park, Ekdeep Singh Lubana, Itamar Pres, Hidenori Tanaka

# 2024-11-26
+ [ThreatModeling-LLM: Automating Threat Modeling using Large Language Models for Banking System](https://arxiv.org//abs/2411.17058)

	Tingmin Wu, Shuiqiao Yang, Shigang Liu, David Nguyen, Seung Jang, Alsharif Abuadbba

# 2024-11-22
+ [XGrammar: Flexible and Efficient Structured Generation Engine for Large Language Models](https://arxiv.org//abs/2411.15100)

	Yixin Dong, Charlie F. Ruan, Yaxing Cai, Ruihang Lai, Ziyi Xu, Yilong Zhao, Tianqi Chen

# 2024-11-21
+ [Insight-V: Exploring Long-Chain Visual Reasoning with Multimodal Large Language Models](https://arxiv.org//abs/2411.14432)

	Yuhao Dong, Zuyan Liu, Hai-Long Sun, Jingkang Yang, Winston Hu, Yongming Rao, Ziwei Liu

# 2024-11-19
+ [The Moral Mind(s) of Large Language Models](https://arxiv.org//abs/2412.04476)

	Avner Seror

# 2024-11-18
+ [PEEK: Phishing Evolution Framework for Phishing Generation and Evolving Pattern Analysis using Large Language Models](https://arxiv.org//abs/2411.11389)

	Fengchao Chen, Tingmin Wu, Van Nguyen, Shuo Wang, Alsharif Abuadbba, Carsten Rudolph

+ [PSPO*: An Effective Process-supervised Policy Optimization for Reasoning Alignment](https://arxiv.org//abs/2411.11681)

	Jiawei Li, Xinyue Liang, Junlong Zhang, Yizhe Yang, Chong Feng, Yang Gao

# 2024-11-17
+ [JailbreakLens: Interpreting Jailbreak Mechanism in the Lens of Representation and Circuit](https://arxiv.org//abs/2411.11114)

	Zeqing He, Zhibo Wang, Zhixuan Chu, Huiyu Xu, Wenhui Zhang, Qinglong Wang, Rui Zheng


+ [SRA-MCTS: Self-driven Reasoning Augmentation with Monte Carlo Tree Search for Code Generation](https://arxiv.org//abs/2411.11053)

	Bin Xu, Yiguan Lin, Yinghao Li, Yang Gao

# 2024-11-12
+ [Knowledge-Augmented Multimodal Clinical Rationale Generation for Disease Diagnosis with Small Language Models](https://arxiv.org//abs/2411.07611)

	Shuai Niu, Jing Ma, Hongzhan Lin, Liang Bai, Zhihua Wang, Yida Xu, Yunya Song, Xian Yang

+ [Beyond the Safety Bundle: Auditing the Helpful and Harmless Dataset](https://arxiv.org//abs/2411.08243)

	Khaoula Chehbouni, Jonathan Colaço Carr, Yash More, Jackie CK Cheung, Golnoosh Farnadi

+ [Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for Knowledge Graph Completion](https://arxiv.org//abs/2411.08165)

	Muzhi Li, Cehao Yang, Chengjin Xu, Xuhui Jiang, Yiyan Qi, Jian Guo, Ho-fung Leung, Irwin King

# 2024-11-10
+ [An Efficient Matrix Multiplication Algorithm for Accelerating Inference in Binary and Ternary Neural Networks](https://arxiv.org//abs/2411.06360)

	Mohsen Dehghankar, Mahdi Erfanian, Abolfazl Asudeh

# 2024-11-09
+ [A Picture is Worth A Thousand Numbers: Enabling LLMs Reason about Time Series via Visualization](https://arxiv.org//abs/2411.06018)

	Haoxin Liu, Chenghao Liu, B. Aditya Prakash

# 2024-11-08
+ [LLM-PySC2: Starcraft II learning environment for Large Language Models](https://arxiv.org//abs/2411.05348)

	Zongyuan Li, Yanan Ni, Runnan Qi, Lumin Jiang, Chang Lu, Xiaojie Xu, Xiangbei Liu, Pengfei Li, Yunzheng Guo, Zhe Ma, Huanyu Li, Hui Wu, Xian Guo, Kuihua Huang, Xuebo Zhang

# 2024-11-06
+ [LSHBloom: Memory-efficient, Extreme-scale Document Deduplication](https://arxiv.org//abs/2411.04257)

	Arham Khan, Robert Underwood, Carlo Siebenschuh, Yadu Babuji, Aswathy Ajith, Kyle Hippe, Ozan Gokdemir, Alexander Brace, Kyle Chard, Ian Foster

# 2024-11-01
+ [E2E-AFG: An End-to-End Model with Adaptive Filtering for Retrieval-Augmented Generation](https://arxiv.org//abs/2411.00437)

	Yun Jiang, Zilong Xie, Wei Zhang, Yun Fang, Shuai Pan

# 2024-10-31
+ [AlphaTrans: A Neuro-Symbolic Compositional Approach for Repository-Level Code Translation and Validation](https://arxiv.org//abs/2410.24117)

	Ali Reza Ibrahimzada, Kaiyao Ke, Mrigank Pawagi, Muhammad Salman Abid, Rangeet Pan, Saurabh Sinha, Reyhaneh Jabbarvand

+ [Constraint Back-translation Improves Complex Instruction Following of Large Language Models](https://arxiv.org//abs/2410.24175)

	Yunjia Qi, Hao Peng, Xiaozhi Wang, Bin Xu, Lei Hou, Juanzi Li

# 2024-10-30
+ [MDCure: A Scalable Pipeline for Multi-Document Instruction-Following](https://arxiv.org//abs/2410.23463)

	Gabrielle Kaili-May Liu, Bowen Shi, Avi Caciularu, Idan Szpektor, Arman Cohan

# 2024-10-29
+ [Personalization of Large Language Models: A Survey](https://arxiv.org//abs/2411.00027)

	Zhehao Zhang, Ryan A. Rossi, Branislav Kveton, Yijia Shao, Diyi Yang, Hamed Zamani, Franck Dernoncourt, Joe Barrow, Tong Yu, Sungchul Kim, Ruiyi Zhang, Jiuxiang Gu, Tyler Derr, Hongjie Chen, Junda Wu, Xiang Chen, Zichao Wang, Subrata Mitra, Nedim Lipka, Nesreen Ahmed, Yu Wang

+ [Unlearning as multi-task optimization: A normalized gradient difference approach with an adaptive learning rate](https://arxiv.org//abs/2410.22086)

	Zhiqi Bu, Xiaomeng Jin, Bhanukiran Vinzamuri, Anil Ramakrishna, Kai-Wei Chang, Volkan Cevher, Mingyi Hong

+ [Vision-Language Models Create Cross-Modal Task Representations](https://arxiv.org//abs/2410.22330)

	Grace Luo, Trevor Darrell, Amir Bar

# 2024-10-28
+ [Are LLM-Judges Robust to Expressions of Uncertainty? Investigating the effect of Epistemic Markers on LLM-based Evaluation](https://arxiv.org//abs/2410.20774)

	Dongryeol Lee, Yerin Hwang, Yongil Kim, Joonsuk Park, Kyomin Jung

# 2024-10-26
+ [Agentic Feedback Loop Modeling Improves Recommendation and User Simulation](https://arxiv.org//abs/2410.20027)

	Shihao Cai, Jizhi Zhang, Keqin Bao, Chongming Gao, Qifan Wang, Fuli Feng, Xiangnan He

# 2024-10-24
+ [Parameter-Efficient Fine-Tuning in Large Models: A Survey of Methodologies](https://arxiv.org//abs/2410.19878)

	Luping Wang, Sheng Chen, Linnan Jiang, Shu Pan, Runze Cai, Sen Yang, Fei Yang

# 2024-10-21
+ [Long Term Memory: The Foundation of AI Self-Evolution](https://arxiv.org//abs/2410.15665)

	Xun Jiang, Feng Li, Han Zhao, Jiahao Qiu, Jiaying Wang, Jun Shao, Shihao Xu, Shu Zhang, Weiling Chen, Xavier Tang, Yize Chen, Mengyue Wu, Weizhi Ma, Mengdi Wang, Tianqiao Chen

# 2024-10-18
+ [ELOQ: Resources for Enhancing LLM Detection of Out-of-Scope Questions](https://arxiv.org//abs/2410.14567)

	Zhiyuan Peng, Jinming Nian, Alexandre Evfimievski, Yi Fang

+ [Electrocardiogram-Language Model for Few-Shot Question Answering with Meta Learning](https://arxiv.org//abs/2410.14464)

	Jialu Tang, Tong Xia, Yuan Lu, Cecilia Mascolo, Aaqib Saeed

# 2024-10-17
+ [MobA: Multifaceted Memory-Enhanced Adaptive Planning for Efficient Mobile Task Automation](https://arxiv.org//abs/2410.13757)

	Zichen Zhu, Hao Tang, Yansi Li, Dingye Liu, Hongshen Xu, Kunyao Lan, Danyang Zhang, Yixuan Jiang, Hao Zhou, Chenrun Wang, Situo Zhang, Liangtai Sun, Yixiao Wang, Yuheng Sun, Lu Chen, Kai Yu

# 2024-10-16
+ [TradExpert: Revolutionizing Trading with Mixture of Expert LLMs](https://arxiv.org//abs/2411.00782)

	Qianggang Ding, Haochen Shi, Jiadong Guo, Bang Liu

# 2024-10-15
+ [MIND: Math Informed syNthetic Dialogues for Pretraining LLMs](https://arxiv.org//abs/2410.12881)

	Syeda Nahida Akter, Shrimai Prabhumoye, John Kamalu, Sanjeev Satheesh, Eric Nyberg, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro

# 2024-10-13
+ [Self-Data Distillation for Recovering Quality in Pruned Large Language Models](https://arxiv.org//abs/2410.09982)

	Vithursan Thangarasa, Ganesh Venkatesh, Mike Lasby, Nish Sinnadurai, Sean Lie

# 2024-10-10
+ [Extracting and Transferring Abilities For Building Multi-lingual Ability-enhanced Large Language Models](https://arxiv.org//abs/2410.07825)

	Zhipeng Chen, Kun Zhou, Liang Song, Wayne Xin Zhao, Bingning Wang, Weipeng Chen, Ji-Rong Wen

# 2024-10-09
+ [Let's Ask GNN: Empowering Large Language Model for Graph In-Context Learning](https://arxiv.org//abs/2410.07074)

	Zhengyu Hu, Yichuan Li, Zhengyu Chen, Jingang Wang, Han Liu, Kyumin Lee, Kaize Ding

+ [Steering Large Language Models using Conceptors: Improving Addition-Based Activation Engineering](https://arxiv.org//abs/2410.16314)

	Joris Postmus, Steven Abreu

+ [CursorCore: Assist Programming through Aligning Anything](https://arxiv.org//abs/2410.07002)

	Hao Jiang, Qi Liu, Rui Li, Shengyu Ye, Shijin Wang

# 2024-10-06
+ [Regressing the Relative Future: Efficient Policy Optimization for Multi-turn RLHF](https://arxiv.org//abs/2410.04612)

	Zhaolin Gao, Wenhao Zhan, Jonathan D. Chang, Gokul Swamy, Kianté Brantley, Jason D. Lee, Wen Sun


# 2024-10-04
+ [Understanding Large Language Models in Your Pockets: Performance Study on COTS Mobile Devices](https://arxiv.org//abs/2410.03613)

	Jie Xiao, Qianyi Huang, Xu Chen, Chen Tian

+ [Look Twice Before You Answer: Memory-Space Visual Retracing for Hallucination Mitigation in Multimodal Large Language Models](https://arxiv.org//abs/2410.03577)

	Xin Zou, Yizhou Wang, Yibo Yan, Yuanhuiyi Lyu, Kening Zheng, Sirui Huang, Junkai Chen, Peijie Jiang, Jia Liu, Chang Tang, Xuming Hu

# 2024-10-03
+ [Selective Attention Improves Transformer](https://arxiv.org//abs/2410.02703)

	Yaniv Leviathan, Matan Kalman, Yossi Matias


+ [A Formal Framework for Understanding Length Generalization in Transformers](https://arxiv.org//abs/2410.02140)

	Xinting Huang, Andy Yang, Satwik Bhattamishra, Yash Sarrof, Andreas Krebs, Hattie Zhou, Preetum Nakkiran, Michael Hahn

+ [Theoretical Insights into Fine-Tuning Attention Mechanism: Generalization and Optimization](https://arxiv.org//abs/2410.02247)

	Xinhao Yao, Hongjin Qian, Xiaolin Hu, Gengze Xu, Wei Liu, Jian Luan, Bin Wang, Yong Liu

# 2024-10-02
+ [TypedThinker: Diversify Large Language Model Reasoning with Typed Thinking](https://arxiv.org//abs/2410.01952)

	Danqing Wang, Jianxin Ma, Fei Fang, Lei Li


+ [Racing Thoughts: Explaining Contextualization Errors in Large Language Models](https://arxiv.org//abs/2410.02102)

	Michael A. Lepori, Michael C. Mozer, Asma Ghandeharioun

+ [Moral Alignment for LLM Agents](https://arxiv.org//abs/2410.01639)

	Elizaveta Tennant, Stephen Hailes, Mirco Musolesi

# 2024-09-30
+ [Beyond Single Concept Vector: Modeling Concept Subspace in LLMs with Gaussian Distribution](https://arxiv.org//abs/2410.00153)

	Haiyan Zhao, Heng Zhao, Bo Shen, Ali Payani, Fan Yang, Mengnan Du

+ [Characterizing and Efficiently Accelerating Multimodal Generation Model Inference](https://arxiv.org//abs/2410.00215)

	Yejin Lee, Anna Sun, Basil Hosmer, Bilge Acun, Can Balioglu, Changhan Wang, Charles David Hernandez, Christian Puhrsch, Daniel Haziza, Driss Guessous, Francisco Massa, Jacob Kahn, Jeffrey Wan, Jeremy Reizenstein, Jiaqi Zhai, Joe Isaacson, Joel Schlosser, Juan Pino, Kaushik Ram Sadagopan, Leonid Shamis, Linjian Ma, Min-Jae Hwang, Mingda Chen, Mostafa Elhoushi, Pedro Rodriguez, Ram Pasunuru, Scott Yih, Sravya Popuri, Xing Liu, Carole-Jean Wu

# 2024-09-27
+ [Can LLMs Really Learn to Translate a Low-Resource Language from One Grammar Book?](https://arxiv.org//abs/2409.19151)

	Seth Aycock, David Stap, Di Wu, Christof Monz, Khalil Sima'an

# 2024-09-23
+ [Scideator: Human-LLM Scientific Idea Generation Grounded in Research-Paper Facet Recombination](https://arxiv.org//abs/2409.14634)

	Marissa Radensky, Simra Shahid, Raymond Fok, Pao Siangliulue, Tom Hope, Daniel S. Weld

+ [Revise, Reason, and Recognize: LLM-Based Emotion Recognition via Emotion-Specific Prompts and ASR Error Correction](https://arxiv.org//abs/2409.15551)

	Yuanchao Li, Yuan Gong, Chao-Han Huck Yang, Peter Bell, Catherine Lai

# 2024-09-19
+ [Prompts Are Programs Too! Understanding How Developers Build Software Containing Prompts](https://arxiv.org//abs/2409.12447)

	Jenny T. Liang, Melissa Lin, Nikitha Rao, Brad A. Myers

# 2024-09-18
+ [To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning](https://arxiv.org//abs/2409.12183)

	Zayne Sprague, Fangcong Yin, Juan Diego Rodriguez, Dongwei Jiang, Manya Wadhwa, Prasann Singhal, Xinyu Zhao, Xi Ye, Kyle Mahowald, Greg Durrett

# 2024-09-17
+ [Measuring and Enhancing Trustworthiness of LLMs in RAG through Grounded Attributions and Learning to Refuse](https://arxiv.org//abs/2409.11242)

	Maojia Song, Shang Hong Sim, Rishabh Bhardwaj, Hai Leong Chieu, Navonil Majumder, Soujanya Poria

+ [Exploring the Trade-Offs: Quantization Methods, Task Difficulty, and Model Size in Large Language Models From Edge to Giant](https://arxiv.org//abs/2409.11055)

	Jemin Lee, Sihyeong Park, Jinse Kwon, Jihun Oh, Yongin Kwon

# 2024-09-16
+ [Lab-AI: Using Retrieval Augmentation to Enhance Language Models for Personalized Lab Test Interpretation in Clinical Medicine](https://arxiv.org//abs/2409.18986)

	Xiaoyu Wang, Haoyong Ouyang, Balu Bhasuran, Xiao Luo, Karim Hanna, Mia Liza A. Lustria, Carl Yang, Zhe He


# 2024-09-13
+ [Your Weak LLM is Secretly a Strong Teacher for Alignment](https://arxiv.org//abs/2409.08813)

	Leitian Tao, Yixuan Li

# 2024-09-10
+ [LaMsS: When Large Language Models Meet Self-Skepticism](https://arxiv.org//abs/2409.06601)

	Yetao Wu, Yihong Wang, Teng Chen, Ningyuan Xi, Qingqing Gu, Hongyang Lei, Luo Ji

# 2024-09-07
+ [Reward Guidance for Reinforcement Learning Tasks Based on Large Language Models: The LMGT Framework](https://arxiv.org//abs/2409.04744)

	Yongxin Deng, Xihe Qiu, Jue Chen, Xiaoyu Tan

# 2024-09-06
+ [From Calculation to Adjudication: Examining LLM judges on Mathematical Reasoning Tasks](https://arxiv.org//abs/2409.04168)

	Andreas Stephan, Dawei Zhu, Matthias Aßenmacher, Xiaoyu Shen, Benjamin Roth

# 2024-09-03
+ [Efficient LLM Context Distillation](https://arxiv.org//abs/2409.01930)

	Rajesh Upadhayayaya, Manish Raj Osti, Zachary Smith, Chritopher Kottmyer

# 2024-08-30
+ [Training Ultra Long Context Language Model with Fully Pipelined Distributed Transformer](https://arxiv.org//abs/2408.16978)

	Jinghan Yao, Sam Ade Jacobs, Masahiro Tanaka, Olatunji Ruwase, Hari Subramoni, Dhabaleswar K. Panda

# 2024-08-26
+ [CHARTOM: A Visual Theory-of-Mind Benchmark for Multimodal Large Language Models](https://arxiv.org//abs/2408.14419)

	Shubham Bharti, Shiyun Cheng, Jihyun Rho, Jianrui Zhang, Mu Cai, Yong Jae Lee, Martina Rau, Xiaojin Zhu

# 2024-08-19
+ [Kubrick: Multimodal Agent Collaborations for Synthetic Video Generation](https://arxiv.org//abs/2408.10453)

	Liu He, Yizhi Song, Hejun Huang, Pinxin Liu, Yunlong Tang, Daniel Aliaga, Xin Zhou

+ [Bridging the Language Gap: Enhancing Multilingual Prompt-Based Code Generation in LLMs via Zero-Shot Cross-Lingual Transfer](https://arxiv.org//abs/2408.09701)

	Mingda Li, Abhijit Mishra, Utkarsh Mujumdar

# 2024-08-13
+ [Bridging LLMs and KGs without Fine-Tuning: Intermediate Probing Meets Subgraph-Aware Entity Descriptions](https://arxiv.org//abs/2408.06787)

	Bo Xue, Yi Xu, Yunchong Song, Yiming Pang, Yuyang Ren, Jiaxin Ding, Luoyi Fu, Xinbing Wang

# 2024-08-09
+ [Order Matters in Hallucination: Reasoning Order as Benchmark and Reflexive Prompting for Large-Language-Models](https://arxiv.org//abs/2408.05093)

	Zikai Xie

# 2024-08-08
+ [The Struggles of LLMs in Cross-lingual Code Clone Detection](https://arxiv.org//abs/2408.04430)

	Micheline Bénédicte Moumoula, Abdoul Kader Kabore, Jacques Klein, Tegawendé Bissyande

# 2024-08-07
+ [A Logical Fallacy-Informed Framework for Argument Generation](https://arxiv.org//abs/2408.03618)

	Luca Mouchel, Debjit Paul, Shaobo Cui, Robert West, Antoine Bosselut, Boi Faltings

# 2024-08-02
+ [CFBench: A Comprehensive Constraints-Following Benchmark for LLMs](https://arxiv.org//abs/2408.01122)

	Tao Zhang, Chenglin Zhu, Yanjun Shen, Wenjing Luo, Yan Zhang, Hao Liang, Tao Zhang, Fan Yang, Mingan Lin, Yujing Qiao, Weipeng Chen, Bin Cui, Wentao Zhang, Zenan Zhou

# 2024-07-31
+ [Correcting Negative Bias in Large Language Models through Negative Attention Score Alignment](https://arxiv.org//abs/2408.00137)

	Sangwon Yu, Jongyoon Song, Bongkyu Hwang, Hoyoung Kang, Sooah Cho, Junhwa Choi, Seongho Joe, Taehee Lee, Youngjune L. Gwon, Sungroh Yoon

# 2024-07-26
+ [Patched MOA: optimizing inference for diverse software development tasks](https://arxiv.org//abs/2407.18521)

	Asankhaya Sharma

# 2024-07-23
+ [Patched RTC: evaluating LLMs for diverse software development tasks](https://arxiv.org//abs/2407.16557)

	Asankhaya Sharma

# 2024-07-21
+ [A Practical Analysis of Human Alignment with *PO](https://arxiv.org//abs/2407.15229)

	Kian Ahrabian, Xihui Lin, Barun Patra, Vishrav Chaudhary, Alon Benhaim, Jay Pujara, Xia Song

# 2024-07-16
+ [NeedleBench: Can LLMs Do Retrieval and Reasoning in Information-Dense Context?](https://arxiv.org//abs/2407.11963)

	Mo Li, Songyang Zhang, Taolin Zhang, Haodong Duan, Yunxin Liu, Kai Chen

# 2024-06-28
+ [Scaling Synthetic Data Creation with 1,000,000,000 Personas](https://arxiv.org//abs/2406.20094)

	Tao Ge, Xin Chan, Xiaoyang Wang, Dian Yu, Haitao Mi, Dong Yu

+ [LLMEasyQuant: Scalable Quantization for Parallel and Distributed LLM Inference](https://arxiv.org//abs/2406.19657)

	Dong Liu, Yanxuan Yu

# 2024-06-26
+ [Is In-Context Learning a Type of Error-Driven Learning? Evidence from the Inverse Frequency Effect in Structural Priming](https://arxiv.org//abs/2406.18501)

	Zhenghao Zhou, Robert Frank, R. Thomas McCoy

# 2024-06-25
+ [OPT-Tree: Speculative Decoding with Adaptive Draft Tree Structure](https://arxiv.org//abs/2406.17276)

	Jikai Wang, Yi Su, Juntao Li, Qingrong Xia, Zi Ye, Xinyu Duan, Zhefeng Wang, Min Zhang


+ [Recite, Reconstruct, Recollect: Memorization in LMs as a Multifaceted Phenomenon](https://arxiv.org//abs/2406.17746)

	USVSN Sai Prashanth, Alvin Deng, Kyle O'Brien, Jyothir S V, Mohammad Aflah Khan, Jaydeep Borkar, Christopher A. Choquette-Choo, Jacob Ray Fuehne, Stella Biderman, Tracy Ke, Katherine Lee, Naomi Saphra

+ [From Distributional to Overton Pluralism: Investigating Large Language Model Alignment](https://arxiv.org//abs/2406.17692)

	Thom Lake, Eunsol Choi, Greg Durrett

# 2024-06-20
+ [ReaL: Efficient RLHF Training of Large Language Models with Parameter Reallocation](https://arxiv.org//abs/2406.14088)

	Zhiyu Mei, Wei Fu, Kaiwei Li, Guangju Wang, Huanchen Zhang, Yi Wu

# 2024-06-15
+ [Unlocking Large Language Model's Planning Capabilities with Maximum Diversity Fine-tuning](https://arxiv.org//abs/2406.10479)

	Wenjun Li, Changyu Chen, Pradeep Varakantham

# 2024-06-14
+ [Recent Advances in Federated Learning Driven Large Language Models: A Survey on Architecture, Performance, and Security](https://arxiv.org//abs/2406.09831)

	Youyang Qu, Ming Liu, Tianqing Zhu, Longxiang Gao, Shui Yu, Wanlei Zhou

# 2024-06-13
+ [Talking Heads: Understanding Inter-layer Communication in Transformer Language Models](https://arxiv.org//abs/2406.09519)

	Jack Merullo, Carsten Eickhoff, Ellie Pavlick

# 2024-06-12
+ [Enhancing Differential Testing With LLMs For Testing Deep Learning Libraries](https://arxiv.org//abs/2406.07944)

	Meiziniu Li, Dongze Li, Jianmeng Liu, Jialun Cao, Yongqiang Tian, Shing-Chi Cheung

# 2024-06-03
+ [Re-ReST: Reflection-Reinforced Self-Training for Language Agents](https://arxiv.org//abs/2406.01495)

	Zi-Yi Dou, Cheng-Fu Yang, Xueqing Wu, Kai-Wei Chang, Nanyun Peng

# 2024-05-30
+ [Uncovering Bias in Large Vision-Language Models at Scale with Counterfactuals](https://arxiv.org//abs/2405.20152)

	Phillip Howard, Kathleen C. Fraser, Anahita Bhiwandiwalla, Svetlana Kiritchenko

# 2024-05-29
+ [Nearest Neighbor Speculative Decoding for LLM Generation and Attribution](https://arxiv.org//abs/2405.19325)

	Minghan Li, Xilun Chen, Ari Holtzman, Beidi Chen, Jimmy Lin, Wen-tau Yih, Xi Victoria Lin

# 2024-05-24
+ [Emergence of a High-Dimensional Abstraction Phase in Language Transformers](https://arxiv.org//abs/2405.15471)

	Emily Cheng, Diego Doimo, Corentin Kervadec, Iuri Macocco, Jade Yu, Alessandro Laio, Marco Baroni

# 2024-05-23
+ [OAC: Output-adaptive Calibration for Accurate Post-training Quantization](https://arxiv.org//abs/2405.15025)

	Ali Edalati, Alireza Ghaffari, Mahsa Ghazvini Nejad, Lu Hou, Boxing Chen, Masoud Asgharian, Vahid Partovi Nia

# 2024-05-20
+ [(Perhaps) Beyond Human Translation: Harnessing Multi-Agent Collaboration for Translating Ultra-Long Literary Texts](https://arxiv.org//abs/2405.11804)

	Minghao Wu, Jiahao Xu, Yulin Yuan, Gholamreza Haffari, Longyue Wang, Weihua Luo, Kaifu Zhang

# 2024-05-07
+ [QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving](https://arxiv.org//abs/2405.04532)

	Yujun Lin, Haotian Tang, Shang Yang, Zhekai Zhang, Guangxuan Xiao, Chuang Gan, Song Han

+ [Folded Context Condensation in Path Integral Formalism for Infinite Context Transformers](https://arxiv.org//abs/2405.04620)

	Won-Gi Paeng, Daesuk Kwon, Kyungwon Jeong, Honggyo Suh

+ [Fleet of Agents: Coordinated Problem Solving with Large Language Models](https://arxiv.org//abs/2405.06691)

	Lars Klein, Nearchos Potamitis, Roland Aydin, Robert West, Caglar Gulcehre, Akhil Arora

# 2024-05-06
+ [Outlier Gradient Analysis: Efficiently Identifying Detrimental Training Samples for Deep Learning Models](https://arxiv.org//abs/2405.03869)

	Anshuman Chhabra, Bo Li, Jian Chen, Prasant Mohapatra, Hongfu Liu

# 2024-04-26
+ [Large Language Model Agent as a Mechanical Designer](https://arxiv.org//abs/2404.17525)

	Yayati Jadhav, Amir Barati Farimani

# 2024-04-18
+ [Lean Copilot: Large Language Models as Copilots for Theorem Proving in Lean](https://arxiv.org//abs/2404.12534)

	Peiyang Song, Kaiyu Yang, Anima Anandkumar

# 2024-04-06
+ [Multilingual Brain Surgeon: Large Language Models Can be Compressed Leaving No Language Behind](https://arxiv.org//abs/2404.04748)

	Hongchuan Zeng, Hongshen Xu, Lu Chen, Kai Yu

# 2024-04-04
+ [PRobELM: Plausibility Ranking Evaluation for Language Models](https://arxiv.org//abs/2404.03818)

	Zhangdie Yuan, Eric Chamoun, Rami Aly, Chenxi Whitehouse, Andreas Vlachos

# 2024-03-31
+ [ParaICL: Towards Parallel In-Context Learning](https://arxiv.org//abs/2404.00570)

	Xingxuan Li, Xuan-Phi Nguyen, Shafiq Joty, Lidong Bing

# 2024-03-28
+ [Large Language Models Are Struggle to Cope with Unreasonability in Math Problems](https://arxiv.org//abs/2403.19346)

	Jingyuan Ma, Damai Dai, Zihang Yuan, Rui li, Weilin Luo, Bin Wang, Qun Liu, Lei Sha, Zhifang Sui

# 2024-03-25
+ [AIOS: LLM Agent Operating System](https://arxiv.org//abs/2403.16971)

	Kai Mei, Xi Zhu, Wujiang Xu, Wenyue Hua, Mingyu Jin, Zelong Li, Shuyuan Xu, Ruosong Ye, Yingqiang Ge, Yongfeng Zhang

# 2024-03-21
+ [Agentic AI: The Era of Semantic Decoding](https://arxiv.org//abs/2403.14562)

	Maxime Peyrard, Martin Josifoski, Robert West

# 2024-03-19
+ [To Help or Not to Help: LLM-based Attentive Support for Human-Robot Group Interactions](https://arxiv.org//abs/2403.12533)

	Daniel Tanneberg, Felix Ocker, Stephan Hasler, Joerg Deigmoeller, Anna Belardinelli, Chao Wang, Heiko Wersing, Bernhard Sendhoff, Michael Gienger

# 2024-03-04
+ [DECIDER: A Dual-System Rule-Controllable Decoding Framework for Language Generation](https://arxiv.org//abs/2403.01954)

	Chen Xu, Tian Lan, Yu Ji, Changlong Yu, Wei Wang, Jun Gao, Qunxi Dong, Kun Qian, Piji Li, Wei Bi, Bin Hu

# 2024-02-29
+ [LoRATK: LoRA Once, Backdoor Everywhere in the Share-and-Play Ecosystem](https://arxiv.org//abs/2403.00108)

	Hongyi Liu, Shaochen Zhong, Xintong Sun, Minghao Tian, Mohsen Hariri, Zirui Liu, Ruixiang Tang, Zhimeng Jiang, Jiayi Yuan, Yu-Neng Chuang, Li Li, Soo-Hyun Choi, Rui Chen, Vipin Chaudhary, Xia Hu

+ [FlexLLM: A System for Co-Serving Large Language Model Inference and Parameter-Efficient Finetuning](https://arxiv.org//abs/2402.18789)

	Gabriele Oliaro, Xupeng Miao, Xinhao Cheng, Vineeth Kada, Ruohan Gao, Yingyi Huang, Remi Delacourt, April Yang, Yingcheng Wang, Mengdi Wu, Colin Unger, Zhihao Jia

# 2024-02-21
+ [Round Trip Translation Defence against Large Language Model Jailbreaking Attacks](https://arxiv.org//abs/2402.13517)

	Canaan Yung, Hadi Mohaghegh Dolatabadi, Sarah Erfani, Christopher Leckie

# 2024-02-13
+ ["Reasoning" with Rhetoric: On the Style-Evidence Tradeoff in LLM-Generated Counter-Arguments](https://arxiv.org//abs/2402.08498)

	Preetika Verma, Kokil Jaidka, Svetlana Churina

# 2024-02-10
+ [Fiddler: CPU-GPU Orchestration for Fast Inference of Mixture-of-Experts Models](https://arxiv.org//abs/2402.07033)

	Keisuke Kamahori, Tian Tang, Yile Gu, Kan Zhu, Baris Kasikci

# 2024-02-05
+ [LLM Multi-Agent Systems: Challenges and Open Problems](https://arxiv.org//abs/2402.03578)

	Shanshan Han, Qifan Zhang, Yuhang Yao, Weizhao Jin, Zhaozhuo Xu

# 2024-02-02
+ [Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach](https://arxiv.org//abs/2402.01454)

	Masayuki Takayama, Tadahisa Okuda, Thong Pham, Tatsuyoshi Ikenoue, Shingo Fukuma, Shohei Shimizu, Akiyoshi Sannai

# 2024-01-30
+ [Incoherent Probability Judgments in Large Language Models](https://arxiv.org//abs/2401.16646)

	Jian-Qiao Zhu, Thomas L. Griffiths

# 2023-11-30
+ [RaDialog: A Large Vision-Language Model for Radiology Report Generation and Conversational Assistance](https://arxiv.org//abs/2311.18681)

	Chantal Pellegrini, Ege Özsoy, Benjamin Busam, Nassir Navab, Matthias Keicher

# 2023-11-16
+ [Automating the Generation of Prompts for LLM-based Action Choice in PDDL Planning](https://arxiv.org//abs/2311.09830)

	Katharina Stein, Daniel Fišer, Jörg Hoffmann, Alexander Koller

# 2023-10-20
+ [Towards Understanding Sycophancy in Language Models](https://arxiv.org//abs/2310.13548)

	Mrinank Sharma, Meg Tong, Tomasz Korbak, David Duvenaud, Amanda Askell, Samuel R. Bowman, Newton Cheng, Esin Durmus, Zac Hatfield-Dodds, Scott R. Johnston, Shauna Kravec, Timothy Maxwell, Sam McCandlish, Kamal Ndousse, Oliver Rausch, Nicholas Schiefer, Da Yan, Miranda Zhang, Ethan Perez

# 2023-10-11
+ [CoPAL: Corrective Planning of Robot Actions with Large Language Models](https://arxiv.org//abs/2310.07263)

	Frank Joublin, Antonello Ceravola, Pavel Smirnov, Felix Ocker, Joerg Deigmoeller, Anna Belardinelli, Chao Wang, Stephan Hasler, Daniel Tanneberg, Michael Gienger


# 2023-10-07
+ [Uncovering Model Processing Strategies with Non-Negative Per-Example Fisher Factorization](https://arxiv.org//abs/2310.04649)

	Michael Matena, Colin Raffel

# 2023-10-05
+ [LLM-Coordination: Evaluating and Analyzing Multi-agent Coordination Abilities in Large Language Models](https://arxiv.org//abs/2310.03903)

	Saaket Agashe, Yue Fan, Anthony Reyna, Xin Eric Wang

# 2023-09-15
+ [EvoPrompt: Connecting LLMs with Evolutionary Algorithms Yields Powerful Prompt Optimizers](https://arxiv.org//abs/2309.08532)

	Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song, Xu Tan, Guoqing Liu, Jiang Bian, Yujiu Yang

# 2023-08-29
+ [Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models](https://arxiv.org//abs/2308.15022)

	Qingyue Wang, Yanhe Fu, Yanan Cao, Shuai Wang, Zhiliang Tian, Liang Ding

# 2023-08-17
+ [Semantic Consistency for Assuring Reliability of Large Language Models](https://arxiv.org//abs/2308.09138)

	Harsh Raj, Vipul Gupta, Domenic Rosati, Subhabrata Majumdar

# 2023-05-26
+ [Playing repeated games with Large Language Models](https://arxiv.org//abs/2305.16867)

	Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, Eric Schulz

# 2023-03-03
+ [Prophet: Prompting Large Language Models with Complementary Answer Heuristics for Knowledge-based Visual Question Answering](https://arxiv.org//abs/2303.01903)

	Zhou Yu, Xuecheng Ouyang, Zhenwei Shao, Meng Wang, Jun Yu

# 2023-01-11
+ [Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability](https://arxiv.org//abs/2301.04709)

	Atticus Geiger, Duligur Ibeling, Amir Zur, Maheep Chaudhary, Sonakshi Chauhan, Jing Huang, Aryaman Arora, Zhengxuan Wu, Noah Goodman, Christopher Potts, Thomas Icard

