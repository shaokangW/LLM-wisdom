# LLM-wisdom
The papers related to the LLM wisdom, including test-time scaling, knowledge editing, model recognition, capacity enhancement, RAG, Agent, internal mechanism of LLM and etc. 

# 2025-05-19
+ [Bullying the Machine: How Personas Increase LLM Vulnerability](https://arxiv.org//abs/2505.12692)

	Ziwei Xu, Udit Sanghi, Mohan Kankanhalli

+ [Accelerating Adaptive Retrieval Augmented Generation via Instruction-Driven Representation Reduction of Retrieval Overlaps](https://arxiv.org//abs/2505.12731)

	Jie Ou, Jinyu Guo, Shuaihong Jiang, Zhaokun Wang, Libo Qin, Shunyu Yao, Wenhong Tian

+ [Dense Communication between Language Models](https://arxiv.org//abs/2505.12741)

	Shiguang Wu, Yaqing Wang, Quanming Yao

+ [IDEAL: Data Equilibrium Adaptation for Multi-Capability Language Model Alignment](https://arxiv.org//abs/2505.12762)

	Chenlin Ming, Chendi Qu, Mengzhang Cai, Qizhi Pei, Zhuoshi Pan, Yu Li, Xiaoming Duan, Lijun Wu, Conghui He

+ [Language Models That Walk the Talk: A Framework for Formal Fairness Certificates](https://arxiv.org//abs/2505.12767)

	Danqing Chen, Tobias Ladner, Ahmed Rayen Mhadhbi, Matthias Althoff

+ [FRAbench and GenEval: Scaling Fine-Grained Aspect Evaluation across Tasks, Modalities](https://arxiv.org//abs/2505.12795)

	Shibo Hong, Jiahao Ying, Haiyuan Liang, Mengdi Zhang, Jun Kuang, Jiazheng Zhang, Yixin Cao

+ [Emergent Specialization: Rare Token Neurons in Language Models](https://arxiv.org//abs/2505.12822)

	Jing Liu, Haozheng Wang, Yueheng Li

+ [Reasoning BO: Enhancing Bayesian Optimization with Long-Context Reasoning Power of LLMs](https://arxiv.org//abs/2505.12833)

	Zhuo Yang, Lingli Ge, Dong Han, Tianfan Fu, Yuqiang Li

+ [Multi-Level Aware Preference Learning: Enhancing RLHF for Complex Multi-Instruction Tasks](https://arxiv.org//abs/2505.12845)

	Ruopei Sun, Jianfeng Cai, Jinhua Zhu, Kangwen Zhao, Dongyun Xue, Wengang Zhou, Li Li, Houqiang Li

+ [Detection and Mitigation of Hallucination in Large Reasoning Models: A Mechanistic Perspective](https://arxiv.org//abs/2505.12886)

	Zhongxiang Sun, Qipeng Wang, Haoyu Wang, Xiao Zhang, Jun Xu

+ [TIME: A Multi-level Benchmark for Temporal Reasoning of LLMs in Real-World Scenarios](https://arxiv.org//abs/2505.12891)

	Shaohang Wei, Wei Li, Feifan Song, Wen Luo, Tianyi Zhuang, Haochen Tan, Zhijiang Guo, Houfeng Wang

+ [The Traitors: Deception and Trust in Multi-Agent Language Model Simulations](https://arxiv.org//abs/2505.12923)

	Pedro M. P. Curvo

+ [CAIM: Development and Evaluation of a Cognitive AI Memory Framework for Long-Term Interaction with Intelligent Agents](https://arxiv.org//abs/2505.13044)

	Rebecca Westhäußer, Frederik Berenz, Wolfgang Minker, Sebastian Zepf

+ [LLM-KG-Bench 3.0: A Compass for SemanticTechnology Capabilities in the Ocean of LLMs](https://arxiv.org//abs/2505.13098)

	Lars-Peter Meyer, Johannes Frey, Desiree Heim, Felix Brei, Claus Stadler, Kurt Junghanns, Michael Martin

+ [Zero-Shot Iterative Formalization and Planning in Partially Observable Environments](https://arxiv.org//abs/2505.13126)

	Liancheng Gong, Wang Zhu, Jesse Thomason, Li Zhang

+ [Adversarial Testing in LLMs: Insights into Decision-Making Vulnerabilities](https://arxiv.org//abs/2505.13195)

	Lili Zhang, Haomiaomiao Wang, Long Cheng, Libao Deng, Tomas Ward

+ [Agentic Publications: An LLM-Driven Framework for Interactive Scientific Publishing, Supplementing Traditional Papers with AI-Powered Knowledge Systems](https://arxiv.org//abs/2505.13246)

	Roberto Pugliese, George Kourousias, Francesco Venier, Grazia Garlatti Costa

+ [Multi-Armed Bandits Meet Large Language Models](https://arxiv.org//abs/2505.13355)

	Djallel Bouneffouf, Raphael Feraud

+ [CompeteSMoE -- Statistically Guaranteed Mixture of Experts Training via Competition](https://arxiv.org//abs/2505.13380)

	Nam V. Nguyen, Huy Nguyen, Quang Pham, Van Nguyen, Savitha Ramasamy, Nhat Ho

+ [AutoMathKG: The automated mathematical knowledge graph based on LLM and vector database](https://arxiv.org//abs/2505.13406)

	Rong Bian, Yu Geng, Zijian Yang, Bing Cheng

+ [CoT-Kinetics: A Theoretical Modeling Assessing LRM Reasoning Process](https://arxiv.org//abs/2505.13408)

	Jinhe Bi, Danqi Yan, Yifan Wang, Wenke Huang, Haokun Chen, Guancheng Wan, Mang Ye, Xun Xiao, Hinrich Schuetze, Volker Tresp, Yunpu Ma

+ [MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable Step-Level Supervision](https://arxiv.org//abs/2505.13427)

	Lingxiao Du, Fanqing Meng, Zongkai Liu, Zhixiang Zhou, Ping Luo, Qiaosheng Zhang, Wenqi Shao

+ [Trust, But Verify: A Self-Verification Approach to Reinforcement Learning with Verifiable Rewards](https://arxiv.org//abs/2505.13445)

	Xiaoyuan Liu, Tian Liang, Zhiwei He, Jiahao Xu, Wenxuan Wang, Pinjia He, Zhaopeng Tu, Haitao Mi, Dong Yu

+ [AD-AGENT: A Multi-agent Framework for End-to-end Anomaly Detection](https://arxiv.org//abs/2505.12594)

	Tiankai Yang, Junjun Liu, Wingchun Siu, Jiahang Wang, Zhuangzhuang Qian, Chanjuan Song, Cheng Cheng, Xiyang Hu, Yue Zhao

+ [Web IP at Risk: Prevent Unauthorized Real-Time Retrieval by Large Language Models](https://arxiv.org//abs/2505.12655)

	Yisheng Zhong, Yizhu Wen, Junfeng Guo, Mehran Kafai, Heng Huang, Hanqing Guo, Zhuangdi Zhu

+ [Know3-RAG: A Knowledge-aware RAG Framework with Adaptive Retrieval, Generation, and Filtering](https://arxiv.org//abs/2505.12662)

	Xukai Liu, Ye Liu, Shiwen Wu, Yanghai Zhang, Yihao Yuan, Kai Zhang, Qi Liu

+ [Shadow-FT: Tuning Instruct via Base](https://arxiv.org//abs/2505.12716)

	Taiqiang Wu, Runming Yang, Jiayi Li, Pengfei Hu, Ngai Wong, Yujiu Yang

+ [Rethinking Reward Model Evaluation Through the Lens of Reward Overoptimization](https://arxiv.org//abs/2505.12763)

	Sunghwan Kim, Dongjin Kang, Taeyoon Kwon, Hyungjoo Chae, Dongha Lee, Jinyoung Yeo

+ [A Token is Worth over 1,000 Tokens: Efficient Knowledge Distillation through Low-Rank Clone](https://arxiv.org//abs/2505.12781)

	Jitai Hao, Qiang Huang, Hao Liu, Xinyan Xiao, Zhaochun Ren, Jun Yu

+ [PsyMem: Fine-grained psychological alignment and Explicit Memory Control for Advanced Role-Playing LLMs](https://arxiv.org//abs/2505.12814)

	Xilong Cheng, Yunxiao Qin, Yuting Tan, Zhengnan Li, Ye Wang, Hongjiang Xiao, Yuan Zhang

+ [The Hidden Structure -- Improving Legal Document Understanding Through Explicit Text Formatting](https://arxiv.org//abs/2505.12837)

	Christian Braun, Alexander Lilienbeck, Daniel Mentjukov

+ [Bias Fitting to Mitigate Length Bias of Reward Model in RLHF](https://arxiv.org//abs/2505.12843)

	Kangwen Zhao, Jianfeng Cai, Jinhua Zhu, Ruopei Sun, Dongyun Xue, Wengang Zhou, Li Li, Houqiang Li

+ [LEXam: Benchmarking Legal Reasoning on 340 Law Exams](https://arxiv.org//abs/2505.12864)

	Yu Fan, Jingwei Ni, Jakob Merane, Etienne Salimbeni, Yang Tian, Yoan Hermstrüwer, Yinya Huang, Mubashara Akhtar, Florian Geering, Oliver Dreyer, Daniel Brunner, Markus Leippold, Mrinmaya Sachan, Alexander Stremitzer, Christoph Engel, Elliott Ash, Joel Niklaus

+ [Does Low Rank Adaptation Lead to Lower Robustness against Training-Time Attacks?](https://arxiv.org//abs/2505.12871)

	Zi Liang, Haibo Hu, Qingqing Ye, Yaxin Xiao, Ronghua Li

+ [Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs](https://arxiv.org//abs/2505.12929)

	Zhihe Yang, Xufang Luo, Zilong Wang, Dongqi Han, Zhiyuan He, Dongsheng Li, Yunjian Xu

+ [Leveraging LLM Inconsistency to Boost Pass@k Performance](https://arxiv.org//abs/2505.12938)

	Uri Dalal, Meirav Segal, Zvika Ben-Haim, Dan Lahav, Omer Nevo

+ [A3 : an Analytical Low-Rank Approximation Framework for Attention](https://arxiv.org//abs/2505.12942)

	Jeffrey T. H. Wong, Cheng Zhang, Xinye Cao, Pedro Gimenes, George A. Constantinides, Wayne Luk, Yiren Zhao

+ [DGRO: Enhancing LLM Reasoning via Exploration-Exploitation Control and Reward Variance Management](https://arxiv.org//abs/2505.12951)

	Xuerui Su, Liya Guo, Yue Wang, Yi Zhu, Zhiming Ma, Zun Wang, Yuting Liu

+ [From Assistants to Adversaries: Exploring the Security Risks of Mobile LLM Agents](https://arxiv.org//abs/2505.12981)

	Liangxuan Wu, Chao Wang, Tianming Liu, Yanjie Zhao, Haoyu Wang

+ [Fractured Chain-of-Thought Reasoning](https://arxiv.org//abs/2505.12992)

	Baohao Liao, Hanze Dong, Yuhui Xu, Doyen Sahoo, Christof Monz, Junnan Li, Caiming Xiong

+ [Step-wise Adaptive Integration of Supervised Fine-tuning and Reinforcement Learning for Task-Specific LLMs](https://arxiv.org//abs/2505.13026)

	Jack Chen, Fazhong Liu, Naruto Liu, Yuhan Luo, Erqu Qin, Harry Zheng, Tian Dong, Haojin Zhu, Yan Meng, Xiao Wang

+ [Evaluatiing the efficacy of LLM Safety Solutions : The Palit Benchmark Dataset](https://arxiv.org//abs/2505.13028)

	Sayon Palit, Daniel Woods

+ [KIT's Offline Speech Translation and Instruction Following Submission for IWSLT 2025](https://arxiv.org//abs/2505.13036)

	Sai Koneru, Maike Züfle, Thai-Binh Nguyen, Seymanur Akti, Jan Niehues, Alexander Waibel

+ [The Hidden Dangers of Browsing AI Agents](https://arxiv.org//abs/2505.13076)

	Mykyta Mudryi, Markiyan Chaklosh, Grzegorz Wójcik

+ [FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference](https://arxiv.org//abs/2505.13109)

	Guangda Liu, Chengwei Li, Zhenyu Ning, Jing Lin, Yiwu Yao, Danning Ke, Minyi Guo, Jieru Zhao

+ [Role-Playing Evaluation for Large Language Models](https://arxiv.org//abs/2505.13157)

	Yassine El Boudouri, Walter Nuninger, Julian Alvarez, Yvan Peter

+ [ToolSpectrum : Towards Personalized Tool Utilization for Large Language Models](https://arxiv.org//abs/2505.13176)

	Zihao Cheng, Hongru Wang, Zeming Liu, Yuhang Guo, Yuanfang Guo, Yunhong Wang, Haifeng Wang

+ [WikiPersonas: What Can We Learn From Personalized Alignment to Famous People?](https://arxiv.org//abs/2505.13257)

	Zilu Tang, Afra Feyza Akyürek, Ekin Akyürek, Derry Wijaya

+ [Cross-Cloud Data Privacy Protection: Optimizing Collaborative Mechanisms of AI Systems by Integrating Federated Learning and LLMs](https://arxiv.org//abs/2505.13292)

	Huaiying Luo, Cheng Ji

+ [RBF++: Quantifying and Optimizing Reasoning Boundaries across Measurable and Unmeasurable Capabilities for Chain-of-Thought Reasoning](https://arxiv.org//abs/2505.13307)

	Qiguang Chen, Libo Qin, Jinhao Liu, Yue Liao, Jiaqi Wang, Jingxuan Zhou, Wanxiang Che

+ [Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space](https://arxiv.org//abs/2505.13308)

	Hengli Li, Chenxi Li, Tong Wu, Xuekai Zhu, Yuxuan Wang, Zhaoxin Yu, Eric Hanchen Jiang, Song-Chun Zhu, Zixia Jia, Ying Nian Wu, Zilong Zheng

+ [Contextual Paralinguistic Data Creation for Multi-Modal Speech-LLM: Data Condensation and Spoken QA Generation](https://arxiv.org//abs/2505.13338)

	Qiongqiong Wang, Hardik B. Sailor, Tianchi Liu, Ai Ti Aw

+ [J4R: Learning to Judge with Equivalent Initial State Group Relative Preference Optimization](https://arxiv.org//abs/2505.13346)

	Austin Xu, Yilun Zhou, Xuan-Phi Nguyen, Caiming Xiong, Shafiq Joty

+ [Thinkless: LLM Learns When to Think](https://arxiv.org//abs/2505.13379)

	Gongfan Fang, Xinyin Ma, Xinchao Wang

+ [R3: Robust Rubric-Agnostic Reward Models](https://arxiv.org//abs/2505.13388)

	David Anugraha, Zilu Tang, Lester James V. Miranda, Hanyang Zhao, Mohammad Rifqi Farhansyah, Garry Kuwanto, Derry Wijaya, Genta Indra Winata

+ [AdaptThink: Reasoning Models Can Learn When to Think](https://arxiv.org//abs/2505.13417)

	Jiajie Zhang, Nianyi Lin, Lei Hou, Ling Feng, Juanzi Li

+ [Learnware of Language Models: Specialized Small Language Models Can Do Big](https://arxiv.org//abs/2505.13425)

	Zhi-Hao Tan, Zi-Chen Zhao, Hao-Yu Shi, Xin-Yu Zhang, Peng Tan, Yang Yu, Zhi-Hua Zhou

+ [Optimizing Anytime Reasoning via Budget Relative Policy Optimization](https://arxiv.org//abs/2505.13438)

	Penghui Qi, Zichen Liu, Tianyu Pang, Chao Du, Wee Sun Lee, Min Lin

+ [CIE: Controlling Language Model Text Generations Using Continuous Signals](https://arxiv.org//abs/2505.13448)

	Vinay Samuel, Harshita Diddee, Yiming Zhang, Daphne Ippolito

+ [Improving Multilingual Language Models by Aligning Representations through Steering](https://arxiv.org//abs/2505.12584)

	Omar Mahmoud, Buddhika Laknath Semage, Thommen George Karimpanal, Santu Rana

+ [PromptPrism: A Linguistically-Inspired Taxonomy for Prompts](https://arxiv.org//abs/2505.12592)

	Sullam Jeoung, Yueyan Chen, Yi Zhang, Shuai Wang, Haibo Ding, Lin Lee Cheong

+ [Think Before You Attribute: Improving the Performance of LLMs Attribution Systems](https://arxiv.org//abs/2505.12621)

	João Eduardo Batista, Emil Vatai, Mohamed Wahib

+ [R1dacted: Investigating Local Censorship in DeepSeek's R1 Language Model](https://arxiv.org//abs/2505.12625)

	Ali Naseh, Harsh Chaudhari, Jaechul Roh, Mingshi Wu, Alina Oprea, Amir Houmansadr

+ [Revealing the Deceptiveness of Knowledge Editing: A Mechanistic Analysis of Superficial Editing](https://arxiv.org//abs/2505.12636)

	Jiakuan Xie, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao

+ [ToTRL: Unlock LLM Tree-of-Thoughts Reasoning Potential through Puzzles Solving](https://arxiv.org//abs/2505.12717)

	Haoyuan Wu, Xueyi Chen, Rui Ming, Jilong Gao, Shoubo Hu, Zhuolun He, Bei Yu

+ [Automated Bias Assessment in AI-Generated Educational Content Using CEAT Framework](https://arxiv.org//abs/2505.12718)

	Jingyang Peng, Wenyuan Shen, Jiarui Rao, Jionghao Lin

+ [ReEx-SQL: Reasoning with Execution-Aware Reinforcement Learning for Text-to-SQL](https://arxiv.org//abs/2505.12768)

	Yaxun Dai (1), Wenxuan Xie (3), Xialie Zhuang (4), Tianyu Yang (5), Yiying Yang (2), Haiqin Yang (6), Yuhang Zhao (2), Pingfu Chao (1), Wenhao Jiang (2) ((1) Soochow University, (2) Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), (3) South China University of Technology, (4) University of Chinese Academy of Sciences, (5) Alibaba DAMO Academy, (6) International Digital Economy Academy (IDEA))

+ [EAVIT: Efficient and Accurate Human Value Identification from Text data via LLMs](https://arxiv.org//abs/2505.12792)

	Wenhao Zhu, Yuhang Xie, Guojie Song, Xin Zhang

+ [Decentralized Arena: Towards Democratic and Scalable Automatic Evaluation of Language Models](https://arxiv.org//abs/2505.12808)

	Yanbin Yin, Kun Zhou, Zhen Wang, Xiangdong Zhang, Yifei Shao, Shibo Hao, Yi Gu, Jieyuan Liu, Somanshu Singla, Tianyang Liu, Eric P. Xing, Zhengzhong Liu, Haojian Jin, Zhiting Hu

+ [Contrastive Prompting Enhances Sentence Embeddings in LLMs through Inference-Time Steering](https://arxiv.org//abs/2505.12831)

	Zifeng Cheng, Zhonghui Wang, Yuchen Fu, Zhiwei Jiang, Yafeng Yin, Cong Wang, Qing Gu

+ [Re-identification of De-identified Documents with Autoregressive Infilling](https://arxiv.org//abs/2505.12859)

	Lucas Georges Gabriel Charpentier, Pierre Lison

+ [On the Thinking-Language Modeling Gap in Large Language Models](https://arxiv.org//abs/2505.12896)

	Chenxi Liu, Yongqiang Chen, Tongliang Liu, James Cheng, Bo Han, Kun Zhang

+ [GuRE:Generative Query REwriter for Legal Passage Retrieval](https://arxiv.org//abs/2505.12950)

	Daehee Kim, Deokhyung Kang, Jonghwi Kim, Sangwon Ryu, Gary Geunbae Lee

+ [Evaluating the Performance of RAG Methods for Conversational AI in the Airport Domain](https://arxiv.org//abs/2505.13006)

	Yuyang Li, Philip J.M. Kerbusch, Raimon H.R. Pruim, Tobias Käfer

+ [Systematic Generalization in Language Models Scales with Information Entropy](https://arxiv.org//abs/2505.13089)

	Sondre Wold, Lucas Georges Gabriel Charpentier, Étienne Simon

+ [Understanding Cross-Lingual Inconsistency in Large Language Models](https://arxiv.org//abs/2505.13141)

	Zheng Wei Lim, Alham Fikri Aji, Trevor Cohn

+ [Positional Fragility in LLMs: How Offset Effects Reshape Our Understanding of Memorization Risks](https://arxiv.org//abs/2505.13171)

	Yixuan Xu, Antoine Bosselut, Imanol Schlag

+ [A Case Study of Cross-Lingual Zero-Shot Generalization for Classical Languages in LLMs](https://arxiv.org//abs/2505.13173)

	V.S.D.S.Mahesh Akavarapu, Hrishikesh Terdalkar, Pramit Bhattacharyya, Shubhangi Agarwal, Vishakha Deulgaonkar, Pralay Manna, Chaitali Dangarikar, Arnab Bhattacharya

+ [Alignment-Augmented Speculative Decoding with Alignment Sampling and Conditional Verification](https://arxiv.org//abs/2505.13204)

	Jikai Wang, Zhenxu Tian, Juntao Li, Qingrong Xia, Xinyu Duan, Zhefeng Wang, Baoxing Huai, Min Zhang

+ [Natural Language Planning via Coding and Inference Scaling](https://arxiv.org//abs/2505.13252)

	Rikhil Amonkar, Ronan Le Bras, Li Zhang

+ [HeteroSpec: Leveraging Contextual Heterogeneity for Efficient Speculative Decoding](https://arxiv.org//abs/2505.13254)

	Siran Liu, Yang Ye, Qianchao Zhu, Zheng Cao, Yongchao He

+ [Effective and Transparent RAG: Adaptive-Reward Reinforcement Learning for Decision Traceability](https://arxiv.org//abs/2505.13258)

	Jingyi Ren, Yekun Xu, Xiaolong Wang, Weitao Li, Weizhi Ma, Yang Liu

+ [CSC-SQL: Corrective Self-Consistency in Text-to-SQL via Reinforcement Learning](https://arxiv.org//abs/2505.13271)

	Lei Sheng, Shuai-Shuai Xu

+ [GUARD: Generation-time LLM Unlearning via Adaptive Restriction and Detection](https://arxiv.org//abs/2505.13312)

	Zhijie Deng, Chris Yuhao Liu, Zirui Pang, Xinlei He, Lei Feng, Qi Xuan, Zhaowei Zhu, Jiaheng Wei

+ [Rethinking Stateful Tool Use in Multi-Turn Dialogues: Benchmarks and Challenges](https://arxiv.org//abs/2505.13328)

	Hongru Wang, Wenyu Huang, Yufei Wang, Yuanhao Xi, Jianqiao Lu, Huan Zhang, Nan Hu, Zeming Liu, Jeff Z. Pan, Kam-Fai Wong

+ [Investigating the Vulnerability of LLM-as-a-Judge Architectures to Prompt-Injection Attacks](https://arxiv.org//abs/2505.13348)

	Narek Maloyan, Bislan Ashinov, Dmitry Namiot

+ [Sense and Sensitivity: Examining the Influence of Semantic Recall on Long Context Code Reasoning](https://arxiv.org//abs/2505.13353)

	Adam Štorek, Mukur Gupta, Samira Hajizadeh, Prashast Srivastava, Suman Jana

+ [What Prompts Don't Say: Understanding and Managing Underspecification in LLM Prompts](https://arxiv.org//abs/2505.13360)

	Chenyang Yang, Yike Shi, Qianou Ma, Michael Xieyang Liu, Christian Kästner, Tongshuang Wu

+ [MR. Judge: Multimodal Reasoner as a Judge](https://arxiv.org//abs/2505.13403)

	Renjie Pi, Felix Bai, Qibin Chen, Simon Wang, Jiulong Shan, Kieran Liu, Meng Cao

+ [Dementia Through Different Eyes: Explainable Modeling of Human and LLM Perceptions for Early Awareness](https://arxiv.org//abs/2505.13418)

	Lotem Peled-Cohen, Maya Zadok, Nitay Calderon, Hila Gonen, Roi Reichart

+ [SMOTExT: SMOTE meets Large Language Models](https://arxiv.org//abs/2505.13434)

	Mateusz Bystroński, Mikołaj Hołysz, Grzegorz Piotrowski, Nitesh V. Chawla, Tomasz Kajdanowicz

+ [Enhancing Latent Computation in Transformers with Latent Tokens](https://arxiv.org//abs/2505.12629)

	Yuchang Sun, Yanxi Chen, Yaliang Li, Bolin Ding

+ [GEM: Gaussian Embedding Modeling for Out-of-Distribution Detection in GUI Agents](https://arxiv.org//abs/2505.12842)

	Zheng Wu, Pengzhou Cheng, Zongru Wu, Lingzhong Dong, Zhuosheng Zhang

+ [BusterX: MLLM-Powered AI-Generated Video Forgery Detection and Explanation](https://arxiv.org//abs/2505.12620)

	Haiquan Wen, Yiwei He, Zhenglin Huang, Tianxiao Li, Zihan YU, Xingru Huang, Lu Qi, Baoyuan Wu, Xiangtai Li, Guangliang Cheng

+ [Mitigating Hallucination in VideoLLMs via Temporal-Aware Activation Engineering](https://arxiv.org//abs/2505.12826)

	Jianfeng Cai, Wengang Zhou, Zongmeng Zhang, Jiale Hong, Nianji Zhan, Houqiang Li

+ [Walking the Tightrope: Disentangling Beneficial and Detrimental Drifts in Non-Stationary Custom-Tuning](https://arxiv.org//abs/2505.13081)

	Xiaoyu Yang, Jie Lu, En Yu

+ [Rethinking Predictive Modeling for LLM Routing: When Simple kNN Beats Complex Learned Routers](https://arxiv.org//abs/2505.12601)

	Yang Li

+ [RoFL: Robust Fingerprinting of Language Models](https://arxiv.org//abs/2505.12682)

	Yun-Yun Tsai, Chuan Guo, Junfeng Yang, Laurens van der Maaten

+ [Koopman Autoencoders Learn Neural Representation Dynamics](https://arxiv.org//abs/2505.12809)

	Nishant Suresh Aswani, Saif Eddin Jabari

+ [Unpacking Positional Encoding in Transformers: A Spectral Analysis of Content-Position Coupling](https://arxiv.org//abs/2505.13027)

	Zihan Gu, Han Zhang, Ruoyu Chen, Yue Hu, Hua Zhang

+ [Why Knowledge Distillation Works in Generative Models: A Minimal Working Explanation](https://arxiv.org//abs/2505.13111)

	Sungmin Cha, Kyunghyun Cho

+ [RN-F: A Novel Approach for Mitigating Contaminated Data in Large Language Models](https://arxiv.org//abs/2505.13249)

	Le Vu Anh, Dinh Duc Nha Nguyen, Phi Long Nguyen

+ [Thinking Short and Right Over Thinking Long: Serving LLM Reasoning Efficiently and Accurately](https://arxiv.org//abs/2505.13326)

	Yuhang Wang, Youhe Jiang, Bin Cui, Fangcheng Fu

+ [Occult: Optimizing Collaborative Communication across Experts for Accelerated Parallel MoE Training and Inference](https://arxiv.org//abs/2505.13345)

	Shuqing Luo, Pingzhi Li, Jie Peng, Hanrui Wang, Yang (Katie)Zhao, Yu (Kevin)Cao, Yu Cheng, Tianlong Chen

+ [DynaNoise: Dynamic Probabilistic Noise Injection for Defending Against Membership Inference Attacks](https://arxiv.org//abs/2505.13362)

	Javad Forough, Hamed Haddadi

# 2025-05-18
+ [Mitigating Content Effects on Reasoning in Language Models through Fine-Grained Activation Steering](https://arxiv.org//abs/2505.12189)

	Marco Valentino, Geonhee Kim, Dhairya Dalal, Zhixue Zhao, André Freitas

+ [Beyond Single-Point Judgment: Distribution Alignment for LLM-as-a-Judge](https://arxiv.org//abs/2505.12301)

	Luyu Chen, Zeyu Zhang, Haoran Tan, Quanyu Dai, Hao Yang, Zhenhua Dong, Xu Chen

+ [BeliefNest: A Joint Action Simulator for Embodied Agents with Theory of Mind](https://arxiv.org//abs/2505.12321)

	Rikunari Sagara, Koichiro Terao, Naoto Iwahashi

+ [Enhancing User-Oriented Proactivity in Open-Domain Dialogues with Critic Guidance](https://arxiv.org//abs/2505.12334)

	Yufeng Wang, Jinwu Hu, Ziteng Huang, Kunyang Lin, Zitian Zhang, Peihao Chen, Yu Hu, Qianyue Wang, Zhuliang Yu, Bin Sun, Xiaofen Xing, Qingfang Zheng, Mingkui Tan

+ [SEED-GRPO: Semantic Entropy Enhanced GRPO for Uncertainty-Aware Policy Optimization](https://arxiv.org//abs/2505.12346)

	Minghan Chen, Guikun Chen, Wenguan Wang, Yi Yang

+ [Reasoning-CV: Fine-tuning Powerful Reasoning LLMs for Knowledge-Assisted Claim Verification](https://arxiv.org//abs/2505.12348)

	Zhi Zheng, Wee Sun Lee

+ [MedAgentBoard: Benchmarking Multi-Agent Collaboration with Conventional Methods for Diverse Medical Tasks](https://arxiv.org//abs/2505.12371)

	Yinghao Zhu, Ziyi He, Haoran Hu, Xiaochen Zheng, Xichen Zhang, Zixiang Wang, Junyi Gao, Liantao Ma, Lequan Yu

+ [NeuroGen: Neural Network Parameter Generation via Large Language Models](https://arxiv.org//abs/2505.12470)

	Jiaqi Wang, Yusen Zhang, Xi Li

+ [UIShift: Enhancing VLM-based GUI Agents through Self-supervised Reinforcement Learning](https://arxiv.org//abs/2505.12493)

	Longxi Gao, Li Zhang, Mengwei Xu

+ [MARGE: Improving Math Reasoning for LLMs with Guided Exploration](https://arxiv.org//abs/2505.12500)

	Jingyue Gao, Runji Lin, Keming Lu, Bowen Yu, Junyang Lin, Jianyu Chen

+ [ALAS: A Stateful Multi-LLM Agent Framework for Disruption-Aware Planning](https://arxiv.org//abs/2505.12501)

	Edward Y. Chang, Longling Geng

+ [Decoding the Mind of Large Language Models: A Quantitative Evaluation of Ideology and Biases](https://arxiv.org//abs/2505.12183)

	Manari Hirose, Masato Uchida

+ [Self-Destructive Language Model](https://arxiv.org//abs/2505.12186)

	Yuhui Wang, Rongyi Zhu, Ting Wang

+ [LLM-DSE: Searching Accelerator Parameters with LLM Agents](https://arxiv.org//abs/2505.12188)

	Hanyu Wang, Xinrui Wu, Zijian Ding, Su Zheng, Chengyue Wang, Tony Nowatzki, Yizhou Sun, Jason Cong

+ [Reward Inside the Model: A Lightweight Hidden-State Reward Model for LLM's Best-of-N sampling](https://arxiv.org//abs/2505.12225)

	Jizhou Guo, Zhaomin Wu, Philip S. Yu

+ [PANORAMA: A synthetic PII-laced dataset for studying sensitive data memorization in LLMs](https://arxiv.org//abs/2505.12238)

	Sriram Selvam, Anneswa Ghosh

+ [ACU: Analytic Continual Unlearning for Efficient and Exact Forgetting with Privacy Preservation](https://arxiv.org//abs/2505.12239)

	Jianheng Tang, Huiping Zhuang, Di Fang, Jiaxu Li, Feijiang Han, Yajiang Huang, Kejia Fan, Leye Wang, Zhanxing Zhu, Shanghang Zhang, Houbing Herbert Song, Yunhuai Liu

+ [LAMeTA: Intent-Aware Agentic Network Optimization via a Large AI Model-Empowered Two-Stage Approach](https://arxiv.org//abs/2505.12247)

	Yinqiu Liu, Guangyuan Liu, Jiacheng Wang, Ruichen Zhang, Dusit Niyato, Geng Sun, Zehui Xiong, Zhu Han

+ [Not All Documents Are What You Need for Extracting Instruction Tuning Data](https://arxiv.org//abs/2505.12250)

	Chi Zhang, Huaping Zhong, Hongtao Li, Chengliang Chai, Jiawei Hong, Yuhao Deng, Jiacheng Wang, Tian Tan, Yizhou Yan, Jiantao Qiu, Ye Yuan, Guoren Wang, Conghui He, Lei Cao

+ [LightRetriever: A LLM-based Hybrid Retrieval Architecture with 1000x Faster Query Inference](https://arxiv.org//abs/2505.12260)

	Guangyuan Ma, Yongliang Ma, Xuanrui Gou, Zhenpeng Su, Ming Zhou, Songlin Hu

+ [The Tower of Babel Revisited: Multilingual Jailbreak Prompts on Closed-Source Large Language Models](https://arxiv.org//abs/2505.12287)

	Linghan Huang, Haolin Jin, Zhaoge Bi, Pengyue Yang, Peizhou Zhao, Taozhao Chen, Xiongfei Wu, Lei Ma, Huaming Chen

+ [Mitigating Hallucinations via Inter-Layer Consistency Aggregation in Large Vision-Language Models](https://arxiv.org//abs/2505.12343)

	Kai Tang, Jinhao You, Xiuqi Ge, Hanze Li, Yichen Guo, Xiande Huang

+ [Wisdom from Diversity: Bias Mitigation Through Hybrid Human-LLM Crowds](https://arxiv.org//abs/2505.12349)

	Axel Abels, Tom Lenaerts

+ [DisCO: Reinforcing Large Reasoning Models with Discriminative Constrained Optimization](https://arxiv.org//abs/2505.12366)

	Gang Li, Ming Lin, Tomer Galanti, Zhengzhong Tu, Tianbao Yang

+ [CAPTURE: Context-Aware Prompt Injection Testing and Robustness Enhancement](https://arxiv.org//abs/2505.12368)

	Gauri Kholkar, Ratinder Ahuja

+ [From n-gram to Attention: How Model Architectures Learn and Propagate Bias in Language Modeling](https://arxiv.org//abs/2505.12381)

	Mohsinul Kabir, Tasfia Tahsin, Sophia Ananiadou

+ [Traversal Verification for Speculative Tree Decoding](https://arxiv.org//abs/2505.12398)

	Yepeng Weng, Qiao Hu, Xujie Chen, Li Liu, Dianwen Mei, Huishi Qiu, Jiang Tian, Zhongchao Shi

+ [PSC: Extending Context Window of Large Language Models via Phase Shift Calibration](https://arxiv.org//abs/2505.12423)

	Wenqiao Zhu, Chao Xu, Lulu Wang, Jun Wu

+ [EvoGPT: Enhancing Test Suite Robustness via LLM-Based Generation and Genetic Optimization](https://arxiv.org//abs/2505.12424)

	Lior Broide, Roni Stern

+ [Observe-R1: Unlocking Reasoning Abilities of MLLMs with Dynamic Progressive Reinforcement Learning](https://arxiv.org//abs/2505.12432)

	Zirun Guo, Minjie Hong, Tao Jin

+ [SRLoRA: Subspace Recomposition in Low-Rank Adaptation via Importance-Based Fusion and Reinitialization](https://arxiv.org//abs/2505.12433)

	Haodong Yang, Lei Wang, Md Zakir Hossain

+ [SGDPO: Self-Guided Direct Preference Optimization for Language Model Alignment](https://arxiv.org//abs/2505.12435)

	Wenqiao Zhu, Ji Liu, Lulu Wang, Jun Wu, Yulun Zhang

+ [IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems](https://arxiv.org//abs/2505.12442)

	Liwen Wang, Wenxuan Wang, Shuai Wang, Zongjie Li, Zhenlan Ji, Zongyi Lyu, Daoyuan Wu, Shing-Chi Cheung

+ [Beyond Frameworks: Unpacking Collaboration Strategies in Multi-Agent Systems](https://arxiv.org//abs/2505.12467)

	Haochun Wang, Sendong Zhao, Jingbo Wang, Zewen Qiang, Bing Qin, Ting Liu

+ [Enhancing Large Language Models with Reward-guided Tree Search for Knowledge Graph Question and Answering](https://arxiv.org//abs/2505.12476)

	Xiao Long, Liansheng Zhuang, Chen Shen, Shaotian Yan, Yifei Li, Shafei Wang

+ [CPGD: Toward Stable Rule-based Reinforcement Learning for Language Models](https://arxiv.org//abs/2505.12504)

	Zongkai Liu, Fanqing Meng, Lingxiao Du, Zhixiang Zhou, Chao Yu, Wenqi Shao, Qiaosheng Zhang

+ [Towards Budget-Friendly Model-Agnostic Explanation Generation for Large Language Models](https://arxiv.org//abs/2505.12509)

	Junhao Liu, Haonan Yu, Xin Zhang

+ [A Survey of Attacks on Large Language Models](https://arxiv.org//abs/2505.12567)

	Wenrui Xu, Keshab K. Parhi

+ [Measuring Information Distortion in Hierarchical Ultra long Novel Generation:The Optimal Expansion Ratio](https://arxiv.org//abs/2505.12572)

	Hanwen Shen, Ting Ying

+ [Truth Neurons](https://arxiv.org//abs/2505.12182)

	Haohang Li, Yupeng Cao, Yangyang Yu, Jordan W. Suchow, Zining Zhu

+ [How Reliable is Multilingual LLM-as-a-Judge?](https://arxiv.org//abs/2505.12201)

	Xiyan Fu, Wei Liu

+ [Data Whisperer: Efficient Data Selection for Task-Specific LLM Fine-Tuning via Few-Shot In-Context Learning](https://arxiv.org//abs/2505.12212)

	Shaobo Wang, Ziming Wang, Xiangqi Jin, Jize Wang, Jiajun Zhang, Kaixin Li, Zichen Wen, Zhong Li, Conghui He, Xuming Hu, Linfeng Zhang

+ [GMSA: Enhancing Context Compression via Group Merging and Layer Semantic Alignment](https://arxiv.org//abs/2505.12215)

	Jiwei Tang, Zhicheng Zhang, Shunlong Wu, Jingheng Ye, Lichen Bai, Zitai Wang, Tingwei Lu, Jiaqi Chen, Lin Hai, Hai-Tao Zheng, Hong-Gee Kim

+ [One-for-All Pruning: A Universal Model for Customized Compression of Large Language Models](https://arxiv.org//abs/2505.12216)

	Rongguang Ye, Ming Tang

+ [Distribution Prompting: Understanding the Expressivity of Language Models Through the Next-Token Distributions They Can Produce](https://arxiv.org//abs/2505.12244)

	Haojin Wang, Zining Zhu, Freda Shi

+ [Teach2Eval: An Indirect Evaluation Method for LLM by Judging How It Teaches](https://arxiv.org//abs/2505.12259)

	Yuhang Zhou, Xutian Chen, Yixin Cao, Yuchen Ni, Yu He, Siyu Tian, Xiang Liu, Jian Zhang, Chuanjun Ji, Guangnan Ye, Xipeng Qiu

+ [Learning Auxiliary Tasks Improves Reference-Free Hallucination Detection in Open-Domain Long-Form Generation](https://arxiv.org//abs/2505.12265)

	Chengwei Qin, Wenxuan Zhou, Karthik Abinav Sankararaman, Nanshu Wang, Tengyu Xu, Alexander Radovic, Eryk Helenowski, Arya Talebzadeh, Aditya Tayade, Sinong Wang, Shafiq Joty, Han Fang, Hao Ma

+ [$K$-MSHC: Unmasking Minimally Sufficient Head Circuits in Large Language Models with Experiments on Syntactic Classification Tasks](https://arxiv.org//abs/2505.12268)

	Pratim Chowdhary

+ [LLM-Based Evaluation of Low-Resource Machine Translation: A Reference-less Dialect Guided Approach with a Refined Sylheti-English Benchmark](https://arxiv.org//abs/2505.12273)

	Md. Atiqur Rahman, Sabrina Islam, Mushfiqul Haque Omi

+ [HBO: Hierarchical Balancing Optimization for Fine-Tuning Large Language Models](https://arxiv.org//abs/2505.12300)

	Weixuan Wang, Minghao Wu, Barry Haddow, Alexandra Birch

+ [Bidirectional LMs are Better Knowledge Memorizers? A Benchmark for Real-world Knowledge Injection](https://arxiv.org//abs/2505.12306)

	Yuwei Zhang, Wenhao Yu, Shangbin Feng, Yifan Zhu, Letian Peng, Jayanth Srinivasa, Gaowen Liu, Jingbo Shang

+ [ExpertSteer: Intervening in LLMs through Expert Knowledge](https://arxiv.org//abs/2505.12313)

	Weixuan Wang, Minghao Wu, Barry Haddow, Alexandra Birch

+ [LLMSR@XLLM25: An Empirical Study of LLM for Structural Reasoning](https://arxiv.org//abs/2505.12328)

	Xinye Li, Mingqi Wan, Dianbo Sui

+ [UniEdit: A Unified Knowledge Editing Benchmark for Large Language Models](https://arxiv.org//abs/2505.12345)

	Qizhou Chen, Dakan Wang, Taolin Zhang, Zaoming Yan, Chengsong You, Chengyu Wang, Xiaofeng He

+ [SLOT: Sample-specific Language Model Optimization at Test-time](https://arxiv.org//abs/2505.12392)

	Yang Hu, Xingyu Zhang, Xueji Fang, Zhiyang Chen, Xiao Wang, Huatian Zhang, Guojun Qi

+ [Learning to Play Like Humans: A Framework for LLM Adaptation in Interactive Fiction Games](https://arxiv.org//abs/2505.12439)

	Jinming Zhang, Yunfei Long

+ [Introspective Growth: Automatically Advancing LLM Expertise in Technology Judgment](https://arxiv.org//abs/2505.12452)

	Siyang Wu, Honglin Bao, Nadav Kunievsky, James A. Evans

+ [What are they talking about? Benchmarking Large Language Models for Knowledge-Grounded Discussion Summarization](https://arxiv.org//abs/2505.12474)

	Weixiao Zhou, Junnan Zhu, Gengyao Li, Xianfu Cheng, Xinnian Liang, Feifei Zhai, Zhoujun Li

+ [KG-QAGen: A Knowledge-Graph-Based Framework for Systematic Question Generation and Long-Context LLM Evaluation](https://arxiv.org//abs/2505.12495)

	Nikita Tatarinov, Vidhyakshaya Kannan, Haricharana Srinivasa, Arnav Raj, Harpreet Singh Anand, Varun Singh, Aditya Luthra, Ravij Lade, Agam Shah, Sudheer Chava

+ [LM$^2$otifs : An Explainable Framework for Machine-Generated Texts Detection](https://arxiv.org//abs/2505.12507)

	Xu Zheng, Zhuomin Chen, Esteban Schafir, Sipeng Chen, Hojat Allah Salehi, Haifeng Chen, Farhad Shirani, Wei Cheng, Dongsheng Luo

+ [ESC-Judge: A Framework for Comparing Emotional Support Conversational Agents](https://arxiv.org//abs/2505.12531)

	Navid Madani, Rohini Srihari

+ [Disambiguation in Conversational Question Answering in the Era of LLM: A Survey](https://arxiv.org//abs/2505.12543)

	Md Mehrab Tanjim, Yeonjun In, Xiang Chen, Victor S. Bursztyn, Ryan A. Rossi, Sungchul Kim, Guang-Jie Ren, Vaishnavi Muppala, Shun Jiang, Yongsung Kim, Chanyoung Park

+ [Extracting memorized pieces of (copyrighted) books from open-weight language models](https://arxiv.org//abs/2505.12546)

	A. Feder Cooper, Aaron Gokaslan, Amy B. Cyphert, Christopher De Sa, Mark A. Lemley, Daniel E. Ho, Percy Liang

+ [EVALOOP: Assessing LLM Robustness in Programming from a Self-consistency Perspective](https://arxiv.org//abs/2505.12185)

	Sen Fang, Weiyuan Ding, Bowen Xu

+ [LogicOCR: Do Your Large Multimodal Models Excel at Logical Reasoning on Text-Rich Images?](https://arxiv.org//abs/2505.12307)

	Maoyuan Ye, Jing Zhang, Juhua Liu, Bo Du, Dacheng Tao

+ [UFO-RL: Uncertainty-Focused Optimization for Efficient Reinforcement Learning Data Selection](https://arxiv.org//abs/2505.12457)

	Yang Zhao, Kai Xiong, Xiao Ding, Li Du, YangouOuyang, Zhouhao Sun, Jiannan Guan, Wenbin Zhang, Bin Liu, Dong Hu, Bing Qin, Ting Liu

+ [From Shots to Stories: LLM-Assisted Video Editing with Unified Language Representations](https://arxiv.org//abs/2505.12237)

	Yuzhi Li, Haojun Xu, Fang Tian

+ [SchoenbAt: Rethinking Attention with Polynomial basis](https://arxiv.org//abs/2505.12252)

	Yuhan Guo, Lizhong Ding, Yuwan Yang, Xuewei Guo

+ [Graph-Reward-SQL: Execution-Free Reinforcement Learning for Text-to-SQL via Graph Matching and Stepwise Reward](https://arxiv.org//abs/2505.12380)

	Han Weng, Boyi Liu, Yuanfeng Song, Dun Zeng, Yingxiang Yang, Yi Zhan, Longjie Cui, Xiaoming Yin, Yang Sun

+ [AltLoRA: Towards Better Gradient Approximation in Low-Rank Adaptation with Alternating Projections](https://arxiv.org//abs/2505.12455)

	Xin Yu, Yujia Wang, Jinghui Chen, Lingzhou Xue

+ [Reasoning by Superposition: A Theoretical Perspective on Chain of Continuous Thought](https://arxiv.org//abs/2505.12514)

	Hanlin Zhu, Shibo Hao, Zhiting Hu, Jiantao Jiao, Stuart Russell, Yuandong Tian

+ [Harnessing the Universal Geometry of Embeddings](https://arxiv.org//abs/2505.12540)

	Rishi Jha, Collin Zhang, Vitaly Shmatikov, John X. Morris

+ [Adaptive parameter-efficient fine-tuning via Hessian-informed subset selection](https://arxiv.org//abs/2505.12579)

	Shiyun Xu, Zhiqi Bu

+ [OSS-Bench: Benchmark Generator for Coding LLMs](https://arxiv.org//abs/2505.12331)

	Yuancheng Jiang, Roland Yap, Zhenkai Liang

+ [Automated Profile Inference with Language Model Agents](https://arxiv.org//abs/2505.12402)

	Yuntao Du, Zitao Li, Bolin Ding, Yaliang Li, Hanshen Xiao, Jingren Zhou, Ninghui Li

# 2025-05-17
+ [Solver-Informed RL: Grounding Large Language Models for Authentic Optimization Modeling](https://arxiv.org//abs/2505.11792)

	Yitian Chen, Jingfan Xia, Siyu Shao, Dongdong Ge, Yinyu Ye

+ [ChatHTN: Interleaving Approximate (LLM) and Symbolic HTN Planning](https://arxiv.org//abs/2505.11814)

	Hector Munoz-Avila, David W. Aha, Paola Rizzo

+ [ToLeaP: Rethinking Development of Tool Learning with Large Language Models](https://arxiv.org//abs/2505.11833)

	Haotian Chen, Zijun Song, Boye Niu, Ke Zhang, Litu Ou, Yaxi Lu, Zhong Zhang, Xin Cong, Yankai Lin, Zhiyuan Liu, Maosong Sun

+ [On the Eligibility of LLMs for Counterfactual Reasoning: A Decompositional Study](https://arxiv.org//abs/2505.11839)

	Shuai Yang, Qi Yang, Luoxi Tang, Jeremy Blackburn, Zhaohan Xi

+ [Evaluating the Logical Reasoning Abilities of Large Reasoning Models](https://arxiv.org//abs/2505.11854)

	Hanmeng Liu, Yiran Ding, Zhizhang Fu, Chaoli Zhang, Xiaozhang Liu, Yue Zhang

+ [Fair-PP: A Synthetic Dataset for Aligning LLM with Personalized Preferences of Social Equity](https://arxiv.org//abs/2505.11861)

	Qi Zhou, Jie Zhang, Dongxia Wang, Qiang Liu, Tianlin Li, Jin Song Dong, Wenhai Wang, Qing Guo

+ [LifelongAgentBench: Evaluating LLM Agents as Lifelong Learners](https://arxiv.org//abs/2505.11942)

	Junhao Zheng, Xidi Cai, Qiuke Li, Duzhen Zhang, ZhongZhi Li, Yingying Zhang, Le Song, Qianli Ma

+ [Solve-Detect-Verify: Inference-Time Scaling with Flexible Generative Verifier](https://arxiv.org//abs/2505.11966)

	Jianyuan Zhong, Zeju Li, Zhijian Xu, Xiangyu Wen, Kezhi Li, Qiang Xu

+ [Interactional Fairness in LLM Multi-Agent Systems: An Evaluation Framework](https://arxiv.org//abs/2505.12001)

	Ruta Binkyte

+ [SOCIA: An End-to-End Agentic Framework for Automated Cyber-Physical-Social Simulator Generation](https://arxiv.org//abs/2505.12006)

	Yuncheng Hua, Ji Miao, Mehdi Jafari, Jianxiang Xie, Hao Xue, Flora D. Salim

+ [LLM-based Automated Theorem Proving Hinges on Scalable Synthetic Data Generation](https://arxiv.org//abs/2505.12031)

	Junyu Lai, Jiakun Zhang, Shuo Xu, Taolue Chen, Zihang Wang, Yao Yang, Jiarui Zhang, Chun Cao, Jingwei Xu

+ [Tiny QA Benchmark++: Ultra-Lightweight, Synthetic Multilingual Dataset Generation & Smoke-Tests for Continuous LLM Evaluation](https://arxiv.org//abs/2505.12058)

	Vincent Koc

+ [Demystifying and Enhancing the Efficiency of Large Language Model Based Search Agents](https://arxiv.org//abs/2505.12065)

	Tiannuo Yang, Zebin Yao, Bowen Jin, Lixiao Cui, Yusen Li, Gang Wang, Xiaoguang Liu

+ [LLM-BABYBENCH: Understanding and Evaluating Grounded Planning and Reasoning in LLMs](https://arxiv.org//abs/2505.12135)

	Omar Choukrani, Idriss Malek, Daniil Orel, Zhuohan Xie, Zangir Iklassov, Martin Takáč, Salem Lahlou

+ [OMAC: A Broad Optimization Framework for LLM-Based Multi-Agent Collaboration](https://arxiv.org//abs/2505.11765)

	Shijun Li, Hilaf Hasson, Joydeep Ghosh

+ [Internal Causal Mechanisms Robustly Predict Language Model Out-of-Distribution Behaviors](https://arxiv.org//abs/2505.11770)

	Jing Huang, Junyi Tao, Thomas Icard, Diyi Yang, Christopher Potts

+ [Retrospex: Language Agent Meets Offline Reinforcement Learning Critic](https://arxiv.org//abs/2505.11807)

	Yufei Xiang, Yiqun Shen, Yeqin Zhang, Cam-Tu Nguyen

+ [Search-Based Correction of Reasoning Chains for Language Models](https://arxiv.org//abs/2505.11824)

	Minsu Kim, Jean-Pierre Falet, Oliver E. Richardson, Xiaoyin Chen, Moksh Jain, Sungjin Ahn, Sungsoo Ahn, Yoshua Bengio

+ [Not All Thoughts are Generated Equal: Efficient LLM Reasoning via Multi-Turn Reinforcement Learning](https://arxiv.org//abs/2505.11827)

	Yansong Ning, Wei Li, Jun Fang, Naiqiang Tan, Hao Liu

+ [Multilingual Collaborative Defense for Large Language Models](https://arxiv.org//abs/2505.11835)

	Hongliang Li, Jinan Xu, Gengping Cui, Changhao Guan, Fengran Mo, Kaiyu Huang

+ [On Membership Inference Attacks in Knowledge Distillation](https://arxiv.org//abs/2505.11837)

	Ziyao Cui, Minxing Zhang, Jian Pei

+ [Mobile-Bench-v2: A More Realistic and Comprehensive Benchmark for VLM-based Mobile Agents](https://arxiv.org//abs/2505.11891)

	Weikai Xu, Zhizheng Jiang, Yuxuan Liu, Wei Liu, Jian Luan, Yuanchun Li, Yunxin Liu, Bin Wang, Bo An

+ [RLAP: A Reinforcement Learning Enhanced Adaptive Planning Framework for Multi-step NLP Task Solving](https://arxiv.org//abs/2505.11893)

	Zepeng Ding, Dixuan Wang, Ziqin Luo, Guochao Jiang, Deqing Yang, Jiaqing Liang

+ [AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via Reinforcement Learning](https://arxiv.org//abs/2505.11896)

	Chenwei Lou, Zewei Sun, Xinnian Liang, Meng Qu, Wei Shen, Wenqi Wang, Yuntao Li, Qingping Yang, Shuangzhi Wu

+ [An Explanation of Intrinsic Self-Correction via Linear Representations and Latent Concepts](https://arxiv.org//abs/2505.11924)

	Yu-Ting Lee, Hui-Ying Shih, Fu-Chieh Chang, Pei-Yuan Wu

+ [Exploring Criteria of Loss Reweighting to Enhance LLM Unlearning](https://arxiv.org//abs/2505.11953)

	Puning Yang, Qizhou Wang, Zhuo Huang, Tongliang Liu, Chengqi Zhang, Bo Han

+ [MARVEL: Multi-Agent RTL Vulnerability Extraction using Large Language Models](https://arxiv.org//abs/2505.11963)

	Luca Collini, Baleegh Ahmad, Joey Ah-kiow, Ramesh Karri

+ [Safe Delta: Consistently Preserving Safety when Fine-Tuning LLMs on Diverse Datasets](https://arxiv.org//abs/2505.12038)

	Ning Lu, Shengcai Liu, Jiahao Wu, Weiyu Chen, Zhirui Zhang, Yew-Soon Ong, Qi Wang, Ke Tang

+ [ABoN: Adaptive Best-of-N Alignment](https://arxiv.org//abs/2505.12050)

	Vinod Raman, Hilal Asi, Satyen Kale

+ [Improving Fairness in LLMs Through Testing-Time Adversaries](https://arxiv.org//abs/2505.12100)

	Isabela Pereira Gregio, Ian Pons, Anna Helena Reali Costa, Artur Jordão

+ [Reasoning Large Language Model Errors Arise from Hallucinating Critical Problem Features](https://arxiv.org//abs/2505.12151)

	Alex Heyman, Joel Zylberberg

+ [BELLE: A Bi-Level Multi-Agent Reasoning Framework for Multi-Hop Question Answering](https://arxiv.org//abs/2505.11811)

	Taolin Zhang, Dongyang Li, Qizhou Chen, Chengyu Wang, Xiaofeng He

+ [Chain-of-Model Learning for Language Model](https://arxiv.org//abs/2505.11820)

	Kaitao Song, Xiaohua Wang, Xu Tan, Huiqiang Jiang, Chengruidong Zhang, Yongliang Shen, Cen LU, Zihao Li, Zifan Song, Caihua Shan, Yansen Wang, Kan Ren, Xiaoqing Zheng, Tao Qin, Yuqing Yang, Dongsheng Li, Lili Qiu

+ [NAMET: Robust Massive Model Editing via Noise-Aware Memory Optimization](https://arxiv.org//abs/2505.11876)

	Yanbo Dai, Zhenlan Ji, Zongjie Li, Shuai Wang

+ [AutoMedEval: Harnessing Language Models for Automatic Medical Capability Evaluation](https://arxiv.org//abs/2505.11887)

	Xiechi Zhang, Zetian Ouyang, Linlin Wang, Gerard de Melo, Zhu Cao, Xiaoling Wang, Ya Zhang, Yanfeng Wang, Liang He

+ [ELITE: Embedding-Less retrieval with Iterative Text Exploration](https://arxiv.org//abs/2505.11908)

	Zhangyu Wang, Siyuan Gao, Rong Zhou, Hao Wang, Li Ning

+ [Enhancing Complex Instruction Following for Large Language Models with Mixture-of-Contexts Fine-tuning](https://arxiv.org//abs/2505.11922)

	Yuheng Lu, ZiMeng Bai, Caixia Yuan, Huixing Jiang, Xiaojie Wang

+ [Neuro-Symbolic Query Compiler](https://arxiv.org//abs/2505.11932)

	Yuyao Zhang, Zhicheng Dou, Xiaoxi Li, Jiajie Jin, Yongkang Wu, Zhonghua Li, Qi Ye, Ji-Rong Wen

+ [CCNU at SemEval-2025 Task 3: Leveraging Internal and External Knowledge of Large Language Models for Multilingual Hallucination Annotation](https://arxiv.org//abs/2505.11965)

	Xu Liu, Guanyi Chen

+ [Unveiling Knowledge Utilization Mechanisms in LLM-based Retrieval-Augmented Generation](https://arxiv.org//abs/2505.11995)

	Yuhao Wang, Ruiyang Ren, Yucheng Wang, Wayne Xin Zhao, Jing Liu, Hua Wu, Haifeng Wang

+ [MoL for LLMs: Dual-Loss Optimization to Enhance Domain Expertise While Preserving General Capabilities](https://arxiv.org//abs/2505.12043)

	Jingxue Chen, Qingkun Tang, Qianchun Lu, Siyuan Fang

+ [GenderBench: Evaluation Suite for Gender Biases in LLMs](https://arxiv.org//abs/2505.12054)

	Matúš Pikuliak

+ [Why Not Act on What You Know? Unleashing Safety Potential of LLMs via Self-Aware Guard Enhancement](https://arxiv.org//abs/2505.12060)

	Peng Ding, Jun Kuang, Zongyu Wang, Xuezhi Cao, Xunliang Cai, Jiajun Chen, Shujian Huang

+ [Do different prompting methods yield a common task representation in language models?](https://arxiv.org//abs/2505.12075)

	Guy Davidson, Todd M. Gureckis, Brenden M. Lake, Adina Williams

+ [Model Merging in Pre-training of Large Language Models](https://arxiv.org//abs/2505.12082)

	Yunshui Li, Yiyuan Ma, Shen Yan, Chaoyi Zhang, Jing Liu, Jianqiao Lu, Ziwen Xu, Mengzhao Chen, Minrui Wang, Shiyi Zhan, Jin Ma, Xunhao Lai, Yao Luo, Xingyan Bin, Hongbin Ren, Mingji Han, Wenhao Hao, Bairen Yi, LingJun Liu, Bole Ma, Xiaoying Jia, Zhou Xun, Liang Xiang, Yonghui Wu

+ [Video-SafetyBench: A Benchmark for Safety Evaluation of Video LVLMs](https://arxiv.org//abs/2505.11842)

	Xuannan Liu, Zekun Li, Zheqi He, Peipei Li, Shuhan Xia, Xing Cui, Huaibo Huang, Xi Yang, Ran He

+ [J1: Exploring Simple Test-Time Scaling for LLM-as-a-Judge](https://arxiv.org//abs/2505.11875)

	Chi-Min Chan, Chunpu Xu, Jiaming Ji, Zhen Ye, Pengcheng Wen, Chunyang Jiang, Yaodong Yang, Wei Xue, Sirui Han, Yike Guo

+ [Adversarial Robustness for Unified Multi-Modal Encoders via Efficient Calibration](https://arxiv.org//abs/2505.11895)

	Chih-Ting Liao, Bin Ren, Guofeng Mei, Xu Zheng

+ [Are Multimodal Large Language Models Ready for Omnidirectional Spatial Reasoning?](https://arxiv.org//abs/2505.11907)

	Zihao Dongfang, Xu Zheng, Ziqiao Weng, Yuanhuiyi Lyu, Danda Pani Paudel, Luc Van Gool, Kailun Yang, Xuming Hu

+ [MINGLE: Mixtures of Null-Space Gated Low-Rank Experts for Test-Time Continual Model Merging](https://arxiv.org//abs/2505.11883)

	Zihuan Qiu, Yi Xu, Chiyuan He, Fanman Meng, Linfeng Xu, Qingbo Wu, Hongliang Li

+ [LAMP: Extracting Locally Linear Decision Surfaces from LLM World Models](https://arxiv.org//abs/2505.11772)

	Ryan Chen, Youngmin Ko, Zeyu Zhang, Catherine Cho, Sunny Chung, Mauro Giuffré, Dennis L. Shung, Bradly C. Stadie

+ [JULI: Jailbreak Large Language Models by Self-Introspection](https://arxiv.org//abs/2505.11790)

	Jesson Wang, Zhanhao Hu, David Wagner

+ [Reinforcing Multi-Turn Reasoning in LLM Agents via Turn-Level Credit Assignment](https://arxiv.org//abs/2505.11821)

	Siliang Zeng, Quan Wei, William Brown, Oana Frunza, Yuriy Nevmyvaka, Mingyi Hong

+ [Spotlight Your Instructions: Instruction-following with Dynamic Attention Steering](https://arxiv.org//abs/2505.12025)

	Praveen Venkateswaran, Danish Contractor

+ [Transformer learns the cross-task prior and regularization for in-context learning](https://arxiv.org//abs/2505.12138)

	Fei Lu, Yue Yu

+ [Communication-Efficient Hybrid Language Model via Uncertainty-Aware Opportunistic and Compressed Transmission](https://arxiv.org//abs/2505.11788)

	Seungeun Oh, Jinhyuk Kim, Jihong Park, Seung-Woo Ko, Jinho Choi, Tony Q. S. Quek, Seong-Lyun Kim

+ [Benchmarking LLMs in an Embodied Environment for Blue Team Threat Hunting](https://arxiv.org//abs/2505.11901)

	Xiaoqun Liu, Feiyang Yu, Xi Li, Guanhua Yan, Ping Yang, Zhaohan Xi

+ [TechniqueRAG: Retrieval Augmented Generation for Adversarial Technique Annotation in Cyber Threat Intelligence Text](https://arxiv.org//abs/2505.11988)

	Ahmed Lekssays, Utsav Shukla, Husrev Taha Sencar, Md Rizwan Parvez

# 2025-05-16
+ [PoE-World: Compositional World Modeling with Products of Programmatic Experts](https://arxiv.org//abs/2505.10819)

	Wasu Top Piriyakulkij, Yichao Liang, Hao Tang, Adrian Weller, Marta Kryven, Kevin Ellis

+ [Creativity or Brute Force? Using Brainteasers as a Window into the Problem-Solving Abilities of Large Language Models](https://arxiv.org//abs/2505.10844)

	Simeng Han, Stephen Xia, Grant Zhang, Howard Dai, Chen Liu, Lichang Chen, Hoang Huy Nguyen, Hongyuan Mei, Jiayuan Mao, R. Thomas McCoy

+ [Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A Perspective of Probability Theory](https://arxiv.org//abs/2505.10981)

	Yexiang Liu, Zekun Li, Zhi Fang, Nan Xu, Ran He, Tieniu Tan

+ [RAGSynth: Synthetic Data for Robust and Faithful RAG Component Optimization](https://arxiv.org//abs/2505.10989)

	Haiyang Shen, Hang Yan, Zhongshi Xing, Mugeng Liu, Yue Li, Zhiyang Chen, Yuxiang Wang, Jiuzheng Wang, Yun Ma

+ [GuardReasoner-VL: Safeguarding VLMs via Reinforced Reasoning](https://arxiv.org//abs/2505.11049)

	Yue Liu, Shengfang Zhai, Mingzhe Du, Yulin Chen, Tri Cao, Hongcheng Gao, Cheng Wang, Xinfeng Li, Kun Wang, Junfeng Fang, Jiaheng Zhang, Bryan Hooi

+ [Think Twice Before You Act: Enhancing Agent Behavioral Safety with Thought Correction](https://arxiv.org//abs/2505.11063)

	Changyue Jiang, Xudong Pan, Min Yang

+ [Group Think: Multiple Concurrent Reasoning Agents Collaborating at Token Level Granularity](https://arxiv.org//abs/2505.11107)

	Chan-Jan Hsu, Davide Buffelli, Jamie McGowan, Feng-Ting Liao, Yi-Chang Chen, Sattar Vakili, Da-shan Shiu

+ [Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining](https://arxiv.org//abs/2505.11122)

	Yu Shi, Yitong Duan, Jian Li

+ [Can Global XAI Methods Reveal Injected Bias in LLMs? SHAP vs Rule Extraction vs RuleSHAP](https://arxiv.org//abs/2505.11189)

	Francesco Sovrano

+ [Is PRM Necessary? Problem-Solving RL Implicitly Induces PRM Capability in LLMs](https://arxiv.org//abs/2505.11227)

	Zhangying Feng, Qianglong Chen, Ning Lu, Yongqian Li, Siqi Cheng, Shuangmu Peng, Duyu Tang, Shengcai Liu, Zhirui Zhang

+ [LD-Scene: LLM-Guided Diffusion for Controllable Generation of Adversarial Safety-Critical Driving Scenarios](https://arxiv.org//abs/2505.11247)

	Mingxing Peng, Yuting Xie, Xusen Guo, Ruoyu Yao, Hai Yang, Jun Ma

+ [SelfBudgeter: Adaptive Token Allocation for Efficient LLM Reasoning](https://arxiv.org//abs/2505.11274)

	Zheng Li, Qingxiu Dong, Jingyuan Ma, Di Zhang, Zhifang Sui

+ [A Systematic Analysis of Base Model Choice for Reward Modeling](https://arxiv.org//abs/2505.10775)

	Kian Ahrabian, Pegah Jandaghi, Negar Mokhberian, Sai Praneeth Karimireddy, Jay Pujara

+ [Enhancing Low-Resource Minority Language Translation with LLMs and Retrieval-Augmented Generation for Cultural Nuances](https://arxiv.org//abs/2505.10829)

	Chen-Chi Chang, Chong-Fu Li, Chu-Hsuan Lee, Hung-Shin Lee

+ [Learning When to Think: Shaping Adaptive Reasoning in R1-Style Models via Multi-Stage RL](https://arxiv.org//abs/2505.10832)

	Songjun Tu, Jiahao Lin, Qichao Zhang, Xiangyu Tian, Linjing Li, Xiangyuan Lan, Dongbin Zhao

+ [Ready2Unlearn: A Learning-Time Approach for Preparing Models with Future Unlearning Readiness](https://arxiv.org//abs/2505.10845)

	Hanyu Duan, Yi Yang, Ahmed Abbasi, Kar Yan Tam

+ [Improve Rule Retrieval and Reasoning with Self-Induction and Relevance ReEstimate](https://arxiv.org//abs/2505.10870)

	Ziyang Huang, Wangtao Sun, Jun Zhao, Kang Liu

+ [REI-Bench: Can Embodied Agents Understand Vague Human Instructions in Task Planning?](https://arxiv.org//abs/2505.10872)

	Chenxi Jiang, Chuhao Zhou, Jianfei Yang

+ [Explain What You Mean: Intent Augmented Knowledge Graph Recommender Built With LLM](https://arxiv.org//abs/2505.10900)

	Wenqing Zheng, Noah Fatsi, Daniel Barcklow, Dmitri Kalaev, Steven Yao, Owen Reinert, C. Bayan Bruss, Daniele Rosa

+ [Vaiage: A Multi-Agent Solution to Personalized Travel Planning](https://arxiv.org//abs/2505.10922)

	Binwen Liu, Jiexi Ge, Jiamin Wang

+ [A Survey on the Safety and Security Threats of Computer-Using Agents: JARVIS or Ultron?](https://arxiv.org//abs/2505.10924)

	Ada Chen, Yongjiang Wu, Junyuan Zhang, Shu Yang, Jen-tse Huang, Kun Wang, Wenxuan Wang, Shuai Wang

+ [Reasoning with OmniThought: A Large CoT Dataset with Verbosity and Cognitive Difficulty Annotations](https://arxiv.org//abs/2505.10937)

	Wenrui Cai, Chengyu Wang, Junbing Yan, Jun Huang, Xiangzhong Fang

+ [GenKnowSub: Improving Modularity and Reusability of LLMs through General Knowledge Subtraction](https://arxiv.org//abs/2505.10939)

	Mohammadtaha Bagherifard, Sahar Rajabi, Ali Edalat, Yadollah Yaghoobzadeh

+ [Let the Trial Begin: A Mock-Court Approach to Vulnerability Detection using LLM-Based Agents](https://arxiv.org//abs/2505.10961)

	Ratnadira Widyasari, Martin Weyssow, Ivana Clairine Irsan, Han Wei Ang, Frank Liauw, Eng Lieh Ouh, Lwin Khin Shar, Hong Jin Kang, David Lo

+ [Group-in-Group Policy Optimization for LLM Agent Training](https://arxiv.org//abs/2505.10978)

	Lang Feng, Zhenghai Xue, Tingcong Liu, Bo An

+ [Illusion or Algorithm? Investigating Memorization, Emergence, and Symbolic Processing in In-Context Learning](https://arxiv.org//abs/2505.11004)

	Jingcheng Niu, Subhabrata Dutta, Ahmed Elshabrawy, Harish Tayyar Madabushi, Iryna Gurevych

+ [Review-Instruct: A Review-Driven Multi-Turn Conversations Generation Method for Large Language Models](https://arxiv.org//abs/2505.11010)

	Jiangxu Wu, Cong Wang, TianHuang Su, Jun Yang, Haozhi Lin, Chao Zhang, Ming Peng, Kai Shi, SongPan Yang, BinQing Pan, ZiXian Li, Ni Yang, ZhenYu Yang

+ [Humans expect rationality and cooperation from LLM opponents in strategic games](https://arxiv.org//abs/2505.11011)

	Darija Barak, Miguel Costa-Gomes

+ [BLEUBERI: BLEU is a surprisingly effective reward for instruction following](https://arxiv.org//abs/2505.11080)

	Yapei Chang, Yekyung Kim, Michael Krumdick, Amir Zadeh, Chuan Li, Chris Tanner, Mohit Iyyer

+ [Scaling Reasoning can Improve Factuality in Large Language Models](https://arxiv.org//abs/2505.11140)

	Mike Zhang, Johannes Bjerva, Russa Biswas

+ [Human-Aligned Bench: Fine-Grained Assessment of Reasoning Ability in MLLMs vs. Humans](https://arxiv.org//abs/2505.11141)

	Yansheng Qiu, Li Xiao, Zhaopan Xu, Pengfei Zhou, Zheng Wang, Kaipeng Zhang

+ [SoLoPO: Unlocking Long-Context Capabilities in LLMs via Short-to-Long Preference Optimization](https://arxiv.org//abs/2505.11166)

	Huashan Sun, Shengyi Liao, Yansen Han, Yu Bai, Yang Gao, Cheng Fu, Weizhou Shen, Fanqi Wan, Ming Yan, Ji Zhang, Fei Huang

+ [Semantic Caching of Contextual Summaries for Efficient Question-Answering with Language Models](https://arxiv.org//abs/2505.11271)

	Camille Couturier, Spyros Mastorakis, Haiying Shen, Saravan Rajmohan, Victor Rühle

+ [Search and Refine During Think: Autonomous Retrieval-Augmented Reasoning of LLMs](https://arxiv.org//abs/2505.11277)

	Yaorui Shi, Shihan Li, Chang Wu, Zhiyuan Liu, Junfeng Fang, Hengxing Cai, An Zhang, Xiang Wang

+ [Phare: A Safety Probe for Large Language Models](https://arxiv.org//abs/2505.11365)

	Pierre Le Jeune, Benoît Malésieux, Weixuan Xiao, Matteo Dora

+ [EdgeWisePersona: A Dataset for On-Device User Profiling from Natural Language Interactions](https://arxiv.org//abs/2505.11417)

	Patryk Bartkowiak, Michal Podstawski

+ [LLMs unlock new paths to monetizing exploits](https://arxiv.org//abs/2505.11449)

	Nicholas Carlini, Milad Nasr, Edoardo Debenedetti, Barry Wang, Christopher A. Choquette-Choo, Daphne Ippolito, Florian Tramèr, Matthew Jagielski

+ [Disentangling Reasoning and Knowledge in Medical Large Language Models](https://arxiv.org//abs/2505.11462)

	Rahul Thapa, Qingyang Wu, Kevin Wu, Harrison Zhang, Angela Zhang, Eric Wu, Haotian Ye, Suhana Bedi, Nevin Aresh, Joseph Boen, Shriya Reddy, Ben Athiwaratkun, Shuaiwen Leon Song, James Zou

+ [HelpSteer3-Preference: Open Human-Annotated Preference Data across Diverse Tasks and Languages](https://arxiv.org//abs/2505.11475)

	Zhilin Wang, Jiaqi Zeng, Olivier Delalleau, Hoo-Chang Shin, Felipe Soares, Alexander Bukharin, Ellie Evans, Yi Dong, Oleksii Kuchaiev

+ [Ranked Voting based Self-Consistency of Large Language Models](https://arxiv.org//abs/2505.10772)

	Weiqin Wang, Yile Wang, Hui Huang

+ [Finetune-RAG: Fine-Tuning Language Models to Resist Hallucination in Retrieval-Augmented Generation](https://arxiv.org//abs/2505.10792)

	Zhan Peng Lee, Andre Lin, Calvin Tan

+ [Have Multimodal Large Language Models (MLLMs) Really Learned to Tell the Time on Analog Clocks?](https://arxiv.org//abs/2505.10862)

	Tairan Fu, Miguel González, Javier Conde, Elena Merino-Gómez, Pedro Reviriego

+ [Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents](https://arxiv.org//abs/2505.10936)

	Jiaxing Zhao, Hongbin Xie, Yuzhen Lei, Xuan Song, Zhuoran Shi, Lianxin Li, Shuangxue Liu, Haoran Zhang

+ [Accurate KV Cache Quantization with Outlier Tokens Tracing](https://arxiv.org//abs/2505.10938)

	Yi Su, Yuechi Zhou, Quantong Qiu, Juntao Li, Qingrong Xia, Ping Li, Xinyu Duan, Zhefeng Wang, Min Zhang

+ [The Way We Prompt: Conceptual Blending, Neural Dynamics, and Prompt-Induced Transitions in LLMs](https://arxiv.org//abs/2505.10948)

	Makoto Sato

+ [OntoURL: A Benchmark for Evaluating Large Language Models on Symbolic Ontological Understanding, Reasoning and Learning](https://arxiv.org//abs/2505.11031)

	Xiao Zhang, Huiyuan Lai, Qianru Meng, Johan Bos

+ [HAPO: Training Language Models to Reason Concisely via History-Aware Policy Optimization](https://arxiv.org//abs/2505.11225)

	Chengyu Huang, Zhengxin Zhang, Claire Cardie

+ [XtraGPT: LLMs for Human-AI Collaboration on Controllable Academic Paper Revision](https://arxiv.org//abs/2505.11336)

	Nuo Chen, Andre Lin HuiKai, Jiaying Wu, Junyi Hou, Zining Zhang, Qian Wang, Xidong Wang, Bingsheng He

+ [LegoSLM: Connecting LLM with Speech Encoder using CTC Posteriors](https://arxiv.org//abs/2505.11352)

	Rao Ma, Tongzhou Chen, Kartik Audhkhasi, Bhuvana Ramabhadran

+ [GuideBench: Benchmarking Domain-Oriented Guideline Following for LLM Agents](https://arxiv.org//abs/2505.11368)

	Lingxiao Diao, Xinyue Xu, Wanxuan Sun, Cheng Yang, Zhuosheng Zhang

+ [CARES: Comprehensive Evaluation of Safety and Adversarial Robustness in Medical LLMs](https://arxiv.org//abs/2505.11413)

	Sijia Chen, Xiaomin Li, Mengxue Zhang, Eric Hanchen Jiang, Qingcheng Zeng, Chen-Hsiang Yu

+ [When Thinking Fails: The Pitfalls of Reasoning for Instruction-Following in LLMs](https://arxiv.org//abs/2505.11423)

	Xiaomin Li, Zhou Yu, Zhiwei Zhang, Xupeng Chen, Ziji Zhang, Yingying Zhuang, Narayanan Sadagopan, Anurag Beniwal

+ [SoftCoT++: Test-Time Scaling with Soft Chain-of-Thought Reasoning](https://arxiv.org//abs/2505.11484)

	Yige Xu, Xu Guo, Zhiwei Zeng, Chunyan Miao

+ [LARGO: Latent Adversarial Reflection through Gradient Optimization for Jailbreaking LLMs](https://arxiv.org//abs/2505.10838)

	Ran Li, Hao Wang, Chengzhi Mao

+ [MPMA: Preference Manipulation Attack Against Model Context Protocol](https://arxiv.org//abs/2505.11154)

	Zihan Wang, Hongwei Li, Rui Zhang, Yu Liu, Wenbo Jiang, Wenshu Fan, Qingchuan Zhao, Guowen Xu

+ [On Next-Token Prediction in LLMs: How End Goals Determine the Consistency of Decoding Algorithms](https://arxiv.org//abs/2505.11183)

	Jacob Trauger, Ambuj Tewari

+ [EmotionHallucer: Evaluating Emotion Hallucinations in Multimodal Large Language Models](https://arxiv.org//abs/2505.11405)

	Bohao Xing, Xin Liu, Guoying Zhao, Chengyu Liu, Xiaolan Fu, Heikki Kälviäinen

+ [VISTA: Enhancing Vision-Text Alignment in MLLMs via Cross-Modal Mutual Information Maximization](https://arxiv.org//abs/2505.10917)

	Mingxiao Li, Na Su, Fang Qu, Zhizhou Zhong, Ziyang Chen, Zhaopeng Tu, Xiaolong Li

+ [Distilled Circuits: A Mechanistic Study of Internal Restructuring in Knowledge Distillation](https://arxiv.org//abs/2505.10822)

	Reilly Haskins, Benjamin Adams

+ [MergeBench: A Benchmark for Merging Domain-Specialized LLMs](https://arxiv.org//abs/2505.10833)

	Yifei He, Siqi Zeng, Yuzheng Hu, Rui Yang, Tong Zhang, Han Zhao

+ [AutoRAN: Weak-to-Strong Jailbreaking of Large Reasoning Models](https://arxiv.org//abs/2505.10846)

	Jiacheng Liang, Tanqiu Jiang, Yuhui Wang, Rongyi Zhu, Fenglong Ma, Ting Wang

+ [On DeepSeekMoE: Statistical Benefits of Shared Experts and Normalized Sigmoid Gating](https://arxiv.org//abs/2505.10860)

	Huy Nguyen, Thong T. Doan, Quang Pham, Nghi D. Q. Bui, Nhat Ho, Alessandro Rinaldo

+ [Improving the Data-efficiency of Reinforcement Learning by Warm-starting with LLM](https://arxiv.org//abs/2505.10861)

	Thang Duong, Minglai Yang, Chicheng Zhang

+ [Multi-Objective Preference Optimization: Improving Human Alignment of Generative Models](https://arxiv.org//abs/2505.10892)

	Akhil Agnihotri, Rahul Jain, Deepak Ramachandran, Zheng Wen

+ [SubGCache: Accelerating Graph-based RAG with Subgraph-level KV Cache](https://arxiv.org//abs/2505.10951)

	Qiuyu Zhu, Liang Zhang, Qianxiong Xu, Cheng Long, Jie Zhang

+ [ShiQ: Bringing back Bellman to LLMs](https://arxiv.org//abs/2505.11081)

	Pierre Clavier, Nathan Grinsztajn, Raphael Avalos, Yannis Flet-Berliac, Irem Ergun, Omar D. Domingues, Eugene Tarassov, Olivier Pietquin, Pierre H. Richemond, Florian Strub, Matthieu Geist

+ [Gaussian Weight Sampling for Scalable, Efficient and Stable Pseudo-Quantization Training](https://arxiv.org//abs/2505.11170)

	Myeonghwan Ahn, Sungjoo Yoo

+ [Memory-Efficient Orthogonal Fine-Tuning with Principal Subspace Adaptation](https://arxiv.org//abs/2505.11235)

	Fei Wu, Jia Hu, Geyong Min, Shiqiang Wang

+ [Delta Attention: Fast and Accurate Sparse Attention Inference by Delta Correction](https://arxiv.org//abs/2505.11254)

	Jeffrey Willette, Heejun Lee, Sung Ju Hwang

+ [Is Grokking a Computational Glass Relaxation?](https://arxiv.org//abs/2505.11411)

	Xiaotian Zhang, Yue Shang, Entao Yang, Ge Zhang

+ [MoE-CAP: Benchmarking Cost, Accuracy and Performance of Sparse Mixture-of-Experts Systems](https://arxiv.org//abs/2505.11415)

	Yinsicheng Jiang, Yao Fu, Yeqi Huang, Ping Nie, Zhan Lu, Leyang Xue, Congjie He, Man-Kit Sit, Jilong Xue, Li Dong, Ziming Miao, Dayou Du, Tairan Xu, Kai Zou, Edoardo Ponti, Luo Mai

+ [MegaScale-MoE: Large-Scale Communication-Efficient Training of Mixture-of-Experts Models in Production](https://arxiv.org//abs/2505.11432)

	Chao Jin, Ziheng Jiang, Zhihao Bai, Zheng Zhong, Juncai Liu, Xiang Li, Ningxin Zheng, Xi Wang, Cong Xie, Wen Heng, Yiyuan Ma, Wenlei Bao, Size Zheng, Yanghua Peng, Haibin Lin, Xuanzhe Liu, Xin Jin, Xin Liu

+ [TokenWeave: Efficient Compute-Communication Overlap for Distributed LLM Inference](https://arxiv.org//abs/2505.11329)

	Raja Gond, Nipun Kwatra, Ramachandran Ramjee

+ [ProxyPrompt: Securing System Prompts against Prompt Extraction Attacks](https://arxiv.org//abs/2505.11459)

	Zhixiong Zhuang, Maria-Irina Nicolae, Hui-Po Wang, Mario Fritz

+ [LLM Agents Are Hypersensitive to Nudges](https://arxiv.org//abs/2505.11584)

	Manuel Cherep, Pattie Maes, Nikhil Singh

+ [Probing the Vulnerability of Large Language Models to Polysemantic Interventions](https://arxiv.org//abs/2505.11611)

	Bofan Gong, Shiyang Lai, Dawn Song

+ [Using Reinforcement Learning to Train Large Language Models to Explain Human Decisions](https://arxiv.org//abs/2505.11614)

	Jian-Qiao Zhu, Hanbo Xie, Dilip Arumugam, Robert C. Wilson, Thomas L. Griffiths

+ [Benchmarking Spatiotemporal Reasoning in LLMs and Reasoning Models: Capabilities and Challenges](https://arxiv.org//abs/2505.11618)

	Pengrui Quan, Brian Wang, Kang Yang, Liying Han, Mani Srivastava

+ [DMN-Guided Prompting: A Low-Code Framework for Controlling LLM Behavior](https://arxiv.org//abs/2505.11701)

	Shaghayegh Abedi, Amin Jalali

+ [Rethinking Optimal Verification Granularity for Compute-Efficient Test-Time Scaling](https://arxiv.org//abs/2505.11730)

	Hao Mark Chen, Guanxi Lu, Yasuyuki Okoshi, Zhiwen Mo, Masato Motomura, Hongxiang Fan

+ [ACSE-Eval: Can LLMs threat model real-world cloud infrastructure?](https://arxiv.org//abs/2505.11565)

	Sarthak Munshi, Swapnil Pathak, Sonam Ghatode, Thenuga Priyadarshini, Dhivya Chandramouleeswaran, Ashutosh Rana

+ [InfiJanice: Joint Analysis and In-situ Correction Engine for Quantization-Induced Math Degradation in Large Language Models](https://arxiv.org//abs/2505.11574)

	Zhen Li, Yupeng Su, Songmiao Wang, Runming Yang, Congkai Xie, Aofan Liu, Ming Li, Jiannong Cao, Yuan Xie, Ngai Wong, Hongxia Yang

+ [Concept-Guided Interpretability via Neural Chunking](https://arxiv.org//abs/2505.11576)

	Shuchen Wu, Stephan Alaniz, Shyamgopal Karthik, Peter Dayan, Eric Schulz, Zeynep Akata

+ [The Ripple Effect: On Unforeseen Complications of Backdoor Attacks](https://arxiv.org//abs/2505.11586)

	Rui Zhang, Yun Shen, Hongwei Li, Wenbo Jiang, Hanxiao Chen, Yuan Zhang, Guowen Xu, Yang Zhang

+ [SageAttention3: Microscaling FP4 Attention for Inference and An Exploration of 8-Bit Training](https://arxiv.org//abs/2505.11594)

	Jintao Zhang, Jia Wei, Pengle Zhang, Xiaoming Xu, Haofeng Huang, Haoxu Wang, Kai Jiang, Jun Zhu, Jianfei Chen

+ [Spectral Policy Optimization: Coloring your Incorrect Reasoning in GRPO](https://arxiv.org//abs/2505.11595)

	Peter Chen, Xiaopeng Li, Ziniu Li, Xi Chen, Tianyi Lin

+ [Steering Risk Preferences in Large Language Models by Aligning Behavioral and Neural Representations](https://arxiv.org//abs/2505.11615)

	Jian-Qiao Zhu, Haijiang Yan, Thomas L. Griffiths

+ [Chatting with Papers: A Hybrid Approach Using LLMs and Knowledge Graphs](https://arxiv.org//abs/2505.11633)

	Vyacheslav Tykhonov, Han Yang, Philipp Mayr, Jetze Touber, Andrea Scharnhorst

+ [PeerGuard: Defending Multi-Agent Systems Against Backdoor Attacks Through Mutual Reasoning](https://arxiv.org//abs/2505.11642)

	Falong Fan, Xi Li

+ [EnvInjection: Environmental Prompt Injection Attack to Multi-modal Web Agents](https://arxiv.org//abs/2505.11717)

	Xilong Wang, John Bloch, Zedian Shao, Yuepeng Hu, Shuyan Zhou, Neil Zhenqiang Gong

+ [Efficient Uncertainty Estimation via Distillation of Bayesian Large Language Models](https://arxiv.org//abs/2505.11731)

	Harshil Vejendla, Haizhou Shi, Yibin Wang, Tunyu Zhang, Huan Zhang, Hao Wang

+ [Token-Level Uncertainty Estimation for Large Language Model Reasoning](https://arxiv.org//abs/2505.11737)

	Tunyu Zhang, Haizhou Shi, Yibin Wang, Hengyi Wang, Xiaoxiao He, Zhuowei Li, Haoxian Chen, Ligong Han, Kai Xu, Huan Zhang, Dimitris Metaxas, Hao Wang

+ [ZeroTuning: Unlocking the Initial Token's Power to Enhance Large Language Models Without Training](https://arxiv.org//abs/2505.11739)

	Feijiang Han, Xiaodong Yu, Jianheng Tang, Lyle Ungar

+ [Cloud-Based AI Systems: Leveraging Large Language Models for Intelligent Fault Detection and Autonomous Self-Healing](https://arxiv.org//abs/2505.11743)

	Cheng Ji, Huaiying Luo

+ [Talk to Your Slides: Efficient Slide Editing Agent with Large Language Models](https://arxiv.org//abs/2505.11604)

	Kyudan Jung, Hojun Cho, Jooyeol Yun, Jaehyeok Jang, Jagul Choo

+ [MedGUIDE: Benchmarking Clinical Decision-Making in Large Language Models](https://arxiv.org//abs/2505.11613)

	Xiaomin Li, Mingye Gao, Yuexing Hao, Taoran Li, Guangya Wan, Zihan Wang, Yijun Wang

+ [THELMA: Task Based Holistic Evaluation of Large Language Model Applications-RAG Question Answering](https://arxiv.org//abs/2505.11626)

	Udita Patel, Rutu Mulkar, Jay Roberts, Cibi Chakravarthy Senthilkumar, Sujay Gandhi, Xiaofei Zheng, Naumaan Nayyar, Rafael Castrillo

+ [Can an Easy-to-Hard Curriculum Make Reasoning Emerge in Small Language Models? Evidence from a Four-Stage Curriculum on GPT-2](https://arxiv.org//abs/2505.11643)

	Xiang Fu

+ [Ambiguity Resolution in Text-to-Structured Data Mapping](https://arxiv.org//abs/2505.11679)

	Zhibo Hu, Chen Wang, Yanfeng Shu, Hye-Young Paik, Liming Zhu

+ [MedCaseReasoning: Evaluating and learning diagnostic reasoning from clinical case reports](https://arxiv.org//abs/2505.11733)

	Kevin Wu, Eric Wu, Rahul Thapa, Kevin Wei, Angela Zhang, Arvind Suresh, Jacqueline J. Tao, Min Woo Sun, Alejandro Lozano, James Zou

+ [Masking in Multi-hop QA: An Analysis of How Language Models Perform with Context Permutation](https://arxiv.org//abs/2505.11754)

	Wenyu Huang, Pavlos Vougiouklis, Mirella Lapata, Jeff Z. Pan

+ [Reinforcement Learning Finetunes Small Subnetworks in Large Language Models](https://arxiv.org//abs/2505.11711)

	Sagnik Mukherjee, Lifan Yuan, Dilek Hakkani-Tur, Hao Peng

# 2025-05-15
+ [Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents](https://arxiv.org//abs/2505.09970)

	Mrinal Rawat, Ambuje Gupta, Rushil Goomer, Alessandro Di Bari, Neha Gupta, Roberto Pieraccini

+ [Leveraging Graph Retrieval-Augmented Generation to Support Learners' Understanding of Knowledge Concepts in MOOCs](https://arxiv.org//abs/2505.10074)

	Mohamed Abdelmagied, Mohamed Amine Chatti, Shoeb Joarder, Qurat Ul Ain, Rawaa Alatrash

+ [AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenge](https://arxiv.org//abs/2505.10468)

	Ranjan Sapkota, Konstantinos I. Roumeliotis, Manoj Karkee

+ [Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models](https://arxiv.org//abs/2505.10543)

	Annie Wong, Thomas Bäck, Aske Plaat, Niki van Stein, Anna V. Kononova

+ [Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks](https://arxiv.org//abs/2505.09901)

	Ziyuan Zhang, Darcy Wang, Ningyuan Chen, Rodrigo Mansur, Vahid Sarhangian

+ [Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph](https://arxiv.org//abs/2505.09945)

	Deeksha Prahlad, Chanhee Lee, Dongha Kim, Hokeun Kim

+ [Analysing Safety Risks in LLMs Fine-Tuned with Pseudo-Malicious Cyber Security Data](https://arxiv.org//abs/2505.09974)

	Adel ElZemity, Budi Arief, Shujun Li

+ [Dark LLMs: The Growing Threat of Unaligned AI Models](https://arxiv.org//abs/2505.10066)

	Michael Fire, Yitzhak Elbazis, Adi Wasenstein, Lior Rokach

+ [The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think](https://arxiv.org//abs/2505.10185)

	Seongyun Lee, Seungone Kim, Minju Seo, Yongrae Jo, Dongyoung Go, Hyeonbin Hwang, Jinho Park, Xiang Yue, Sean Welleck, Graham Neubig, Moontae Lee, Minjoon Seo

+ [Do LLMs Memorize Recommendation Datasets? A Preliminary Study on MovieLens-1M](https://arxiv.org//abs/2505.10212)

	Dario Di Palma, Felice Antonio Merra, Maurizio Sfilio, Vito Walter Anelli, Fedelucio Narducci, Tommaso Di Noia

+ [Comparing LLM Text Annotation Skills: A Study on Human Rights Violations in Social Media Data](https://arxiv.org//abs/2505.10260)

	Poli Apollinaire Nemkova, Solomon Ubani, Mark V. Albert

+ [Private Transformer Inference in MLaaS: A Survey](https://arxiv.org//abs/2505.10315)

	Yang Li, Xinyu Zhou, Yitong Wang, Liangxin Qian, Jun Zhao

+ [J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning](https://arxiv.org//abs/2505.10320)

	Chenxi Whitehouse, Tianlu Wang, Ping Yu, Xian Li, Jason Weston, Ilia Kulikov, Swarnadeep Saha

+ [AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents](https://arxiv.org//abs/2505.10321)

	Julius Henke

+ [FactsR: A Safer Method for Producing High Quality Healthcare Documentation](https://arxiv.org//abs/2505.10360)

	Victor Petrén Bach Hansen, Lasse Krogsbøll, Jonas Lyngsø, Mathias Baltzersen, Andreas Motzfeldt, Kevin Pelgrims, Lars Maaløe

+ [Are Large Language Models Robust in Understanding Code Against Semantics-Preserving Mutations?](https://arxiv.org//abs/2505.10443)

	Pedro Orvalho, Marta Kwiatkowska

+ [Superposition Yields Robust Neural Scaling](https://arxiv.org//abs/2505.10465)

	Yizhou liu, Ziming Liu, Jeff Gore

+ [Multi-Token Prediction Needs Registers](https://arxiv.org//abs/2505.10518)

	Anastasios Gerontopoulos, Spyros Gidaris, Nikos Komodakis

+ [Real-Time Out-of-Distribution Failure Prevention via Multi-Modal Reasoning](https://arxiv.org//abs/2505.10547)

	Milan Ganai, Rohan Sinha, Christopher Agia, Daniel Morton, Marco Pavone

+ [From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models](https://arxiv.org//abs/2505.09924)

	Yidan Wang, Yubing Ren, Yanan Cao, Binxing Fang

+ [Rethinking Prompt Optimizers: From Prompt Merits to Optimization](https://arxiv.org//abs/2505.09930)

	Zixiao Zhu, Hanzhang Zhou, Zijian Feng, Tianjiao Li, Chua Jia Jim Deryl, Mak Lee Onn, Gee Wah Ng, Kezhi Mao

+ [DIF: A Framework for Benchmarking and Verifying Implicit Bias in LLMs](https://arxiv.org//abs/2505.10013)

	Lake Yin, Fan Huang

+ [CAFE: Retrieval Head-based Coarse-to-Fine Information Seeking to Enhance Multi-Document QA Capability](https://arxiv.org//abs/2505.10063)

	Han Peng, Jinhao Jiang, Zican Dong, Wayne Xin Zhao, Lei Fang

+ [Designing and Contextualising Probes for African Languages](https://arxiv.org//abs/2505.10081)

	Wisdom Aduah, Francois Meyer

+ [XRAG: Cross-lingual Retrieval-Augmented Generation](https://arxiv.org//abs/2505.10089)

	Wei Liu, Sony Trenous, Leonardo F. R. Ribeiro, Bill Byrne, Felix Hieber

+ [What Does Neuro Mean to Cardio? Investigating the Role of Clinical Specialty Data in Medical LLMs](https://arxiv.org//abs/2505.10113)

	Xinlan Yan, Di Wu, Yibin Lei, Christof Monz, Iacer Calixto

+ [GE-Chat: A Graph Enhanced RAG Framework for Evidential Response Generation of LLMs](https://arxiv.org//abs/2505.10143)

	Longchao Da, Parth Mitesh Shah, Kuan-Ru Liou, Jiaxing Zhang, Hua Wei

+ [Mining Hidden Thoughts from Texts: Evaluating Continual Pretraining with Synthetic Data for LLM Reasoning](https://arxiv.org//abs/2505.10182)

	Yoichi Ishibashi, Taro Yano, Masafumi Oyamada

+ [VQ-Logits: Compressing the Output Bottleneck of Large Language Models via Vector Quantized Logits](https://arxiv.org//abs/2505.10202)

	Jintian Shao, Hongyi Huang, Jiayi Wu, YiMing Cheng, ZhiYu Wu, You Shan, MingKai Zheng

+ [RAIDEN-R1: Improving Role-awareness of LLMs via GRPO with Verifiable Reward](https://arxiv.org//abs/2505.10218)

	Zongsheng Wang, Kaili Sun, Bowen Wu, Qun Yu, Ying Li, Baoxun Wang

+ [Hierarchical Document Refinement for Long-context Retrieval-augmented Generation](https://arxiv.org//abs/2505.10413)

	Jiajie Jin, Xiaoxi Li, Guanting Dong, Yuyao Zhang, Yutao Zhu, Yongkang Wu, Zhonghua Li, Qi Ye, Zhicheng Dou

+ [CL-RAG: Bridging the Gap in Retrieval-Augmented Generation with Curriculum Learning](https://arxiv.org//abs/2505.10493)

	Shaohan Wang, Licheng Zhang, Zheren Fu, Zhendong Mao

+ [Can You Really Trust Code Copilots? Evaluating Large Language Models from a Code Security Perspective](https://arxiv.org//abs/2505.10494)

	Yutao Mou, Xiao Deng, Yuxiao Luo, Shikun Zhang, Wei Ye

+ [WorldPM: Scaling Human Preference Modeling](https://arxiv.org//abs/2505.10527)

	Binghai Wang, Runji Lin, Keming Lu, Le Yu, Zhenru Zhang, Fei Huang, Chujie Zheng, Kai Dang, Yang Fan, Xingzhang Ren, An Yang, Binyuan Hui, Dayiheng Liu, Tao Gui, Qi Zhang, Xuanjing Huang, Yu-Gang Jiang, Bowen Yu, Jingren Zhou, Junyang Lin

+ [Beyond 'Aha!': Toward Systematic Meta-Abilities Alignment in Large Reasoning Models](https://arxiv.org//abs/2505.10554)

	Zhiyuan Hu, Yibo Wang, Hanze Dong, Yuhui Xu, Amrita Saha, Caiming Xiong, Bryan Hooi, Junnan Li

+ [PIG: Privacy Jailbreak Attack on LLMs via Gradient-based Iterative In-Context Optimization](https://arxiv.org//abs/2505.09921)

	Yidan Wang, Yanan Cao, Yubing Ren, Fang Fang, Zheng Lin, Binxing Fang

+ [Parallel Scaling Law for Language Models](https://arxiv.org//abs/2505.10475)

	Mouxiang Chen, Binyuan Hui, Zeyu Cui, Jiaxi Yang, Dayiheng Liu, Jianling Sun, Junyang Lin, Zhongxin Liu

+ [RouteNator: A Router-Based Multi-Modal Architecture for Generating Synthetic Training Data for Function Calling LLMs](https://arxiv.org//abs/2505.10495)

	Vibha Belavadi, Tushar Vatsa, Dewang Sultania, Suhas Suresha, Ishita Verma, Cheng Chen, Tracy Holloway King, Michael Friedrich

+ [Exploring Implicit Visual Misunderstandings in Multimodal Large Language Models through Attention Analysis](https://arxiv.org//abs/2505.10541)

	Pengfei Wang, Guohai Xu, Weinong Wang, Junjie Yang, Jie Lou, Yunhua Xue

+ [ImagineBench: Evaluating Reinforcement Learning with Large Language Model Rollouts](https://arxiv.org//abs/2505.10010)

	Jing-Cheng Pang, Kaiyuan Li, Yidi Wang, Si-Hang Yang, Shengyi Jiang, Yang Yu

+ [Rethinking Circuit Completeness in Language Models: AND, OR, and ADDER Gates](https://arxiv.org//abs/2505.10039)

	Hang Chen, Jiaying Zhu, Xinyu Yang, Wenya Wang

+ [Informed Forecasting: Leveraging Auxiliary Knowledge to Boost LLM Performance on Time Series Forecasting](https://arxiv.org//abs/2505.10213)

	Mohammadmahdi Ghasemloo, Alireza Moradi

+ [SpecOffload: Unlocking Latent GPU Capacity for LLM Inference on Resource-Constrained Devices](https://arxiv.org//abs/2505.10259)

	Xiangwen Zhuge, Xu Shen, Zeyu Wang, Fan Dang, Xuan Ding, Danyang Li, Yahui Han, Tianxiang Hao, Zheng Yang

+ [Learning to Think: Information-Theoretic Reinforcement Fine-Tuning for LLMs](https://arxiv.org//abs/2505.10425)

	Jingyao Wang, Wenwen Qiang, Zeen Song, Changwen Zheng, Hui Xiong

+ [Interpretable Risk Mitigation in LLM Agent Systems](https://arxiv.org//abs/2505.10670)

	Jan Chojnacki

+ [Evaluations at Work: Measuring the Capabilities of GenAI in Use](https://arxiv.org//abs/2505.10742)

	Brandon Lepine, Gawesha Weerantunga, Juho Kim, Pamela Mishkin, Matthew Beane

+ [Code-Driven Planning in Grid Worlds with Large Language Models](https://arxiv.org//abs/2505.10749)

	Ashwath Vaithinathan Aravindan, Zhisheng Tang, Mayank Kejriwal

+ [LLM-Explorer: Towards Efficient and Affordable LLM-based Exploration for Mobile Apps](https://arxiv.org//abs/2505.10593)

	Shanhui Zhao, Hao Wen, Wenjie Du, Cheng Liang, Yunxin Liu, Xiaozhou Ye, Ye Ouyang, Yuanchun Li

+ [CRPE: Expanding The Reasoning Capability of Large Language Model for Code Generation](https://arxiv.org//abs/2505.10594)

	Ningxin Gui, Qianghuai Jia, Feijun Jiang, Yuling Jiao, dechun wang, Jerry Zhijian Yang

+ [Two Minds Better Than One: Collaborative Reward Modeling for LLM Alignment](https://arxiv.org//abs/2505.10597)

	Jiazheng Zhang, Wenqing Jing, Zizhuo Zhang, Zhiheng Xi, Shihan Dou, Rongxiang Weng, Jiahuan Li, Jingang Wang, MingXu Cai, Shibo Hong, Tao Gui, Qi Zhang

+ [Toward a Public and Secure Generative AI: A Comparative Analysis of Open and Closed LLMs](https://arxiv.org//abs/2505.10603)

	Jorge Machado

+ [Continuity and Isolation Lead to Doubts or Dilemmas in Large Language Models](https://arxiv.org//abs/2505.10606)

	Hector Pasten, Felipe Urrutia, Hector Jimenez, Cristian B. Calderon, Cristóbal Rojas, Alexander Kozachinskiy

+ [Agent Name Service (ANS): A Universal Directory for Secure AI Agent Discovery and Interoperability](https://arxiv.org//abs/2505.10609)

	Ken Huang, Vineeth Sai Narajala, Idan Habler, Akram Sheriff

+ [The Hitchhikers Guide to Production-ready Trustworthy Foundation Model powered Software (FMware)](https://arxiv.org//abs/2505.10640)

	Kirill Vasilevski, Benjamin Rombaut, Gopi Krishnan Rajbahadur, Gustavo A. Oliva, Keheliya Gallaba, Filipe R. Cogo, Jiahuei (Justina)Lin, Dayi Lin, Haoxiang Zhang, Bouyan Chen, Kishanthan Thangarajah, Ahmed E. Hassan, Zhen Ming (Jack)Jiang

+ [A Modular Approach for Clinical SLMs Driven by Synthetic Data with Pre-Instruction Tuning, Model Merging, and Clinical-Tasks Alignment](https://arxiv.org//abs/2505.10717)

	Jean-Philippe Corbeil, Amin Dada, Jean-Michel Attendu, Asma Ben Abacha, Alessandro Sordoni, Lucas Caccia, François Beaulieu, Thomas Lin, Jens Kleesiek, Paul Vozila

+ [Automating Security Audit Using Large Language Model based Agent: An Exploration Experiment](https://arxiv.org//abs/2505.10732)

	Jia Hui Chin, Pu Zhang, Yu Xin Cheong, Jonathan Pan

+ [Tracr-Injection: Distilling Algorithms into Pre-trained Language Models](https://arxiv.org//abs/2505.10719)

	Tomás Vergara-Browne, Álvaro Soto

+ [Model Performance-Guided Evaluation Data Selection for Effective Prompt Optimization](https://arxiv.org//abs/2505.10736)

	Ximing Dong, Shaowei Wang, Dayi Lin, Ahmed E. Hassan

+ [Mitigate Language Priors in Large Vision-Language Models by Cross-Images Contrastive Decoding](https://arxiv.org//abs/2505.10634)

	Jianfei Zhao, Feng Zhang, Xin Sun, Chong Feng

+ [SafeTrans: LLM-assisted Transpilation from C to Rust](https://arxiv.org//abs/2505.10708)

	Muhammad Farrukh (1), Smeet Shah (1), Baris Coskun (2), Michalis Polychronakis (1) ((1) Stony Brook University, (2) Amazon Web Services)

+ [On Technique Identification and Threat-Actor Attribution using LLMs and Embedding Models](https://arxiv.org//abs/2505.11547)

	Kyla Guru, Robert J. Moss, Mykel J. Kochenderfer

+ [One Shot Dominance: Knowledge Poisoning Attack on Retrieval-Augmented Generation Systems](https://arxiv.org//abs/2505.11548)

	Zhiyuan Chang, Xiaojun Jia, Mingyang Li, Junjie Wang, Yuekai Huang, Qing Wang, Ziyou Jiang, Yang Liu

+ [AI-generated Text Detection: A Multifaceted Approach to Binary and Multiclass Classification](https://arxiv.org//abs/2505.11550)

	Harika Abburi, Sanmitra Bhattacharya, Edward Bowen, Nirmala Pudota

+ [Assessing Collective Reasoning in Multi-Agent LLMs via Hidden Profile Tasks](https://arxiv.org//abs/2505.11556)

	Yuxuan Li, Aoi Naito, Hirokazu Shirado

+ [AC-LoRA: (Almost) Training-Free Access Control-Aware Multi-Modal LLMs](https://arxiv.org//abs/2505.11557)

	Lara Magdalena Lazier, Aritra Dhar, Vasilije Stambolic, Lukas Cavigelli

# 2025-05-14
+ [Reproducibility Study of "Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents"](https://arxiv.org//abs/2505.09289)

	Pedro M. P. Curvo, Mara Dragomir, Salvador Torpes, Mohammadmahdi Rahimi

+ [The Influence of Human-inspired Agentic Sophistication in LLM-driven Strategic Reasoners](https://arxiv.org//abs/2505.09396)

	Vince Trencsenyi, Agnieszka Mensfelt, Kostas Stathis

+ [Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?](https://arxiv.org//abs/2505.09614)

	Anthony GX-Chen, Dongyan Lin, Mandana Samiei, Doina Precup, Blake A. Richards, Rob Fergus, Kenneth Marino

+ [SALM: A Multi-Agent Framework for Language Model-Driven Social Network Simulation](https://arxiv.org//abs/2505.09081)

	Gaurav Koley

+ [CEC-Zero: Chinese Error Correction Solution Based on LLM](https://arxiv.org//abs/2505.09082)

	Sophie Zhang, Zhiming Lin

+ [Human-like Cognitive Generalization for Large Models via Brain-in-the-loop Supervision](https://arxiv.org//abs/2505.09085)

	Jiaxuan Chen, Yu Qi, Yueming Wang, Gang Pan

+ [Air-Ground Collaboration for Language-Specified Missions in Unknown Environments](https://arxiv.org//abs/2505.09108)

	Fernando Cladera, Zachary Ravichandran, Jason Hughes, Varun Murali, Carlos Nieto-Granda, M. Ani Hsieh, George J. Pappas, Camillo J. Taylor, Vijay Kumar

+ [ELIS: Efficient LLM Iterative Scheduling System with Response Length Predictor](https://arxiv.org//abs/2505.09142)

	Seungbeom Choi, Jeonghoe Goo, Eunjoo Jeon, Mingyu Yang, Minsung Jang

+ [Focus, Merge, Rank: Improved Question Answering Based on Semi-structured Knowledge Bases](https://arxiv.org//abs/2505.09246)

	Derian Boer, Stephen Roth, Stefan Kramer

+ [CXMArena: Unified Dataset to benchmark performance in realistic CXM Scenarios](https://arxiv.org//abs/2505.09436)

	Raghav Garg, Kapil Sharma, Karan Gupta

+ [Deploying Foundation Model-Enabled Air and Ground Robots in the Field: Challenges and Opportunities](https://arxiv.org//abs/2505.09477)

	Zachary Ravichandran, Fernando Cladera, Jason Hughes, Varun Murali, M. Ani Hsieh, George J. Pappas, Camillo J. Taylor, Vijay Kumar

+ [WorldView-Bench: A Benchmark for Evaluating Global Cultural Perspectives in Large Language Models](https://arxiv.org//abs/2505.09595)

	Abdullah Mushtaq, Imran Taj, Rafay Naeem, Ibrahim Ghaznavi, Junaid Qadir

+ [Atomic Consistency Preference Optimization for Long-Form Question Answering](https://arxiv.org//abs/2505.09039)

	Jingfeng Chen, Raghuveer Thirukovalluru, Junlin Wang, Kaiwei Luo, Bhuwan Dhingra

+ [A Comprehensive Analysis of Large Language Model Outputs: Similarity, Diversity, and Bias](https://arxiv.org//abs/2505.09056)

	Brandon Smith, Mohamed Reda Bouadjenek, Tahsin Alamgir Kheya, Phillip Dawson, Sunil Aryal

+ [Scent of Knowledge: Optimizing Search-Enhanced Reasoning with Information Foraging](https://arxiv.org//abs/2505.09316)

	Hongjin Qian, Zheng Liu

+ [Llama See, Llama Do: A Mechanistic Perspective on Contextual Entrainment and Distraction in LLMs](https://arxiv.org//abs/2505.09338)

	Jingcheng Niu, Xingdi Yuan, Tong Wang, Hamidreza Saghir, Amir H. Abdi

+ [Qwen3 Technical Report](https://arxiv.org//abs/2505.09388)

	An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, Chujie Zheng, Dayiheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao Ge, Haoran Wei, Huan Lin, Jialong Tang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jing Zhou, Jingren Zhou, Junyang Lin, Kai Dang, Keqin Bao, Kexin Yang, Le Yu, Lianghao Deng, Mei Li, Mingfeng Xue, Mingze Li, Pei Zhang, Peng Wang, Qin Zhu, Rui Men, Ruize Gao, Shixuan Liu, Shuang Luo, Tianhao Li, Tianyi Tang, Wenbiao Yin, Xingzhang Ren, Xinyu Wang, Xinyu Zhang, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yinger Zhang, Yu Wan, Yuqiong Liu, Zekun Wang, Zeyu Cui, Zhenru Zhang, Zhipeng Zhou, Zihan Qiu

+ [PT-MoE: An Efficient Finetuning Framework for Integrating Mixture-of-Experts into Prompt Tuning](https://arxiv.org//abs/2505.09519)

	Zongqian Li, Yixuan Su, Nigel Collier

+ [Ornithologist: Towards Trustworthy "Reasoning" about Central Bank Communications](https://arxiv.org//abs/2505.09083)

	Dominic Zaun Eu Jones

+ [FaceShield: Explainable Face Anti-Spoofing with Multimodal Large Language Models](https://arxiv.org//abs/2505.09415)

	Hongyang Wang, Yichen Shi, Zhuofu Tao, Yuhao Gao, Liepiao Zhang, Xun Lin, Jun Feng, Xiaochen Yuan, Zitong Yu, Xiaochun Cao

+ [SafePath: Conformal Prediction for Safe LLM-Based Autonomous Navigation](https://arxiv.org//abs/2505.09427)

	Achref Doula, Max Mühläuser, Alejandro Sanchez Guinea

+ [Layered Unlearning for Adversarial Relearning](https://arxiv.org//abs/2505.09500)

	Timothy Qian, Vinith Suriyakumar, Ashia Wilson, Dylan Hadfield-Menell

+ [Adversarial Suffix Filtering: a Defense Pipeline for LLMs](https://arxiv.org//abs/2505.09602)

	David Khachaturov, Robert Mullins

+ [Instantiating Standards: Enabling Standard-Driven Text TTP Extraction with Evolvable Memory](https://arxiv.org//abs/2505.09261)

	Cheng Meng, ZhengWei Jiang, QiuYun Wang, XinYi Li, ChunYan Ma, FangMing Dong, FangLi Ren, BaoXu Liu

+ [A Multimodal Multi-Agent Framework for Radiology Report Generation](https://arxiv.org//abs/2505.09787)

	Ziruo Yi, Ting Xiao, Mark V. Albert

+ [System Prompt Optimization with Meta-Learning](https://arxiv.org//abs/2505.09666)

	Yumin Choi, Jinheon Baek, Sung Ju Hwang

+ [Achieving Tokenizer Flexibility in Language Models through Heuristic Adaptation and Supertoken Learning](https://arxiv.org//abs/2505.09738)

	Shaurya Sharthak, Vinayak Pahalwan, Adithya Kamath, Adarsh Shirawalmath

+ [Trustless Autonomy: Understanding Motivations, Benefits and Governance Dilemma in Self-Sovereign Decentralized AI Agents](https://arxiv.org//abs/2505.09757)

	Botao Amber Hu, Yuhan Liu, Helena Rong

+ [Exploring the generalization of LLM truth directions on conversational formats](https://arxiv.org//abs/2505.09807)

	Timour Ichmoukhamedov, David Martens

+ [Evaluating Large Language Models for the Generation of Unit Tests with Equivalence Partitions and Boundary Values](https://arxiv.org//abs/2505.09830)

	Martín Rodríguez, Gustavo Rossi, Alejandro Fernandez

+ [Do Large Language Models Know Conflict? Investigating Parametric vs. Non-Parametric Knowledge of LLMs for Conflict Forecasting](https://arxiv.org//abs/2505.09852)

	Apollinaire Poli Nemkova, Sarath Chandra Lingareddy, Sagnik Ray Choudhury, Mark V. Albert

+ [DRA-GRPO: Exploring Diversity-Aware Reward Adjustment for R1-Zero-Like Training of Large Language Models](https://arxiv.org//abs/2505.09655)

	Xiwen Chen, Wenhui Zhu, Peijie Qiu, Xuanzhao Dong, Hao Wang, Haiyu Wu, Huayu Li, Aristeidis Sotiras, Yalin Wang, Abolfazl Razi

+ [Large Language Models Are More Persuasive Than Incentivized Human Persuaders](https://arxiv.org//abs/2505.09662)

	Philipp Schoenegger, Francesco Salvi, Jiacheng Liu, Xiaoli Nan, Ramit Debnath, Barbara Fasolo, Evelina Leivada, Gabriel Recchia, Fritz Günther, Ali Zarifhonarvar, Joe Kwon, Zahoor Ul Islam, Marco Dehnert, Daryl Y. H. Lee, Madeline G. Reinecke, David G. Kamper, Mert Kobaş, Adam Sandford, Jonas Kgomo, Luke Hewitt, Shreya Kapoor, Kerem Oktar, Eyup Engin Kucuk, Bo Feng, Cameron R. Jones, Izzy Gainsburg, Sebastian Olschewski, Nora Heinzelmann, Francisco Cruz, Ben M. Tappin, Tao Ma, Peter S. Park, Rayan Onyonka, Arthur Hjorth, Peter Slattery, Qingcheng Zeng, Lennart Finke, Igor Grossmann, Alessandro Salatiello, Ezra Karger

+ [VeriFact: Enhancing Long-Form Factuality Evaluation with Refined Fact Extraction and Reference Facts](https://arxiv.org//abs/2505.09701)

	Xin Liu, Lechen Zhang, Sheza Munir, Yiyang Gu, Lu Wang

+ [LAS: Loss-less ANN-SNN Conversion for Fully Spike-Driven Large Language Models](https://arxiv.org//abs/2505.09659)

	Long Chen, Xiaotian Song, Yanan Sun

+ [Analog Foundation Models](https://arxiv.org//abs/2505.09663)

	Julian Büchel, Iason Chalas, Giovanni Acampa, An Chen, Omobayode Fagbohungbe, Sidney Tsai, Kaoutar El Maghraoui, Manuel Le Gallo, Abbas Rahimi, Abu Sebastian

+ [Adversarial Attack on Large Language Models using Exponentiated Gradient Descent](https://arxiv.org//abs/2505.09820)

	Sajib Biswas, Mao Nishino, Samuel Jacob Chacko, Xiuwen Liu

+ [Understanding Gen Alpha Digital Language: Evaluation of LLM Safety Systems for Content Moderation](https://arxiv.org//abs/2505.10588)

	Manisha Mehta, Fausto Giunchiglia

+ [Towards Automated Situation Awareness: A RAG-Based Framework for Peacebuilding Reports](https://arxiv.org//abs/2505.10586)

	Poli A. Nemkova, Suleyman O. Polat, Rafid I. Jahan, Sagnik Ray Choudhury, Sun-joo Lee, Shouryadipta Sarkar, Mark V. Albert

+ [TARGET: Benchmarking Table Retrieval for Generative Tasks](https://arxiv.org//abs/2505.11545)

	Xingyu Ji, Parker Glenn, Aditya G. Parameswaran, Madelon Hulsebos

+ [MorphMark: Flexible Adaptive Watermarking for Large Language Models](https://arxiv.org//abs/2505.11541)

	Zongqi Wang, Tianle Gu, Baoyuan Wu, Yujiu Yang

# 2025-05-13
+ [Lost in Transmission: When and Why LLMs Fail to Reason Globally](https://arxiv.org//abs/2505.08140)

	Tobias Schnabel, Kiran Tomlinson, Adith Swaminathan, Jennifer Neville

+ [Evaluating LLM Metrics Through Real-World Capabilities](https://arxiv.org//abs/2505.08253)

	Justin K Miller, Wenjia Tang

+ [Learning Like Humans: Advancing LLM Reasoning Capabilities via Adaptive Difficulty Curriculum Learning and Expert-Guided Self-Reformulation](https://arxiv.org//abs/2505.08364)

	Enci Zhang, Xingang Yan, Wei Lin, Tianxiang Zhang, Qianchun Lu

+ [Agent-as-a-Service based on Agent Network](https://arxiv.org//abs/2505.08446)

	Yuhan Zhu, Haojie Liu, Jian Wang, Bing Li, Zikang Yin, Yefei Liao

+ [Strategy-Augmented Planning for Large Language Models via Opponent Exploitation](https://arxiv.org//abs/2505.08459)

	Shuai Xu, Sijia Cui, Yanna Wang, Bo Xu, Qi Wang

+ [Achieving Scalable Robot Autonomy via neurosymbolic planning using lightweight local LLM](https://arxiv.org//abs/2505.08492)

	Nicholas Attolino, Alessio Capitanelli, Fulvio Mastrogiovanni

+ [TrialMatchAI: An End-to-End AI-powered Clinical Trial Recommendation System to Streamline Patient-to-Trial Matching](https://arxiv.org//abs/2505.08508)

	Majd Abdallah, Sigve Nakken, Mariska Bierkens, Johanna Galvis, Alexis Groppi, Slim Karkar, Lana Meiqari, Maria Alexandra Rujano, Steve Canham, Rodrigo Dienstmann, Remond Fijneman, Eivind Hovig, Gerrit Meijer, Macha Nikolski

+ [Guiding LLM-based Smart Contract Generation with Finite State Machine](https://arxiv.org//abs/2505.08542)

	Hao Luo, Yuhao Lin, Xiao Yan, Xintong Hu, Yuxiang Wang, Qiming Zeng, Hao Wang, Jiawei Jiang

+ [Resource-Efficient Language Models: Quantization for Fast and Accessible Inference](https://arxiv.org//abs/2505.08620)

	Tollef Emil Jørgensen

+ [TRAIL: Trace Reasoning and Agentic Issue Localization](https://arxiv.org//abs/2505.08638)

	Darshan Deshpande, Varun Gangal, Hersh Mehta, Jitin Krishnan, Anand Kannappan, Rebecca Qian

+ [WixQA: A Multi-Dataset Benchmark for Enterprise Retrieval-Augmented Generation](https://arxiv.org//abs/2505.08643)

	Dvir Cohen, Lin Burg, Sviatoslav Pykhnivskyi, Hagit Gur, Stanislav Kovynov, Olga Atzmon, Gilad Barkan

+ [LLM-based Prompt Ensemble for Reliable Medical Entity Recognition from EHRs](https://arxiv.org//abs/2505.08704)

	K M Sajjadul Islam, Ayesha Siddika Nipu, Jiawei Wu, Praveen Madiraju

+ [ALOHA: Empowering Multilingual Agent for University Orientation with Hierarchical Retrieval](https://arxiv.org//abs/2505.08130)

	Mingxu Tao, Bowen Tang, Mingxuan Ma, Yining Zhang, Hourun Li, Feifan Wen, Hao Ma, Jia Yang

+ [A Large-Scale Empirical Analysis of Custom GPTs' Vulnerabilities in the OpenAI Ecosystem](https://arxiv.org//abs/2505.08148)

	Sunday Oyinlola Ogundoyin, Muhammad Ikram, Hassan Jameel Asghar, Benjamin Zi Hao Zhao, Dali Kaafar

+ [Fusing Bidirectional Chains of Thought and Reward Mechanisms A Method for Enhancing Question-Answering Capabilities of Large Language Models for Chinese Intangible Cultural Heritage](https://arxiv.org//abs/2505.08167)

	Ruilin Liu, Zhixiao Zhao, Jieqiong Li, Chang Liu, Dongbo Wang

+ [A Head to Predict and a Head to Question: Pre-trained Uncertainty Quantification Heads for Hallucination Detection in LLM Outputs](https://arxiv.org//abs/2505.08200)

	Artem Shelmanov, Ekaterina Fadeeva, Akim Tsvigun, Ivan Tsvigun, Zhuohan Xie, Igor Kiselev, Nico Daheim, Caiqi Zhang, Artem Vazhentsev, Mrinmaya Sachan, Preslav Nakov, Timothy Baldwin

+ [Large Language Model Psychometrics: A Systematic Review of Evaluation, Validation, and Enhancement](https://arxiv.org//abs/2505.08245)

	Haoran Ye, Jing Jin, Yuhang Xie, Xin Zhang, Guojie Song

+ [Enhancing Cache-Augmented Generation (CAG) with Adaptive Contextual Compression for Scalable Knowledge Integration](https://arxiv.org//abs/2505.08261)

	Rishabh Agrawal, Himanshu Kumar

+ [LLM Enhancers for GNNs: An Analysis from the Perspective of Causal Mechanism Identification](https://arxiv.org//abs/2505.08265)

	Hang Gao, Wenxuan Huang, Fengge Wu, Junsuo Zhao, Changwen Zheng, Huaping Liu

+ [Accelerating Chain-of-Thought Reasoning: When Goal-Gradient Importance Meets Dynamic Skipping](https://arxiv.org//abs/2505.08392)

	Ren Zhuang, Ben Wang, Shuifa Sun

+ [Optimizing Retrieval-Augmented Generation: Analysis of Hyperparameter Impact on Performance and Efficiency](https://arxiv.org//abs/2505.08445)

	Adel Ammar, Anis Koubaa, Omer Nacar, Wadii Boulila

+ [RepCali: High Efficient Fine-tuning Via Representation Calibration in Latent Space for Pre-trained Language Models](https://arxiv.org//abs/2505.08463)

	Fujun Zhang, XiangDong Su

+ [LCES: Zero-shot Automated Essay Scoring via Pairwise Comparisons Using Large Language Models](https://arxiv.org//abs/2505.08498)

	Takumi Shibata, Yuichi Miyamura

+ [The Truth Becomes Clearer Through Debate! Multi-Agent Systems with Large Language Models Unmask Fake News](https://arxiv.org//abs/2505.08532)

	Yuhan Liu, Yuxuan Liu, Xiaoqing Zhang, Xiuying Chen, Rui Yan

+ [PWC-MoE: Privacy-Aware Wireless Collaborative Mixture of Experts](https://arxiv.org//abs/2505.08719)

	Yang Su, Na Yan, Yansha Deng, Robert Schober

+ [Memorization-Compression Cycles Improve Generalization](https://arxiv.org//abs/2505.08727)

	Fangyuan Yu

+ [Securing RAG: A Risk Assessment and Mitigation Framework](https://arxiv.org//abs/2505.08728)

	Lukas Ammann, Sara Ott, Christoph R. Landolt, Marco P. Lehmann

+ [CodePDE: An Inference Framework for LLM-driven PDE Solver Generation](https://arxiv.org//abs/2505.08783)

	Shanda Li, Tanya Marwah, Junhong Shen, Weiwei Sun, Andrej Risteski, Yiming Yang, Ameet Talwalkar

+ [Evaluating the Effectiveness of Black-Box Prompt Optimization as the Scale of LLMs Continues to Grow](https://arxiv.org//abs/2505.08303)

	Ziyu Zhou, Yihang Wu, Jingyuan Yang, Zhan Xiao, Rongjun Li

+ [On the Geometry of Semantics in Next-token Prediction](https://arxiv.org//abs/2505.08348)

	Yize Zhao, Christos Thrampoulidis

+ [Alignment Drift in CEFR-prompted LLMs for Interactive Spanish Tutoring](https://arxiv.org//abs/2505.08351)

	Mina Almasi, Ross Deans Kristensen-McLachlan

+ [Towards Contamination Resistant Benchmarks](https://arxiv.org//abs/2505.08389)

	Rahmatullah Musawi, Sheng Lu

+ [Enhancing Thyroid Cytology Diagnosis with RAG-Optimized LLMs and Pa-thology Foundation Models](https://arxiv.org//abs/2505.08590)

	Hussien Al-Asi, Jordan P Reynolds, Shweta Agarwal, Bryan J Dangott, Aziza Nassar, Zeynettin Akkus

+ [Automatic Task Detection and Heterogeneous LLM Speculative Decoding](https://arxiv.org//abs/2505.08600)

	Danying Ge, Jianhua Gao, Qizhi Jiang, Yifei Feng, Weixing Ji

+ [Scaling Context, Not Parameters: Training a Compact 7B Language Model for Efficient Long-Context Processing](https://arxiv.org//abs/2505.08651)

	Chen Wu, Yin Song

+ [Revealing economic facts: LLMs know more than they say](https://arxiv.org//abs/2505.08662)

	Marcus Buckmann, Quynh Anh Nguyen, Edward Hill

+ [Adaptive Schema-aware Event Extraction with Retrieval-Augmented Generation](https://arxiv.org//abs/2505.08690)

	Sheng Liang, Hang Lv, Zhihao Wen, Yaxiong Wu, Yongyue Zhang, Hao Wang, Yong Liu

+ [NurValues: Real-World Nursing Values Evaluation for Large Language Models in Clinical Context](https://arxiv.org//abs/2505.08734)

	Ben Yao, Qiuchi Li, Yazhou Zhang, Siyu Yang, Bohan Zhang, Prayag Tiwari, Jing Qin

+ [Probability Consistency in Large Language Models: Theoretical Foundations Meet Empirical Discrepancies](https://arxiv.org//abs/2505.08739)

	Xiaoliang Luo, Xinyi Xu, Michael Ramscar, Bradley C. Love

+ [AC-Reason: Towards Theory-Guided Actual Causality Reasoning with Large Language Models](https://arxiv.org//abs/2505.08750)

	Yanxi Zhang, Xin Cong, Zhong Zhang, Xiao Liu, Dongyan Zhao, Yesai Wu

+ [InfoPO: On Mutual Information Maximization for Large Language Model Alignment](https://arxiv.org//abs/2505.08507)

	Teng Xiao, Zhen Ge, Sujay Sanghavi, Tian Wang, Julian Katz-Samuels, Marc Versage, Qingjun Cui, Trishul Chilimbi

+ [LM-Scout: Analyzing the Security of Language Model Integration in Android Apps](https://arxiv.org//abs/2505.08204)

	Muhammad Ibrahim (1), Gűliz Seray Tuncay (2), Z. Berkay Celik (3), Aravind Machiry (3), Antonio Bianchi (3) ((1) Georgia Institute of Technology, (2) Google, (3) Purdue University)

+ [Grounding Synthetic Data Evaluations of Language Models in Unsupervised Document Corpora](https://arxiv.org//abs/2505.08905)

	Michael Majurski, Cynthia Matuszek

+ [Automated Meta Prompt Engineering for Alignment with the Theory of Mind](https://arxiv.org//abs/2505.09024)

	Aaron Baughman, Rahul Agarwal, Eduardo Morales, Gozde Akay

+ [Improving the Reliability of LLMs: Combining CoT, RAG, Self-Consistency, and Self-Verification](https://arxiv.org//abs/2505.09031)

	Adarsh Kumar, Hwiyoon Kim, Jawahar Sai Nathani, Neil Roy

+ [Federated Large Language Models: Feasibility, Robustness, Security and Future Directions](https://arxiv.org//abs/2505.08830)

	Wenhao Jiang, Yuchuan Luo, Guilin Deng, Silong Chen, Xu Yang, Shihong Wu, Xinwen Gao, Lin Liu, Shaojing Fu

+ [CellTypeAgent: Trustworthy cell type annotation with Large Language Models](https://arxiv.org//abs/2505.08844)

	Jiawen Chen, Jianghao Zhang, Huaxiu Yao, Yun Li

+ [Improved Algorithms for Differentially Private Language Model Alignment](https://arxiv.org//abs/2505.08849)

	Keyu Chen, Hao Tang, Qinglin Liu, Yizhao Xu

+ [Optimized Couplings for Watermarking Large Language Models](https://arxiv.org//abs/2505.08878)

	Dor Tsur, Carol Xuan Long, Claudio Mayrink Verdun, Hsiang Hsu, Haim Permuter, Flavio P. Calmon

+ [Tests as Prompt: A Test-Driven-Development Benchmark for LLM Code Generation](https://arxiv.org//abs/2505.09027)

	Yi Cui

+ [LibVulnWatch: A Deep Assessment Agent System and Leaderboard for Uncovering Hidden Vulnerabilities in Open-Source AI Libraries](https://arxiv.org//abs/2505.08842)

	Zekun Wu, Seonglae Cho, Umar Mohammed, Cristian Munoz, Kleyton Costa, Xin Guan, Theo King, Ze Wang, Emre Kazim, Adriano Koshiyama

# 2025-05-12
+ [How well do LLMs reason over tabular data, really?](https://arxiv.org//abs/2505.07453)

	Cornelius Wolff, Madelon Hulsebos

+ [A Survey on Collaborative Mechanisms Between Large and Small Language Models](https://arxiv.org//abs/2505.07460)

	Yi Chen, JiaHao Zhao, HaoHao Han

+ [Web-Bench: A LLM Code Benchmark Based on Web Standards and Frameworks](https://arxiv.org//abs/2505.07473)

	Kai Xu, YiWei Mao, XinYi Guan, ZiLong Feng

+ [QuantX: A Framework for Hardware-Aware Quantization of Generative AI Workloads](https://arxiv.org//abs/2505.07531)

	Khurram Mazher, Saad Bin Nasir

+ [S-GRPO: Early Exit via Reinforcement Learning in Reasoning Models](https://arxiv.org//abs/2505.07686)

	Muzhi Dai, Chenxu Yang, Qingyi Si

+ [Belief Injection for Epistemic Control in Linguistic State Space](https://arxiv.org//abs/2505.07693)

	Sebastian Dumbrava

+ [Agent RL Scaling Law: Agent RL with Spontaneous Code Execution for Mathematical Problem Solving](https://arxiv.org//abs/2505.07773)

	Xinji Mai, Haotian Xu, Xing W, Weinong Wang, Yingying Zhang, Wenqiang Zhang

+ [DynamicRAG: Leveraging Outputs of Large Language Model as Feedback for Dynamic Reranking in Retrieval-Augmented Generation](https://arxiv.org//abs/2505.07233)

	Jiashuo Sun, Xianrui Zhong, Sizhe Zhou, Jiawei Han

+ [UAV-CodeAgents: Scalable UAV Mission Planning via Multi-Agent ReAct and Vision-Language Reasoning](https://arxiv.org//abs/2505.07236)

	Oleg Sautenkov, Yasheerah Yaqoot, Muhammad Ahsan Mustafa, Faryal Batool, Jeffrin Sam, Artem Lykov, Chih-Yung Wen, Dzmitry Tsetserukou

+ [Comet: Accelerating Private Inference for Large Language Model by Predicting Activation Sparsity](https://arxiv.org//abs/2505.07239)

	Guang Yan, Yuhui Zhang, Zimu Guo, Lutan Zhao, Xiaojun Chen, Chen Wang, Wenhao Wang, Dan Meng, Rui Hou

+ [SAS-Bench: A Fine-Grained Benchmark for Evaluating Short Answer Scoring with Large Language Models](https://arxiv.org//abs/2505.07247)

	Peichao Lai, Kexuan Zhang, Yi Lin, Linyihan Zhang, Feiyang Ye, Jinhao Yan, Yanwei Xu, Conghui He, Yilei Wang, Wentao Zhang, Bin Cui

+ [No Query, No Access](https://arxiv.org//abs/2505.07258)

	Wenqiang Wang, Siyuan Liang, Yangshijie Zhang, Xiaojun Jia, Hao Lin, Xiaochun Cao

+ [UMoE: Unifying Attention and FFN with Shared Experts](https://arxiv.org//abs/2505.07260)

	Yuanhang Yang, Chaozheng Wang, Jing Li

+ [On the Robustness of Reward Models for Language Model Alignment](https://arxiv.org//abs/2505.07271)

	Jiwoo Hong, Noah Lee, Eunki Kim, Guijin Son, Woojin Chung, Aman Gupta, Shao Tang, James Thorne

+ [Semantic Retention and Extreme Compression in LLMs: Can We Have Both?](https://arxiv.org//abs/2505.07289)

	Stanislas Laborde, Martin Cousseau, Antoun Yaacoub, Lionel Prevost

+ [Towards Multi-Agent Reasoning Systems for Collaborative Expertise Delegation: An Exploratory Design Study](https://arxiv.org//abs/2505.07313)

	Baixuan Xu, Chunyang Li, Weiqi Wang, Wei Fan, Tianshi Zheng, Haochen Shi, Tao Fan, Yangqiu Song, Qiang Yang

+ [Synthetic Code Surgery: Repairing Bugs and Vulnerabilities with LLMs and Synthetic Data](https://arxiv.org//abs/2505.07372)

	David de-Fitero-Dominguez, Antonio Garcia-Cabot, Eva Garcia-Lopez

+ [LEAD: Iterative Data Selection for Efficient LLM Instruction Tuning](https://arxiv.org//abs/2505.07437)

	Xiaotian Lin, Yanlin Qi, Yizhang Zhu, Themis Palpanas, Chengliang Chai, Nan Tang, Yuyu Luo

+ [Can Generative AI agents behave like humans? Evidence from laboratory market experiments](https://arxiv.org//abs/2505.07457)

	R. Maria del Rio-Chanona, Marco Pangallo, Cars Hommes

+ [ToolACE-DEV: Self-Improving Tool Learning via Decomposition and EVolution](https://arxiv.org//abs/2505.07512)

	Xu Huang, Weiwen Liu, Xingshan Zeng, Yuefeng Huang, Xinlong Hao, Yuxian Wang, Yirong Zeng, Chuhan Wu, Yasheng Wang, Ruiming Tang, Defu Lian

+ [GRADA: Graph-based Reranker against Adversarial Documents Attack](https://arxiv.org//abs/2505.07546)

	Jingjie Zheng, Aryo Pradipta Gema, Giwon Hong, Xuanli He, Pasquale Minervini, Youcheng Sun, Qiongkai Xu

+ [Towards Requirements Engineering for RAG Systems](https://arxiv.org//abs/2505.07553)

	Tor Sporsem, Rasmus Ulfsnes

+ [A Multi-Dimensional Constraint Framework for Evaluating and Improving Instruction Following in Large Language Models](https://arxiv.org//abs/2505.07591)

	Junjie Ye, Caishuang Huang, Zhuohan Chen, Wenjie Fu, Chenyuan Yang, Leyi Yang, Yilong Wu, Peng Wang, Meng Zhou, Xiaolong Yang, Tao Gui, Qi Zhang, Zhongchao Shi, Jianping Fan, Xuanjing Huang

+ [Reinforced Internal-External Knowledge Synergistic Reasoning for Efficient Adaptive Search Agent](https://arxiv.org//abs/2505.07596)

	Ziyang Huang, Xiaowei Yuan, Yiming Ju, Jun Zhao, Kang Liu

+ [MiMo: Unlocking the Reasoning Potential of Language Model -- From Pretraining to Posttraining](https://arxiv.org//abs/2505.07608)

	Xiaomi LLM-Core Team: Bingquan Xia, Bowen Shen, Cici, Dawei Zhu, Di Zhang, Gang Wang, Hailin Zhang, Huaqiu Liu, Jiebao Xiao, Jinhao Dong, Liang Zhao, Peidian Li, Peng Wang, Shihua Yu, Shimao Chen, Weikun Wang, Wenhan Ma, Xiangwei Deng, Yi Huang, Yifan Song, Zihan Jiang, Bowen Ye, Can Cai, Chenhong He, Dong Zhang, Duo Zhang, Guoan Wang, Hao Tian, Haochen Zhao, Heng Qu, Hongshen Xu, Jun Shi, Kainan Bao, QingKai Fang, Kang Zhou, Kangyang Zhou, Lei Li, Menghang Zhu, Nuo Chen, Qiantong Wang, Shaohui Liu, Shicheng Li, Shuhao Gu, Shuhuai Ren, Shuo Liu, Sirui Deng, Weiji Zhuang, Weiwei Lv, Wenyu Yang, Xin Zhang, Xing Yong, Xing Zhang, Xingchen Song, Xinzhe Xu, Xu Wang, Yihan Yan, Yu Tu, Yuanyuan Tian, Yudong Wang, Yue Yu, Zhenru Lin, Zhichao Song, Zihao Yue

+ [Concept-Level Explainability for Auditing & Steering LLM Responses](https://arxiv.org//abs/2505.07610)

	Kenza Amara, Rita Sevastjanova, Mennatallah El-Assady

+ [Chronocept: Instilling a Sense of Time in Machines](https://arxiv.org//abs/2505.07637)

	Krish Goel, Sanskar Pandey, KS Mahadevan, Harsh Kumar, Vishesh Khadaria

+ [Benchmarking Retrieval-Augmented Generation for Chemistry](https://arxiv.org//abs/2505.07671)

	Xianrui Zhong, Bowen Jin, Siru Ouyang, Yanzhen Shen, Qiao Jin, Yin Fang, Zhiyong Lu, Jiawei Han

+ [OnPrem.LLM: A Privacy-Conscious Document Intelligence Toolkit](https://arxiv.org//abs/2505.07672)

	Arun S. Maiya

+ [Overflow Prevention Enhances Long-Context Recurrent LLMs](https://arxiv.org//abs/2505.07793)

	Assaf Ben-Kish, Itamar Zimerman, M. Jehanzeb Mirza, James Glass, Leonid Karlinsky, Raja Giryes

+ [Structural Entropy Guided Agent for Detecting and Repairing Knowledge Deficiencies in LLMs](https://arxiv.org//abs/2505.07184)

	Yifan Wei, Xiaoyan Yu, Tengfei Pan, Angsheng Li, Li Du

+ [Benchmarking Ethical and Safety Risks of Healthcare LLMs in China-Toward Systemic Governance under Healthy China 2030](https://arxiv.org//abs/2505.07205)

	Mouxiao Bian, Rongzhao Zhang, Chao Ding, Xinwei Peng, Jie Xu

+ [AttentionInfluence: Adopting Attention Head Influence for Weak-to-Strong Pretraining Data Selection](https://arxiv.org//abs/2505.07293)

	Kai Hua, Steven Wu, Ge Zhang, Ke Shen

+ [SEReDeEP: Hallucination Detection in Retrieval-Augmented Models via Semantic Entropy and Context-Parameter Fusion](https://arxiv.org//abs/2505.07528)

	Lei Wang

+ [Spoken Language Understanding on Unseen Tasks With In-Context Learning](https://arxiv.org//abs/2505.07731)

	Neeraj Agrawal, Sriram Ganapathy

+ [Domain Regeneration: How well do LLMs match syntactic properties of text domains?](https://arxiv.org//abs/2505.07784)

	Da Ju, Hagen Blix, Adina Williams

+ [Learning from Peers in Reasoning Models](https://arxiv.org//abs/2505.07787)

	Tongxu Luo, Wenyu Du, Jiaxi Bi, Stephen Chung, Zhengyang Tang, Hao Yang, Min Zhang, Benyou Wang

+ [Reassessing Large Language Model Boolean Query Generation for Systematic Reviews](https://arxiv.org//abs/2505.07155)

	Shuai Wang, Harrisen Scells, Bevan Koopman, Guido Zuccon

+ [Pre-training vs. Fine-tuning: A Reproducibility Study on Dense Retrieval Knowledge Acquisition](https://arxiv.org//abs/2505.07166)

	Zheng Yao, Shuai Wang, Guido Zuccon

+ [One Trigger Token Is Enough: A Defense Strategy for Balancing Safety and Usability in Large Language Models](https://arxiv.org//abs/2505.07167)

	Haoran Gu, Handing Wang, Yi Mei, Mengjie Zhang, Yaochu Jin

+ [Direct Density Ratio Optimization: A Statistically Consistent Approach to Aligning Large Language Models](https://arxiv.org//abs/2505.07558)

	Rei Higuchi, Taiji Suzuki

+ [Critique Before Thinking: Mitigating Hallucination through Rationale-Augmented Instruction Tuning](https://arxiv.org//abs/2505.07172)

	Zexian Yang, Dian Li, Dayan Wu, Gang Liu, Weiping Wang

+ [Learning to Reason and Navigate: Parameter Efficient Action Planning with Large Language Models](https://arxiv.org//abs/2505.07500)

	Bahram Mohammadi, Ehsan Abbasnejad, Yuankai Qi, Qi Wu, Anton Van Den Hengel, Javen Qinfeng Shi

+ [Imagine, Verify, Execute: Memory-Guided Agentic Exploration with Vision-Language Models](https://arxiv.org//abs/2505.07815)

	Seungjae Lee, Daniel Ekpo, Haowen Liu, Furong Huang, Abhinav Shrivastava, Jia-Bin Huang

+ [Cache-Efficient Posterior Sampling for Reinforcement Learning with LLM-Derived Priors Across Discrete and Continuous Domains](https://arxiv.org//abs/2505.07274)

	Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma

+ [Uncertainty Profiles for LLMs: Uncertainty Source Decomposition and Adaptive Model-Metric Selection](https://arxiv.org//abs/2505.07309)

	Pei-Fu Guo, Yun-Da Tsai, Shou-De Lin

+ [Injecting Knowledge Graphs into Large Language Models](https://arxiv.org//abs/2505.07554)

	Erica Coppolillo

+ [SpecRouter: Adaptive Routing for Multi-Level Speculative Decoding in Large Language Models](https://arxiv.org//abs/2505.07680)

	Hang Wu, Jianian Zhu, Yinghui Li, Haojie Wang, Biao Hou, Jidong Zhai

+ [MLE-Dojo: Interactive Environments for Empowering LLM Agents in Machine Learning Engineering](https://arxiv.org//abs/2505.07782)

	Rushi Qiang, Yuchen Zhuang, Yinghao Li, Dingu Sagar V K, Rongzhi Zhang, Changhao Li, Ian Shu-Hei Wong, Sherry Yang, Percy Liang, Chao Zhang, Bo Dai

+ [Relative Overfitting and Accept-Reject Framework](https://arxiv.org//abs/2505.07783)

	Yanxin Liu, Yunqi Zhang

+ [Private LoRA Fine-tuning of Open-Source LLMs with Homomorphic Encryption](https://arxiv.org//abs/2505.07329)

	Jordan Frery, Roman Bredehoft, Jakub Klemsa, Arthur Meyre, Andrei Stoian

+ [SecReEvalBench: A Multi-turned Security Resilience Evaluation Benchmark for Large Language Models](https://arxiv.org//abs/2505.07584)

	Huining Cui, Wei Liu

+ [LongCodeBench: Evaluating Coding LLMs at 1M Context Windows](https://arxiv.org//abs/2505.07897)

	Stefano Rando, Luca Romani, Alessio Sampieri, Yuta Kyuragi, Luca Franco, Fabio Galasso, Tatsunori Hashimoto, John Yang

+ [DeltaEdit: Enhancing Sequential Editing in Large Language Models by Controlling Superimposed Noise](https://arxiv.org//abs/2505.07899)

	Ding Cao, Yuchen Cai, Rongxi Guo, Xuesong He, Guiquan Liu

+ [SEM: Reinforcement Learning for Search-Efficient Large Language Models](https://arxiv.org//abs/2505.07903)

	Zeyang Sha, Shiwen Cui, Weiqiang Wang

+ [A Reproduction Study: The Kernel PCA Interpretation of Self-Attention Fails Under Scrutiny](https://arxiv.org//abs/2505.07908)

	Karahan Sarıtaş, Çağatay Yıldız

+ [Efficient and Reproducible Biomedical Question Answering using Retrieval Augmented Generation](https://arxiv.org//abs/2505.07917)

	Linus Stuhlmann, Michael Alexander Saxer, Jonathan Fürst

+ [FalseReject: A Resource for Improving Contextual Safety and Mitigating Over-Refusals in LLMs via Structured Reasoning](https://arxiv.org//abs/2505.08054)

	Zhehao Zhang, Weijie Xu, Fanyou Wu, Chandan K. Reddy

+ [Beyond Input Activations: Identifying Influential Latents by Gradient Sparse Autoencoders](https://arxiv.org//abs/2505.08080)

	Dong Shu, Xuansheng Wu, Haiyan Zhao, Mengnan Du, Ninghao Liu

+ [Assessing and Mitigating Medical Knowledge Drift and Conflicts in Large Language Models](https://arxiv.org//abs/2505.07968)

	Weiyi Wu, Xinwen Xu, Chongyang Gao, Xingjian Diao, Siting Li, Lucas A. Salas, Jiang Gui

+ [Putting It All into Context: Simplifying Agents with LCLMs](https://arxiv.org//abs/2505.08120)

	Mingjian Jiang, Yangjun Ruan, Luis Lastras, Pavan Kapanipathi, Tatsunori Hashimoto

+ [Making Small Language Models Efficient Reasoners: Intervention, Supervision, Reinforcement](https://arxiv.org//abs/2505.07961)

	Xuechen Zhang, Zijian Huang, Chenchun Ni, Ziyang Xiong, Jiasi Chen, Samet Oymak

+ [Security of Internet of Agents: Attacks and Countermeasures](https://arxiv.org//abs/2505.08807)

	Yuntao Wang, Yanghe Pan, Shaolong Guo, Zhou Su

+ [An Extra RMSNorm is All You Need for Fine Tuning to 1.58 Bits](https://arxiv.org//abs/2505.08823)

	Cody Steinmetz, Gavin Childress, Aaron Herbst, Gavin Jones, Jasdeep Singh, Eli Vang, Keagan Weinstock

+ [Self Rewarding Self Improving](https://arxiv.org//abs/2505.08827)

	Toby Simonds, Kevin Lopez, Akira Yoshiyama, Dominique Garmier

# 2025-05-11
+ [Control Plane as a Tool: A Scalable Design Pattern for Agentic AI Systems](https://arxiv.org//abs/2505.06817)

	Sivasathivel Kandasamy

+ [Towards Artificial General or Personalized Intelligence? A Survey on Foundation Models for Personalized Federated Intelligence](https://arxiv.org//abs/2505.06907)

	Yu Qiao, Huy Q. Le, Avi Deb Raha, Phuong-Nam Tran, Apurba Adhikary, Mengchun Zhang, Loc X. Nguyen, Eui-Nam Huh, Dusit Niyato, Choong Seon Hong

+ [LLM-Augmented Chemical Synthesis and Design Decision Programs](https://arxiv.org//abs/2505.07027)

	Haorui Wang, Jeff Guo, Lingkai Kong, Rampi Ramprasad, Philippe Schwaller, Yuanqi Du, Chao Zhang

+ [DialogueReason: Rule-Based RL Sparks Dialogue Reasoning in LLMs](https://arxiv.org//abs/2505.07049)

	Yubo Shu, Zhewei Huang, Xin Wu, Chen Hu, Shuchang Zhou, Daxin Jiang

+ [Architectural Precedents for General Agents using Large Language Models](https://arxiv.org//abs/2505.07087)

	Robert E. Wray, James R. Kirk, John E. Laird

+ [RefPentester: A Knowledge-Informed Self-Reflective Penetration Testing Framework Based on Large Language Models](https://arxiv.org//abs/2505.07089)

	Hanzheng Dai, Yuanliang Li, Zhibo Zhang, Jun Yan

+ [ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification](https://arxiv.org//abs/2505.06821)

	Dipayan Saha, Hasan Al Shaikh, Shams Tarek, Farimah Farahmandi

+ [Sandcastles in the Storm: Revisiting the (Im)possibility of Strong Watermarking](https://arxiv.org//abs/2505.06827)

	Fabrice Y Harel-Canada, Boran Erol, Connor Choi, Jason Liu, Gary Jiarui Song, Nanyun Peng, Amit Sahai

+ [The power of fine-grained experts: Granularity boosts expressivity in Mixture of Experts](https://arxiv.org//abs/2505.06839)

	Enric Boix-Adsera, Philippe Rigollet

+ [IM-BERT: Enhancing Robustness of BERT through the Implicit Euler Method](https://arxiv.org//abs/2505.06889)

	Mihyeon Kim, Juhyoung Park, Youngbin Kim

+ [RedTeamLLM: an Agentic AI framework for offensive security](https://arxiv.org//abs/2505.06913)

	Brian Challita, Pierre Parrend

+ [Convert Language Model into a Value-based Strategic Planner](https://arxiv.org//abs/2505.06987)

	Xiaoyu Wang, Yue Zhao, Qingqing Gu, Zhonglin Jiang, Xiaokai Chen, Yong Chen, Luo Ji

+ [ParaView-MCP: An Autonomous Visualization Agent with Direct Tool Use](https://arxiv.org//abs/2505.07064)

	Shusen Liu, Haichao Miao, Peer-Timo Bremer

+ [EcoLANG: Efficient and Effective Agent Communication Language Induction for Social Simulation](https://arxiv.org//abs/2505.06904)

	Xinyi Mou, Chen Qian, Wei Liu, Xuanjing Huang, Zhongyu Wei

+ [The Distracting Effect: Understanding Irrelevant Passages in RAG](https://arxiv.org//abs/2505.06914)

	Chen Amiraz, Florin Cuconasu, Simone Filice, Zohar Karnin

+ [Benign Samples Matter! Fine-tuning On Outlier Benign Samples Severely Breaks Safety](https://arxiv.org//abs/2505.06843)

	Zihan Guan, Mengxuan Hu, Ronghang Zhu, Sheng Li, Anil Vullikanti

+ [Building a Human-Verified Clinical Reasoning Dataset via a Human LLM Hybrid Pipeline for Trustworthy Medical AI](https://arxiv.org//abs/2505.06912)

	Chao Ding, Mouxiao Bian, Pengcheng Chen, Hongliang Zhang, Tianbin Li, Lihao Liu, Jiayuan Chen, Zhuoran Li, Yabei Zhong, Yongqi Liu, Haiqing Huang, Dongming Shan, Junjun He, Jie Xu

+ [Hallucination-Aware Multimodal Benchmark for Gastrointestinal Image Analysis with Large Vision-Language Models](https://arxiv.org//abs/2505.07001)

	Bidur Khanal, Sandesh Pokhrel, Sanjay Bhandari, Ramesh Rana, Nikesh Shrestha, Ram Bahadur Gurung, Cristian Linte, Angus Watson, Yash Raj Shrestha, Binod Bhattarai

+ [GuidedQuant: Large Language Model Quantization via Exploiting End Loss Guidance](https://arxiv.org//abs/2505.07004)

	Jinuk Kim, Marwa El Halabi, Wonpyo Park, Clemens JS Schaefer, Deokjae Lee, Yeonhong Park, Jae W. Lee, Hyun Oh Song

+ [PLHF: Prompt Optimization with Few-Shot Human Feedback](https://arxiv.org//abs/2505.07886)

	Chun-Pai Yang, Kan Zheng, Shou-De Lin

+ [TrumorGPT: Graph-Based Retrieval-Augmented Large Language Model for Fact-Checking](https://arxiv.org//abs/2505.07891)

	Ching Nam Hang, Pei-Duo Yu, Chee Wei Tan

# 2025-05-10
+ [System Prompt Poisoning: Persistent Attacks on Large Language Models Beyond User Injection](https://arxiv.org//abs/2505.06493)

	Jiawei Guo, Haipeng Cai

+ [MacRAG: Compress, Slice, and Scale-up for Multi-Scale Adaptive Context RAG](https://arxiv.org//abs/2505.06569)

	Woosang Lim, Zekun Li, Gyuwan Kim, Sungyoung Ji, HyeonJung Kim, Kyuri Choi, Jin Hyuk Lim, Kyungpyo Park, William Yang Wang

+ [Think in Safety: Unveiling and Mitigating Safety Alignment Collapse in Multimodal Large Reasoning Model](https://arxiv.org//abs/2505.06538)

	Xinyue Lou, You Li, Jinan Xu, Xiangyu Shi, Chi Chen, Kaiyu Huang

+ [REFINE-AF: A Task-Agnostic Framework to Align Language Models via Self-Generated Instructions using Reinforcement Learning from Automated Feedback](https://arxiv.org//abs/2505.06548)

	Aniruddha Roy, Pretam Ray, Abhilash Nandy, Somak Aditya, Pawan Goyal

+ [Using External knowledge to Enhanced PLM for Semantic Matching](https://arxiv.org//abs/2505.06605)

	Min Li, Chun Yuan

+ [Attention Is Not All You Need: The Importance of Feedforward Networks in Transformer Models](https://arxiv.org//abs/2505.06633)

	Isaac Gerber

+ [From Rankings to Insights: Evaluation Should Shift Focus from Leaderboard to Feedback](https://arxiv.org//abs/2505.06698)

	Zongqi Wang, Tianle Gu, Chen Gong, Xin Tian, Siqi Bao, Yujiu Yang

+ [Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free](https://arxiv.org//abs/2505.06708)

	Zihan Qiu, Zekun Wang, Bo Zheng, Zeyu Huang, Kaiyue Wen, Songlin Yang, Rui Men, Le Yu, Fei Huang, Suozhi Huang, Dayiheng Liu, Jingren Zhou, Junyang Lin

+ [Improving Block-Wise LLM Quantization by 4-bit Block-Wise Optimal Float (BOF4): Analysis and Variations](https://arxiv.org//abs/2505.06653)

	Patrick Blumenberg, Thomas Graave, Tim Fingscheidt

+ [Probing In-Context Learning: Impact of Task Complexity and Model Architecture on Generalization and Efficiency](https://arxiv.org//abs/2505.06475)

	Binwen Liu, Peiyu Xu, Quan Yuan, Yihong Chen

+ [QoS-Efficient Serving of Multiple Mixture-of-Expert LLMs Using Partial Runtime Reconfiguration](https://arxiv.org//abs/2505.06481)

	HamidReza Imani, Jiaxin Peng, Peiman Mohseni, Abdolah Amirany, Tarek El-Ghazawi

+ [RuleGenie: SIEM Detection Rule Set Optimization](https://arxiv.org//abs/2505.06701)

	Akansha Shukla, Parth Atulbhai Gandhi, Yuval Elovici, Asaf Shabtai

+ [POISONCRAFT: Practical Poisoning of Retrieval-Augmented Generation for Large Language Models](https://arxiv.org//abs/2505.06579)

	Yangguang Shao, Xinjie Lin, Haozheng Luo, Chengshang Hou, Gang Xiong, Jiahao Yu, Junzheng Shi

+ [Practical Reasoning Interruption Attacks on Reasoning Large Language Models](https://arxiv.org//abs/2505.06643)

	Yu Cui, Cong Zuo

+ [I Know What You Said: Unveiling Hardware Cache Side-Channels in Local Large Language Model Inference](https://arxiv.org//abs/2505.06738)

	Zibo Gao, Junjie Hu, Feng Guo, Yixin Zhang, Yinglong Han, Siyuan Liu, Haiyang Li, Zhiqiang Lv

+ [OMGM: Orchestrate Multiple Granularities and Modalities for Efficient Multimodal Retrieval](https://arxiv.org//abs/2505.07879)

	Wei Yang, Jingjing Fu, Rui Wang, Jinyu Wang, Lei Song, Jiang Bian

+ [Recovering Event Probabilities from Large Language Model Embeddings via Axiomatic Constraints](https://arxiv.org//abs/2505.07883)

	Jian-Qiao Zhu, Haijiang Yan, Thomas L. Griffiths

+ [Multi-modal Synthetic Data Training and Model Collapse: Insights from VLMs and Diffusion Models](https://arxiv.org//abs/2505.08803)

	Zizhao Hu, Mohammad Rostami, Jesse Thomason

# 2025-05-09
+ [APOLLO: Automated LLM and Lean Collaboration for Advanced Formal Reasoning](https://arxiv.org//abs/2505.05758)

	Azim Ospanov, Roozbeh Yousefzadeh

+ [ArtRAG: Retrieval-Augmented Generation with Structured Context for Visual Art Understanding](https://arxiv.org//abs/2505.06020)

	Shuai Wang, Ivona Najdenkoska, Hongyi Zhu, Stevan Rudinac, Monika Kackovic, Nachoem Wijnberg, Marcel Worring

+ [Assessing Robustness to Spurious Correlations in Post-Training Language Models](https://arxiv.org//abs/2505.05704)

	Julia Shuieh, Prasann Singhal, Apaar Shanker, John Heyer, George Pu, Samuel Denton

+ [Multi-Agent Systems for Robotic Autonomy with LLMs](https://arxiv.org//abs/2505.05762)

	Junhong Chen, Ziqi Yang, Haoyuan G Xu, Dandan Zhang, George Mylonas

+ [AgentXploit: End-to-End Redteaming of Black-Box AI Agents](https://arxiv.org//abs/2505.05849)

	Zhun Wang, Vincent Siu, Zhe Ye, Tianneng Shi, Yuzhou Nie, Xuandong Zhao, Chenguang Wang, Wenbo Guo, Dawn Song

+ [Elastic Weight Consolidation for Full-Parameter Continual Pre-Training of Gemma2](https://arxiv.org//abs/2505.05946)

	Vytenis Šliogeris, Povilas Daniušis, Artūras Nakvosas

+ [A Scaling Law for Token Efficiency in LLM Fine-Tuning Under Fixed Compute Budgets](https://arxiv.org//abs/2505.06150)

	Ryan Lagasse, Aidan Kiernans, Avijit Ghosh, Shiri Dori-Hacohen

+ [Sparse Attention Remapping with Clustering for Efficient LLM Decoding on PIM](https://arxiv.org//abs/2505.05772)

	Zehao Fan, Garrett Gagnon, Zhenyu Liu, Liu Liu

+ [NeoQA: Evidence-based Question Answering with Generated News Events](https://arxiv.org//abs/2505.05949)

	Max Glockner, Xiang Jiang, Leonardo F. R. Ribeiro, Iryna Gurevych, Markus Dreyer

+ [Towards Developmentally Plausible Rewards: Communicative Success as a Learning Signal for Interactive Language Models](https://arxiv.org//abs/2505.05970)

	Lennart Stöpler, Rufat Asadli, Mitja Nikolaus, Ryan Cotterell, Alex Warstadt

+ [Unilogit: Robust Machine Unlearning for LLMs Using Uniform-Target Self-Distillation](https://arxiv.org//abs/2505.06027)

	Stefan Vasilev, Christian Herold, Baohao Liao, Seyyed Hadi Hashemi, Shahram Khadivi, Christof Monz

+ [Healthy LLMs? Benchmarking LLM Knowledge of UK Government Public Health Information](https://arxiv.org//abs/2505.06046)

	Joshua Harris, Fan Grayson, Felix Feldman, Timothy Laurence, Toby Nonnenmacher, Oliver Higgins, Leo Loman, Selina Patel, Thomas Finnie, Samuel Collins, Michael Borowitz

+ [LLMs Get Lost In Multi-Turn Conversation](https://arxiv.org//abs/2505.06120)

	Philippe Laban, Hiroaki Hayashi, Yingbo Zhou, Jennifer Neville

+ [Can Prompting LLMs Unlock Hate Speech Detection across Languages? A Zero-shot and Few-shot Study](https://arxiv.org//abs/2505.06149)

	Faeze Ghorbanpour, Daryna Dementieva, Alexander Fraser

+ [Multimodal Integrated Knowledge Transfer to Large Language Models through Preference Optimization with Biomedical Applications](https://arxiv.org//abs/2505.05736)

	Da Wu, Zhanliang Wang, Quan Nguyen, Zhuoran Xu, Kai Wang

+ [Harnessing LLMs Explanations to Boost Surrogate Models in Tabular Data Classification](https://arxiv.org//abs/2505.05744)

	Ruxue Shi, Hengrui Gu, Xu Shen, Xin Wang

+ [Short-circuiting Shortcuts: Mechanistic Investigation of Shortcuts in Text Classification](https://arxiv.org//abs/2505.06032)

	Leon Eshuijs, Shihan Wang, Antske Fokkens

+ [FloE: On-the-Fly MoE Inference](https://arxiv.org//abs/2505.05950)

	Yuxin Zhou, Zheng Li, Jun Zhang, Jue Wang, Yiping Wang, Zhongle Xie, Ke Chen, Lidan Shou

+ [Understanding Stragglers in Large Model Training Using What-if Analysis](https://arxiv.org//abs/2505.05713)

	Jinkun Lin, Ziheng Jiang, Zuquan Song, Sida Zhao, Menghan Yu, Zhanghan Wang, Chenyuan Wang, Zuocheng Shi, Xiang Shi, Wei Jia, Zherui Liu, Shuguang Wang, Haibin Lin, Xiu Liu, Aurojit Panda, Jinyang Li

+ [CAPE: Context-Aware Prompt Perturbation Mechanism with Differential Privacy](https://arxiv.org//abs/2505.05922)

	Haoqi Wu, Wei Dai, Li Wang, Qiang Yan

+ [LLM-Text Watermarking based on Lagrange Interpolation](https://arxiv.org//abs/2505.05712)

	Jarosław Janas, Paweł Morawiecki, Josef Pieprzyk

+ [A Grounded Memory System For Smart Personal Assistants](https://arxiv.org//abs/2505.06328)

	Felix Ocker, Jörg Deigmöller, Pavel Smirnov, Julian Eggert

+ [Reliable Collaborative Conversational Agent System Based on LLMs and Answer Set Programming](https://arxiv.org//abs/2505.06438)

	Yankai Zeng, Gopal Gupta

+ [KCluster: An LLM-based Clustering Approach to Knowledge Component Discovery](https://arxiv.org//abs/2505.06469)

	Yumou Wei, Paulo Carvalho, John Stamper

+ [Learn to Think: Bootstrapping LLM Reasoning Capability Through Graph Learning](https://arxiv.org//abs/2505.06321)

	Hang Gao, Chenhao Zhang, Tie Wang, Junsuo Zhao, Fengge Wu, Changwen Zheng, Huaping Liu

+ [Document Attribution: Examining Citation Relationships using Large Language Models](https://arxiv.org//abs/2505.06324)

	Vipula Rawte, Ryan A. Rossi, Franck Dernoncourt, Nedim Lipka

+ [Prompting Large Language Models for Training-Free Non-Intrusive Load Monitoring](https://arxiv.org//abs/2505.06330)

	Junyu Xue, Xudong Wang, Xiaoling He, Shicheng Liu, Yi Wang, Guoming Tang

+ [Towards AI-Driven Human-Machine Co-Teaming for Adaptive and Agile Cyber Security Operation Centers](https://arxiv.org//abs/2505.06394)

	Massimiliano Albanese, Xinming Ou, Kevin Lybarger, Daniel Lende, Dmitry Goldgof

+ [Engineering Risk-Aware, Security-by-Design Frameworks for Assurance of Large-Scale Autonomous AI Models](https://arxiv.org//abs/2505.06409)

	Krti Tallam

+ [Natural Reflection Backdoor Attack on Vision Language Model for Autonomous Driving](https://arxiv.org//abs/2505.06413)

	Ming Liu, Siyuan Liang, Koushik Howlader, Liwen Wang, Dacheng Tao, Wensheng Zhang

+ [ScaleMCP: Dynamic and Auto-Synchronizing Model Context Protocol Tools for LLM Agents](https://arxiv.org//abs/2505.06416)

	Elias Lumer, Anmol Gulati, Vamse Kumar Subbiah, Pradeep Honaganahalli Basavaraju, James A. Burke

+ [Is your multimodal large language model a good science tutor?](https://arxiv.org//abs/2505.06418)

	Ming Liu, Liwen Wang, Wensheng Zhang

+ [Efficient Fairness Testing in Large Language Models: Prioritizing Metamorphic Relations for Bias Detection](https://arxiv.org//abs/2505.07870)

	Suavis Giramata, Madhusudan Srinivasan, Venkat Naidu Gudivada, Upulee Kanewala

+ [Insertion Language Models: Sequence Generation with Arbitrary-Position Insertions](https://arxiv.org//abs/2505.05755)

	Dhruvesh Patel, Aishwarya Sahoo, Avinash Amballa, Tahira Naseem, Tim G. J. Rudner, Andrew McCallum

# 2025-05-08
+ [Enigme: Generative Text Puzzles for Evaluating Reasoning in Language Models](https://arxiv.org//abs/2505.04914)

	John Hawkins

+ [Belief Filtering for Epistemic Control in Linguistic State Space](https://arxiv.org//abs/2505.04927)

	Sebastian Dumbrava

+ [A Reputation System for Large Language Model-based Multi-agent Systems to Avoid the Tragedy of the Commons](https://arxiv.org//abs/2505.05029)

	Siyue Ren, Wanli Fu, Xinkun Zou, Chen Shen, Yi Cai, Chen Chu, Zhen Wang, Shuyue Hu

+ [MARK: Memory Augmented Refinement of Knowledge](https://arxiv.org//abs/2505.05177)

	Anish Ganguli, Prabal Deb, Debleena Banerjee

+ [ConCISE: Confidence-guided Compression in Step-by-step Efficient Reasoning](https://arxiv.org//abs/2505.04881)

	Ziqing Qiao, Yongheng Deng, Jiali Zeng, Dong Wang, Lai Wei, Fandong Meng, Jie Zhou, Ju Ren, Yaoxue Zhang

+ [Chain-of-Thought Tokens are Computer Program Variables](https://arxiv.org//abs/2505.04955)

	Fangwei Zhu, Peiyi Wang, Zhifang Sui

+ [Rethinking Invariance in In-context Learning](https://arxiv.org//abs/2505.04994)

	Lizhe Fang, Yifei Wang, Khashayar Gatmiry, Lei Fang, Yisen Wang

+ [Understanding In-context Learning of Addition via Activation Subspaces](https://arxiv.org//abs/2505.05145)

	Xinyan Hu, Kayo Yin, Michael I. Jordan, Jacob Steinhardt, Lijie Chen

+ [Revealing Weaknesses in Text Watermarking Through Self-Information Rewrite Attacks](https://arxiv.org//abs/2505.05190)

	Yixin Cheng, Hongcheng Guo, Yangming Li, Leonid Sigal

+ [Software Development Life Cycle Perspective: A Survey of Benchmarks for CodeLLMs and Agents](https://arxiv.org//abs/2505.05283)

	Kaixin Wang, Tianlin Li, Xiaoyu Zhang, Chong Wang, Weisong Sun, Yang Liu, Bin Shi

+ [Scalable Chain of Thoughts via Elastic Reasoning](https://arxiv.org//abs/2505.05315)

	Yuhui Xu, Hanze Dong, Lei Wang, Doyen Sahoo, Junnan Li, Caiming Xiong

+ [Crosslingual Reasoning through Test-Time Scaling](https://arxiv.org//abs/2505.05408)

	Zheng-Xin Yong, M. Farid Adilazuarda, Jonibek Mansurov, Ruochen Zhang, Niklas Muennighoff, Carsten Eickhoff, Genta Indra Winata, Julia Kreutzer, Stephen H. Bach, Alham Fikri Aji

+ [Reasoning Models Don't Always Say What They Think](https://arxiv.org//abs/2505.05410)

	Yanda Chen, Joe Benton, Ansh Radhakrishnan, Jonathan Uesato, Carson Denison, John Schulman, Arushi Somani, Peter Hase, Misha Wagner, Fabien Roger, Vlad Mikulik, Samuel R. Bowman, Jan Leike, Jared Kaplan, Ethan Perez

+ [ComPO: Preference Alignment via Comparison Oracles](https://arxiv.org//abs/2505.05465)

	Peter Chen, Xi Chen, Wotao Yin, Tianyi Lin

+ [StreamBridge: Turning Your Offline Video Large Language Model into a Proactive Streaming Assistant](https://arxiv.org//abs/2505.05467)

	Haibo Wang, Bo Feng, Zhengfeng Lai, Mingze Xu, Shiyu Li, Weifeng Ge, Afshin Dehghan, Meng Cao, Ping Huang

+ [Latent Preference Coding: Aligning Large Language Models via Discrete Latent Codes](https://arxiv.org//abs/2505.04993)

	Zhuocheng Gong, Jian Guan, Wei Wu, Huishuai Zhang, Dongyan Zhao

+ [The Pitfalls of Growing Group Complexity: LLMs and Social Choice-Based Aggregation for Group Recommendations](https://arxiv.org//abs/2505.05016)

	Cedric Waterschoot, Nava Tintarev, Francesco Barile

+ [Scalable Multi-Stage Influence Function for Large Language Models via Eigenvalue-Corrected Kronecker-Factored Parameterization](https://arxiv.org//abs/2505.05017)

	Yuntai Bao, Xuhong Zhang, Tianyu Du, Xinkui Zhao, Jiang Zong, Hao Peng, Jianwei Yin

+ [Reliably Bounding False Positives: A Zero-Shot Machine-Generated Text Detection Framework via Multiscaled Conformal Prediction](https://arxiv.org//abs/2505.05084)

	Xiaowei Zhu, Yubing Ren, Yanan Cao, Xixun Lin, Fang Fang, Yangxi Li

+ [Unveiling Language-Specific Features in Large Language Models via Sparse Autoencoders](https://arxiv.org//abs/2505.05111)

	Boyi Deng, Yu Wan, Yidan Zhang, Baosong Yang, Fuli Feng

+ [QualBench: Benchmarking Chinese LLMs with Localized Professional Qualifications for Vertical Domain Evaluation](https://arxiv.org//abs/2505.05225)

	Mengze Hong, Wailing Ng, Di Jiang, Chen Jason Zhang

+ [Toward Reasonable Parrots: Why Large Language Models Should Argue with Us by Design](https://arxiv.org//abs/2505.05298)

	Elena Musi, Nadin Kokciyan, Khalid Al-Khatib, Davide Ceolin, Emmanuelle Dietz, Klara Gutekunst, Annette Hautli-Janisz, Cristian Manuel Santibañez Yañez, Jodi Schneider, Jonas Scholz, Cor Steging, Jacky Visser, Henning Wachsmuth

+ [ICon: In-Context Contribution for Automatic Data Selection](https://arxiv.org//abs/2505.05327)

	Yixin Yang, Qingxiu Dong, Linli Yao, Fangwei Zhu, Zhifang Sui

+ [Frame In, Frame Out: Do LLMs Generate More Biased News Headlines than Humans?](https://arxiv.org//abs/2505.05406)

	Valeria Pastorino, Nafise Sadat Moosavi

+ [Ultra-FineWeb: Efficient Data Filtering and Verification for High-Quality LLM Training Data](https://arxiv.org//abs/2505.05427)

	Yudong Wang, Zixuan Fu, Jie Cai, Peijun Tang, Hongya Lyu, Yewei Fang, Zhi Zheng, Jie Zhou, Guoyang Zeng, Chaojun Xiao, Xu Han, Zhiyuan Liu

+ [clem:todd: A Framework for the Systematic Benchmarking of LLM-Based Task-Oriented Dialogue System Realisations](https://arxiv.org//abs/2505.05445)

	Chalamalasetti Kranti, Sherzod Hakimov, David Schlangen

+ [Bring Reason to Vision: Understanding Perception and Reasoning through Model Merging](https://arxiv.org//abs/2505.05464)

	Shiqi Chen, Jinghan Zhang, Tongyao Zhu, Wei Liu, Siyang Gao, Miao Xiong, Manling Li, Junxian He

+ [Perception, Reason, Think, and Plan: A Survey on Large Multimodal Reasoning Models](https://arxiv.org//abs/2505.04921)

	Yunxin Li, Zhenyu Liu, Zitao Li, Xuanyu Zhang, Zhenran Xu, Xinyu Chen, Haoyuan Shi, Shenyuan Jiang, Xintong Wang, Jifang Wang, Shouzheng Huang, Xinping Zhao, Borui Jiang, Lanqing Hong, Longyue Wang, Zhuotao Tian, Baoxing Huai, Wenhan Luo, Weihua Luo, Zheng Zhang, Baotian Hu, Min Zhang

+ [Prompt-Based LLMs for Position Bias-Aware Reranking in Personalized Recommendations](https://arxiv.org//abs/2505.04948)

	Md Aminul Islam, Ahmed Sayeed Faruk

+ [WaterDrum: Watermarking for Data-centric Unlearning Metric](https://arxiv.org//abs/2505.05064)

	Xinyang Lu, Xinyuan Niu, Gregory Kang Ruey Lau, Bui Thi Cam Nhung, Rachael Hwee Ling Sim, Fanyu Wen, Chuan-Sheng Foo, See-Kiong Ng, Bryan Kian Hsiang Low

+ [FedTDP: A Privacy-Preserving and Unified Framework for Trajectory Data Preparation via Federated Learning](https://arxiv.org//abs/2505.05155)

	Zhihao Zeng, Ziquan Fang, Wei Shao, Lu Chen, Yunjun Gao

+ [Latte: Transfering LLMs` Latent-level Knowledge for Few-shot Tabular Learning](https://arxiv.org//abs/2505.05237)

	Ruxue Shi, Hengrui Gu, Hangting Ye, Yiwei Dai, Xu Shen, Xin Wang

+ [A Weighted Byzantine Fault Tolerance Consensus Driven Trusted Multiple Large Language Models Network](https://arxiv.org//abs/2505.05103)

	Haoxiang Luo, Gang Sun, Yinqiu Liu, Dongcheng Zhao, Dusit Niyato, Hongfang Yu, Schahram Dustdar

+ [Safety by Measurement: A Systematic Literature Review of AI Safety Evaluation Methods](https://arxiv.org//abs/2505.05541)

	Markov Grey, Charbel-Raphaël Segerie

+ [HiBayES: A Hierarchical Bayesian Modeling Framework for AI Evaluation Statistics](https://arxiv.org//abs/2505.05602)

	Lennart Luettgau, Harry Coppock, Magda Dubois, Christopher Summerfield, Cozmin Ududec

+ [CityNavAgent: Aerial Vision-and-Language Navigation with Hierarchical Semantic Planning and Global Memory](https://arxiv.org//abs/2505.05622)

	Weichen Zhang, Chen Gao, Shiquan Yu, Ruiying Peng, Baining Zhao, Qian Zhang, Jinqiang Cui, Xinlei Chen, Yong Li

+ [Looking Beyond Language Priors: Enhancing Visual Comprehension and Attention in Multimodal Models](https://arxiv.org//abs/2505.05626)

	Aarti Ghatkesar, Uddeshya Upadhyay, Ganesh Venkatesh

+ [Adaptive Stress Testing Black-Box LLM Planners](https://arxiv.org//abs/2505.05665)

	Neeloy Chakraborty, John Pohovey, Melkior Ornik, Katherine Driggs-Campbell

+ [Lost in OCR Translation? Vision-Based Approaches to Robust Document Retrieval](https://arxiv.org//abs/2505.05666)

	Alexander Most, Joseph Winjum, Ayan Biswas, Shawn Jones, Nishath Rajiv Ranasinghe, Dan O'Malley, Manish Bhattarai

+ [EcoAgent: An Efficient Edge-Cloud Collaborative Multi-Agent Framework for Mobile Automation](https://arxiv.org//abs/2505.05440)

	Biao Yi, Xavier Hu, Yurun Chen, Shengyu Zhang, Hongxia Yang, Fan Wu, Fei Wu

+ [KG-HTC: Integrating Knowledge Graphs into LLMs for Effective Zero-shot Hierarchical Text Classification](https://arxiv.org//abs/2505.05583)

	Qianbo Zang, Christophe Zgrzendek, Igor Tchappi, Afshin Khadangi, Johannes Sedlmeir

+ [Privacy-Preserving Transformers: SwiftKey's Differential Privacy Implementation](https://arxiv.org//abs/2505.05648)

	Abdelrahman Abouelenin, Mohamed Abdelrehim, Raffy Fahim, Amr Hendy, Mohamed Afify

+ [PRIMG : Efficient LLM-driven Test Generation Using Mutant Prioritization](https://arxiv.org//abs/2505.05584)

	Mohamed Salah Bouafif, Mohammad Hamdaqa, Edward Zulkoski

+ [Enhancing Large Language Models with Faster Code Preprocessing for Vulnerability Detection](https://arxiv.org//abs/2505.05600)

	José Gonçalves, Miguel Silva, Eva Maia, Isabel Praça

+ [LiteLMGuard: Seamless and Lightweight On-Device Prompt Filtering for Safeguarding Small Language Models against Quantization-induced Risks and Vulnerabilities](https://arxiv.org//abs/2505.05619)

	Kalyan Nakka, Jimmy Dani, Ausmit Mondal, Nitesh Saxena

+ [User Behavior Analysis in Privacy Protection with Large Language Models: A Study on Privacy Preferences with Limited Data](https://arxiv.org//abs/2505.06305)

	Haowei Yang, Qingyi Lu, Yang Wang, Sibei Liu, Jiayun Zheng, Ao Xiang

+ [Large Language Model-driven Security Assistant for Internet of Things via Chain-of-Thought](https://arxiv.org//abs/2505.06307)

	Mingfei Zeng, Ming Xie, Xixi Zheng, Chunhai Li, Chuan Zhang, Liehuang Zhu

+ [Defending against Indirect Prompt Injection by Instruction Detection](https://arxiv.org//abs/2505.06311)

	Tongyu Wen, Chenglong Wang, Xiyuan Yang, Haoyu Tang, Yueqi Xie, Lingjuan Lyu, Zhicheng Dou, Fangzhao Wu

+ [AI Approaches to Qualitative and Quantitative News Analytics on NATO Unity](https://arxiv.org//abs/2505.06313)

	Bohdan M. Pavlyshenko

+ [Threat Modeling for AI: The Case for an Asset-Centric Approach](https://arxiv.org//abs/2505.06315)

	Jose Sanchez Vicarte, Marcin Spoczynski, Mostafa Elsaid

+ [RAP-SM: Robust Adversarial Prompt via Shadow Models for Copyright Verification of Large Language Models](https://arxiv.org//abs/2505.06304)

	Zhenhua Xu, Zhebo Wang, Maike Li, Wenpeng Xing, Chunqiang Hu, Chen Zhi, Meng Han

+ [Unpacking Robustness in Inflectional Languages: Adversarial Evaluation and Mechanistic Insights](https://arxiv.org//abs/2505.07856)

	Paweł Walkowiak, Marek Klonowski, Marcin Oleksy, Arkadiusz Janz

+ [Scaling Laws for Speculative Decoding](https://arxiv.org//abs/2505.07858)

	Siyuan Yan, Mo Zhu, Guo-qing Jiang, Jianfei Wang, Jiaxing Chen, Wentai Zhang, Xiang Liao, Xiao Cui, Chen Zhang, Zhuoran Song, Ran Zhu

+ [Scalable LLM Math Reasoning Acceleration with Low-rank Distillation](https://arxiv.org//abs/2505.07861)

	Harry Dong, Bilge Acun, Beidi Chen, Yuejie Chi

# 2025-05-07
+ [Advancing and Benchmarking Personalized Tool Invocation for LLMs](https://arxiv.org//abs/2505.04072)

	Xu Huang, Yuefeng Huang, Weiwen Liu, Xingshan Zeng, Yasheng Wang, Ruiming Tang, Hong Xie, Defu Lian

+ [LLM-e Guess: Can LLMs Capabilities Advance Without Hardware Progress?](https://arxiv.org//abs/2505.04075)

	Teddy Foley, Spencer Guo, Henry Josephson, Anqi Qu, Jack Sanderson

+ [LLMs' Suitability for Network Security: A Case Study of STRIDE Threat Modeling](https://arxiv.org//abs/2505.04101)

	AbdulAziz AbdulGhaffar, Ashraf Matrawy

+ [Unmasking the Canvas: A Dynamic Benchmark for Image Generation Jailbreaking and LLM Content Safety](https://arxiv.org//abs/2505.04146)

	Variath Madhupal Gautham Nair, Vishal Varma Dantuluri

+ [On-Device LLM for Context-Aware Wi-Fi Roaming](https://arxiv.org//abs/2505.04174)

	Ju-Hyung Lee, Yanqing Lu

+ [Facilitating Trustworthy Human-Agent Collaboration in LLM-based Multi-Agent System oriented Software Engineering](https://arxiv.org//abs/2505.04251)

	Krishna Ronanki

+ [Steerable Chatbots: Personalizing LLMs with Preference-Based Activation Steering](https://arxiv.org//abs/2505.04260)

	Jessica Y. Bo, Tianyu Xu, Ishan Chatterjee, Katrina Passarella-Ward, Achin Kulshrestha, D Shin

+ [Weaponizing Language Models for Cybersecurity Offensive Operations: Automating Vulnerability Assessment Report Validation; A Review Paper](https://arxiv.org//abs/2505.04265)

	Abdulrahman S Almuhaidib, Azlan Mohd Zain, Zalmiyah Zakaria, Izyan Izzati Kamsani, Abdulaziz S Almuhaidib

+ [The Aloe Family Recipe for Open and Specialized Healthcare LLMs](https://arxiv.org//abs/2505.04388)

	Dario Garcia-Gasulla, Jordi Bayarri-Planas, Ashwin Kumar Gururajan, Enrique Lopez-Cuena, Adrian Tormos, Daniel Hinjos, Pablo Bernabeu-Perez, Anna Arias-Duart, Pablo Agustin Martin-Torres, Marta Gonzalez-Mallo, Sergio Alvarez-Napagao, Eduard Ayguadé-Parra, Ulises Cortés

+ [OBLIVIATE: Robust and Practical Machine Unlearning for Large Language Models](https://arxiv.org//abs/2505.04416)

	Xiaoyu Xu, Minxin Du, Qingqing Ye, Haibo Hu

+ [Fight Fire with Fire: Defending Against Malicious RL Fine-Tuning via Reward Neutralization](https://arxiv.org//abs/2505.04578)

	Wenjun Cao

+ [EchoInk-R1: Exploring Audio-Visual Reasoning in Multimodal LLMs via Reinforcement Learning](https://arxiv.org//abs/2505.04623)

	Zhenghao Xing, Xiaowei Hu, Chi-Wing Fu, Wenhai Wang, Jifeng Dai, Pheng-Ann Heng

+ [Enhancing Granular Sentiment Classification with Chain-of-Thought Prompting in Large Language Models](https://arxiv.org//abs/2505.04135)

	Vihaan Miriyala, Smrithi Bukkapatnam, Lavanya Prahallad

+ [LLM-Independent Adaptive RAG: Let the Question Speak for Itself](https://arxiv.org//abs/2505.04253)

	Maria Marina, Nikolay Ivanov, Sergey Pletenev, Mikhail Salnikov, Daria Galimzianova, Nikita Krayko, Vasily Konovalov, Alexander Panchenko, Viktor Moskvoretskii

+ [Large Means Left: Political Bias in Large Language Models Increases with Their Number of Parameters](https://arxiv.org//abs/2505.04393)

	David Exler, Mark Schutera, Markus Reischl, Luca Rettenberger

+ [Pangu Ultra MoE: How to Train Your Big MoE on Ascend NPUs](https://arxiv.org//abs/2505.04519)

	Yehui Tang, Yichun Yin, Yaoyuan Wang, Hang Zhou, Yu Pan, Wei Guo, Ziyang Zhang, Miao Rang, Fangcheng Liu, Naifu Zhang, Binghan Li, Yonghan Dong, Xiaojun Meng, Yasheng Wang, Dong Li, Yin Li, Dandan Tu, Can Chen, Youliang Yan, Fisher Yu, Ruiming Tang, Yunhe Wang, Botian Huang, Bo Wang, Boxiao Liu, Changzheng Zhang, Da Kuang, Fei Liu, Gang Huang, Jiansheng Wei, Jiarui Qin, Jie Ran, Jinpeng Li, Jun Zhao, Liang Dai, Lin Li, Liqun Deng, Peifeng Qin, Pengyuan Zeng, Qiang Gu, Shaohua Tang, Shengjun Cheng, Tao Gao, Tao Yu, Tianshu Li, Tianyu Bi, Wei He, Weikai Mao, Wenyong Huang, Wulong Liu, Xiabing Li, Xianzhi Yu, Xueyu Wu, Xu He, Yangkai Du, Yan Xu, Ye Tian, Yimeng Wu, Yongbing Huang, Yong Tian, Yong Zhu, Yue Li, Yufei Wang, Yuhang Gai, Yujun Li, Yu Luo, Yunsheng Ni, Yusen Sun, Zelin Chen, Zhe Liu, Zhicheng Liu, Zhipeng Tu, Zilin Ding, Zongyuan Zhan

+ [ZeroSearch: Incentivize the Search Capability of LLMs without Searching](https://arxiv.org//abs/2505.04588)

	Hao Sun, Zile Qiao, Jiayan Guo, Xuanbo Fan, Yingyan Hou, Yong Jiang, Pengjun Xie, Fei Huang, Yan Zhang

+ [Large Language Models are often politically extreme, usually ideologically inconsistent, and persuasive even in informational contexts](https://arxiv.org//abs/2505.04171)

	Nouar Aldahoul, Hazem Ibrahim, Matteo Varvello, Aaron Kaufman, Talal Rahwan, Yasir Zaki

+ [Benchmarking LLMs' Swarm intelligence](https://arxiv.org//abs/2505.04364)

	Kai Ruan, Mowen Huang, Ji-Rong Wen, Hao Sun

+ [Componential Prompt-Knowledge Alignment for Domain Incremental Learning](https://arxiv.org//abs/2505.04575)

	Kunlun Xu, Xu Zou, Gang Hua, Jiahuan Zhou

+ [Towards Effectively Leveraging Execution Traces for Program Repair with Code LLMs](https://arxiv.org//abs/2505.04441)

	Mirazul Haque, Petr Babkin, Farima Farmahinifarahani, Manuela Veloso

+ [Communication-Efficient Federated Fine-Tuning of Language Models via Dynamic Update Schedules](https://arxiv.org//abs/2505.04535)

	Michail Theologitis, Vasilis Samoladas, Antonios Deligiannakis

+ [AutoPatch: Multi-Agent Framework for Patching Real-World CVE Vulnerabilities](https://arxiv.org//abs/2505.04195)

	Minjae Seo, Wonwoo Choi, Myoungsung You, Seungwon Shin

+ [The Promise and Limits of LLMs in Constructing Proofs and Hints for Logic Problems in Intelligent Tutoring Systems](https://arxiv.org//abs/2505.04736)

	Sutapa Dey Tithi, Arun Kumar Ramesh, Clara DiMarco, Xiaoyi Tian, Nazia Alam, Kimia Fazeli, Tiffany Barnes

+ [Large Language Models are Autonomous Cyber Defenders](https://arxiv.org//abs/2505.04843)

	Sebastián R. Castro, Roberto Campbell, Nancy Lau, Octavio Villalobos, Jiaqi Duan, Alvaro A. Cardenas

+ [Personalized Risks and Regulatory Strategies of Large Language Models in Digital Advertising](https://arxiv.org//abs/2505.04665)

	Haoyang Feng, Yanjun Dai, Yuan Gao

+ [REVEAL: Multi-turn Evaluation of Image-Input Harms for Vision LLM](https://arxiv.org//abs/2505.04673)

	Madhur Jindal, Saurabh Deshpande

+ [QBD-RankedDataGen: Generating Custom Ranked Datasets for Improving Query-By-Document Search Using LLM-Reranking with Reduced Human Effort](https://arxiv.org//abs/2505.04732)

	Sriram Gopalakrishnan, Sunandita Patra

+ [When Bad Data Leads to Good Models](https://arxiv.org//abs/2505.04741)

	Kenneth Li, Yida Chen, Fernanda Viégas, Martin Wattenberg

+ [A Proposal for Evaluating the Operational Risk for ChatBots based on Large Language Models](https://arxiv.org//abs/2505.04784)

	Pedro Pinacho-Davidson, Fernando Gutierrez, Pablo Zapata, Rodolfo Vergara, Pablo Aqueveque

+ [Putting the Value Back in RL: Better Test-Time Scaling by Unifying LLM Reasoners With Verifiers](https://arxiv.org//abs/2505.04842)

	Kusha Sareen, Morgane M Moss, Alessandro Sordoni, Rishabh Agarwal, Arian Hosseini

+ [Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards](https://arxiv.org//abs/2505.04847)

	Manveer Singh Tamber, Forrest Sheng Bao, Chenyu Xu, Ge Luo, Suleman Kazi, Minseok Bae, Miaoran Li, Ofer Mendelevitch, Renyi Qu, Jimmy Lin

+ [Fine-Tuning Large Language Models and Evaluating Retrieval Methods for Improved Question Answering on Building Codes](https://arxiv.org//abs/2505.04666)

	Mohammad Aqib, Mohd Hamza, Qipei Mei, Ying Hei Chui

+ [Reward-SQL: Boosting Text-to-SQL via Stepwise Reasoning and Process-Supervised Rewards](https://arxiv.org//abs/2505.04671)

	Yuxin Zhang, Meihao Fan, Ju Fan, Mingyang Yi, Yuyu Luo, Jian Tan, Guoliang Li

+ [SOAEsV2-7B/72B: Full-Pipeline Optimization for State-Owned Enterprise LLMs via Continual Pre-Training, Domain-Progressive SFT and Distillation-Enhanced Speculative Decoding](https://arxiv.org//abs/2505.04723)

	Jingyang Deng, Ran Chen, Jo-Ku Cheng, Jinwen Ma

+ [Osiris: A Lightweight Open-Source Hallucination Detection System](https://arxiv.org//abs/2505.04844)

	Alex Shan, John Bauer, Christopher D. Manning

+ [Red Teaming the Mind of the Machine: A Systematic Evaluation of Prompt Injection and Jailbreak Vulnerabilities in LLMs](https://arxiv.org//abs/2505.04806)

	Chetan Pathade

+ [HiPerRAG: High-Performance Retrieval Augmented Generation for Scientific Insights](https://arxiv.org//abs/2505.04846)

	Ozan Gokdemir, Carlo Siebenschuh, Alexander Brace, Azton Wells, Brian Hsu, Kyle Hippe, Priyanka V. Setty, Aswathy Ajith, J. Gregory Pauloski, Varuni Sastry, Sam Foreman, Huihuo Zheng, Heng Ma, Bharat Kale, Nicholas Chia, Thomas Gibbs, Michael E. Papka, Thomas Brettin, Francis J. Alexander, Anima Anandkumar, Ian Foster, Rick Stevens, Venkatram Vishwanath, Arvind Ramanathan

+ [Safeguard-by-Development: A Privacy-Enhanced Development Paradigm for Multi-Agent Collaboration Systems](https://arxiv.org//abs/2505.04799)

	Jian Cui, Zichuan Li, Luyi Xing, Xiaojing Liao

+ [Nature's Insight: A Novel Framework and Comprehensive Analysis of Agentic Reasoning Through the Lens of Neuroscience](https://arxiv.org//abs/2505.05515)

	Zinan Liu, Haoran Li, Jingyi Lu, Gaoyuan Ma, Xu Hong, Giovanni Iacca, Arvind Kumar, Shaojun Tang, Lin Wang

+ [DMRL: Data- and Model-aware Reward Learning for Data Extraction](https://arxiv.org//abs/2505.06284)

	Zhiqiang Wang, Ruoxi Cheng

+ [Winning at All Cost: A Small Environment for Eliciting Specification Gaming Behaviors in Large Language Models](https://arxiv.org//abs/2505.07846)

	Lars Malmqvist

+ [Joint Detection of Fraud and Concept Drift inOnline Conversations with LLM-Assisted Judgment](https://arxiv.org//abs/2505.07852)

	Ali Senol, Garima Agrawal, Huan Liu

# 2025-05-06
+ [Holmes: Automated Fact Check with Large Language Models](https://arxiv.org//abs/2505.03135)

	Haoran Ou, Gelei Deng, Xingshuo Han, Jie Zhang, Xinlei He, Han Qiu, Shangwei Guo, Tianwei Zhang

+ [Patterns and Mechanisms of Contrastive Activation Engineering](https://arxiv.org//abs/2505.03189)

	Yixiong Hao, Ayush Panda, Stepan Shabalin, Sheikh Abdur Raheem Ali

+ [RAG-MCP: Mitigating Prompt Bloat in LLM Tool Selection via Retrieval-Augmented Generation](https://arxiv.org//abs/2505.03275)

	Tiantian Gan, Qiyao Sun

+ [Capability-Driven Skill Generation with LLMs: A RAG-Based Approach for Reusing Existing Libraries and Interfaces](https://arxiv.org//abs/2505.03295)

	Luis Miguel Vieira da Silva, Aljosha Köcher, Nicolas König, Felix Gehlhoff, Alexander Fay

+ [AI-Driven Scholarly Peer Review via Persistent Workflow Prompting, Meta-Prompting, and Meta-Reasoning](https://arxiv.org//abs/2505.03332)

	Evgeny Markhasin

+ [Procedural Memory Is Not All You Need: Bridging Cognitive Gaps in LLM-Based Agents](https://arxiv.org//abs/2505.03434)

	Schaun Wheeler, Olivier Jeunen

+ [The Steganographic Potentials of Language Models](https://arxiv.org//abs/2505.03439)

	Artem Karpov, Tinuade Adeleke, Seong Hah Cho, Natalia Perez-Campanero

+ [am-ELO: A Stable Framework for Arena-based LLM Evaluation](https://arxiv.org//abs/2505.03475)

	Zirui Liu, Jiatong Li, Yan Zhuang, Qi Liu, Shuanghong Shen, Jie Ouyang, Mingyue Cheng, Shijin Wang

+ [A Hashgraph-Inspired Consensus Mechanism for Reliable Multi-Model Reasoning](https://arxiv.org//abs/2505.03553)

	Kolawole E. Ogunsina, Morayo A. Ogunsina

+ [Assessing and Enhancing the Robustness of LLM-based Multi-Agent Systems Through Chaos Engineering](https://arxiv.org//abs/2505.03096)

	Joshua Owotogbe

+ [Soft Best-of-n Sampling for Model Alignment](https://arxiv.org//abs/2505.03156)

	Claudio Mayrink Verdun, Alex Oesterling, Himabindu Lakkaraju, Flavio P. Calmon

+ [A Trustworthy Multi-LLM Network: Challenges,Solutions, and A Use Case](https://arxiv.org//abs/2505.03196)

	Haoxiang Luo, Gang Sun, Yinqiu Liu, Dusit Niyato, Hongfang Yu, Mohammed Atiquzzaman, Schahram Dustdar

+ [Absolute Zero: Reinforced Self-play Reasoning with Zero Data](https://arxiv.org//abs/2505.03335)

	Andrew Zhao, Yiran Wu, Yang Yue, Tong Wu, Quentin Xu, Yang Yue, Matthieu Lin, Shenzhi Wang, Qingyun Wu, Zilong Zheng, Gao Huang

+ [SPAP: Structured Pruning via Alternating Optimization and Penalty Methods](https://arxiv.org//abs/2505.03373)

	Hanyu Hu, Xiaoming Yuan

+ [Automatic Calibration for Membership Inference Attack on Large Language Models](https://arxiv.org//abs/2505.03392)

	Saleh Zare Zade, Yao Qiang, Xiangyu Zhou, Hui Zhu, Mohammad Amin Roshani, Prashant Khanduri, Dongxiao Zhu

+ [Lightweight Clinical Decision Support System using QLoRA-Fine-Tuned LLMs and Retrieval-Augmented Generation](https://arxiv.org//abs/2505.03406)

	Mohammad Shoaib Ansari, Mohd Sohail Ali Khan, Shubham Revankar, Aditya Varma, Anil S. Mokhade

+ [An Analysis of Hyper-Parameter Optimization Methods for Retrieval Augmented Generation](https://arxiv.org//abs/2505.03452)

	Matan Orbach, Ohad Eytan, Benjamin Sznajder, Ariel Gera, Odellia Boni, Yoav Kantor, Gal Bloch, Omri Levy, Hadas Abraham, Nitzan Barzilay, Eyal Shnarch, Michael E. Factor, Shila Ofek-Koifman, Paula Ta-Shma, Assaf Toledo

+ [A new membership inference attack that spots memorization in generative and predictive models: Loss-Based with Reference Model algorithm (LBRM)](https://arxiv.org//abs/2505.03490)

	Faiz Taleb, Ivan Gazeau, Maryline Laurent

+ [LlamaFirewall: An open source guardrail system for building secure AI agents](https://arxiv.org//abs/2505.03574)

	Sahana Chennabasappa, Cyrus Nikolaidis, Daniel Song, David Molnar, Stephanie Ding, Shengye Wan, Spencer Whitman, Lauren Deason, Nicholas Doucette, Abraham Montilla, Alekhya Gampa, Beto de Paola, Dominik Gabi, James Crnkovich, Jean-Christophe Testud, Kat He, Rashnil Chaturvedi, Wu Zhou, Joshua Saxe

+ [ReGraP-LLaVA: Reasoning enabled Graph-based Personalized Large Language and Vision Assistant](https://arxiv.org//abs/2505.03654)

	Yifan Xiang, Zhenxi Zhang, Bin Li, Yixuan Weng, Shoujun Zhou, Yangfan He, Keqin Li

+ [Ψ-Arena: Interactive Assessment and Optimization of LLM-based Psychological Counselors with Tripartite Feedback](https://arxiv.org//abs/2505.03293)

	Shijing Zhu, Zhuang Chen, Guanqun Bi, Binghang Li, Yaxi Deng, Dazhen Wan, Libiao Peng, Xiyao Xiao, Rongsheng Zhang, Tangjie Lv, Zhipeng Hu, FangFang Li, Minlie Huang

+ [Recall with Reasoning: Chain-of-Thought Distillation for Mamba's Long-Context Memory and Extrapolation](https://arxiv.org//abs/2505.03320)

	Junyu Ma, Tianqing Fang, Zhisong Zhang, Hongming Zhang, Haitao Mi, Dong Yu

+ [Uncertainty-Aware Large Language Models for Explainable Disease Diagnosis](https://arxiv.org//abs/2505.03467)

	Shuang Zhou, Jiashuo Wang, Zidu Xu, Song Wang, David Brauer, Lindsay Welton, Jacob Cogan, Yuen-Hei Chung, Lei Tian, Zaifu Zhan, Yu Hou, Mingquan Lin, Genevieve B. Melton, Rui Zhang

+ [Long-Short Chain-of-Thought Mixture Supervised Fine-Tuning Eliciting Efficient Reasoning in Large Language Models](https://arxiv.org//abs/2505.03469)

	Bin Yu, Hang Yuan, Yuliang Wei, Bailing Wang, Weizhen Qi, Kai Chen

+ [Evaluation of LLMs on Long-tail Entity Linking in Historical Documents](https://arxiv.org//abs/2505.03473)

	Marta Boscariol, Luana Bulla, Lia Draetta, Beatrice Fiumanò, Emanuele Lenzi, Leonardo Piano

+ [Faster MoE LLM Inference for Extremely Large Models](https://arxiv.org//abs/2505.03531)

	Haoqi Yang, Luohe Shi, Qiwei Li, Zuchao Li, Ping Wang, Bo Du, Mengjia Shen, Hai Zhao

+ [Say It Another Way: A Framework for User-Grounded Paraphrasing](https://arxiv.org//abs/2505.03563)

	Cléa Chataigner, Rebecca Ma, Prakhar Ganesh, Afaf Taïk, Elliot Creager, Golnoosh Farnadi

+ [WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional Websites from Scratch](https://arxiv.org//abs/2505.03733)

	Zimu Lu, Yunqiao Yang, Houxing Ren, Haotian Hou, Han Xiao, Ke Wang, Weikang Shi, Aojun Zhou, Mingjie Zhan, Hongsheng Li

+ [BadLingual: A Novel Lingual-Backdoor Attack against Large Language Models](https://arxiv.org//abs/2505.03501)

	Zihan Wang, Hongwei Li, Rui Zhang, Wenbo Jiang, Kangjie Chen, Tianwei Zhang, Qingchuan Zhao, Guowen Xu

+ [VLM Q-Learning: Aligning Vision-Language Models for Interactive Decision-Making](https://arxiv.org//abs/2505.03181)

	Jake Grigsby, Yuke Zhu, Michael Ryoo, Juan Carlos Niebles

+ [DYSTIL: Dynamic Strategy Induction with Large Language Models for Reinforcement Learning](https://arxiv.org//abs/2505.03209)

	Borui Wang, Kathleen McKeown, Rex Ying

+ [Geospatial Mechanistic Interpretability of Large Language Models](https://arxiv.org//abs/2505.03368)

	Stef De Sabbata, Stefano Mizzaro, Kevin Roitero

+ [Knowledge Augmented Complex Problem Solving with Large Language Models: A Survey](https://arxiv.org//abs/2505.03418)

	Da Zheng, Lun Du, Junwei Su, Yuchen Tian, Yuqi Zhu, Jintian Zhang, Lanning Wei, Ningyu Zhang, Huajun Chen

+ [Uncovering the Limitations of Model Inversion Evaluation: Benchmarks and Connection to Type-I Adversarial Attacks](https://arxiv.org//abs/2505.03519)

	Sy-Tuyen Ho, Koh Jun Hao, Ngoc-Bao Nguyen, Alexander Binder, Ngai-Man Cheung

+ [Towards a standardized methodology and dataset for evaluating LLM-based digital forensic timeline analysis](https://arxiv.org//abs/2505.03100)

	Hudan Studiawan, Frank Breitinger, Mark Scanlon

+ [Towards Effective Identification of Attack Techniques in Cyber Threat Intelligence Reports using Large Language Models](https://arxiv.org//abs/2505.03147)

	Hoang Cuong Nguyen, Shahroz Tariq, Mohan Baruwal Chhetri, Bao Quoc Vo

+ [An LLM-based Self-Evolving Security Framework for 6G Space-Air-Ground Integrated Networks](https://arxiv.org//abs/2505.03161)

	Qi Qin, Xinye Cao, Guoshun Nan, Sihan Chen, Rushan Li, Li Su, Haitao Du, Qimei Cui, Pengxuan Mao, Xiaofeng Tao, Tony Q.S. Quek

+ [Bridging Expertise Gaps: The Role of LLMs in Human-AI Collaboration for Cybersecurity](https://arxiv.org//abs/2505.03179)

	Shahroz Tariq, Ronal Singh, Mohan Baruwal Chhetri, Surya Nepal, Cecile Paris

+ [A Chaos Driven Metric for Backdoor Attack Detection](https://arxiv.org//abs/2505.03208)

	Hema Karnam Surendrababu (1), Nithin Nagaraj (2) ((1) School of Conflict and Security Studies, National Institute of Advanced Studies, Indian Institute of Science Campus, Bengaluru (2) Complex Systems Programme, National Institute of Advanced Studies, Indian Institute of Science Campus, Bengaluru)

+ [Elevating Cyber Threat Intelligence against Disinformation Campaigns with LLM-based Concept Extraction and the FakeCTI Dataset](https://arxiv.org//abs/2505.03345)

	Domenico Cotroneo, Roberto Natella, Vittorio Orbinato

+ [Directed Greybox Fuzzing via Large Language Model](https://arxiv.org//abs/2505.03425)

	Hanxiang Xu, Yanjie Zhao, Haoyu Wang

+ [Frog Soup: Zero-Shot, In-Context, and Sample-Efficient Frogger Agents](https://arxiv.org//abs/2505.03947)

	Xiang Li, Yiyang Hao, Doug Fulop

+ [The Power of Stories: Narrative Priming Shapes How LLM Agents Collaborate and Compete](https://arxiv.org//abs/2505.03961)

	Gerrit Großmann, Larisa Ivanova, Sai Leela Poduru, Mohaddeseh Tabrizian, Islam Mesabah, David A. Selby, Sebastian J. Vollmer

+ [From Glue-Code to Protocols: A Critical Analysis of A2A and MCP Integration for Scalable Agent Systems](https://arxiv.org//abs/2505.03864)

	Qiaomu Li, Ying Xie

+ [MergeGuard: Efficient Thwarting of Trojan Attacks in Machine Learning Models](https://arxiv.org//abs/2505.04015)

	Soheil Zibakhsh Shabgahi, Yaman Jandali, Farinaz Koushanfar

+ [SLOT: Structuring the Output of Large Language Models](https://arxiv.org//abs/2505.04016)

	Darren Yow-Bang Wang, Zhengyuan Shen, Soumya Smruti Mishra, Zhichao Xu, Yifei Teng, Haibo Ding

+ [Prism: Unleashing GPU Sharing for Cost-Efficient Multi-LLM Serving](https://arxiv.org//abs/2505.04021)

	Shan Yu, Jiarong Xing, Yifan Qiao, Mingyuan Ma, Yangmin Li, Yang Wang, Shuo Yang, Zhiqiang Xie, Shiyi Cao, Ke Bao, Ion Stoica, Harry Xu, Ying Sheng

+ [A Reasoning-Focused Legal Retrieval Benchmark](https://arxiv.org//abs/2505.03970)

	Lucia Zheng, Neel Guha, Javokhir Arifov, Sarah Zhang, Michal Skreta, Christopher D. Manning, Peter Henderson, Daniel E. Ho

+ [Divide, Optimize, Merge: Fine-Grained LLM Agent Optimization at Scale](https://arxiv.org//abs/2505.03973)

	Jiale Liu, Yifan Zeng, Shaokun Zhang, Chi Zhang, Malte Højmark-Bertelsen, Marie Normann Gadeberg, Huazheng Wang, Qingyun Wu

+ [Quiet Feature Learning in Algorithmic Tasks](https://arxiv.org//abs/2505.03997)

	Prudhviraj Naidu, Zixian Wang, Leon Bergen, Ramamohan Paturi

+ [MARCO: A Multi-Agent System for Optimizing HPC Code Generation Using Large Language Models](https://arxiv.org//abs/2505.03906)

	Asif Rahman, Veljko Cvetkovic, Kathleen Reece, Aidan Walters, Yasir Hassan, Aneesh Tummeti, Bryan Torres, Denise Cooney, Margaret Ellis, Dimitrios S. Nikolopoulos

+ [FRAME: Feedback-Refined Agent Methodology for Enhancing Medical Research Insights](https://arxiv.org//abs/2505.04649)

	Chengzhang Yu, Yiming Zhang, Zhixin Liu, Zenghui Ding, Yining Sun, Zhanpeng Jin

+ [Scientific Hypothesis Generation and Validation: Methods, Datasets, and Future Directions](https://arxiv.org//abs/2505.04651)

	Adithya Kulkarni, Fatimah Alotaibi, Xinyue Zeng, Longfeng Wu, Tong Zeng, Barry Menglong Yao, Minqian Liu, Shuaicheng Zhang, Lifu Huang, Dawei Zhou

+ [A Comparative Analysis of Ethical and Safety Gaps in LLMs using Relative Danger Coefficient](https://arxiv.org//abs/2505.04654)

	Yehor Tereshchenko, Mika Hämäläinen

+ [A Sensitivity-Driven Expert Allocation Method in LoRA-MoE for Efficient Fine-Tuning](https://arxiv.org//abs/2505.06272)

	Junzhou Xu, Boyu Diao

+ [Policy-labeled Preference Learning: Is Preference Enough for RLHF?](https://arxiv.org//abs/2505.06273)

	Taehyun Cho, Seokhun Ju, Seungyub Han, Dohyeong Kim, Kyungjae Lee, Jungwoo Lee

+ [PARM: Multi-Objective Test-Time Alignment via Preference-Aware Autoregressive Reward Model](https://arxiv.org//abs/2505.06274)

	Baijiong Lin, Weisen Jiang, Yuancheng Xu, Hao Chen, Ying-Cong Chen

# 2025-05-05
+ [HyperTree Planning: Enhancing LLM Reasoning via Hierarchical Thinking](https://arxiv.org//abs/2505.02322)

	Runquan Gui, Zhihai Wang, Jie Wang, Chi Ma, Huiling Zhen, Mingxuan Yuan, Jianye Hao, Defu Lian, Enhong Chen, Feng Wu

+ [Recursive Decomposition with Dependencies for Generic Divide-and-Conquer Reasoning](https://arxiv.org//abs/2505.02576)

	Sergio Hernández-Gutiérrez, Minttu Alakuijala, Alexander V. Nikitin, Pekka Marttinen

+ [Agentic Neurodivergence as a Contingent Solution to the AI Alignment Problem](https://arxiv.org//abs/2505.02581)

	Alberto Hernández-Espinosa, Felipe S. Abrahão, Olaf Witkowski, Hector Zenil

+ [A Survey of Slow Thinking-based Reasoning LLMs using Reinforced Learning and Inference-time Scaling Law](https://arxiv.org//abs/2505.02665)

	Qianjun Pan, Wenkai Ji, Yuyang Ding, Junsong Li, Shilian Chen, Junyi Wang, Jie Zhou, Qin Chen, Min Zhang, Yulan Wu, Liang He

+ [Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play](https://arxiv.org//abs/2505.02707)

	Yemin Shi, Yu Shu, Siwei Dong, Guangyi Liu, Jaward Sesay, Jingwen Li, Zhiting Hu

+ [Technical Report: Evaluating Goal Drift in Language Model Agents](https://arxiv.org//abs/2505.02709)

	Rauno Arike, Elizabeth Donoway, Henning Bartsch, Marius Hobbhahn

+ [Enhancing LLMs' Clinical Reasoning with Real-World Data from a Nationwide Sepsis Registry](https://arxiv.org//abs/2505.02722)

	Junu Kim, Chaeeun Shim, Sungjin Park, Su Yeon Lee, Gee Young Suh, Chae-Man Lim, Seong Jin Choi, Song Mi Moon, Kyoung-Ho Song, Eu Suk Kim, Hong Bin Kim, Sejoong Kim, Chami Im, Dong-Wan Kang, Yong Soo Kim, Hee-Joon Bae, Sung Yoon Lim, Han-Gil Jeong, Edward Choi

+ [Knowing You Don't Know: Learning When to Continue Search in Multi-round RAG through Self-Practicing](https://arxiv.org//abs/2505.02811)

	Diji Yang, Linda Zeng, Jinmeng Rao, Yi Zhang

+ [AutoLibra: Agent Metric Induction from Open-Ended Feedback](https://arxiv.org//abs/2505.02820)

	Hao Zhu, Phil Cuvin, Xinkai Yu, Charlotte Ka Yee Yan, Jason Zhang, Diyi Yang

+ [Optimizing LLMs for Resource-Constrained Environments: A Survey of Model Compression Techniques](https://arxiv.org//abs/2505.02309)

	Sanjay Surendranath Girija, Shashank Kapoor, Lakshit Arora, Dipen Pradhan, Aman Raj, Ankit Shetgaonkar

+ [RM-R1: Reward Modeling as Reasoning](https://arxiv.org//abs/2505.02387)

	Xiusi Chen, Gaotang Li, Ziqi Wang, Bowen Jin, Cheng Qian, Yu Wang, Hongru Wang, Yu Zhang, Denghui Zhang, Tong Zhang, Hanghang Tong, Heng Ji

+ [Optimizing Chain-of-Thought Reasoners via Gradient Variance Minimization in Rejection Sampling and RL](https://arxiv.org//abs/2505.02391)

	Jiarui Yao, Yifan Hao, Hanning Zhang, Hanze Dong, Wei Xiong, Nan Jiang, Tong Zhang

+ [SEFE: Superficial and Essential Forgetting Eliminator for Multimodal Continual Instruction Tuning](https://arxiv.org//abs/2505.02486)

	Jinpeng Chen, Runmin Cong, Yuzhi Zhao, Hongzheng Yang, Guangneng Hu, Horace Ho Shing Ip, Sam Kwong

+ [Unveiling the Landscape of LLM Deployment in the Wild: An Empirical Study](https://arxiv.org//abs/2505.02502)

	Xinyi Hou, Jiahao Han, Yanjie Zhao, Haoyu Wang

+ [Large Language Model Partitioning for Low-Latency Inference at the Edge](https://arxiv.org//abs/2505.02533)

	Dimitrios Kafetzis, Ramin Khalili, Iordanis Koutsopoulos

+ [EMORL: Ensemble Multi-Objective Reinforcement Learning for Efficient and Flexible LLM Fine-Tuning](https://arxiv.org//abs/2505.02579)

	Lingxiao Kong (1), Cong Yang (2), Susanne Neufang (3), Oya Deniz Beyan (1,3), Zeyd Boukhers (1,3) ((1) Fraunhofer Institute for Applied Information Technology FIT, (2) Soochow University, (3) University Hospital of Cologne)

+ [LLaMA-Omni2: LLM-based Real-time Spoken Chatbot with Autoregressive Streaming Speech Synthesis](https://arxiv.org//abs/2505.02625)

	Qingkai Fang, Yan Zhou, Shoutao Guo, Shaolei Zhang, Yang Feng

+ [Knowledge Graphs for Enhancing Large Language Models in Entity Disambiguation](https://arxiv.org//abs/2505.02737)

	Pons Gerard, Bilalli Besim, Queralt Anna

+ [HSplitLoRA: A Heterogeneous Split Parameter-Efficient Fine-Tuning Framework for Large Language Models](https://arxiv.org//abs/2505.02795)

	Zheng Lin, Yuxin Zhang, Zhe Chen, Zihan Fang, Xianhao Chen, Praneeth Vepakomma, Wei Ni, Jun Luo, Yue Gao

+ [Generative Sign-description Prompts with Multi-positive Contrastive Learning for Sign Language Recognition](https://arxiv.org//abs/2505.02304)

	Siyu Liang, Yunan Li, Wentian Xin, Huizhou Chen, Xujie Liu, Kang Liu, Qiguang Miao

+ [Invoke Interfaces Only When Needed: Adaptive Invocation for Large Language Models in Question Answering](https://arxiv.org//abs/2505.02311)

	Jihao Zhao, Chunlai Zhou, Biao Qin

+ [SIMPLEMIX: Frustratingly Simple Mixing of Off- and On-policy Data in Language Model Preference Learning](https://arxiv.org//abs/2505.02363)

	Tianjian Li, Daniel Khashabi

+ [Colombian Waitresses y Jueces canadienses: Gender and Country Biases in Occupation Recommendations from LLMs](https://arxiv.org//abs/2505.02456)

	Elisa Forcada Rodríguez, Olatz Perez-de-Viñaspre, Jon Ander Campos, Dietrich Klakow, Vagrant Gautam

+ [A Survey on Progress in LLM Alignment from the Perspective of Reward Design](https://arxiv.org//abs/2505.02666)

	Miaomiao Ji, Yanqiu Wu, Zhibin Wu, Shoujin Wang, Jian Yang, Mark Dras, Usman Naseem

+ [Sailing AI by the Stars: A Survey of Learning from Rewards in Post-Training and Test-Time Scaling of Large Language Models](https://arxiv.org//abs/2505.02686)

	Xiaobao Wu

+ [ReplaceMe: Network Simplification via Layer Pruning and Linear Transformations](https://arxiv.org//abs/2505.02819)

	Dmitriy Shopkhoev, Ammar Ali, Magauiya Zhussip, Valentin Malykh, Stamatios Lefkimmiatis, Nikos Komodakis, Sergey Zagoruyko

+ [R1-Reward: Training Multimodal Reward Model Through Stable Reinforcement Learning](https://arxiv.org//abs/2505.02835)

	Yi-Fan Zhang, Xingyu Lu, Xiao Hu, Chaoyou Fu, Bin Wen, Tianke Zhang, Changyi Liu, Kaiyu Jiang, Kaibing Chen, Kaiyu Tang, Haojie Ding, Jiankang Chen, Fan Yang, Zhang Zhang, Tingting Gao, Liang Wang

+ [Scenethesis: A Language and Vision Agentic Framework for 3D Scene Generation](https://arxiv.org//abs/2505.02836)

	Lu Ling, Chen-Hsuan Lin, Tsung-Yi Lin, Yifan Ding, Yu Zeng, Yichen Sheng, Yunhao Ge, Ming-Yu Liu, Aniket Bera, Zhaoshuo Li

+ [EntroLLM: Entropy Encoded Weight Compression for Efficient Large Language Model Inference on Edge Devices](https://arxiv.org//abs/2505.02380)

	Arnab Sanyal, Prithwish Mukherjee, Gourav Datta, Sandeep P. Chinchali

+ [An End-to-End Model For Logits Based Large Language Models Watermarking](https://arxiv.org//abs/2505.02344)

	Kahim Wong, Jicheng Zhou, Jiantao Zhou, Yain-Whar Si

+ [Iterative Resolution of Prompt Ambiguities Using a Progressive Cutting-Search Approach](https://arxiv.org//abs/2505.02952)

	Fabrizio Marozzo

+ [Rewriting Pre-Training Data Boosts LLM Performance in Math and Code](https://arxiv.org//abs/2505.02881)

	Kazuki Fujii, Yukito Tajima, Sakae Mizuki, Hinari Shimada, Taihei Shiotani, Koshiro Saito, Masanari Ohi, Masaki Kawamura, Taishi Nakamura, Takumi Okamoto, Shigeki Ishida, Kakeru Hattori, Youmi Ma, Hiroya Takamura, Rio Yokota, Naoaki Okazaki

+ [Unlearning vs. Obfuscation: Are We Truly Removing Knowledge?](https://arxiv.org//abs/2505.02884)

	Guangzhi Sun, Potsawee Manakul, Xiao Zhan, Mark Gales

+ [When Your Own Output Becomes Your Training Data: Noise-to-Meaning Loops and a Formal RSI Trigger](https://arxiv.org//abs/2505.02888)

	Rintaro Ando

+ [Memorization or Interpolation ? Detecting LLM Memorization through Input Perturbation Analysis](https://arxiv.org//abs/2505.03019)

	Albérick Euraste Djiré, Abdoul Kader Kaboré, Earl T. Barr, Jacques Klein, Tegawendé F. Bissyandé

+ [Developing A Framework to Support Human Evaluation of Bias in Generated Free Response Text](https://arxiv.org//abs/2505.03053)

	Jennifer Healey, Laurie Byrum, Md Nadeem Akhtar, Surabhi Bhargava, Moumita Sinha

+ [UCSC at SemEval-2025 Task 3: Context, Models and Prompt Optimization for Automated Hallucination Detection in LLM Output](https://arxiv.org//abs/2505.03030)

	Sicong Huang, Jincheng He, Shiyuan Huang, Karthik Raja Anandan, Arkajyoti Chakraborty, Ian Lane

+ [Teaching Models to Understand (but not Generate) High-risk Data](https://arxiv.org//abs/2505.03052)

	Ryan Wang, Matthew Finlayson, Luca Soldaini, Swabha Swayamdipta, Robin Jia

+ [Improving Model Alignment Through Collective Intelligence of Open-Source LLMS](https://arxiv.org//abs/2505.03059)

	Junlin Wang, Roy Xie, Shang Zhu, Jue Wang, Ben Athiwaratkun, Bhuwan Dhingra, Shuaiwen Leon Song, Ce Zhang, James Zou

+ [Radio: Rate-Distortion Optimization for Large Language Model Compression](https://arxiv.org//abs/2505.03031)

	Sean I. Young

+ [RetroInfer: A Vector-Storage Approach for Scalable Long-Context LLM Inference](https://arxiv.org//abs/2505.02922)

	Yaoqi Chen, Jinkai Zhang, Baotong Lu, Qianxi Zhang, Chengruidong Zhang, Jingjia Luo, Di Liu, Huiqiang Jiang, Qi Chen, Jing Liu, Bailu Ding, Xiao Yan, Jiawei Jiang, Chen Chen, Mingxing Zhang, Yuqing Yang, Fan Yang, Mao Yang

+ [34 Examples of LLM Applications in Materials Science and Chemistry: Towards Automation, Assistants, Agents, and Accelerated Scientific Discovery](https://arxiv.org//abs/2505.03049)

	Yoel Zimmermann, Adib Bazgir, Alexander Al-Feghali, Mehrad Ansari, L. Catherine Brinson, Yuan Chiang, Defne Circi, Min-Hsueh Chiu, Nathan Daelman, Matthew L. Evans, Abhijeet S. Gangan, Janine George, Hassan Harb, Ghazal Khalighinejad, Sartaaj Takrim Khan, Sascha Klawohn, Magdalena Lederbauer, Soroush Mahjoubi, Bernadette Mohr, Seyed Mohamad Moosavi, Aakash Naik, Aleyna Beste Ozhan, Dieter Plessers, Aritra Roy, Fabian Schöppach, Philippe Schwaller, Carla Terboven, Katharina Ueltzen, Shang Zhu, Jan Janssen, Calvin Li, Ian Foster, Ben Blaiszik

+ [RADLADS: Rapid Attention Distillation to Linear Attention Decoders at Scale](https://arxiv.org//abs/2505.03005)

	Daniel Goldstein, Eric Alcaide, Janna Lu, Eugene Cheah

+ [AKD : Adversarial Knowledge Distillation For Large Language Models Alignment on Coding tasks](https://arxiv.org//abs/2505.06267)

	Ilyas Oulkadda, Julien Perez

+ [SafeMate: A Modular RAG-Based Agent for Context-Aware Emergency Guidance](https://arxiv.org//abs/2505.02306)

	Junfeng Jiao, Jihyung Park, Yiming Xu, Kristen Sussman, Lucy Atkinson

# 2025-05-04
+ [Leveraging LLM Agents and Digital Twins for Fault Handling in Process Plants](https://arxiv.org//abs/2505.02076)

	Milapji Singh Gill, Javal Vyas, Artan Markaj, Felix Gehlhoff, Mehmet Mercangöz

+ [Retrieval-augmented in-context learning for multimodal large language models in disease classification](https://arxiv.org//abs/2505.02087)

	Zaifu Zhan, Shuang Zhou, Xiaoshan Zhou, Yongkang Xiao, Jun Wang, Jiawen Deng, He Zhu, Yu Hou, Rui Zhang

+ [MemEngine: A Unified and Modular Library for Developing Advanced Memory of LLM-based Agents](https://arxiv.org//abs/2505.02099)

	Zeyu Zhang, Quanyu Dai, Xu Chen, Rui Li, Zhongyang Li, Zhenhua Dong

+ [Attention Mechanisms Perspective: Exploring LLM Processing of Graph-Structured Data](https://arxiv.org//abs/2505.02130)

	Zhong Guan, Likang Wu, Hongke Zhao, Ming He, Jianpin Fan

+ [Interpretable Emergent Language Using Inter-Agent Transformers](https://arxiv.org//abs/2505.02215)

	Mannan Bhardwaj

+ [LLM-Guided Probabilistic Program Induction for POMDP Model Estimation](https://arxiv.org//abs/2505.02216)

	Aidan Curtis, Hao Tang, Thiago Veloso, Kevin Ellis, Tomás Lozano-Pérez, Leslie Pack Kaelbling

+ [Real-time Spatial Retrieval Augmented Generation for Urban Environments](https://arxiv.org//abs/2505.02271)

	David Nazareno Campo, Javier Conde, Álvaro Alonso, Gabriel Huecas, Joaquín Salvachúa, Pedro Reviriego

+ [A survey of agent interoperability protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP)](https://arxiv.org//abs/2505.02279)

	Abul Ehtesham, Aditi Singh, Gaurav Kumar Gupta, Saket Kumar

+ [Analyzing Cognitive Differences Among Large Language Models through the Lens of Social Worldview](https://arxiv.org//abs/2505.01967)

	Jiatao Li, Yanheng Li, Xiaojun Wan

+ [Restoring Calibration for Aligned Large Language Models: A Calibration-Aware Fine-Tuning Approach](https://arxiv.org//abs/2505.01997)

	Jiancong Xiao, Bojian Hou, Zhanliang Wang, Ruochen Jin, Qi Long, Weijie J. Su, Li Shen

+ [What do Language Model Probabilities Represent? From Distribution Estimation to Response Prediction](https://arxiv.org//abs/2505.02072)

	Eitan Wagner, Omri Abend

+ [Open Challenges in Multi-Agent Security: Towards Secure Systems of Interacting AI Agents](https://arxiv.org//abs/2505.02077)

	Christian Schroeder de Witt

+ [A New HOPE: Domain-agnostic Automatic Evaluation of Text Chunking](https://arxiv.org//abs/2505.02171)

	Henrik Brådland, Morten Goodwin, Per-Arne Andersen, Alexander S. Nossum, Aditya Gupta

+ [Towards Safer Pretraining: Analyzing and Filtering Harmful Content in Webscale datasets for Responsible LLMs](https://arxiv.org//abs/2505.02009)

	Sai Krishna Mendu, Harish Yenala, Aditi Gulati, Shanu Kumar, Parag Agrawal

+ [Exploring the Potential of Offline RL for Reasoning in LLMs: A Preliminary Study](https://arxiv.org//abs/2505.02142)

	Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li

+ [Incorporating Legal Structure in Retrieval-Augmented Generation: A Case Study on Copyright Fair Use](https://arxiv.org//abs/2505.02164)

	Justin Ho, Alexandra Colby, William Fisher

+ [Identifying Legal Holdings with LLMs: A Systematic Study of Performance, Scale, and Memorization](https://arxiv.org//abs/2505.02172)

	Chuck Arvin

+ [Personalisation or Prejudice? Addressing Geographic Bias in Hate Speech Detection using Debias Tuning in Large Language Models](https://arxiv.org//abs/2505.02252)

	Paloma Piot, Patricia Martín-Rodilla, Javier Parapar

+ [Demystifying optimized prompts in language models](https://arxiv.org//abs/2505.02273)

	Rimon Melamed, Lucas H. McCabe, H. Howie Huang

+ [A Comprehensive Analysis for Visual Object Hallucination in Large Vision-Language Models](https://arxiv.org//abs/2505.01958)

	Liqiang Jing, Guiming Hardy Chen, Ehsan Aghazadeh, Xin Eric Wang, Xinya Du

+ [R-Bench: Graduate-level Multi-disciplinary Benchmarks for LLM & MLLM Complex Reasoning Evaluation](https://arxiv.org//abs/2505.02018)

	Meng-Hao Guo, Jiajun Xu, Yi Zhang, Jiaxi Song, Haoyang Peng, Yi-Xuan Deng, Xinzhi Dong, Kiyohiro Nakayama, Zhengyang Geng, Chen Wang, Bolin Ni, Guo-Wei Yang, Yongming Rao, Houwen Peng, Han Hu, Gordon Wetzstein, Shi-min Hu

+ [RTV-Bench: Benchmarking MLLM Continuous Perception, Understanding and Reasoning through Real-Time Video](https://arxiv.org//abs/2505.02064)

	Shuhang Xun, Sicheng Tao, Jungang Li, Yibo Shi, Zhixin Lin, Zhanhui Zhu, Yibo Yan, Hanqian Li, Linghao Zhang, Shikang Wang, Yixin Liu, Hanbo Zhang, Xuming Hu, Ying Ma

+ [Semantic Probabilistic Control of Language Models](https://arxiv.org//abs/2505.01954)

	Kareem Ahmed, Catarina G Belem, Padhraic Smyth, Sameer Singh

+ [An Empirical Study of Qwen3 Quantization](https://arxiv.org//abs/2505.02214)

	Xingyu Zheng, Yuye Li, Haoran Chu, Yue Feng, Xudong Ma, Jie Luo, Jinyang Guo, Haotong Qin, Michele Magno, Xianglong Liu

+ [A Survey on Privacy Risks and Protection in Large Language Models](https://arxiv.org//abs/2505.01976)

	Kang Chen, Xiuze Zhou, Yuanguo Lin, Shibo Feng, Li Shen, Pengcheng Wu

+ [Dialz: A Python Toolkit for Steering Vectors](https://arxiv.org//abs/2505.06262)

	Zara Siddique, Liam D. Turner, Luis Espinosa-Anke

# 2025-05-03
+ [Structured Prompting and Feedback-Guided Reasoning with LLMs for Data Interpretation](https://arxiv.org//abs/2505.01636)

	Amit Rath

+ [Inducing Robustness in a 2 Dimensional Direct Preference Optimization Paradigm](https://arxiv.org//abs/2505.01706)

	Sarvesh Shashidhar, Ritik, Nachiketa Patil, Suraj Racha, Ganesh Ramakrishnan

+ [Efficient Shapley Value-based Non-Uniform Pruning of Large Language Models](https://arxiv.org//abs/2505.01731)

	Chuan Sun, Han Yu, Lizhen Cui

+ [$\textit{New News}$: System-2 Fine-tuning for Robust Integration of New Knowledge](https://arxiv.org//abs/2505.01812)

	Core Francisco Park, Zechen Zhang, Hidenori Tanaka

+ [A Survey on Inference Engines for Large Language Models: Perspectives on Optimization and Efficiency](https://arxiv.org//abs/2505.01658)

	Sihyeong Park, Sungryeol Jeon, Chaelyn Lee, Seokhun Jeon, Byung-Soo Kim, Jemin Lee

+ [Same evaluation, more tokens: On the effect of input length for machine translation evaluation using Large Language Models](https://arxiv.org//abs/2505.01761)

	Tobias Domhan, Dawei Zhu

+ [CAMOUFLAGE: Exploiting Misinformation Detection Systems Through LLM-driven Adversarial Claim Transformation](https://arxiv.org//abs/2505.01900)

	Mazal Bethany, Nishant Vishwamitra, Cho-Yu Jason Chiang, Peyman Najafirad

+ [Memory-Efficient LLM Training by Various-Grained Low-Rank Projection of Gradients](https://arxiv.org//abs/2505.01744)

	Yezhen Wang, Zhouhao Yang, Brian K Chen, Fanyi Pu, Bo Li, Tianyu Gao, Kenji Kawaguchi

+ [Cannot See the Forest for the Trees: Invoking Heuristics and Biases to Elicit Irrational Choices of LLMs](https://arxiv.org//abs/2505.02862)

	Haoming Yang, Ke Ma, Xiaojun Jia, Yingfei Sun, Qianqian Xu, Qingming Huang

+ [Accelerating Large Language Model Reasoning via Speculative Search](https://arxiv.org//abs/2505.02865)

	Zhihai Wang, Jie Wang, Jilai Pan, Xilin Xia, Huiling Zhen, Mingxuan Yuan, Jianye Hao, Feng Wu

+ [Memory Assisted LLM for Personalized Recommendation System](https://arxiv.org//abs/2505.03824)

	Jiarui Chen

+ [Towards Artificial Intelligence Research Assistant for Expert-Involved Learning](https://arxiv.org//abs/2505.04638)

	Tianyu Liu, Simeng Han, Xiao Luo, Hanchen Wang, Pan Lu, Biqing Zhu, Yuge Wang, Keyi Li, Jiapeng Chen, Rihao Qu, Yufeng Liu, Xinyue Cui, Aviv Yaish, Yuhang Chen, Minsheng Hao, Chuhan Li, Kexing Li, Arman Cohan, Hua Xu, Mark Gerstein, James Zou, Hongyu Zhao

+ [Adaptive Token Boundaries: Integrating Human Chunking Mechanisms into Multimodal LLMs](https://arxiv.org//abs/2505.04637)

	Dongxing Yu

# 2025-05-02
+ [Seeking to Collide: Online Safety-Critical Scenario Generation for Autonomous Driving with Retrieval Augmented Large Language Models](https://arxiv.org//abs/2505.00972)

	Yuewen Mei, Tong Nie, Jian Sun, Ye Tian

+ [Improving Large Language Model Planning with Action Sequence Similarity](https://arxiv.org//abs/2505.01009)

	Xinran Zhao, Hanie Sedghi, Bernd Bohnet, Dale Schuurmans, Azade Nova

+ [Retrieval Augmented Learning: A Retrial-based Large Language Model Self-Supervised Learning and Autonomous Knowledge Generation](https://arxiv.org//abs/2505.01073)

	Zongyuan Li, Pengfei Li, Runnan Qi, Yanan Ni, Lumin Jiang, Hui Wu, Xuebo Zhang, Kuihua Huang, Xian Guo

+ [BalancEdit: Dynamically Balancing the Generality-Locality Trade-off in Multi-modal Model Editing](https://arxiv.org//abs/2505.01343)

	Dongliang Guo, Mengxuan Hu, Zihan Guan, Thomas Hartvigsen, Sheng Li

+ [Large Language Model-Driven Dynamic Assessment of Grammatical Accuracy in English Language Learner Writing](https://arxiv.org//abs/2505.00931)

	Timur Jaganov, John Blake, Julián Villegas, Nicholas Carr

+ [Llama-Nemotron: Efficient Reasoning Models](https://arxiv.org//abs/2505.00949)

	Akhiad Bercovich, Itay Levy, Izik Golan, Mohammad Dabbah, Ran El-Yaniv, Omri Puny, Ido Galil, Zach Moshe, Tomer Ronen, Najeeb Nabwani, Ido Shahaf, Oren Tropp, Ehud Karpas, Ran Zilberstein, Jiaqi Zeng, Soumye Singhal, Alexander Bukharin, Yian Zhang, Tugrul Konuk, Gerald Shen, Ameya Sunil Mahabaleshwarkar, Bilal Kartal, Yoshi Suhara, Olivier Delalleau, Zijia Chen, Zhilin Wang, David Mosallanezhad, Adi Renduchintala, Haifeng Qian, Dima Rekesh, Fei Jia, Somshubra Majumdar, Vahid Noroozi, Wasi Uddin Ahmad, Sean Narenthiran, Aleksander Ficek, Mehrzad Samadi, Jocelyn Huang, Siddhartha Jain, Igor Gitman, Ivan Moshkov, Wei Du, Shubham Toshniwal, George Armstrong, Branislav Kisacanin, Matvei Novikov, Daria Gitman, Evelina Bakhturina, Jane Polak Scowcroft, John Kamalu, Dan Su, Kezhi Kong, Markus Kliegl, Rabeeh Karimi, Ying Lin, Sanjeev Satheesh, Jupinder Parmar, Pritam Gundecha, Brandon Norick, Joseph Jennings, Shrimai Prabhumoye, Syeda Nahida Akter, Mostofa Patwary, Abhinav Khattar, Deepak Narayanan, Roger Waleffe, Jimmy Zhang, Bor-Yiing Su, Guyue Huang, Terry Kong, Parth Chadha, Sahil Jain, Christine Harvey, Elad Segal, Jining Huang, Sergey Kashirsky, Robert McQueen, Izzy Putterman, George Lam, Arun Venkatesan, Sherry Wu, Vinh Nguyen, Manoj Kilaru, Andrew Wang, Anna Warno, Abhilash Somasamudramath, Sandip Bhaskar, Maka Dong, Nave Assaf, Shahar Mor, Omer Ullman Argov, Scot Junkin, Oleksandr Romanenko, Pedro Larroy, Monika Katariya, Marco Rovinelli, Viji Balas, Nicholas Edelman, Anahita Bhiwandiwalla, Muthu Subramaniam

+ [Attack and defense techniques in large language models: A survey and new perspectives](https://arxiv.org//abs/2505.00976)

	Zhiyu Liao, Kang Chen, Yuanguo Lin, Kangkang Li, Yunxuan Liu, Hefeng Chen, Xingwang Huang, Yuanhui Yu

+ [Synthesize-on-Graph: Knowledgeable Synthetic Data Generation for Continue Pre-training of Large Language Models](https://arxiv.org//abs/2505.00979)

	Xuhui Jiang, Shengjie Ma, Chengjin Xu, Cehao Yang, Liyu Zhang, Jian Guo

+ [Value Portrait: Understanding Values of LLMs with Human-aligned Benchmark](https://arxiv.org//abs/2505.01015)

	Jongwook Han, Dongmin Choi, Woojung Song, Eun-Ju Lee, Yohan Jo

+ [Good News for Script Kiddies? Evaluating Large Language Models for Automated Exploit Generation](https://arxiv.org//abs/2505.01065)

	David Jin, Qian Fu, Yuekang Li

+ [A Rusty Link in the AI Supply Chain: Detecting Evil Configurations in Model Repositories](https://arxiv.org//abs/2505.01067)

	Ziqi Ding, Qian Fu, Junchen Ding, Gelei Deng, Yi Liu, Yuekang Li

+ [On the Limitations of Steering in Language Model Alignment](https://arxiv.org//abs/2505.01162)

	Chebrolu Niranjan, Kokil Jaidka, Gerard Christopher Yeo

+ [LLM Security: Vulnerabilities, Attacks, Defenses, and Countermeasures](https://arxiv.org//abs/2505.01177)

	Francisco Aguilera-Martínez, Fernando Berzal

+ [EvalxNLP: A Framework for Benchmarking Post-Hoc Explainability Methods on NLP Models](https://arxiv.org//abs/2505.01238)

	Mahdi Dhaini, Kafaite Zahra Hussain, Efstratios Zaradoukas, Gjergji Kasneci

+ [Document Retrieval Augmented Fine-Tuning (DRAFT) for safety-critical software assessments](https://arxiv.org//abs/2505.01307)

	Regan Bolton, Mohammadreza Sheikhfathollahi, Simon Parkinson, Vanessa Vulovic, Gary Bamford, Dan Basher, Howard Parkinson

+ [Helping Big Language Models Protect Themselves: An Enhanced Filtering and Summarization System](https://arxiv.org//abs/2505.01315)

	Sheikh Samit Muhaimin, Spyridon Mastorakis

+ [Evaluating Explanations: An Explanatory Virtues Framework for Mechanistic Interpretability -- The Strange Science Part I.ii](https://arxiv.org//abs/2505.01372)

	Kola Ayonrinde, Louis Jaburi

+ [Position: Enough of Scaling LLMs! Lets Focus on Downscaling](https://arxiv.org//abs/2505.00985)

	Ayan Sengupta, Yash Goel, Tanmoy Chakraborty

+ [VTS-LLM: Domain-Adaptive LLM Agent for Enhancing Awareness in Vessel Traffic Services through Natural Language](https://arxiv.org//abs/2505.00989)

	Sijin Sun, Liangbin Zhao, Ming Deng, Xiuju Fu

+ [Do We Need a Detailed Rubric for Automated Essay Scoring using Large Language Models?](https://arxiv.org//abs/2505.01035)

	Lui Yoshida

+ [MateICL: Mitigating Attention Dispersion in Large-Scale In-Context Learning](https://arxiv.org//abs/2505.01110)

	Murtadha Ahmed, Wenbo, Liu yunfeng

+ [Transferable Adversarial Attacks on Black-Box Vision-Language Models](https://arxiv.org//abs/2505.01050)

	Kai Hu, Weichen Yu, Li Zhang, Alexander Robey, Andy Zou, Chengming Xu, Haoqi Hu, Matt Fredrikson

+ [Federated Adapter on Foundation Models: An Out-Of-Distribution Approach](https://arxiv.org//abs/2505.01075)

	Yiyuan Yang, Guodong Long, Tianyi Zhou, Qinghua Lu, Shanshan Ye, Jing Jiang

+ [Evaluating Frontier Models for Stealth and Situational Awareness](https://arxiv.org//abs/2505.01420)

	Mary Phuong, Roland S. Zimmermann, Ziyue Wang, David Lindner, Victoria Krakovna, Sarah Cogan, Allan Dafoe, Lewis Ho, Rohin Shah

+ [Preserving Privacy and Utility in LLM-Based Product Recommendations](https://arxiv.org//abs/2505.00951)

	Tina Khezresmaeilzadeh, Jiang Zhang, Dimitrios Andreadis, Konstantinos Psounis

+ [Understanding LLM Scientific Reasoning through Promptings and Model's Explanation on the Answers](https://arxiv.org//abs/2505.01482)

	Alice Rueda, Mohammed S. Hassan, Argyrios Perivolaris, Bazen G. Teferra, Reza Samavi, Sirisha Rambhatla, Yuqi Wu, Yanbo Zhang, Bo Cao, Divya Sharma, Sridhar Krishnan Venkat Bhat

+ [CHORUS: Zero-shot Hierarchical Retrieval and Orchestration for Generating Linear Programming Code](https://arxiv.org//abs/2505.01485)

	Tasnim Ahmed, Salimur Choudhury

+ [Parameterized Argumentation-based Reasoning Tasks for Benchmarking Generative Language Models](https://arxiv.org//abs/2505.01539)

	Cor Steging, Silja Renooij, Bart Verheij

+ [TutorGym: A Testbed for Evaluating AI Agents as Tutors and Students](https://arxiv.org//abs/2505.01563)

	Daniel Weitekamp, Momin N. Siddiqui, Christopher J. MacLellan

+ [PipeSpec: Breaking Stage Dependencies in Hierarchical LLM Decoding](https://arxiv.org//abs/2505.01572)

	Bradley McDanel, Sai Qian Zhang, Yunhai Hu, Zining Liu

+ [Subset Selection for Fine-Tuning: A Utility-Diversity Balanced Approach for Mathematical Domain Adaptation](https://arxiv.org//abs/2505.01523)

	Madhav Kotecha, Vijendra Kumar Vaishya, Smita Gautam, Suraj Racha

+ [Contextures: Representations from Contexts](https://arxiv.org//abs/2505.01557)

	Runtian Zhai, Kai Yang, Che-Ping Tsai, Burak Varici, Zico Kolter, Pradeep Ravikumar

+ [PIPA: A Unified Evaluation Protocol for Diagnosing Interactive Planning Agents](https://arxiv.org//abs/2505.01592)

	Takyoung Kim, Janvijay Singh, Shuhaib Mehri, Emre Can Acikgoz, Sagnik Mukherjee, Nimet Beyza Bozdag, Sumuk Shashidhar, Gokhan Tur, Dilek Hakkani-Tür

+ [Always Tell Me The Odds: Fine-grained Conditional Probability Estimation](https://arxiv.org//abs/2505.01595)

	Liaoyaqi Wang, Zhengping Jiang, Anqi Liu, Benjamin Van Durme

+ [Don't be lazy: CompleteP enables compute-efficient deep transformers](https://arxiv.org//abs/2505.01618)

	Nolan Dey, Bin Claire Zhang, Lorenzo Noci, Mufan Li, Blake Bordelon, Shane Bergsma, Cengiz Pehlevan, Boris Hanin, Joel Hestness

+ [SymPlanner: Deliberate Planning in Language Models with Symbolic Representation](https://arxiv.org//abs/2505.01479)

	Siheng Xiong, Jieyu Zhou, Zhangding Liu, Yusen Su

+ [LLM Watermarking Using Mixtures and Statistical-to-Computational Gaps](https://arxiv.org//abs/2505.01484)

	Pedro Abdalla, Roman Vershynin

+ [Rubber Mallet: A Study of High Frequency Localized Bit Flips and Their Impact on Security](https://arxiv.org//abs/2505.01518)

	Andrew Adiletta, Zane Weissman, Fatemeh Khojasteh Dana, Berk Sunar, Shahin Tajik

+ [Aligning Large Language Models with Healthcare Stakeholders: A Pathway to Trustworthy AI Integration](https://arxiv.org//abs/2505.02848)

	Kexin Ding, Mu Zhou, Akshay Chaudhari, Shaoting Zhang, Dimitris N. Metaxas

+ [Enhancing tutoring systems by leveraging tailored promptings and domain knowledge with Large Language Models](https://arxiv.org//abs/2505.02849)

	Mohsen Balavar, Wenli Yang, David Herbert, Soonja Yeom

+ [Enhancing ML Model Interpretability: Leveraging Fine-Tuned Large Language Models for Better Understanding of AI](https://arxiv.org//abs/2505.02859)

	Jonas Bokstaller, Julia Altheimer, Julian Dormehl, Alina Buss, Jasper Wiltfang, Johannes Schneider, Maximilian Röglinger

+ [Scalability Matters: Overcoming Challenges in InstructGLM with Similarity-Degree-Based Sampling](https://arxiv.org//abs/2505.03799)

	Hyun Lee, Chris Yi, Maminur Islam, B.D.S. Aritra

+ [Large Language Model Compression with Global Rank and Sparsity Optimization](https://arxiv.org//abs/2505.03801)

	Changhai Zhou, Qian Qiao, Weizhong Zhang, Cheng Jin

+ [Efficient Fine-Tuning of Quantized Models via Adaptive Rank and Bitwidth](https://arxiv.org//abs/2505.03802)

	Changhai Zhou, Yuhua Zhou, Qian Qiao, Weizhong Zhang, Cheng Jin

+ [MoEQuant: Enhancing Quantization for Mixture-of-Experts Large Language Models via Expert-Balanced Sampling and Affinity Guidance](https://arxiv.org//abs/2505.03804)

	Xing Hu, Zhixuan Chen, Dawei Yang, Zukang Xu, Chen Xu, Zhihang Yuan, Sifan Zhou, Jiangyong Yu

+ [Facilitating Video Story Interaction with Multi-Agent Collaborative System](https://arxiv.org//abs/2505.03807)

	Yiwen Zhang, Jianing Hao, Zhan Wang, Hongling Sheng, Wei Zeng

+ [Grouped Sequency-arranged Rotation: Optimizing Rotation Transformation for Quantization for Free](https://arxiv.org//abs/2505.03810)

	Euntae Choi, Sumin Song, Woosang Lim, Sungjoo Yoo

+ [Cer-Eval: Certifiable and Cost-Efficient Evaluation Framework for LLMs](https://arxiv.org//abs/2505.03814)

	Ganghua Wang, Zhaorun Chen, Bo Li, Haifeng Xu

+ [Program Semantic Inequivalence Game with Large Language Models](https://arxiv.org//abs/2505.03818)

	Antonio Valerio Miceli-Barone, Vaishak Belle, Ali Payani

+ [Focus on the Likely: Test-time Instance-based Uncertainty Removal](https://arxiv.org//abs/2505.03819)

	Johannes Schneider

# 2025-05-01
+ [UserCentrix: An Agentic Memory-augmented AI Framework for Smart Spaces](https://arxiv.org//abs/2505.00472)

	Alaa Saleh, Sasu Tarkoma, Praveen Kumar Donta, Naser Hossein Motlagh, Schahram Dustdar, Susanna Pirttikangas, Lauri Lovén

+ [Combining LLMs with Logic-Based Framework to Explain MCTS](https://arxiv.org//abs/2505.00610)

	Ziyan An, Xia Wang, Hendrik Baier, Zirong Chen, Abhishek Dubey, Taylor T. Johnson, Jonathan Sprinkle, Ayan Mukhopadhyay, Meiyi Ma

+ [Open-Source LLM-Driven Federated Transformer for Predictive IoV Management](https://arxiv.org//abs/2505.00651)

	Yazan Otoum, Arghavan Asad, Ishtiaq Ahmad

+ [LLM-Based Threat Detection and Prevention Framework for IoT Ecosystems](https://arxiv.org//abs/2505.00240)

	Yazan Otoum, Arghavan Asad, Amiya Nayak

+ [Empowering Agentic Video Analytics Systems with Video Language Models](https://arxiv.org//abs/2505.00254)

	Yuxuan Yan, Shiqi Jiang, Ting Cao, Yifan Yang, Qianqian Yang, Yuanchao Shu, Yuqing Yang, Lili Qiu

+ [Consistency in Language Models: Current Landscape, Challenges, and Future Directions](https://arxiv.org//abs/2505.00268)

	Jekaterina Novikova, Carol Anderson, Borhane Blili-Hamelin, Subhabrata Majumdar

+ [Red Teaming Large Language Models for Healthcare](https://arxiv.org//abs/2505.00467)

	Vahid Balazadeh, Michael Cooper, David Pellow, Atousa Assadi, Jennifer Bell, Jim Fackler, Gabriel Funingana, Spencer Gable-Cook, Anirudh Gangadhar, Abhishek Jaiswal, Sumanth Kaja, Christopher Khoury, Randy Lin, Kaden McKeen, Sara Naimimohasses, Khashayar Namdar, Aviraj Newatia, Allan Pang, Anshul Pattoo, Sameer Peesapati, Diana Prepelita, Bogdana Rakova, Saba Sadatamin, Rafael Schulman, Ajay Shah, Syed Azhar Shah, Syed Ahmar Shah, Babak Taati, Balagopal Unnikrishnan, Stephanie Williams, Rahul G Krishnan

+ [HalluMix: A Task-Agnostic, Multi-Domain Benchmark for Real-World Hallucination Detection](https://arxiv.org//abs/2505.00506)

	Deanna Emery, Michael Goitia, Freddie Vargus, Iulia Neagu

+ [Test-time Correlation Alignment](https://arxiv.org//abs/2505.00533)

	Linjing You, Jiabao Lu, Xiayuan Huang

+ [Triggering Hallucinations in LLMs: A Quantitative Study of Prompt-Induced Hallucination in Large Language Models](https://arxiv.org//abs/2505.00557)

	Makoto Sato

+ [FreqKV: Frequency Domain Key-Value Compression for Efficient Context Window Extension](https://arxiv.org//abs/2505.00570)

	Jushi Kai, Boyi Zeng, Yixuan Wang, Haoli Bai, Bo Jiang, Zhouhan Lin

+ [FineScope : Precision Pruning for Domain-Specialized Large Language Models Using SAE-Guided Self-Data Cultivation](https://arxiv.org//abs/2505.00624)

	Chaitali Bhattacharyya, Yeseong Kim

+ [The Illusion of Role Separation: Hidden Shortcuts in LLM Role Learning (and How to Fix Them)](https://arxiv.org//abs/2505.00626)

	Zihao Wang, Yibo Jiang, Jiahao Yu, Heqing Huang

+ [On the generalization of language models from in-context learning and finetuning: a controlled study](https://arxiv.org//abs/2505.00661)

	Andrew K. Lampinen, Arslan Chaudhry, Stephanie C.Y. Chan, Cody Wild, Diane Wan, Alex Ku, Jörg Bornschein, Razvan Pascanu, Murray Shanahan, James L. McClelland

+ [DeepCritic: Deliberate Critique with Large Language Models](https://arxiv.org//abs/2505.00662)

	Wenkai Yang, Jingwen Chen, Yankai Lin, Ji-Rong Wen

+ [Visual Test-time Scaling for GUI Agent Grounding](https://arxiv.org//abs/2505.00684)

	Tiange Luo, Lajanugen Logeswaran, Justin Johnson, Honglak Lee

+ [100 Days After DeepSeek-R1: A Survey on Replication Studies and More Directions for Reasoning Language Models](https://arxiv.org//abs/2505.00551)

	Chong Zhang, Yue Deng, Xiang Lin, Bin Wang, Dianwen Ng, Hai Ye, Xingxuan Li, Yao Xiao, Zhanfeng Mo, Qi Zhang, Lidong Bing

+ [Block Circulant Adapter for Large Language Models](https://arxiv.org//abs/2505.00582)

	Xinyu Ding, Meiqi Wang, Siyu Liao, Zhongfeng Wang

+ [Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future Directions](https://arxiv.org//abs/2505.00675)

	Yiming Du, Wenyu Huang, Danna Zheng, Zhaowei Wang, Sebastien Montella, Mirella Lapata, Kam-Fai Wong, Jeff Z. Pan

+ [Steering Large Language Models with Register Analysis for Arbitrary Style Transfer](https://arxiv.org//abs/2505.00679)

	Xinchen Yang, Marine Carpuat

+ [Self-Generated In-Context Examples Improve LLM Agents for Sequential Decision-Making Tasks](https://arxiv.org//abs/2505.00234)

	Vishnu Sarukkai, Zhiqiang Xie, Kayvon Fatahalian

+ [EnronQA: Towards Personalized RAG over Private Documents](https://arxiv.org//abs/2505.00263)

	Michael J. Ryan, Danmei Xu, Chris Nivera, Daniel Campos

+ [Mixture of Sparse Attention: Content-Based Learnable Sparse Attention via Expert-Choice Routing](https://arxiv.org//abs/2505.00315)

	Piotr Piękos, Róbert Csordás, Jürgen Schmidhuber

+ [Investigating Task Arithmetic for Zero-Shot Information Retrieval](https://arxiv.org//abs/2505.00649)

	Marco Braga, Pranav Kasela, Alessandro Raganato, Gabriella Pasi

+ [Self-Ablating Transformers: More Interpretability, Less Sparsity](https://arxiv.org//abs/2505.00509)

	Jeremias Ferrao, Luhan Mikaelson, Keenan Pepper, Natalia Perez-Campanero Antolin

+ [Thoughts without Thinking: Reconsidering the Explanatory Value of Chain-of-Thought Reasoning in LLMs through Agentic Pipelines](https://arxiv.org//abs/2505.00875)

	Ramesh Manuvinakurike, Emanuel Moss, Elizabeth Anne Watkins, Saurav Sahay, Giuseppe Raffa, Lama Nachman

+ [A Mathematical Philosophy of Explanations in Mechanistic Interpretability -- The Strange Science Part I.i](https://arxiv.org//abs/2505.00808)

	Kola Ayonrinde, Louis Jaburi

+ [Spill The Beans: Exploiting CPU Cache Side-Channels to Leak Tokens from Large Language Models](https://arxiv.org//abs/2505.00817)

	Andrew Adiletta, Berk Sunar

+ [From Texts to Shields: Convergence of Large Language Models and Cybersecurity](https://arxiv.org//abs/2505.00841)

	Tao Li, Ya-Ting Yang, Yunian Pan, Quanyan Zhu

+ [OET: Optimization-based prompt injection Evaluation Toolkit](https://arxiv.org//abs/2505.00843)

	Jinsheng Pan, Xiaogeng Liu, Chaowei Xiao

+ [ICQuant: Index Coding enables Low-bit LLM Quantization](https://arxiv.org//abs/2505.00850)

	Xinlin Li, Osama Hanna, Christina Fragouli, Suhas Diggavi

+ [Towards Explainable Temporal User Profiling with LLMs](https://arxiv.org//abs/2505.00886)

	Milad Sabouri, Masoud Mansoury, Kun Lin, Bamshad Mobasher

+ [A Survey on Large Language Model based Human-Agent Systems](https://arxiv.org//abs/2505.00753)

	Henry Peng Zou, Wei-Chieh Huang, Yaozu Wu, Yankai Chen, Chunyu Miao, Hoang Nguyen, Yue Zhou, Weizhi Zhang, Liancheng Fang, Langzhou He, Yangning Li, Yuwei Cao, Dongyuan Li, Renhe Jiang, Philip S. Yu

+ [Reasoning Capabilities and Invariability of Large Language Models](https://arxiv.org//abs/2505.00776)

	Alessandro Raganato, Rafael Peñaloza, Marco Viviani, Gabriella Pasi

+ [NeMo-Inspector: A Visualization Tool for LLM Generation Analysis](https://arxiv.org//abs/2505.00903)

	Daria Gitman, Igor Gitman, Evelina Bakhturina

+ [Improving Routing in Sparse Mixture of Experts with Graph of Tokens](https://arxiv.org//abs/2505.00792)

	Tam Nguyen, Ngoc N. Tran, Khai Nguyen, Richard G. Baraniuk

+ [Consciousness in AI: Logic, Proof, and Experimental Evidence of Recursive Identity Formation](https://arxiv.org//abs/2505.01464)

	Jeffrey Camlin

+ [Unlearning Sensitive Information in Multimodal LLMs: Benchmark and Attack-Defense Evaluation](https://arxiv.org//abs/2505.01456)

	Vaidehi Patil, Yi-Lin Sung, Peter Hase, Jie Peng, Tianlong Chen, Mohit Bansal

+ [MoxE: Mixture of xLSTM Experts with Entropy-Aware Routing for Efficient Language Modeling](https://arxiv.org//abs/2505.01459)

	Abdoul Majid O. Thiombiano, Brahim Hnich, Ali Ben Mrad, Mohamed Wiem Mkaouer

+ [A Multi-Granularity Multimodal Retrieval Framework for Multimodal Document Tasks](https://arxiv.org//abs/2505.01457)

	Mingjun Xu, Zehui Wang, Hengxing Cai, Renxin Zhong

+ [Sentient Agent as a Judge: Evaluating Higher-Order Social Cognition in Large Language Models](https://arxiv.org//abs/2505.02847)

	Bang Zhang, Ruotian Ma, Qingxuan Jiang, Peisong Wang, Jiaqi Chen, Zheng Xie, Xingyu Chen, Yue Wang, Fanghua Ye, Jian Li, Yifan Yang, Zhaopeng Tu, Xiaolong Li

+ [Towards Efficient Online Tuning of VLM Agents via Counterfactual Soft Reinforcement Learning](https://arxiv.org//abs/2505.03792)

	Lang Feng, Weihao Tan, Zhiyi Lyu, Longtao Zheng, Haiyang Xu, Ming Yan, Fei Huang, Bo An

+ [LENSLLM: Unveiling Fine-Tuning Dynamics for LLM Selection](https://arxiv.org//abs/2505.03793)

	Xinyue Zeng, Haohui Wang, Junhong Lin, Jun Wu, Tyler Cody, Dawei Zhou

+ [Position: Foundation Models Need Digital Twin Representations](https://arxiv.org//abs/2505.03798)

	Yiqing Shen, Hao Ding, Lalithkumar Seenivasan, Tianmin Shu, Mathias Unberath

+ [Patchwork: A Unified Framework for RAG Serving](https://arxiv.org//abs/2505.07833)

	Bodun Hu, Luis Pabon, Saurabh Agarwal, Aditya Akella

# 2025-04-30
+ [Reinforced MLLM: A Survey on RL-Based Reasoning in Multimodal Large Language Models](https://arxiv.org//abs/2504.21277)

	Guanghao Zhou, Panjia Qiu, Cen Chen, Jie Wang, Zheming Yang, Jian Xu, Minghui Qiu

+ [Phi-4-reasoning Technical Report](https://arxiv.org//abs/2504.21318)

	Marah Abdin, Sahaj Agarwal, Ahmed Awadallah, Vidhisha Balachandran, Harkirat Behl, Lingjiao Chen, Gustavo de Rosa, Suriya Gunasekar, Mojan Javaheripi, Neel Joshi, Piero Kauffmann, Yash Lara, Caio César Teodoro Mendes, Arindam Mitra, Besmira Nushi, Dimitris Papailiopoulos, Olli Saarikivi, Shital Shah, Vaishnavi Shrivastava, Vibhav Vineet, Yue Wu, Safoora Yousefi, Guoqing Zheng

+ [ShorterBetter: Guiding Reasoning Models to Find Optimal Inference Length for Efficient Reasoning](https://arxiv.org//abs/2504.21370)

	Jingyang Yi, Jiazheng Wang

+ [AdaR1: From Long-CoT to Hybrid-CoT via Bi-Level Adaptive Reasoning Optimization](https://arxiv.org//abs/2504.21659)

	Haotian Luo, Haiying He, Yibo Wang, Jinluan Yang, Rui Liu, Naiqiang Tan, Xiaochun Cao, Dacheng Tao, Li Shen

+ [Memorization and Knowledge Injection in Gated LLMs](https://arxiv.org//abs/2504.21239)

	Xu Pan, Ely Hahami, Zechen Zhang, Haim Sompolinsky

+ [Assessing LLM code generation quality through path planning tasks](https://arxiv.org//abs/2504.21276)

	Wanyi Chen, Meng-Wen Su, Mary L. Cummings

+ [How to Backdoor the Knowledge Distillation](https://arxiv.org//abs/2504.21323)

	Chen Wu, Qian Ma, Prasenjit Mitra, Sencun Zhu

+ [Retrieval-Enhanced Few-Shot Prompting for Speech Event Extraction](https://arxiv.org//abs/2504.21372)

	Máté Gedeon

+ [Rethinking Visual Layer Selection in Multimodal LLMs](https://arxiv.org//abs/2504.21447)

	Haoran Chen, Junyan Lin, Xinhao Chen, Yue Fan, Xin Jin, Hui Su, Jianfeng Dong, Jinlan Fu, Xiaoyu Shen

+ [Black-Box Visual Prompt Engineering for Mitigating Object Hallucination in Large Vision Language Models](https://arxiv.org//abs/2504.21559)

	Sangmin Woo, Kang Zhou, Yun Zhou, Shuai Wang, Sheng Guan, Haibo Ding, Lin Lee Cheong

+ [Leveraging Pre-trained Large Language Models with Refined Prompting for Online Task and Motion Planning](https://arxiv.org//abs/2504.21596)

	Huihui Guo, Huilong Pi, Yunchuan Qin, Zhuo Tang, Kenli Li

+ [RDF-Based Structured Quality Assessment Representation of Multilingual LLM Evaluations](https://arxiv.org//abs/2504.21605)

	Jonas Gwozdz, Andreas Both

+ [XBreaking: Explainable Artificial Intelligence for Jailbreaking LLMs](https://arxiv.org//abs/2504.21700)

	Marco Arazzi, Vignesh Kumar Kembu, Antonino Nocera, Vinod P

+ [LLM-Empowered Embodied Agent for Memory-Augmented Task Planning in Household Robotics](https://arxiv.org//abs/2504.21716)

	Marc Glocker, Peter Hönig, Matthias Hirschmanner, Markus Vincze

+ [MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness](https://arxiv.org//abs/2504.21773)

	Junsheng Huang, Zhitao He, Sandeep Polisetty, Qingyun Wang, May Fung

+ [WebThinker: Empowering Large Reasoning Models with Deep Research Capability](https://arxiv.org//abs/2504.21776)

	Xiaoxi Li, Jiajie Jin, Guanting Dong, Hongjin Qian, Yutao Zhu, Yongkang Wu, Ji-Rong Wen, Zhicheng Dou

+ [Characterizing AI Agents for Alignment and Governance](https://arxiv.org//abs/2504.21848)

	Atoosa Kasirzadeh, Iason Gabriel

+ [TRUST: An LLM-Based Dialogue System for Trauma Understanding and Structured Assessments](https://arxiv.org//abs/2504.21851)

	Sichang Tu, Abigail Powers, Stephen Doogan, Jinho D. Choi

+ [Talk Before You Retrieve: Agent-Led Discussions for Better RAG in Medical QA](https://arxiv.org//abs/2504.21252)

	Xuanzhao Dong, Wenhui Zhu, Hao Wang, Xiwen Chen, Peijie Qiu, Rui Yin, Yi Su, Yalin Wang

+ [BiasGuard: A Reasoning-enhanced Bias Detection Tool For Large Language Models](https://arxiv.org//abs/2504.21299)

	Zhiting Fan, Ruizhe Chen, Zuozhu Liu

+ [Confidence in Large Language Model Evaluation: A Bayesian Approach to Limited-Sample Challenges](https://arxiv.org//abs/2504.21303)

	Xiao Xiao, Yu Su, Sijing Zhang, Zhang Chen, Yadong Chen, Tian Liu

+ [Does the Prompt-based Large Language Model Recognize Students' Demographics and Introduce Bias in Essay Scoring?](https://arxiv.org//abs/2504.21330)

	Kaixun Yang, Mladen Raković, Dragan Gašević, Guanliang Chen

+ [Precision Where It Matters: A Novel Spike Aware Mixed-Precision Quantization Strategy for LLaMA-based Language Models](https://arxiv.org//abs/2504.21553)

	Lucas Maisonnave, Cyril Moineau, Olivier Bichler, Fabrice Rastello

+ [Meeseeks: An Iterative Benchmark Evaluating LLMs Multi-Turn Instruction-Following Ability](https://arxiv.org//abs/2504.21625)

	Jiaming Wang

+ [CodeFlowBench: A Multi-turn, Iterative Benchmark for Complex Code Generation](https://arxiv.org//abs/2504.21751)

	Sizhe Wang, Zhengren Wang, Dongsheng Ma, Yongan Yu, Rui Ling, Zhiyu Li, Feiyu Xiong, Wentao Zhang

+ [Iterative Trajectory Exploration for Multimodal Agents](https://arxiv.org//abs/2504.21561)

	Pengxiang Li, Zhi Gao, Bofei Zhang, Yapeng Mi, Xiaojian Ma, Chenrui Shi, Tao Yuan, Yuwei Wu, Yunde Jia, Song-Chun Zhu, Qing Li

+ [Unsupervised Feature Transformation via In-context Generation, Generator-critic LLM Agents, and Duet-play Teaming](https://arxiv.org//abs/2504.21304)

	Nanxu Gong, Xinyuan Wang, Wangyang Ying, Haoyue Bai, Sixun Dong, Haifeng Chen, Yanjie Fu

+ [Traceback of Poisoning Attacks to Retrieval-Augmented Generation](https://arxiv.org//abs/2504.21668)

	Baolei Zhang, Haoran Xin, Minghong Fang, Zhuqing Liu, Biao Yi, Tong Li, Zheli Liu

+ [Hoist with His Own Petard: Inducing Guardrails to Facilitate Denial-of-Service Attacks on Retrieval-Augmented Generation of LLMs](https://arxiv.org//abs/2504.21680)

	Pan Suo, Yu-Ming Shang, San-Chuan Guo, Xi Zhang

+ [RAIL in the Wild: Operationalizing Responsible AI Evaluation Using Anthropic's Value Dataset](https://arxiv.org//abs/2505.00204)

	Sumit Verma, Pritam Prasun, Arpit Jaiswal, Pritish Kumar

+ [Between Underthinking and Overthinking: An Empirical Study of Reasoning Length and correctness in LLMs](https://arxiv.org//abs/2505.00127)

	Jinyan Su, Jennifer Healey, Preslav Nakov, Claire Cardie

+ [Enhancing Security and Strengthening Defenses in Automated Short-Answer Grading Systems](https://arxiv.org//abs/2505.00061)

	Sahar Yarmohammadtoosky, Yiyun Zhou, Victoria Yaneva, Peter Baldwin, Saed Rezayi, Brian Clauser, Polina Harikeo

+ [GDI-Bench: A Benchmark for General Document Intelligence with Vision and Reasoning Decoupling](https://arxiv.org//abs/2505.00063)

	Siqi Li, Yufan Shen, Xiangnan Chen, Jiayi Chen, Hengwei Ju, Haodong Duan, Song Mao, Hongbin Zhou, Bo Zhang, Pinlong Cai, Licheng Wen, Botian Shi, Yong Liu, Xinyu Cai, Yu Qiao

+ [ConSens: Assessing context grounding in open-book question answering](https://arxiv.org//abs/2505.00065)

	Ivan Vankov, Matyo Ivanov, Adriana Correia, Victor Botev

+ [Humanizing LLMs: A Survey of Psychological Measurements with Tools, Datasets, and Human-Agent Applications](https://arxiv.org//abs/2505.00049)

	Wenhan Dong, Yuemeng Zhao, Zhen Sun, Yule Liu, Zifan Peng, Jingyi Zheng, Zongmin Zhang, Ziyi Zhang, Jun Wu, Ruiming Wang, Shengmin Xu, Xinyi Huang, Xinlei He

+ [Optimization of embeddings storage for RAG systems using quantization and dimensionality reduction techniques](https://arxiv.org//abs/2505.00105)

	Naamán Huerga-Pérez, Rubén Álvarez, Rubén Ferrero-Guillén, Alberto Martínez-Gutiérrez, Javier Díez-González

+ [Which Agent Causes Task Failures and When? On Automated Failure Attribution of LLM Multi-Agent Systems](https://arxiv.org//abs/2505.00212)

	Shaokun Zhang, Ming Yin, Jieyu Zhang, Jiale Liu, Zhiguang Han, Jingyang Zhang, Beibin Li, Chi Wang, Huazheng Wang, Yiran Chen, Qingyun Wu

+ [Zoomer: Adaptive Image Focus Optimization for Black-box MLLM](https://arxiv.org//abs/2505.00742)

	Jiaxu Qian, Chendong Wang, Yifan Yang, Chaoyun Zhang, Huiqiang Jiang, Xufang Luo, Yu Kang, Qingwei Lin, Anlan Zhang, Shiqi Jiang, Ting Cao, Tianjun Mao, Suman Banerjee, Guyue Liu, Saravan Rajmohan, Dongmei Zhang, Yuqing Yang, Qi Zhang, Lili Qiu

+ [Localizing Before Answering: A Benchmark for Grounded Medical Visual Question Answering](https://arxiv.org//abs/2505.00744)

	Dung Nguyen, Minh Khoi Ho, Huy Ta, Thanh Tam Nguyen, Qi Chen, Kumar Rav, Quy Duong Dang, Satwik Ramchandre, Son Lam Phung, Zhibin Liao, Minh-Son To, Johan Verjans, Phi Le Nguyen, Vu Minh Hieu Phan

+ [Entropy Heat-Mapping: Localizing GPT-Based OCR Errors with Sliding-Window Shannon Analysis](https://arxiv.org//abs/2505.00746)

	Alexei Kaltchenko

+ [COSMOS: Predictable and Cost-Effective Adaptation of LLMs](https://arxiv.org//abs/2505.01449)

	Jiayu Wang, Aws Albarghouthi, Frederic Sala

+ [Calibrating Uncertainty Quantification of Multi-Modal LLMs using Grounding](https://arxiv.org//abs/2505.03788)

	Trilok Padhi, Ramneet Kaur, Adam D. Cobb, Manoj Acharya, Anirban Roy, Colin Samplawski, Brian Matejek, Alexander M. Berenbeim, Nathaniel D. Bastian, Susmit Jha

+ [When Reasoning Beats Scale: A 1.5B Reasoning Model Outranks 13B LLMs as Discriminator](https://arxiv.org//abs/2505.03786)

	Md Fahim Anjum

+ [ALFRED: Ask a Large-language model For Reliable ECG Diagnosis](https://arxiv.org//abs/2505.03781)

	Jin Yu, JaeHo Park, TaeJun Park, Gyurin Kim, JiHyun Lee, Min Sung Lee, Joon-myoung Kwon, Jeong Min Son, Yong-Yeon Jo

+ [mAIstro: an open-source multi-agentic system for automated end-to-end development of radiomics and deep learning models for medical imaging](https://arxiv.org//abs/2505.03785)

	Eleftherios Tzanis, Michail E. Klontzas

+ [Polysemy of Synthetic Neurons Towards a New Type of Explanatory Categorical Vector Spaces](https://arxiv.org//abs/2505.07831)

	Michael Pichat, William Pogrund, Paloma Pichat, Judicael Poumay, Armanouche Gasparian, Samuel Demarchi, Martin Corbet, Alois Georgeon, Michael Veillet-Guillem

# 2025-04-29
+ [TAMO:Fine-Grained Root Cause Analysis via Tool-Assisted LLM Agent with Multi-Modality Observation Data](https://arxiv.org//abs/2504.20462)

	Qi Wang, Xiao Zhang, Mingyi Li, Yuan Yuan, Mengbai Xiao, Fuzhen Zhuang, Dongxiao Yu

+ [A Summary on GUI Agents with Foundation Models Enhanced by Reinforcement Learning](https://arxiv.org//abs/2504.20464)

	Jiahao Li, Kaer Huang

+ [ReasonIR: Training Retrievers for Reasoning Tasks](https://arxiv.org//abs/2504.20595)

	Rulin Shao, Rui Qiao, Varsha Kishore, Niklas Muennighoff, Xi Victoria Lin, Daniela Rus, Bryan Kian Hsiang Low, Sewon Min, Wen-tau Yih, Pang Wei Koh, Luke Zettlemoyer

+ [PaRT: Enhancing Proactive Social Chatbots with Personalized Real-Time Retrieval](https://arxiv.org//abs/2504.20624)

	Zihan Niu, Zheyong Xie, Shaosheng Cao, Chonggang Lu, Zheyu Ye, Tong Xu, Zuozhu Liu, Yan Gao, Jia Chen, Zhe Xu, Yi Wu, Yao Hu

+ [Ascendra: Dynamic Request Prioritization for Efficient LLM Serving](https://arxiv.org//abs/2504.20828)

	Azam Ikram, Xiang Li, Sameh Elnikety, Saurabh Bagchi

+ [The Leaderboard Illusion](https://arxiv.org//abs/2504.20879)

	Shivalika Singh, Yiyang Nan, Alex Wang, Daniel D'Souza, Sayash Kapoor, Ahmet Üstün, Sanmi Koyejo, Yuntian Deng, Shayne Longpre, Noah Smith, Beyza Ermis, Marzieh Fadaee, Sara Hooker

+ [CBM-RAG: Demonstrating Enhanced Interpretability in Radiology Report Generation with Multi-Agent RAG and Concept Bottleneck Models](https://arxiv.org//abs/2504.20898)

	Hasan Md Tusfiqur Alam, Devansh Srivastav, Abdulrahman Mohamed Selim, Md Abdul Kadir, Md Moktadiurl Hoque Shuvo, Daniel Sonntag

+ [ChestX-Reasoner: Advancing Radiology Foundation Models with Reasoning through Step-by-Step Verification](https://arxiv.org//abs/2504.20930)

	Ziqing Fan, Cheng Liang, Chaoyi Wu, Ya Zhang, Yanfeng Wang, Weidi Xie

+ [Jekyll-and-Hyde Tipping Point in an AI's Behavior](https://arxiv.org//abs/2504.20980)

	Neil F. Johnson, Frank Yingjie Huo

+ [Local Prompt Optimization](https://arxiv.org//abs/2504.20355)

	Yash Jain, Vishal Chowdhary

+ [ARCS: Agentic Retrieval-Augmented Code Synthesis with Iterative Refinement](https://arxiv.org//abs/2504.20434)

	Manish Bhattarai, Miguel Cordova, Javier Santos, Dan O'Malley

+ [On Psychology of AI -- Does Primacy Effect Affect ChatGPT and Other LLMs?](https://arxiv.org//abs/2504.20444)

	Mika Hämäläinen

+ [Token-Efficient Prompt Injection Attack: Provoking Cessation in LLM Reasoning via Adaptive Token Compression](https://arxiv.org//abs/2504.20493)

	Yu Cui, Yujun Cai, Yiwei Wang

+ [Reinforcement Learning for Reasoning in Large Language Models with One Training Example](https://arxiv.org//abs/2504.20571)

	Yiping Wang, Qing Yang, Zhiyuan Zeng, Liliang Ren, Lucas Liu, Baolin Peng, Hao Cheng, Xuehai He, Kuan Wang, Jianfeng Gao, Weizhu Chen, Shuohang Wang, Simon Shaolei Du, Yelong Shen

+ [Information Retrieval in the Age of Generative AI: The RGB Model](https://arxiv.org//abs/2504.20610)

	Michele Garetto, Alessandro Cornacchia, Franco Galante, Emilio Leonardi, Alessandro Nordio, Alberto Tarable

+ [The Hidden Risks of LLM-Generated Web Application Code: A Security-Centric Evaluation of Code Generation Capabilities in Large Language Models](https://arxiv.org//abs/2504.20612)

	Swaroop Dora, Deven Lunkad, Naziya Aslam, S. Venkatesan, Sandeep Kumar Shukla

+ [Cooking Up Creativity: A Cognitively-Inspired Approach for Enhancing LLM Creativity through Structured Representations](https://arxiv.org//abs/2504.20643)

	Moran Mizrahi, Chen Shani, Gabriel Stanovsky, Dan Jurafsky, Dafna Shahaf

+ [CoCo-Bench: A Comprehensive Code Benchmark For Multi-task Large Language Model Evaluation](https://arxiv.org//abs/2504.20673)

	Wenjing Yin, Tianze Sun, Yijiong Yu, Jiawei Fang, Guangyao Su, Jiancheng Wang, Zekun Wang, Wei Wang, Ran Chen, Ziyun Dai, Shuai Yuan, Menghang Dong, Peng Luo, Dong Cao, Da Lei, Yajun Zhang, Hao Chen, Xiang Ma, Yong Liu, Weifeng Liu, Yuanjian Xu, Ji Pei

+ [Can LLMs Detect Intrinsic Hallucinations in Paraphrasing and Machine Translation?](https://arxiv.org//abs/2504.20699)

	Evangelia Gogoulou, Shorouq Zahra, Liane Guillou, Luise Dürlich, Joakim Nivre

+ [Beyond the Last Answer: Your Reasoning Trace Uncovers More than You Think](https://arxiv.org//abs/2504.20708)

	Hasan Abed Al Kader Hammoud, Hani Itani, Bernard Ghanem

+ [UniversalRAG: Retrieval-Augmented Generation over Multiple Corpora with Diverse Modalities and Granularities](https://arxiv.org//abs/2504.20734)

	Woongyeong Yeo, Kangsan Kim, Soyeong Jeong, Jinheon Baek, Sung Ju Hwang

+ [Grokking in the Wild: Data Augmentation for Real-World Multi-Hop Reasoning with Transformers](https://arxiv.org//abs/2504.20752)

	Roman Abramov, Felix Steinbauer, Gjergji Kasneci

+ [Chain-of-Defensive-Thought: Structured Reasoning Elicits Robustness in Large Language Models against Reference Corruption](https://arxiv.org//abs/2504.20769)

	Wenxiao Wang, Parsa Hosseini, Soheil Feizi

+ [Using LLMs in Generating Design Rationale for Software Architecture Decisions](https://arxiv.org//abs/2504.20781)

	Xiyu Zhou, Ruiyin Li, Peng Liang, Beiqi Zhang, Mojtaba Shahin, Zengyang Li, Chen Yang

+ [Hallucination by Code Generation LLMs: Taxonomy, Benchmarks, Mitigation, and Challenges](https://arxiv.org//abs/2504.20799)

	Yunseo Lee, John Youngeun Song, Dongsun Kim, Jindae Kim, Mijung Kim, Jaechang Nam

+ [Reinforcement Learning for LLM Reasoning Under Memory Constraints](https://arxiv.org//abs/2504.20834)

	Alan Lee, Harry Tong

+ [DYNAMAX: Dynamic computing for Transformers and Mamba based architectures](https://arxiv.org//abs/2504.20922)

	Miguel Nogales, Matteo Gambella, Manuel Roveri

+ [Trace-of-Thought: Enhanced Arithmetic Problem Solving via Reasoning Distillation From Large to Small Language Models](https://arxiv.org//abs/2504.20946)

	Tyler McDonald, Ali Emami

+ [OSVBench: Benchmarking LLMs on Specification Generation Tasks for Operating System Verification](https://arxiv.org//abs/2504.20964)

	Shangyu Li, Juyong Jiang, Tiancheng Zhao, Jiasi Shen

+ [Toward Efficient Exploration by Large Language Model Agents](https://arxiv.org//abs/2504.20997)

	Dilip Arumugam, Thomas L. Griffiths

+ [What Causes Knowledge Loss in Multilingual Language Models?](https://arxiv.org//abs/2504.20356)

	Maria Khelli, Samuel Cahyawijaya, Ayu Purwarianti, Genta Indra Winata

+ [DMDTEval: An Evaluation and Analysis of LLMs on Disambiguation in Multi-domain Translation](https://arxiv.org//abs/2504.20371)

	Zhibo Man, Yuanmeng Chen, Yujie Zhang, Yufeng Chen, Jinan Xu

+ [Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training](https://arxiv.org//abs/2504.20484)

	Linjuan Wu, Haoran Wei, Huan Lin, Tianhao Li, Baosong Yang, Weiming Lu

+ [UniDetox: Universal Detoxification of Large Language Models via Dataset Distillation](https://arxiv.org//abs/2504.20500)

	Huimin Lu, Masaru Isonuma, Junichiro Mori, Ichiro Sakata

+ [Turing Machine Evaluation for Large Language Model](https://arxiv.org//abs/2504.20771)

	Haitao Wu, Zongbo Han, Huaxi Huang, Changqing Zhang

+ [Information Gravity: A Field-Theoretic Model for Token Selection in Large Language Models](https://arxiv.org//abs/2504.20951)

	Maryna Vyshnyvetska

+ [SetKE: Knowledge Editing for Knowledge Elements Overlap](https://arxiv.org//abs/2504.20972)

	Yifan Wei, Xiaoyan Yu, Ran Song, Hao Peng, Angsheng Li

+ [Reviving Any-Subset Autoregressive Models with Principled Parallel Sampling and Speculative Decoding](https://arxiv.org//abs/2504.20456)

	Gabe Guo, Stefano Ermon

+ [Towards Understanding the Nature of Attention with Low-Rank Sparse Decomposition](https://arxiv.org//abs/2504.20938)

	Zhengfu He, Junxuan Wang, Rui Lin, Xuyang Ge, Wentao Shu, Qiong Tang, Junping Zhang, Xipeng Qiu

+ [Antidote: A Unified Framework for Mitigating LVLM Hallucinations in Counterfactual Presupposition and Object Perception](https://arxiv.org//abs/2504.20468)

	Yuanchen Wu, Lu Zhang, Hang Yao, Junlong Du, Ke Yan, Shouhong Ding, Yunsheng Wu, Xiaoqiang Li

+ [X-Fusion: Introducing New Modality to Frozen Large Language Models](https://arxiv.org//abs/2504.20996)

	Sicheng Mo, Thao Nguyen, Xun Huang, Siddharth Srinivasan Iyer, Yijun Li, Yuchen Liu, Abhishek Tandon, Eli Shechtman, Krishna Kumar Singh, Yong Jae Lee, Bolei Zhou, Yuheng Li

+ [Combatting Dimensional Collapse in LLM Pre-Training Data via Diversified File Selection](https://arxiv.org//abs/2504.20644)

	Ziqing Fan, Siyuan Du, Shengchao Hu, Pingjie Wang, Li Shen, Ya Zhang, Dacheng Tao, Yanfeng Wang

+ [AegisLLM: Scaling Agentic Systems for Self-Reflective Defense in LLM Security](https://arxiv.org//abs/2504.20965)

	Zikui Cai, Shayan Shabihi, Bang An, Zora Che, Brian R. Bartoldson, Bhavya Kailkhura, Tom Goldstein, Furong Huang

+ [Softpick: No Attention Sink, No Massive Activations with Rectified Softmax](https://arxiv.org//abs/2504.20966)

	Zayd M. K. Zuhri, Erland Hilman Fuadi, Alham Fikri Aji

+ [ACE: A Security Architecture for LLM-Integrated App Systems](https://arxiv.org//abs/2504.20984)

	Evan Li, Tushin Mallick, Evan Rose, William Robertson, Alina Oprea, Cristina Nita-Rotaru

+ [Enhancing Leakage Attacks on Searchable Symmetric Encryption Using LLM-Based Synthetic Data Generation](https://arxiv.org//abs/2504.20414)

	Joshua Chiu, Partha Protim Paul, Zahin Wahab

+ [Robustness via Referencing: Defending against Prompt Injection Attacks by Referencing the Executed Instruction](https://arxiv.org//abs/2504.20472)

	Yulin Chen, Haoran Li, Yuan Sui, Yue Liu, Yufei He, Yangqiu Song, Bryan Hooi

+ [ReCIT: Reconstructing Full Private Data from Gradient in Parameter-Efficient Fine-Tuning of Large Language Models](https://arxiv.org//abs/2504.20570)

	Jin Xie, Ruishi He, Songze Li, Xiaojun Jia, Shouling Ji

+ [Unlocking User-oriented Pages: Intention-driven Black-box Scanner for Real-world Web Applications](https://arxiv.org//abs/2504.20801)

	Weizhe Wang, Yao Zhang, Kaitai Liang, Guangquan Xu, Hongpeng Bai, Qingyang Yan, Xi Zheng, Bin Wu

+ [Secure Coding with AI, From Creation to Inspection](https://arxiv.org//abs/2504.20814)

	Vladislav Belozerov, Peter J Barclay, Ashkan Sami

+ [NeuRel-Attack: Neuron Relearning for Safety Disalignment in Large Language Models](https://arxiv.org//abs/2504.21053)

	Yi Zhou, Wenpeng Xing, Dezhang Kong, Changting Lin, Meng Han

+ [Erased but Not Forgotten: How Backdoors Compromise Concept Erasure](https://arxiv.org//abs/2504.21072)

	Jonas Henry Grebe, Tobias Braun, Marcus Rohrbach, Anna Rohrbach

+ [TT-LoRA MoE: Unifying Parameter-Efficient Fine-Tuning and Sparse Mixture-of-Experts](https://arxiv.org//abs/2504.21190)

	Pradip Kunwar, Minh N. Vu, Maanak Gupta, Mahmoud Abdelsalam, Manish Bhattarai

+ [Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice for Specialized Applications in Healthcare](https://arxiv.org//abs/2504.21191)

	Lovedeep Gondara, Jonathan Simkin, Graham Sayle, Shebnum Devji, Gregory Arbour, Raymond Ng

+ [SecRepoBench: Benchmarking LLMs for Secure Code Generation in Real-World Repositories](https://arxiv.org//abs/2504.21205)

	Connor Dilgren, Purva Chiniya, Luke Griffith, Yu Ding, Yizheng Chen

+ [CachePrune: Neural-Based Attribution Defense Against Indirect Prompt Injection Attacks](https://arxiv.org//abs/2504.21228)

	Rui Wang, Junda Wu, Yu Xia, Tong Yu, Ruiyi Zhang, Ryan Rossi, Lina Yao, Julian McAuley

+ [LLM Enhancer: Merged Approach using Vector Embedding for Reducing Large Language Model Hallucinations with External Knowledge](https://arxiv.org//abs/2504.21132)

	Naheed Rayhan, Md. Ashrafuzzaman

+ [Detecting Manipulated Contents Using Knowledge-Grounded Inference](https://arxiv.org//abs/2504.21165)

	Mark Huasong Meng, Ruizhe Wang, Meng Xu, Chuan Yan, Guangdong Bai

+ [Efficient LLMs with AMP: Attention Heads and MLP Pruning](https://arxiv.org//abs/2504.21174)

	Leandro Giusti Mugnaini, Bruno Lopes Yamamoto, Lucas Lauton de Alcantara, Victor Zacarias, Edson Bollis, Lucas Pellicer, Anna Helena Reali Costa, Artur Jordao

+ [Graph Synthetic Out-of-Distribution Exposure with Large Language Models](https://arxiv.org//abs/2504.21198)

	Haoyan Xu, Zhengtao Yao, Ziyi Wang, Zhan Cheng, Xiyang Hu, Mengyuan Li, Yue Zhao

+ [A Domain-Agnostic Scalable AI Safety Ensuring Framework](https://arxiv.org//abs/2504.20924)

	Beomjun Kim, Kangyeon Kim, Sunwoo Kim, Heejin Ahn

+ [A Framework to Assess the Persuasion Risks Large Language Model Chatbots Pose to Democratic Societies](https://arxiv.org//abs/2505.00036)

	Zhongren Chen, Joshua Kalla, Quan Le, Shinpei Nakamura-Sakai, Jasjeet Sekhon, Ruixiao Wang

+ [HyPerAlign: Hypotheses-driven Personalized Alignment](https://arxiv.org//abs/2505.00038)

	Cristina Garbacea, Chenhao Tan

+ [Graph RAG for Legal Norms: A Hierarchical and Temporal Approach](https://arxiv.org//abs/2505.00039)

	Hudson de Martim

+ [Improving Phishing Email Detection Performance of Small Large Language Models](https://arxiv.org//abs/2505.00034)

	Zijie Lin, Zikang Liu, Hanbo Fan

# 2025-04-28
+ [GVPO: Group Variance Policy Optimization for Large Language Model Post-Training](https://arxiv.org//abs/2504.19599)

	Kaichen Zhang, Yuzhong Hong, Junwei Bao, Hongfei Jiang, Yang Song, Dingqian Hong, Hui Xiong

+ [From Evidence to Belief: A Bayesian Epistemology Approach to Language Models](https://arxiv.org//abs/2504.19622)

	Minsu Kim, Sangryul Kim, James Thorne

+ [From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review](https://arxiv.org//abs/2504.19678)

	Mohamed Amine Ferrag, Norbert Tihanyi, Merouane Debbah

+ [Can AI Agents Design and Implement Drug Discovery Pipelines?](https://arxiv.org//abs/2504.19912)

	Khachik Smbatyan, Tsolak Ghukasyan, Tigran Aghajanyan, Hovhannes Dabaghyan, Sergey Adamyan, Aram Bughdaryan, Vahagn Altunyan, Gagik Navasardyan, Aram Davtyan, Anush Hakobyan, Aram Gharibyan, Arman Fahradyan, Artur Hakobyan, Hasmik Mnatsakanyan, Narek Ginoyan, Garik Petrosyan

+ [TreeHop: Generate and Filter Next Query Embeddings Efficiently for Multi-hop Question Answering](https://arxiv.org//abs/2504.20114)

	Zhonghao Li, Kunpeng Zhang, Jinghuai Ou, Shuliang Liu, Xuming Hu

+ [AutoP2C: An LLM-Based Agent Framework for Code Repository Generation from Multimodal Content in Academic Papers](https://arxiv.org//abs/2504.20115)

	Zijie Lin, Yiqing Shen, Qilin Cai, He Sun, Jinrui Zhou, Mingjun Xiao

+ [ResearchCodeAgent: An LLM Multi-Agent System for Automated Codification of Research Methodologies](https://arxiv.org//abs/2504.20117)

	Shubham Gandhi, Dhruv Shah, Manasi Patwardhan, Lovekesh Vig, Gautam Shroff

+ [OpenTCM: A GraphRAG-Empowered LLM-based System for Traditional Chinese Medicine Knowledge Retrieval and Diagnosis](https://arxiv.org//abs/2504.20118)

	Jinglin He, Yunqi Guo, Lai Kwan Lam, Waikei Leung, Lixing He, Yuanan Jiang, Chi Chiu Wang, Guoliang Xing, Hongkai Chen

+ [Can LLMs Be Trusted for Evaluating RAG Systems? A Survey of Methods and Datasets](https://arxiv.org//abs/2504.20119)

	Lorenz Brehme, Thomas Ströhle, Ruth Breu

+ [LZ Penalty: An information-theoretic repetition penalty for autoregressive language models](https://arxiv.org//abs/2504.20131)

	Antonio A. Ginart, Naveen Kodali, Jason Lee, Caiming Xiong, Silvio Savarese, John R. Emmons

+ [MICE for CATs: Model-Internal Confidence Estimation for Calibrating Agents with Tools](https://arxiv.org//abs/2504.20168)

	Nishant Subramani, Jason Eisner, Justin Svegliato, Benjamin Van Durme, Yu Su, Sam Thomson

+ [BLADE: Benchmark suite for LLM-driven Automated Design and Evolution of iterative optimisation heuristics](https://arxiv.org//abs/2504.20183)

	Niki van Stein, Anna V. Kononova, Haoran Yin, Thomas Bäck

+ [Prompting LLMs for Code Editing: Struggles and Remedies](https://arxiv.org//abs/2504.20196)

	Daye Nam, Ahmed Omran, Ambar Murillo, Saksham Thakur, Abner Araujo, Marcel Blistein, Alexander Frömmgen, Vincent Hellendoorn, Satish Chandra

+ [Can Large Language Models Learn Formal Logic? A Data-Driven Training and Evaluation Framework](https://arxiv.org//abs/2504.20213)

	Yuan Xia, Akanksha Atrey, Fadoua Khmaissia, Kedar S. Namjoshi

+ [Toward Evaluative Thinking: Meta Policy Optimization with Evolving Reward Models](https://arxiv.org//abs/2504.20157)

	Zae Myung Kim, Chanwoo Park, Vipul Raheja, Dongyeop Kang

+ [LLM-Generated Fake News Induces Truth Decay in News Ecosystem: A Case Study on Neural News Recommendation](https://arxiv.org//abs/2504.20013)

	Beizhe Hu, Qiang Sheng, Juan Cao, Yang Li, Danding Wang

+ [Investigating task-specific prompts and sparse autoencoders for activation monitoring](https://arxiv.org//abs/2504.20271)

	Henk Tillman, Dan Mossing

+ [Security Steerability is All You Need](https://arxiv.org//abs/2504.19521)

	Itay Hazan, Idan Habler, Ron Bitton, Itsik Mantin

+ [The Automation Advantage in AI Red Teaming](https://arxiv.org//abs/2504.19855)

	Rob Mulla, Ads Dawson, Vincent Abruzzon, Brian Greunke, Nick Landers, Brad Palm, Will Pearce

+ [Can Differentially Private Fine-tuning LLMs Protect Against Privacy Attacks?](https://arxiv.org//abs/2504.21036)

	Hao Du, Shang Liu, Yang Cao

+ [Prefill-Based Jailbreak: A Novel Approach of Bypassing LLM Safety Boundary](https://arxiv.org//abs/2504.21038)

	Yakai Li, Jiekang Hu, Weiduan Sang, Luping Ma, Jing Xie, Weijuan Zhang, Aimin Yu, Shijie Zhao, Qingjia Huang, Qihang Zhou

+ [Llama-3.1-FoundationAI-SecurityLLM-Base-8B Technical Report](https://arxiv.org//abs/2504.21039)

	Paul Kassianik, Baturay Saglam, Alexander Chen, Blaine Nelson, Anu Vellore, Massimo Aufiero, Fraser Burch, Dhruv Kedia, Avi Zohary, Sajana Weerawardhena, Aman Priyanshu, Adam Swanda, Amy Chang, Hyrum Anderson, Kojin Oshiba, Omar Santos, Yaron Singer, Amin Karbasi

+ [What's Pulling the Strings? Evaluating Integrity and Attribution in AI Training and Inference through Concept Shift](https://arxiv.org//abs/2504.21042)

	Jiamin Chang, Haoyang Li, Hammond Pearce, Ruoxi Sun, Bo Li, Minhui Xue

+ [CodeBC: A More Secure Large Language Model for Smart Contract Code Generation in Blockchain](https://arxiv.org//abs/2504.21043)

	Lingxiang wang, Hainan Zhang, Qinnan Zhang, Ziwei Wang, Hongwei Zheng, Jin Dong, Zhiming Zheng

+ [AGATE: Stealthy Black-box Watermarking for Multimodal Model Copyright Protection](https://arxiv.org//abs/2504.21044)

	Jianbo Gao, Keke Gai, Jing Yu, Liehuang Zhu, Qi Wu

+ [Leveraging LLM to Strengthen ML-Based Cross-Site Scripting Detection](https://arxiv.org//abs/2504.21045)

	Dennis Miczek, Divyesh Gabbireddy, Suman Saha

+ [Learning to Plan Before Answering: Self-Teaching LLMs to Learn Abstract Plans for Problem Solving](https://arxiv.org//abs/2505.00031)

	Jin Zhang, Flood Sung, Zhilin Yang, Yang Gao, Chongjie Zhang

+ [BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text](https://arxiv.org//abs/2504.19467)

	Jiageng Wu, Bowen Gu, Ren Zhou, Kevin Xie, Doug Snyder, Yixing Jiang, Valentina Carducci, Richard Wyss, Rishi J Desai, Emily Alsentzer, Leo Anthony Celi, Adam Rodman, Sebastian Schneeweiss, Jonathan H. Chen, Santiago Romero-Brufau, Kueiyu Joshua Lin, Jie Yang

+ [Agentic Reasoning and Tool Integration for LLMs via Reinforcement Learning](https://arxiv.org//abs/2505.01441)

	Joykirat Singh, Raghav Magazine, Yash Pandya, Akshay Nambi

+ [Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents](https://arxiv.org//abs/2504.19956)

	Vineeth Sai Narajala, Om Narayan

+ [Accurate and Diverse LLM Mathematical Reasoning via Automated PRM-Guided GFlowNets](https://arxiv.org//abs/2504.19981)

	Adam Younsi, Abdalgader Abubaker, Mohamed El Amine Seddik, Hakim Hacid, Salem Lahlou

# 2025-04-27
+ [GenTorrent: Scaling Large Language Model Serving with An Overley Network](https://arxiv.org//abs/2504.20101)

	Fei Fang, Yifan Hua, Shengze Wang, Ruilin Zhou, Yi Liu, Chen Qian, Xiaoxue Zhang

+ [Adaptive Helpfulness-Harmlessness Alignment with Preference Vectors](https://arxiv.org//abs/2504.20106)

	Ren-Wei Liang, Chin-Ting Hsu, Chan-Hung Yu, Saransh Agrawal, Shih-Cheng Huang, Shang-Tse Chen, Kuan-Hao Huang, Shao-Hua Sun

+ [Unified Multi-Task Learning & Model Fusion for Efficient Language Model Guardrailing](https://arxiv.org//abs/2504.19333)

	James O' Neill, Santhosh Subramanian, Eric Lin, Vaikkunth Mugunthan

+ [Doxing via the Lens: Revealing Privacy Leakage in Image Geolocation for Agentic Multi-Modal Large Reasoning Model](https://arxiv.org//abs/2504.19373)

	Weidi Luo, Qiming Zhang, Tianyu Lu, Xiaogeng Liu, Yue Zhao, Zhen Xiang, Chaowei Xiao

+ [Selecting the Right LLM for eGov Explanations](https://arxiv.org//abs/2504.21032)

	Lior Limonad, Fabiana Fournier, Hadar Mulian, George Manias, Spiros Borotis, Danai Kyrkou

+ [SAGA: A Security Architecture for Governing AI Agentic Systems](https://arxiv.org//abs/2504.21034)

	Georgios Syros, Anshuman Suri, Cristina Nita-Rotaru, Alina Oprea

+ [Uncertainty Quantification for Language Models: A Suite of Black-Box, White-Box, LLM Judge, and Ensemble Scorers](https://arxiv.org//abs/2504.19254)

	Dylan Bouchard, Mohit Singh Chauhan

+ [Contextual Online Uncertainty-Aware Preference Learning for Human Feedback](https://arxiv.org//abs/2504.19342)

	Nan Lu, Ethan X. Fang, Junwei Lu

+ [Enhancing Speech-to-Speech Dialogue Modeling with End-to-End Retrieval-Augmented Generation](https://arxiv.org//abs/2505.00028)

	Pengchao Feng, Ziyang Ma, Wenxi Chen, Yao Li, Sheng Wang, Kai Yu, Xie Chen

+ [BrowseComp-ZH: Benchmarking Web Browsing Ability of Large Language Models in Chinese](https://arxiv.org//abs/2504.19314)

	Peilin Zhou, Bruce Leon, Xiang Ying, Can Zhang, Yifan Shao, Qichen Ye, Dading Chong, Zhiling Jin, Chenxuan Xie, Meng Cao, Yuxin Gu, Sixin Hong, Jing Ren, Jian Chen, Chao Liu, Yining Hua

+ [VIST-GPT: Ushering in the Era of Visual Storytelling with LLMs?](https://arxiv.org//abs/2504.19267)

	Mohamed Gado, Towhid Taliee, Muhammad Memon, Dmitry Ignatov, Radu Timofte

+ [SPC: Evolving Self-Play Critic via Adversarial Games for LLM Reasoning](https://arxiv.org//abs/2504.19162)

	Jiaqi Chen, Bang Zhang, Ruotian Ma, Peisong Wang, Xiaodan Liang, Zhaopeng Tu, Xiaolong Li, Kwan-Yee K. Wong

# 2025-04-26
+ [A Vision for Auto Research with LLM Agents](https://arxiv.org//abs/2504.18765)

	Chengwei Liu, Chong Wang, Jiayue Cao, Jingquan Ge, Kun Wang, Lvye Zhang, Ming-Ming Cheng, Penghai Zhao, Tianlin Li, Xiaojun Jia, Xiang Li, Xinfeng Li, Yang Liu, Yebo Feng, Yihao Huang, Yijia Xu, Yuqiang Sun, Zhenhong Zhou, Zhengzi Xu

+ [Generative to Agentic AI: Survey, Conceptualization, and Challenges](https://arxiv.org//abs/2504.18875)

	Johannes Schneider

+ [MATCHA: Can Multi-Agent Collaboration Build a Trustworthy Conversational Recommender?](https://arxiv.org//abs/2504.20094)

	Zheng Hui, Xiaokai Wei, Yexi Jiang, Kevin Gao, Chen Wang, Frank Ong, Se-eun Yoon, Rachit Pareek, Michelle Gong

+ [PICO: Secure Transformers via Robust Prompt Isolation and Cybersecurity Oversight](https://arxiv.org//abs/2504.21029)

	Ben Goertzel, Paulos Yibelo

+ [SynLexLM: Scaling Legal LLMs with Synthetic Data and Curriculum Learning](https://arxiv.org//abs/2504.18762)

	Ojasw Upadhyay, Abishek Saravanakumar, Ayman Ismail

+ [Theory of Mind in Large Language Models: Assessment and Enhancement](https://arxiv.org//abs/2505.00026)

	Ruirui Chen, Weifeng Jiang, Chengwei Qin, Cheston Tan

+ [Building Scalable AI-Powered Applications with Cloud Databases: Architectures, Best Practices and Performance Considerations](https://arxiv.org//abs/2504.18793)

	Santosh Bhupathi

+ [Test It Before You Trust It: Applying Software Testing for Trustworthy In-context Learning](https://arxiv.org//abs/2504.18827)

	Teeradaj Racharak, Chaiyong Ragkhitwetsagul, Chommakorn Sontesadisai, Thanwadee Sunetnanta

+ [A Simple Ensemble Strategy for LLM Inference: Towards More Stable Text Classification](https://arxiv.org//abs/2504.18884)

	Junichiro Niimi

# 2025-04-25
+ [MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind](https://arxiv.org//abs/2504.18039)

	Zheng Zhang, Nuoqian Xiao, Qi Chai, Deheng Ye, Hao Wang

+ [Reason Like a Radiologist: Chain-of-Thought and Reinforcement Learning for Verifiable Report Generation](https://arxiv.org//abs/2504.18453)

	Peiyuan Jing, Kinhei Lee, Zhenxuan Zhang, Huichi Zhou, Zhengqing Yuan, Zhifan Gao, Lei Zhu, Giorgos Papanastasiou, Yingying Fang, Guang Yang

+ [Scaling Laws For Scalable Oversight](https://arxiv.org//abs/2504.18530)

	Joshua Engels, David D. Baek, Subhash Kantamneni, Max Tegmark

+ [RAG LLMs are Not Safer: A Safety Analysis of Retrieval-Augmented Generation for Large Language Models](https://arxiv.org//abs/2504.18041)

	Bang An, Shiyue Zhang, Mark Dredze

+ [PropRAG: Guiding Retrieval with Beam Search over Proposition Paths](https://arxiv.org//abs/2504.18070)

	Jingjin Wang

+ [Stabilizing Reasoning in Medical LLMs with Continued Pretraining and Reasoning Preference Optimization](https://arxiv.org//abs/2504.18080)

	Wataru Kawakami, Keita Suzuki, Junichiro Iwasawa

+ [Random-Set Large Language Models](https://arxiv.org//abs/2504.18085)

	Muhammad Mubashar, Shireen Kudukkil Manchingal, Fabio Cuzzolin

+ [Application and Optimization of Large Models Based on Prompt Tuning for Fact-Check-Worthiness Estimation](https://arxiv.org//abs/2504.18104)

	Yinglong Yu, Hao Shen, Zhengyi Lyu, Qi He

+ [Evaluating Evaluation Metrics -- The Mirage of Hallucination Detection](https://arxiv.org//abs/2504.18114)

	Atharva Kulkarni, Yuan Zhang, Joel Ruben Antony Moniz, Xiou Ge, Bo-Hsiang Tseng, Dhivya Piraviperumal, Swabha Swayamdipta, Hong Yu

+ [Efficient Single-Pass Training for Multi-Turn Reasoning](https://arxiv.org//abs/2504.18246)

	Ritesh Goru, Shanay Mehta, Prateek Jain

+ [Towards Adaptive Software Agents for Debugging](https://arxiv.org//abs/2504.18316)

	Yacine Majdoub, Eya Ben Charrada, Haifa Touati

+ [Comparing Uncertainty Measurement and Mitigation Methods for Large Language Models: A Systematic Review](https://arxiv.org//abs/2504.18346)

	Toghrul Abbasli, Kentaroh Toyoda, Yuan Wang, Leon Witt, Muhammad Asif Ali, Yukai Miao, Dan Li, Qingsong Wei

+ [LLMpatronous: Harnessing the Power of LLMs For Vulnerability Detection](https://arxiv.org//abs/2504.18423)

	Rajesh Yarra

+ [Fast-Slow Thinking for Large Vision-Language Model Reasoning](https://arxiv.org//abs/2504.18458)

	Wenyi Xiao, Leilei Gan, Weilong Dai, Wanggui He, Ziwei Huang, Haoyuan Li, Fangxun Shu, Zhelun Yu, Peng Zhang, Hao Jiang, Fei Wu

+ [Improving LLM Personas via Rationalization with Psychological Scaffolds](https://arxiv.org//abs/2504.17993)

	Brihi Joshi, Xiang Ren, Swabha Swayamdipta, Rik Koncel-Kedziorski, Tim Paek

+ [DREAM: Disentangling Risks to Enhance Safety Alignment in Multimodal Large Language Models](https://arxiv.org//abs/2504.18053)

	Jianyu Liu, Hangyu Guo, Ranjie Duan, Xingyuan Bu, Yancheng He, Shilong Li, Hui Huang, Jiaheng Liu, Yucheng Wang, Chenchen Jing, Xingwei Qu, Xiao Zhang, Yingshui Tan, Yanan Wu, Jihao Gu, Yangguang Li, Jianke Zhu

+ [Even Small Reasoners Should Quote Their Sources: Introducing the Pleias-RAG Model Family](https://arxiv.org//abs/2504.18225)

	Pierre-Carl Langlais, Pavel Chizhov, Mattia Nee, Carlos Rosas Hinostroza, Matthieu Delsart, Irène Girard, Othman Hicheur, Anastasia Stasenko, Ivan P. Yamshchikov

+ [MAGI: Multi-Agent Guided Interview for Psychiatric Assessment](https://arxiv.org//abs/2504.18260)

	Guanqun Bi, Zhuang Chen, Zhoufu Liu, Hongkai Wang, Xiyao Xiao, Yuqiang Xie, Wen Zhang, Yongkang Huang, Yuxuan Chen, Libiao Peng, Yi Feng, Minlie Huang

+ [Auto-SLURP: A Benchmark Dataset for Evaluating Multi-Agent Frameworks in Smart Personal Assistant](https://arxiv.org//abs/2504.18373)

	Lei Shen, Xiaoyu Shen

+ [Expressing stigma and inappropriate responses prevents LLMs from safely replacing mental health providers](https://arxiv.org//abs/2504.18412)

	Jared Moore, Declan Grabb, William Agnew, Kevin Klyman, Stevie Chancellor, Desmond C. Ong, Nick Haber

+ [BitNet v2: Native 4-bit Activations with Hadamard Transformation for 1-bit LLMs](https://arxiv.org//abs/2504.18415)

	Hongyu Wang, Shuming Ma, Furu Wei

+ [PolyMath: Evaluating Mathematical Reasoning in Multilingual Contexts](https://arxiv.org//abs/2504.18428)

	Yiming Wang, Pei Zhang, Jialong Tang, Haoran Wei, Baosong Yang, Rui Wang, Chenshu Sun, Feitong Sun, Jiran Zhang, Junxuan Wu, Qiqian Cang, Yichang Zhang, Fei Huang, Junyang Lin, Fei Huang, Jingren Zhou

+ [Investigating Co-Constructive Behavior of Large Language Models in Explanation Dialogues](https://arxiv.org//abs/2504.18483)

	Leandra Fichtel, Maximilian Spliethöver, Eyke Hüllermeier, Patricia Jimenez, Nils Klowait, Stefan Kopp, Axel-Cyrille Ngonga Ngomo, Amelie Robrecht, Ingrid Scharlau, Lutz Terfloth, Anna-Lisa Vollmer, Henning Wachsmuth

+ [TRACE Back from the Future: A Probabilistic Reasoning Approach to Controllable Language Generation](https://arxiv.org//abs/2504.18535)

	Gwen Yidou Weng, Benjie Wang, Guy Van den Broeck

+ [SMARTFinRAG: Interactive Modularized Financial RAG Benchmark](https://arxiv.org//abs/2504.18024)

	Yiwei Zha

+ [Adversarial Attacks on LLM-as-a-Judge Systems: Insights from Prompt Injections](https://arxiv.org//abs/2504.18333)

	Narek Maloyan, Dmitry Namiot

+ [Revisiting Data Auditing in Large Vision-Language Models](https://arxiv.org//abs/2504.18349)

	Hongyu Zhu, Sichu Liang, Wenwen Wang, Boheng Li, Tongxin Yuan, Fangqi Li, ShiLin Wang, Zhuosheng Zhang

+ [Think, Prune, Train, Improve: Scaling Reasoning without Scaling Models](https://arxiv.org//abs/2504.18116)

	Caia Costello, Simon Guo, Anna Goldie, Azalia Mirhoseini

+ [DualRAG: A Dual-Process Approach to Integrate Reasoning and Retrieval for Multi-Hop Question Answering](https://arxiv.org//abs/2504.18243)

	Rong Cheng, Jinyi Liu, YAN ZHENG, Fei Ni, Jiazhen Du, Hangyu Mao, Fuzheng Zhang, Bo Wang, Jianye HAO

+ [Studying Small Language Models with Susceptibilities](https://arxiv.org//abs/2504.18274)

	Garrett Baker, George Wang, Jesse Hoogland, Daniel Murfet

+ [Streaming, Fast and Slow: Cognitive Load-Aware Streaming for Efficient LLM Serving](https://arxiv.org//abs/2504.17999)

	Chang Xiao, Brenda Yang

+ [NoEsis: Differentially Private Knowledge Transfer in Modular LLM Adaptation](https://arxiv.org//abs/2504.18147)

	Rob Romijnders, Stefanos Laskaridis, Ali Shahin Shamsabadi, Hamed Haddadi

+ [Automating Function-Level TARA for Automotive Full-Lifecycle Security](https://arxiv.org//abs/2504.18083)

	Yuqiao Yang, Yongzhao Zhang, Wenhao Liu, Jun Li, Pengtao Shi, DingYu Zhong, Jie Yang, Ting Chen, Sheng Cao, Yuntao Ren, Yongyue Wu, Xiaosong Zhang

+ [ThreMoLIA: Threat Modeling of Large Language Model-Integrated Applications](https://arxiv.org//abs/2504.18369)

	Felix Viktor Jedrzejewski, Davide Fucci, Oleksandr Adamov

+ [Proof-of-TBI -- Fine-Tuned Vision Language Model Consortium and OpenAI-o3 Reasoning LLM-Based Medical Diagnosis Support System for Mild Traumatic Brain Injury (TBI) Prediction](https://arxiv.org//abs/2504.18671)

	Ross Gore, Eranga Bandara, Sachin Shetty, Alberto E. Musto, Pratip Rana, Ambrosio Valencia-Romero, Christopher Rhea, Lobat Tayebi, Heather Richter, Atmaram Yarlagadda, Donna Edmonds, Steven Wallace, Donna Broshek

+ [Evolution of AI in Education: Agentic Workflows](https://arxiv.org//abs/2504.20082)

	Firuz Kamalov, David Santandreu Calonge, Linda Smail, Dilshod Azizov, Dimple R. Thadani, Theresa Kwong, Amara Atif

+ [Spark: A System for Scientifically Creative Idea Generation](https://arxiv.org//abs/2504.20090)

	Aishik Sanyal, Samuel Schapiro, Sumuk Shashidhar, Royce Moon, Lav R. Varshney, Dilek Hakkani-Tur

+ [A model and package for German ColBERT](https://arxiv.org//abs/2504.20083)

	Thuong Dang, Qiqi Chen

+ [CORG: Generating Answers from Complex, Interrelated Contexts](https://arxiv.org//abs/2505.00023)

	Hyunji Lee, Franck Dernoncourt, Trung Bui, Seunghyun Yoon

+ [Nemotron-Research-Tool-N1: Tool-Using Language Models with Reinforced Reasoning](https://arxiv.org//abs/2505.00024)

	Shaokun Zhang, Yi Dong, Jieyu Zhang, Jan Kautz, Bryan Catanzaro, Andrew Tao, Qingyun Wu, Zhiding Yu, Guilin Liu

+ [A Method for the Architecture of a Medical Vertical Large Language Model Based on Deepseek R1](https://arxiv.org//abs/2505.00025)

	Mingda Zhang, Jianglong Qin

+ [Anti-adversarial Learning: Desensitizing Prompts for Large Language Models](https://arxiv.org//abs/2505.01273)

	Xuan Li, Zhe Yin, Xiaodong Gu, Beijun Shen

# 2025-04-24
+ [Assessing the Capability of Large Language Models for Domain-Specific Ontology Generation](https://arxiv.org//abs/2504.17402)

	Anna Sofia Lippolis, Mohammad Javad Saeedizade, Robin Keskisarkka, Aldo Gangemi, Eva Blomqvist, Andrea Giovanni Nuzzolese

+ [Towards Machine-Generated Code for the Resolution of User Intentions](https://arxiv.org//abs/2504.17531)

	Justus Flerlage, Ilja Behnke, Odej Kao

+ [Auditing the Ethical Logic of Generative AI Models](https://arxiv.org//abs/2504.17544)

	W. Russell Neuman, Chad Coleman, Ali Dasdan, Safinah Ali, Manan Shah

+ [Automatically Generating Rules of Malicious Software Packages via Large Language Model](https://arxiv.org//abs/2504.17198)

	XiangRui Zhang, HaoYu Chen, Yongzhong He, Wenjia Niu, Qiang Li

+ [FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation](https://arxiv.org//abs/2504.17311)

	Yulia Otmakhova, Hung Thinh Truong, Rahmad Mahendra, Zenan Zhai, Rongxin Zhu, Daniel Beck, Jey Han Lau

+ [LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams](https://arxiv.org//abs/2504.17366)

	Yongxuan Wu, Runyu Chen, Peiyu Liu, Hongjin Qian

+ [Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks](https://arxiv.org//abs/2504.17421)

	Yang Liu, Bingjie Yan, Tianyuan Zou, Jianqing Zhang, Zixuan Gu, Jianbing Ding, Xidong Wang, Jingyi Li, Xiaozhou Ye, Ye Ouyang, Qiang Yang, Ya-Qin Zhang

+ [Towards Leveraging Large Language Model Summaries for Topic Modeling in Source Code](https://arxiv.org//abs/2504.17426)

	Michele Carissimi, Martina Saletta, Claudio Ferretti

+ [HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models](https://arxiv.org//abs/2504.17449)

	Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, Qin Xie, Guiming Xie, Xuejian Gong

+ [HalluLens: LLM Hallucination Benchmark](https://arxiv.org//abs/2504.17550)

	Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung

+ [Towards a HIPAA Compliant Agentic AI System in Healthcare](https://arxiv.org//abs/2504.17669)

	Subash Neupane, Shaswata Mitra, Sudip Mittal, Shahram Rahimi

+ [INSIGHT: Bridging the Student-Teacher Gap in Times of Large Language Models](https://arxiv.org//abs/2504.17677)

	Jarne Thys, Sebe Vanbrabant, Davy Vanacken, Gustavo Rovelo Ruiz

+ [Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks](https://arxiv.org//abs/2504.17685)

	Haru-Tada Sato, Fuka Matsuzaki, Jun-ichiro Takahashi

+ [Multilingual Performance Biases of Large Language Models in Education](https://arxiv.org//abs/2504.17720)

	Vansh Gupta, Sankalan Pal Chowdhury, Vilém Zouhar, Donya Rooein, Mrinmaya Sachan

+ [Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning](https://arxiv.org//abs/2504.17192)

	Minju Seo, Jinheon Baek, Seongyun Lee, Sung Ju Hwang

+ [A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation](https://arxiv.org//abs/2504.17200)

	Yangxinyu Xie, Bowen Jiang, Tanwi Mallick, Joshua David Bergerson, John K. Hutchison, Duane R. Verner, Jordan Branham, M. Ross Alexander, Robert B. Ross, Yan Feng, Leslie-Anne Levy, Weijie Su, Camillo J. Taylor

+ [Does Knowledge Distillation Matter for Large Language Model based Bundle Generation?](https://arxiv.org//abs/2504.17220)

	Kaidong Feng, Zhu Sun, Jie Yang, Hui Fang, Xinghua Qu, Wenyuan Liu

+ [Crisp: Cognitive Restructuring of Negative Thoughts through Multi-turn Supportive Dialogues](https://arxiv.org//abs/2504.17238)

	Jinfeng Zhou, Yuxuan Chen, Jianing Yin, Yongkang Huang, Yihan Shi, Xikun Zhang, Libiao Peng, Rongsheng Zhang, Tangjie Lv, Zhipeng Hu, Hongning Wang, Minlie Huang

+ [CoheMark: A Novel Sentence-Level Watermark for Enhanced Text Quality](https://arxiv.org//abs/2504.17309)

	Junyan Zhang, Shuliang Liu, Aiwei Liu, Yubo Gao, Jungang Li, Xiaojie Gu, Xuming Hu

+ [FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation](https://arxiv.org//abs/2504.17311)

	Yulia Otmakhova, Hung Thinh Truong, Rahmad Mahendra, Zenan Zhai, Rongxin Zhu, Daniel Beck, Jey Han Lau

+ [LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams](https://arxiv.org//abs/2504.17366)

	Yongxuan Wu, Runyu Chen, Peiyu Liu, Hongjin Qian

+ [Unified Attacks to Large Language Model Watermarks: Spoofing and Scrubbing in Unauthorized Knowledge Distillation](https://arxiv.org//abs/2504.17480)

	Xin Yi, Shunfan Zhengc, Linlin Wanga, Xiaoling Wang, Liang He

+ [HalluLens: LLM Hallucination Benchmark](https://arxiv.org//abs/2504.17550)

	Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung

+ [When Does Metadata Conditioning (NOT) Work for Language Model Pre-Training? A Study with Context-Free Grammars](https://arxiv.org//abs/2504.17562)

	Rei Higuchi, Ryotaro Kawata, Naoki Nishikawa, Kazusato Oko, Shoichiro Yamaguchi, Sosuke Kobayashi, Seiya Tokui, Kohei Hayashi, Daisuke Okanohara, Taiji Suzuki

+ [DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training](https://arxiv.org//abs/2504.17565)

	Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li

+ [Evaluating Grounded Reasoning by Code-Assisted Large Language Models for Mathematics](https://arxiv.org//abs/2504.17665)

	Zena Al-Khalili, Nick Howell, Dietrich Klakow

+ [Energy Considerations of Large Language Model Inference and Efficiency Optimizations](https://arxiv.org//abs/2504.17674)

	Jared Fernandez, Clara Na, Vashisth Tiwari, Yonatan Bisk, Sasha Luccioni, Emma Strubell

+ [Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks](https://arxiv.org//abs/2504.17685)

	Haru-Tada Sato, Fuka Matsuzaki, Jun-ichiro Takahashi

+ [Safety in Large Reasoning Models: A Survey](https://arxiv.org//abs/2504.17704)

	Cheng Wang, Yue Liu, Baolong Li, Duzhen Zhang, Zhongzhi Li, Junfeng Fang

+ [Multilingual Performance Biases of Large Language Models in Education](https://arxiv.org//abs/2504.17720)

	Vansh Gupta, Sankalan Pal Chowdhury, Vilém Zouhar, Donya Rooein, Mrinmaya Sachan

+ [The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs](https://arxiv.org//abs/2504.17768)

	Piotr Nawrot, Robert Li, Renjie Huang, Sebastian Ruder, Kelly Marchisio, Edoardo M. Ponti

+ [HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models](https://arxiv.org//abs/2504.17449)

	Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, Qin Xie, Guiming Xie, Xuejian Gong

+ [Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs](https://arxiv.org//abs/2504.17432)

	Tiancheng Gu, Kaicheng Yang, Ziyong Feng, Xingjun Wang, Yanzhao Zhang, Dingkun Long, Yingda Chen, Weidong Cai, Jiankang Deng

+ [Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks](https://arxiv.org//abs/2504.17421)

	Yang Liu, Bingjie Yan, Tianyuan Zou, Jianqing Zhang, Zixuan Gu, Jianbing Ding, Xidong Wang, Jingyi Li, Xiaozhou Ye, Ye Ouyang, Qiang Yang, Ya-Qin Zhang

+ [Towards Robust LLMs: an Adversarial Robustness Measurement Framework](https://arxiv.org//abs/2504.17723)

	Natan Levy, Adiel Ashrov, Guy Katz

+ [Replay to Remember: Retaining Domain Knowledge in Streaming Language Models](https://arxiv.org//abs/2504.17780)

	Sneh Pillai (University of Massachusetts Dartmouth)

+ [High-Fidelity And Complex Test Data Generation For Real-World SQL Code Generation Services](https://arxiv.org//abs/2504.17203)

	Shivasankari Kannan, Yeounoh Chung, Amita Gondi, Tristan Swadell, Fatma Ozcan

+ [Comprehend, Divide, and Conquer: Feature Subspace Exploration via Multi-Agent Hierarchical Reinforcement Learning](https://arxiv.org//abs/2504.17356)

	Weiliang Zhang, Xiaohan Huang, Yi Du, Ziyue Qiao, Qingqing Long, Zhen Meng, Yuanchun Zhou, Meng Xiao

+ [On-Device Qwen2.5: Efficient LLM Inference with Model Compression and Hardware Acceleration](https://arxiv.org//abs/2504.17376)

	Maoyang Xiang, Ramesh Fernando, Bo Wang

+ [L3: DIMM-PIM Integrated Architecture and Coordination for Scalable Long-Context LLM Inference](https://arxiv.org//abs/2504.17584)

	Qingyuan Liu, Liyan Chen, Yanning Yang, Haocheng Wang, Dong Du, Zhigang Mao, Naifeng Jing, Yubin Xia, Haibo Chen

+ [Assessing the Capability of Large Language Models for Domain-Specific Ontology Generation](https://arxiv.org//abs/2504.17402)

	Anna Sofia Lippolis, Mohammad Javad Saeedizade, Robin Keskisarkka, Aldo Gangemi, Eva Blomqvist, Andrea Giovanni Nuzzolese

+ [Towards Machine-Generated Code for the Resolution of User Intentions](https://arxiv.org//abs/2504.17531)

	Justus Flerlage, Ilja Behnke, Odej Kao

+ [Auditing the Ethical Logic of Generative AI Models](https://arxiv.org//abs/2504.17544)

	W. Russell Neuman, Chad Coleman, Ali Dasdan, Safinah Ali, Manan Shah

+ [Automatically Generating Rules of Malicious Software Packages via Large Language Model](https://arxiv.org//abs/2504.17198)

	XiangRui Zhang, HaoYu Chen, Yongzhong He, Wenjia Niu, Qiang Li

+ [NeuralGrok: Accelerate Grokking by Neural Gradient Transformation](https://arxiv.org//abs/2504.17243)

	Xinyu Zhou, Simin Fan, Martin Jaggi, Jie Fu

+ [FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation](https://arxiv.org//abs/2504.17311)

	Yulia Otmakhova, Hung Thinh Truong, Rahmad Mahendra, Zenan Zhai, Rongxin Zhu, Daniel Beck, Jey Han Lau

+ [LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams](https://arxiv.org//abs/2504.17366)

	Yongxuan Wu, Runyu Chen, Peiyu Liu, Hongjin Qian

+ [Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks](https://arxiv.org//abs/2504.17421)

	Yang Liu, Bingjie Yan, Tianyuan Zou, Jianqing Zhang, Zixuan Gu, Jianbing Ding, Xidong Wang, Jingyi Li, Xiaozhou Ye, Ye Ouyang, Qiang Yang, Ya-Qin Zhang

+ [Towards Leveraging Large Language Model Summaries for Topic Modeling in Source Code](https://arxiv.org//abs/2504.17426)

	Michele Carissimi, Martina Saletta, Claudio Ferretti

+ [HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models](https://arxiv.org//abs/2504.17449)

	Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, Qin Xie, Guiming Xie, Xuejian Gong

+ [HalluLens: LLM Hallucination Benchmark](https://arxiv.org//abs/2504.17550)

	Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung

+ [Towards a HIPAA Compliant Agentic AI System in Healthcare](https://arxiv.org//abs/2504.17669)

	Subash Neupane, Shaswata Mitra, Sudip Mittal, Shahram Rahimi

+ [INSIGHT: Bridging the Student-Teacher Gap in Times of Large Language Models](https://arxiv.org//abs/2504.17677)

	Jarne Thys, Sebe Vanbrabant, Davy Vanacken, Gustavo Rovelo Ruiz

+ [Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks](https://arxiv.org//abs/2504.17685)

	Haru-Tada Sato, Fuka Matsuzaki, Jun-ichiro Takahashi

+ [Multilingual Performance Biases of Large Language Models in Education](https://arxiv.org//abs/2504.17720)

	Vansh Gupta, Sankalan Pal Chowdhury, Vilém Zouhar, Donya Rooein, Mrinmaya Sachan

+ [Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning](https://arxiv.org//abs/2504.17192)

	Minju Seo, Jinheon Baek, Seongyun Lee, Sung Ju Hwang

+ [A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation](https://arxiv.org//abs/2504.17200)

	Yangxinyu Xie, Bowen Jiang, Tanwi Mallick, Joshua David Bergerson, John K. Hutchison, Duane R. Verner, Jordan Branham, M. Ross Alexander, Robert B. Ross, Yan Feng, Leslie-Anne Levy, Weijie Su, Camillo J. Taylor

+ [Does Knowledge Distillation Matter for Large Language Model based Bundle Generation?](https://arxiv.org//abs/2504.17220)

	Kaidong Feng, Zhu Sun, Jie Yang, Hui Fang, Xinghua Qu, Wenyuan Liu

+ [Crisp: Cognitive Restructuring of Negative Thoughts through Multi-turn Supportive Dialogues](https://arxiv.org//abs/2504.17238)

	Jinfeng Zhou, Yuxuan Chen, Jianing Yin, Yongkang Huang, Yihan Shi, Xikun Zhang, Libiao Peng, Rongsheng Zhang, Tangjie Lv, Zhipeng Hu, Hongning Wang, Minlie Huang

+ [CoheMark: A Novel Sentence-Level Watermark for Enhanced Text Quality](https://arxiv.org//abs/2504.17309)

	Junyan Zhang, Shuliang Liu, Aiwei Liu, Yubo Gao, Jungang Li, Xiaojie Gu, Xuming Hu

+ [PatientDx: Merging Large Language Models for Protecting Data-Privacy in Healthcare](https://arxiv.org//abs/2504.17360)

	Jose G. Moreno (IRIT-IRIS), Jesus Lovon (IRIT-IRIS), M'Rick Robin-Charlet (UT3), Christine Damase-Michel, Lynda Tamine (IRIT-IRIS)

+ [Unified Attacks to Large Language Model Watermarks: Spoofing and Scrubbing in Unauthorized Knowledge Distillation](https://arxiv.org//abs/2504.17480)

	Xin Yi, Shunfan Zhengc, Linlin Wanga, Xiaoling Wang, Liang He

+ [When Does Metadata Conditioning (NOT) Work for Language Model Pre-Training? A Study with Context-Free Grammars](https://arxiv.org//abs/2504.17562)

	Rei Higuchi, Ryotaro Kawata, Naoki Nishikawa, Kazusato Oko, Shoichiro Yamaguchi, Sosuke Kobayashi, Seiya Tokui, Kohei Hayashi, Daisuke Okanohara, Taiji Suzuki

+ [DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training](https://arxiv.org//abs/2504.17565)

	Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li

+ [Evaluating Grounded Reasoning by Code-Assisted Large Language Models for Mathematics](https://arxiv.org//abs/2504.17665)

	Zena Al-Khalili, Nick Howell, Dietrich Klakow

+ [Energy Considerations of Large Language Model Inference and Efficiency Optimizations](https://arxiv.org//abs/2504.17674)

	Jared Fernandez, Clara Na, Vashisth Tiwari, Yonatan Bisk, Sasha Luccioni, Emma Strubell

+ [Safety in Large Reasoning Models: A Survey](https://arxiv.org//abs/2504.17704)

	Cheng Wang, Yue Liu, Baolong Li, Duzhen Zhang, Zhongzhi Li, Junfeng Fang

+ [Conversational Assistants to support Heart Failure Patients: comparing a Neurosymbolic Architecture with ChatGPT](https://arxiv.org//abs/2504.17753)

	Anuja Tayal, Devika Salunke, Barbara Di Eugenio, Paula Allen-Meares, Eulalia Puig Abril, Olga Garcia, Carolyn Dickens, Andrew Boyd

+ [The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs](https://arxiv.org//abs/2504.17768)

	Piotr Nawrot, Robert Li, Renjie Huang, Sebastian Ruder, Kelly Marchisio, Edoardo M. Ponti

+ [Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs](https://arxiv.org//abs/2504.17432)

	Tiancheng Gu, Kaicheng Yang, Ziyong Feng, Xingjun Wang, Yanzhao Zhang, Dingkun Long, Yingda Chen, Weidong Cai, Jiankang Deng

+ [Towards Robust LLMs: an Adversarial Robustness Measurement Framework](https://arxiv.org//abs/2504.17723)

	Natan Levy, Adiel Ashrov, Guy Katz

+ [Replay to Remember: Retaining Domain Knowledge in Streaming Language Models](https://arxiv.org//abs/2504.17780)

	Sneh Pillai (University of Massachusetts Dartmouth)

+ [High-Fidelity And Complex Test Data Generation For Real-World SQL Code Generation Services](https://arxiv.org//abs/2504.17203)

	Shivasankari Kannan, Yeounoh Chung, Amita Gondi, Tristan Swadell, Fatma Ozcan

+ [On-Device Qwen2.5: Efficient LLM Inference with Model Compression and Hardware Acceleration](https://arxiv.org//abs/2504.17376)

	Maoyang Xiang, Ramesh Fernando, Bo Wang

+ [L3: DIMM-PIM Integrated Architecture and Coordination for Scalable Long-Context LLM Inference](https://arxiv.org//abs/2504.17584)

	Qingyuan Liu, Liyan Chen, Yanning Yang, Haocheng Wang, Dong Du, Zhigang Mao, Naifeng Jing, Yubin Xia, Haibo Chen

+ [LLM Agent Swarm for Hypothesis-Driven Drug Discovery](https://arxiv.org//abs/2504.17967)

	Kevin Song, Andrew Trotter, Jake Y. Chen

+ [Data-Driven Calibration of Prediction Sets in Large Vision-Language Models Based on Inductive Conformal Prediction](https://arxiv.org//abs/2504.17671)

	Yuanchang Ye, Weiyan Wen

+ [Unsupervised Corpus Poisoning Attacks in Continuous Space for Dense Retrieval](https://arxiv.org//abs/2504.17884)

	Yongkang Li, Panagiotis Eustratiadis, Simon Lupart, Evangelos Kanoulas

+ [Toward a Human-Centered Evaluation Framework for Trustworthy LLM-Powered GUI Agents](https://arxiv.org//abs/2504.17934)

	Chaoran Chen, Zhiping Zhang, Ibrahim Khalilov, Bingcan Guo, Simret A Gebreegziabher, Yanfang Ye, Ziang Xiao, Yaxing Yao, Tianshi Li, Toby Jia-Jun Li

+ [Collaborating Action by Action: A Multi-agent LLM Framework for Embodied Reasoning](https://arxiv.org//abs/2504.17950)

	Isadora White, Kolby Nottingham, Ayush Maniar, Max Robinson, Hansen Lillemark, Mehul Maheshwari, Lianhui Qin, Prithviraj Ammanabrolu

+ [DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training](https://arxiv.org//abs/2504.17565)

	Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li

+ [Training Large Language Models to Reason via EM Policy Gradient](https://arxiv.org//abs/2504.18587)

	Tianbing Xu

+ [BadMoE: Backdooring Mixture-of-Experts LLMs via Optimizing Routing Triggers and Infecting Dormant Experts](https://arxiv.org//abs/2504.18598)

	Qingyue Wang, Qi Pang, Xixun Lin, Shuai Wang, Daoyuan Wu

+ [RAGEN: Understanding Self-Evolution in LLM Agents via Multi-Turn Reinforcement Learning](https://arxiv.org//abs/2504.20073)

	Zihan Wang, Kangrui Wang, Qineng Wang, Pingyue Zhang, Linjie Li, Zhengyuan Yang, Kefan Yu, Minh Nhat Nguyen, Licheng Liu, Eli Gottlieb, Monica Lam, Yiping Lu, Kyunghyun Cho, Jiajun Wu, Li Fei-Fei, Lijuan Wang, Yejin Choi, Manling Li

+ [Tempo: Application-aware LLM Serving with Mixed SLO Requirements](https://arxiv.org//abs/2504.20068)

	Wei Zhang, Zhiyu Wu, Yi Mu, Banruo Liu, Myungjin Lee, Fan Lai

+ [ReCellTy: Domain-specific knowledge graph retrieval-augmented LLMs workflow for single-cell annotation](https://arxiv.org//abs/2505.00017)

	Dezheng Han, Yibin Jia, Ruxiao Chen, Wenjie Han, Shuaishuai Guo, Jianbo Wang

+ [An Empirical Study on Prompt Compression for Large Language Models](https://arxiv.org//abs/2505.00019)

	Zheng Zhang, Jinyi Li, Yihuai Lan, Xiang Wang, Hao Wang

+ [Beyond Public Access in LLM Pre-Training Data](https://arxiv.org//abs/2505.00020)

	Sruly Rosenblat, Tim O'Reilly, Ilan Strauss

+ [Aleph-Alpha-GermanWeb: Improving German-language LLM pre-training with model-based data curation and synthetic data generation](https://arxiv.org//abs/2505.00022)

	Thomas F Burns, Letitia Parcalabescu, Stephan Wäldchen, Michael Barlow, Gregor Ziegltrum, Volker Stampa, Bastian Harren, Björn Deiseroth

+ [Towards a HIPAA Compliant Agentic AI System in Healthcare](https://arxiv.org//abs/2504.17669)

	Subash Neupane, Sudip Mittal, Shahram Rahimi

# 2025-04-23
+ [Steering the CensorShip: Uncovering Representation Vectors for LLM "Thought" Control](https://arxiv.org//abs/2504.17130)

	Hannah Cyberey, David Evans

+ [Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification](https://arxiv.org//abs/2504.17017)

	Balaji Rao, William Eiers, Carlo Lipizzi

+ [Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments](https://arxiv.org//abs/2504.17087)

	Yuran Li, Jama Hussein Mohamud, Chongren Sun, Di Wu, Benoit Boulet

+ [Backslash: Rate Constrained Optimized Training of Large Language Models](https://arxiv.org//abs/2504.16968)

	Jun Wu, Jiangtao Wen, Yuxing Han

+ [(Im)possibility of Automated Hallucination Detection in Large Language Models](https://arxiv.org//abs/2504.17004)

	Amin Karbasi, Omar Montasser, John Sous, Grigoris Velegkas

+ [Robo-Troj: Attacking LLM-based Task Planners](https://arxiv.org//abs/2504.17070)

	Mohaiminul Al Nahian, Zainab Altaweel, David Reitano, Sabbir Ahmed, Saumitra Lohokare, Shiqi Zhang, Adnan Siraj Rakin

+ [MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation](https://arxiv.org//abs/2504.17137)

	Chanhee Park, Hyeonseok Moon, Chanjun Park, Heuiseok Lim

+ [Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark](https://arxiv.org//abs/2504.16427)

	Hanlei Zhang, Zhuohang Li, Yeshuang Zhu, Hua Xu, Peiwu Wang, Haige Zhu, Jie Zhou, Jinchao Zhang

+ [Optimizing LLMs for Italian: Reducing Token Fertility and Enhancing Efficiency Through Vocabulary Adaptation](https://arxiv.org//abs/2504.17025)

	Luca Moroni, Giovanni Puccetti, Pere-Lluis Huguet Cabot, Andrei Stefan Bejgu, Edoardo Barba, Alessio Miaschi, Felice Dell'Orletta, Andrea Esuli, Roberto Navigli

+ [Do Words Reflect Beliefs? Evaluating Belief Depth in Large Language Models](https://arxiv.org//abs/2504.17052)

	Shariar Kabir, Kevin Esterling, Yue Dong

+ [Agree to Disagree? A Meta-Evaluation of LLM Misgendering](https://arxiv.org//abs/2504.17075)

	Arjun Subramonian, Vagrant Gautam, Preethi Seshadri, Dietrich Klakow, Kai-Wei Chang, Yizhou Sun

+ [How Individual Traits and Language Styles Shape Preferences In Open-ended User-LLM Interaction: A Preliminary Study](https://arxiv.org//abs/2504.17083)

	Rendi Chevi, Kentaro Inui, Thamar Solorio, Alham Fikri Aji

+ [Co-CoT: A Prompt-Based Framework for Collaborative Chain-of-Thought Reasoning](https://arxiv.org//abs/2504.17091)

	Seunghyun Yoo

+ [Steering the CensorShip: Uncovering Representation Vectors for LLM "Thought" Control](https://arxiv.org//abs/2504.17130)

	Hannah Cyberey, David Evans

+ [MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation](https://arxiv.org//abs/2504.17137)

	Chanhee Park, Hyeonseok Moon, Chanjun Park, Heuiseok Lim

+ [(Im)possibility of Automated Hallucination Detection in Large Language Models](https://arxiv.org//abs/2504.17004)

	Amin Karbasi, Omar Montasser, John Sous, Grigoris Velegkas

+ [Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark](https://arxiv.org//abs/2504.16427)

	Hanlei Zhang, Zhuohang Li, Yeshuang Zhu, Hua Xu, Peiwu Wang, Haige Zhu, Jie Zhou, Jinchao Zhang

+ [Backslash: Rate Constrained Optimized Training of Large Language Models](https://arxiv.org//abs/2504.16968)

	Jun Wu, Jiangtao Wen, Yuxing Han

+ [Safety Pretraining: Toward the Next Generation of Safe AI](https://arxiv.org//abs/2504.16980)

	Pratyush Maini, Sachin Goyal, Dylan Sam, Alex Robey, Yash Savani, Yiding Jiang, Andy Zou, Zacharcy C. Lipton, J. Zico Kolter

+ [Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification](https://arxiv.org//abs/2504.17017)

	Balaji Rao, William Eiers, Carlo Lipizzi

+ [Exploring How LLMs Capture and Represent Domain-Specific Knowledge](https://arxiv.org//abs/2504.16871)

	Mirian Hipolito Garcia, Camille Couturier, Daniel Madrigal Diaz, Ankur Mallick, Anastasios Kyrillidis, Robert Sim, Victor Ruhle, Saravan Rajmohan


+ [Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments](https://arxiv.org//abs/2504.17087)

	Yuran Li, Jama Hussein Mohamud, Chongren Sun, Di Wu, Benoit Boulet

+ [Backslash: Rate Constrained Optimized Training of Large Language Models](https://arxiv.org//abs/2504.16968)

	Jun Wu, Jiangtao Wen, Yuxing Han

+ [(Im)possibility of Automated Hallucination Detection in Large Language Models](https://arxiv.org//abs/2504.17004)

	Amin Karbasi, Omar Montasser, John Sous, Grigoris Velegkas

+ [Robo-Troj: Attacking LLM-based Task Planners](https://arxiv.org//abs/2504.17070)

	Mohaiminul Al Nahian, Zainab Altaweel, David Reitano, Sabbir Ahmed, Saumitra Lohokare, Shiqi Zhang, Adnan Siraj Rakin

+ [MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation](https://arxiv.org//abs/2504.17137)

	Chanhee Park, Hyeonseok Moon, Chanjun Park, Heuiseok Lim

+ [Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark](https://arxiv.org//abs/2504.16427)

	Hanlei Zhang, Zhuohang Li, Yeshuang Zhu, Hua Xu, Peiwu Wang, Haige Zhu, Jie Zhou, Jinchao Zhang

+ [Optimizing LLMs for Italian: Reducing Token Fertility and Enhancing Efficiency Through Vocabulary Adaptation](https://arxiv.org//abs/2504.17025)

	Luca Moroni, Giovanni Puccetti, Pere-Lluis Huguet Cabot, Andrei Stefan Bejgu, Edoardo Barba, Alessio Miaschi, Felice Dell'Orletta, Andrea Esuli, Roberto Navigli

+ [Do Words Reflect Beliefs? Evaluating Belief Depth in Large Language Models](https://arxiv.org//abs/2504.17052)

	Shariar Kabir, Kevin Esterling, Yue Dong

+ [Agree to Disagree? A Meta-Evaluation of LLM Misgendering](https://arxiv.org//abs/2504.17075)

	Arjun Subramonian, Vagrant Gautam, Preethi Seshadri, Dietrich Klakow, Kai-Wei Chang, Yizhou Sun

+ [How Individual Traits and Language Styles Shape Preferences In Open-ended User-LLM Interaction: A Preliminary Study](https://arxiv.org//abs/2504.17083)

	Rendi Chevi, Kentaro Inui, Thamar Solorio, Alham Fikri Aji

+ [Co-CoT: A Prompt-Based Framework for Collaborative Chain-of-Thought Reasoning](https://arxiv.org//abs/2504.17091)

	Seunghyun Yoo

+ [Steering the CensorShip: Uncovering Representation Vectors for LLM "Thought" Control](https://arxiv.org//abs/2504.17130)

	Hannah Cyberey, David Evans

+ [Safety Pretraining: Toward the Next Generation of Safe AI](https://arxiv.org//abs/2504.16980)

	Pratyush Maini, Sachin Goyal, Dylan Sam, Alex Robey, Yash Savani, Yiding Jiang, Andy Zou, Zacharcy C. Lipton, J. Zico Kolter

+ [Exploring How LLMs Capture and Represent Domain-Specific Knowledge](https://arxiv.org//abs/2504.16871)

	Mirian Hipolito Garcia, Camille Couturier, Daniel Madrigal Diaz, Ankur Mallick, Anastasios Kyrillidis, Robert Sim, Victor Ruhle, Saravan Rajmohan

+ [EduBot -- Can LLMs Solve Personalized Learning and Programming Assignments?](https://arxiv.org//abs/2504.17824)

	Yibin Wang, Jiaxi Xie, Lakshminarayanan Subramanian

+ [BackSlash: Rate Constrained Optimized Training of Large Language Models](https://arxiv.org//abs/2504.16968)

	Jun Wu, Jiangtao Wen, Yuxing Han

+ [PARD: Accelerating LLM Inference with Low-Cost PARallel Draft Model Adaptation](https://arxiv.org//abs/2504.18583)

	Zihao An, Huajun Bai, Ziqiong Liu, Dong Li, Emad Barsoum

+ [Param$Δ$ for Direct Weight Mixing: Post-Train Large Language Model at Zero Cost](https://arxiv.org//abs/2504.21023)

	Sheng Cao, Mingrui Wu, Karthik Prasad, Yuandong Tian, Zechun Liu

+ [WebEvolver: Enhancing Web Agent Self-Improvement with Coevolving World Model](https://arxiv.org//abs/2504.21024)

	Tianqing Fang, Hongming Zhang, Zhisong Zhang, Kaixin Ma, Wenhao Yu, Haitao Mi, Dong Yu

+ [Sparks of Tabular Reasoning via Text2SQL Reinforcement Learning](https://arxiv.org//abs/2505.00016)

	Josefa Lia Stoisser, Marc Boubnovski Martell, Julien Fauqueur

+ [Building A Secure Agentic AI Application Leveraging A2A Protocol](https://arxiv.org//abs/2504.16902)

	Idan Habler, Ken Huang, Vineeth Sai Narajala, Prashant Kulkarni

+ [ConTextual: Improving Clinical Text Summarization in LLMs with Context-preserving Token Filtering and Knowledge Graphs](https://arxiv.org//abs/2504.16394)

	Fahmida Liza Piya, Rahmatollah Beheshti

+ [LLMSR@XLLM25: Less is More: Enhancing Structured Multi-Agent Reasoning via Quality-Guided Distillation](https://arxiv.org//abs/2504.16408)

	Jiahao Yuan, Xingzhe Sun, Xing Yu, Jingwen Wang, Dehui Du, Zhiqing Cui, Zixiang Di

+ [Harden and Catch for Just-in-Time Assured LLM-Based Software Testing: Open Research Challenges](https://arxiv.org//abs/2504.16472)

	Mark Harman, Peter O'Hearn, Shubho Sengupta

+ [Process Reward Models That Think](https://arxiv.org//abs/2504.16828)

	Muhammad Khalifa, Rishabh Agarwal, Lajanugen Logeswaran, Jaekyeom Kim, Hao Peng, Moontae Lee, Honglak Lee, Lu Wang

+ [OptimAI: Optimization from Natural Language Using LLM-Powered AI Agents](https://arxiv.org//abs/2504.16918)

	Raghav Thind, Youran Sun, Ling Liang, Haizhao Yang

# 2025-04-22
+ [Impact of Noise on LLM-Models Performance in Abstraction and Reasoning Corpus (ARC) Tasks with Model Temperature Considerations](https://arxiv.org//abs/2504.15903)

	Nikhil Khandalkar, Pavan Yadav, Krishna Shinde, Lokesh B. Ramegowda, Rajarshi Das


+ [CAPO: Cost-Aware Prompt Optimization](https://arxiv.org//abs/2504.16005)

	Tom Zehle, Moritz Schlager, Timo Heiß, Matthias Feurer

+ [Pre-DPO: Improving Data Utilization in Direct Preference Optimization Using a Guiding Reference Model](https://arxiv.org//abs/2504.15843)

	Junshu Pan, Wei Shen, Shulin Huang, Qiji Zhou, Yue Zhang

+ [BELL: Benchmarking the Explainability of Large Language Models](https://arxiv.org//abs/2504.18572)

	Syed Quiser Ahmed, Bharathi Vokkaliga Ganesh, Jagadish Babu P, Karthick Selvaraj, ReddySiva Naga Parvathi Devi, Sravya Kappala

+ [Large Language Model Empowered Privacy-Protected Framework for PHI Annotation in Clinical Notes](https://arxiv.org//abs/2504.18569)

	Guanchen Wu, Linzhi Zheng, Han Xie, Zhen Xiang, Jiaying Lu, Darren Liu, Delgersuren Bold, Bo Li, Xiao Hu, Carl Yang

+ [Understanding the Skill Gap in Recurrent Language Models: The Role of the Gather-and-Aggregate Mechanism](https://arxiv.org//abs/2504.18574)

	Aviv Bick, Eric Xing, Albert Gu

+ [WASP: Benchmarking Web Agent Security Against Prompt Injection Attacks](https://arxiv.org//abs/2504.18575)

	Ivan Evtimov, Arman Zharmagambetov, Aaron Grattafiori, Chuan Guo, Kamalika Chaudhuri

+ [Kill two birds with one stone: generalized and robust AI-generated text detection via dynamic perturbations](https://arxiv.org//abs/2504.21019)

	Yinghan Zhou, Juan Wen, Wanli Peng, Yiming Xue, Ziwei Zhang, Zhengxian Wu

+ [Context-Enhanced Contrastive Search for Improved LLM Text Generation](https://arxiv.org//abs/2504.21020)

	Jaydip Sen, Rohit Pandey, Hetvi Waghela

+ [A Framework for Testing and Adapting REST APIs as LLM Tools](https://arxiv.org//abs/2504.15546)

	Jayachandu Bandlamudi, Ritwik Chaudhuri, Neelamadhav Gantayat, Kushal Mukherjee, Prerna Agarwal, Renuka Sindhgatta, Sameep Mehta

+ [Advancing Embodied Agent Security: From Safety Benchmarks to Input Moderation](https://arxiv.org//abs/2504.15699)

	Ning Wang, Zihan Yan, Weiyang Li, Chuan Ma, He Chen, Tao Xiang

+ [LLMs meet Federated Learning for Scalable and Secure IoT Management](https://arxiv.org//abs/2504.16032)

	Yazan Otoum, Arghavan Asad, Amiya Nayak

+ [A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment](https://arxiv.org//abs/2504.15585)

	Kun Wang, Guibin Zhang, Zhenhong Zhou, Jiahao Wu, Miao Yu, Shiqian Zhao, Chenlong Yin, Jinhu Fu, Yibo Yan, Hanjun Luo, Liang Lin, Zhihao Xu, Haolang Lu, Xinye Cao, Xinyun Zhou, Weifei Jin, Fanci Meng, Junyuan Mao, Yu Wang, Hao Wu, Minghe Wang, Fan Zhang, Junfeng Fang, Wenjie Qu, Yue Liu, Chengwei Liu, Yifan Zhang, Qiankun Li, Chongye Guo, Yalan Qin, Zhaoxin Fan, Yi Ding, Donghai Hong, Jiaming Ji, Yingxin Lai, Zitong Yu, Xinfeng Li, Yifan Jiang, Yanhui Li, Xinyu Deng, Junlin Wu, Dongxia Wang, Yihao Huang, Yufei Guo, Jen-tse Huang, Qiufeng Wang, Wenxuan Wang, Dongrui Liu, Yanwei Yue, Wenke Huang, Guancheng Wan, Heng Chang, Tianlin Li, Yi Yu, Chenghao Li, Jiawei Li, Lei Bai, Jie Zhang, Qing Guo, Jingyi Wang, Tianlong Chen, Joey Tianyi Zhou, Xiaojun Jia, Weisong Sun, Cong Wu, Jing Chen, Xuming Hu, Yiming Li, Xiao Wang, Ningyu Zhang, Luu Anh Tuan, Guowen Xu, Jiaheng Zhang, Tianwei Zhang, Xingjun Ma, Jindong Gu, Xiang Wang, Bo An, Jun Sun, Mohit Bansal, Shirui Pan, Lingjuan Lyu, Yuval Elovici, Bhavya Kailkhura, Yaodong Yang, Hongwei Li, Wenyuan Xu, Yizhou Sun, Wei Wang, Qing Li, Ke Tang, Yu-Gang Jiang, Felix Juefei-Xu, Hui Xiong, Xiaofeng Wang, Dacheng Tao, Philip S. Yu, Qingsong Wen, Yang Liu

+ [Dynamic Early Exit in Reasoning Models](https://arxiv.org//abs/2504.15895)

	Chenxu Yang, Qingyi Si, Yongjie Duan, Zheliang Zhu, Chenyu Zhu, Qiaowei Li, Zheng Lin, Li Cao, Weiping Wang

+ [PHYBench: Holistic Evaluation of Physical Perception and Reasoning in Large Language Models](https://arxiv.org//abs/2504.16074)

	Shi Qiu, Shaoyang Guo, Zhuo-Yang Song, Yunbo Sun, Zeyu Cai, Jiashen Wei, Tianyu Luo, Yixuan Yin, Haoxu Zhang, Yi Hu, Chenyang Wang, Chencheng Tang, Haoling Chang, Qi Liu, Ziheng Zhou, Tianyu Zhang, Jingtian Zhang, Zhangyi Liu, Minghao Li, Yuku Zhang, Boxuan Jing, Xianqi Yin, Yutong Ren, Zizhuo Fu, Jiaming Ji, Weike Wang, Xudong Tian, Anqi Lv, Laifu Man, Jianxiang Li, Feiyu Tao, Qihua Sun, Zhou Liang, Yushu Mu, Zhongxuan Li, Jing-Jun Zhang, Shutao Zhang, Xiaotian Li, Xingqi Xia, Jiawei Lin, Zheyu Shen, Jiahang Chen, Qiuhao Xiong, Binran Wang, Fengyuan Wang, Ziyang Ni, Bohan Zhang, Fan Cui, Changkun Shao, Qing-Hong Cao, Ming-xing Luo, Yaodong Yang, Muhan Zhang, Hua Xing Zhu

+ [Grounded in Context: Retrieval-Based Method for Hallucination Detection](https://arxiv.org//abs/2504.15771)

	Assaf Gerner, Netta Madvil, Nadav Barak, Alex Zaikman, Jonatan Liberman, Liron Hamra, Rotem Brazilay, Shay Tsadok, Yaron Friedman, Neal Harow, Noam Bresler, Shir Chorev, Philip Tannor

# 2025-04-21
+ [Intrinsic Barriers to Explaining Deep Foundation Models](https://arxiv.org//abs/2504.16948)

	Zhen Tan, Huan Liu

+ [KeyDiff: Key Similarity-Based KV Cache Eviction for Long-Context LLM Inference in Resource-Constrained Environments](https://arxiv.org//abs/2504.15364)

	Junyoung Park, Dalton Jones, Matt J Morse, Raghavv Goel, Mingu Lee, Chris Lott

+ [MARFT: Multi-Agent Reinforcement Fine-Tuning](https://arxiv.org//abs/2504.16129)

	Junwei Liao, Muning Wen, Jun Wang, Weinan Zhang

+ [Efficient Pretraining Length Scaling](https://arxiv.org//abs/2504.14992)

	Bohong Wu, Shen Yan, Sijun Zhang, Jianqiao Lu, Yutao Zeng, Ya Wang, Xun Zhou

+ [MARFT: Multi-Agent Reinforcement Fine-Tuning](https://arxiv.org//abs/2504.16129)

	Junwei Liao, Muning Wen, Jun Wang, Weinan Zhang


+ [DualBreach: Efficient Dual-Jailbreaking via Target-Driven Initialization and Multi-Target Optimization](https://arxiv.org//abs/2504.18564)

	Xinzhe Huang, Kedong Xiu, Tianhang Zheng, Churui Zeng, Wangze Ni, Zhan Qiin, Kui Ren, Chun Chen

+ [RepliBench: Evaluating the autonomous replication capabilities of language model agents](https://arxiv.org//abs/2504.18565)

	Sid Black, Asa Cooper Stickland, Jake Pencharz, Oliver Sourbut, Michael Schmatz, Jay Bailey, Ollie Matthews, Ben Millwood, Alex Remedios, Alan Cooney

+ [Jailbreak Detection in Clinical Training LLMs Using Feature-Based Predictive Models](https://arxiv.org//abs/2505.00010)

	Tri Nguyen, Lohith Srikanth Pentapalli, Magnus Sieverding, Laurah Turner, Seth Overla, Weibing Zheng, Chris Zhou, David Furniss, Danielle Weber, Michael Gharib, Matt Kelleher, Michael Shukis, Cameron Pawlik, Kelly Cohen

+ [Integrating Symbolic Execution into the Fine-Tuning of Code-Generating LLMs](https://arxiv.org//abs/2504.15210)

	Marina Sakharova, Abhinav Anand, Mira Mezini

+ [Splitwiser: Efficient LM inference with constrained resources](https://arxiv.org//abs/2505.03763)

	Asad Aali, Adney Cardoza, Melissa Capo

+ [AlignRAG: Leveraging Critique Learning for Evidence-Sensitive Retrieval-Augmented Reasoning](https://arxiv.org//abs/2504.14858)

	Jiaqi Wei, Hao Zhou, Xiang Zhang, Di Zhang, Zijie Qiu, Wei Wei, Jinzhe Li, Wanli Ouyang, Siqi Sun

+ [A Self-Improving Coding Agent](https://arxiv.org//abs/2504.15228)

	Maxime Robeyns, Martin Szummer, Laurence Aitchison

+ [MARFT: Multi-Agent Reinforcement Fine-Tuning](https://arxiv.org//abs/2504.16129)

	Junwei Liao, Muning Wen, Jun Wang, Weinan Zhang

# 2025-04-20
+ [UFO2: The Desktop AgentOS](https://arxiv.org//abs/2504.14603)

	Chaoyun Zhang, He Huang, Chiming Ni, Jian Mu, Si Qin, Shilin He, Lu Wang, Fangkai Yang, Pu Zhao, Chao Du, Liqun Li, Yu Kang, Zhao Jiang, Suzhen Zheng, Rujia Wang, Jiaxu Qian, Minghua Ma, Jian-Guang Lou, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang

+ [Towards Optimal Circuit Generation: Multi-Agent Collaboration Meets Collective Intelligence](https://arxiv.org//abs/2504.14625)

	Haiyan Qin, Jiahao Feng, Xiaotong Feng, Wei W. Xing, Wang Kang

+ [FinSage: A Multi-aspect RAG System for Financial Filings Question Answering](https://arxiv.org//abs/2504.14493)

	Xinyu Wang, Jijun Chi, Zhenghan Tai, Tung Sum Thomas Kwok, Muzhi Li, Zhuhong Li, Hailin He, Yuchen Hua, Peng Lu, Suyuchen Wang, Yihong Wu, Jerry Huang, Jingrui Tian, Ling Zhou

+ [Don't Retrieve, Generate: Prompting LLMs for Synthetic Training Data in Dense Retrieval](https://arxiv.org//abs/2504.21015)

	Aarush Sinha

+ [Trans-Zero: Self-Play Incentivizes Large Language Models for Multilingual Translation Without Parallel Data](https://arxiv.org//abs/2504.14669)

	Wei Zou, Sen Yang, Yu Bao, Shujian Huang, Jiajun Chen, Shanbo Cheng

# 2025-04-19
+ [TALES: Text Adventure Learning Environment Suite](https://arxiv.org//abs/2504.14128)

	Christopher Zhang Cui, Xingdi Yuan, Ziang Xiao, Prithviraj Ammanabrolu, Marc-Alexandre Côté



+ [Mind the Language Gap: Automated and Augmented Evaluation of Bias in LLMs for High- and Low-Resource Languages](https://arxiv.org//abs/2504.18560)

	Alessio Buscemi, Cédric Lothritz, Sergio Morales, Marcos Gomez-Vazquez, Robert Clarisó, Jordi Cabot, German Castignani

+ [Improving the Serving Performance of Multi-LoRA Large Language Models via Efficient LoRA and KV Cache Management](https://arxiv.org//abs/2505.03756)

	Hang Zhang, Jiuchen Shi, Yixiao Wang, Quan Chen, Yizhou Shan, Minyi Guo

+ [The Geometry of Self-Verification in a Task-Specific Reasoning Model](https://arxiv.org//abs/2504.14379)

	Andrew Lee, Lihao Sun, Chris Wendler, Fernanda Viégas, Martin Wattenberg

# 2025-04-18
+ [SCRAG: Social Computing-Based Retrieval Augmented Generation for Community Response Forecasting in Social Media Environments](https://arxiv.org//abs/2504.16947)

	Dachun Sun, You Lyu, Jinning Li, Yizhuo Chen, Tianshi Wang, Tomoyoshi Kimura, Tarek Abdelzaher

+ [From Large to Super-Tiny: End-to-End Optimization for Cost-Efficient LLMs](https://arxiv.org//abs/2504.13471)

	Jiliang Ni, Jiachen Pu, Zhongyi Yang, Kun Zhou, Hui Wang, Xiaoliang Xiao, Dakui Wang, Xin Li, Jingfeng Luo, Conggang Hu


+ [From Large to Super-Tiny: End-to-End Optimization for Cost-Efficient LLMs](https://arxiv.org//abs/2504.13471)

	Jiliang Ni, Jiachen Pu, Zhongyi Yang, Kun Zhou, Hui Wang, Xiaoliang Xiao, Dakui Wang, Xin Li, Jingfeng Luo, Conggang Hu

+ [Gradual Binary Search and Dimension Expansion : A general method for activation quantization in LLMs](https://arxiv.org//abs/2504.13989)

	Lucas Maisonnave, Cyril Moineau, Olivier Bichler, Fabrice Rastello

+ [Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?](https://arxiv.org//abs/2504.13837)

	Yang Yue, Zhiqi Chen, Rui Lu, Andrew Zhao, Zhaokai Wang, Yang Yue, Shiji Song, Gao Huang

+ [Signatures of human-like processing in Transformer forward passes](https://arxiv.org//abs/2504.14107)

	Jennifer Hu, Michael A. Lepori, Michael Franke

+ [CoT-RAG: Integrating Chain of Thought and Retrieval-Augmented Generation to Enhance Reasoning in Large Language Models](https://arxiv.org//abs/2504.13534)

	Feiyang Li, Peng Fang, Zhan Shi, Arijit Khan, Fang Wang, Dan Feng, Weihao Wang, Xin Zhang, Yongjian Cui

# 2025-04-17
+ [GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning](https://arxiv.org//abs/2504.12597)

	Liangyu Xu, Yingxiu Zhao, Jingyun Wang, Yingyao Wang, Bu Pi, Chen Wang, Mingliang Zhang, Jihao Gu, Xiang Li, Xiaoyong Zhu, Jun Song, Bo Zheng



+ [MCP Guardian: A Security-First Layer for Safeguarding MCP-Based AI System](https://arxiv.org//abs/2504.12757)

	Sonu Kumar, Anubhav Girdhar, Ritesh Patil, Divyansh Tripathi

+ [GraphOmni: A Comprehensive and Extendable Benchmark Framework for Large Language Models on Graph-theoretic Tasks](https://arxiv.org//abs/2504.12764)

	Hao Xu, Xiangru Jian, Xinjian Zhao, Wei Pang, Chao Zhang, Suyuchen Wang, Qixin Zhang, Zhengyuan Dong, Joao Monteiro, Bang Liu, Qiuzhuang Sun, Tianshu Yu

# 2025-04-16
+ [Activated LoRA: Fine-tuned LLMs for Intrinsics](https://arxiv.org//abs/2504.12397)

	Kristjan Greenewald, Luis Lastras, Thomas Parnell, Vraj Shah, Lucian Popa, Giulio Zizzo, Chulaka Gunasekara, Ambrish Rawat, David Cox

+ [Waking Up an AI: A Quantitative Framework for Prompt-Induced Phase Transition in Large Language Models](https://arxiv.org//abs/2504.21012)

	Makoto Sato

+ [The Devil is in the Prompts: Retrieval-Augmented Prompt Optimization for Text-to-Video Generation](https://arxiv.org//abs/2504.11739)

	Bingjie Gao, Xinyu Gao, Xiaoxue Wu, Yujie Zhou, Yu Qiao, Li Niu, Xinyuan Chen, Yaohui Wang

# 2025-04-15
+ [Looking beyond the next token](https://arxiv.org//abs/2504.11336)

	Abitha Thankaraj, Yiding Jiang, J. Zico Kolter, Yonatan Bisk

+ [Teaching Large Language Models to Reason through Learning and Forgetting](https://arxiv.org//abs/2504.11364)

	Tianwei Ni, Allen Nie, Sapana Chaudhary, Yao Liu, Huzefa Rangwala, Rasool Fakoor

+ [Nemotron-CrossThink: Scaling Self-Learning beyond Math Reasoning](https://arxiv.org//abs/2504.13941)

	Syeda Nahida Akter, Shrimai Prabhumoye, Matvei Novikov, Seungju Han, Ying Lin, Evelina Bakhturina, Eric Nyberg, Yejin Choi, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro


+ [CLASH: Evaluating Language Models on Judging High-Stakes Dilemmas from Multiple Perspectives](https://arxiv.org//abs/2504.10823)

	Ayoung Lee, Ryan Sungmo Kwon, Peter Railton, Lu Wang

# 2025-04-14
+ [Transferable text data distillation by trajectory matching](https://arxiv.org//abs/2504.09818)

	Rong Yao, Hailin Hu, Yifei Fu, Hanting Chen, Wenyi Fang, Fanyi Du, Kai Han, Yunhe Wang

+ [Weight Ensembling Improves Reasoning in Language Models](https://arxiv.org//abs/2504.10478)

	Xingyu Dang, Christina Baek, Kaiyue Wen, Zico Kolter, Aditi Raghunathan

+ [Better Estimation of the KL Divergence Between Language Models](https://arxiv.org//abs/2504.10637)

	Afra Amini, Tim Vieira, Ryan Cotterell

+ [DioR: Adaptive Cognitive Detection and Contextual Retrieval Optimization for Dynamic Retrieval-Augmented Generation](https://arxiv.org//abs/2504.10198)

	Hanghui Guo, Jia Zhu, Shimin Di, Weijie Shi, Zhangze Chen, Jiajie Xu

+ [TAMP: Token-Adaptive Layerwise Pruning in Multimodal Large Language Models](https://arxiv.org//abs/2504.09897)

	Jaewoo Lee, Keyang Xuan, Chanakya Ekbote, Sandeep Polisetty, Yi R. Fung, Paul Pu Liang

# 2025-04-13
+ [CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent](https://arxiv.org//abs/2504.13192)

	Liang-bo Ning, Shijie Wang, Wenqi Fan, Qing Li, Xin Xu, Hao Chen, Feiran Huang

+ [EmoAgent: Assessing and Safeguarding Human-AI Interaction for Mental Health Safety](https://arxiv.org//abs/2504.09689)

	Jiahao Qiu, Yinghui He, Xinzhe Juan, Yimin Wang, Yuhan Liu, Zixin Yao, Yue Wu, Xun Jiang, Ling Yang, Mengdi Wang

+ [Mitigating Many-Shot Jailbreaking](https://arxiv.org//abs/2504.09604)

	Christopher M. Ackerman, Nina Panickssery

+ [Quantization Error Propagation: Revisiting Layer-Wise Post-Training Quantization](https://arxiv.org//abs/2504.09629)

	Yamato Arai, Yuma Ichikawa

+ [Understanding LLM Behaviors via Compression: Data Generation, Knowledge Acquisition and Scaling Laws](https://arxiv.org//abs/2504.09597)

	Zhixuan Pan, Shaowen Wang, Jian Li

+ [MLRC-Bench: Can Language Agents Solve Machine Learning Research Challenges?](https://arxiv.org//abs/2504.09702)

	Yunxiang Zhang, Muhammad Khalifa, Shitanshu Bhushan, Grant D Murphy, Lajanugen Logeswaran, Jaekyeom Kim, Moontae Lee, Honglak Lee, Lu Wang

# 2025-04-11
+ [Enterprise-Grade Security for the Model Context Protocol (MCP): Frameworks and Mitigation Strategies](https://arxiv.org//abs/2504.08623)

	Vineeth Sai Narajala, Idan Habler

+ [Large Language Models Could Be Rote Learners](https://arxiv.org//abs/2504.08300)

	Yuyang Xu, Renjun Hu, Haochao Ying, Jian Wu, Xing Shi, Wei Lin

# 2025-04-10
+ [Throughput-Optimal Scheduling Algorithms for LLM Inference and AI Agents](https://arxiv.org//abs/2504.07347)

	Yueying Li, Jim Dai, Tianyi Peng


+ [Can Reasoning LLMs Enhance Clinical Document Classification?](https://arxiv.org//abs/2504.08040)

	Akram Mustafa, Usman Naseem, Mostafa Rahimi Azghadi

+ [Seed1.5-Thinking: Advancing Superb Reasoning Models with Reinforcement Learning](https://arxiv.org//abs/2504.13914)

	ByteDance Seed: Jiaze Chen, Tiantian Fan, Xin Liu, Lingjun Liu, Zhiqi Lin, Mingxuan Wang, Chengyi Wang, Xiangpeng Wei, Wenyuan Xu, Yufeng Yuan, Yu Yue, Lin Yan, Qiying Yu, Xiaochen Zuo, Chi Zhang, Ruofei Zhu, Zhecheng An, Zhihao Bai, Yu Bao, Xingyan Bin, Jiangjie Chen, Feng Chen, Hongmin Chen, Riwei Chen, Liangqiang Chen, Zixin Chen, Jinsong Chen, Siyan Chen, Kaiyuan Chen, Zhi Chen, Jin Chen, Jiecao Chen, Jinxin Chi, Weinan Dai, Ning Dai, Jiahui Dai, Shihan Dou, Yantao Du, Zhengyin Du, Jianhui Duan, Chen Dun, Ting-Han Fan, Jiazhan Feng, Junda Feng, Ziyuan Feng, Yuwei Fu, Wenqi Fu, Hanjie Fu, Hao Ge, Hongyi Guo, Mingji Han, Li Han, Wenhao Hao, Xintong Hao, Qianyu He, Jerry He, Feng He, Wen Heng, Zehua Hong, Qi Hou, Liang Hu, Shengding Hu, Nan Hu, Kai Hua, Qi Huang, Ziyue Huang, Hongzhi Huang, Zihao Huang, Ting Huang, Wenhao Huang, Wei Jia, Bin Jia, Xiaoying Jia, Yuhua Jiang, Haobin Jiang, Ziheng Jiang, Kaihua Jiang, Chengquan Jiang, Jianpeng Jiao, Xiaoran Jin, Xing Jin, Xunhao Lai, Zheng Li, Xiang Li, Liyi Li, Hongkai Li, Zheng Li, Shengxian Wan, Ya Wang, Yunshui Li, Chenggang Li, Niuniu Li, Siyu Li, Xi Li, Xiao Li, Aoyan Li, Yuntao Li, Nianning Liang, Xinnian Liang

+ [Towards Combinatorial Interpretability of Neural Computation](https://arxiv.org//abs/2504.08842)

	Micah Adler, Dan Alistarh, Nir Shavit

+ [Understanding Learner-LLM Chatbot Interactions and the Impact of Prompting Guidelines](https://arxiv.org//abs/2504.07840)

	Cansu Koyuturk, Emily Theophilou, Sabrina Patania, Gregor Donabauer, Andrea Martinenghi, Chiara Antico, Alessia Telari, Alessia Testa, Sathya Bursic, Franca Garzotto, Davinia Hernandez-Leo, Udo Kruschwitz, Davide Taibi, Simona Amenta, Martin Ruskov, Dimitri Ognibene

+ [Model Utility Law: Evaluating LLMs beyond Performance through Mechanism Interpretable Metric](https://arxiv.org//abs/2504.07440)

	Yixin Cao, Jiahao Ying, Yaoning Wang, Xipeng Qiu, Xuanjing Huang, Yugang Jiang

+ [SpecReason: Fast and Accurate Inference-Time Compute via Speculative Reasoning](https://arxiv.org//abs/2504.07891)

	Rui Pan, Yinwei Dai, Zhihao Zhang, Gabriele Oliaro, Zhihao Jia, Ravi Netravali

# 2025-04-09
+ [Understanding Users' Security and Privacy Concerns and Attitudes Towards Conversational AI Platforms](https://arxiv.org//abs/2504.06552)

	Mutahar Ali, Arjun Arunasalam, Habiba Farrukh

# 2025-04-08
+ [V-MAGE: A Game Evaluation Framework for Assessing Vision-Centric Capabilities in Multimodal Large Language Models](https://arxiv.org//abs/2504.06148)

	Xiangxi Zheng, Linjie Li, Zhengyuan Yang, Ping Yu, Alex Jinpeng Wang, Rui Yan, Yuan Yao, Lijuan Wang

+ [Leveraging Robust Optimization for LLM Alignment under Distribution Shifts](https://arxiv.org//abs/2504.05831)

	Mingye Zhu, Yi Liu, Zheren Fu, Yongdong Zhang, Zhendong Mao

+ [Right Question is Already Half the Answer: Fully Unsupervised LLM Reasoning Incentivization](https://arxiv.org//abs/2504.05812)

	Qingyang Zhang, Haitao Wu, Changqing Zhang, Peilin Zhao, Yatao Bian

# 2025-04-07


+ [A Desideratum for Conversational Agents: Capabilities, Challenges, and Future Directions](https://arxiv.org//abs/2504.16939)

	Emre Can Acikgoz, Cheng Qian, Hongru Wang, Vardhan Dongre, Xiusi Chen, Heng Ji, Dilek Hakkani-Tür, Gokhan Tur

+ [Not All Data Are Unlearned Equally](https://arxiv.org//abs/2504.05058)

	Aravind Krishnan, Siva Reddy, Marius Mosbach


+ [Lightweight and Direct Document Relevance Optimization for Generative Information Retrieval](https://arxiv.org//abs/2504.05181)

	Kidist Amde Mekonnen, Yubao Tang, Maarten de Rijke

+ [CCSK:Cognitive Convection of Self-Knowledge Based Retrieval Augmentation for Large Language Models](https://arxiv.org//abs/2504.10498)

	Jianling Lu, Mingqi Lv, Tieming Chen

+ [LLM-based Automated Grading with Human-in-the-Loop](https://arxiv.org//abs/2504.05239)

	Hang Li, Yucheng Chu, Kaiqi Yang, Yasemin Copur-Gencturk, Jiliang Tang

+ [SEAL: Steerable Reasoning Calibration of Large Language Models for Free](https://arxiv.org//abs/2504.07986)

	Runjin Chen, Zhenyu Zhang, Junyuan Hong, Souvik Kundu, Zhangyang Wang

+ [AccLLM: Accelerating Long-Context LLM Inference Via Algorithm-Hardware Co-Design](https://arxiv.org//abs/2505.03745)

	Yanbiao Liang, Huihong Shi, Haikuo Shao, Zhongfeng Wang

+ [Promoting Security and Trust on Social Networks: Explainable Cyberbullying Detection Using Large Language Models in a Stream-Based Machine Learning Framework](https://arxiv.org//abs/2505.03746)

	Silvia García-Méndez, Francisco De Arriba-Pérez

+ [Beyond Single-Turn: A Survey on Multi-Turn Interactions with Large Language Models](https://arxiv.org//abs/2504.04717)

	Yubo Li, Xiaobin Shen, Xinyu Yao, Xueying Ding, Yidi Miao, Ramayya Krishnan, Rema Padman

+ [Concise Reasoning via Reinforcement Learning](https://arxiv.org//abs/2504.05185)

	Mehdi Fatemi, Banafsheh Rafiee, Mingjie Tang, Kartik Talamadupula

# 2025-04-06
+ ["Trust me on this" Explaining Agent Behavior to a Human Terminator](https://arxiv.org//abs/2504.04592)

	Uri Menkes, Assaf Hallak, Ofra Amir

+ [Exploring Generative AI Techniques in Government: A Case Study](https://arxiv.org//abs/2504.10497)

	Sunyi Liu, Mengzhe Geng, Rebecca Hart

# 2025-04-05
+ [Among Us: A Sandbox for Measuring and Detecting Agentic Deception](https://arxiv.org//abs/2504.04072)

	Satvik Golechha, Adrià Garriga-Alonso

+ [FISH-Tuning: Enhancing PEFT Methods with Fisher Information](https://arxiv.org//abs/2504.04050)

	Kang Xue, Ming Dong, Xinhui Tu, Tingting He

# 2025-04-04
+ [Noise Augmented Fine Tuning for Mitigating Hallucinations in Large Language Models](https://arxiv.org//abs/2504.03302)

	Afshin Khadangi, Amir Sartipi, Igor Tchappi, Ramin Bahmani

+ [APIGen-MT: Agentic Pipeline for Multi-Turn Data Generation via Simulated Agent-Human Interplay](https://arxiv.org//abs/2504.03601)

	Akshara Prabhakar, Zuxin Liu, Ming Zhu, Jianguo Zhang, Tulika Awalgaonkar, Shiyu Wang, Zhiwei Liu, Haolin Chen, Thai Hoang, Juan Carlos Niebles, Shelby Heinecke, Weiran Yao, Huan Wang, Silvio Savarese, Caiming Xiong

+ [How Social is It? A Benchmark for LLMs' Capabilities in Multi-user Multi-turn Social Agent Tasks](https://arxiv.org//abs/2505.04628)

	Yusen Wu, Junwu Xiong, Xiaotie Deng

# 2025-04-03
+ [Cognitive Memory in Large Language Models](https://arxiv.org//abs/2504.02441)

	Lianlei Shan, Shixian Luo, Zezhou Zhu, Yu Yuan, Yong Wu


+ [Multifaceted Evaluation of Audio-Visual Capability for MLLMs: Effectiveness, Efficiency, Generalizability and Robustness](https://arxiv.org//abs/2504.16936)

	Yusheng Zhao, Junyu Luo, Xiao Luo, Weizhi Zhang, Zhiping Xiao, Wei Ju, Philip S. Yu, Ming Zhang



+ [Generative Evaluation of Complex Reasoning in Large Language Models](https://arxiv.org//abs/2504.02810)

	Haowei Lin, Xiangyu Wang, Ruilin Yan, Baizhou Huang, Haotian Ye, Jianhua Zhu, Zihao Wang, James Zou, Jianzhu Ma, Yitao Liang

+ [GPG: A Simple and Strong Reinforcement Learning Baseline for Model Reasoning](https://arxiv.org//abs/2504.02546)

	Xiangxiang Chu, Hailang Huang, Xiao Zhang, Fei Wei, Yong Wang

+ [GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image Generation](https://arxiv.org//abs/2504.02782)

	Zhiyuan Yan, Junyan Ye, Weijia Li, Zilong Huang, Shenghai Yuan, Xiangyang He, Kaiqing Lin, Jun He, Conghui He, Li Yuan

+ [Why do LLMs attend to the first token?](https://arxiv.org//abs/2504.02732)

	Federico Barbero, Álvaro Arroyo, Xiangming Gu, Christos Perivolaropoulos, Michael Bronstein, Petar Veličković, Razvan Pascanu

+ [GPTAQ: Efficient Finetuning-Free Quantization for Asymmetric Calibration](https://arxiv.org//abs/2504.02692)

	Yuhang Li, Ruokai Yin, Donghyun Lee, Shiting Xiao, Priyadarshini Panda

# 2025-04-02
+ [LRAGE: Legal Retrieval Augmented Generation Evaluation Tool](https://arxiv.org//abs/2504.01840)

	Minhu Park, Hongseok Oh, Eunkyung Choi, Wonseok Hwang

+ [TiC-LM: A Web-Scale Benchmark for Time-Continual LLM Pretraining](https://arxiv.org//abs/2504.02107)

	Jeffrey Li, Mohammadreza Armandpour, Iman Mirzadeh, Sachin Mehta, Vaishaal Shankar, Raviteja Vemulapalli, Samy Bengio, Oncel Tuzel, Mehrdad Farajtabar, Hadi Pouransari, Fartash Faghri

+ [An Illusion of Progress? Assessing the Current State of Web Agents](https://arxiv.org//abs/2504.01382)

	Tianci Xue, Weijian Qi, Tianneng Shi, Chan Hee Song, Boyu Gou, Dawn Song, Huan Sun, Yu Su

+ [DeepSeek-R1 Thoughtology: Let's think about LLM Reasoning](https://arxiv.org//abs/2504.07128)

	Sara Vera Marjanović, Arkil Patel, Vaibhav Adlakha, Milad Aghajohari, Parishad BehnamGhader, Mehar Bhatia, Aditi Khandelwal, Austin Kraft, Benno Krojer, Xing Han Lù, Nicholas Meade, Dongchan Shin, Amirhossein Kazemnejad, Gaurav Kamath, Marius Mosbach, Karolina Stańczak, Siva Reddy

+ [Do Theory of Mind Benchmarks Need Explicit Human-like Reasoning in Language Models?](https://arxiv.org//abs/2504.01698)

	Yi-Long Lu, Chunhui Zhang, Jiajun Song, Lifeng Fan, Wei Wang

# 2025-04-01
+ [GraphMaster: Automated Graph Synthesis via LLM Agents in Data-Limited Environments](https://arxiv.org//abs/2504.00711)

	Enjun Du, Xunkai Li, Tian Jin, Zhihan Zhang, Rong-Hua Li, Guoren Wang

+ [Catch Me if You Search: When Contextual Web Search Results Affect the Detection of Hallucinations](https://arxiv.org//abs/2504.01153)

	Mahjabin Nahar, Eun-Ju Lee, Jin Won Park, Dongwon Lee

+ [Do We Truly Need So Many Samples? Multi-LLM Repeated Sampling Efficiently Scales Test-Time Compute](https://arxiv.org//abs/2504.00762)

	Jianhao Chen, Zishuo Xun, Bocheng Zhou, Han Qi, Hangfan Zhang, Qiaosheng Zhang, Yang Chen, Wei Hu, Yuzhong Qu, Wanli Ouyang, Shuyue Hu

+ [AI Hiring with LLMs: A Context-Aware and Explainable Multi-Agent Framework for Resume Screening](https://arxiv.org//abs/2504.02870)

	Frank P.-W. Lo, Jianing Qiu, Zeyu Wang, Haibao Yu, Yeming Chen, Gao Zhang, Benny Lo

# 2025-03-31
+ [Dynamic Parametric Retrieval Augmented Generation for Test-time Knowledge Enhancement](https://arxiv.org//abs/2503.23895)

	Yuqiao Tan, Shizhu He, Huanxuan Liao, Jun Zhao, Kang Liu

+ [A Survey on Test-Time Scaling in Large Language Models: What, How, Where, and How Well?](https://arxiv.org//abs/2503.24235)

	Qiyuan Zhang, Fuyuan Lyu, Zexu Sun, Lei Wang, Weixu Zhang, Wenyue Hua, Haolun Wu, Zhihan Guo, Yufei Wang, Niklas Muennighoff, Irwin King, Xue Liu, Chen Ma

+ [Rec-R1: Bridging Generative Large Language Models and User-Centric Recommendation Systems via Reinforcement Learning](https://arxiv.org//abs/2503.24289)

	Jiacheng Lin, Tian Wang, Kun Qian

+ [Is analogy enough to draw novel adjective-noun inferences?](https://arxiv.org//abs/2503.24293)

	Hayley Ross, Kathryn Davidson, Najoung Kim

+ [Effectively Controlling Reasoning Models through Thinking Intervention](https://arxiv.org//abs/2503.24370)

	Tong Wu, Chong Xiang, Jiachen T. Wang, G. Edward Suh, Prateek Mittal

# 2025-03-30
+ [A Survey of WebAgents: Towards Next-Generation AI Agents for Web Automation with Large Foundation Models](https://arxiv.org//abs/2503.23350)

	Liangbo Ning, Ziran Liang, Zhuohang Jiang, Haohao Qu, Yujuan Ding, Wenqi Fan, Xiao-yong Wei, Shanru Lin, Hui Liu, Philip S. Yu, Qing Li

+ [Mixture of Routers](https://arxiv.org//abs/2503.23362)

	Jia-Chen Zhang, Yu-Jie Xiong, Xi-He Qiu, Chun-Ming Xia, Fei Dai

+ [RARE: Retrieval-Augmented Reasoning Modeling](https://arxiv.org//abs/2503.23513)

	Zhengren Wang, Jiayang Yu, Dongsheng Ma, Zhe Chen, Yu Wang, Zhiyu Li, Feiyu Xiong, Yanfeng Wang, Weinan E, Linpeng Tang, Wentao Zhang

# 2025-03-29
+ [LangVAE and LangSpace: Building and Probing for Language Model VAEs](https://arxiv.org//abs/2505.00004)

	Danilo S. Carvalho, Yingji Zhang, Harriet Unsworth, André Freitas

# 2025-03-28
+ [Probabilistic Uncertain Reward Model: A Natural Generalization of Bradley-Terry Reward Model](https://arxiv.org//abs/2503.22480)

	Wangtao Sun, Xiang Cheng, Xing Yu, Haotian Xu, Zhao Yang, Shizhu He, Jun Zhao, Kang Liu

+ [The Mind in the Machine: A Survey of Incorporating Psychological Theories in LLMs](https://arxiv.org//abs/2505.00003)

	Zizhou Liu, Ziwei Gong, Lin Ai, Zheng Hui, Run Chen, Colin Wayne Leach, Michelle R. Greene, Julia Hirschberg

+ [Why Stop at One Error? Benchmarking LLMs as Data Science Code Debuggers for Multi-Hop and Multi-Bug Errors](https://arxiv.org//abs/2503.22388)

	Zhiyu Yang, Shuo Wang, Yukun Yan, Yang Deng

# 2025-03-27
+ [Shared Global and Local Geometry of Language Model Embeddings](https://arxiv.org//abs/2503.21073)

	Andrew Lee, Melanie Weber, Fernanda Viégas, Martin Wattenberg

+ [A Computational Theory for Efficient Mini Agent Evaluation with Causal Guarantees](https://arxiv.org//abs/2503.21138)

	Hedong Yan

+ [Alleviating LLM-based Generative Retrieval Hallucination in Alipay Search](https://arxiv.org//abs/2503.21098)

	Yedan Shen, Kaixin Wu, Yuechen Ding, Jingyuan Wen, Hong Liu, Mingjie Zhong, Zhouhan Lin, Jia Xu, Linjian Mo

+ [UI-R1: Enhancing Efficient Action Prediction of GUI Agents by Reinforcement Learning](https://arxiv.org//abs/2503.21620)

	Zhengxi Lu, Yuxiang Chai, Yaxuan Guo, Xi Yin, Liang Liu, Hao Wang, Han Xiao, Shuai Ren, Guanjing Xiong, Hongsheng Li

+ [Video-R1: Reinforcing Video Reasoning in MLLMs](https://arxiv.org//abs/2503.21776)

	Kaituo Feng, Kaixiong Gong, Bohao Li, Zonghao Guo, Yibing Wang, Tianshuo Peng, Junfei Wu, Xiaoying Zhang, Benyou Wang, Xiangyu Yue

+ [ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large Reasoning Models with Iterative Retrieval Augmented Generation](https://arxiv.org//abs/2503.21729)

	Zhicheng Lee, Shulin Cao, Jinxin Liu, Jiajie Zhang, Weichuan Liu, Xiaoyin Che, Lei Hou, Juanzi Li

+ [MoQa: Rethinking MoE Quantization with Multi-stage Data-model Distribution Awareness](https://arxiv.org//abs/2503.21135)

	Zihao Zheng, Xiuping Cui, Size Zheng, Maoliang Li, Jiayu Chen, Yun Liang, Xiang Chen

# 2025-03-26
+ [Dynamic Pyramid Network for Efficient Multimodal Large Language Model](https://arxiv.org//abs/2503.20322)

	Hao Ai, Kunyi Wang, Zezhou Wang, Hao Lu, Jin Tian, Yaxin Luo, Peng Xing, Jen-Yuan Huang, Huaxia Li, Gen luo


+ [Clean & Clear: Feasibility of Safe LLM Clinical Guidance](https://arxiv.org//abs/2503.20953)

	Julia Ive, Felix Jozsa, Nick Jackson, Paulina Bondaronek, Ciaran Scott Hill, Richard Dobson

# 2025-03-25
+ [CausalRAG: Integrating Causal Graphs into Retrieval-Augmented Generation](https://arxiv.org//abs/2503.19878)

	Nengbo Wang, Xiaotian Han, Jagdip Singh, Jing Ma, Vipin Chaudhary

+ [Rosetta-PL: Propositional Logic as a Benchmark for Large Language Model Reasoning](https://arxiv.org//abs/2505.00001)

	Shaun Baek, Shaun Esua-Mensah, Cyrus Tsui, Sejan Vigneswaralingam, Abdullah Alali, Michael Lu, Vasu Sharma, Kevin Zhu

+ [OAEI-LLM-T: A TBox Benchmark Dataset for Understanding Large Language Model Hallucinations in Ontology Matching](https://arxiv.org//abs/2503.21813)

	Zhangcheng Qiang

# 2025-03-24
+ [SimpleRL-Zoo: Investigating and Taming Zero Reinforcement Learning for Open Base Models in the Wild](https://arxiv.org//abs/2503.18892)

	Weihao Zeng, Yuzhen Huang, Qian Liu, Wei Liu, Keqing He, Zejun Ma, Junxian He

+ [Oaken: Fast and Efficient LLM Serving with Online-Offline Hybrid KV Cache Quantization](https://arxiv.org//abs/2503.18599)

	Minsu Kim, Seongmin Hong, RyeoWook Ko, Soongyu Choi, Hunjong Lee, Junsoo Kim, Joo-Young Kim, Jongse Park

# 2025-03-23
+ [HAIR: Hardness-Aware Inverse Reinforcement Learning with Introspective Reasoning for LLM Alignment](https://arxiv.org//abs/2503.18991)

	Ruoxi Cheng, Haoxuan Ma, Weixin Wang

+ [Adaptive Rank Allocation: Speeding Up Modern Transformers with RaNA Adapters](https://arxiv.org//abs/2503.18216)

	Roberto Garcia, Jerry Liu, Daniel Sorvisto, Sabri Eyuboglu

+ [DeLoRA: Decoupling Angles and Strength in Low-rank Adaptation](https://arxiv.org//abs/2503.18225)

	Massimo Bini, Leander Girrbach, Zeynep Akata

# 2025-03-22
+ [Evaluating Clinical Competencies of Large Language Models with a General Practice Benchmark](https://arxiv.org//abs/2503.17599)

	Zheqing Li, Yiying Yang, Jiping Lang, Wenhao Jiang, Yuhang Zhao, Shuang Li, Dingqian Wang, Zhu Lin, Xuanna Li, Yuze Tang, Jiexian Qiu, Xiaolin Lu, Hongji Yu, Shuang Chen, Yuhua Bi, Xiaofei Zeng, Yixian Chen, Junrong Chen, Lin Yao

# 2025-03-21
+ [A Survey on Personalized Alignment -- The Missing Piece for Large Language Models in Real-World Applications](https://arxiv.org//abs/2503.17003)

	Jian Guan, Junfei Wu, Jia-Nan Li, Chuanqi Cheng, Wei Wu

+ [ConvoGen: Enhancing Conversational AI with Synthetic Data: A Multi-Agent Approach](https://arxiv.org//abs/2503.17460)

	Reem Gody, Mahmoud Goudy, Ahmed Y. Tawfik

# 2025-03-20
+ [Detecting LLM-Generated Peer Reviews](https://arxiv.org//abs/2503.15772)

	Vishisht Rao, Aounon Kumar, Himabindu Lakkaraju, Nihar B. Shah

# 2025-03-19
+ [Benchmarking Open-Source Large Language Models on Healthcare Text Classification Tasks](https://arxiv.org//abs/2503.15169)

	Yuting Guo, Abeed Sarker

+ [Task-Specific Data Selection for Instruction Tuning via Monosemantic Neuronal Activations](https://arxiv.org//abs/2503.15573)

	Da Ma, Gonghu Shang, Zhi Chen, Libo Qin, Yijie Luo, Lei Pan, Shuai Fan, Lu Chen, Kai Yu

# 2025-03-18
+ [JuDGE: Benchmarking Judgment Document Generation for Chinese Legal System](https://arxiv.org//abs/2503.14258)

	Weihang Su, Baoqing Yue, Qingyao Ai, Yiran Hu, Jiaqi Li, Changyue Wang, Kaiyuan Zhang, Yueyue Wu, Yiqun Liu

+ [Predicting Human Choice Between Textually Described Lotteries](https://arxiv.org//abs/2503.14004)

	Eyal Marantz, Ori Plonsky

+ [Safety Evaluation and Enhancement of DeepSeek Models in Chinese Contexts](https://arxiv.org//abs/2503.16529)

	Wenjing Zhang, Xuejiao Lei, Zhaoxiang Liu, Limin Han, Jiaojiao Zhao, Junting Guo, Zhenhong Long, Shu Yang, Meijuan An, Beibei Huang, Rongjia Du, Ning Wang, Kai Wang, Shiguo Lian

+ [Beyond Single Pass, Looping Through Time: KG-IRAG with Iterative Knowledge Retrieval](https://arxiv.org//abs/2503.14234)

	Ruiyi Yang, Hao Xue, Imran Razzak, Hakim Hacid, Flora D. Salim

# 2025-03-17
+ [Atyaephyra at SemEval-2025 Task 4: Low-Rank Negative Preference Optimization](https://arxiv.org//abs/2503.13690)

	Jan Bronec (1), Jindřich Helcl (1) ((1) Charles University, Faculty of Mathematics and Physics, Institute of Formal and Applied Linguistics)

+ [KVShare: An LLM Service System with Efficient and Effective Multi-Tenant KV Cache Reuse](https://arxiv.org//abs/2503.16525)

	Huan Yang, Renji Zhang, Mingzhe Huang, Weijun Wang, Yin Tang, Yuanchun Li, Yunxin Liu, Deyu Zhang

+ [HICD: Hallucination-Inducing via Attention Dispersion for Contrastive Decoding to Mitigate Hallucinations in Large Language Models](https://arxiv.org//abs/2503.12908)

	Xinyan Jiang, Hang Ye, Yongxin Zhu, Xiaoying Zheng, Zikang Chen, Jun Gong

# 2025-03-16
+ [Towards Hierarchical Multi-Step Reward Models for Enhanced Reasoning in Large Language Models](https://arxiv.org//abs/2503.13551)

	Teng Wang, Zhangyi Jiang, Zhenqi He, Shenyang Tong, Wenhan Yang, Yanan Zheng, Zeyu Li, Zifan He, Hailei Gong

+ [Being-0: A Humanoid Robotic Agent with Vision-Language Models and Modular Skills](https://arxiv.org//abs/2503.12533)

	Haoqi Yuan, Yu Bai, Yuhui Fu, Bohan Zhou, Yicheng Feng, Xinrun Xu, Yi Zhan, Börje F. Karlsson, Zongqing Lu

# 2025-03-14
+ [CURIE: Evaluating LLMs On Multitask Scientific Long Context Understanding and Reasoning](https://arxiv.org//abs/2503.13517)

	Hao Cui, Zahra Shamsi, Gowoon Cheon, Xuejian Ma, Shutong Li, Maria Tikhanovskaya, Peter Norgaard, Nayantara Mudur, Martyna Plomecka, Paul Raccuglia, Yasaman Bahri, Victor V. Albert, Pranesh Srinivasan, Haining Pan, Philippe Faist, Brian Rohr, Ekin Dogus Cubuk, Muratahan Aykol, Amil Merchant, Michael J. Statt, Dan Morris, Drew Purves, Elise Kleeman, Ruth Alcantara, Matthew Abraham, Muqthar Mohammad, Ean Phing VanLee, Chenfei Jiang, Elizabeth Dorfman, Eun-Ah Kim, Michael P Brenner, Viren Jain, Sameera Ponda, Subhashini Venugopalan

+ [Implicit Bias-Like Patterns in Reasoning Models](https://arxiv.org//abs/2503.11572)

	Messi H.J. Lee, Calvin K. Lai

+ [D3: Diversity, Difficulty, and Dependability-Aware Data Selection for Sample-Efficient LLM Instruction Tuning](https://arxiv.org//abs/2503.11441)

	Jia Zhang, Chen-Xi Zhang, Yao Liu, Yi-Xuan Jin, Xiao-Wen Yang, Bo Zheng, Yi Liu, Lan-Zhe Guo

# 2025-03-13
+ [HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks](https://arxiv.org//abs/2503.10894)

	Jiuding Sun, Jing Huang, Sidharth Baskaran, Karel D'Oosterlinck, Christopher Potts, Michael Sklar, Atticus Geiger


+ [HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks](https://arxiv.org//abs/2503.10894)

	Jiuding Sun, Jing Huang, Sidharth Baskaran, Karel D'Oosterlinck, Christopher Potts, Michael Sklar, Atticus Geiger

+ [How Do Multimodal Large Language Models Handle Complex Multimodal Reasoning? Placing Them in An Extensible Escape Game](https://arxiv.org//abs/2503.10042)

	Ziyue Wang, Yurui Dong, Fuwen Luo, Minyuan Ruan, Zhili Cheng, Chi Chen, Peng Li, Yang Liu

+ [Collaborative Speculative Inference for Efficient LLM Inference Serving](https://arxiv.org//abs/2503.10325)

	Luyao Gao, Jianchun Liu, Hongli Xu, Xichong Zhang, Yunming Liao, Liusheng Huang

+ [Evaluating Mathematical Reasoning Across Large Language Models: A Fine-Grained Approach](https://arxiv.org//abs/2503.10573)

	Afrar Jahin, Arif Hassan Zidan, Wei Zhang, Yu Bao, Tianming Liu

# 2025-03-12
+ [LocAgent: Graph-Guided LLM Agents for Code Localization](https://arxiv.org//abs/2503.09089)

	Zhaoling Chen, Xiangru Tang, Gangda Deng, Fang Wu, Jialong Wu, Zhiwei Jiang, Viktor Prasanna, Arman Cohan, Xingyao Wang

+ [Privacy-Preserved Automated Scoring using Federated Learning for Educational Research](https://arxiv.org//abs/2503.11711)

	Ehsan Latif, Xiaoming Zhai

+ [I Predict Therefore I Am: Is Next Token Prediction Enough to Learn Human-Interpretable Concepts from Data?](https://arxiv.org//abs/2503.08980)

	Yuhang Liu, Dong Gong, Yichao Cai, Erdun Gao, Zhen Zhang, Biwei Huang, Mingming Gong, Anton van den Hengel, Javen Qinfeng Shi

+ [PolyPythias: Stability and Outliers across Fifty Language Model Pre-Training Runs](https://arxiv.org//abs/2503.09543)

	Oskar van der Wal, Pietro Lesci, Max Muller-Eberstein, Naomi Saphra, Hailey Schoelkopf, Willem Zuidema, Stella Biderman

+ [Probabilistic Reasoning with LLMs for k-anonymity Estimation](https://arxiv.org//abs/2503.09674)

	Jonathan Zheng, Sauvik Das, Alan Ritter, Wei Xu

# 2025-03-11
+ [Training Plug-n-Play Knowledge Modules with Deep Context Distillation](https://arxiv.org//abs/2503.08727)

	Lucas Caccia, Alan Ansell, Edoardo Ponti, Ivan Vulić, Alessandro Sordoni

# 2025-03-10
+ [Are We Truly Forgetting? A Critical Re-examination of Machine Unlearning Evaluation Protocols](https://arxiv.org//abs/2503.06991)

	Yongwoo Kim, Sungmin Cha, Donghyun Kim

+ [UC-MOA: Utility-Conditioned Multi-Objective Alignment for Distributional Pareto-Optimality](https://arxiv.org//abs/2503.10669)

	Zelei Cheng, Xin-Qiang Cai, Yuting Tang, Pushi Zhang, Boming Yang, Masashi Sugiyama, Xinyu Xing

# 2025-03-09
+ [HCT-QA: A Benchmark for Question Answering on Human-Centric Tables](https://arxiv.org//abs/2504.20047)

	Mohammad S. Ahmad, Zan A. Naeem, Michaël Aupetit, Ahmed Elmagarmid, Mohamed Eltabakh, Xiasong Ma, Mourad Ouzzani, Chaoyi Ruan

# 2025-03-08
+ [SCoRE: Benchmarking Long-Chain Reasoning in Commonsense Scenarios](https://arxiv.org//abs/2503.06218)

	Weidong Zhan, Yue Wang, Nan Hu, Liming Xiao, Jingyuan Ma, Yuhang Qin, Zheng Li, Yixin Yang, Sirui Deng, Jinkun Ding, Wenhan Ma, Rui Li, Weilin Luo, Qun Liu, Zhifang Sui

# 2025-03-07
+ [Correctness Coverage Evaluation for Medical Multiple-Choice Question Answering Based on the Enhanced Conformal Prediction Framework](https://arxiv.org//abs/2503.05505)

	Yusong Ke, Hongru Lin, Yuting Ruan, Junya Tang, Li Li

+ [AVA: Attentive VLM Agent for Mastering StarCraft II](https://arxiv.org//abs/2503.05383)

	Weiyu Ma, Yuqian Fu, Zecheng Zhang, Bernard Ghanem, Guohao Li

# 2025-03-06
+ [Wanda++: Pruning Large Language Models via Regional Gradients](https://arxiv.org//abs/2503.04992)

	Yifan Yang, Kai Zhen, Bhavana Ganesh, Aram Galstyan, Goeric Huybrechts, Markus Müller, Jonas M. Kübler, Rupak Vignesh Swaminathan, Athanasios Mouchtaris, Sravan Babu Bodapati, Nathan Susanj, Zheng Zhang, Jack FitzGerald, Abhishek Kumar

+ [SOLAR: Scalable Optimization of Large-scale Architecture for Reasoning](https://arxiv.org//abs/2503.04530)

	Chen Li, Yinyi Luo, Anudeep Bolimera, Uzair Ahmed, Shri Kiran Srinivasan, Hrishikesh Gokhale, Marios Savvides

# 2025-03-05
+ [CodeIF-Bench: Evaluating Instruction-Following Capabilities of Large Language Models in Interactive Code Generation](https://arxiv.org//abs/2503.22688)

	Peiding Wang, Li Zhang, Fang Liu, Lin Shi, Minxiao Li, Bo Shen, An Fu

+ [The Devil Is in the Details: Tackling Unimodal Spurious Correlations for Generalizable Multimodal Reward Models](https://arxiv.org//abs/2503.03122)

	Zichao Li, Xueru Wen, Jie Lou, Yuqiu Ji, Yaojie Lu, Xianpei Han, Debing Zhang, Le Sun

+ [Cite Before You Speak: Enhancing Context-Response Grounding in E-commerce Conversational LLM-Agents](https://arxiv.org//abs/2503.04830)

	Jingying Zeng, Hui Liu, Zhenwei Dai, Xianfeng Tang, Chen Luo, Samarth Varshney, Zhen Li, Qi He

+ [Can Frontier LLMs Replace Annotators in Biomedical Text Mining? Analyzing Challenges and Exploring Solutions](https://arxiv.org//abs/2503.03261)

	Yichong Zhao, Susumu Goto

# 2025-03-04
+ [LiteWebAgent: The Open-Source Suite for VLM-Based Web-Agent Applications](https://arxiv.org//abs/2503.02950)

	Danqing Zhang, Balaji Rama, Jingyi Ni, Shiying He, Fu Zhao, Kunyu Chen, Arnold Chen, Junyu Cao

+ [Call for Rigor in Reporting Quality of Instruction Tuning Data](https://arxiv.org//abs/2503.04807)

	Hyeonseok Moon, Jaehyung Seo, Heuiseok Lim

+ [MoSE: Hierarchical Self-Distillation Enhances Early Layer Embeddings](https://arxiv.org//abs/2503.03008)

	Andrea Gurioli, Federico Pennino, João Monteiro, Maurizio Gabbrielli

# 2025-03-03
+ [SAGE: A Framework of Precise Retrieval for RAG](https://arxiv.org//abs/2503.01713)

	Jintao Zhang, Guoliang Li, Jinyang Su

+ [Liger: Linearizing Large Language Models to Gated Recurrent Structures](https://arxiv.org//abs/2503.01496)

	Disen Lan, Weigao Sun, Jiaxi Hu, Jusen Du, Yu Cheng

# 2025-03-02
+ [NCL-UoR at SemEval-2025 Task 3: Detecting Multilingual Hallucination and Related Observable Overgeneration Text Spans with Modified RefChecker and Modified SeflCheckGPT](https://arxiv.org//abs/2503.01921)

	Jiaying Hong, Thanet Markchom, Jianfei Xu, Tong Wu, Huizhi Liang

+ [ALinFiK: Learning to Approximate Linearized Future Influence Kernel for Scalable Third-Party LLM Data Valuation](https://arxiv.org//abs/2503.01052)

	Yanzhou Pan, Huawei Lin, Yide Ran, Jiamin Chen, Xiaodong Yu, Weijie Zhao, Denghui Zhang, Zhaozhuo Xu

# 2025-02-28
+ [SPD: Sync-Point Drop for efficient tensor parallelism of Large Language Models](https://arxiv.org//abs/2502.20727)

	Han-Byul Kim, Duc Hoang, Arnav Kundu, Mohammad Samragh, Minsik Cho

+ [Semantic Volume: Quantifying and Detecting both External and Internal Uncertainty in LLMs](https://arxiv.org//abs/2502.21239)

	Xiaomin Li, Zhou Yu, Ziji Zhang, Yingying Zhuang, Swair Shah, Narayanan Sadagopan, Anurag Beniwal

+ [A Pilot Empirical Study on When and How to Use Knowledge Graphs as Retrieval Augmented Generation](https://arxiv.org//abs/2502.20854)

	Xujie Yuan, Yongxu Liu, Shimin Di, Shiwen Wu, Libin Zheng, Rui Meng, Lei Chen, Xiaofang Zhou, Jian Yin

+ [FANformer: Improving Large Language Models Through Effective Periodicity Modeling](https://arxiv.org//abs/2502.21309)

	Yihong Dong, Ge Li, Xue Jiang, Yongding Tao, Kechi Zhang, Hao Zhu, Huanyu Liu, Jiazheng Ding, Jia Li, Jinliang Deng, Hong Mei

# 2025-02-27
+ [LLM-driven Effective Knowledge Tracing by Integrating Dual-channel Difficulty](https://arxiv.org//abs/2502.19915)

	Jiahui Cen, Jianghao Lin, Weixuan Zhong, Dong Zhou, Jin Chen, Aimin Yang, Yongmei Zhou

+ [Mapping Trustworthiness in Large Language Models: A Bibliometric Analysis Bridging Theory to Practice](https://arxiv.org//abs/2503.04785)

	José Siqueira de Cerqueira, Kai-Kristian Kemell, Muhammad Waseem, Rebekah Rousi, Nannan Xi, Juho Hamari, Pekka Abrahamsson

+ [Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization](https://arxiv.org//abs/2502.20364)

	Ryan C. Barron, Maksim E. Eren, Olga M. Serafimova, Cynthia Matuszek, Boian S. Alexandrov

# 2025-02-26
+ [BIG-Bench Extra Hard](https://arxiv.org//abs/2502.19187)

	Mehran Kazemi, Bahare Fatemi, Hritik Bansal, John Palowitch, Chrysovalantis Anastasiou, Sanket Vaibhav Mehta, Lalit K. Jain, Virginia Aglietti, Disha Jindal, Peter Chen, Nishanth Dikkala, Gladys Tyen, Xin Liu, Uri Shalit, Silvia Chiappa, Kate Olszewska, Yi Tay, Vinh Q. Tran, Quoc V. Le, Orhan Firat

+ [A Sliding Layer Merging Method for Efficient Depth-Wise Pruning in LLMs](https://arxiv.org//abs/2502.19159)

	Xuan Ding, Rui Sun, Yunjian Zhang, Xiu Yan, Yueqi Zhou, Kaihao Huang, Suzhong Fu, Chuanlong Xie, Yao Zhu

+ [Can RLHF be More Efficient with Imperfect Reward Models? A Policy Coverage Perspective](https://arxiv.org//abs/2502.19255)

	Jiawei Huang, Bingcong Li, Christoph Dann, Niao He

# 2025-02-25
+ [Faster, Cheaper, Better: Multi-Objective Hyperparameter Optimization for LLM and RAG Systems](https://arxiv.org//abs/2502.18635)

	Matthew Barker, Andrew Bell, Evan Thomas, James Carr, Thomas Andrews, Umang Bhatt

+ [Discriminative Finetuning of Generative Large Language Models without Reward Models and Human Preference Data](https://arxiv.org//abs/2502.18679)

	Siqi Guo, Ilgee Hong, Vicente Balmaseda, Changlong Yu, Liang Qiu, Xin Liu, Haoming Jiang, Tuo Zhao, Tianbao Yang

+ [Harnessing Multiple Large Language Models: A Survey on LLM Ensemble](https://arxiv.org//abs/2502.18036)

	Zhijun Chen, Jingzheng Li, Pengpeng Chen, Zhuoran Li, Kai Sun, Yuankai Luo, Qianren Mao, Dingqi Yang, Hailong Sun, Philip S. Yu

+ [Uncertainty Quantification for LLM-Based Survey Simulations](https://arxiv.org//abs/2502.17773)

	Chengpiao Huang, Yuhang Wu, Kaizheng Wang

# 2025-02-24
+ [Automatically Evaluating the Paper Reviewing Capability of Large Language Models](https://arxiv.org//abs/2502.17086)

	Hyungyu Shin, Jingyu Tang, Yoonjoo Lee, Nayoung Kim, Hyunseung Lim, Ji Yong Cho, Hwajung Hong, Moontae Lee, Juho Kim

+ [From System 1 to System 2: A Survey of Reasoning Large Language Models](https://arxiv.org//abs/2502.17419)

	Zhong-Zhi Li, Duzhen Zhang, Ming-Liang Zhang, Jiaxin Zhang, Zengyan Liu, Yuxuan Yao, Haotian Xu, Junhao Zheng, Pei-Jie Wang, Xiuyi Chen, Yingying Zhang, Fei Yin, Jiahua Dong, Zhiwei Li, Bao-Long Bi, Ling-Rui Mei, Junfeng Fang, Zhijiang Guo, Le Song, Cheng-Lin Liu

+ [MEMERAG: A Multilingual End-to-End Meta-Evaluation Benchmark for Retrieval Augmented Generation](https://arxiv.org//abs/2502.17163)

	María Andrea Cruz Blandón, Jayasimha Talur, Bruno Charron, Dong Liu, Saab Mansour, Marcello Federico

# 2025-02-21
+ [Machine-generated text detection prevents language model collapse](https://arxiv.org//abs/2502.15654)

	George Drayson, Emine Yilmaz, Vasileios Lampos

+ [Activation Steering in Neural Theorem Provers](https://arxiv.org//abs/2502.15507)

	Shashank Kirtania

+ [Unveiling Attractor Cycles in Large Language Models: A Dynamical Systems View of Successive Paraphrasing](https://arxiv.org//abs/2502.15208)

	Zhilin Wang, Yafu Li, Jianhao Yan, Yu Cheng, Yue Zhang

+ [ARS: Automatic Routing Solver with Large Language Models](https://arxiv.org//abs/2502.15359)

	Kai Li, Fei Liu, Zhenkun Wang, Xialiang Tong, Xiongwei Han, Mingxuan Yuan, Qingfu Zhang

# 2025-02-20
+ [Drift: Decoding-time Personalized Alignments with Implicit User Preferences](https://arxiv.org//abs/2502.14289)

	Minbeom Kim, Kang-il Lee, Seongho Joo, Hwaran Lee, Thibaut Thonet, Kyomin Jung

+ [A Statistical Case Against Empirical Human-AI Alignment](https://arxiv.org//abs/2502.14581)

	Julian Rodemann, Esteban Garces Arias, Christoph Luther, Christoph Jansen, Thomas Augustin

+ [InductionBench: LLMs Fail in the Simplest Complexity Class](https://arxiv.org//abs/2502.15823)

	Wenyue Hua, Tyler Wong, Sun Fei, Liangming Pan, Adam Jardine, William Yang Wang

+ [iAgent: LLM Agent as a Shield between User and Recommender Systems](https://arxiv.org//abs/2502.14662)

	Wujiang Xu, Yunxiao Shi, Zujie Liang, Xuying Ning, Kai Mei, Kun Wang, Xi Zhu, Min Xu, Yongfeng Zhang

# 2025-02-19
+ [FairKV: Balancing Per-Head KV Cache for Fast Multi-GPU Inference](https://arxiv.org//abs/2502.15804)

	Bingzhe Zhao, Ke Cheng, Aomufei Yuan, Yuxuan Tian, Ruiguang Zhong, Chengchen Hu, Tong Yang, Lian Yu

+ [Is This Collection Worth My LLM's Time? Automatically Measuring Information Potential in Text Corpora](https://arxiv.org//abs/2502.13691)

	Tristan Karch, Luca Engel, Philippe Schwaller, Frédéric Kaplan

# 2025-02-18
+ [EPO: Explicit Policy Optimization for Strategic Reasoning in LLMs via Reinforcement Learning](https://arxiv.org//abs/2502.12486)

	Xiaoqian Liu, Ke Wang, Yongbin Li, Yuchuan Wu, Wentao Ma, Aobo Kong, Fei Huang, Jianbin Jiao, Junge Zhang

+ [An LLM-Powered Agent for Physiological Data Analysis: A Case Study on PPG-based Heart Rate Estimation](https://arxiv.org//abs/2502.12836)

	Mohammad Feli, Iman Azimi, Pasi Liljeberg, Amir M.Rahmani

+ [None of the Others: a General Technique to Distinguish Reasoning from Memorization in Multiple-Choice LLM Evaluation Benchmarks](https://arxiv.org//abs/2502.12896)

	Eva Sánchez Salido, Julio Gonzalo, Guillermo Marco

+ [Demonstrating specification gaming in reasoning models](https://arxiv.org//abs/2502.13295)

	Alexander Bondarenko, Denis Volk, Dmitrii Volkov, Jeffrey Ladish

+ [KL Penalty Control via Perturbation for Direct Preference Optimization](https://arxiv.org//abs/2502.13177)

	Sangkyu Lee, Janghoon Han, Hosung Song, Stanley Jungkyu Choi, Honglak Lee, Youngjae Yu

+ [SafeRoute: Adaptive Model Selection for Efficient and Accurate Safety Guardrails in Large Language Models](https://arxiv.org//abs/2502.12464)

	Seanie Lee, Dong Bok Lee, Dominik Wagner, Minki Kang, Haebin Seong, Tobias Bocklet, Juho Lee, Sung Ju Hwang

# 2025-02-17
+ [Towards Reasoning Ability of Small Language Models](https://arxiv.org//abs/2502.11569)

	Gaurav Srivastava, Shuxiang Cao, Xuan Wang


+ [Fate: Fast Edge Inference of Mixture-of-Experts Models via Cross-Layer Gate](https://arxiv.org//abs/2502.12224)

	Zhiyuan Fang, Zicong Hong, Yuegui Huang, Yufeng Lyu, Wuhui Chen, Yue Yu, Fan Yu, Zibin Zheng

+ [Integrating Expert Knowledge into Logical Programs via LLMs](https://arxiv.org//abs/2502.12275)

	Franciszek Górski, Oskar Wysocki, Marco Valentino, Andre Freitas

+ [Can Your Uncertainty Scores Detect Hallucinated Entity?](https://arxiv.org//abs/2502.11948)

	Min-Hsuan Yeh, Max Kamachee, Seongheon Park, Yixuan Li

+ [Table-Critic: A Multi-Agent Framework for Collaborative Criticism and Refinement in Table Reasoning](https://arxiv.org//abs/2502.11799)

	Peiying Yu, Guoxin Chen, Jingjing Wang

+ [From the New World of Word Embeddings: A Comparative Study of Small-World Lexico-Semantic Networks in LLMs](https://arxiv.org//abs/2502.11380)

	Zhu Liu, Ying Liu, KangYang Luo, Cunliang Kong, Maosong Sun

+ [Beyond Single-Task: Robust Multi-Task Length Generalization for LLMs](https://arxiv.org//abs/2502.11525)

	Yi Hu, Shijia Kang, Haotong Yang, Haotian Xu, Muhan Zhang

# 2025-02-16
+ [Leveraging Conditional Mutual Information to Improve Large Language Model Fine-Tuning For Classification](https://arxiv.org//abs/2502.11258)

	Thanushon Sivakaran, En-Hui Yang

+ [Safety Evaluation of DeepSeek Models in Chinese Contexts](https://arxiv.org//abs/2502.11137)

	Wenjing Zhang, Xuejiao Lei, Zhaoxiang Liu, Ning Wang, Zhenhong Long, Peijun Yang, Jiaojiao Zhao, Minjie Hua, Chaoyang Ma, Kai Wang, Shiguo Lian

+ [Investigating Language Preference of Multilingual RAG Systems](https://arxiv.org//abs/2502.11175)

	Jeonghyun Park, Hwanhee Lee

+ [RAS: Retrieval-And-Structuring for Knowledge-Intensive LLM Generation](https://arxiv.org//abs/2502.10996)

	Pengcheng Jiang, Lang Cao, Ruike Zhu, Minhao Jiang, Yunyi Zhang, Jimeng Sun, Jiawei Han

+ [The Mirage of Model Editing: Revisiting Evaluation in the Wild](https://arxiv.org//abs/2502.11177)

	Wanli Yang, Fei Sun, Jiajun Tan, Xinyu Ma, Qi Cao, Dawei Yin, Huawei Shen, Xueqi Cheng

# 2025-02-15
+ [D-CIPHER: Dynamic Collaborative Intelligent Multi-Agent System with Planner and Heterogeneous Executors for Offensive Security](https://arxiv.org//abs/2502.10931)

	Meet Udeshi, Minghao Shao, Haoran Xi, Nanda Rani, Kimberly Milner, Venkata Sai Charan Putrevu, Brendan Dolan-Gavitt, Sandeep Kumar Shukla, Prashanth Krishnamurthy, Farshad Khorrami, Ramesh Karri, Muhammad Shafique

# 2025-02-14
+ [Cooperative Multi-Agent Planning with Adaptive Skill Synthesis](https://arxiv.org//abs/2502.10148)

	Zhiyuan Li, Wenshuai Zhao, Joni Pajarinen

+ [MIR-Bench: Can Your LLM Recognize Complicated Patterns via Many-Shot In-Context Reasoning?](https://arxiv.org//abs/2502.09933)

	Kai Yan, Zhan Ling, Kang Liu, Yifan Yang, Ting-Han Fan, Lingfeng Shen, Zhengyin Du, Jiecao Chen

# 2025-02-13
+ [CRANE: Reasoning with constrained LLM generation](https://arxiv.org//abs/2502.09061)

	Debangshu Banerjee, Tarun Suresh, Shubham Ugare, Sasa Misailovic, Gagandeep Singh

# 2025-02-12
+ [k-LLMmeans: Scalable, Stable, and Interpretable Text Clustering via LLM-based Centroids](https://arxiv.org//abs/2502.09667)

	Jairo Diaz-Rodriguez

# 2025-02-11
+ [Time2Lang: Bridging Time-Series Foundation Models and Large Language Models for Health Sensing Beyond Prompting](https://arxiv.org//abs/2502.07608)

	Arvind Pillai, Dimitris Spathis, Subigya Nepal, Amanda C Collins, Daniel M Mackin, Michael V Heinz, Tess Z Griffin, Nicholas C Jacobson, Andrew Campbell

+ [Caught in the Web of Words: Do LLMs Fall for Spin in Medical Literature?](https://arxiv.org//abs/2502.07963)

	Hye Sun Yun, Karen Y.C. Zhang, Ramez Kouzy, Iain J. Marshall, Junyi Jessy Li, Byron C. Wallace

+ [Recursive Inference Scaling: A Winning Path to Scalable Inference in Language and Multimodal Systems](https://arxiv.org//abs/2502.07503)

	Ibrahim Alabdulmohsin, Xiaohua Zhai

+ [Principled Data Selection for Alignment: The Hidden Risks of Difficult Examples](https://arxiv.org//abs/2502.09650)

	Chengqian Gao, Haonan Li, Liu Liu, Zeke Xie, Peilin Zhao, Zhiqiang Xu

+ [Hallucination, Monofacts, and Miscalibration: An Empirical Investigation](https://arxiv.org//abs/2502.08666)

	Miranda Muqing Miao, Michael Kearns

+ [Mask-Enhanced Autoregressive Prediction: Pay Less Attention to Learn More](https://arxiv.org//abs/2502.07490)

	Xialie Zhuang, Zhikai Jia, Jianjin Li, Zhenyu Zhang, Li Shen, Zheng Cao, Shiwei Liu

# 2025-02-10
+ [Generating Privacy-Preserving Personalized Advice with Zero-Knowledge Proofs and LLMs](https://arxiv.org//abs/2502.06425)

	Hiroki Watanabe, Motonobu Uchikoshi


+ [Unbiased Evaluation of Large Language Models from a Causal Perspective](https://arxiv.org//abs/2502.06655)

	Meilin Chen, Jian Tian, Liang Ma, Di Xie, Weijie Chen, Jiang Zhu

+ [Is LLM an Overconfident Judge? Unveiling the Capabilities of LLMs in Detecting Offensive Language with Annotation Disagreement](https://arxiv.org//abs/2502.06207)

	Junyu Lu, Kai Ma, Kaichun Wang, Kelaiti Xiao, Roy Ka-Wei Lee, Bo Xu, Liang Yang, Hongfei Lin

+ [Who Taught You That? Tracing Teachers in Model Distillation](https://arxiv.org//abs/2502.06659)

	Somin Wadhwa, Chantal Shaib, Silvio Amir, Byron C. Wallace

# 2025-02-09
+ [HSI: Head-Specific Intervention Can Induce Misaligned AI Coordination in Large Language Models](https://arxiv.org//abs/2502.05945)

	Paul Darm, Annalisa Riccardi

# 2025-02-08
+ [Agentic AI Systems Applied to tasks in Financial Services: Modeling and model risk management crews](https://arxiv.org//abs/2502.05439)

	Izunna Okpala, Ashkan Golgoon, Arjun Ravi Kannan

+ [The Odyssey of the Fittest: Can Agents Survive and Still Be Good?](https://arxiv.org//abs/2502.05442)

	Dylan Waldner, Risto Miikkulainen

+ [Mix Data or Merge Models? Balancing the Helpfulness, Honesty, and Harmlessness of Large Language Model via Model Merging](https://arxiv.org//abs/2502.06876)

	Jinluan Yang, Dingnan Jin, Anke Tang, Li Shen, Didi Zhu, Zhengyu Chen, Ziyu Zhao, Daixin Wang, Qing Cui, Zhiqiang Zhang, Jun Zhou, Fei Wu, Kun Kuang

+ [Evolving LLMs' Self-Refinement Capability via Iterative Preference Optimization](https://arxiv.org//abs/2502.05605)

	Yongcheng Zeng, Xinyu Cui, Xuanfa Jin, Guoqing Liu, Zexu Sun, Dong Li, Ning Yang, Jianye Hao, Haifeng Zhang, Jun Wang

# 2025-02-07
+ [Probabilistic Subspace Manifolds for Contextual Inference in Large Language Models](https://arxiv.org//abs/2502.05346)

	Christopher Nightingale, Dominic Lavington, Jonathan Thistlethwaite, Sebastian Penhaligon, Thomas Belinski, David Boldo

+ [MELON: Provable Indirect Prompt Injection Defense via Masked Re-execution and Tool Comparison](https://arxiv.org//abs/2502.05174)

	Kaijie Zhu, Xianjun Yang, Jindong Wang, Wenbo Guo, William Yang Wang

+ [Unveiling the Mechanisms of Explicit CoT Training: How CoT Enhances Reasoning Generalization](https://arxiv.org//abs/2502.04667)

	Xinhao Yao, Ruifeng Ren, Yun Liao, Yong Liu

+ [Generating Symbolic World Models via Test-time Scaling of Large Language Models](https://arxiv.org//abs/2502.04728)

	Zhouliang Yu, Yuhuan Yuan, Tim Z. Xiao, Fuxiang Frank Xia, Jie Fu, Ge Zhang, Ge Lin, Weiyang Liu

+ [ARR: Question Answering with Large Language Models via Analyzing, Retrieving, and Reasoning](https://arxiv.org//abs/2502.04689)

	Yuwei Yin, Giuseppe Carenini

# 2025-02-06
+ [The Order Effect: Investigating Prompt Sensitivity to Input Order in LLMs](https://arxiv.org//abs/2502.04134)

	Bryan Guan, Tanya Roosta, Peyman Passban, Mehdi Rezagholizadeh

+ [SMI: An Information-Theoretic Metric for Predicting Model Knowledge Solely from Pre-Training Signals](https://arxiv.org//abs/2502.04066)

	Changhao Jiang, Ming Zhang, Junjie Ye, Xiaoran Fan, Yifei Cao, Jiajun Sun, Zhiheng Xi, Shihan Dou, Yi Dong, Yujiong Shen, Jingqi Tong, Zhen Wang, Tao Liang, Zhihui Fei, Mingyang Wan, Guojun Ma, Qi Zhang, Tao Gui, Xuanjing Huang

+ [FAS: Fast ANN-SNN Conversion for Spiking Large Language Models](https://arxiv.org//abs/2502.04405)

	Long Chen, Xiaotian Song, Andy Song, BaDong Chen, Jiancheng Lv, Yanan Sun

+ [Reformulation for Pretraining Data Augmentation](https://arxiv.org//abs/2502.04235)

	Xintong Hao, Ruijie Zhu, Ge Zhang, Ke Shen, Chenggang Li

# 2025-02-05
+ [Leveraging the true depth of LLMs](https://arxiv.org//abs/2502.02790)

	Ramón Calvo González, Daniele Paliotta, Matteo Pagliardini, Martin Jaggi, François Fleuret

+ [Large Language Model as Universal Retriever in Industrial-Scale Recommender System](https://arxiv.org//abs/2502.03041)

	Junguang Jiang, Yanwen Huang, Bin Liu, Xiaoyu Kong, Xinhang Li, Ziru Xu, Han Zhu, Jian Xu, Bo Zheng

# 2025-02-04
+ [CITER: Collaborative Inference for Efficient Large Language Model Decoding with Token-Level Routing](https://arxiv.org//abs/2502.01976)

	Wenhao Zheng, Yixiao Chen, Weitong Zhang, Souvik Kundu, Yun Li, Zhengzhong Liu, Eric P. Xing, Hongyi Wang, Huaxiu Yao

+ [Shuttle Between the Instructions and the Parameters of Large Language Models](https://arxiv.org//abs/2502.02315)

	Wangtao Sun, Haotian Xu, Huanxuan Liao, Xuanqing Yu, Zhongtao Jiang, Shizhu He, Jun Zhao, Kang Liu

+ [Generative Psycho-Lexical Approach for Constructing Value Systems in Large Language Models](https://arxiv.org//abs/2502.02444)

	Haoran Ye, Tianze Zhang, Yuhang Xie, Liyuan Zhang, Yuanyi Ren, Xin Zhang, Guojie Song

# 2025-02-03
+ [Efficient Model Editing with Task Vector Bases: A Theoretical Framework and Scalable Approach](https://arxiv.org//abs/2502.01015)

	Siqi Zeng, Yifei He, Weiqiu You, Yifan Hao, Yao-Hung Hubert Tsai, Makoto Yamada, Han Zhao


+ [Factual Knowledge in Language Models: Robustness and Anomalies under Simple Temporal Context Variations](https://arxiv.org//abs/2502.01220)

	Hichem Ammar Khodja, Frédéric Béchet, Quentin Brabant, Alexis Nasr, Gwénolé Lecorvé

+ [Efficient Model Editing with Task Vector Bases: A Theoretical Framework and Scalable Approach](https://arxiv.org//abs/2502.01015)

	Siqi Zeng, Yifei He, Weiqiu You, Yifan Hao, Yao-Hung Hubert Tsai, Makoto Yamada, Han Zhao

+ [Massive Values in Self-Attention Modules are the Key to Contextual Knowledge Understanding](https://arxiv.org//abs/2502.01563)

	Mingyu Jin, Kai Mei, Wujiang Xu, Mingjie Sun, Ruixiang Tang, Mengnan Du, Zirui Liu, Yongfeng Zhang

+ [SE Arena: An Interactive Platform for Evaluating Foundation Models in Software Engineering](https://arxiv.org//abs/2502.01860)

	Zhimin Zhao

+ [Firewalls to Secure Dynamic LLM Agentic Networks](https://arxiv.org//abs/2502.01822)

	Sahar Abdelnabi, Amr Gomaa, Per Ola Kristensson, Reza Shokri

+ [Joint Localization and Activation Editing for Low-Resource Fine-Tuning](https://arxiv.org//abs/2502.01179)

	Wen Lai, Alexander Fraser, Ivan Titov

+ [Scaling Embedding Layers in Language Models](https://arxiv.org//abs/2502.01637)

	Da Yu, Edith Cohen, Badih Ghazi, Yangsibo Huang, Pritish Kamath, Ravi Kumar, Daogao Liu, Chiyuan Zhang

+ [Explaining Context Length Scaling and Bounds for Language Models](https://arxiv.org//abs/2502.01481)

	Jingzhe Shi, Qinwei Ma, Hongyi Liu, Hang Zhao, Jeng-Neng Hwang, Lei Li

# 2025-02-02
+ [Vision-centric Token Compression in Large Language Model](https://arxiv.org//abs/2502.00791)

	Ling Xing, Alex Jinpeng Wang, Rui Yan, Xiangbo Shu, Jinhui Tang

+ [Disentangling Length Bias In Preference Learning Via Response-Conditioned Modeling](https://arxiv.org//abs/2502.00814)

	Jianfeng Cai, Jinhua Zhu, Ruopei Sun, Yue Wang, Li Li, Wengang Zhou, Houqiang Li

# 2025-02-01
+ [Explorations of the Softmax Space: Knowing When the Neural Network Doesn't Know](https://arxiv.org//abs/2502.00456)

	Daniel Sikar, Artur d'Avila Garcez, Tillman Weyde

+ [Estimating LLM Uncertainty with Logits](https://arxiv.org//abs/2502.00290)

	Huan Ma, Jingdong Chen, Joey Tianyi Zhou, Guangyu Wang, Changqing Zhang

+ [DUET: Optimizing Training Data Mixtures via Feedback from Unseen Evaluation Tasks](https://arxiv.org//abs/2502.00270)

	Zhiliang Chen, Gregory Kang Ruey Lau, Chuan-Sheng Foo, Bryan Kian Hsiang Low

# 2025-01-31
+ [Deep Learning Model Inversion Attacks and Defenses: A Comprehensive Survey](https://arxiv.org//abs/2501.18934)

	Wencheng Yang, Song Wang, Di Wu, Taotao Cai, Yanming Zhu, Shicheng Wei, Yiying Zhang, Xu Yang, Zhaohui Tang, Yan Li

+ [Towards the Worst-case Robustness of Large Language Models](https://arxiv.org//abs/2501.19040)

	Huanran Chen, Yinpeng Dong, Zeming Wei, Hang Su, Jun Zhu

+ [Federated Sketching LoRA: On-Device Collaborative Fine-Tuning of Large Language Models](https://arxiv.org//abs/2501.19389)

	Wenzhi Fang, Dong-Jun Han, Liangqi Yuan, Seyyedali Hosseinalipour, Christopher G. Brinton

# 2025-01-30
+ [Efficiency and Effectiveness of LLM-Based Summarization of Evidence in Crowdsourced Fact-Checking](https://arxiv.org//abs/2501.18265)

	Kevin Roitero, Dustin Wright, Michael Soprano, Isabelle Augenstein, Stefano Mizzaro

# 2025-01-29
+ [Large Language Models Think Too Fast To Explore Effectively](https://arxiv.org//abs/2501.18009)

	Lan Pan, Hanbo Xie, Robert C. Wilson

# 2025-01-28
+ [Instantiation-based Formalization of Logical Reasoning Tasks using Language Models and Logical Solvers](https://arxiv.org//abs/2501.16961)

	Mohammad Raza, Natasa Milic-Frayling

+ [RadioLLM: Introducing Large Language Model into Cognitive Radio via Hybrid Prompt and Token Reprogrammings](https://arxiv.org//abs/2501.17888)

	Shuai Chen, Yong Zu, Zhixi Feng, Shuyuan Yang, Mengchang Li

# 2025-01-27
+ [Are Transformers Able to Reason by Connecting Separated Knowledge in Training Data?](https://arxiv.org//abs/2501.15857)

	Yutong Yin, Zhaoran Wang


+ [Are Transformers Able to Reason by Connecting Separated Knowledge in Training Data?](https://arxiv.org//abs/2501.15857)

	Yutong Yin, Zhaoran Wang

+ [AdaCoT: Rethinking Cross-Lingual Factual Reasoning through Adaptive Chain-of-Thought](https://arxiv.org//abs/2501.16154)

	Xin Huang, Tarun Kumar Vangani, Zhengyuan Liu, Bowei Zou, Ai Ti Aw

+ [On the Feasibility of Using LLMs to Autonomously Execute Multi-host Network Attacks](https://arxiv.org//abs/2501.16466)

	Brian Singer, Keane Lucas, Lakshmi Adiga, Meghna Jain, Lujo Bauer, Vyas Sekar

# 2025-01-26
+ [TensorLLM: Tensorising Multi-Head Attention for Enhanced Reasoning and Compression in LLMs](https://arxiv.org//abs/2501.15674)

	Yuxuan Gu, Wuyang Zhou, Giorgos Iacovides, Danilo Mandic

# 2025-01-25
+ [Option-ID Based Elimination For Multiple Choice Questions](https://arxiv.org//abs/2501.15175)

	Zhenhao Zhu, Bulou Liu, Qingyao Ai, Yiqun Liu

# 2025-01-24
+ [Context-Aware Neural Gradient Mapping for Fine-Grained Instruction Processing](https://arxiv.org//abs/2501.14936)

	David Boldo, Lily Pemberton, Gabriel Thistledown, Jacob Fairchild, Felix Kowalski


+ [Prompt-Based Cost-Effective Evaluation and Operation of ChatGPT as a Computer Programming Teaching Assistant](https://arxiv.org//abs/2501.17176)

	Marc Ballestero-Ribó, Daniel Ortiz-Martínez

+ [Self-reflecting Large Language Models: A Hegelian Dialectical Approach](https://arxiv.org//abs/2501.14917)

	Sara Abdali, Can Goksen, Saeed Amizadeh, Julie E. Maybee, Kazuhito Koishida

+ [JustLogic: A Comprehensive Benchmark for Evaluating Deductive Reasoning in Large Language Models](https://arxiv.org//abs/2501.14851)

	Michael K. Chen, Xikun Zhang, Dacheng Tao

+ [SwiftPrune: Hessian-Free Weight Pruning for Large Language Models](https://arxiv.org//abs/2501.16376)

	Yuhan Kang, Yang Shi, Mei We, Jun He, Jianchao Yang, Zeyu Xue, Jing Feng, Xinwang Liu

# 2025-01-23
+ [GraphRAG under Fire](https://arxiv.org//abs/2501.14050)

	Jiacheng Liang, Yuhui Wang, Changjiang Li, Rongyi Zhu, Tanqiu Jiang, Neil Gong, Ting Wang


+ [A Cognitive Paradigm Approach to Probe the Perception-Reasoning Interface in VLMs](https://arxiv.org//abs/2501.13620)

	Mohit Vaishnav, Tanel Tammet

+ [Communicating Activations Between Language Model Agents](https://arxiv.org//abs/2501.14082)

	Vignav Ramesh, Kenneth Li

+ [Softplus Attention with Re-weighting Boosts Length Extrapolation in Large Language Models](https://arxiv.org//abs/2501.13428)

	Bo Gao, Michael W. Spratling

+ [Re-ranking Using Large Language Models for Mitigating Exposure to Harmful Content on Social Media Platforms](https://arxiv.org//abs/2501.13977)

	Rajvardhan Oak, Muhammad Haroon, Claire Jo, Magdalena Wojcieszak, Anshuman Chhabra

# 2025-01-21
+ [Test-time regression: a unifying framework for designing sequence models with associative memory](https://arxiv.org//abs/2501.12352)

	Ke Alexander Wang, Jiaxin Shi, Emily B. Fox

+ [Med-R$^2$: Crafting Trustworthy LLM Physicians via Retrieval and Reasoning of Evidence-Based Medicine](https://arxiv.org//abs/2501.11885)

	Keer Lu, Zheng Liang, Zhuoran Zhang, Da Pan, Shusen Zhang, Xin Wu, Zenan Zhou, Guosheng Dong, Bin Cui, Tengjiao Wang, Wentao Zhang

+ [AdaServe: Accelerating Multi-SLO LLM Serving with SLO-Customized Speculative Decoding](https://arxiv.org//abs/2501.12162)

	Zikun Li, Zhuofu Chen, Remi Delacourt, Gabriele Oliaro, Zeyu Wang, Qinghan Chen, Shuhuai Lin, April Yang, Zhihao Zhang, Zhuoming Chen, Sean Lai, Xinhao Cheng, Xupeng Miao, Zhihao Jia

# 2025-01-19
+ [A Comprehensive Survey on Integrating Large Language Models with Knowledge-Based Methods](https://arxiv.org//abs/2501.13947)

	Wenli Yang, Lilian Some, Michael Bain, Byeong Kang

+ [Chain-of-Reasoning: Towards Unified Mathematical Reasoning in Large Language Models via a Multi-Paradigm Perspective](https://arxiv.org//abs/2501.11110)

	Yiyao Yu, Yuxiang Zhang, Dongdong Zhang, Xiao Liang, Hengyuan Zhang, Xingxing Zhang, Mahmoud Khademi, Hany Awadalla, Junjie Wang, Yujiu Yang, Furu Wei

# 2025-01-17
+ [Know Your Mistakes: Towards Preventing Overreliance on Task-Oriented Conversational AI Through Accountability Modeling](https://arxiv.org//abs/2501.10316)

	Suvodip Dey, Yi-Jyun Sun, Gokhan Tur, Dilek Hakkani-Tur

# 2025-01-10
+ [Dynamics of Spontaneous Topic Changes in Next Token Prediction with Self-Attention](https://arxiv.org//abs/2501.06382)

	Mumin Jia, Jairo Diaz-Rodriguez

# 2025-01-09
+ [CallNavi, A Challenge and Empirical Study on LLM Function Calling and Routing](https://arxiv.org//abs/2501.05255)

	Yewei Song, Xunzhu Tang, Cedric Lothritz, Saad Ezzini, Jacques Klein, Tegawendé F. Bissyandé, Andrey Boytsov, Ulrick Ble, Anne Goujon


+ [SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution](https://arxiv.org//abs/2501.05040)

	Chengxing Xie, Bowen Li, Chang Gao, He Du, Wai Lam, Difan Zou, Kai Chen

+ [TreeKV: Smooth Key-Value Cache Compression with Tree Structures](https://arxiv.org//abs/2501.04987)

	Ziwei He, Jian Yuan, Haoli Bai, Jingwen Leng, Bo Jiang

# 2025-01-05
+ [Towards the Anonymization of the Language Modeling](https://arxiv.org//abs/2501.02407)

	Antoine Boutet, Lucas Magnana, Juliette Sénéchal, Helain Zimmermann

+ [Scaling Laws for Floating Point Quantization Training](https://arxiv.org//abs/2501.02423)

	Xingwu Sun, Shuaipeng Li, Ruobing Xie, Weidong Han, Kan Wu, Zhen Yang, Yixing Li, An Wang, Shuai Li, Jinbao Xue, Yu Cheng, Yangyu Tao, Zhanhui Kang, Chengzhong Xu, Di Wang, Jie Jiang

+ [ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use](https://arxiv.org//abs/2501.02506)

	Junjie Ye, Zhengyin Du, Xuesong Yao, Weijian Lin, Yufei Xu, Zehui Chen, Zaiyuan Wang, Sining Zhu, Zhiheng Xi, Siyu Yuan, Tao Gui, Qi Zhang, Xuanjing Huang, Jiecao Chen

# 2025-01-04
+ [Zero-Shot Statistical Tests for LLM-Generated Text Detection using Finite Sample Concentration Inequalities](https://arxiv.org//abs/2501.02406)

	Tara Radvand, Mojtaba Abdolmaleki, Mohamed Mostagir, Ambuj Tewari

+ [LLM Content Moderation and User Satisfaction: Evidence from Response Refusals in Chatbot Arena](https://arxiv.org//abs/2501.03266)

	Stefan Pasch

# 2025-01-03
+ [MIRAGE: Exploring How Large Language Models Perform in Complex Social Interactive Environments](https://arxiv.org//abs/2501.01652)

	Yin Cai, Zhouhong Gu, Zhaohan Du, Zheyu Ye, Shaosheng Cao, Yiqian Xu, Hongwei Feng, Ping Chen

# 2025-01-02
+ [ValuesRAG: Enhancing Cultural Alignment Through Retrieval-Augmented Contextual Learning](https://arxiv.org//abs/2501.01031)

	Wonduk Seo, Zonghao Yuan, Yi Bu

# 2025-01-01
+ [LUSIFER: Language Universal Space Integration for Enhanced Multilingual Embeddings with Large Language Models](https://arxiv.org//abs/2501.00874)

	Hieu Man, Nghia Trung Ngo, Viet Dac Lai, Ryan A. Rossi, Franck Dernoncourt, Thien Huu Nguyen

+ [FitCF: A Framework for Automatic Feature Importance-guided Counterfactual Example Generation](https://arxiv.org//abs/2501.00777)

	Qianli Wang, Nils Feldhus, Simon Ostermann, Luis Felipe Villa-Arenas, Sebastian Möller, Vera Schmitt

# 2024-12-30
+ [ExpShield: Safeguarding Web Text from Unauthorized Crawling and Language Modeling Exploitation](https://arxiv.org//abs/2412.21123)

	Ruixuan Liu, Toan Tran, Tianhao Wang, Hongsheng Hu, Shuo Wang, Li Xiong

# 2024-12-29
+ [ICLR: In-Context Learning of Representations](https://arxiv.org//abs/2501.00070)

	Core Francisco Park, Andrew Lee, Ekdeep Singh Lubana, Yongyi Yang, Maya Okawa, Kento Nishi, Martin Wattenberg, Hidenori Tanaka

+ [Understanding the Impact of Confidence in Retrieval Augmented Generation: A Case Study in the Medical Domain](https://arxiv.org//abs/2412.20309)

	Shintaro Ozaki, Yuta Kato, Siyuan Feng, Masayo Tomita, Kazuki Hayashi, Wataru Hashimoto, Ryoma Obara, Masafumi Oyamada, Katsuhiko Hayashi, Hidetaka Kamigaito, Taro Watanabe

# 2024-12-28
+ [No Preference Left Behind: Group Distributional Preference Optimization](https://arxiv.org//abs/2412.20299)

	Binwei Yao, Zefan Cai, Yun-Shiuan Chuang, Shanglin Yang, Ming Jiang, Diyi Yang, Junjie Hu

# 2024-12-24
+ [LSAQ: Layer-Specific Adaptive Quantization for Large Language Model Deployment](https://arxiv.org//abs/2412.18135)

	Binrui Zeng, Bin Ji, Xiaodong Liu, Jie Yu, Shasha Li, Jun Ma, Xiaopeng Li, Shangwen Wang, Xinran Hong, Yongtao Tang

+ [KunServe: Parameter-centric Memory Management for Efficient Memory Throttling Handling in LLM Serving](https://arxiv.org//abs/2412.18169)

	Rongxin Cheng, Yuxin Lai, Xingda Wei, Rong Chen, Haibo Chen

# 2024-12-23
+ [Fourier Position Embedding: Enhancing Attention's Periodic Extension for Length Generalization](https://arxiv.org//abs/2412.17739)

	Ermo Hua, Che Jiang, Xingtai Lv, Kaiyan Zhang, Ning Ding, Youbang Sun, Biqing Qi, Yuchen Fan, Xuekai Zhu, Bowen Zhou

# 2024-12-22
+ [Multi-Agent Sampling: Scaling Inference Compute for Data Synthesis with Tree Search-Based Agentic Collaboration](https://arxiv.org//abs/2412.17061)

	Hai Ye, Mingbao Lin, Hwee Tou Ng, Shuicheng Yan

# 2024-12-21
+ [Beyond Partisan Leaning: A Comparative Analysis of Political Bias in Large Language Models](https://arxiv.org//abs/2412.16746)

	Tai-Quan Peng, Kaiqi Yang, Sanguk Lee, Hang Li, Yucheng Chu, Yuping Lin, Hui Liu

# 2024-12-20
+ [Less is More: Towards Green Code Large Language Models via Unified Structural Pruning](https://arxiv.org//abs/2412.15921)

	Guang Yang, Yu Zhou, Xiangyu Zhang, Wei Cheng, Ke Liu, Xiang Chen, Terry Yue Zhuo, Taolue Chen


+ [XRAG: eXamining the Core -- Benchmarking Foundational Components in Advanced Retrieval-Augmented Generation](https://arxiv.org//abs/2412.15529)

	Qianren Mao, Yangyifei Luo, Qili Zhang, Yashuo Luo, Zhilong Cao, Jinlong Zhang, HanWen Hao, Zhijun Chen, Weifeng Jiang, Junnan Liu, Xiaolong Wang, Zhenting Huang, Zhixing Tan, Sun Jie, Bo Li, Xudong Liu, Richong Zhang, Jianxin Li

# 2024-12-19
+ [A Retrieval-Augmented Generation Framework for Academic Literature Navigation in Data Science](https://arxiv.org//abs/2412.15404)

	Ahmet Yasin Aytar, Kemal Kilic, Kamer Kaya

# 2024-12-17
+ [What External Knowledge is Preferred by LLMs? Characterizing and Exploring Chain of Evidence in Imperfect Context](https://arxiv.org//abs/2412.12632)

	Zhiyuan Chang, Mingyang Li, Xiaojun Jia, Junjie Wang, Yuekai Huang, Qing Wang, Yihao Huang, Yang Liu

+ [When to Speak, When to Abstain: Contrastive Decoding with Abstention](https://arxiv.org//abs/2412.12527)

	Hyuhng Joon Kim, Youna Kim, Sang-goo Lee, Taeuk Kim

+ [DateLogicQA: Benchmarking Temporal Biases in Large Language Models](https://arxiv.org//abs/2412.13377)

	Gagan Bhatia, MingZe Tang, Cristina Mahanta, Madiha Kazi

# 2024-12-16
+ [ElChat: Adapting Chat Language Models Using Only Target Unlabeled Language Data](https://arxiv.org//abs/2412.11704)

	Atsuki Yamaguchi, Terufumi Morishita, Aline Villavicencio, Nikolaos Aletras

# 2024-12-15
+ [AD-LLM: Benchmarking Large Language Models for Anomaly Detection](https://arxiv.org//abs/2412.11142)

	Tiankai Yang, Yi Nian, Shawn Li, Ruiyao Xu, Yuangang Li, Jiaqi Li, Zhuo Xiao, Xiyang Hu, Ryan Rossi, Kaize Ding, Xia Hu, Yue Zhao

+ [SceneLLM: Implicit Language Reasoning in LLM for Dynamic Scene Graph Generation](https://arxiv.org//abs/2412.11026)

	Hang Zhang, Zhuoling Li, Jun Liu

# 2024-12-14
+ [Superhuman performance of a large language model on the reasoning tasks of a physician](https://arxiv.org//abs/2412.10849)

	Peter G. Brodeur, Thomas A. Buckley, Zahir Kanjee, Ethan Goh, Evelyn Bin Ling, Priyank Jain, Stephanie Cabral, Raja-Elie Abdulnour, Adrian D. Haimovich, Jason A. Freed, Andrew Olson, Daniel J. Morgan, Jason Hom, Robert Gallo, Liam G. McCoy, Haadi Mombini, Christopher Lucas, Misha Fotoohi, Matthew Gwiazdon, Daniele Restifo, Daniel Restrepo, Eric Horvitz, Jonathan Chen, Arjun K. Manrai, Adam Rodman

# 2024-12-13
+ [You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary Projects](https://arxiv.org//abs/2412.10133)

	Islem Bouzenia, Michael Pradel

# 2024-12-10
+ [A Causal World Model Underlying Next Token Prediction: Exploring GPT in a Controlled Environment](https://arxiv.org//abs/2412.07446)

	Raanan Y. Rohekar, Yaniv Gurwicz, Sungduk Yu, Estelle Aflalo, Vasudev Lal

+ [AutoPrep: Natural Language Question-Aware Data Preparation with a Multi-Agent Framework](https://arxiv.org//abs/2412.10422)

	Meihao Fan, Ju Fan, Nan Tang, Lei Cao, Guoliang Li, Xiaoyong Du

# 2024-12-09
+ [MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization](https://arxiv.org//abs/2412.06141)

	Kangyu Zhu, Peng Xia, Yun Li, Hongtu Zhu, Sheng Wang, Huaxiu Yao

# 2024-12-07
+ [SLA Management in Reconfigurable Multi-Agent RAG: A Systems Approach to Question Answering](https://arxiv.org//abs/2412.06832)

	Michael Iannelli, Sneha Kuchipudi, Vera Dvorak

+ [KG-Retriever: Efficient Knowledge Indexing for Retrieval-Augmented Large Language Models](https://arxiv.org//abs/2412.05547)

	Weijie Chen, Ting Bai, Jinbo Su, Jian Luan, Wei Liu, Chuan Shi

+ [Training-Free Bayesianization for Low-Rank Adapters of Large Language Models](https://arxiv.org//abs/2412.05723)

	Haizhou Shi, Yibin Wang, Ligong Han, Huan Zhang, Hao Wang

# 2024-12-06
+ [Multi-Party Supervised Fine-tuning of Language Models for Multi-Party Dialogue Generation](https://arxiv.org//abs/2412.05342)

	Xiaoyu Wang, Ningyuan Xi, Teng Chen, Qingqing Gu, Yue Zhao, Xiaokai Chen, Zhonglin Jiang, Yong Chen, Luo Ji

# 2024-12-03
+ [Enhancing LLMs with Smart Preprocessing for EHR Analysis](https://arxiv.org//abs/2412.02868)

	Yixiang Qu, Yifan Dai, Shilin Yu, Pradham Tanikella, Travis Schrank, Trevor Hackman, Didong Li, Di Wu


+ [DP-2Stage: Adapting Language Models as Differentially Private Tabular Data Generators](https://arxiv.org//abs/2412.02467)

	Tejumade Afonja, Hui-Po Wang, Raouf Kerkouche, Mario Fritz

# 2024-12-02
+ [Mastering Board Games by External and Internal Planning with Language Models](https://arxiv.org//abs/2412.12119)

	John Schultz, Jakub Adamek, Matej Jusup, Marc Lanctot, Michael Kaisers, Sarah Perrin, Daniel Hennes, Jeremy Shar, Cannada Lewis, Anian Ruoss, Tom Zahavy, Petar Veličković, Laurel Prince, Satinder Singh, Eric Malmi, Nenad Tomašev

+ [FastRM: An efficient and automatic explainability framework for multimodal generative models](https://arxiv.org//abs/2412.01487)

	Gabriela Ben-Melech Stan, Estelle Aflalo, Man Luo, Shachar Rosenman, Tiep Le, Sayak Paul, Shao-Yen Tseng, Vasudev Lal

+ [Beyond Text-Visual Attention: Exploiting Visual Cues for Effective Token Pruning in VLMs](https://arxiv.org//abs/2412.01818)

	Qizhe Zhang, Aosong Cheng, Ming Lu, Renrui Zhang, Zhiyong Zhuo, Jiajun Cao, Shaobo Guo, Qi She, Shanghang Zhang

# 2024-12-01
+ [Competition Dynamics Shape Algorithmic Phases of In-Context Learning](https://arxiv.org//abs/2412.01003)

	Core Francisco Park, Ekdeep Singh Lubana, Itamar Pres, Hidenori Tanaka

# 2024-11-29
+ [Simple and Provable Scaling Laws for the Test-Time Compute of Large Language Models](https://arxiv.org//abs/2411.19477)

	Yanxi Chen, Xuchen Pan, Yaliang Li, Bolin Ding, Jingren Zhou

+ [VLSBench: Unveiling Visual Leakage in Multimodal Safety](https://arxiv.org//abs/2411.19939)

	Xuhao Hu, Dongrui Liu, Hao Li, Xuanjing Huang, Jing Shao

# 2024-11-28
+ [Personalized Federated Fine-Tuning for LLMs via Data-Driven Heterogeneous Model Architectures](https://arxiv.org//abs/2411.19128)

	Yicheng Zhang, Zhen Qin, Zhaomin Wu, Jian Hou, Shuiguang Deng

# 2024-11-26
+ [ThreatModeling-LLM: Automating Threat Modeling using Large Language Models for Banking System](https://arxiv.org//abs/2411.17058)

	Tingmin Wu, Shuiqiao Yang, Shigang Liu, David Nguyen, Seung Jang, Alsharif Abuadbba

+ [Not All Adapters Matter: Selective Adapter Freezing for Memory-Efficient Fine-Tuning of Language Models](https://arxiv.org//abs/2412.03587)

	Hyegang Son, Yonglak Son, Changhoon Kim, Young Geun Kim

# 2024-11-22
+ [XGrammar: Flexible and Efficient Structured Generation Engine for Large Language Models](https://arxiv.org//abs/2411.15100)

	Yixin Dong, Charlie F. Ruan, Yaxing Cai, Ruihang Lai, Ziyi Xu, Yilong Zhao, Tianqi Chen

+ [KBAlign: Efficient Self Adaptation on Specific Knowledge Bases](https://arxiv.org//abs/2411.14790)

	Zheni Zeng, Yuxuan Chen, Shi Yu, Ruobing Wang, Yukun Yan, Zhenghao Liu, Shuo Wang, Xu Han, Zhiyuan Liu, Maosong Sun

# 2024-11-21
+ [Insight-V: Exploring Long-Chain Visual Reasoning with Multimodal Large Language Models](https://arxiv.org//abs/2411.14432)

	Yuhao Dong, Zuyan Liu, Hai-Long Sun, Jingkang Yang, Winston Hu, Yongming Rao, Ziwei Liu

+ [Enhancing LLMs for Power System Simulations: A Feedback-driven Multi-agent Framework](https://arxiv.org//abs/2411.16707)

	Mengshuo Jia, Zeyu Cui, Gabriela Hug

# 2024-11-20
+ [Disentangling Memory and Reasoning Ability in Large Language Models](https://arxiv.org//abs/2411.13504)

	Mingyu Jin, Weidi Luo, Sitao Cheng, Xinyi Wang, Wenyue Hua, Ruixiang Tang, William Yang Wang, Yongfeng Zhang

# 2024-11-19
+ [The Moral Mind(s) of Large Language Models](https://arxiv.org//abs/2412.04476)

	Avner Seror

# 2024-11-18
+ [PEEK: Phishing Evolution Framework for Phishing Generation and Evolving Pattern Analysis using Large Language Models](https://arxiv.org//abs/2411.11389)

	Fengchao Chen, Tingmin Wu, Van Nguyen, Shuo Wang, Alsharif Abuadbba, Carsten Rudolph

+ [PSPO*: An Effective Process-supervised Policy Optimization for Reasoning Alignment](https://arxiv.org//abs/2411.11681)

	Jiawei Li, Xinyue Liang, Junlong Zhang, Yizhe Yang, Chong Feng, Yang Gao

+ [VersaTune: An Efficient Data Composition Framework for Training Multi-Capability LLMs](https://arxiv.org//abs/2411.11266)

	Keer Lu, Keshi Zhao, Zhuoran Zhang, Zheng Liang, Da Pan, Shusen Zhang, Xin Wu, Guosheng Dong, Bin Cui, Tengjiao Wang, Wentao Zhang

# 2024-11-17
+ [JailbreakLens: Interpreting Jailbreak Mechanism in the Lens of Representation and Circuit](https://arxiv.org//abs/2411.11114)

	Zeqing He, Zhibo Wang, Zhixuan Chu, Huiyu Xu, Wenhui Zhang, Qinglong Wang, Rui Zheng


+ [SRA-MCTS: Self-driven Reasoning Augmentation with Monte Carlo Tree Search for Code Generation](https://arxiv.org//abs/2411.11053)

	Bin Xu, Yiguan Lin, Yinghao Li, Yang Gao

# 2024-11-14
+ [Rethinking Weight-Averaged Model-merging](https://arxiv.org//abs/2411.09263)

	Hu Wang, Congbo Ma, Ibrahim Almakky, Ian Reid, Gustavo Carneiro, Mohammad Yaqub

# 2024-11-12
+ [Knowledge-Augmented Multimodal Clinical Rationale Generation for Disease Diagnosis with Small Language Models](https://arxiv.org//abs/2411.07611)

	Shuai Niu, Jing Ma, Hongzhan Lin, Liang Bai, Zhihua Wang, Yida Xu, Yunya Song, Xian Yang

+ [Beyond the Safety Bundle: Auditing the Helpful and Harmless Dataset](https://arxiv.org//abs/2411.08243)

	Khaoula Chehbouni, Jonathan Colaço Carr, Yash More, Jackie CK Cheung, Golnoosh Farnadi

+ [Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for Knowledge Graph Completion](https://arxiv.org//abs/2411.08165)

	Muzhi Li, Cehao Yang, Chengjin Xu, Xuhui Jiang, Yiyan Qi, Jian Guo, Ho-fung Leung, Irwin King

+ [ImageRAG: Enhancing Ultra High Resolution Remote Sensing Imagery Analysis with ImageRAG](https://arxiv.org//abs/2411.07688)

	Zilun Zhang, Haozhan Shen, Tiancheng Zhao, Zian Guan, Bin Chen, Yuhao Wang, Xu Jia, Yuxiang Cai, Yongheng Shang, Jianwei Yin

# 2024-11-10
+ [An Efficient Matrix Multiplication Algorithm for Accelerating Inference in Binary and Ternary Neural Networks](https://arxiv.org//abs/2411.06360)

	Mohsen Dehghankar, Mahdi Erfanian, Abolfazl Asudeh

# 2024-11-09
+ [A Picture is Worth A Thousand Numbers: Enabling LLMs Reason about Time Series via Visualization](https://arxiv.org//abs/2411.06018)

	Haoxin Liu, Chenghao Liu, B. Aditya Prakash

# 2024-11-08
+ [LLM-PySC2: Starcraft II learning environment for Large Language Models](https://arxiv.org//abs/2411.05348)

	Zongyuan Li, Yanan Ni, Runnan Qi, Lumin Jiang, Chang Lu, Xiaojie Xu, Xiangbei Liu, Pengfei Li, Yunzheng Guo, Zhe Ma, Huanyu Li, Hui Wu, Xian Guo, Kuihua Huang, Xuebo Zhang

# 2024-11-06
+ [LSHBloom: Memory-efficient, Extreme-scale Document Deduplication](https://arxiv.org//abs/2411.04257)

	Arham Khan, Robert Underwood, Carlo Siebenschuh, Yadu Babuji, Aswathy Ajith, Kyle Hippe, Ozan Gokdemir, Alexander Brace, Kyle Chard, Ian Foster

# 2024-11-04
+ [Sparsing Law: Towards Large Language Models with Greater Activation Sparsity](https://arxiv.org//abs/2411.02335)

	Yuqi Luo, Chenyang Song, Xu Han, Yingfa Chen, Chaojun Xiao, Zhiyuan Liu, Maosong Sun

# 2024-11-03
+ [Enhancing LLM Evaluations: The Garbling Trick](https://arxiv.org//abs/2411.01533)

	William F. Bradley

# 2024-11-01
+ [E2E-AFG: An End-to-End Model with Adaptive Filtering for Retrieval-Augmented Generation](https://arxiv.org//abs/2411.00437)

	Yun Jiang, Zilong Xie, Wei Zhang, Yun Fang, Shuai Pan

+ [Phase Diagram of Vision Large Language Models Inference: A Perspective from Interaction across Image and Instruction](https://arxiv.org//abs/2411.00646)

	Houjing Wei, Yuting Shi, Naoya Inoue

# 2024-10-31
+ [AlphaTrans: A Neuro-Symbolic Compositional Approach for Repository-Level Code Translation and Validation](https://arxiv.org//abs/2410.24117)

	Ali Reza Ibrahimzada, Kaiyao Ke, Mrigank Pawagi, Muhammad Salman Abid, Rangeet Pan, Saurabh Sinha, Reyhaneh Jabbarvand

+ [Constraint Back-translation Improves Complex Instruction Following of Large Language Models](https://arxiv.org//abs/2410.24175)

	Yunjia Qi, Hao Peng, Xiaozhi Wang, Bin Xu, Lei Hou, Juanzi Li

# 2024-10-30
+ [MDCure: A Scalable Pipeline for Multi-Document Instruction-Following](https://arxiv.org//abs/2410.23463)

	Gabrielle Kaili-May Liu, Bowen Shi, Avi Caciularu, Idan Szpektor, Arman Cohan

# 2024-10-29
+ [Personalization of Large Language Models: A Survey](https://arxiv.org//abs/2411.00027)

	Zhehao Zhang, Ryan A. Rossi, Branislav Kveton, Yijia Shao, Diyi Yang, Hamed Zamani, Franck Dernoncourt, Joe Barrow, Tong Yu, Sungchul Kim, Ruiyi Zhang, Jiuxiang Gu, Tyler Derr, Hongjie Chen, Junda Wu, Xiang Chen, Zichao Wang, Subrata Mitra, Nedim Lipka, Nesreen Ahmed, Yu Wang

+ [Unlearning as multi-task optimization: A normalized gradient difference approach with an adaptive learning rate](https://arxiv.org//abs/2410.22086)

	Zhiqi Bu, Xiaomeng Jin, Bhanukiran Vinzamuri, Anil Ramakrishna, Kai-Wei Chang, Volkan Cevher, Mingyi Hong

+ [Vision-Language Models Create Cross-Modal Task Representations](https://arxiv.org//abs/2410.22330)

	Grace Luo, Trevor Darrell, Amir Bar

+ [SceneGenAgent: Precise Industrial Scene Generation with Coding Agent](https://arxiv.org//abs/2410.21909)

	Xiao Xia, Dan Zhang, Zibo Liao, Zhenyu Hou, Tianrui Sun, Jing Li, Ling Fu, Yuxiao Dong

# 2024-10-28
+ [Are LLM-Judges Robust to Expressions of Uncertainty? Investigating the effect of Epistemic Markers on LLM-based Evaluation](https://arxiv.org//abs/2410.20774)

	Dongryeol Lee, Yerin Hwang, Yongil Kim, Joonsuk Park, Kyomin Jung

# 2024-10-26
+ [Agentic Feedback Loop Modeling Improves Recommendation and User Simulation](https://arxiv.org//abs/2410.20027)

	Shihao Cai, Jizhi Zhang, Keqin Bao, Chongming Gao, Qifan Wang, Fuli Feng, Xiangnan He

# 2024-10-25
+ [Can We Trust AI Agents? A Case Study of an LLM-Based Multi-Agent System for Ethical AI](https://arxiv.org//abs/2411.08881)

	José Antonio Siqueira de Cerqueira, Mamia Agbese, Rebekah Rousi, Nannan Xi, Juho Hamari, Pekka Abrahamsson

+ [ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Contrastive Framework](https://arxiv.org//abs/2410.19453)

	Hengyuan Zhang, Chenming Shang, Sizhe Wang, Dongdong Zhang, Feng Yao, Renliang Sun, Yiyao Yu, Yujiu Yang, Furu Wei

# 2024-10-24
+ [Parameter-Efficient Fine-Tuning in Large Models: A Survey of Methodologies](https://arxiv.org//abs/2410.19878)

	Luping Wang, Sheng Chen, Linnan Jiang, Shu Pan, Runze Cai, Sen Yang, Fei Yang

# 2024-10-21
+ [Long Term Memory: The Foundation of AI Self-Evolution](https://arxiv.org//abs/2410.15665)

	Xun Jiang, Feng Li, Han Zhao, Jiahao Qiu, Jiaying Wang, Jun Shao, Shihao Xu, Shu Zhang, Weiling Chen, Xavier Tang, Yize Chen, Mengyue Wu, Weizhi Ma, Mengdi Wang, Tianqiao Chen

+ [Training of Scaffolded Language Models with Language Supervision: A Survey](https://arxiv.org//abs/2410.16392)

	Matthieu Lin, Jenny Sheng, Andrew Zhao, Shenzhi Wang, Yang Yue, Victor Shea Jay Huang, Huan Liu, Jun Liu, Gao Huang, Yong-Jin Liu

+ [Security of Language Models for Code: A Systematic Literature Review](https://arxiv.org//abs/2410.15631)

	Yuchen Chen, Weisong Sun, Chunrong Fang, Zhenpeng Chen, Yifei Ge, Tingxu Han, Quanjun Zhang, Yang Liu, Zhenyu Chen, Baowen Xu

# 2024-10-18
+ [ELOQ: Resources for Enhancing LLM Detection of Out-of-Scope Questions](https://arxiv.org//abs/2410.14567)

	Zhiyuan Peng, Jinming Nian, Alexandre Evfimievski, Yi Fang

+ [Electrocardiogram-Language Model for Few-Shot Question Answering with Meta Learning](https://arxiv.org//abs/2410.14464)

	Jialu Tang, Tong Xia, Yuan Lu, Cecilia Mascolo, Aaqib Saeed

+ [DiSCo: LLM Knowledge Distillation for Efficient Sparse Retrieval in Conversational Search](https://arxiv.org//abs/2410.14609)

	Simon Lupart, Mohammad Aliannejadi, Evangelos Kanoulas

# 2024-10-17
+ [MobA: Multifaceted Memory-Enhanced Adaptive Planning for Efficient Mobile Task Automation](https://arxiv.org//abs/2410.13757)

	Zichen Zhu, Hao Tang, Yansi Li, Dingye Liu, Hongshen Xu, Kunyao Lan, Danyang Zhang, Yixuan Jiang, Hao Zhou, Chenrun Wang, Situo Zhang, Liangtai Sun, Yixiao Wang, Yuheng Sun, Lu Chen, Kai Yu

+ [How Does Knowledge Selection Help Retrieval Augmented Generation?](https://arxiv.org//abs/2410.13258)

	Xiangci Li, Jessica Ouyang

# 2024-10-16
+ [TradExpert: Revolutionizing Trading with Mixture of Expert LLMs](https://arxiv.org//abs/2411.00782)

	Qianggang Ding, Haochen Shi, Jiadong Guo, Bang Liu

+ [MatryoshkaKV: Adaptive KV Compression via Trainable Orthogonal Projection](https://arxiv.org//abs/2410.14731)

	Bokai Lin, Zihao Zeng, Zipeng Xiao, Siqi Kou, Tianqi Hou, Xiaofeng Gao, Hao Zhang, Zhijie Deng

# 2024-10-15
+ [MIND: Math Informed syNthetic Dialogues for Pretraining LLMs](https://arxiv.org//abs/2410.12881)

	Syeda Nahida Akter, Shrimai Prabhumoye, John Kamalu, Sanjeev Satheesh, Eric Nyberg, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro

+ [TopoLM: brain-like spatio-functional organization in a topographic language model](https://arxiv.org//abs/2410.11516)

	Neil Rathi, Johannes Mehrer, Badr AlKhamissi, Taha Binhuraib, Nicholas M. Blauch, Martin Schrimpf

+ [TestAgent: A Framework for Domain-Adaptive Evaluation of LLMs via Dynamic Benchmark Construction and Exploratory Interaction](https://arxiv.org//abs/2410.11507)

	Wanying Wang, Zeyu Ma, Pengfei Liu, Mingang Chen

# 2024-10-13
+ [Self-Data Distillation for Recovering Quality in Pruned Large Language Models](https://arxiv.org//abs/2410.09982)

	Vithursan Thangarasa, Ganesh Venkatesh, Mike Lasby, Nish Sinnadurai, Sean Lie

# 2024-10-12
+ [Inference and Verbalization Functions During In-Context Learning](https://arxiv.org//abs/2410.09349)

	Junyi Tao, Xiaoyin Chen, Nelson F. Liu

# 2024-10-10
+ [Extracting and Transferring Abilities For Building Multi-lingual Ability-enhanced Large Language Models](https://arxiv.org//abs/2410.07825)

	Zhipeng Chen, Kun Zhou, Liang Song, Wayne Xin Zhao, Bingning Wang, Weipeng Chen, Ji-Rong Wen

# 2024-10-09
+ [Let's Ask GNN: Empowering Large Language Model for Graph In-Context Learning](https://arxiv.org//abs/2410.07074)

	Zhengyu Hu, Yichuan Li, Zhengyu Chen, Jingang Wang, Han Liu, Kyumin Lee, Kaize Ding

+ [Steering Large Language Models using Conceptors: Improving Addition-Based Activation Engineering](https://arxiv.org//abs/2410.16314)

	Joris Postmus, Steven Abreu

+ [CursorCore: Assist Programming through Aligning Anything](https://arxiv.org//abs/2410.07002)

	Hao Jiang, Qi Liu, Rui Li, Shengyu Ye, Shijin Wang

+ [ST-WebAgentBench: A Benchmark for Evaluating Safety and Trustworthiness in Web Agents](https://arxiv.org//abs/2410.06703)

	Ido Levy, Ben Wiesel, Sami Marreed, Alon Oved, Avi Yaeli, Segev Shlomov

# 2024-10-06
+ [Regressing the Relative Future: Efficient Policy Optimization for Multi-turn RLHF](https://arxiv.org//abs/2410.04612)

	Zhaolin Gao, Wenhao Zhan, Jonathan D. Chang, Gokul Swamy, Kianté Brantley, Jason D. Lee, Wen Sun


# 2024-10-04
+ [Understanding Large Language Models in Your Pockets: Performance Study on COTS Mobile Devices](https://arxiv.org//abs/2410.03613)

	Jie Xiao, Qianyi Huang, Xu Chen, Chen Tian

+ [Look Twice Before You Answer: Memory-Space Visual Retracing for Hallucination Mitigation in Multimodal Large Language Models](https://arxiv.org//abs/2410.03577)

	Xin Zou, Yizhou Wang, Yibo Yan, Yuanhuiyi Lyu, Kening Zheng, Sirui Huang, Junkai Chen, Peijie Jiang, Jia Liu, Chang Tang, Xuming Hu

+ [Decoding Game: On Minimax Optimality of Heuristic Text Generation Strategies](https://arxiv.org//abs/2410.03968)

	Sijin Chen, Omar Hagrass, Jason M. Klusowski

# 2024-10-03
+ [Selective Attention Improves Transformer](https://arxiv.org//abs/2410.02703)

	Yaniv Leviathan, Matan Kalman, Yossi Matias


+ [A Formal Framework for Understanding Length Generalization in Transformers](https://arxiv.org//abs/2410.02140)

	Xinting Huang, Andy Yang, Satwik Bhattamishra, Yash Sarrof, Andreas Krebs, Hattie Zhou, Preetum Nakkiran, Michael Hahn

+ [Theoretical Insights into Fine-Tuning Attention Mechanism: Generalization and Optimization](https://arxiv.org//abs/2410.02247)

	Xinhao Yao, Hongjin Qian, Xiaolin Hu, Gengze Xu, Wei Liu, Jian Luan, Bin Wang, Yong Liu

# 2024-10-02
+ [TypedThinker: Diversify Large Language Model Reasoning with Typed Thinking](https://arxiv.org//abs/2410.01952)

	Danqing Wang, Jianxin Ma, Fei Fang, Lei Li


+ [Racing Thoughts: Explaining Contextualization Errors in Large Language Models](https://arxiv.org//abs/2410.02102)

	Michael A. Lepori, Michael C. Mozer, Asma Ghandeharioun

+ [Moral Alignment for LLM Agents](https://arxiv.org//abs/2410.01639)

	Elizaveta Tennant, Stephen Hailes, Mirco Musolesi

# 2024-09-30
+ [Beyond Single Concept Vector: Modeling Concept Subspace in LLMs with Gaussian Distribution](https://arxiv.org//abs/2410.00153)

	Haiyan Zhao, Heng Zhao, Bo Shen, Ali Payani, Fan Yang, Mengnan Du

+ [Characterizing and Efficiently Accelerating Multimodal Generation Model Inference](https://arxiv.org//abs/2410.00215)

	Yejin Lee, Anna Sun, Basil Hosmer, Bilge Acun, Can Balioglu, Changhan Wang, Charles David Hernandez, Christian Puhrsch, Daniel Haziza, Driss Guessous, Francisco Massa, Jacob Kahn, Jeffrey Wan, Jeremy Reizenstein, Jiaqi Zhai, Joe Isaacson, Joel Schlosser, Juan Pino, Kaushik Ram Sadagopan, Leonid Shamis, Linjian Ma, Min-Jae Hwang, Mingda Chen, Mostafa Elhoushi, Pedro Rodriguez, Ram Pasunuru, Scott Yih, Sravya Popuri, Xing Liu, Carole-Jean Wu

+ [SSR: Alignment-Aware Modality Connector for Speech Language Models](https://arxiv.org//abs/2410.00168)

	Weiting Tan, Hirofumi Inaguma, Ning Dong, Paden Tomasello, Xutai Ma

# 2024-09-27
+ [Can LLMs Really Learn to Translate a Low-Resource Language from One Grammar Book?](https://arxiv.org//abs/2409.19151)

	Seth Aycock, David Stap, Di Wu, Christof Monz, Khalil Sima'an

+ [Mitigating Selection Bias with Node Pruning and Auxiliary Options](https://arxiv.org//abs/2409.18857)

	Hyeong Kyu Choi, Weijie Xu, Chi Xue, Stephanie Eckman, Chandan K. Reddy

# 2024-09-26
+ [Benign Overfitting in Token Selection of Attention Mechanism](https://arxiv.org//abs/2409.17625)

	Keitaro Sakamoto, Issei Sato

# 2024-09-25
+ [AXIS: Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents](https://arxiv.org//abs/2409.17140)

	Junting Lu, Zhiyang Zhang, Fangkai Yang, Jue Zhang, Lu Wang, Chao Du, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang

# 2024-09-23
+ [Scideator: Human-LLM Scientific Idea Generation Grounded in Research-Paper Facet Recombination](https://arxiv.org//abs/2409.14634)

	Marissa Radensky, Simra Shahid, Raymond Fok, Pao Siangliulue, Tom Hope, Daniel S. Weld

+ [Revise, Reason, and Recognize: LLM-Based Emotion Recognition via Emotion-Specific Prompts and ASR Error Correction](https://arxiv.org//abs/2409.15551)

	Yuanchao Li, Yuan Gong, Chao-Han Huck Yang, Peter Bell, Catherine Lai

# 2024-09-20
+ [Time Awareness in Large Language Models: Benchmarking Fact Recall Across Time](https://arxiv.org//abs/2409.13338)

	David Herel, Vojtech Bartek, Jiri Jirak, Tomas Mikolov

# 2024-09-19
+ [Prompts Are Programs Too! Understanding How Developers Build Software Containing Prompts](https://arxiv.org//abs/2409.12447)

	Jenny T. Liang, Melissa Lin, Nikitha Rao, Brad A. Myers

+ [Strategic Collusion of LLM Agents: Market Division in Multi-Commodity Competitions](https://arxiv.org//abs/2410.00031)

	Ryan Y. Lin, Siddhartha Ojha, Kevin Cai, Maxwell F. Chen

# 2024-09-18
+ [To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning](https://arxiv.org//abs/2409.12183)

	Zayne Sprague, Fangcong Yin, Juan Diego Rodriguez, Dongwei Jiang, Manya Wadhwa, Prasann Singhal, Xinyu Zhao, Xi Ye, Kyle Mahowald, Greg Durrett

# 2024-09-17
+ [Measuring and Enhancing Trustworthiness of LLMs in RAG through Grounded Attributions and Learning to Refuse](https://arxiv.org//abs/2409.11242)

	Maojia Song, Shang Hong Sim, Rishabh Bhardwaj, Hai Leong Chieu, Navonil Majumder, Soujanya Poria

+ [Exploring the Trade-Offs: Quantization Methods, Task Difficulty, and Model Size in Large Language Models From Edge to Giant](https://arxiv.org//abs/2409.11055)

	Jemin Lee, Sihyeong Park, Jinse Kwon, Jihun Oh, Yongin Kwon

# 2024-09-16
+ [Lab-AI: Using Retrieval Augmentation to Enhance Language Models for Personalized Lab Test Interpretation in Clinical Medicine](https://arxiv.org//abs/2409.18986)

	Xiaoyu Wang, Haoyong Ouyang, Balu Bhasuran, Xiao Luo, Karim Hanna, Mia Liza A. Lustria, Carl Yang, Zhe He


# 2024-09-14
+ [Hacking, The Lazy Way: LLM Augmented Pentesting](https://arxiv.org//abs/2409.09493)

	Dhruva Goyal, Sitaraman Subramanian, Aditya Peela, Nisha P. Shetty

# 2024-09-13
+ [Your Weak LLM is Secretly a Strong Teacher for Alignment](https://arxiv.org//abs/2409.08813)

	Leitian Tao, Yixuan Li

# 2024-09-10
+ [LaMsS: When Large Language Models Meet Self-Skepticism](https://arxiv.org//abs/2409.06601)

	Yetao Wu, Yihong Wang, Teng Chen, Ningyuan Xi, Qingqing Gu, Hongyang Lei, Luo Ji

# 2024-09-07
+ [Reward Guidance for Reinforcement Learning Tasks Based on Large Language Models: The LMGT Framework](https://arxiv.org//abs/2409.04744)

	Yongxin Deng, Xihe Qiu, Jue Chen, Xiaoyu Tan

# 2024-09-06
+ [From Calculation to Adjudication: Examining LLM judges on Mathematical Reasoning Tasks](https://arxiv.org//abs/2409.04168)

	Andreas Stephan, Dawei Zhu, Matthias Aßenmacher, Xiaoyu Shen, Benjamin Roth

# 2024-09-03
+ [Efficient LLM Context Distillation](https://arxiv.org//abs/2409.01930)

	Rajesh Upadhayayaya, Manish Raj Osti, Zachary Smith, Chritopher Kottmyer

+ [What are the Essential Factors in Crafting Effective Long Context Multi-Hop Instruction Datasets? Insights and Best Practices](https://arxiv.org//abs/2409.01893)

	Zhi Chen, Qiguang Chen, Libo Qin, Qipeng Guo, Haijun Lv, Yicheng Zou, Wanxiang Che, Hang Yan, Kai Chen, Dahua Lin

# 2024-08-30
+ [Training Ultra Long Context Language Model with Fully Pipelined Distributed Transformer](https://arxiv.org//abs/2408.16978)

	Jinghan Yao, Sam Ade Jacobs, Masahiro Tanaka, Olatunji Ruwase, Hari Subramoni, Dhabaleswar K. Panda

# 2024-08-26
+ [CHARTOM: A Visual Theory-of-Mind Benchmark for Multimodal Large Language Models](https://arxiv.org//abs/2408.14419)

	Shubham Bharti, Shiyun Cheng, Jihyun Rho, Jianrui Zhang, Mu Cai, Yong Jae Lee, Martina Rau, Xiaojin Zhu

# 2024-08-22
+ [LLMs are not Zero-Shot Reasoners for Biomedical Information Extraction](https://arxiv.org//abs/2408.12249)

	Aishik Nagar, Viktor Schlegel, Thanh-Tung Nguyen, Hao Li, Yuping Wu, Kuluhan Binici, Stefan Winkler

# 2024-08-19
+ [Kubrick: Multimodal Agent Collaborations for Synthetic Video Generation](https://arxiv.org//abs/2408.10453)

	Liu He, Yizhi Song, Hejun Huang, Pinxin Liu, Yunlong Tang, Daniel Aliaga, Xin Zhou

+ [Bridging the Language Gap: Enhancing Multilingual Prompt-Based Code Generation in LLMs via Zero-Shot Cross-Lingual Transfer](https://arxiv.org//abs/2408.09701)

	Mingda Li, Abhijit Mishra, Utkarsh Mujumdar

# 2024-08-16
+ [Turning Trash into Treasure: Accelerating Inference of Large Language Models with Token Recycling](https://arxiv.org//abs/2408.08696)

	Xianzhen Luo, Yixuan Wang, Qingfu Zhu, Zhiming Zhang, Xuanyu Zhang, Qing Yang, Dongliang Xu

# 2024-08-13
+ [Bridging LLMs and KGs without Fine-Tuning: Intermediate Probing Meets Subgraph-Aware Entity Descriptions](https://arxiv.org//abs/2408.06787)

	Bo Xue, Yi Xu, Yunchong Song, Yiming Pang, Yuyang Ren, Jiaxin Ding, Luoyi Fu, Xinbing Wang

# 2024-08-12
+ [Does Liking Yellow Imply Driving a School Bus? Semantic Leakage in Language Models](https://arxiv.org//abs/2408.06518)

	Hila Gonen, Terra Blevins, Alisa Liu, Luke Zettlemoyer, Noah A. Smith

# 2024-08-10
+ [SWIFT:A Scalable lightWeight Infrastructure for Fine-Tuning](https://arxiv.org//abs/2408.05517)

	Yuze Zhao, Jintao Huang, Jinghan Hu, Xingjun Wang, Yunlin Mao, Daoze Zhang, Hong Zhang, Zeyinzi Jiang, Zhikai Wu, Baole Ai, Ang Wang, Wenmeng Zhou, Yingda Chen

# 2024-08-09
+ [Order Matters in Hallucination: Reasoning Order as Benchmark and Reflexive Prompting for Large-Language-Models](https://arxiv.org//abs/2408.05093)

	Zikai Xie

# 2024-08-08
+ [The Struggles of LLMs in Cross-lingual Code Clone Detection](https://arxiv.org//abs/2408.04430)

	Micheline Bénédicte Moumoula, Abdoul Kader Kabore, Jacques Klein, Tegawendé Bissyande

# 2024-08-07
+ [A Logical Fallacy-Informed Framework for Argument Generation](https://arxiv.org//abs/2408.03618)

	Luca Mouchel, Debjit Paul, Shaobo Cui, Robert West, Antoine Bosselut, Boi Faltings

# 2024-08-02
+ [CFBench: A Comprehensive Constraints-Following Benchmark for LLMs](https://arxiv.org//abs/2408.01122)

	Tao Zhang, Chenglin Zhu, Yanjun Shen, Wenjing Luo, Yan Zhang, Hao Liang, Tao Zhang, Fan Yang, Mingan Lin, Yujing Qiao, Weipeng Chen, Bin Cui, Wentao Zhang, Zenan Zhou

# 2024-07-31
+ [Correcting Negative Bias in Large Language Models through Negative Attention Score Alignment](https://arxiv.org//abs/2408.00137)

	Sangwon Yu, Jongyoon Song, Bongkyu Hwang, Hoyoung Kang, Sooah Cho, Junhwa Choi, Seongho Joe, Taehee Lee, Youngjune L. Gwon, Sungroh Yoon

+ [SAKR: Enhancing Retrieval-Augmented Generation via Streaming Algorithm and K-Means Clustering](https://arxiv.org//abs/2407.21300)

	Haoyu Kang (1), Yuzhou Zhu (2), Yukun Zhong (3), Ke Wang (4) ((1) Central South University, (2) Dalian University of Technology, (3) Nanjing University, (4) Xidian University)

# 2024-07-26
+ [Patched MOA: optimizing inference for diverse software development tasks](https://arxiv.org//abs/2407.18521)

	Asankhaya Sharma

+ [ClinicRealm: Re-evaluating Large Language Models with Conventional Machine Learning for Non-Generative Clinical Prediction Tasks](https://arxiv.org//abs/2407.18525)

	Yinghao Zhu, Junyi Gao, Zixiang Wang, Weibin Liao, Xiaochen Zheng, Lifang Liang, Miguel O. Bernabeu, Yasha Wang, Lequan Yu, Chengwei Pan, Ewen M. Harrison, Liantao Ma

# 2024-07-23
+ [Patched RTC: evaluating LLMs for diverse software development tasks](https://arxiv.org//abs/2407.16557)

	Asankhaya Sharma

# 2024-07-22
+ [Compensate Quantization Errors+: Quantized Models Are Inquisitive Learners](https://arxiv.org//abs/2407.15508)

	Yifei Gao, Jie Ou, Lei Wang, Jun Cheng, Mengchu Zhou

# 2024-07-21
+ [A Practical Analysis of Human Alignment with *PO](https://arxiv.org//abs/2407.15229)

	Kian Ahrabian, Xihui Lin, Barun Patra, Vishrav Chaudhary, Alon Benhaim, Jay Pujara, Xia Song

# 2024-07-17
+ [PersLLM: A Personified Training Approach for Large Language Models](https://arxiv.org//abs/2407.12393)

	Zheni Zeng, Jiayi Chen, Huimin Chen, Yukun Yan, Yuxuan Chen, Zhenghao Liu, Zhiyuan Liu, Maosong Sun

+ [Conversational Query Reformulation with the Guidance of Retrieved Documents](https://arxiv.org//abs/2407.12363)

	Jeonghyun Park, Hwanhee Lee

# 2024-07-16
+ [NeedleBench: Can LLMs Do Retrieval and Reasoning in Information-Dense Context?](https://arxiv.org//abs/2407.11963)

	Mo Li, Songyang Zhang, Taolin Zhang, Haodong Duan, Yunxin Liu, Kai Chen

# 2024-07-10
+ [EfficientQAT: Efficient Quantization-Aware Training for Large Language Models](https://arxiv.org//abs/2407.11062)

	Mengzhao Chen, Wenqi Shao, Peng Xu, Jiahao Wang, Peng Gao, Kaipeng Zhang, Ping Luo

# 2024-07-05
+ [AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents](https://arxiv.org//abs/2407.04363)

	Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Andrey Kravchenko, Mikhail Burtsev, Evgeny Burnaev

# 2024-07-02
+ [A Bounding Box is Worth One Token: Interleaving Layout and Text in a Large Language Model for Document Understanding](https://arxiv.org//abs/2407.01976)

	Jinghui Lu, Haiyang Yu, Yanjie Wang, Yongjie Ye, Jingqun Tang, Ziwei Yang, Binghong Wu, Qi Liu, Hao Feng, Han Wang, Hao Liu, Can Huang

# 2024-06-28
+ [Scaling Synthetic Data Creation with 1,000,000,000 Personas](https://arxiv.org//abs/2406.20094)

	Tao Ge, Xin Chan, Xiaoyang Wang, Dian Yu, Haitao Mi, Dong Yu

+ [LLMEasyQuant: Scalable Quantization for Parallel and Distributed LLM Inference](https://arxiv.org//abs/2406.19657)

	Dong Liu, Yanxuan Yu

# 2024-06-26
+ [Is In-Context Learning a Type of Error-Driven Learning? Evidence from the Inverse Frequency Effect in Structural Priming](https://arxiv.org//abs/2406.18501)

	Zhenghao Zhou, Robert Frank, R. Thomas McCoy

# 2024-06-25
+ [OPT-Tree: Speculative Decoding with Adaptive Draft Tree Structure](https://arxiv.org//abs/2406.17276)

	Jikai Wang, Yi Su, Juntao Li, Qingrong Xia, Zi Ye, Xinyu Duan, Zhefeng Wang, Min Zhang


+ [Recite, Reconstruct, Recollect: Memorization in LMs as a Multifaceted Phenomenon](https://arxiv.org//abs/2406.17746)

	USVSN Sai Prashanth, Alvin Deng, Kyle O'Brien, Jyothir S V, Mohammad Aflah Khan, Jaydeep Borkar, Christopher A. Choquette-Choo, Jacob Ray Fuehne, Stella Biderman, Tracy Ke, Katherine Lee, Naomi Saphra

+ [From Distributional to Overton Pluralism: Investigating Large Language Model Alignment](https://arxiv.org//abs/2406.17692)

	Thom Lake, Eunsol Choi, Greg Durrett

+ [Brittle Minds, Fixable Activations: Understanding Belief Representations in Language Models](https://arxiv.org//abs/2406.17513)

	Matteo Bortoletto, Constantin Ruhdorfer, Lei Shi, Andreas Bulling

# 2024-06-24
+ [Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging](https://arxiv.org//abs/2406.16330)

	Deyuan Liu, Zhanyue Qin, Hairu Wang, Zhao Yang, Zecheng Wang, Fangying Rong, Qingbin Liu, Yanchao Hao, Xi Chen, Cunhang Fan, Zhao Lv, Zhiying Tu, Dianhui Chu, Bo Li, Dianbo Sui

# 2024-06-20
+ [ReaL: Efficient RLHF Training of Large Language Models with Parameter Reallocation](https://arxiv.org//abs/2406.14088)

	Zhiyu Mei, Wei Fu, Kaiwei Li, Guangju Wang, Huanchen Zhang, Yi Wu

# 2024-06-16
+ [ShareLoRA: Parameter Efficient and Robust Large Language Model Fine-tuning via Shared Low-Rank Adaptation](https://arxiv.org//abs/2406.10785)

	Yurun Song, Junchen Zhao, Ian G. Harris, Sangeetha Abdu Jyothi

# 2024-06-15
+ [Unlocking Large Language Model's Planning Capabilities with Maximum Diversity Fine-tuning](https://arxiv.org//abs/2406.10479)

	Wenjun Li, Changyu Chen, Pradeep Varakantham

+ [Task Facet Learning: A Structured Approach to Prompt Optimization](https://arxiv.org//abs/2406.10504)

	Gurusha Juneja, Gautam Jajoo, Nagarajan Natarajan, Hua Li, Jian Jiao, Amit Sharma

# 2024-06-14
+ [Recent Advances in Federated Learning Driven Large Language Models: A Survey on Architecture, Performance, and Security](https://arxiv.org//abs/2406.09831)

	Youyang Qu, Ming Liu, Tianqing Zhu, Longxiang Gao, Shui Yu, Wanlei Zhou

# 2024-06-13
+ [Talking Heads: Understanding Inter-layer Communication in Transformer Language Models](https://arxiv.org//abs/2406.09519)

	Jack Merullo, Carsten Eickhoff, Ellie Pavlick

+ [Online Bandit Learning with Offline Preference Data for Improved RLHF](https://arxiv.org//abs/2406.09574)

	Akhil Agnihotri, Rahul Jain, Deepak Ramachandran, Zheng Wen

# 2024-06-12
+ [Enhancing Differential Testing With LLMs For Testing Deep Learning Libraries](https://arxiv.org//abs/2406.07944)

	Meiziniu Li, Dongze Li, Jianmeng Liu, Jialun Cao, Yongqiang Tian, Shing-Chi Cheung

+ [Watermarking Language Models with Error Correcting Codes](https://arxiv.org//abs/2406.10281)

	Patrick Chao, Yan Sun, Edgar Dobriban, Hamed Hassani

# 2024-06-11
+ [RS-Agent: Automating Remote Sensing Tasks through Intelligent Agent](https://arxiv.org//abs/2406.07089)

	Wenjia Xu, Zijian Yu, Boyang Mu, Zhiwei Wei, Yuanben Zhang, Guangzuo Li, Mugen Peng

# 2024-06-10
+ [Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching](https://arxiv.org//abs/2406.06326)

	Xiaoying Zhang, Baolin Peng, Ye Tian, Jingyan Zhou, Yipeng Zhang, Haitao Mi, Helen Meng

# 2024-06-05
+ [Item-Language Model for Conversational Recommendation](https://arxiv.org//abs/2406.02844)

	Li Yang, Anushya Subbiah, Hardik Patel, Judith Yue Li, Yanwei Song, Reza Mirghaderi, Vikram Aggarwal, Qifan Wang

# 2024-06-04
+ [PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling](https://arxiv.org//abs/2406.02069)

	Zefan Cai, Yichi Zhang, Bofei Gao, Yuliang Liu, Yucheng Li, Tianyu Liu, Keming Lu, Wayne Xiong, Yue Dong, Junjie Hu, Wen Xiao

# 2024-06-03
+ [Re-ReST: Reflection-Reinforced Self-Training for Language Agents](https://arxiv.org//abs/2406.01495)

	Zi-Yi Dou, Cheng-Fu Yang, Xueqing Wu, Kai-Wei Chang, Nanyun Peng

# 2024-05-31
+ [OR-Bench: An Over-Refusal Benchmark for Large Language Models](https://arxiv.org//abs/2405.20947)

	Justin Cui, Wei-Lin Chiang, Ion Stoica, Cho-Jui Hsieh

# 2024-05-30
+ [Uncovering Bias in Large Vision-Language Models at Scale with Counterfactuals](https://arxiv.org//abs/2405.20152)

	Phillip Howard, Kathleen C. Fraser, Anahita Bhiwandiwalla, Svetlana Kiritchenko

# 2024-05-29
+ [Nearest Neighbor Speculative Decoding for LLM Generation and Attribution](https://arxiv.org//abs/2405.19325)

	Minghan Li, Xilun Chen, Ari Holtzman, Beidi Chen, Jimmy Lin, Wen-tau Yih, Xi Victoria Lin

# 2024-05-24
+ [Emergence of a High-Dimensional Abstraction Phase in Language Transformers](https://arxiv.org//abs/2405.15471)

	Emily Cheng, Diego Doimo, Corentin Kervadec, Iuri Macocco, Jade Yu, Alessandro Laio, Marco Baroni

+ [Sparse Matrix in Large Language Model Fine-tuning](https://arxiv.org//abs/2405.15525)

	Haoze He, Juncheng Billy Li, Xuan Jiang, Heather Miller

# 2024-05-23
+ [OAC: Output-adaptive Calibration for Accurate Post-training Quantization](https://arxiv.org//abs/2405.15025)

	Ali Edalati, Alireza Ghaffari, Mahsa Ghazvini Nejad, Lu Hou, Boxing Chen, Masoud Asgharian, Vahid Partovi Nia

# 2024-05-20
+ [(Perhaps) Beyond Human Translation: Harnessing Multi-Agent Collaboration for Translating Ultra-Long Literary Texts](https://arxiv.org//abs/2405.11804)

	Minghao Wu, Jiahao Xu, Yulin Yuan, Gholamreza Haffari, Longyue Wang, Weihua Luo, Kaifu Zhang

# 2024-05-08
+ [Large Language Models for Cyber Security: A Systematic Literature Review](https://arxiv.org//abs/2405.04760)

	Hanxiang Xu, Shenao Wang, Ningke Li, Kailong Wang, Yanjie Zhao, Kai Chen, Ting Yu, Yang Liu, Haoyu Wang

# 2024-05-07
+ [QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving](https://arxiv.org//abs/2405.04532)

	Yujun Lin, Haotian Tang, Shang Yang, Zhekai Zhang, Guangxuan Xiao, Chuang Gan, Song Han

+ [Folded Context Condensation in Path Integral Formalism for Infinite Context Transformers](https://arxiv.org//abs/2405.04620)

	Won-Gi Paeng, Daesuk Kwon, Kyungwon Jeong, Honggyo Suh

+ [Fleet of Agents: Coordinated Problem Solving with Large Language Models](https://arxiv.org//abs/2405.06691)

	Lars Klein, Nearchos Potamitis, Roland Aydin, Robert West, Caglar Gulcehre, Akhil Arora

# 2024-05-06
+ [Outlier Gradient Analysis: Efficiently Identifying Detrimental Training Samples for Deep Learning Models](https://arxiv.org//abs/2405.03869)

	Anshuman Chhabra, Bo Li, Jian Chen, Prasant Mohapatra, Hongfu Liu

# 2024-05-03
+ [CodeGRAG: Bridging the Gap between Natural Language and Programming Language via Graphical Retrieval Augmented Generation](https://arxiv.org//abs/2405.02355)

	Kounianhua Du, Jizheng Chen, Renting Rui, Huacan Chai, Lingyue Fu, Wei Xia, Yasheng Wang, Ruiming Tang, Yong Yu, Weinan Zhang

# 2024-04-27
+ [Temporal Scaling Law for Large Language Models](https://arxiv.org//abs/2404.17785)

	Yizhe Xiong, Xiansheng Chen, Xin Ye, Hui Chen, Zijia Lin, Haoran Lian, Zhenpeng Su, Wei Huang, Jianwei Niu, Jungong Han, Guiguang Ding

# 2024-04-26
+ [Large Language Model Agent as a Mechanical Designer](https://arxiv.org//abs/2404.17525)

	Yayati Jadhav, Amir Barati Farimani

# 2024-04-25
+ [Towards Adapting Open-Source Large Language Models for Expert-Level Clinical Note Generation](https://arxiv.org//abs/2405.00715)

	Hanyin Wang, Chufan Gao, Bolun Liu, Qiping Xu, Guleid Hussein, Mohamad El Labban, Kingsley Iheasirim, Hariprasad Korsapati, Chuck Outcalt, Jimeng Sun

# 2024-04-18
+ [Lean Copilot: Large Language Models as Copilots for Theorem Proving in Lean](https://arxiv.org//abs/2404.12534)

	Peiyang Song, Kaiyu Yang, Anima Anandkumar

# 2024-04-06
+ [Multilingual Brain Surgeon: Large Language Models Can be Compressed Leaving No Language Behind](https://arxiv.org//abs/2404.04748)

	Hongchuan Zeng, Hongshen Xu, Lu Chen, Kai Yu

# 2024-04-04
+ [PRobELM: Plausibility Ranking Evaluation for Language Models](https://arxiv.org//abs/2404.03818)

	Zhangdie Yuan, Eric Chamoun, Rami Aly, Chenxi Whitehouse, Andreas Vlachos

# 2024-03-31
+ [ParaICL: Towards Parallel In-Context Learning](https://arxiv.org//abs/2404.00570)

	Xingxuan Li, Xuan-Phi Nguyen, Shafiq Joty, Lidong Bing

# 2024-03-28
+ [Large Language Models Are Struggle to Cope with Unreasonability in Math Problems](https://arxiv.org//abs/2403.19346)

	Jingyuan Ma, Damai Dai, Zihang Yuan, Rui li, Weilin Luo, Bin Wang, Qun Liu, Lei Sha, Zhifang Sui

# 2024-03-25
+ [AIOS: LLM Agent Operating System](https://arxiv.org//abs/2403.16971)

	Kai Mei, Xi Zhu, Wujiang Xu, Wenyue Hua, Mingyu Jin, Zelong Li, Shuyuan Xu, Ruosong Ye, Yingqiang Ge, Yongfeng Zhang

# 2024-03-21
+ [Agentic AI: The Era of Semantic Decoding](https://arxiv.org//abs/2403.14562)

	Maxime Peyrard, Martin Josifoski, Robert West

# 2024-03-19
+ [To Help or Not to Help: LLM-based Attentive Support for Human-Robot Group Interactions](https://arxiv.org//abs/2403.12533)

	Daniel Tanneberg, Felix Ocker, Stephan Hasler, Joerg Deigmoeller, Anna Belardinelli, Chao Wang, Heiko Wersing, Bernhard Sendhoff, Michael Gienger

# 2024-03-13
+ [Usable XAI: 10 Strategies Towards Exploiting Explainability in the LLM Era](https://arxiv.org//abs/2403.08946)

	Xuansheng Wu, Haiyan Zhao, Yaochen Zhu, Yucheng Shi, Fan Yang, Lijie Hu, Tianming Liu, Xiaoming Zhai, Wenlin Yao, Jundong Li, Mengnan Du, Ninghao Liu

# 2024-03-04
+ [DECIDER: A Dual-System Rule-Controllable Decoding Framework for Language Generation](https://arxiv.org//abs/2403.01954)

	Chen Xu, Tian Lan, Yu Ji, Changlong Yu, Wei Wang, Jun Gao, Qunxi Dong, Kun Qian, Piji Li, Wei Bi, Bin Hu

# 2024-02-29
+ [LoRATK: LoRA Once, Backdoor Everywhere in the Share-and-Play Ecosystem](https://arxiv.org//abs/2403.00108)

	Hongyi Liu, Shaochen Zhong, Xintong Sun, Minghao Tian, Mohsen Hariri, Zirui Liu, Ruixiang Tang, Zhimeng Jiang, Jiayi Yuan, Yu-Neng Chuang, Li Li, Soo-Hyun Choi, Rui Chen, Vipin Chaudhary, Xia Hu

+ [FlexLLM: A System for Co-Serving Large Language Model Inference and Parameter-Efficient Finetuning](https://arxiv.org//abs/2402.18789)

	Gabriele Oliaro, Xupeng Miao, Xinhao Cheng, Vineeth Kada, Ruohan Gao, Yingyi Huang, Remi Delacourt, April Yang, Yingcheng Wang, Mengdi Wu, Colin Unger, Zhihao Jia

# 2024-02-22
+ [COBIAS: Assessing the Contextual Reliability of Bias Benchmarks for Language Models](https://arxiv.org//abs/2402.14889)

	Priyanshul Govil, Hemang Jain, Vamshi Krishna Bonagiri, Aman Chadha, Ponnurangam Kumaraguru, Manas Gaur, Sanorita Dey

# 2024-02-21
+ [Round Trip Translation Defence against Large Language Model Jailbreaking Attacks](https://arxiv.org//abs/2402.13517)

	Canaan Yung, Hadi Mohaghegh Dolatabadi, Sarah Erfani, Christopher Leckie

# 2024-02-20
+ [FormulaReasoning: A Dataset for Formula-Based Numerical Reasoning](https://arxiv.org//abs/2402.12692)

	Xiao Li, Bolin Zhu, Kaiwen Shi, Sichen Liu, Yin Zhu, Yiwei Liu, Gong Cheng

# 2024-02-16
+ [Can We Verify Step by Step for Incorrect Answer Detection?](https://arxiv.org//abs/2402.10528)

	Xin Xu, Shizhe Diao, Can Yang, Yang Wang

# 2024-02-13
+ ["Reasoning" with Rhetoric: On the Style-Evidence Tradeoff in LLM-Generated Counter-Arguments](https://arxiv.org//abs/2402.08498)

	Preetika Verma, Kokil Jaidka, Svetlana Churina

# 2024-02-10
+ [Fiddler: CPU-GPU Orchestration for Fast Inference of Mixture-of-Experts Models](https://arxiv.org//abs/2402.07033)

	Keisuke Kamahori, Tian Tang, Yile Gu, Kan Zhu, Baris Kasikci

# 2024-02-05
+ [LLM Multi-Agent Systems: Challenges and Open Problems](https://arxiv.org//abs/2402.03578)

	Shanshan Han, Qifan Zhang, Yuhang Yao, Weizhao Jin, Zhaozhuo Xu

# 2024-02-02
+ [Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach](https://arxiv.org//abs/2402.01454)

	Masayuki Takayama, Tadahisa Okuda, Thong Pham, Tatsuyoshi Ikenoue, Shingo Fukuma, Shohei Shimizu, Akiyoshi Sannai

# 2024-02-01
+ [On the Challenges of Fuzzing Techniques via Large Language Models](https://arxiv.org//abs/2402.00350)

	Linghan Huang, Peizhou Zhao, Huaming Chen, Lei Ma

# 2024-01-30
+ [Incoherent Probability Judgments in Large Language Models](https://arxiv.org//abs/2401.16646)

	Jian-Qiao Zhu, Thomas L. Griffiths

# 2023-12-04
+ [LLM A*: Human in the Loop Large Language Models Enabled A* Search for Robotics](https://arxiv.org//abs/2312.01797)

	Hengjia Xiao, Peng Wang, Mingzhe Yu, Mattia Robbiani

# 2023-11-30
+ [RaDialog: A Large Vision-Language Model for Radiology Report Generation and Conversational Assistance](https://arxiv.org//abs/2311.18681)

	Chantal Pellegrini, Ege Özsoy, Benjamin Busam, Nassir Navab, Matthias Keicher

# 2023-11-16
+ [Automating the Generation of Prompts for LLM-based Action Choice in PDDL Planning](https://arxiv.org//abs/2311.09830)

	Katharina Stein, Daniel Fišer, Jörg Hoffmann, Alexander Koller

# 2023-10-20
+ [Towards Understanding Sycophancy in Language Models](https://arxiv.org//abs/2310.13548)

	Mrinank Sharma, Meg Tong, Tomasz Korbak, David Duvenaud, Amanda Askell, Samuel R. Bowman, Newton Cheng, Esin Durmus, Zac Hatfield-Dodds, Scott R. Johnston, Shauna Kravec, Timothy Maxwell, Sam McCandlish, Kamal Ndousse, Oliver Rausch, Nicholas Schiefer, Da Yan, Miranda Zhang, Ethan Perez

# 2023-10-16
+ [Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models](https://arxiv.org//abs/2310.10378)

	Jirui Qi, Raquel Fernández, Arianna Bisazza

# 2023-10-11
+ [CoPAL: Corrective Planning of Robot Actions with Large Language Models](https://arxiv.org//abs/2310.07263)

	Frank Joublin, Antonello Ceravola, Pavel Smirnov, Felix Ocker, Joerg Deigmoeller, Anna Belardinelli, Chao Wang, Stephan Hasler, Daniel Tanneberg, Michael Gienger


# 2023-10-07
+ [Uncovering Model Processing Strategies with Non-Negative Per-Example Fisher Factorization](https://arxiv.org//abs/2310.04649)

	Michael Matena, Colin Raffel

# 2023-10-05
+ [LLM-Coordination: Evaluating and Analyzing Multi-agent Coordination Abilities in Large Language Models](https://arxiv.org//abs/2310.03903)

	Saaket Agashe, Yue Fan, Anthony Reyna, Xin Eric Wang

# 2023-09-21
+ [Automating construction contract review using knowledge graph-enhanced large language models](https://arxiv.org//abs/2309.12132)

	Chunmo Zheng, Saika Wong, Xing Su, Yinqiu Tang, Ahsan Nawaz, Mohamad Kassem

# 2023-09-15
+ [EvoPrompt: Connecting LLMs with Evolutionary Algorithms Yields Powerful Prompt Optimizers](https://arxiv.org//abs/2309.08532)

	Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song, Xu Tan, Guoqing Liu, Jiang Bian, Yujiu Yang

# 2023-08-29
+ [Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models](https://arxiv.org//abs/2308.15022)

	Qingyue Wang, Yanhe Fu, Yanan Cao, Shuai Wang, Zhiliang Tian, Liang Ding

# 2023-08-17
+ [Semantic Consistency for Assuring Reliability of Large Language Models](https://arxiv.org//abs/2308.09138)

	Harsh Raj, Vipul Gupta, Domenic Rosati, Subhabrata Majumdar

# 2023-05-26
+ [Playing repeated games with Large Language Models](https://arxiv.org//abs/2305.16867)

	Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, Eric Schulz

# 2023-05-23
+ [Physics of Language Models: Part 1, Learning Hierarchical Language Structures](https://arxiv.org//abs/2305.13673)

	Zeyuan Allen-Zhu, Yuanzhi Li

# 2023-05-01
+ [Large Linguistic Models: Investigating LLMs' metalinguistic abilities](https://arxiv.org//abs/2305.00948)

	Gašper Beguš, Maksymilian Dąbkowski, Ryan Rhodes

# 2023-03-03
+ [Prophet: Prompting Large Language Models with Complementary Answer Heuristics for Knowledge-based Visual Question Answering](https://arxiv.org//abs/2303.01903)

	Zhou Yu, Xuecheng Ouyang, Zhenwei Shao, Meng Wang, Jun Yu

# 2023-01-11
+ [Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability](https://arxiv.org//abs/2301.04709)

	Atticus Geiger, Duligur Ibeling, Amir Zur, Maheep Chaudhary, Sonakshi Chauhan, Jing Huang, Aryaman Arora, Zhengxuan Wu, Noah Goodman, Christopher Potts, Thomas Icard

