# LLM-wisdom
The papers related to the LLM wisdom, including test-time scaling, knowledge editing, model recognition, capacity enhancement, RAG, Agent, internal mechanism of LLM and etc. 

# 2025-04-29
+ [TAMO:Fine-Grained Root Cause Analysis via Tool-Assisted LLM Agent with Multi-Modality Observation Data](https://arxiv.org//abs/2504.20462)

	Qi Wang, Xiao Zhang, Mingyi Li, Yuan Yuan, Mengbai Xiao, Fuzhen Zhuang, Dongxiao Yu

+ [A Summary on GUI Agents with Foundation Models Enhanced by Reinforcement Learning](https://arxiv.org//abs/2504.20464)

	Jiahao Li, Kaer Huang

+ [ReasonIR: Training Retrievers for Reasoning Tasks](https://arxiv.org//abs/2504.20595)

	Rulin Shao, Rui Qiao, Varsha Kishore, Niklas Muennighoff, Xi Victoria Lin, Daniela Rus, Bryan Kian Hsiang Low, Sewon Min, Wen-tau Yih, Pang Wei Koh, Luke Zettlemoyer

+ [PaRT: Enhancing Proactive Social Chatbots with Personalized Real-Time Retrieval](https://arxiv.org//abs/2504.20624)

	Zihan Niu, Zheyong Xie, Shaosheng Cao, Chonggang Lu, Zheyu Ye, Tong Xu, Zuozhu Liu, Yan Gao, Jia Chen, Zhe Xu, Yi Wu, Yao Hu

+ [Ascendra: Dynamic Request Prioritization for Efficient LLM Serving](https://arxiv.org//abs/2504.20828)

	Azam Ikram, Xiang Li, Sameh Elnikety, Saurabh Bagchi

+ [The Leaderboard Illusion](https://arxiv.org//abs/2504.20879)

	Shivalika Singh, Yiyang Nan, Alex Wang, Daniel D'Souza, Sayash Kapoor, Ahmet Üstün, Sanmi Koyejo, Yuntian Deng, Shayne Longpre, Noah Smith, Beyza Ermis, Marzieh Fadaee, Sara Hooker

+ [CBM-RAG: Demonstrating Enhanced Interpretability in Radiology Report Generation with Multi-Agent RAG and Concept Bottleneck Models](https://arxiv.org//abs/2504.20898)

	Hasan Md Tusfiqur Alam, Devansh Srivastav, Abdulrahman Mohamed Selim, Md Abdul Kadir, Md Moktadiurl Hoque Shuvo, Daniel Sonntag

+ [ChestX-Reasoner: Advancing Radiology Foundation Models with Reasoning through Step-by-Step Verification](https://arxiv.org//abs/2504.20930)

	Ziqing Fan, Cheng Liang, Chaoyi Wu, Ya Zhang, Yanfeng Wang, Weidi Xie

+ [Jekyll-and-Hyde Tipping Point in an AI's Behavior](https://arxiv.org//abs/2504.20980)

	Neil F. Johnson, Frank Yingjie Huo

+ [Local Prompt Optimization](https://arxiv.org//abs/2504.20355)

	Yash Jain, Vishal Chowdhary

+ [ARCS: Agentic Retrieval-Augmented Code Synthesis with Iterative Refinement](https://arxiv.org//abs/2504.20434)

	Manish Bhattarai, Miguel Cordova, Javier Santos, Dan O'Malley

+ [On Psychology of AI -- Does Primacy Effect Affect ChatGPT and Other LLMs?](https://arxiv.org//abs/2504.20444)

	Mika Hämäläinen

+ [Token-Efficient Prompt Injection Attack: Provoking Cessation in LLM Reasoning via Adaptive Token Compression](https://arxiv.org//abs/2504.20493)

	Yu Cui, Yujun Cai, Yiwei Wang

+ [Reinforcement Learning for Reasoning in Large Language Models with One Training Example](https://arxiv.org//abs/2504.20571)

	Yiping Wang, Qing Yang, Zhiyuan Zeng, Liliang Ren, Lucas Liu, Baolin Peng, Hao Cheng, Xuehai He, Kuan Wang, Jianfeng Gao, Weizhu Chen, Shuohang Wang, Simon Shaolei Du, Yelong Shen

+ [Information Retrieval in the Age of Generative AI: The RGB Model](https://arxiv.org//abs/2504.20610)

	Michele Garetto, Alessandro Cornacchia, Franco Galante, Emilio Leonardi, Alessandro Nordio, Alberto Tarable

+ [The Hidden Risks of LLM-Generated Web Application Code: A Security-Centric Evaluation of Code Generation Capabilities in Large Language Models](https://arxiv.org//abs/2504.20612)

	Swaroop Dora, Deven Lunkad, Naziya Aslam, S. Venkatesan, Sandeep Kumar Shukla

+ [Cooking Up Creativity: A Cognitively-Inspired Approach for Enhancing LLM Creativity through Structured Representations](https://arxiv.org//abs/2504.20643)

	Moran Mizrahi, Chen Shani, Gabriel Stanovsky, Dan Jurafsky, Dafna Shahaf

+ [CoCo-Bench: A Comprehensive Code Benchmark For Multi-task Large Language Model Evaluation](https://arxiv.org//abs/2504.20673)

	Wenjing Yin, Tianze Sun, Yijiong Yu, Jiawei Fang, Guangyao Su, Jiancheng Wang, Zekun Wang, Wei Wang, Ran Chen, Ziyun Dai, Shuai Yuan, Menghang Dong, Peng Luo, Dong Cao, Da Lei, Yajun Zhang, Hao Chen, Xiang Ma, Yong Liu, Weifeng Liu, Yuanjian Xu, Ji Pei

+ [Can LLMs Detect Intrinsic Hallucinations in Paraphrasing and Machine Translation?](https://arxiv.org//abs/2504.20699)

	Evangelia Gogoulou, Shorouq Zahra, Liane Guillou, Luise Dürlich, Joakim Nivre

+ [Beyond the Last Answer: Your Reasoning Trace Uncovers More than You Think](https://arxiv.org//abs/2504.20708)

	Hasan Abed Al Kader Hammoud, Hani Itani, Bernard Ghanem

+ [UniversalRAG: Retrieval-Augmented Generation over Multiple Corpora with Diverse Modalities and Granularities](https://arxiv.org//abs/2504.20734)

	Woongyeong Yeo, Kangsan Kim, Soyeong Jeong, Jinheon Baek, Sung Ju Hwang

+ [Grokking in the Wild: Data Augmentation for Real-World Multi-Hop Reasoning with Transformers](https://arxiv.org//abs/2504.20752)

	Roman Abramov, Felix Steinbauer, Gjergji Kasneci

+ [Chain-of-Defensive-Thought: Structured Reasoning Elicits Robustness in Large Language Models against Reference Corruption](https://arxiv.org//abs/2504.20769)

	Wenxiao Wang, Parsa Hosseini, Soheil Feizi

+ [Using LLMs in Generating Design Rationale for Software Architecture Decisions](https://arxiv.org//abs/2504.20781)

	Xiyu Zhou, Ruiyin Li, Peng Liang, Beiqi Zhang, Mojtaba Shahin, Zengyang Li, Chen Yang

+ [Hallucination by Code Generation LLMs: Taxonomy, Benchmarks, Mitigation, and Challenges](https://arxiv.org//abs/2504.20799)

	Yunseo Lee, John Youngeun Song, Dongsun Kim, Jindae Kim, Mijung Kim, Jaechang Nam

+ [Reinforcement Learning for LLM Reasoning Under Memory Constraints](https://arxiv.org//abs/2504.20834)

	Alan Lee, Harry Tong

+ [DYNAMAX: Dynamic computing for Transformers and Mamba based architectures](https://arxiv.org//abs/2504.20922)

	Miguel Nogales, Matteo Gambella, Manuel Roveri

+ [Trace-of-Thought: Enhanced Arithmetic Problem Solving via Reasoning Distillation From Large to Small Language Models](https://arxiv.org//abs/2504.20946)

	Tyler McDonald, Ali Emami

+ [OSVBench: Benchmarking LLMs on Specification Generation Tasks for Operating System Verification](https://arxiv.org//abs/2504.20964)

	Shangyu Li, Juyong Jiang, Tiancheng Zhao, Jiasi Shen

+ [Toward Efficient Exploration by Large Language Model Agents](https://arxiv.org//abs/2504.20997)

	Dilip Arumugam, Thomas L. Griffiths

+ [What Causes Knowledge Loss in Multilingual Language Models?](https://arxiv.org//abs/2504.20356)

	Maria Khelli, Samuel Cahyawijaya, Ayu Purwarianti, Genta Indra Winata

+ [DMDTEval: An Evaluation and Analysis of LLMs on Disambiguation in Multi-domain Translation](https://arxiv.org//abs/2504.20371)

	Zhibo Man, Yuanmeng Chen, Yujie Zhang, Yufeng Chen, Jinan Xu

+ [Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training](https://arxiv.org//abs/2504.20484)

	Linjuan Wu, Haoran Wei, Huan Lin, Tianhao Li, Baosong Yang, Weiming Lu

+ [UniDetox: Universal Detoxification of Large Language Models via Dataset Distillation](https://arxiv.org//abs/2504.20500)

	Huimin Lu, Masaru Isonuma, Junichiro Mori, Ichiro Sakata

+ [Turing Machine Evaluation for Large Language Model](https://arxiv.org//abs/2504.20771)

	Haitao Wu, Zongbo Han, Huaxi Huang, Changqing Zhang

+ [Information Gravity: A Field-Theoretic Model for Token Selection in Large Language Models](https://arxiv.org//abs/2504.20951)

	Maryna Vyshnyvetska

+ [SetKE: Knowledge Editing for Knowledge Elements Overlap](https://arxiv.org//abs/2504.20972)

	Yifan Wei, Xiaoyan Yu, Ran Song, Hao Peng, Angsheng Li

+ [Reviving Any-Subset Autoregressive Models with Principled Parallel Sampling and Speculative Decoding](https://arxiv.org//abs/2504.20456)

	Gabe Guo, Stefano Ermon

+ [Towards Understanding the Nature of Attention with Low-Rank Sparse Decomposition](https://arxiv.org//abs/2504.20938)

	Zhengfu He, Junxuan Wang, Rui Lin, Xuyang Ge, Wentao Shu, Qiong Tang, Junping Zhang, Xipeng Qiu

+ [Antidote: A Unified Framework for Mitigating LVLM Hallucinations in Counterfactual Presupposition and Object Perception](https://arxiv.org//abs/2504.20468)

	Yuanchen Wu, Lu Zhang, Hang Yao, Junlong Du, Ke Yan, Shouhong Ding, Yunsheng Wu, Xiaoqiang Li

+ [X-Fusion: Introducing New Modality to Frozen Large Language Models](https://arxiv.org//abs/2504.20996)

	Sicheng Mo, Thao Nguyen, Xun Huang, Siddharth Srinivasan Iyer, Yijun Li, Yuchen Liu, Abhishek Tandon, Eli Shechtman, Krishna Kumar Singh, Yong Jae Lee, Bolei Zhou, Yuheng Li

+ [Combatting Dimensional Collapse in LLM Pre-Training Data via Diversified File Selection](https://arxiv.org//abs/2504.20644)

	Ziqing Fan, Siyuan Du, Shengchao Hu, Pingjie Wang, Li Shen, Ya Zhang, Dacheng Tao, Yanfeng Wang

+ [AegisLLM: Scaling Agentic Systems for Self-Reflective Defense in LLM Security](https://arxiv.org//abs/2504.20965)

	Zikui Cai, Shayan Shabihi, Bang An, Zora Che, Brian R. Bartoldson, Bhavya Kailkhura, Tom Goldstein, Furong Huang

+ [Softpick: No Attention Sink, No Massive Activations with Rectified Softmax](https://arxiv.org//abs/2504.20966)

	Zayd M. K. Zuhri, Erland Hilman Fuadi, Alham Fikri Aji

+ [ACE: A Security Architecture for LLM-Integrated App Systems](https://arxiv.org//abs/2504.20984)

	Evan Li, Tushin Mallick, Evan Rose, William Robertson, Alina Oprea, Cristina Nita-Rotaru

+ [Enhancing Leakage Attacks on Searchable Symmetric Encryption Using LLM-Based Synthetic Data Generation](https://arxiv.org//abs/2504.20414)

	Joshua Chiu, Partha Protim Paul, Zahin Wahab

+ [Robustness via Referencing: Defending against Prompt Injection Attacks by Referencing the Executed Instruction](https://arxiv.org//abs/2504.20472)

	Yulin Chen, Haoran Li, Yuan Sui, Yue Liu, Yufei He, Yangqiu Song, Bryan Hooi

+ [ReCIT: Reconstructing Full Private Data from Gradient in Parameter-Efficient Fine-Tuning of Large Language Models](https://arxiv.org//abs/2504.20570)

	Jin Xie, Ruishi He, Songze Li, Xiaojun Jia, Shouling Ji

+ [Unlocking User-oriented Pages: Intention-driven Black-box Scanner for Real-world Web Applications](https://arxiv.org//abs/2504.20801)

	Weizhe Wang, Yao Zhang, Kaitai Liang, Guangquan Xu, Hongpeng Bai, Qingyang Yan, Xi Zheng, Bin Wu

+ [Secure Coding with AI, From Creation to Inspection](https://arxiv.org//abs/2504.20814)

	Vladislav Belozerov, Peter J Barclay, Ashkan Sami

# 2025-04-28
+ [GVPO: Group Variance Policy Optimization for Large Language Model Post-Training](https://arxiv.org//abs/2504.19599)

	Kaichen Zhang, Yuzhong Hong, Junwei Bao, Hongfei Jiang, Yang Song, Dingqian Hong, Hui Xiong

+ [From Evidence to Belief: A Bayesian Epistemology Approach to Language Models](https://arxiv.org//abs/2504.19622)

	Minsu Kim, Sangryul Kim, James Thorne

+ [From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review](https://arxiv.org//abs/2504.19678)

	Mohamed Amine Ferrag, Norbert Tihanyi, Merouane Debbah

+ [Can AI Agents Design and Implement Drug Discovery Pipelines?](https://arxiv.org//abs/2504.19912)

	Khachik Smbatyan, Tsolak Ghukasyan, Tigran Aghajanyan, Hovhannes Dabaghyan, Sergey Adamyan, Aram Bughdaryan, Vahagn Altunyan, Gagik Navasardyan, Aram Davtyan, Anush Hakobyan, Aram Gharibyan, Arman Fahradyan, Artur Hakobyan, Hasmik Mnatsakanyan, Narek Ginoyan, Garik Petrosyan

+ [TreeHop: Generate and Filter Next Query Embeddings Efficiently for Multi-hop Question Answering](https://arxiv.org//abs/2504.20114)

	Zhonghao Li, Kunpeng Zhang, Jinghuai Ou, Shuliang Liu, Xuming Hu

+ [AutoP2C: An LLM-Based Agent Framework for Code Repository Generation from Multimodal Content in Academic Papers](https://arxiv.org//abs/2504.20115)

	Zijie Lin, Yiqing Shen, Qilin Cai, He Sun, Jinrui Zhou, Mingjun Xiao

+ [ResearchCodeAgent: An LLM Multi-Agent System for Automated Codification of Research Methodologies](https://arxiv.org//abs/2504.20117)

	Shubham Gandhi, Dhruv Shah, Manasi Patwardhan, Lovekesh Vig, Gautam Shroff

+ [OpenTCM: A GraphRAG-Empowered LLM-based System for Traditional Chinese Medicine Knowledge Retrieval and Diagnosis](https://arxiv.org//abs/2504.20118)

	Jinglin He, Yunqi Guo, Lai Kwan Lam, Waikei Leung, Lixing He, Yuanan Jiang, Chi Chiu Wang, Guoliang Xing, Hongkai Chen

+ [Can LLMs Be Trusted for Evaluating RAG Systems? A Survey of Methods and Datasets](https://arxiv.org//abs/2504.20119)

	Lorenz Brehme, Thomas Ströhle, Ruth Breu

+ [LZ Penalty: An information-theoretic repetition penalty for autoregressive language models](https://arxiv.org//abs/2504.20131)

	Antonio A. Ginart, Naveen Kodali, Jason Lee, Caiming Xiong, Silvio Savarese, John R. Emmons

+ [MICE for CATs: Model-Internal Confidence Estimation for Calibrating Agents with Tools](https://arxiv.org//abs/2504.20168)

	Nishant Subramani, Jason Eisner, Justin Svegliato, Benjamin Van Durme, Yu Su, Sam Thomson

+ [BLADE: Benchmark suite for LLM-driven Automated Design and Evolution of iterative optimisation heuristics](https://arxiv.org//abs/2504.20183)

	Niki van Stein, Anna V. Kononova, Haoran Yin, Thomas Bäck

+ [Prompting LLMs for Code Editing: Struggles and Remedies](https://arxiv.org//abs/2504.20196)

	Daye Nam, Ahmed Omran, Ambar Murillo, Saksham Thakur, Abner Araujo, Marcel Blistein, Alexander Frömmgen, Vincent Hellendoorn, Satish Chandra

+ [Can Large Language Models Learn Formal Logic? A Data-Driven Training and Evaluation Framework](https://arxiv.org//abs/2504.20213)

	Yuan Xia, Akanksha Atrey, Fadoua Khmaissia, Kedar S. Namjoshi

+ [Toward Evaluative Thinking: Meta Policy Optimization with Evolving Reward Models](https://arxiv.org//abs/2504.20157)

	Zae Myung Kim, Chanwoo Park, Vipul Raheja, Dongyeop Kang

+ [LLM-Generated Fake News Induces Truth Decay in News Ecosystem: A Case Study on Neural News Recommendation](https://arxiv.org//abs/2504.20013)

	Beizhe Hu, Qiang Sheng, Juan Cao, Yang Li, Danding Wang

+ [Investigating task-specific prompts and sparse autoencoders for activation monitoring](https://arxiv.org//abs/2504.20271)

	Henk Tillman, Dan Mossing

+ [Security Steerability is All You Need](https://arxiv.org//abs/2504.19521)

	Itay Hazan, Idan Habler, Ron Bitton, Itsik Mantin

+ [The Automation Advantage in AI Red Teaming](https://arxiv.org//abs/2504.19855)

	Rob Mulla, Ads Dawson, Vincent Abruzzon, Brian Greunke, Nick Landers, Brad Palm, Will Pearce

# 2025-04-27
+ [GenTorrent: Scaling Large Language Model Serving with An Overley Network](https://arxiv.org//abs/2504.20101)

	Fei Fang, Yifan Hua, Shengze Wang, Ruilin Zhou, Yi Liu, Chen Qian, Xiaoxue Zhang

+ [Adaptive Helpfulness-Harmlessness Alignment with Preference Vectors](https://arxiv.org//abs/2504.20106)

	Ren-Wei Liang, Chin-Ting Hsu, Chan-Hung Yu, Saransh Agrawal, Shih-Cheng Huang, Shang-Tse Chen, Kuan-Hao Huang, Shao-Hua Sun

+ [Unified Multi-Task Learning & Model Fusion for Efficient Language Model Guardrailing](https://arxiv.org//abs/2504.19333)

	James O' Neill, Santhosh Subramanian, Eric Lin, Vaikkunth Mugunthan

+ [Doxing via the Lens: Revealing Privacy Leakage in Image Geolocation for Agentic Multi-Modal Large Reasoning Model](https://arxiv.org//abs/2504.19373)

	Weidi Luo, Qiming Zhang, Tianyu Lu, Xiaogeng Liu, Yue Zhao, Zhen Xiang, Chaowei Xiao

# 2025-04-26
+ [A Vision for Auto Research with LLM Agents](https://arxiv.org//abs/2504.18765)

	Chengwei Liu, Chong Wang, Jiayue Cao, Jingquan Ge, Kun Wang, Lvye Zhang, Ming-Ming Cheng, Penghai Zhao, Tianlin Li, Xiaojun Jia, Xiang Li, Xinfeng Li, Yang Liu, Yebo Feng, Yihao Huang, Yijia Xu, Yuqiang Sun, Zhenhong Zhou, Zhengzi Xu

+ [Generative to Agentic AI: Survey, Conceptualization, and Challenges](https://arxiv.org//abs/2504.18875)

	Johannes Schneider

+ [MATCHA: Can Multi-Agent Collaboration Build a Trustworthy Conversational Recommender?](https://arxiv.org//abs/2504.20094)

	Zheng Hui, Xiaokai Wei, Yexi Jiang, Kevin Gao, Chen Wang, Frank Ong, Se-eun Yoon, Rachit Pareek, Michelle Gong

# 2025-04-25
+ [MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind](https://arxiv.org//abs/2504.18039)

	Zheng Zhang, Nuoqian Xiao, Qi Chai, Deheng Ye, Hao Wang

+ [Reason Like a Radiologist: Chain-of-Thought and Reinforcement Learning for Verifiable Report Generation](https://arxiv.org//abs/2504.18453)

	Peiyuan Jing, Kinhei Lee, Zhenxuan Zhang, Huichi Zhou, Zhengqing Yuan, Zhifan Gao, Lei Zhu, Giorgos Papanastasiou, Yingying Fang, Guang Yang

+ [Scaling Laws For Scalable Oversight](https://arxiv.org//abs/2504.18530)

	Joshua Engels, David D. Baek, Subhash Kantamneni, Max Tegmark

+ [RAG LLMs are Not Safer: A Safety Analysis of Retrieval-Augmented Generation for Large Language Models](https://arxiv.org//abs/2504.18041)

	Bang An, Shiyue Zhang, Mark Dredze

+ [PropRAG: Guiding Retrieval with Beam Search over Proposition Paths](https://arxiv.org//abs/2504.18070)

	Jingjin Wang

+ [Stabilizing Reasoning in Medical LLMs with Continued Pretraining and Reasoning Preference Optimization](https://arxiv.org//abs/2504.18080)

	Wataru Kawakami, Keita Suzuki, Junichiro Iwasawa

+ [Random-Set Large Language Models](https://arxiv.org//abs/2504.18085)

	Muhammad Mubashar, Shireen Kudukkil Manchingal, Fabio Cuzzolin

+ [Application and Optimization of Large Models Based on Prompt Tuning for Fact-Check-Worthiness Estimation](https://arxiv.org//abs/2504.18104)

	Yinglong Yu, Hao Shen, Zhengyi Lyu, Qi He

+ [Evaluating Evaluation Metrics -- The Mirage of Hallucination Detection](https://arxiv.org//abs/2504.18114)

	Atharva Kulkarni, Yuan Zhang, Joel Ruben Antony Moniz, Xiou Ge, Bo-Hsiang Tseng, Dhivya Piraviperumal, Swabha Swayamdipta, Hong Yu

+ [Efficient Single-Pass Training for Multi-Turn Reasoning](https://arxiv.org//abs/2504.18246)

	Ritesh Goru, Shanay Mehta, Prateek Jain

+ [Towards Adaptive Software Agents for Debugging](https://arxiv.org//abs/2504.18316)

	Yacine Majdoub, Eya Ben Charrada, Haifa Touati

+ [Comparing Uncertainty Measurement and Mitigation Methods for Large Language Models: A Systematic Review](https://arxiv.org//abs/2504.18346)

	Toghrul Abbasli, Kentaroh Toyoda, Yuan Wang, Leon Witt, Muhammad Asif Ali, Yukai Miao, Dan Li, Qingsong Wei

+ [LLMpatronous: Harnessing the Power of LLMs For Vulnerability Detection](https://arxiv.org//abs/2504.18423)

	Rajesh Yarra

+ [Fast-Slow Thinking for Large Vision-Language Model Reasoning](https://arxiv.org//abs/2504.18458)

	Wenyi Xiao, Leilei Gan, Weilong Dai, Wanggui He, Ziwei Huang, Haoyuan Li, Fangxun Shu, Zhelun Yu, Peng Zhang, Hao Jiang, Fei Wu

+ [Improving LLM Personas via Rationalization with Psychological Scaffolds](https://arxiv.org//abs/2504.17993)

	Brihi Joshi, Xiang Ren, Swabha Swayamdipta, Rik Koncel-Kedziorski, Tim Paek

+ [DREAM: Disentangling Risks to Enhance Safety Alignment in Multimodal Large Language Models](https://arxiv.org//abs/2504.18053)

	Jianyu Liu, Hangyu Guo, Ranjie Duan, Xingyuan Bu, Yancheng He, Shilong Li, Hui Huang, Jiaheng Liu, Yucheng Wang, Chenchen Jing, Xingwei Qu, Xiao Zhang, Yingshui Tan, Yanan Wu, Jihao Gu, Yangguang Li, Jianke Zhu

+ [Even Small Reasoners Should Quote Their Sources: Introducing the Pleias-RAG Model Family](https://arxiv.org//abs/2504.18225)

	Pierre-Carl Langlais, Pavel Chizhov, Mattia Nee, Carlos Rosas Hinostroza, Matthieu Delsart, Irène Girard, Othman Hicheur, Anastasia Stasenko, Ivan P. Yamshchikov

+ [MAGI: Multi-Agent Guided Interview for Psychiatric Assessment](https://arxiv.org//abs/2504.18260)

	Guanqun Bi, Zhuang Chen, Zhoufu Liu, Hongkai Wang, Xiyao Xiao, Yuqiang Xie, Wen Zhang, Yongkang Huang, Yuxuan Chen, Libiao Peng, Yi Feng, Minlie Huang

+ [Auto-SLURP: A Benchmark Dataset for Evaluating Multi-Agent Frameworks in Smart Personal Assistant](https://arxiv.org//abs/2504.18373)

	Lei Shen, Xiaoyu Shen

+ [Expressing stigma and inappropriate responses prevents LLMs from safely replacing mental health providers](https://arxiv.org//abs/2504.18412)

	Jared Moore, Declan Grabb, William Agnew, Kevin Klyman, Stevie Chancellor, Desmond C. Ong, Nick Haber

+ [BitNet v2: Native 4-bit Activations with Hadamard Transformation for 1-bit LLMs](https://arxiv.org//abs/2504.18415)

	Hongyu Wang, Shuming Ma, Furu Wei

+ [PolyMath: Evaluating Mathematical Reasoning in Multilingual Contexts](https://arxiv.org//abs/2504.18428)

	Yiming Wang, Pei Zhang, Jialong Tang, Haoran Wei, Baosong Yang, Rui Wang, Chenshu Sun, Feitong Sun, Jiran Zhang, Junxuan Wu, Qiqian Cang, Yichang Zhang, Fei Huang, Junyang Lin, Fei Huang, Jingren Zhou

+ [Investigating Co-Constructive Behavior of Large Language Models in Explanation Dialogues](https://arxiv.org//abs/2504.18483)

	Leandra Fichtel, Maximilian Spliethöver, Eyke Hüllermeier, Patricia Jimenez, Nils Klowait, Stefan Kopp, Axel-Cyrille Ngonga Ngomo, Amelie Robrecht, Ingrid Scharlau, Lutz Terfloth, Anna-Lisa Vollmer, Henning Wachsmuth

+ [TRACE Back from the Future: A Probabilistic Reasoning Approach to Controllable Language Generation](https://arxiv.org//abs/2504.18535)

	Gwen Yidou Weng, Benjie Wang, Guy Van den Broeck

+ [SMARTFinRAG: Interactive Modularized Financial RAG Benchmark](https://arxiv.org//abs/2504.18024)

	Yiwei Zha

+ [Adversarial Attacks on LLM-as-a-Judge Systems: Insights from Prompt Injections](https://arxiv.org//abs/2504.18333)

	Narek Maloyan, Dmitry Namiot

+ [Revisiting Data Auditing in Large Vision-Language Models](https://arxiv.org//abs/2504.18349)

	Hongyu Zhu, Sichu Liang, Wenwen Wang, Boheng Li, Tongxin Yuan, Fangqi Li, ShiLin Wang, Zhuosheng Zhang

+ [Think, Prune, Train, Improve: Scaling Reasoning without Scaling Models](https://arxiv.org//abs/2504.18116)

	Caia Costello, Simon Guo, Anna Goldie, Azalia Mirhoseini

+ [DualRAG: A Dual-Process Approach to Integrate Reasoning and Retrieval for Multi-Hop Question Answering](https://arxiv.org//abs/2504.18243)

	Rong Cheng, Jinyi Liu, YAN ZHENG, Fei Ni, Jiazhen Du, Hangyu Mao, Fuzheng Zhang, Bo Wang, Jianye HAO

+ [Studying Small Language Models with Susceptibilities](https://arxiv.org//abs/2504.18274)

	Garrett Baker, George Wang, Jesse Hoogland, Daniel Murfet

+ [Streaming, Fast and Slow: Cognitive Load-Aware Streaming for Efficient LLM Serving](https://arxiv.org//abs/2504.17999)

	Chang Xiao, Brenda Yang

+ [NoEsis: Differentially Private Knowledge Transfer in Modular LLM Adaptation](https://arxiv.org//abs/2504.18147)

	Rob Romijnders, Stefanos Laskaridis, Ali Shahin Shamsabadi, Hamed Haddadi

+ [Automating Function-Level TARA for Automotive Full-Lifecycle Security](https://arxiv.org//abs/2504.18083)

	Yuqiao Yang, Yongzhao Zhang, Wenhao Liu, Jun Li, Pengtao Shi, DingYu Zhong, Jie Yang, Ting Chen, Sheng Cao, Yuntao Ren, Yongyue Wu, Xiaosong Zhang

+ [ThreMoLIA: Threat Modeling of Large Language Model-Integrated Applications](https://arxiv.org//abs/2504.18369)

	Felix Viktor Jedrzejewski, Davide Fucci, Oleksandr Adamov

+ [Proof-of-TBI -- Fine-Tuned Vision Language Model Consortium and OpenAI-o3 Reasoning LLM-Based Medical Diagnosis Support System for Mild Traumatic Brain Injury (TBI) Prediction](https://arxiv.org//abs/2504.18671)

	Ross Gore, Eranga Bandara, Sachin Shetty, Alberto E. Musto, Pratip Rana, Ambrosio Valencia-Romero, Christopher Rhea, Lobat Tayebi, Heather Richter, Atmaram Yarlagadda, Donna Edmonds, Steven Wallace, Donna Broshek

+ [Evolution of AI in Education: Agentic Workflows](https://arxiv.org//abs/2504.20082)

	Firuz Kamalov, David Santandreu Calonge, Linda Smail, Dilshod Azizov, Dimple R. Thadani, Theresa Kwong, Amara Atif

+ [Spark: A System for Scientifically Creative Idea Generation](https://arxiv.org//abs/2504.20090)

	Aishik Sanyal, Samuel Schapiro, Sumuk Shashidhar, Royce Moon, Lav R. Varshney, Dilek Hakkani-Tur

+ [A model and package for German ColBERT](https://arxiv.org//abs/2504.20083)

	Thuong Dang, Qiqi Chen

# 2025-04-24
+ [Assessing the Capability of Large Language Models for Domain-Specific Ontology Generation](https://arxiv.org//abs/2504.17402)

	Anna Sofia Lippolis, Mohammad Javad Saeedizade, Robin Keskisarkka, Aldo Gangemi, Eva Blomqvist, Andrea Giovanni Nuzzolese

+ [Towards Machine-Generated Code for the Resolution of User Intentions](https://arxiv.org//abs/2504.17531)

	Justus Flerlage, Ilja Behnke, Odej Kao

+ [Auditing the Ethical Logic of Generative AI Models](https://arxiv.org//abs/2504.17544)

	W. Russell Neuman, Chad Coleman, Ali Dasdan, Safinah Ali, Manan Shah

+ [Automatically Generating Rules of Malicious Software Packages via Large Language Model](https://arxiv.org//abs/2504.17198)

	XiangRui Zhang, HaoYu Chen, Yongzhong He, Wenjia Niu, Qiang Li

+ [FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation](https://arxiv.org//abs/2504.17311)

	Yulia Otmakhova, Hung Thinh Truong, Rahmad Mahendra, Zenan Zhai, Rongxin Zhu, Daniel Beck, Jey Han Lau

+ [LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams](https://arxiv.org//abs/2504.17366)

	Yongxuan Wu, Runyu Chen, Peiyu Liu, Hongjin Qian

+ [Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks](https://arxiv.org//abs/2504.17421)

	Yang Liu, Bingjie Yan, Tianyuan Zou, Jianqing Zhang, Zixuan Gu, Jianbing Ding, Xidong Wang, Jingyi Li, Xiaozhou Ye, Ye Ouyang, Qiang Yang, Ya-Qin Zhang

+ [Towards Leveraging Large Language Model Summaries for Topic Modeling in Source Code](https://arxiv.org//abs/2504.17426)

	Michele Carissimi, Martina Saletta, Claudio Ferretti

+ [HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models](https://arxiv.org//abs/2504.17449)

	Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, Qin Xie, Guiming Xie, Xuejian Gong

+ [HalluLens: LLM Hallucination Benchmark](https://arxiv.org//abs/2504.17550)

	Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung

+ [Towards a HIPAA Compliant Agentic AI System in Healthcare](https://arxiv.org//abs/2504.17669)

	Subash Neupane, Shaswata Mitra, Sudip Mittal, Shahram Rahimi

+ [INSIGHT: Bridging the Student-Teacher Gap in Times of Large Language Models](https://arxiv.org//abs/2504.17677)

	Jarne Thys, Sebe Vanbrabant, Davy Vanacken, Gustavo Rovelo Ruiz

+ [Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks](https://arxiv.org//abs/2504.17685)

	Haru-Tada Sato, Fuka Matsuzaki, Jun-ichiro Takahashi

+ [Multilingual Performance Biases of Large Language Models in Education](https://arxiv.org//abs/2504.17720)

	Vansh Gupta, Sankalan Pal Chowdhury, Vilém Zouhar, Donya Rooein, Mrinmaya Sachan

+ [Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning](https://arxiv.org//abs/2504.17192)

	Minju Seo, Jinheon Baek, Seongyun Lee, Sung Ju Hwang

+ [A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation](https://arxiv.org//abs/2504.17200)

	Yangxinyu Xie, Bowen Jiang, Tanwi Mallick, Joshua David Bergerson, John K. Hutchison, Duane R. Verner, Jordan Branham, M. Ross Alexander, Robert B. Ross, Yan Feng, Leslie-Anne Levy, Weijie Su, Camillo J. Taylor

+ [Does Knowledge Distillation Matter for Large Language Model based Bundle Generation?](https://arxiv.org//abs/2504.17220)

	Kaidong Feng, Zhu Sun, Jie Yang, Hui Fang, Xinghua Qu, Wenyuan Liu

+ [Crisp: Cognitive Restructuring of Negative Thoughts through Multi-turn Supportive Dialogues](https://arxiv.org//abs/2504.17238)

	Jinfeng Zhou, Yuxuan Chen, Jianing Yin, Yongkang Huang, Yihan Shi, Xikun Zhang, Libiao Peng, Rongsheng Zhang, Tangjie Lv, Zhipeng Hu, Hongning Wang, Minlie Huang

+ [CoheMark: A Novel Sentence-Level Watermark for Enhanced Text Quality](https://arxiv.org//abs/2504.17309)

	Junyan Zhang, Shuliang Liu, Aiwei Liu, Yubo Gao, Jungang Li, Xiaojie Gu, Xuming Hu

+ [FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation](https://arxiv.org//abs/2504.17311)

	Yulia Otmakhova, Hung Thinh Truong, Rahmad Mahendra, Zenan Zhai, Rongxin Zhu, Daniel Beck, Jey Han Lau

+ [LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams](https://arxiv.org//abs/2504.17366)

	Yongxuan Wu, Runyu Chen, Peiyu Liu, Hongjin Qian

+ [Unified Attacks to Large Language Model Watermarks: Spoofing and Scrubbing in Unauthorized Knowledge Distillation](https://arxiv.org//abs/2504.17480)

	Xin Yi, Shunfan Zhengc, Linlin Wanga, Xiaoling Wang, Liang He

+ [HalluLens: LLM Hallucination Benchmark](https://arxiv.org//abs/2504.17550)

	Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung

+ [When Does Metadata Conditioning (NOT) Work for Language Model Pre-Training? A Study with Context-Free Grammars](https://arxiv.org//abs/2504.17562)

	Rei Higuchi, Ryotaro Kawata, Naoki Nishikawa, Kazusato Oko, Shoichiro Yamaguchi, Sosuke Kobayashi, Seiya Tokui, Kohei Hayashi, Daisuke Okanohara, Taiji Suzuki

+ [DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training](https://arxiv.org//abs/2504.17565)

	Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li

+ [Evaluating Grounded Reasoning by Code-Assisted Large Language Models for Mathematics](https://arxiv.org//abs/2504.17665)

	Zena Al-Khalili, Nick Howell, Dietrich Klakow

+ [Energy Considerations of Large Language Model Inference and Efficiency Optimizations](https://arxiv.org//abs/2504.17674)

	Jared Fernandez, Clara Na, Vashisth Tiwari, Yonatan Bisk, Sasha Luccioni, Emma Strubell

+ [Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks](https://arxiv.org//abs/2504.17685)

	Haru-Tada Sato, Fuka Matsuzaki, Jun-ichiro Takahashi

+ [Safety in Large Reasoning Models: A Survey](https://arxiv.org//abs/2504.17704)

	Cheng Wang, Yue Liu, Baolong Li, Duzhen Zhang, Zhongzhi Li, Junfeng Fang

+ [Multilingual Performance Biases of Large Language Models in Education](https://arxiv.org//abs/2504.17720)

	Vansh Gupta, Sankalan Pal Chowdhury, Vilém Zouhar, Donya Rooein, Mrinmaya Sachan

+ [The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs](https://arxiv.org//abs/2504.17768)

	Piotr Nawrot, Robert Li, Renjie Huang, Sebastian Ruder, Kelly Marchisio, Edoardo M. Ponti

+ [HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models](https://arxiv.org//abs/2504.17449)

	Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, Qin Xie, Guiming Xie, Xuejian Gong

+ [Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs](https://arxiv.org//abs/2504.17432)

	Tiancheng Gu, Kaicheng Yang, Ziyong Feng, Xingjun Wang, Yanzhao Zhang, Dingkun Long, Yingda Chen, Weidong Cai, Jiankang Deng

+ [Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks](https://arxiv.org//abs/2504.17421)

	Yang Liu, Bingjie Yan, Tianyuan Zou, Jianqing Zhang, Zixuan Gu, Jianbing Ding, Xidong Wang, Jingyi Li, Xiaozhou Ye, Ye Ouyang, Qiang Yang, Ya-Qin Zhang

+ [Towards Robust LLMs: an Adversarial Robustness Measurement Framework](https://arxiv.org//abs/2504.17723)

	Natan Levy, Adiel Ashrov, Guy Katz

+ [Replay to Remember: Retaining Domain Knowledge in Streaming Language Models](https://arxiv.org//abs/2504.17780)

	Sneh Pillai (University of Massachusetts Dartmouth)

+ [High-Fidelity And Complex Test Data Generation For Real-World SQL Code Generation Services](https://arxiv.org//abs/2504.17203)

	Shivasankari Kannan, Yeounoh Chung, Amita Gondi, Tristan Swadell, Fatma Ozcan

+ [Comprehend, Divide, and Conquer: Feature Subspace Exploration via Multi-Agent Hierarchical Reinforcement Learning](https://arxiv.org//abs/2504.17356)

	Weiliang Zhang, Xiaohan Huang, Yi Du, Ziyue Qiao, Qingqing Long, Zhen Meng, Yuanchun Zhou, Meng Xiao

+ [On-Device Qwen2.5: Efficient LLM Inference with Model Compression and Hardware Acceleration](https://arxiv.org//abs/2504.17376)

	Maoyang Xiang, Ramesh Fernando, Bo Wang

+ [L3: DIMM-PIM Integrated Architecture and Coordination for Scalable Long-Context LLM Inference](https://arxiv.org//abs/2504.17584)

	Qingyuan Liu, Liyan Chen, Yanning Yang, Haocheng Wang, Dong Du, Zhigang Mao, Naifeng Jing, Yubin Xia, Haibo Chen

+ [Assessing the Capability of Large Language Models for Domain-Specific Ontology Generation](https://arxiv.org//abs/2504.17402)

	Anna Sofia Lippolis, Mohammad Javad Saeedizade, Robin Keskisarkka, Aldo Gangemi, Eva Blomqvist, Andrea Giovanni Nuzzolese

+ [Towards Machine-Generated Code for the Resolution of User Intentions](https://arxiv.org//abs/2504.17531)

	Justus Flerlage, Ilja Behnke, Odej Kao

+ [Auditing the Ethical Logic of Generative AI Models](https://arxiv.org//abs/2504.17544)

	W. Russell Neuman, Chad Coleman, Ali Dasdan, Safinah Ali, Manan Shah

+ [Automatically Generating Rules of Malicious Software Packages via Large Language Model](https://arxiv.org//abs/2504.17198)

	XiangRui Zhang, HaoYu Chen, Yongzhong He, Wenjia Niu, Qiang Li

+ [NeuralGrok: Accelerate Grokking by Neural Gradient Transformation](https://arxiv.org//abs/2504.17243)

	Xinyu Zhou, Simin Fan, Martin Jaggi, Jie Fu

+ [FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation](https://arxiv.org//abs/2504.17311)

	Yulia Otmakhova, Hung Thinh Truong, Rahmad Mahendra, Zenan Zhai, Rongxin Zhu, Daniel Beck, Jey Han Lau

+ [LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams](https://arxiv.org//abs/2504.17366)

	Yongxuan Wu, Runyu Chen, Peiyu Liu, Hongjin Qian

+ [Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks](https://arxiv.org//abs/2504.17421)

	Yang Liu, Bingjie Yan, Tianyuan Zou, Jianqing Zhang, Zixuan Gu, Jianbing Ding, Xidong Wang, Jingyi Li, Xiaozhou Ye, Ye Ouyang, Qiang Yang, Ya-Qin Zhang

+ [Towards Leveraging Large Language Model Summaries for Topic Modeling in Source Code](https://arxiv.org//abs/2504.17426)

	Michele Carissimi, Martina Saletta, Claudio Ferretti

+ [HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models](https://arxiv.org//abs/2504.17449)

	Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, Qin Xie, Guiming Xie, Xuejian Gong

+ [HalluLens: LLM Hallucination Benchmark](https://arxiv.org//abs/2504.17550)

	Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung

+ [Towards a HIPAA Compliant Agentic AI System in Healthcare](https://arxiv.org//abs/2504.17669)

	Subash Neupane, Shaswata Mitra, Sudip Mittal, Shahram Rahimi

+ [INSIGHT: Bridging the Student-Teacher Gap in Times of Large Language Models](https://arxiv.org//abs/2504.17677)

	Jarne Thys, Sebe Vanbrabant, Davy Vanacken, Gustavo Rovelo Ruiz

+ [Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks](https://arxiv.org//abs/2504.17685)

	Haru-Tada Sato, Fuka Matsuzaki, Jun-ichiro Takahashi

+ [Multilingual Performance Biases of Large Language Models in Education](https://arxiv.org//abs/2504.17720)

	Vansh Gupta, Sankalan Pal Chowdhury, Vilém Zouhar, Donya Rooein, Mrinmaya Sachan

+ [Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning](https://arxiv.org//abs/2504.17192)

	Minju Seo, Jinheon Baek, Seongyun Lee, Sung Ju Hwang

+ [A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation](https://arxiv.org//abs/2504.17200)

	Yangxinyu Xie, Bowen Jiang, Tanwi Mallick, Joshua David Bergerson, John K. Hutchison, Duane R. Verner, Jordan Branham, M. Ross Alexander, Robert B. Ross, Yan Feng, Leslie-Anne Levy, Weijie Su, Camillo J. Taylor

+ [Does Knowledge Distillation Matter for Large Language Model based Bundle Generation?](https://arxiv.org//abs/2504.17220)

	Kaidong Feng, Zhu Sun, Jie Yang, Hui Fang, Xinghua Qu, Wenyuan Liu

+ [Crisp: Cognitive Restructuring of Negative Thoughts through Multi-turn Supportive Dialogues](https://arxiv.org//abs/2504.17238)

	Jinfeng Zhou, Yuxuan Chen, Jianing Yin, Yongkang Huang, Yihan Shi, Xikun Zhang, Libiao Peng, Rongsheng Zhang, Tangjie Lv, Zhipeng Hu, Hongning Wang, Minlie Huang

+ [CoheMark: A Novel Sentence-Level Watermark for Enhanced Text Quality](https://arxiv.org//abs/2504.17309)

	Junyan Zhang, Shuliang Liu, Aiwei Liu, Yubo Gao, Jungang Li, Xiaojie Gu, Xuming Hu

+ [PatientDx: Merging Large Language Models for Protecting Data-Privacy in Healthcare](https://arxiv.org//abs/2504.17360)

	Jose G. Moreno (IRIT-IRIS), Jesus Lovon (IRIT-IRIS), M'Rick Robin-Charlet (UT3), Christine Damase-Michel, Lynda Tamine (IRIT-IRIS)

+ [Unified Attacks to Large Language Model Watermarks: Spoofing and Scrubbing in Unauthorized Knowledge Distillation](https://arxiv.org//abs/2504.17480)

	Xin Yi, Shunfan Zhengc, Linlin Wanga, Xiaoling Wang, Liang He

+ [When Does Metadata Conditioning (NOT) Work for Language Model Pre-Training? A Study with Context-Free Grammars](https://arxiv.org//abs/2504.17562)

	Rei Higuchi, Ryotaro Kawata, Naoki Nishikawa, Kazusato Oko, Shoichiro Yamaguchi, Sosuke Kobayashi, Seiya Tokui, Kohei Hayashi, Daisuke Okanohara, Taiji Suzuki

+ [DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training](https://arxiv.org//abs/2504.17565)

	Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li

+ [Evaluating Grounded Reasoning by Code-Assisted Large Language Models for Mathematics](https://arxiv.org//abs/2504.17665)

	Zena Al-Khalili, Nick Howell, Dietrich Klakow

+ [Energy Considerations of Large Language Model Inference and Efficiency Optimizations](https://arxiv.org//abs/2504.17674)

	Jared Fernandez, Clara Na, Vashisth Tiwari, Yonatan Bisk, Sasha Luccioni, Emma Strubell

+ [Safety in Large Reasoning Models: A Survey](https://arxiv.org//abs/2504.17704)

	Cheng Wang, Yue Liu, Baolong Li, Duzhen Zhang, Zhongzhi Li, Junfeng Fang

+ [Conversational Assistants to support Heart Failure Patients: comparing a Neurosymbolic Architecture with ChatGPT](https://arxiv.org//abs/2504.17753)

	Anuja Tayal, Devika Salunke, Barbara Di Eugenio, Paula Allen-Meares, Eulalia Puig Abril, Olga Garcia, Carolyn Dickens, Andrew Boyd

+ [The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs](https://arxiv.org//abs/2504.17768)

	Piotr Nawrot, Robert Li, Renjie Huang, Sebastian Ruder, Kelly Marchisio, Edoardo M. Ponti

+ [Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs](https://arxiv.org//abs/2504.17432)

	Tiancheng Gu, Kaicheng Yang, Ziyong Feng, Xingjun Wang, Yanzhao Zhang, Dingkun Long, Yingda Chen, Weidong Cai, Jiankang Deng

+ [Towards Robust LLMs: an Adversarial Robustness Measurement Framework](https://arxiv.org//abs/2504.17723)

	Natan Levy, Adiel Ashrov, Guy Katz

+ [Replay to Remember: Retaining Domain Knowledge in Streaming Language Models](https://arxiv.org//abs/2504.17780)

	Sneh Pillai (University of Massachusetts Dartmouth)

+ [High-Fidelity And Complex Test Data Generation For Real-World SQL Code Generation Services](https://arxiv.org//abs/2504.17203)

	Shivasankari Kannan, Yeounoh Chung, Amita Gondi, Tristan Swadell, Fatma Ozcan

+ [On-Device Qwen2.5: Efficient LLM Inference with Model Compression and Hardware Acceleration](https://arxiv.org//abs/2504.17376)

	Maoyang Xiang, Ramesh Fernando, Bo Wang

+ [L3: DIMM-PIM Integrated Architecture and Coordination for Scalable Long-Context LLM Inference](https://arxiv.org//abs/2504.17584)

	Qingyuan Liu, Liyan Chen, Yanning Yang, Haocheng Wang, Dong Du, Zhigang Mao, Naifeng Jing, Yubin Xia, Haibo Chen

+ [LLM Agent Swarm for Hypothesis-Driven Drug Discovery](https://arxiv.org//abs/2504.17967)

	Kevin Song, Andrew Trotter, Jake Y. Chen

+ [Data-Driven Calibration of Prediction Sets in Large Vision-Language Models Based on Inductive Conformal Prediction](https://arxiv.org//abs/2504.17671)

	Yuanchang Ye, Weiyan Wen

+ [Unsupervised Corpus Poisoning Attacks in Continuous Space for Dense Retrieval](https://arxiv.org//abs/2504.17884)

	Yongkang Li, Panagiotis Eustratiadis, Simon Lupart, Evangelos Kanoulas

+ [Toward a Human-Centered Evaluation Framework for Trustworthy LLM-Powered GUI Agents](https://arxiv.org//abs/2504.17934)

	Chaoran Chen, Zhiping Zhang, Ibrahim Khalilov, Bingcan Guo, Simret A Gebreegziabher, Yanfang Ye, Ziang Xiao, Yaxing Yao, Tianshi Li, Toby Jia-Jun Li

+ [Collaborating Action by Action: A Multi-agent LLM Framework for Embodied Reasoning](https://arxiv.org//abs/2504.17950)

	Isadora White, Kolby Nottingham, Ayush Maniar, Max Robinson, Hansen Lillemark, Mehul Maheshwari, Lianhui Qin, Prithviraj Ammanabrolu

+ [DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training](https://arxiv.org//abs/2504.17565)

	Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li

+ [Training Large Language Models to Reason via EM Policy Gradient](https://arxiv.org//abs/2504.18587)

	Tianbing Xu

+ [BadMoE: Backdooring Mixture-of-Experts LLMs via Optimizing Routing Triggers and Infecting Dormant Experts](https://arxiv.org//abs/2504.18598)

	Qingyue Wang, Qi Pang, Xixun Lin, Shuai Wang, Daoyuan Wu

+ [RAGEN: Understanding Self-Evolution in LLM Agents via Multi-Turn Reinforcement Learning](https://arxiv.org//abs/2504.20073)

	Zihan Wang, Kangrui Wang, Qineng Wang, Pingyue Zhang, Linjie Li, Zhengyuan Yang, Kefan Yu, Minh Nhat Nguyen, Licheng Liu, Eli Gottlieb, Monica Lam, Yiping Lu, Kyunghyun Cho, Jiajun Wu, Li Fei-Fei, Lijuan Wang, Yejin Choi, Manling Li

+ [Tempo: Application-aware LLM Serving with Mixed SLO Requirements](https://arxiv.org//abs/2504.20068)

	Wei Zhang, Zhiyu Wu, Yi Mu, Banruo Liu, Myungjin Lee, Fan Lai

# 2025-04-23
+ [Steering the CensorShip: Uncovering Representation Vectors for LLM "Thought" Control](https://arxiv.org//abs/2504.17130)

	Hannah Cyberey, David Evans

+ [Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification](https://arxiv.org//abs/2504.17017)

	Balaji Rao, William Eiers, Carlo Lipizzi

+ [Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments](https://arxiv.org//abs/2504.17087)

	Yuran Li, Jama Hussein Mohamud, Chongren Sun, Di Wu, Benoit Boulet

+ [Backslash: Rate Constrained Optimized Training of Large Language Models](https://arxiv.org//abs/2504.16968)

	Jun Wu, Jiangtao Wen, Yuxing Han

+ [(Im)possibility of Automated Hallucination Detection in Large Language Models](https://arxiv.org//abs/2504.17004)

	Amin Karbasi, Omar Montasser, John Sous, Grigoris Velegkas

+ [Robo-Troj: Attacking LLM-based Task Planners](https://arxiv.org//abs/2504.17070)

	Mohaiminul Al Nahian, Zainab Altaweel, David Reitano, Sabbir Ahmed, Saumitra Lohokare, Shiqi Zhang, Adnan Siraj Rakin

+ [MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation](https://arxiv.org//abs/2504.17137)

	Chanhee Park, Hyeonseok Moon, Chanjun Park, Heuiseok Lim

+ [Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark](https://arxiv.org//abs/2504.16427)

	Hanlei Zhang, Zhuohang Li, Yeshuang Zhu, Hua Xu, Peiwu Wang, Haige Zhu, Jie Zhou, Jinchao Zhang

+ [Optimizing LLMs for Italian: Reducing Token Fertility and Enhancing Efficiency Through Vocabulary Adaptation](https://arxiv.org//abs/2504.17025)

	Luca Moroni, Giovanni Puccetti, Pere-Lluis Huguet Cabot, Andrei Stefan Bejgu, Edoardo Barba, Alessio Miaschi, Felice Dell'Orletta, Andrea Esuli, Roberto Navigli

+ [Do Words Reflect Beliefs? Evaluating Belief Depth in Large Language Models](https://arxiv.org//abs/2504.17052)

	Shariar Kabir, Kevin Esterling, Yue Dong

+ [Agree to Disagree? A Meta-Evaluation of LLM Misgendering](https://arxiv.org//abs/2504.17075)

	Arjun Subramonian, Vagrant Gautam, Preethi Seshadri, Dietrich Klakow, Kai-Wei Chang, Yizhou Sun

+ [How Individual Traits and Language Styles Shape Preferences In Open-ended User-LLM Interaction: A Preliminary Study](https://arxiv.org//abs/2504.17083)

	Rendi Chevi, Kentaro Inui, Thamar Solorio, Alham Fikri Aji

+ [Co-CoT: A Prompt-Based Framework for Collaborative Chain-of-Thought Reasoning](https://arxiv.org//abs/2504.17091)

	Seunghyun Yoo

+ [Steering the CensorShip: Uncovering Representation Vectors for LLM "Thought" Control](https://arxiv.org//abs/2504.17130)

	Hannah Cyberey, David Evans

+ [MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation](https://arxiv.org//abs/2504.17137)

	Chanhee Park, Hyeonseok Moon, Chanjun Park, Heuiseok Lim

+ [(Im)possibility of Automated Hallucination Detection in Large Language Models](https://arxiv.org//abs/2504.17004)

	Amin Karbasi, Omar Montasser, John Sous, Grigoris Velegkas

+ [Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark](https://arxiv.org//abs/2504.16427)

	Hanlei Zhang, Zhuohang Li, Yeshuang Zhu, Hua Xu, Peiwu Wang, Haige Zhu, Jie Zhou, Jinchao Zhang

+ [Backslash: Rate Constrained Optimized Training of Large Language Models](https://arxiv.org//abs/2504.16968)

	Jun Wu, Jiangtao Wen, Yuxing Han

+ [Safety Pretraining: Toward the Next Generation of Safe AI](https://arxiv.org//abs/2504.16980)

	Pratyush Maini, Sachin Goyal, Dylan Sam, Alex Robey, Yash Savani, Yiding Jiang, Andy Zou, Zacharcy C. Lipton, J. Zico Kolter

+ [Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification](https://arxiv.org//abs/2504.17017)

	Balaji Rao, William Eiers, Carlo Lipizzi

+ [Exploring How LLMs Capture and Represent Domain-Specific Knowledge](https://arxiv.org//abs/2504.16871)

	Mirian Hipolito Garcia, Camille Couturier, Daniel Madrigal Diaz, Ankur Mallick, Anastasios Kyrillidis, Robert Sim, Victor Ruhle, Saravan Rajmohan


+ [Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments](https://arxiv.org//abs/2504.17087)

	Yuran Li, Jama Hussein Mohamud, Chongren Sun, Di Wu, Benoit Boulet

+ [Backslash: Rate Constrained Optimized Training of Large Language Models](https://arxiv.org//abs/2504.16968)

	Jun Wu, Jiangtao Wen, Yuxing Han

+ [(Im)possibility of Automated Hallucination Detection in Large Language Models](https://arxiv.org//abs/2504.17004)

	Amin Karbasi, Omar Montasser, John Sous, Grigoris Velegkas

+ [Robo-Troj: Attacking LLM-based Task Planners](https://arxiv.org//abs/2504.17070)

	Mohaiminul Al Nahian, Zainab Altaweel, David Reitano, Sabbir Ahmed, Saumitra Lohokare, Shiqi Zhang, Adnan Siraj Rakin

+ [MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation](https://arxiv.org//abs/2504.17137)

	Chanhee Park, Hyeonseok Moon, Chanjun Park, Heuiseok Lim

+ [Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark](https://arxiv.org//abs/2504.16427)

	Hanlei Zhang, Zhuohang Li, Yeshuang Zhu, Hua Xu, Peiwu Wang, Haige Zhu, Jie Zhou, Jinchao Zhang

+ [Optimizing LLMs for Italian: Reducing Token Fertility and Enhancing Efficiency Through Vocabulary Adaptation](https://arxiv.org//abs/2504.17025)

	Luca Moroni, Giovanni Puccetti, Pere-Lluis Huguet Cabot, Andrei Stefan Bejgu, Edoardo Barba, Alessio Miaschi, Felice Dell'Orletta, Andrea Esuli, Roberto Navigli

+ [Do Words Reflect Beliefs? Evaluating Belief Depth in Large Language Models](https://arxiv.org//abs/2504.17052)

	Shariar Kabir, Kevin Esterling, Yue Dong

+ [Agree to Disagree? A Meta-Evaluation of LLM Misgendering](https://arxiv.org//abs/2504.17075)

	Arjun Subramonian, Vagrant Gautam, Preethi Seshadri, Dietrich Klakow, Kai-Wei Chang, Yizhou Sun

+ [How Individual Traits and Language Styles Shape Preferences In Open-ended User-LLM Interaction: A Preliminary Study](https://arxiv.org//abs/2504.17083)

	Rendi Chevi, Kentaro Inui, Thamar Solorio, Alham Fikri Aji

+ [Co-CoT: A Prompt-Based Framework for Collaborative Chain-of-Thought Reasoning](https://arxiv.org//abs/2504.17091)

	Seunghyun Yoo

+ [Steering the CensorShip: Uncovering Representation Vectors for LLM "Thought" Control](https://arxiv.org//abs/2504.17130)

	Hannah Cyberey, David Evans

+ [Safety Pretraining: Toward the Next Generation of Safe AI](https://arxiv.org//abs/2504.16980)

	Pratyush Maini, Sachin Goyal, Dylan Sam, Alex Robey, Yash Savani, Yiding Jiang, Andy Zou, Zacharcy C. Lipton, J. Zico Kolter

+ [Exploring How LLMs Capture and Represent Domain-Specific Knowledge](https://arxiv.org//abs/2504.16871)

	Mirian Hipolito Garcia, Camille Couturier, Daniel Madrigal Diaz, Ankur Mallick, Anastasios Kyrillidis, Robert Sim, Victor Ruhle, Saravan Rajmohan

+ [EduBot -- Can LLMs Solve Personalized Learning and Programming Assignments?](https://arxiv.org//abs/2504.17824)

	Yibin Wang, Jiaxi Xie, Lakshminarayanan Subramanian

+ [BackSlash: Rate Constrained Optimized Training of Large Language Models](https://arxiv.org//abs/2504.16968)

	Jun Wu, Jiangtao Wen, Yuxing Han

+ [PARD: Accelerating LLM Inference with Low-Cost PARallel Draft Model Adaptation](https://arxiv.org//abs/2504.18583)

	Zihao An, Huajun Bai, Ziqiong Liu, Dong Li, Emad Barsoum

# 2025-04-22
+ [Impact of Noise on LLM-Models Performance in Abstraction and Reasoning Corpus (ARC) Tasks with Model Temperature Considerations](https://arxiv.org//abs/2504.15903)

	Nikhil Khandalkar, Pavan Yadav, Krishna Shinde, Lokesh B. Ramegowda, Rajarshi Das


+ [CAPO: Cost-Aware Prompt Optimization](https://arxiv.org//abs/2504.16005)

	Tom Zehle, Moritz Schlager, Timo Heiß, Matthias Feurer

+ [Pre-DPO: Improving Data Utilization in Direct Preference Optimization Using a Guiding Reference Model](https://arxiv.org//abs/2504.15843)

	Junshu Pan, Wei Shen, Shulin Huang, Qiji Zhou, Yue Zhang

+ [BELL: Benchmarking the Explainability of Large Language Models](https://arxiv.org//abs/2504.18572)

	Syed Quiser Ahmed, Bharathi Vokkaliga Ganesh, Jagadish Babu P, Karthick Selvaraj, ReddySiva Naga Parvathi Devi, Sravya Kappala

+ [Large Language Model Empowered Privacy-Protected Framework for PHI Annotation in Clinical Notes](https://arxiv.org//abs/2504.18569)

	Guanchen Wu, Linzhi Zheng, Han Xie, Zhen Xiang, Jiaying Lu, Darren Liu, Delgersuren Bold, Bo Li, Xiao Hu, Carl Yang

+ [Understanding the Skill Gap in Recurrent Language Models: The Role of the Gather-and-Aggregate Mechanism](https://arxiv.org//abs/2504.18574)

	Aviv Bick, Eric Xing, Albert Gu

+ [WASP: Benchmarking Web Agent Security Against Prompt Injection Attacks](https://arxiv.org//abs/2504.18575)

	Ivan Evtimov, Arman Zharmagambetov, Aaron Grattafiori, Chuan Guo, Kamalika Chaudhuri

# 2025-04-21
+ [Intrinsic Barriers to Explaining Deep Foundation Models](https://arxiv.org//abs/2504.16948)

	Zhen Tan, Huan Liu

+ [KeyDiff: Key Similarity-Based KV Cache Eviction for Long-Context LLM Inference in Resource-Constrained Environments](https://arxiv.org//abs/2504.15364)

	Junyoung Park, Dalton Jones, Matt J Morse, Raghavv Goel, Mingu Lee, Chris Lott

+ [MARFT: Multi-Agent Reinforcement Fine-Tuning](https://arxiv.org//abs/2504.16129)

	Junwei Liao, Muning Wen, Jun Wang, Weinan Zhang

+ [Efficient Pretraining Length Scaling](https://arxiv.org//abs/2504.14992)

	Bohong Wu, Shen Yan, Sijun Zhang, Jianqiao Lu, Yutao Zeng, Ya Wang, Xun Zhou

+ [MARFT: Multi-Agent Reinforcement Fine-Tuning](https://arxiv.org//abs/2504.16129)

	Junwei Liao, Muning Wen, Jun Wang, Weinan Zhang


+ [DualBreach: Efficient Dual-Jailbreaking via Target-Driven Initialization and Multi-Target Optimization](https://arxiv.org//abs/2504.18564)

	Xinzhe Huang, Kedong Xiu, Tianhang Zheng, Churui Zeng, Wangze Ni, Zhan Qiin, Kui Ren, Chun Chen

+ [RepliBench: Evaluating the autonomous replication capabilities of language model agents](https://arxiv.org//abs/2504.18565)

	Sid Black, Asa Cooper Stickland, Jake Pencharz, Oliver Sourbut, Michael Schmatz, Jay Bailey, Ollie Matthews, Ben Millwood, Alex Remedios, Alan Cooney

# 2025-04-20
+ [UFO2: The Desktop AgentOS](https://arxiv.org//abs/2504.14603)

	Chaoyun Zhang, He Huang, Chiming Ni, Jian Mu, Si Qin, Shilin He, Lu Wang, Fangkai Yang, Pu Zhao, Chao Du, Liqun Li, Yu Kang, Zhao Jiang, Suzhen Zheng, Rujia Wang, Jiaxu Qian, Minghua Ma, Jian-Guang Lou, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang

+ [Towards Optimal Circuit Generation: Multi-Agent Collaboration Meets Collective Intelligence](https://arxiv.org//abs/2504.14625)

	Haiyan Qin, Jiahao Feng, Xiaotong Feng, Wei W. Xing, Wang Kang

# 2025-04-19
+ [TALES: Text Adventure Learning Environment Suite](https://arxiv.org//abs/2504.14128)

	Christopher Zhang Cui, Xingdi Yuan, Ziang Xiao, Prithviraj Ammanabrolu, Marc-Alexandre Côté



+ [Mind the Language Gap: Automated and Augmented Evaluation of Bias in LLMs for High- and Low-Resource Languages](https://arxiv.org//abs/2504.18560)

	Alessio Buscemi, Cédric Lothritz, Sergio Morales, Marcos Gomez-Vazquez, Robert Clarisó, Jordi Cabot, German Castignani

# 2025-04-18
+ [SCRAG: Social Computing-Based Retrieval Augmented Generation for Community Response Forecasting in Social Media Environments](https://arxiv.org//abs/2504.16947)

	Dachun Sun, You Lyu, Jinning Li, Yizhuo Chen, Tianshi Wang, Tomoyoshi Kimura, Tarek Abdelzaher

+ [From Large to Super-Tiny: End-to-End Optimization for Cost-Efficient LLMs](https://arxiv.org//abs/2504.13471)

	Jiliang Ni, Jiachen Pu, Zhongyi Yang, Kun Zhou, Hui Wang, Xiaoliang Xiao, Dakui Wang, Xin Li, Jingfeng Luo, Conggang Hu


# 2025-04-17
+ [GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning](https://arxiv.org//abs/2504.12597)

	Liangyu Xu, Yingxiu Zhao, Jingyun Wang, Yingyao Wang, Bu Pi, Chen Wang, Mingliang Zhang, Jihao Gu, Xiang Li, Xiaoyong Zhu, Jun Song, Bo Zheng



# 2025-04-16
+ [Activated LoRA: Fine-tuned LLMs for Intrinsics](https://arxiv.org//abs/2504.12397)

	Kristjan Greenewald, Luis Lastras, Thomas Parnell, Vraj Shah, Lucian Popa, Giulio Zizzo, Chulaka Gunasekara, Ambrish Rawat, David Cox

# 2025-04-15
+ [Looking beyond the next token](https://arxiv.org//abs/2504.11336)

	Abitha Thankaraj, Yiding Jiang, J. Zico Kolter, Yonatan Bisk

+ [Teaching Large Language Models to Reason through Learning and Forgetting](https://arxiv.org//abs/2504.11364)

	Tianwei Ni, Allen Nie, Sapana Chaudhary, Yao Liu, Huzefa Rangwala, Rasool Fakoor

+ [Nemotron-CrossThink: Scaling Self-Learning beyond Math Reasoning](https://arxiv.org//abs/2504.13941)

	Syeda Nahida Akter, Shrimai Prabhumoye, Matvei Novikov, Seungju Han, Ying Lin, Evelina Bakhturina, Eric Nyberg, Yejin Choi, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro


# 2025-04-14
+ [Transferable text data distillation by trajectory matching](https://arxiv.org//abs/2504.09818)

	Rong Yao, Hailin Hu, Yifei Fu, Hanting Chen, Wenyi Fang, Fanyi Du, Kai Han, Yunhe Wang

# 2025-04-13
+ [CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent](https://arxiv.org//abs/2504.13192)

	Liang-bo Ning, Shijie Wang, Wenqi Fan, Qing Li, Xin Xu, Hao Chen, Feiran Huang

# 2025-04-10
+ [Throughput-Optimal Scheduling Algorithms for LLM Inference and AI Agents](https://arxiv.org//abs/2504.07347)

	Yueying Li, Jim Dai, Tianyi Peng


+ [Can Reasoning LLMs Enhance Clinical Document Classification?](https://arxiv.org//abs/2504.08040)

	Akram Mustafa, Usman Naseem, Mostafa Rahimi Azghadi

+ [Seed1.5-Thinking: Advancing Superb Reasoning Models with Reinforcement Learning](https://arxiv.org//abs/2504.13914)

	ByteDance Seed: Jiaze Chen, Tiantian Fan, Xin Liu, Lingjun Liu, Zhiqi Lin, Mingxuan Wang, Chengyi Wang, Xiangpeng Wei, Wenyuan Xu, Yufeng Yuan, Yu Yue, Lin Yan, Qiying Yu, Xiaochen Zuo, Chi Zhang, Ruofei Zhu, Zhecheng An, Zhihao Bai, Yu Bao, Xingyan Bin, Jiangjie Chen, Feng Chen, Hongmin Chen, Riwei Chen, Liangqiang Chen, Zixin Chen, Jinsong Chen, Siyan Chen, Kaiyuan Chen, Zhi Chen, Jin Chen, Jiecao Chen, Jinxin Chi, Weinan Dai, Ning Dai, Jiahui Dai, Shihan Dou, Yantao Du, Zhengyin Du, Jianhui Duan, Chen Dun, Ting-Han Fan, Jiazhan Feng, Junda Feng, Ziyuan Feng, Yuwei Fu, Wenqi Fu, Hanjie Fu, Hao Ge, Hongyi Guo, Mingji Han, Li Han, Wenhao Hao, Xintong Hao, Qianyu He, Jerry He, Feng He, Wen Heng, Zehua Hong, Qi Hou, Liang Hu, Shengding Hu, Nan Hu, Kai Hua, Qi Huang, Ziyue Huang, Hongzhi Huang, Zihao Huang, Ting Huang, Wenhao Huang, Wei Jia, Bin Jia, Xiaoying Jia, Yuhua Jiang, Haobin Jiang, Ziheng Jiang, Kaihua Jiang, Chengquan Jiang, Jianpeng Jiao, Xiaoran Jin, Xing Jin, Xunhao Lai, Zheng Li, Xiang Li, Liyi Li, Hongkai Li, Zheng Li, Shengxian Wan, Ya Wang, Yunshui Li, Chenggang Li, Niuniu Li, Siyu Li, Xi Li, Xiao Li, Aoyan Li, Yuntao Li, Nianning Liang, Xinnian Liang

# 2025-04-07


+ [A Desideratum for Conversational Agents: Capabilities, Challenges, and Future Directions](https://arxiv.org//abs/2504.16939)

	Emre Can Acikgoz, Cheng Qian, Hongru Wang, Vardhan Dongre, Xiusi Chen, Heng Ji, Dilek Hakkani-Tür, Gokhan Tur

+ [Not All Data Are Unlearned Equally](https://arxiv.org//abs/2504.05058)

	Aravind Krishnan, Siva Reddy, Marius Mosbach


+ [Lightweight and Direct Document Relevance Optimization for Generative Information Retrieval](https://arxiv.org//abs/2504.05181)

	Kidist Amde Mekonnen, Yubao Tang, Maarten de Rijke

+ [CCSK:Cognitive Convection of Self-Knowledge Based Retrieval Augmentation for Large Language Models](https://arxiv.org//abs/2504.10498)

	Jianling Lu, Mingqi Lv, Tieming Chen

+ [LLM-based Automated Grading with Human-in-the-Loop](https://arxiv.org//abs/2504.05239)

	Hang Li, Yucheng Chu, Kaiqi Yang, Yasemin Copur-Gencturk, Jiliang Tang

# 2025-04-03
+ [Cognitive Memory in Large Language Models](https://arxiv.org//abs/2504.02441)

	Lianlei Shan, Shixian Luo, Zezhou Zhu, Yu Yuan, Yong Wu


+ [Multifaceted Evaluation of Audio-Visual Capability for MLLMs: Effectiveness, Efficiency, Generalizability and Robustness](https://arxiv.org//abs/2504.16936)

	Yusheng Zhao, Junyu Luo, Xiao Luo, Weizhi Zhang, Zhiping Xiao, Wei Ju, Philip S. Yu, Ming Zhang



+ [Generative Evaluation of Complex Reasoning in Large Language Models](https://arxiv.org//abs/2504.02810)

	Haowei Lin, Xiangyu Wang, Ruilin Yan, Baizhou Huang, Haotian Ye, Jianhua Zhu, Zihao Wang, James Zou, Jianzhu Ma, Yitao Liang

# 2025-04-02
+ [LRAGE: Legal Retrieval Augmented Generation Evaluation Tool](https://arxiv.org//abs/2504.01840)

	Minhu Park, Hongseok Oh, Eunkyung Choi, Wonseok Hwang

# 2025-03-28
+ [Probabilistic Uncertain Reward Model: A Natural Generalization of Bradley-Terry Reward Model](https://arxiv.org//abs/2503.22480)

	Wangtao Sun, Xiang Cheng, Xing Yu, Haotian Xu, Zhao Yang, Shizhu He, Jun Zhao, Kang Liu

# 2025-03-27
+ [Shared Global and Local Geometry of Language Model Embeddings](https://arxiv.org//abs/2503.21073)

	Andrew Lee, Melanie Weber, Fernanda Viégas, Martin Wattenberg

# 2025-03-26
+ [Dynamic Pyramid Network for Efficient Multimodal Large Language Model](https://arxiv.org//abs/2503.20322)

	Hao Ai, Kunyi Wang, Zezhou Wang, Hao Lu, Jin Tian, Yaxin Luo, Peng Xing, Jen-Yuan Huang, Huaxia Li, Gen luo


# 2025-03-25
+ [CausalRAG: Integrating Causal Graphs into Retrieval-Augmented Generation](https://arxiv.org//abs/2503.19878)

	Nengbo Wang, Xiaotian Han, Jagdip Singh, Jing Ma, Vipin Chaudhary

# 2025-03-13
+ [HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks](https://arxiv.org//abs/2503.10894)

	Jiuding Sun, Jing Huang, Sidharth Baskaran, Karel D'Oosterlinck, Christopher Potts, Michael Sklar, Atticus Geiger


+ [HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks](https://arxiv.org//abs/2503.10894)

	Jiuding Sun, Jing Huang, Sidharth Baskaran, Karel D'Oosterlinck, Christopher Potts, Michael Sklar, Atticus Geiger

# 2025-03-12
+ [LocAgent: Graph-Guided LLM Agents for Code Localization](https://arxiv.org//abs/2503.09089)

	Zhaoling Chen, Xiangru Tang, Gangda Deng, Fang Wu, Jialong Wu, Zhiwei Jiang, Viktor Prasanna, Arman Cohan, Xingyao Wang

# 2025-03-11
+ [Training Plug-n-Play Knowledge Modules with Deep Context Distillation](https://arxiv.org//abs/2503.08727)

	Lucas Caccia, Alan Ansell, Edoardo Ponti, Ivan Vulić, Alessandro Sordoni

# 2025-03-09
+ [HCT-QA: A Benchmark for Question Answering on Human-Centric Tables](https://arxiv.org//abs/2504.20047)

	Mohammad S. Ahmad, Zan A. Naeem, Michaël Aupetit, Ahmed Elmagarmid, Mohamed Eltabakh, Xiasong Ma, Mourad Ouzzani, Chaoyi Ruan

# 2025-03-06
+ [Wanda++: Pruning Large Language Models via Regional Gradients](https://arxiv.org//abs/2503.04992)

	Yifan Yang, Kai Zhen, Bhavana Ganesh, Aram Galstyan, Goeric Huybrechts, Markus Müller, Jonas M. Kübler, Rupak Vignesh Swaminathan, Athanasios Mouchtaris, Sravan Babu Bodapati, Nathan Susanj, Zheng Zhang, Jack FitzGerald, Abhishek Kumar

# 2025-02-24
+ [Automatically Evaluating the Paper Reviewing Capability of Large Language Models](https://arxiv.org//abs/2502.17086)

	Hyungyu Shin, Jingyu Tang, Yoonjoo Lee, Nayoung Kim, Hyunseung Lim, Ji Yong Cho, Hwajung Hong, Moontae Lee, Juho Kim

+ [From System 1 to System 2: A Survey of Reasoning Large Language Models](https://arxiv.org//abs/2502.17419)

	Zhong-Zhi Li, Duzhen Zhang, Ming-Liang Zhang, Jiaxin Zhang, Zengyan Liu, Yuxuan Yao, Haotian Xu, Junhao Zheng, Pei-Jie Wang, Xiuyi Chen, Yingying Zhang, Fei Yin, Jiahua Dong, Zhiwei Li, Bao-Long Bi, Ling-Rui Mei, Junfeng Fang, Zhijiang Guo, Le Song, Cheng-Lin Liu

+ [MEMERAG: A Multilingual End-to-End Meta-Evaluation Benchmark for Retrieval Augmented Generation](https://arxiv.org//abs/2502.17163)

	María Andrea Cruz Blandón, Jayasimha Talur, Bruno Charron, Dong Liu, Saab Mansour, Marcello Federico

# 2025-02-21
+ [Machine-generated text detection prevents language model collapse](https://arxiv.org//abs/2502.15654)

	George Drayson, Emine Yilmaz, Vasileios Lampos

# 2025-02-18
+ [EPO: Explicit Policy Optimization for Strategic Reasoning in LLMs via Reinforcement Learning](https://arxiv.org//abs/2502.12486)

	Xiaoqian Liu, Ke Wang, Yongbin Li, Yuchuan Wu, Wentao Ma, Aobo Kong, Fei Huang, Jianbin Jiao, Junge Zhang

+ [An LLM-Powered Agent for Physiological Data Analysis: A Case Study on PPG-based Heart Rate Estimation](https://arxiv.org//abs/2502.12836)

	Mohammad Feli, Iman Azimi, Pasi Liljeberg, Amir M.Rahmani

# 2025-02-17
+ [Towards Reasoning Ability of Small Language Models](https://arxiv.org//abs/2502.11569)

	Gaurav Srivastava, Shuxiang Cao, Xuan Wang


# 2025-02-11
+ [Time2Lang: Bridging Time-Series Foundation Models and Large Language Models for Health Sensing Beyond Prompting](https://arxiv.org//abs/2502.07608)

	Arvind Pillai, Dimitris Spathis, Subigya Nepal, Amanda C Collins, Daniel M Mackin, Michael V Heinz, Tess Z Griffin, Nicholas C Jacobson, Andrew Campbell

# 2025-02-10
+ [Generating Privacy-Preserving Personalized Advice with Zero-Knowledge Proofs and LLMs](https://arxiv.org//abs/2502.06425)

	Hiroki Watanabe, Motonobu Uchikoshi


# 2025-02-07
+ [Probabilistic Subspace Manifolds for Contextual Inference in Large Language Models](https://arxiv.org//abs/2502.05346)

	Christopher Nightingale, Dominic Lavington, Jonathan Thistlethwaite, Sebastian Penhaligon, Thomas Belinski, David Boldo

# 2025-02-03
+ [Efficient Model Editing with Task Vector Bases: A Theoretical Framework and Scalable Approach](https://arxiv.org//abs/2502.01015)

	Siqi Zeng, Yifei He, Weiqiu You, Yifan Hao, Yao-Hung Hubert Tsai, Makoto Yamada, Han Zhao


+ [Factual Knowledge in Language Models: Robustness and Anomalies under Simple Temporal Context Variations](https://arxiv.org//abs/2502.01220)

	Hichem Ammar Khodja, Frédéric Béchet, Quentin Brabant, Alexis Nasr, Gwénolé Lecorvé

+ [Efficient Model Editing with Task Vector Bases: A Theoretical Framework and Scalable Approach](https://arxiv.org//abs/2502.01015)

	Siqi Zeng, Yifei He, Weiqiu You, Yifan Hao, Yao-Hung Hubert Tsai, Makoto Yamada, Han Zhao

+ [Massive Values in Self-Attention Modules are the Key to Contextual Knowledge Understanding](https://arxiv.org//abs/2502.01563)

	Mingyu Jin, Kai Mei, Wujiang Xu, Mingjie Sun, Ruixiang Tang, Mengnan Du, Zirui Liu, Yongfeng Zhang

# 2025-01-27
+ [Are Transformers Able to Reason by Connecting Separated Knowledge in Training Data?](https://arxiv.org//abs/2501.15857)

	Yutong Yin, Zhaoran Wang


# 2025-01-24
+ [Context-Aware Neural Gradient Mapping for Fine-Grained Instruction Processing](https://arxiv.org//abs/2501.14936)

	David Boldo, Lily Pemberton, Gabriel Thistledown, Jacob Fairchild, Felix Kowalski


# 2025-01-23
+ [GraphRAG under Fire](https://arxiv.org//abs/2501.14050)

	Jiacheng Liang, Yuhui Wang, Changjiang Li, Rongyi Zhu, Tanqiu Jiang, Neil Gong, Ting Wang


# 2025-01-21
+ [Test-time regression: a unifying framework for designing sequence models with associative memory](https://arxiv.org//abs/2501.12352)

	Ke Alexander Wang, Jiaxin Shi, Emily B. Fox

# 2025-01-09
+ [CallNavi, A Challenge and Empirical Study on LLM Function Calling and Routing](https://arxiv.org//abs/2501.05255)

	Yewei Song, Xunzhu Tang, Cedric Lothritz, Saad Ezzini, Jacques Klein, Tegawendé F. Bissyandé, Andrey Boytsov, Ulrick Ble, Anne Goujon


# 2024-12-20
+ [Less is More: Towards Green Code Large Language Models via Unified Structural Pruning](https://arxiv.org//abs/2412.15921)

	Guang Yang, Yu Zhou, Xiangyu Zhang, Wei Cheng, Ke Liu, Xiang Chen, Terry Yue Zhuo, Taolue Chen


# 2024-12-16
+ [ElChat: Adapting Chat Language Models Using Only Target Unlabeled Language Data](https://arxiv.org//abs/2412.11704)

	Atsuki Yamaguchi, Terufumi Morishita, Aline Villavicencio, Nikolaos Aletras

# 2024-12-07
+ [SLA Management in Reconfigurable Multi-Agent RAG: A Systems Approach to Question Answering](https://arxiv.org//abs/2412.06832)

	Michael Iannelli, Sneha Kuchipudi, Vera Dvorak

# 2024-12-03
+ [Enhancing LLMs with Smart Preprocessing for EHR Analysis](https://arxiv.org//abs/2412.02868)

	Yixiang Qu, Yifan Dai, Shilin Yu, Pradham Tanikella, Travis Schrank, Trevor Hackman, Didong Li, Di Wu


+ [DP-2Stage: Adapting Language Models as Differentially Private Tabular Data Generators](https://arxiv.org//abs/2412.02467)

	Tejumade Afonja, Hui-Po Wang, Raouf Kerkouche, Mario Fritz

# 2024-11-19
+ [The Moral Mind(s) of Large Language Models](https://arxiv.org//abs/2412.04476)

	Avner Seror

# 2024-11-17
+ [JailbreakLens: Interpreting Jailbreak Mechanism in the Lens of Representation and Circuit](https://arxiv.org//abs/2411.11114)

	Zeqing He, Zhibo Wang, Zhixuan Chu, Huiyu Xu, Wenhui Zhang, Qinglong Wang, Rui Zheng


# 2024-11-12
+ [Knowledge-Augmented Multimodal Clinical Rationale Generation for Disease Diagnosis with Small Language Models](https://arxiv.org//abs/2411.07611)

	Shuai Niu, Jing Ma, Hongzhan Lin, Liang Bai, Zhihua Wang, Yida Xu, Yunya Song, Xian Yang

+ [Beyond the Safety Bundle: Auditing the Helpful and Harmless Dataset](https://arxiv.org//abs/2411.08243)

	Khaoula Chehbouni, Jonathan Colaço Carr, Yash More, Jackie CK Cheung, Golnoosh Farnadi

# 2024-11-09
+ [A Picture is Worth A Thousand Numbers: Enabling LLMs Reason about Time Series via Visualization](https://arxiv.org//abs/2411.06018)

	Haoxin Liu, Chenghao Liu, B. Aditya Prakash

# 2024-10-31
+ [AlphaTrans: A Neuro-Symbolic Compositional Approach for Repository-Level Code Translation and Validation](https://arxiv.org//abs/2410.24117)

	Ali Reza Ibrahimzada, Kaiyao Ke, Mrigank Pawagi, Muhammad Salman Abid, Rangeet Pan, Saurabh Sinha, Reyhaneh Jabbarvand

+ [Constraint Back-translation Improves Complex Instruction Following of Large Language Models](https://arxiv.org//abs/2410.24175)

	Yunjia Qi, Hao Peng, Xiaozhi Wang, Bin Xu, Lei Hou, Juanzi Li

# 2024-10-30
+ [MDCure: A Scalable Pipeline for Multi-Document Instruction-Following](https://arxiv.org//abs/2410.23463)

	Gabrielle Kaili-May Liu, Bowen Shi, Avi Caciularu, Idan Szpektor, Arman Cohan

# 2024-10-24
+ [Parameter-Efficient Fine-Tuning in Large Models: A Survey of Methodologies](https://arxiv.org//abs/2410.19878)

	Luping Wang, Sheng Chen, Linnan Jiang, Shu Pan, Runze Cai, Sen Yang, Fei Yang

# 2024-10-15
+ [MIND: Math Informed syNthetic Dialogues for Pretraining LLMs](https://arxiv.org//abs/2410.12881)

	Syeda Nahida Akter, Shrimai Prabhumoye, John Kamalu, Sanjeev Satheesh, Eric Nyberg, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro

# 2024-10-06
+ [Regressing the Relative Future: Efficient Policy Optimization for Multi-turn RLHF](https://arxiv.org//abs/2410.04612)

	Zhaolin Gao, Wenhao Zhan, Jonathan D. Chang, Gokul Swamy, Kianté Brantley, Jason D. Lee, Wen Sun


# 2024-10-03
+ [Selective Attention Improves Transformer](https://arxiv.org//abs/2410.02703)

	Yaniv Leviathan, Matan Kalman, Yossi Matias


# 2024-10-02
+ [TypedThinker: Diversify Large Language Model Reasoning with Typed Thinking](https://arxiv.org//abs/2410.01952)

	Danqing Wang, Jianxin Ma, Fei Fang, Lei Li


+ [Racing Thoughts: Explaining Contextualization Errors in Large Language Models](https://arxiv.org//abs/2410.02102)

	Michael A. Lepori, Michael C. Mozer, Asma Ghandeharioun

# 2024-09-27
+ [Can LLMs Really Learn to Translate a Low-Resource Language from One Grammar Book?](https://arxiv.org//abs/2409.19151)

	Seth Aycock, David Stap, Di Wu, Christof Monz, Khalil Sima'an

# 2024-09-23
+ [Scideator: Human-LLM Scientific Idea Generation Grounded in Research-Paper Facet Recombination](https://arxiv.org//abs/2409.14634)

	Marissa Radensky, Simra Shahid, Raymond Fok, Pao Siangliulue, Tom Hope, Daniel S. Weld

# 2024-09-19
+ [Prompts Are Programs Too! Understanding How Developers Build Software Containing Prompts](https://arxiv.org//abs/2409.12447)

	Jenny T. Liang, Melissa Lin, Nikitha Rao, Brad A. Myers

# 2024-09-17
+ [Measuring and Enhancing Trustworthiness of LLMs in RAG through Grounded Attributions and Learning to Refuse](https://arxiv.org//abs/2409.11242)

	Maojia Song, Shang Hong Sim, Rishabh Bhardwaj, Hai Leong Chieu, Navonil Majumder, Soujanya Poria

# 2024-09-16
+ [Lab-AI: Using Retrieval Augmentation to Enhance Language Models for Personalized Lab Test Interpretation in Clinical Medicine](https://arxiv.org//abs/2409.18986)

	Xiaoyu Wang, Haoyong Ouyang, Balu Bhasuran, Xiao Luo, Karim Hanna, Mia Liza A. Lustria, Carl Yang, Zhe He


# 2024-09-13
+ [Your Weak LLM is Secretly a Strong Teacher for Alignment](https://arxiv.org//abs/2409.08813)

	Leitian Tao, Yixuan Li

# 2024-09-10
+ [LaMsS: When Large Language Models Meet Self-Skepticism](https://arxiv.org//abs/2409.06601)

	Yetao Wu, Yihong Wang, Teng Chen, Ningyuan Xi, Qingqing Gu, Hongyang Lei, Luo Ji

# 2024-07-31
+ [Correcting Negative Bias in Large Language Models through Negative Attention Score Alignment](https://arxiv.org//abs/2408.00137)

	Sangwon Yu, Jongyoon Song, Bongkyu Hwang, Hoyoung Kang, Sooah Cho, Junhwa Choi, Seongho Joe, Taehee Lee, Youngjune L. Gwon, Sungroh Yoon

# 2024-07-21
+ [A Practical Analysis of Human Alignment with *PO](https://arxiv.org//abs/2407.15229)

	Kian Ahrabian, Xihui Lin, Barun Patra, Vishrav Chaudhary, Alon Benhaim, Jay Pujara, Xia Song

# 2024-06-25
+ [OPT-Tree: Speculative Decoding with Adaptive Draft Tree Structure](https://arxiv.org//abs/2406.17276)

	Jikai Wang, Yi Su, Juntao Li, Qingrong Xia, Zi Ye, Xinyu Duan, Zhefeng Wang, Min Zhang


# 2024-06-20
+ [ReaL: Efficient RLHF Training of Large Language Models with Parameter Reallocation](https://arxiv.org//abs/2406.14088)

	Zhiyu Mei, Wei Fu, Kaiwei Li, Guangju Wang, Huanchen Zhang, Yi Wu

# 2024-06-15
+ [Unlocking Large Language Model's Planning Capabilities with Maximum Diversity Fine-tuning](https://arxiv.org//abs/2406.10479)

	Wenjun Li, Changyu Chen, Pradeep Varakantham

# 2024-05-29
+ [Nearest Neighbor Speculative Decoding for LLM Generation and Attribution](https://arxiv.org//abs/2405.19325)

	Minghan Li, Xilun Chen, Ari Holtzman, Beidi Chen, Jimmy Lin, Wen-tau Yih, Xi Victoria Lin

# 2024-04-04
+ [PRobELM: Plausibility Ranking Evaluation for Language Models](https://arxiv.org//abs/2404.03818)

	Zhangdie Yuan, Eric Chamoun, Rami Aly, Chenxi Whitehouse, Andreas Vlachos

# 2024-03-21
+ [Agentic AI: The Era of Semantic Decoding](https://arxiv.org//abs/2403.14562)

	Maxime Peyrard, Martin Josifoski, Robert West

# 2024-03-19
+ [To Help or Not to Help: LLM-based Attentive Support for Human-Robot Group Interactions](https://arxiv.org//abs/2403.12533)

	Daniel Tanneberg, Felix Ocker, Stephan Hasler, Joerg Deigmoeller, Anna Belardinelli, Chao Wang, Heiko Wersing, Bernhard Sendhoff, Michael Gienger

# 2023-10-11
+ [CoPAL: Corrective Planning of Robot Actions with Large Language Models](https://arxiv.org//abs/2310.07263)

	Frank Joublin, Antonello Ceravola, Pavel Smirnov, Felix Ocker, Joerg Deigmoeller, Anna Belardinelli, Chao Wang, Stephan Hasler, Daniel Tanneberg, Michael Gienger


# 2023-10-05
+ [LLM-Coordination: Evaluating and Analyzing Multi-agent Coordination Abilities in Large Language Models](https://arxiv.org//abs/2310.03903)

	Saaket Agashe, Yue Fan, Anthony Reyna, Xin Eric Wang

# 2023-08-17
+ [Semantic Consistency for Assuring Reliability of Large Language Models](https://arxiv.org//abs/2308.09138)

	Harsh Raj, Vipul Gupta, Domenic Rosati, Subhabrata Majumdar

# 2023-03-03
+ [Prophet: Prompting Large Language Models with Complementary Answer Heuristics for Knowledge-based Visual Question Answering](https://arxiv.org//abs/2303.01903)

	Zhou Yu, Xuecheng Ouyang, Zhenwei Shao, Meng Wang, Jun Yu

